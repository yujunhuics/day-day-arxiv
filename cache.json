{"2024-10-17T00:00:00Z":{"Computation and Language":[{"id":"http://arxiv.org/abs/2410.12735v2","updated":"2024-10-17T02:47:35Z","published":"2024-10-16T16:51:01Z","title":"CREAM: Consistency Regularized Self-Rewarding Language Models","summary":"  Recent self-rewarding large language models (LLM) have successfully applied\nLLM-as-a-Judge to iteratively improve the alignment performance without the\nneed of human annotations for preference data. These methods commonly utilize\nthe same LLM to act as both the policy model (which generates responses) and\nthe reward model (which scores and ranks those responses). The ranked responses\nare then used as preference pairs to train the LLM via direct alignment\ntechnologies (e.g. DPO). However, it is noteworthy that throughout this\nprocess, there is no guarantee of accuracy in the rewarding and ranking, which\nis critical for ensuring accurate rewards and high-quality preference data.\nEmpirical results from relatively small LLMs (e.g., 7B parameters) also\nindicate that improvements from self-rewarding may diminish after several\niterations in certain situations, which we hypothesize is due to accumulated\nbias in the reward system. This bias can lead to unreliable preference data for\ntraining the LLM. To address this issue, we first formulate and analyze the\ngeneralized iterative preference fine-tuning framework for self-rewarding\nlanguage model. We then introduce the regularization to this generalized\nframework to mitigate the overconfident preference labeling in the\nself-rewarding process. Based on this theoretical insight, we propose a\nConsistency Regularized sElf-rewarding lAnguage Model (CREAM) that leverages\nthe rewarding consistency across different iterations to regularize the\nself-rewarding training, helping the model to learn from more reliable\npreference data. With this explicit regularization, our empirical results\ndemonstrate the superiority of CREAM in improving both reward consistency and\nalignment performance. The code is publicly available at\nhttps://github.com/Raibows/CREAM.\n","authors":["Zhaoyang Wang","Weilei He","Zhiyuan Liang","Xuchao Zhang","Chetan Bansal","Ying Wei","Weitong Zhang","Huaxiu Yao"],"pdf_url":"https://arxiv.org/pdf/2410.12735v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.12691v2","updated":"2024-10-17T13:32:23Z","published":"2024-10-16T15:51:18Z","title":"Building Better: Avoiding Pitfalls in Developing Language Resources when\n  Data is Scarce","summary":"  Language is a symbolic capital that affects people's lives in many ways\n(Bourdieu, 1977, 1991). It is a powerful tool that accounts for identities,\ncultures, traditions, and societies in general. Hence, data in a given language\nshould be viewed as more than a collection of tokens. Good data collection and\nlabeling practices are key to building more human-centered and socially aware\ntechnologies. While there has been a rising interest in mid- to low-resource\nlanguages within the NLP community, work in this space has to overcome unique\nchallenges such as data scarcity and access to suitable annotators. In this\npaper, we collect feedback from those directly involved in and impacted by NLP\nartefacts for mid- to low-resource languages. We conduct a quantitative and\nqualitative analysis of the responses and highlight the main issues related to\n(1) data quality such as linguistic and cultural data suitability; and (2) the\nethics of common annotation practices such as the misuse of online community\nservices. Based on these findings, we make several recommendations for the\ncreation of high-quality language artefacts that reflect the cultural milieu of\nits speakers, while simultaneously respecting the dignity and labor of data\nworkers.\n","authors":["Nedjma Ousidhoum","Meriem Beloucif","Saif M. Mohammad"],"pdf_url":"https://arxiv.org/pdf/2410.12691v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.12622v2","updated":"2024-10-17T08:28:45Z","published":"2024-10-16T14:42:23Z","title":"From Measurement Instruments to Data: Leveraging Theory-Driven Synthetic\n  Training Data for Classifying Social Constructs","summary":"  Computational text classification is a challenging task, especially for\nmulti-dimensional social constructs. Recently, there has been increasing\ndiscussion that synthetic training data could enhance classification by\noffering examples of how these constructs are represented in texts. In this\npaper, we systematically examine the potential of theory-driven synthetic\ntraining data for improving the measurement of social constructs. In\nparticular, we explore how researchers can transfer established knowledge from\nmeasurement instruments in the social sciences, such as survey scales or\nannotation codebooks, into theory-driven generation of synthetic data. Using\ntwo studies on measuring sexism and political topics, we assess the added value\nof synthetic training data for fine-tuning text classification models. Although\nthe results of the sexism study were less promising, our findings demonstrate\nthat synthetic data can be highly effective in reducing the need for labeled\ndata in political topic classification. With only a minimal drop in\nperformance, synthetic data allows for substituting large amounts of labeled\ndata. Furthermore, theory-driven synthetic data performed markedly better than\ndata generated without conceptual information in mind.\n","authors":["Lukas Birkenmaier","Matthias Roth","Indira Sen"],"pdf_url":"https://arxiv.org/pdf/2410.12622v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.12543v2","updated":"2024-10-17T02:28:25Z","published":"2024-10-16T13:21:46Z","title":"LLM-based Translation Inference with Iterative Bilingual Understanding","summary":"  The remarkable understanding and generation capabilities of large language\nmodels (LLMs) have greatly improved translation performance. However, incorrect\nunderstanding of the sentence to be translated can degrade translation quality.\nTo address this issue, we proposed a novel Iterative Bilingual Understanding\nTranslation (IBUT) method based on the cross-lingual capabilities of LLMs and\nthe dual characteristics of translation tasks. The cross-lingual capability of\nLLMs enables the generation of contextual understanding for both the source and\ntarget languages separately. Furthermore, the dual characteristics allow IBUT\nto generate effective cross-lingual feedback, iteratively refining contextual\nunderstanding, thereby reducing errors and improving translation performance.\nExperimental results showed that the proposed IBUT outperforms several strong\ncomparison methods, especially being generalized to multiple domains (e.g.,\nnews, commonsense, and cultural translation benchmarks).\n","authors":["Andong Chen","Kehai Chen","Yang Xiang","Xuefeng Bai","Muyun Yang","Tiejun Zhao","Min zhang"],"pdf_url":"https://arxiv.org/pdf/2410.12543v2.pdf","comment":"Work in progress"},{"id":"http://arxiv.org/abs/2410.12532v2","updated":"2024-10-17T09:22:41Z","published":"2024-10-16T13:10:27Z","title":"MedAide: Towards an Omni Medical Aide via Specialized LLM-based\n  Multi-Agent Collaboration","summary":"  Large Language Model (LLM)-driven interactive systems currently show\npotential promise in healthcare domains. Despite their remarkable capabilities,\nLLMs typically lack personalized recommendations and diagnosis analysis in\nsophisticated medical applications, causing hallucinations and performance\nbottlenecks. To address these challenges, this paper proposes MedAide, an\nLLM-based omni medical multi-agent collaboration framework for specialized\nhealthcare services. Specifically, MedAide first performs query rewriting\nthrough retrieval-augmented generation to accomplish accurate medical intent\nunderstanding. Immediately, we devise a contextual encoder to obtain intent\nprototype embeddings, which are used to recognize fine-grained intents by\nsimilarity matching. According to the intent relevance, the activated agents\ncollaborate effectively to provide integrated decision analysis. Extensive\nexperiments are conducted on four medical benchmarks with composite intents.\nExperimental results from automated metrics and expert doctor evaluations show\nthat MedAide outperforms current LLMs and improves their medical proficiency\nand strategic reasoning.\n","authors":["Jinjie Wei","Dingkang Yang","Yanshu Li","Qingyao Xu","Zhaoyu Chen","Mingcheng Li","Yue Jiang","Xiaolu Hou","Lihua Zhang"],"pdf_url":"https://arxiv.org/pdf/2410.12532v2.pdf","comment":"LLM-based Multi-Agent Collaboration for Medical Applications"},{"id":"http://arxiv.org/abs/2408.09945v3","updated":"2024-10-17T02:17:57Z","published":"2024-08-19T12:34:31Z","title":"Benchmarking LLMs for Translating Classical Chinese Poetry:Evaluating\n  Adequacy, Fluency, and Elegance","summary":"  Large language models (LLMs) have shown remarkable performance in translation\ntasks. However, the increasing demand for high-quality translations that are\nnot only adequate but also fluent and elegant. To evaluate the extent to which\ncurrent LLMs can meet these demands, we introduce a suitable benchmark (PoetMT)\nfor translating classical Chinese poetry into English. This task requires not\nonly adequacy in translating culturally and historically significant content\nbut also a strict adherence to linguistic fluency and poetic elegance. To\novercome the limitations of traditional evaluation metrics, we propose an\nautomatic evaluation metric based on GPT-4, which better evaluates translation\nquality in terms of adequacy, fluency, and elegance. Our evaluation study\nreveals that existing large language models fall short in this task. To\nevaluate these issues, we propose RAT, a Retrieval-Augmented machine\nTranslation method that enhances the translation process by incorporating\nknowledge related to classical poetry. Our dataset and code will be made\navailable.\n","authors":["Andong Chen","Lianzhang Lou","Kehai Chen","Xuefeng Bai","Yang Xiang","Muyun Yang","Tiejun Zhao","Min Zhang"],"pdf_url":"https://arxiv.org/pdf/2408.09945v3.pdf","comment":"Work in progress"},{"id":"http://arxiv.org/abs/2407.08440v4","updated":"2024-10-17T07:00:19Z","published":"2024-07-11T12:26:55Z","title":"Beyond Instruction Following: Evaluating Inferential Rule Following of\n  Large Language Models","summary":"  Although Large Language Models (LLMs) have demonstrated strong ability, they\nare further supposed to be controlled and guided by in real-world scenarios to\nbe safe, accurate, and intelligent. This demands the possession of capability\nof LLMs. However, no prior work has made a clear evaluation of the inferential\nrule-following capability of LLMs. Previous studies that try to evaluate the\ninferential rule-following capability of LLMs fail to distinguish the\ninferential rule-following scenarios from the instruction-following scenarios.\nTherefore, this paper first clarifies the concept of inferential rule-following\nand proposes a comprehensive benchmark, RuleBench, to evaluate a diversified\nrange of inferential rule-following abilities. Our experimental results on a\nvariety of LLMs show that they are still limited in following rules. Our\nanalysis based on the evaluation results provides insights into the\nimprovements for LLMs toward a better inferential rule-following intelligent\nagent. We further propose Inferential Rule-Following Tuning (IRFT). The\nexperimental results show that through IRFT, LLMs can learn abstract\nrule-following abilities from purely synthetic data and then generalize to\nRuleBench. The data and code can be found at:\nhttps://anonymous.4open.science/r/llm-rule-following-B3E3/\n","authors":["Wangtao Sun","Chenxiang Zhang","XueYou Zhang","Xuanqing Yu","Ziyang Huang","Pei Chen","Haotian Xu","Shizhu He","Jun Zhao","Kang Liu"],"pdf_url":"https://arxiv.org/pdf/2407.08440v4.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.12407v2","updated":"2024-10-17T15:59:34Z","published":"2024-10-16T09:42:29Z","title":"Beyond Coarse-Grained Matching in Video-Text Retrieval","summary":"  Video-text retrieval has seen significant advancements, yet the ability of\nmodels to discern subtle differences in captions still requires verification.\nIn this paper, we introduce a new approach for fine-grained evaluation. Our\napproach can be applied to existing datasets by automatically generating hard\nnegative test captions with subtle single-word variations across nouns, verbs,\nadjectives, adverbs, and prepositions. We perform comprehensive experiments\nusing four state-of-the-art models across two standard benchmarks (MSR-VTT and\nVATEX) and two specially curated datasets enriched with detailed descriptions\n(VLN-UVO and VLN-OOPS), resulting in a number of novel insights: 1) our\nanalyses show that the current evaluation benchmarks fall short in detecting a\nmodel's ability to perceive subtle single-word differences, 2) our fine-grained\nevaluation highlights the difficulty models face in distinguishing such subtle\nvariations. To enhance fine-grained understanding, we propose a new baseline\nthat can be easily combined with current methods. Experiments on our\nfine-grained evaluations demonstrate that this approach enhances a model's\nability to understand fine-grained differences.\n","authors":["Aozhu Chen","Hazel Doughty","Xirong Li","Cees G. M. Snoek"],"pdf_url":"https://arxiv.org/pdf/2410.12407v2.pdf","comment":"Accepted to ACCV 2024"},{"id":"http://arxiv.org/abs/2410.12388v2","updated":"2024-10-17T04:09:09Z","published":"2024-10-16T09:13:23Z","title":"Prompt Compression for Large Language Models: A Survey","summary":"  Leveraging large language models (LLMs) for complex natural language tasks\ntypically requires long-form prompts to convey detailed requirements and\ninformation, which results in increased memory usage and inference costs. To\nmitigate these challenges, multiple efficient methods have been proposed, with\nprompt compression gaining significant research interest. This survey provides\nan overview of prompt compression techniques, categorized into hard prompt\nmethods and soft prompt methods. First, the technical approaches of these\nmethods are compared, followed by an exploration of various ways to understand\ntheir mechanisms, including the perspectives of attention optimization,\nParameter-Efficient Fine-Tuning (PEFT), modality integration, and new synthetic\nlanguage. We also examine the downstream adaptations of various prompt\ncompression techniques. Finally, the limitations of current prompt compression\nmethods are analyzed, and several future directions are outlined, such as\noptimizing the compression encoder, combining hard and soft prompts methods,\nand leveraging insights from multimodality.\n","authors":["Zongqian Li","Yinhong Liu","Yixuan Su","Nigel Collier"],"pdf_url":"https://arxiv.org/pdf/2410.12388v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.12298v2","updated":"2024-10-17T11:00:37Z","published":"2024-10-16T06:57:18Z","title":"Pyramid-Driven Alignment: Pyramid Principle Guided Integration of Large\n  Language Models and Knowledge Graphs","summary":"  Large Language Models (LLMs) possess impressive reasoning abilities but are\nprone to generating incorrect information, often referred to as hallucinations.\nWhile incorporating external Knowledge Graphs (KGs) can partially mitigate this\nissue, existing methods primarily treat KGs as static knowledge repositories,\noverlooking the critical disparity between KG and LLM knowledge, and failing to\nfully exploit the reasoning capabilities inherent in KGs. To address these\nlimitations, we propose Pyramid-Driven Alignment (PDA), a novel framework for\nseamlessly integrating LLMs with KGs. PDA utilizes Pyramid Principle analysis\nto construct a hierarchical pyramid structure. This structure is designed to\nreflect the input question and generate more validated deductive knowledge,\nthereby enhancing the alignment of LLMs and KGs and ensuring more cohesive\nintegration. Furthermore, PDA employs a recursive mechanism to harness the\nunderlying reasoning abilities of KGs, resulting in more accurate knowledge\nretrieval for question-answering tasks. Our experimental results reveal a\nsubstantial performance advantage of PDA over state-of-the-art baselines, with\nimprovements reaching 26.70% and 26.78%.\n","authors":["Lei Sun","Xinchen Wang","Youdi Li"],"pdf_url":"https://arxiv.org/pdf/2410.12298v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.12294v2","updated":"2024-10-17T13:27:43Z","published":"2024-10-16T06:51:09Z","title":"LLM-based Cognitive Models of Students with Misconceptions","summary":"  Accurately modeling student cognition is crucial for developing effective\nAI-driven educational technologies. A key challenge is creating realistic\nstudent models that satisfy two essential properties: (1) accurately\nreplicating specific misconceptions, and (2) correctly solving problems where\nthese misconceptions are not applicable. This dual requirement reflects the\ncomplex nature of student understanding, where misconceptions coexist with\ncorrect knowledge. This paper investigates whether Large Language Models (LLMs)\ncan be instruction-tuned to meet this dual requirement and effectively simulate\nstudent thinking in algebra. We introduce MalAlgoPy, a novel Python library\nthat generates datasets reflecting authentic student solution patterns through\na graph-based representation of algebraic problem-solving. Utilizing MalAlgoPy,\nwe define and examine Cognitive Student Models (CSMs) - LLMs instruction tuned\nto faithfully emulate realistic student behavior. Our findings reveal that LLMs\ntrained on misconception examples can efficiently learn to replicate errors.\nHowever, the training diminishes the model's ability to solve problems\ncorrectly, particularly for problem types where the misconceptions are not\napplicable, thus failing to satisfy second property of CSMs. We demonstrate\nthat by carefully calibrating the ratio of correct to misconception examples in\nthe training data - sometimes as low as 0.25 - it is possible to develop CSMs\nthat satisfy both properties. Our insights enhance our understanding of\nAI-based student models and pave the way for effective adaptive learning\nsystems.\n","authors":["Shashank Sonkar","Xinghe Chen","Naiming Liu","Richard G. Baraniuk","Mrinmaya Sachan"],"pdf_url":"https://arxiv.org/pdf/2410.12294v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.13857v1","updated":"2024-10-17T17:59:35Z","published":"2024-10-17T17:59:35Z","title":"How Numerical Precision Affects Mathematical Reasoning Capabilities of\n  LLMs","summary":"  Despite the remarkable success of Transformer-based Large Language Models\n(LLMs) across various domains, understanding and enhancing their mathematical\ncapabilities remains a significant challenge. In this paper, we conduct a\nrigorous theoretical analysis of LLMs' mathematical abilities, with a specific\nfocus on their arithmetic performances. We identify numerical precision as a\nkey factor that influences their effectiveness in mathematical tasks. Our\nresults show that Transformers operating with low numerical precision fail to\naddress arithmetic tasks, such as iterated addition and integer multiplication,\nunless the model size grows super-polynomially with respect to the input\nlength. In contrast, Transformers with standard numerical precision can\nefficiently handle these tasks with significantly smaller model sizes. We\nfurther support our theoretical findings through empirical experiments that\nexplore the impact of varying numerical precision on arithmetic tasks,\nproviding valuable insights for improving the mathematical reasoning\ncapabilities of LLMs.\n","authors":["Guhao Feng","Kai Yang","Yuntian Gu","Xinyue Ai","Shengjie Luo","Jiacheng Sun","Di He","Zhenguo Li","Liwei Wang"],"pdf_url":"https://arxiv.org/pdf/2410.13857v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.13854v1","updated":"2024-10-17T17:59:24Z","published":"2024-10-17T17:59:24Z","title":"Can MLLMs Understand the Deep Implication Behind Chinese Images?","summary":"  As the capabilities of Multimodal Large Language Models (MLLMs) continue to\nimprove, the need for higher-order capability evaluation of MLLMs is\nincreasing. However, there is a lack of work evaluating MLLM for higher-order\nperception and understanding of Chinese visual content. To fill the gap, we\nintroduce the **C**hinese **I**mage **I**mplication understanding\n**Bench**mark, **CII-Bench**, which aims to assess the higher-order perception\nand understanding capabilities of MLLMs for Chinese images. CII-Bench stands\nout in several ways compared to existing benchmarks. Firstly, to ensure the\nauthenticity of the Chinese context, images in CII-Bench are sourced from the\nChinese Internet and manually reviewed, with corresponding answers also\nmanually crafted. Additionally, CII-Bench incorporates images that represent\nChinese traditional culture, such as famous Chinese traditional paintings,\nwhich can deeply reflect the model's understanding of Chinese traditional\nculture. Through extensive experiments on CII-Bench across multiple MLLMs, we\nhave made significant findings. Initially, a substantial gap is observed\nbetween the performance of MLLMs and humans on CII-Bench. The highest accuracy\nof MLLMs attains 64.4%, where as human accuracy averages 78.2%, peaking at an\nimpressive 81.0%. Subsequently, MLLMs perform worse on Chinese traditional\nculture images, suggesting limitations in their ability to understand\nhigh-level semantics and lack a deep knowledge base of Chinese traditional\nculture. Finally, it is observed that most models exhibit enhanced accuracy\nwhen image emotion hints are incorporated into the prompts. We believe that\nCII-Bench will enable MLLMs to gain a better understanding of Chinese semantics\nand Chinese-specific images, advancing the journey towards expert artificial\ngeneral intelligence (AGI). Our project is publicly available at\nhttps://cii-bench.github.io/.\n","authors":["Chenhao Zhang","Xi Feng","Yuelin Bai","Xinrun Du","Jinchang Hou","Kaixin Deng","Guangzeng Han","Qinrui Li","Bingli Wang","Jiaheng Liu","Xingwei Qu","Yifei Zhang","Qixuan Zhao","Yiming Liang","Ziqiang Liu","Feiteng Fang","Min Yang","Wenhao Huang","Chenghua Lin","Ge Zhang","Shiwen Ni"],"pdf_url":"https://arxiv.org/pdf/2410.13854v1.pdf","comment":"32 pages,18 figures. Project Page: https://cii-bench.github.io/ Code:\n  https://github.com/MING_X/CII-Bench Dataset:\n  https://huggingface.co/datasets/m-a-p/CII-Bench"},{"id":"http://arxiv.org/abs/2410.13852v1","updated":"2024-10-17T17:59:03Z","published":"2024-10-17T17:59:03Z","title":"Retrospective Learning from Interactions","summary":"  Multi-turn interactions between large language models (LLMs) and users\nnaturally include implicit feedback signals. If an LLM responds in an\nunexpected way to an instruction, the user is likely to signal it by rephrasing\nthe request, expressing frustration, or pivoting to an alternative task. Such\nsignals are task-independent and occupy a relatively constrained subspace of\nlanguage, allowing the LLM to identify them even if it fails on the actual\ntask. This creates an avenue for continually learning from interactions without\nadditional annotations. We introduce ReSpect, a method to learn from such\nsignals in past interactions via retrospection. We deploy ReSpect in a new\nmultimodal interaction scenario, where humans instruct an LLM to solve an\nabstract reasoning task with a combinatorial solution space. Through thousands\nof interactions with humans, we show how ReSpect gradually improves task\ncompletion rate from 31% to 82%, all without any external annotation.\n","authors":["Zizhao Chen","Mustafa Omer Gul","Yiwei Chen","Gloria Geng","Anne Wu","Yoav Artzi"],"pdf_url":"https://arxiv.org/pdf/2410.13852v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.08928v2","updated":"2024-10-17T17:58:53Z","published":"2024-10-11T15:53:24Z","title":"Towards Multilingual LLM Evaluation for European Languages","summary":"  The rise of Large Language Models (LLMs) has revolutionized natural language\nprocessing across numerous languages and tasks. However, evaluating LLM\nperformance in a consistent and meaningful way across multiple European\nlanguages remains challenging, especially due to the scarcity of\nlanguage-parallel multilingual benchmarks. We introduce a multilingual\nevaluation approach tailored for European languages. We employ translated\nversions of five widely-used benchmarks to assess the capabilities of 40 LLMs\nacross 21 European languages. Our contributions include examining the\neffectiveness of translated benchmarks, assessing the impact of different\ntranslation services, and offering a multilingual evaluation framework for LLMs\nthat includes newly created datasets: EU20-MMLU, EU20-HellaSwag, EU20-ARC,\nEU20-TruthfulQA, and EU20-GSM8K. The benchmarks and results are made publicly\navailable to encourage further research in multilingual LLM evaluation.\n","authors":["Klaudia Thellmann","Bernhard Stadler","Michael Fromm","Jasper Schulze Buschhoff","Alex Jude","Fabio Barth","Johannes Leveling","Nicolas Flores-Herr","Joachim Köhler","René Jäkel","Mehdi Ali"],"pdf_url":"https://arxiv.org/pdf/2410.08928v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.13848v1","updated":"2024-10-17T17:58:37Z","published":"2024-10-17T17:58:37Z","title":"Janus: Decoupling Visual Encoding for Unified Multimodal Understanding\n  and Generation","summary":"  In this paper, we introduce Janus, an autoregressive framework that unifies\nmultimodal understanding and generation. Prior research often relies on a\nsingle visual encoder for both tasks, such as Chameleon. However, due to the\ndiffering levels of information granularity required by multimodal\nunderstanding and generation, this approach can lead to suboptimal performance,\nparticularly in multimodal understanding. To address this issue, we decouple\nvisual encoding into separate pathways, while still leveraging a single,\nunified transformer architecture for processing. The decoupling not only\nalleviates the conflict between the visual encoder's roles in understanding and\ngeneration, but also enhances the framework's flexibility. For instance, both\nthe multimodal understanding and generation components can independently select\ntheir most suitable encoding methods. Experiments show that Janus surpasses\nprevious unified model and matches or exceeds the performance of task-specific\nmodels. The simplicity, high flexibility, and effectiveness of Janus make it a\nstrong candidate for next-generation unified multimodal models.\n","authors":["Chengyue Wu","Xiaokang Chen","Zhiyu Wu","Yiyang Ma","Xingchao Liu","Zizheng Pan","Wen Liu","Zhenda Xie","Xingkai Yu","Chong Ruan","Ping Luo"],"pdf_url":"https://arxiv.org/pdf/2410.13848v1.pdf","comment":"Technical Report"},{"id":"http://arxiv.org/abs/2410.13846v1","updated":"2024-10-17T17:58:14Z","published":"2024-10-17T17:58:14Z","title":"SimLayerKV: A Simple Framework for Layer-Level KV Cache Reduction","summary":"  Recent advancements in large language models (LLMs) have extended their\ncapabilities to handle long contexts. However, increasing the number of model\nlayers and the length of input sequences significantly escalates the memory\nrequired to store key-value (KV) cache, posing challenges for efficient\ninference. To mitigate this issue, we present SimLayerKV, a simple yet\neffective method that reduces inter-layer KV cache redundancies by selectively\ndropping cache in identified lazy layers. Our approach is based on the\nobservation that certain layers in long-context LLMs exhibit \"lazy\" behavior,\ncontributing less to modeling long-range dependencies compared to non-lazy\nlayers. By analyzing attention weight patterns, we find that the behavior of\nthese lazy layers is consistent across tokens during generation for a given\ninput. This insight motivates our SimLayerKV, which identifies lazy layers and\nreduces their KV cache accordingly. SimLayerKV is training-free, generalizable,\nand can be implemented with only seven lines of code. We conduct extensive\nexperiments on three representative LLMs, e.g., LLaMA2-7B, LLaMA3-8B, and\nMistral-7B across 16 tasks from the LongBench benchmark. The results\ndemonstrate that SimLayerKV achieves a KV cache compression ratio of 5$\\times$\nwith only a 1.2% performance drop when combined with 4-bit quantization. Our\ncode is available at https://github.com/sail-sg/SimLayerKV.\n","authors":["Xuan Zhang","Cunxiao Du","Chao Du","Tianyu Pang","Wei Gao","Min Lin"],"pdf_url":"https://arxiv.org/pdf/2410.13846v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.13841v1","updated":"2024-10-17T17:56:53Z","published":"2024-10-17T17:56:53Z","title":"A Unified View of Delta Parameter Editing in Post-Trained Large-Scale\n  Models","summary":"  Post-training has emerged as a crucial paradigm for adapting large-scale\npre-trained models to various tasks, whose effects are fully reflected by delta\nparameters (i.e., the disparity between post-trained and pre-trained\nparameters). While numerous studies have explored delta parameter properties\nvia operations like pruning, quantization, low-rank approximation, and\nextrapolation, a unified framework for systematically examining these\ncharacteristics has been lacking. In this paper, we propose a novel perspective\nbased on Riemann sum approximation of the loss function to elucidate delta\nparameter editing operations. Our analysis categorizes existing methods into\nthree classes based on their post-editing performance: competitive, decreased,\nand improved, explaining how they are expressed by the Riemann sum\napproximation term and how they alter the model performance. Extensive\nexperiments on both visual and language models, including ViT, LLaMA 3, Qwen 2,\nand Mistral, corroborate our theoretical findings. Furthermore, we introduce\nextensions to existing techniques like DARE and BitDelta, highlighting their\nlimitations in leveraging the properties of delta parameters and reorganizing\nthem into general expressions to enhance the applicability and effectiveness of\ndelta parameter editing in post-trained models.\n","authors":["Qiaoyu Tang","Le Yu","Bowen Yu","Hongyu Lin","Keming Lu","Yaojie Lu","Xianpei Han","Le Sun"],"pdf_url":"https://arxiv.org/pdf/2410.13841v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.13828v1","updated":"2024-10-17T17:52:01Z","published":"2024-10-17T17:52:01Z","title":"A Common Pitfall of Margin-based Language Model Alignment: Gradient\n  Entanglement","summary":"  Reinforcement Learning from Human Feedback (RLHF) has become the predominant\napproach for language model (LM) alignment. At its core, RLHF uses a\nmargin-based loss for preference optimization, specifying ideal LM behavior\nonly by the difference between preferred and dispreferred responses. In this\npaper, we identify a common pitfall of margin-based methods -- the\nunder-specification of ideal LM behavior on preferred and dispreferred\nresponses individually, which leads to two unintended consequences as the\nmargin increases: (1) The probability of dispreferred (e.g., unsafe) responses\nmay increase, resulting in potential safety alignment failures. (2) The\nprobability of preferred responses may decrease, even when those responses are\nideal. We demystify the reasons behind these problematic behaviors:\nmargin-based losses couple the change in the preferred probability to the\ngradient of the dispreferred one, and vice versa, often preventing the\npreferred probability from increasing while the dispreferred one decreases, and\nthus causing a synchronized increase or decrease in both probabilities. We term\nthis effect, inherent in margin-based objectives, gradient entanglement.\nFormally, we derive conditions for general margin-based alignment objectives\nunder which gradient entanglement becomes concerning: the inner product of the\ngradients of preferred and dispreferred log-probabilities is large relative to\nthe individual gradient norms. We theoretically investigate why such inner\nproducts can be large when aligning language models and empirically validate\nour findings. Empirical implications of our framework extend to explaining\nimportant differences in the training dynamics of various preference\noptimization algorithms, and suggesting potential algorithm designs to mitigate\nthe under-specification issue of margin-based methods and thereby improving\nlanguage model alignment.\n","authors":["Hui Yuan","Yifan Zeng","Yue Wu","Huazheng Wang","Mengdi Wang","Liu Leqi"],"pdf_url":"https://arxiv.org/pdf/2410.13828v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2407.16833v2","updated":"2024-10-17T17:51:19Z","published":"2024-07-23T20:51:52Z","title":"Retrieval Augmented Generation or Long-Context LLMs? A Comprehensive\n  Study and Hybrid Approach","summary":"  Retrieval Augmented Generation (RAG) has been a powerful tool for Large\nLanguage Models (LLMs) to efficiently process overly lengthy contexts. However,\nrecent LLMs like Gemini-1.5 and GPT-4 show exceptional capabilities to\nunderstand long contexts directly. We conduct a comprehensive comparison\nbetween RAG and long-context (LC) LLMs, aiming to leverage the strengths of\nboth. We benchmark RAG and LC across various public datasets using three latest\nLLMs. Results reveal that when resourced sufficiently, LC consistently\noutperforms RAG in terms of average performance. However, RAG's significantly\nlower cost remains a distinct advantage. Based on this observation, we propose\nSelf-Route, a simple yet effective method that routes queries to RAG or LC\nbased on model self-reflection. Self-Route significantly reduces the\ncomputation cost while maintaining a comparable performance to LC. Our findings\nprovide a guideline for long-context applications of LLMs using RAG and LC.\n","authors":["Zhuowan Li","Cheng Li","Mingyang Zhang","Qiaozhu Mei","Michael Bendersky"],"pdf_url":"https://arxiv.org/pdf/2407.16833v2.pdf","comment":"Accepted to EMNLP 2024 industry track"},{"id":"http://arxiv.org/abs/2410.13825v1","updated":"2024-10-17T17:50:38Z","published":"2024-10-17T17:50:38Z","title":"AgentOccam: A Simple Yet Strong Baseline for LLM-Based Web Agents","summary":"  Autonomy via agents using large language models (LLMs) for personalized,\nstandardized tasks boosts human efficiency. Automating web tasks (like booking\nhotels within a budget) is increasingly sought after. Fulfilling practical\nneeds, the web agent also serves as an important proof-of-concept example for\nvarious agent grounding scenarios, with its success promising advancements in\nmany future applications. Prior research often handcrafts web agent strategies\n(e.g., prompting templates, multi-agent systems, search methods, etc.) and the\ncorresponding in-context examples, which may not generalize well across all\nreal-world scenarios. On the other hand, there has been limited study on the\nmisalignment between a web agent's observation/action representation and the\npre-training data of the LLM it's based on. This discrepancy is especially\nnotable when LLMs are primarily trained for language completion rather than\ntasks involving embodied navigation actions and symbolic web elements. Our\nstudy enhances an LLM-based web agent by simply refining its observation and\naction space to better align with the LLM's capabilities. This approach enables\nour base agent to significantly outperform previous methods on a wide variety\nof web tasks. Specifically, on WebArena, a benchmark featuring general-purpose\nweb interaction tasks, our agent AgentOccam surpasses the previous\nstate-of-the-art and concurrent work by 9.8 (+29.4%) and 5.9 (+15.8%) absolute\npoints respectively, and boosts the success rate by 26.6 points (+161%) over\nsimilar plain web agents with its observation and action space alignment. We\nachieve this without using in-context examples, new agent roles, online\nfeedback or search strategies. AgentOccam's simple design highlights LLMs'\nimpressive zero-shot performance on web tasks, and underlines the critical role\nof carefully tuning observation and action spaces for LLM-based agents.\n","authors":["Ke Yang","Yao Liu","Sapana Chaudhary","Rasool Fakoor","Pratik Chaudhari","George Karypis","Huzefa Rangwala"],"pdf_url":"https://arxiv.org/pdf/2410.13825v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.13824v1","updated":"2024-10-17T17:48:54Z","published":"2024-10-17T17:48:54Z","title":"Harnessing Webpage UIs for Text-Rich Visual Understanding","summary":"  Text-rich visual understanding-the ability to process environments where\ndense textual content is integrated with visuals-is crucial for multimodal\nlarge language models (MLLMs) to interact effectively with structured\nenvironments. To enhance this capability, we propose synthesizing general\nmultimodal instructions from webpage UIs using text-based large language models\n(LLMs). Despite lacking direct visual input, text-based LLMs are able to\nprocess structured text representations from webpage accessibility trees. These\ninstructions are then paired with UI screenshots to train multimodal models. We\nintroduce MultiUI, a dataset containing 7.3 million samples from 1 million\nwebsites, covering diverse multimodal tasks and UI layouts. Models trained on\nMultiUI not only excel in web UI tasks-achieving up to a 48\\% improvement on\nVisualWebBench and a 19.1\\% boost in action accuracy on a web agent dataset\nMind2Web-but also generalize surprisingly well to non-web UI tasks and even to\nnon-UI domains, such as document understanding, OCR, and chart interpretation.\nThese results highlight the broad applicability of web UI data for advancing\ntext-rich visual understanding across various scenarios.\n","authors":["Junpeng Liu","Tianyue Ou","Yifan Song","Yuxiao Qu","Wai Lam","Chenyan Xiong","Wenhu Chen","Graham Neubig","Xiang Yue"],"pdf_url":"https://arxiv.org/pdf/2410.13824v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2404.11018v3","updated":"2024-10-17T17:45:09Z","published":"2024-04-17T02:49:26Z","title":"Many-Shot In-Context Learning","summary":"  Large language models (LLMs) excel at few-shot in-context learning (ICL) --\nlearning from a few examples provided in context at inference, without any\nweight updates. Newly expanded context windows allow us to investigate ICL with\nhundreds or thousands of examples -- the many-shot regime. Going from few-shot\nto many-shot, we observe significant performance gains across a wide variety of\ngenerative and discriminative tasks. While promising, many-shot ICL can be\nbottlenecked by the available amount of human-generated examples. To mitigate\nthis limitation, we explore two new settings: Reinforced and Unsupervised ICL.\nReinforced ICL uses model-generated chain-of-thought rationales in place of\nhuman examples. Unsupervised ICL removes rationales from the prompt altogether,\nand prompts the model only with domain-specific questions. We find that both\nReinforced and Unsupervised ICL can be quite effective in the many-shot regime,\nparticularly on complex reasoning tasks. Finally, we demonstrate that, unlike\nfew-shot learning, many-shot learning is effective at overriding pretraining\nbiases, can learn high-dimensional functions with numerical inputs, and\nperforms comparably to fine-tuning. We also find that inference cost increases\nlinearly in the many-shot regime, and frontier LLMs benefit from many-shot ICL\nto varying degrees. Our analysis also reveals the limitations of next-token\nprediction loss as an indicator of downstream ICL performance.\n","authors":["Rishabh Agarwal","Avi Singh","Lei M. Zhang","Bernd Bohnet","Luis Rosias","Stephanie Chan","Biao Zhang","Ankesh Anand","Zaheer Abbas","Azade Nova","John D. Co-Reyes","Eric Chu","Feryal Behbahani","Aleksandra Faust","Hugo Larochelle"],"pdf_url":"https://arxiv.org/pdf/2404.11018v3.pdf","comment":"NeurIPS (Spotlight)"},{"id":"http://arxiv.org/abs/2410.13808v1","updated":"2024-10-17T17:42:10Z","published":"2024-10-17T17:42:10Z","title":"De-mark: Watermark Removal in Large Language Models","summary":"  Watermarking techniques offer a promising way to identify machine-generated\ncontent via embedding covert information into the contents generated from\nlanguage models (LMs). However, the robustness of the watermarking schemes has\nnot been well explored. In this paper, we present De-mark, an advanced\nframework designed to remove n-gram-based watermarks effectively. Our method\nutilizes a novel querying strategy, termed random selection probing, which aids\nin assessing the strength of the watermark and identifying the red-green list\nwithin the n-gram watermark. Experiments on popular LMs, such as Llama3 and\nChatGPT, demonstrate the efficiency and effectiveness of De-mark in watermark\nremoval and exploitation tasks.\n","authors":["Ruibo Chen","Yihan Wu","Junfeng Guo","Heng Huang"],"pdf_url":"https://arxiv.org/pdf/2410.13808v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.13805v1","updated":"2024-10-17T17:41:28Z","published":"2024-10-17T17:41:28Z","title":"A Watermark for Order-Agnostic Language Models","summary":"  Statistical watermarking techniques are well-established for sequentially\ndecoded language models (LMs). However, these techniques cannot be directly\napplied to order-agnostic LMs, as the tokens in order-agnostic LMs are not\ngenerated sequentially. In this work, we introduce Pattern-mark, a\npattern-based watermarking framework specifically designed for order-agnostic\nLMs. We develop a Markov-chain-based watermark generator that produces\nwatermark key sequences with high-frequency key patterns. Correspondingly, we\npropose a statistical pattern-based detection algorithm that recovers the key\nsequence during detection and conducts statistical tests based on the count of\nhigh-frequency patterns. Our extensive evaluations on order-agnostic LMs, such\nas ProteinMPNN and CMLM, demonstrate Pattern-mark's enhanced detection\nefficiency, generation quality, and robustness, positioning it as a superior\nwatermarking technique for order-agnostic LMs.\n","authors":["Ruibo Chen","Yihan Wu","Yanshuo Chen","Chenxi Liu","Junfeng Guo","Heng Huang"],"pdf_url":"https://arxiv.org/pdf/2410.13805v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.13804v1","updated":"2024-10-17T17:41:15Z","published":"2024-10-17T17:41:15Z","title":"BenTo: Benchmark Task Reduction with In-Context Transferability","summary":"  Evaluating large language models (LLMs) is costly: it requires the generation\nand examination of LLM outputs on a large-scale benchmark of various tasks.\nThis paper investigates how to efficiently reduce the tasks used to benchmark\nLLMs without affecting the evaluation quality. Our study reveals that task\ntransferability and relevance provide critical information to identify the most\nrepresentative subset of tasks via optimizing a facility location function. We\npropose a practically efficient metric for estimating the transferability\nbetween two tasks via in-context learning (ICL). By analyzing the pairwise\ntransferability, we can reduce tasks in a modern LLM benchmark (e.g., MMLU or\nFLAN) to 5% while inducing only a <4% difference to the evaluation on the\noriginal benchmark. Compared to prior works, our method is training-free,\ngradient-free, and highly efficient requiring ICL only.\n","authors":["Hongyu Zhao","Ming Li","Lichao Sun","Tianyi Zhou"],"pdf_url":"https://arxiv.org/pdf/2410.13804v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2312.14180v2","updated":"2024-10-17T17:38:00Z","published":"2023-12-19T00:36:53Z","title":"Dynamic Topic Language Model on Heterogeneous Children's Mental Health\n  Clinical Notes","summary":"  Mental health diseases affect children's lives and well-beings which have\nreceived increased attention since the COVID-19 pandemic. Analyzing psychiatric\nclinical notes with topic models is critical to evaluating children's mental\nstatus over time. However, few topic models are built for longitudinal\nsettings, and most existing approaches fail to capture temporal trajectories\nfor each document. To address these challenges, we develop a dynamic topic\nmodel with consistent topics and individualized temporal dependencies on the\nevolving document metadata. Our model preserves the semantic meaning of\ndiscovered topics over time and incorporates heterogeneity among documents. In\nparticular, when documents can be categorized, we propose a classifier-free\napproach to maximize topic heterogeneity across different document groups. We\nalso present an efficient variational optimization procedure adapted for the\nmultistage longitudinal setting. In this case study, we apply our method to the\npsychiatric clinical notes from a large tertiary pediatric hospital in Southern\nCalifornia and achieve a 38% increase in the overall coherence of extracted\ntopics. Our real data analysis reveals that children tend to express more\nnegative emotions during state shutdowns and more positive when schools reopen.\nFurthermore, it suggests that sexual and gender minority (SGM) children display\nmore pronounced reactions to major COVID-19 events and a greater sensitivity to\nvaccine-related news than non-SGM children. This study examines children's\nmental health progression during the pandemic and offers clinicians valuable\ninsights to recognize disparities in children's mental health related to their\nsexual and gender identities.\n","authors":["Hanwen Ye","Tatiana Moreno","Adrianne Alpern","Louis Ehwerhemuepha","Annie Qu"],"pdf_url":"https://arxiv.org/pdf/2312.14180v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.09013v2","updated":"2024-10-17T17:30:52Z","published":"2024-10-11T17:30:02Z","title":"The Impact of Visual Information in Chinese Characters: Evaluating Large\n  Models' Ability to Recognize and Utilize Radicals","summary":"  The glyphic writing system of Chinese incorporates information-rich visual\nfeatures in each character, such as radicals that provide hints about meaning\nor pronunciation. However, there has been no investigation into whether\ncontemporary Large Language Models (LLMs) and Vision-Language Models (VLMs) can\nharness these sub-character features in Chinese through prompting. In this\nstudy, we establish a benchmark to evaluate LLMs' and VLMs' understanding of\nvisual elements in Chinese characters, including radicals, composition\nstructures, strokes, and stroke counts. Our results reveal that models\nsurprisingly exhibit some, but still limited, knowledge of the visual\ninformation, regardless of whether images of characters are provided. To incite\nmodels' ability to use radicals, we further experiment with incorporating\nradicals into the prompts for Chinese language processing (CLP) tasks. We\nobserve consistent improvement in Part-Of-Speech tagging when providing\nadditional information about radicals, suggesting the potential to enhance CLP\nby integrating sub-character information.\n","authors":["Xiaofeng Wu","Karl Stratos","Wei Xu"],"pdf_url":"https://arxiv.org/pdf/2410.09013v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.13788v1","updated":"2024-10-17T17:29:04Z","published":"2024-10-17T17:29:04Z","title":"Modeling Future Conversation Turns to Teach LLMs to Ask Clarifying\n  Questions","summary":"  Large language models (LLMs) must often respond to highly ambiguous user\nrequests. In such cases, the LLM's best response may be to ask a clarifying\nquestion to elicit more information. We observe existing LLMs often respond by\npresupposing a single interpretation of such ambiguous requests, frustrating\nusers who intended a different interpretation. We speculate this is caused by\ncurrent preference data labeling practice, where LLM responses are evaluated\nonly on their prior contexts. To address this, we propose to assign preference\nlabels by simulating their expected outcomes in the future turns. This allows\nLLMs to learn to ask clarifying questions when it can generate responses that\nare tailored to each user interpretation in future turns. In experiments on\nopen-domain QA, we compare systems that trained using our proposed preference\nlabeling methods against standard methods, which assign preferences based on\nonly prior context. We evaluate systems based on their ability to ask\nclarifying questions that can recover each user's interpretation and expected\nanswer, and find that our training with our proposed method trains LLMs to ask\nclarifying questions with a 5% improvement in F1 measured against the answer\nset from different interpretations of each query\n","authors":["Michael J. Q. Zhang","W. Bradley Knox","Eunsol Choi"],"pdf_url":"https://arxiv.org/pdf/2410.13788v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.13787v1","updated":"2024-10-17T17:24:10Z","published":"2024-10-17T17:24:10Z","title":"Looking Inward: Language Models Can Learn About Themselves by\n  Introspection","summary":"  Humans acquire knowledge by observing the external world, but also by\nintrospection. Introspection gives a person privileged access to their current\nstate of mind (e.g., thoughts and feelings) that is not accessible to external\nobservers. Can LLMs introspect? We define introspection as acquiring knowledge\nthat is not contained in or derived from training data but instead originates\nfrom internal states. Such a capability could enhance model interpretability.\nInstead of painstakingly analyzing a model's internal workings, we could simply\nask the model about its beliefs, world models, and goals. More speculatively,\nan introspective model might self-report on whether it possesses certain\ninternal states such as subjective feelings or desires and this could inform us\nabout the moral status of these states. Such self-reports would not be entirely\ndictated by the model's training data.\n  We study introspection by finetuning LLMs to predict properties of their own\nbehavior in hypothetical scenarios. For example, \"Given the input P, would your\noutput favor the short- or long-term option?\" If a model M1 can introspect, it\nshould outperform a different model M2 in predicting M1's behavior even if M2\nis trained on M1's ground-truth behavior. The idea is that M1 has privileged\naccess to its own behavioral tendencies, and this enables it to predict itself\nbetter than M2 (even if M2 is generally stronger).\n  In experiments with GPT-4, GPT-4o, and Llama-3 models (each finetuned to\npredict itself), we find that the model M1 outperforms M2 in predicting itself,\nproviding evidence for introspection. Notably, M1 continues to predict its\nbehavior accurately even after we intentionally modify its ground-truth\nbehavior. However, while we successfully elicit introspection on simple tasks,\nwe are unsuccessful on more complex tasks or those requiring\nout-of-distribution generalization.\n","authors":["Felix J Binder","James Chua","Tomek Korbak","Henry Sleight","John Hughes","Robert Long","Ethan Perez","Miles Turpin","Owain Evans"],"pdf_url":"https://arxiv.org/pdf/2410.13787v1.pdf","comment":"15 pages, 9 figures"},{"id":"http://arxiv.org/abs/2410.13785v1","updated":"2024-10-17T17:22:05Z","published":"2024-10-17T17:22:05Z","title":"PopAlign: Diversifying Contrasting Patterns for a More Comprehensive\n  Alignment","summary":"  Alignment of large language models (LLMs) involves training models on\npreference-contrastive output pairs to adjust their responses according to\nhuman preferences. To obtain such contrastive pairs, traditional methods like\nRLHF and RLAIF rely on limited contrasting patterns, such as varying model\nvariants or decoding temperatures. This singularity leads to two issues: (1)\nalignment is not comprehensive; and thereby (2) models are susceptible to\njailbreaking attacks. To address these issues, we investigate how to construct\nmore comprehensive and diversified contrasting patterns to enhance preference\ndata (RQ1) and verify the impact of the diversification of contrasting patterns\non model alignment (RQ2). For RQ1, we propose PopAlign, a framework that\nintegrates diversified contrasting patterns across the prompt, model, and\npipeline levels, introducing six contrasting strategies that do not require\nadditional feedback labeling procedures. Regarding RQ2, we conduct thorough\nexperiments demonstrating that PopAlign significantly outperforms existing\nmethods, leading to more comprehensive alignment.\n","authors":["Zekun Moore Wang","Shawn Wang","Kang Zhu","Jiaheng Liu","Ke Xu","Jie Fu","Wangchunshu Zhou","Wenhao Huang"],"pdf_url":"https://arxiv.org/pdf/2410.13785v1.pdf","comment":"28 pages"},{"id":"http://arxiv.org/abs/2410.13783v1","updated":"2024-10-17T17:20:40Z","published":"2024-10-17T17:20:40Z","title":"Quantity vs. Quality of Monolingual Source Data in Automatic Text\n  Translation: Can It Be Too Little If It Is Too Good?","summary":"  Monolingual data, being readily available in large quantities, has been used\nto upscale the scarcely available parallel data to train better models for\nautomatic translation. Self-learning, where a model is made to learn from its\noutput, is one approach to exploit such data. However, it has been shown that\ntoo much of this data can be detrimental to the performance of the model if the\navailable parallel data is comparatively extremely low. In this study, we\ninvestigate whether the monolingual data can also be too little and if this\nreduction, based on quality, has any effect on the performance of the\ntranslation model. Experiments have shown that on English-German low-resource\nNMT, it is often better to select only the most useful additional data, based\non quality or closeness to the domain of the test data, than utilizing all of\nthe available data.\n","authors":["Idris Abdulmumin","Bashir Shehu Galadanci","Garba Aliyu","Shamsuddeen Hassan Muhammad"],"pdf_url":"https://arxiv.org/pdf/2410.13783v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.13780v1","updated":"2024-10-17T17:19:48Z","published":"2024-10-17T17:19:48Z","title":"Optimal Quantization for Matrix Multiplication","summary":"  Recent work in machine learning community proposed multiple methods for\nperforming lossy compression (quantization) of large matrices. This\nquantization is important for accelerating matrix multiplication (main\ncomponent of large language models), which is often bottlenecked by the speed\nof loading these matrices from memory. Unlike classical vector quantization and\nrate-distortion theory, the goal of these new compression algorithms is to be\nable to approximate not the matrices themselves, but their matrix product.\nSpecifically, given a pair of real matrices $A,B$ an encoder (compressor) is\napplied to each of them independently producing descriptions with $R$ bits per\nentry. These representations subsequently are used by the decoder to estimate\nmatrix product $A^\\top B$. In this work, we provide a non-asymptotic lower\nbound on the mean squared error of this approximation (as a function of rate\n$R$) for the case of matrices $A,B$ with iid Gaussian entries. Algorithmically,\nwe construct a universal quantizer based on nested lattices with an explicit\nguarantee of approximation error for any (non-random) pair of matrices $A$, $B$\nin terms of only Frobenius norms $\\|A\\|_F, \\|B\\|_F$ and $\\|A^\\top B\\|_F$. For\niid Gaussian matrices our quantizer achieves the lower bound and is, thus,\nasymptotically optimal. A practical low-complexity version of our quantizer\nachieves performance quite close to optimal. In information-theoretic terms we\nderive rate-distortion function for matrix multiplication of iid Gaussian\nmatrices.\n","authors":["Or Ordentlich","Yury Polyanskiy"],"pdf_url":"https://arxiv.org/pdf/2410.13780v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2405.20967v2","updated":"2024-10-17T17:19:32Z","published":"2024-05-31T16:14:06Z","title":"Superlatives in Context: Modeling the Implicit Semantics of Superlatives","summary":"  Superlatives are used to single out elements with a maximal/minimal property.\nSemantically, superlatives perform a set comparison: something (or some things)\nhas the min/max property out of a set. As such, superlatives provide an ideal\nphenomenon for studying implicit phenomena and discourse restrictions. While\nthis comparison set is often not explicitly defined, its (implicit)\nrestrictions can be inferred from the discourse context the expression appears\nin. In this work we provide an extensive computational study on the semantics\nof superlatives. We propose a unified account of superlative semantics which\nallows us to derive a broad-coverage annotation schema. Using this unified\nschema we annotated a multi-domain dataset of superlatives and their semantic\ninterpretations. We specifically focus on interpreting implicit or ambiguous\nsuperlative expressions, by analyzing how the discourse context restricts the\nset of interpretations. In a set of experiments we then analyze how well models\nperform at variations of predicting superlative semantics, with and without\ncontext. We show that the fine-grained semantics of superlatives in context can\nbe challenging for contemporary models, including GPT-4.\n","authors":["Valentina Pyatkin","Bonnie Webber","Ido Dagan","Reut Tsarfaty"],"pdf_url":"https://arxiv.org/pdf/2405.20967v2.pdf","comment":"11 pages"},{"id":"http://arxiv.org/abs/2410.13779v1","updated":"2024-10-17T17:18:30Z","published":"2024-10-17T17:18:30Z","title":"The Mystery of the Pathological Path-star Task for Language Models","summary":"  The recently introduced path-star task is a minimal task designed to\nexemplify limitations to the abilities of language models (Bachmann and\nNagarajan, 2024). It involves a path-star graph where multiple arms radiate\nfrom a single starting node and each node is unique. Given the start node and a\nspecified target node that ends an arm, the task is to generate the arm\ncontaining that target node. This is straightforward for a human but\nsurprisingly difficult for language models, which did not outperform the random\nbaseline. The authors hypothesized this is due to a deficiency in\nteacher-forcing and the next-token prediction paradigm.\n  We demonstrate the task is learnable using teacher-forcing in alternative\nsettings and that the issue is partially due to representation. We introduce a\nregularization method using structured samples of the same graph but with\ndiffering target nodes, improving results across a variety of model types. We\nprovide RASP proofs showing the task is theoretically solvable. Finally, we\nfind settings where an encoder-only model can consistently solve the task.\n","authors":["Arvid Frydenlund"],"pdf_url":"https://arxiv.org/pdf/2410.13779v1.pdf","comment":"EMNLP 2024 Main"},{"id":"http://arxiv.org/abs/2410.13776v1","updated":"2024-10-17T17:16:00Z","published":"2024-10-17T17:16:00Z","title":"Aggregation Artifacts in Subjective Tasks Collapse Large Language\n  Models' Posteriors","summary":"  In-context Learning (ICL) has become the primary method for performing\nnatural language tasks with Large Language Models (LLMs). The knowledge\nacquired during pre-training is crucial for this few-shot capability, providing\nthe model with task priors. However, recent studies have shown that ICL\npredominantly relies on retrieving task priors rather than \"learning\" to\nperform tasks. This limitation is particularly evident in complex subjective\ndomains such as emotion and morality, where priors significantly influence\nposterior predictions. In this work, we examine whether this is the result of\nthe aggregation used in corresponding datasets, where trying to combine\nlow-agreement, disparate annotations might lead to annotation artifacts that\ncreate detrimental noise in the prompt. Moreover, we evaluate the posterior\nbias towards certain annotators by grounding our study in appropriate,\nquantitative measures of LLM priors. Our results indicate that aggregation is a\nconfounding factor in the modeling of subjective tasks, and advocate focusing\non modeling individuals instead. However, aggregation does not explain the\nentire gap between ICL and the state of the art, meaning other factors in such\ntasks also account for the observed phenomena. Finally, by rigorously studying\nannotator-level labels, we find that it is possible for minority annotators to\nboth better align with LLMs and have their perspectives further amplified.\n","authors":["Georgios Chochlakis","Alexandros Potamianos","Kristina Lerman","Shrikanth Narayanan"],"pdf_url":"https://arxiv.org/pdf/2410.13776v1.pdf","comment":"12 pages, 7 figures, 2 tables"},{"id":"http://arxiv.org/abs/2410.13765v1","updated":"2024-10-17T17:03:23Z","published":"2024-10-17T17:03:23Z","title":"Knowledge-Aware Query Expansion with Large Language Models for Textual\n  and Relational Retrieval","summary":"  Large language models (LLMs) have been used to generate query expansions\naugmenting original queries for improving information search. Recent studies\nalso explore providing LLMs with initial retrieval results to generate query\nexpansions more grounded to document corpus. However, these methods mostly\nfocus on enhancing textual similarities between search queries and target\ndocuments, overlooking document relations. For queries like \"Find me a highly\nrated camera for wildlife photography compatible with my Nikon F-Mount lenses\",\nexisting methods may generate expansions that are semantically similar but\nstructurally unrelated to user intents. To handle such semi-structured queries\nwith both textual and relational requirements, in this paper we propose a\nknowledge-aware query expansion framework, augmenting LLMs with structured\ndocument relations from knowledge graph (KG). To further address the limitation\nof entity-based scoring in existing KG-based methods, we leverage document\ntexts as rich KG node representations and use document-based relation filtering\nfor our Knowledge-Aware Retrieval (KAR). Extensive experiments on three\ndatasets of diverse domains show the advantages of our method compared against\nstate-of-the-art baselines on textual and relational semi-structured retrieval.\n","authors":["Yu Xia","Junda Wu","Sungchul Kim","Tong Yu","Ryan A. Rossi","Haoliang Wang","Julian McAuley"],"pdf_url":"https://arxiv.org/pdf/2410.13765v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2409.06173v3","updated":"2024-10-17T17:02:02Z","published":"2024-09-10T03:06:17Z","title":"Larger Language Models Don't Care How You Think: Why Chain-of-Thought\n  Prompting Fails in Subjective Tasks","summary":"  In-Context Learning (ICL) in Large Language Models (LLM) has emerged as the\ndominant technique for performing natural language tasks, as it does not\nrequire updating the model parameters with gradient-based methods. ICL promises\nto \"adapt\" the LLM to perform the present task at a competitive or\nstate-of-the-art level at a fraction of the computational cost. ICL can be\naugmented by incorporating the reasoning process to arrive at the final label\nexplicitly in the prompt, a technique called Chain-of-Thought (CoT) prompting.\nHowever, recent work has found that ICL relies mostly on the retrieval of task\npriors and less so on \"learning\" to perform tasks, especially for complex\nsubjective domains like emotion and morality, where priors ossify posterior\npredictions. In this work, we examine whether \"enabling\" reasoning also creates\nthe same behavior in LLMs, wherein the format of CoT retrieves reasoning priors\nthat remain relatively unchanged despite the evidence in the prompt. We find\nthat, surprisingly, CoT indeed suffers from the same posterior collapse as ICL\nfor larger language models. Code is avalaible at\nhttps://github.com/gchochla/cot-priors.\n","authors":["Georgios Chochlakis","Niyantha Maruthu Pandiyan","Kristina Lerman","Shrikanth Narayanan"],"pdf_url":"https://arxiv.org/pdf/2409.06173v3.pdf","comment":"5 pages, 2 figures, 1 table. arXiv admin note: text overlap with\n  arXiv:2403.17125"},{"id":"http://arxiv.org/abs/2409.13057v2","updated":"2024-10-17T16:56:34Z","published":"2024-09-19T19:14:50Z","title":"Natural Language Processing Methods for the Study of Protein-Ligand\n  Interactions","summary":"  Recent advances in Natural Language Processing (NLP) have ignited interest in\ndeveloping effective methods for predicting protein-ligand interactions (PLIs)\ngiven their relevance to drug discovery and protein engineering efforts and the\never-growing volume of biochemical sequence and structural data available. The\nparallels between human languages and the \"languages\" used to represent\nproteins and ligands have enabled the use of NLP machine learning approaches to\nadvance PLI studies. In this review, we explain where and how such approaches\nhave been applied in the recent literature and discuss useful mechanisms such\nas long short-term memory, transformers, and attention. We conclude with a\ndiscussion of the current limitations of NLP methods for the study of PLIs as\nwell as key challenges that need to be addressed in future work.\n","authors":["James Michels","Ramya Bandarupalli","Amin Ahangar Akbari","Thai Le","Hong Xiao","Jing Li","Erik F. Y. Hom"],"pdf_url":"https://arxiv.org/pdf/2409.13057v2.pdf","comment":"52 Pages and 3 Figures"},{"id":"http://arxiv.org/abs/2410.13757v1","updated":"2024-10-17T16:53:50Z","published":"2024-10-17T16:53:50Z","title":"MobA: A Two-Level Agent System for Efficient Mobile Task Automation","summary":"  Current mobile assistants are limited by dependence on system APIs or\nstruggle with complex user instructions and diverse interfaces due to\nrestricted comprehension and decision-making abilities. To address these\nchallenges, we propose MobA, a novel Mobile phone Agent powered by multimodal\nlarge language models that enhances comprehension and planning capabilities\nthrough a sophisticated two-level agent architecture. The high-level Global\nAgent (GA) is responsible for understanding user commands, tracking history\nmemories, and planning tasks. The low-level Local Agent (LA) predicts detailed\nactions in the form of function calls, guided by sub-tasks and memory from the\nGA. Integrating a Reflection Module allows for efficient task completion and\nenables the system to handle previously unseen complex tasks. MobA demonstrates\nsignificant improvements in task execution efficiency and completion rate in\nreal-life evaluations, underscoring the potential of MLLM-empowered mobile\nassistants.\n","authors":["Zichen Zhu","Hao Tang","Yansi Li","Kunyao Lan","Yixuan Jiang","Hao Zhou","Yixiao Wang","Situo Zhang","Liangtai Sun","Lu Chen","Kai Yu"],"pdf_url":"https://arxiv.org/pdf/2410.13757v1.pdf","comment":"27 pages, 6 figures, and 5 tables. We will release our source code in\n  a few days"},{"id":"http://arxiv.org/abs/2406.19465v2","updated":"2024-10-17T16:53:12Z","published":"2024-06-27T18:07:40Z","title":"Can Large Language Models Generate High-quality Patent Claims?","summary":"  Large language models (LLMs) have shown exceptional performance across\nvarious text generation tasks but remain under-explored in the patent domain,\nwhich offers highly structured and precise language. This paper constructs a\ndataset to investigate the performance of current LLMs in patent claim\ngeneration. Our results demonstrate that generating claims based on patent\ndescriptions outperforms previous research relying on abstracts. Interestingly,\ncurrent patent-specific LLMs perform much worse than state-of-the-art general\nLLMs, highlighting the necessity for future research on in-domain LLMs. We also\nfind that LLMs can produce high-quality first independent claims, but their\nperformances markedly decrease for subsequent dependent claims. Moreover,\nfine-tuning can enhance the completeness of inventions' features, conceptual\nclarity, and feature linkage. Among the tested LLMs, GPT-4 demonstrates the\nbest performance in comprehensive human evaluations by patent experts, with\nbetter feature coverage, conceptual clarity, and technical coherence. Despite\nthese capabilities, comprehensive revision and modification are still necessary\nto pass rigorous patent scrutiny and ensure legal robustness.\n","authors":["Lekang Jiang","Caiqi Zhang","Pascal A Scherz","Stephan Goetz"],"pdf_url":"https://arxiv.org/pdf/2406.19465v2.pdf","comment":"16 pages, 2 figures, 12 tables"},{"id":"http://arxiv.org/abs/2410.13727v1","updated":"2024-10-17T16:33:01Z","published":"2024-10-17T16:33:01Z","title":"LLM-Human Pipeline for Cultural Context Grounding of Conversations","summary":"  Conversations often adhere to well-understood social norms that vary across\ncultures. For example, while \"addressing parents by name\" is commonplace in the\nWest, it is rare in most Asian cultures. Adherence or violation of such norms\noften dictates the tenor of conversations. Humans are able to navigate social\nsituations requiring cultural awareness quite adeptly. However, it is a hard\ntask for NLP models.\n  In this paper, we tackle this problem by introducing a \"Cultural Context\nSchema\" for conversations. It comprises (1) conversational information such as\nemotions, dialogue acts, etc., and (2) cultural information such as social\nnorms, violations, etc. We generate ~110k social norm and violation\ndescriptions for ~23k conversations from Chinese culture using LLMs. We refine\nthem using automated verification strategies which are evaluated against\nculturally aware human judgements. We organize these descriptions into\nmeaningful structures we call \"Norm Concepts\", using an interactive\nhuman-in-loop framework. We ground the norm concepts and the descriptions in\nconversations using symbolic annotation. Finally, we use the obtained dataset\nfor downstream tasks such as emotion, sentiment, and dialogue act detection. We\nshow that it significantly improves the empirical performance.\n","authors":["Rajkumar Pujari","Dan Goldwasser"],"pdf_url":"https://arxiv.org/pdf/2410.13727v1.pdf","comment":"19 pages, 9 figures, 7 tables"},{"id":"http://arxiv.org/abs/2406.14462v2","updated":"2024-10-17T16:32:46Z","published":"2024-06-20T16:24:07Z","title":"Modeling Human Subjectivity in LLMs Using Explicit and Implicit Human\n  Factors in Personas","summary":"  Large language models (LLMs) are increasingly being used in human-centered\nsocial scientific tasks, such as data annotation, synthetic data creation, and\nengaging in dialog. However, these tasks are highly subjective and dependent on\nhuman factors, such as one's environment, attitudes, beliefs, and lived\nexperiences. Thus, it may be the case that employing LLMs (which do not have\nsuch human factors) in these tasks results in a lack of variation in data,\nfailing to reflect the diversity of human experiences. In this paper, we\nexamine the role of prompting LLMs with human-like personas and asking the\nmodels to answer as if they were a specific human. This is done explicitly,\nwith exact demographics, political beliefs, and lived experiences, or\nimplicitly via names prevalent in specific populations. The LLM personas are\nthen evaluated via (1) subjective annotation task (e.g., detecting toxicity)\nand (2) a belief generation task, where both tasks are known to vary across\nhuman factors. We examine the impact of explicit vs. implicit personas and\ninvestigate which human factors LLMs recognize and respond to. Results show\nthat explicit LLM personas show mixed results when reproducing known human\nbiases, but generally fail to demonstrate implicit biases. We conclude that\nLLMs may capture the statistical patterns of how people speak, but are\ngenerally unable to model the complex interactions and subtleties of human\nperceptions, potentially limiting their effectiveness in social science\napplications.\n","authors":["Salvatore Giorgi","Tingting Liu","Ankit Aich","Kelsey Isman","Garrick Sherman","Zachary Fried","João Sedoc","Lyle H. Ungar","Brenda Curtis"],"pdf_url":"https://arxiv.org/pdf/2406.14462v2.pdf","comment":"Accepted at Findings of EMNLP 2024"},{"id":"http://arxiv.org/abs/2410.13716v1","updated":"2024-10-17T16:18:49Z","published":"2024-10-17T16:18:49Z","title":"MIRAGE-Bench: Automatic Multilingual Benchmark Arena for\n  Retrieval-Augmented Generation Systems","summary":"  Traditional Retrieval-Augmented Generation (RAG) benchmarks rely on different\nheuristic-based metrics for evaluation, but these require human preferences as\nground truth for reference. In contrast, arena-based benchmarks, where two\nmodels compete each other, require an expensive Large Language Model (LLM) as a\njudge for a reliable evaluation. We present an easy and efficient technique to\nget the best of both worlds. The idea is to train a learning to rank model as a\n\"surrogate\" judge using RAG-based evaluation heuristics as input, to produce a\nsynthetic arena-based leaderboard. Using this idea, We develop MIRAGE-Bench, a\nstandardized arena-based multilingual RAG benchmark for 18 diverse languages on\nWikipedia. The benchmark is constructed using MIRACL, a retrieval dataset, and\nextended for multilingual generation evaluation. MIRAGE-Bench evaluates RAG\nextensively coupling both heuristic features and LLM as a judge evaluator. In\nour work, we benchmark 19 diverse multilingual-focused LLMs, and achieve a high\ncorrelation (Kendall Tau ($\\tau$) = 0.909) using our surrogate judge learned\nusing heuristic features with pairwise evaluations and between GPT-4o as a\nteacher on the MIRAGE-Bench leaderboard using the Bradley-Terry framework. We\nobserve proprietary and large open-source LLMs currently dominate in\nmultilingual RAG. MIRAGE-Bench is available at:\nhttps://github.com/vectara/mirage-bench.\n","authors":["Nandan Thakur","Suleman Kazi","Ge Luo","Jimmy Lin","Amin Ahmad"],"pdf_url":"https://arxiv.org/pdf/2410.13716v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2407.01257v3","updated":"2024-10-17T16:15:16Z","published":"2024-07-01T13:07:01Z","title":"uDistil-Whisper: Label-Free Data Filtering for Knowledge Distillation in\n  Low-Data Regimes","summary":"  Recent work on distilling Whisper's knowledge into small models using\npseudo-labels shows promising performance while reducing the size by up to\n50\\%. This results in small, efficient, and dedicated models. However, a\ncritical step of distillation from pseudo-labels involves filtering\nhigh-quality predictions and using only those during training. This step\nrequires ground truth labels to compare and filter low-quality examples making\nthe whole process supervised. In addition to that, the distillation process\nrequires a large amount of data thereby limiting the ability to distill models\nin low-resource settings. To address this challenge, we propose a distillation\nframework that does not require any labeled data. Through experimentation, we\nshow that our best distilled models outperform the teacher model by 5-7 points\nin terms of WER compared to those without filtering and are on par with or\nperform better than similar supervised data filtering setups. When we scale the\ndata, our models significantly outperform all zero-shot and supervised models.\nWe demonstrate that it is possible to distill large Whisper models into\nrelatively small ones without using any labeled data. Our distilled models are\nalso 25-50\\% more compute- and memory-efficient while maintaining performance\nequal to or better than that of the teacher model.\n","authors":["Abdul Waheed","Karima Kadaoui","Bhiksha Raj","Muhammad Abdul-Mageed"],"pdf_url":"https://arxiv.org/pdf/2407.01257v3.pdf","comment":"Work in progress"},{"id":"http://arxiv.org/abs/2402.01521v2","updated":"2024-10-17T16:08:15Z","published":"2024-02-02T16:07:05Z","title":"K-Level Reasoning: Establishing Higher Order Beliefs in Large Language\n  Models for Strategic Reasoning","summary":"  Strategic reasoning is a complex yet essential capability for intelligent\nagents. It requires Large Language Model (LLM) agents to adapt their strategies\ndynamically in multi-agent environments. Unlike static reasoning tasks, success\nin these contexts depends on anticipating other agents' beliefs and actions\nwhile continuously adjusting strategies to achieve individual goals. LLMs and\nLLM agents often struggle with strategic reasoning due to the absence of a\nreasoning framework that enables them to dynamically infer others' perspectives\nand adapt to changing environments. Inspired by the Level-K framework from game\ntheory and behavioral economics, which extends reasoning from simple reactions\nto structured strategic depth, we propose a novel framework: \"K-Level Reasoning\nwith Large Language Models (K-R).\" This framework employs recursive mechanisms\nto enable LLMs to achieve varying levels of strategic depth, allowing agents to\nform higher order beliefs - beliefs about others' beliefs. We validate this\nframework through rigorous testing on four testbeds: two classical game theory\nproblems and two social intelligence tasks. The results demonstrate the\nadvantages of K-R in strategic reasoning. Our work presents the first recursive\nimplementation of strategic depth in large language models (LLMs). It\nestablishes a foundation for future research into theory of mind and strategic\nreasoning in LLMs.\n","authors":["Yadong Zhang","Shaoguang Mao","Tao Ge","Xun Wang","Yan Xia","Man Lan","Furu Wei"],"pdf_url":"https://arxiv.org/pdf/2402.01521v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.13708v1","updated":"2024-10-17T16:08:06Z","published":"2024-10-17T16:08:06Z","title":"On the Role of Attention Heads in Large Language Model Safety","summary":"  Large language models (LLMs) achieve state-of-the-art performance on multiple\nlanguage tasks, yet their safety guardrails can be circumvented, leading to\nharmful generations. In light of this, recent research on safety mechanisms has\nemerged, revealing that when safety representations or component are\nsuppressed, the safety capability of LLMs are compromised. However, existing\nresearch tends to overlook the safety impact of multi-head attention\nmechanisms, despite their crucial role in various model functionalities. Hence,\nin this paper, we aim to explore the connection between standard attention\nmechanisms and safety capability to fill this gap in the safety-related\nmechanistic interpretability. We propose a novel metric which tailored for\nmulti-head attention, the Safety Head ImPortant Score (Ships), to assess the\nindividual heads' contributions to model safety. Based on this, we generalize\nShips to the dataset level and further introduce the Safety Attention Head\nAttRibution Algorithm (Sahara) to attribute the critical safety attention heads\ninside the model. Our findings show that the special attention head has a\nsignificant impact on safety. Ablating a single safety head allows aligned\nmodel (e.g., Llama-2-7b-chat) to respond to 16 times more harmful queries,\nwhile only modifying 0.006% of the parameters, in contrast to the ~ 5%\nmodification required in previous studies. More importantly, we demonstrate\nthat attention heads primarily function as feature extractors for safety and\nmodels fine-tuned from the same base model exhibit overlapping safety heads\nthrough comprehensive experiments. Together, our attribution approach and\nfindings provide a novel perspective for unpacking the black box of safety\nmechanisms within large models.\n","authors":["Zhenhong Zhou","Haiyang Yu","Xinghua Zhang","Rongwu Xu","Fei Huang","Kun Wang","Yang Liu","Junfeng Fang","Yongbin Li"],"pdf_url":"https://arxiv.org/pdf/2410.13708v1.pdf","comment":"28 pages, 18 figures, 7 tables"},{"id":"http://arxiv.org/abs/2410.13699v1","updated":"2024-10-17T16:04:07Z","published":"2024-10-17T16:04:07Z","title":"Unconstrained Model Merging for Enhanced LLM Reasoning","summary":"  Recent advancements in building domain-specific large language models (LLMs)\nhave shown remarkable success, especially in tasks requiring reasoning\nabilities like logical inference over complex relationships and multi-step\nproblem solving. However, creating a powerful all-in-one LLM remains\nchallenging due to the need for proprietary data and vast computational\nresources. As a resource-friendly alternative, we explore the potential of\nmerging multiple expert models into a single LLM. Existing studies on model\nmerging mainly focus on generalist LLMs instead of domain experts, or the LLMs\nunder the same architecture and size. In this work, we propose an unconstrained\nmodel merging framework that accommodates both homogeneous and heterogeneous\nmodel architectures with a focus on reasoning tasks. A fine-grained layer-wise\nweight merging strategy is designed for homogeneous models merging, while\nheterogeneous model merging is built upon the probabilistic distribution\nknowledge derived from instruction-response fine-tuning data. Across 7\nbenchmarks and 9 reasoning-optimized LLMs, we reveal key findings that\ncombinatorial reasoning emerges from merging which surpasses simple additive\neffects. We propose that unconstrained model merging could serve as a\nfoundation for decentralized LLMs, marking a notable progression from the\nexisting centralized LLM framework. This evolution could enhance wider\nparticipation and stimulate additional advancement in the field of artificial\nintelligence, effectively addressing the constraints posed by centralized\nmodels.\n","authors":["Yiming Zhang","Baoyi He","Shengyu Zhang","Yuhao Fu","Qi Zhou","Zhijie Sang","Zijin Hong","Kejing Yang","Wenjun Wang","Jianbo Yuan","Guangning Han","Linyi Li","Chunlin Ji","Fei Wu","Hongxia Yang"],"pdf_url":"https://arxiv.org/pdf/2410.13699v1.pdf","comment":"Under review"},{"id":"http://arxiv.org/abs/2410.13694v1","updated":"2024-10-17T15:59:52Z","published":"2024-10-17T15:59:52Z","title":"Exploring the Design Space of Visual Context Representation in Video\n  MLLMs","summary":"  Video Multimodal Large Language Models (MLLMs) have shown remarkable\ncapability of understanding the video semantics on various downstream tasks.\nDespite the advancements, there is still a lack of systematic research on\nvisual context representation, which refers to the scheme to select frames from\na video and further select the tokens from a frame. In this paper, we explore\nthe design space for visual context representation, and aim to improve the\nperformance of video MLLMs by finding more effective representation schemes.\nFirstly, we formulate the task of visual context representation as a\nconstrained optimization problem, and model the language modeling loss as a\nfunction of the number of frames and the number of embeddings (or tokens) per\nframe, given the maximum visual context window size. Then, we explore the\nscaling effects in frame selection and token selection respectively, and fit\nthe corresponding function curve by conducting extensive empirical experiments.\nWe examine the effectiveness of typical selection strategies and present\nempirical findings to determine the two factors. Furthermore, we study the\njoint effect of frame selection and token selection, and derive the optimal\nformula for determining the two factors. We demonstrate that the derived\noptimal settings show alignment with the best-performed results of empirical\nexperiments. Our code and model are available at:\nhttps://github.com/RUCAIBox/Opt-Visor.\n","authors":["Yifan Du","Yuqi Huo","Kun Zhou","Zijia Zhao","Haoyu Lu","Han Huang","Wayne Xin Zhao","Bingning Wang","Weipeng Chen","Ji-Rong Wen"],"pdf_url":"https://arxiv.org/pdf/2410.13694v1.pdf","comment":"Long Video MLLM; work in progress"},{"id":"http://arxiv.org/abs/2406.20052v2","updated":"2024-10-17T15:57:10Z","published":"2024-06-28T17:03:51Z","title":"Understanding and Mitigating Language Confusion in LLMs","summary":"  We investigate a surprising limitation of LLMs: their inability to\nconsistently generate text in a user's desired language. We create the Language\nConfusion Benchmark (LCB) to evaluate such failures, covering 15 typologically\ndiverse languages with existing and newly-created English and multilingual\nprompts. We evaluate a range of LLMs on monolingual and cross-lingual\ngeneration reflecting practical use cases, finding that Llama Instruct and\nMistral models exhibit high degrees of language confusion and even the\nstrongest models fail to consistently respond in the correct language. We\nobserve that base and English-centric instruct models are more prone to\nlanguage confusion, which is aggravated by complex prompts and high sampling\ntemperatures. We find that language confusion can be partially mitigated via\nfew-shot prompting, multilingual SFT and preference tuning. We release our\nlanguage confusion benchmark, which serves as a first layer of efficient,\nscalable multilingual evaluation at\nhttps://github.com/for-ai/language-confusion.\n","authors":["Kelly Marchisio","Wei-Yin Ko","Alexandre Bérard","Théo Dehaze","Sebastian Ruder"],"pdf_url":"https://arxiv.org/pdf/2406.20052v2.pdf","comment":"EMNLP 2024 Main Conference Camera-ready"},{"id":"http://arxiv.org/abs/2406.16635v2","updated":"2024-10-17T15:45:10Z","published":"2024-06-24T13:41:08Z","title":"ShadowLLM: Predictor-based Contextual Sparsity for Large Language Models","summary":"  The high power consumption and latency-sensitive deployments of large\nlanguage models (LLMs) have motivated efficiency techniques like quantization\nand sparsity. Contextual sparsity, where the sparsity pattern is\ninput-dependent, is crucial in LLMs because the permanent removal of attention\nheads or neurons from LLMs can significantly degrade accuracy. Prior work has\nattempted to model contextual sparsity using neural networks trained to predict\nactivation magnitudes, which can be used to dynamically prune structures with\nlow predicted activation magnitude. In this paper, we look beyond\nmagnitude-based pruning criteria to assess attention head and neuron importance\nin LLMs. We develop a novel predictor called ShadowLLM, which can shadow the\nLLM behavior and enforce better sparsity patterns, resulting in over 15%\nimprovement in end-to-end accuracy compared to prior methods. In addition,\nShadowLLM achieves up to a 20% speed-up over the state-of-the-art DejaVu\nframework. These enhancements are validated on Llama-2 and OPT models with up\nto 30 billion parameters. Our code is available at\n\\href{https://github.com/abdelfattah-lab/shadow_llm/}{ShadowLLM}.\n","authors":["Yash Akhauri","Ahmed F AbouElhamayed","Jordan Dotzel","Zhiru Zhang","Alexander M Rush","Safeen Huda","Mohamed S Abdelfattah"],"pdf_url":"https://arxiv.org/pdf/2406.16635v2.pdf","comment":"Accepted to EMNLP 2024 (Main, Long Paper)"},{"id":"http://arxiv.org/abs/2410.13675v1","updated":"2024-10-17T15:33:54Z","published":"2024-10-17T15:33:54Z","title":"Pose-Based Sign Language Appearance Transfer","summary":"  We introduce a method for transferring the signer's appearance in sign\nlanguage skeletal poses while preserving the sign content. Using estimated\nposes, we transfer the appearance of one signer to another, maintaining natural\nmovements and transitions. This approach improves pose-based rendering and sign\nstitching while obfuscating identity. Our experiments show that while the\nmethod reduces signer identification accuracy, it slightly harms sign\nrecognition performance, highlighting a tradeoff between privacy and utility.\nOur code is available at\n\\url{https://github.com/sign-language-processing/pose-anonymization}.\n","authors":["Amit Moryossef","Gerard Sant","Zifan Jiang"],"pdf_url":"https://arxiv.org/pdf/2410.13675v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.13671v1","updated":"2024-10-17T15:29:57Z","published":"2024-10-17T15:29:57Z","title":"HEALTH-PARIKSHA: Assessing RAG Models for Health Chatbots in Real-World\n  Multilingual Settings","summary":"  Assessing the capabilities and limitations of large language models (LLMs)\nhas garnered significant interest, yet the evaluation of multiple models in\nreal-world scenarios remains rare. Multilingual evaluation often relies on\ntranslated benchmarks, which typically do not capture linguistic and cultural\nnuances present in the source language. This study provides an extensive\nassessment of 24 LLMs on real world data collected from Indian patients\ninteracting with a medical chatbot in Indian English and 4 other Indic\nlanguages. We employ a uniform Retrieval Augmented Generation framework to\ngenerate responses, which are evaluated using both automated techniques and\nhuman evaluators on four specific metrics relevant to our application. We find\nthat models vary significantly in their performance and that instruction tuned\nIndic models do not always perform well on Indic language queries. Further, we\nempirically show that factual correctness is generally lower for responses to\nIndic queries compared to English queries. Finally, our qualitative work shows\nthat code-mixed and culturally relevant queries in our dataset pose challenges\nto evaluated models.\n","authors":["Varun Gumma","Anandhita Raghunath","Mohit Jain","Sunayana Sitaram"],"pdf_url":"https://arxiv.org/pdf/2410.13671v1.pdf","comment":"Under Review"},{"id":"http://arxiv.org/abs/2410.13668v1","updated":"2024-10-17T15:28:45Z","published":"2024-10-17T15:28:45Z","title":"signwriting-evaluation: Effective Sign Language Evaluation via\n  SignWriting","summary":"  The lack of automatic evaluation metrics tailored for SignWriting presents a\nsignificant obstacle in developing effective transcription and translation\nmodels for signed languages. This paper introduces a comprehensive suite of\nevaluation metrics specifically designed for SignWriting, including adaptations\nof standard metrics such as \\texttt{BLEU} and \\texttt{chrF}, the application of\n\\texttt{CLIPScore} to SignWriting images, and a novel symbol distance metric\nunique to our approach. We address the distinct challenges of evaluating single\nsigns versus continuous signing and provide qualitative demonstrations of\nmetric efficacy through score distribution analyses and nearest-neighbor\nsearches within the SignBank corpus. Our findings reveal the strengths and\nlimitations of each metric, offering valuable insights for future advancements\nusing SignWriting. This work contributes essential tools for evaluating\nSignWriting models, facilitating progress in the field of sign language\nprocessing. Our code is available at\n\\url{https://github.com/sign-language-processing/signwriting-evaluation}.\n","authors":["Amit Moryossef","Rotem Zilberman","Ohad Langer"],"pdf_url":"https://arxiv.org/pdf/2410.13668v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.13667v1","updated":"2024-10-17T15:28:27Z","published":"2024-10-17T15:28:27Z","title":"ORCHID: A Chinese Debate Corpus for Target-Independent Stance Detection\n  and Argumentative Dialogue Summarization","summary":"  Dialogue agents have been receiving increasing attention for years, and this\ntrend has been further boosted by the recent progress of large language models\n(LLMs). Stance detection and dialogue summarization are two core tasks of\ndialogue agents in application scenarios that involve argumentative dialogues.\nHowever, research on these tasks is limited by the insufficiency of public\ndatasets, especially for non-English languages. To address this language\nresource gap in Chinese, we present ORCHID (Oral Chinese Debate), the first\nChinese dataset for benchmarking target-independent stance detection and debate\nsummarization. Our dataset consists of 1,218 real-world debates that were\nconducted in Chinese on 476 unique topics, containing 2,436 stance-specific\nsummaries and 14,133 fully annotated utterances. Besides providing a versatile\ntestbed for future research, we also conduct an empirical study on the dataset\nand propose an integrated task. The results show the challenging nature of the\ndataset and suggest a potential of incorporating stance detection in\nsummarization for argumentative dialogue.\n","authors":["Xiutian Zhao","Ke Wang","Wei Peng"],"pdf_url":"https://arxiv.org/pdf/2410.13667v1.pdf","comment":"In EMNLP 2023"},{"id":"http://arxiv.org/abs/2409.15355v4","updated":"2024-10-17T15:27:30Z","published":"2024-09-14T02:34:26Z","title":"Block-Attention for Efficient RAG","summary":"  We introduce Block-Attention, an attention mechanism designed to address the\nincreased inference latency and cost in Retrieval-Augmented Generation (RAG)\nscenarios. Traditional approaches often encode the entire context. Instead,\nBlock-Attention divides retrieved documents into discrete blocks, with each\nblock independently calculating key-value (KV) states except for the final\nblock. In RAG scenarios, by defining each passage as a block, Block-Attention\nenables us to reuse the KV states of passages that have been seen before,\nthereby significantly reducing the latency and the computation overhead during\ninference. The implementation of Block-Attention involves block segmentation,\nposition re-encoding, and fine-tuning the LLM to adapt to the Block-Attention\nmechanism. Experiments on four RAG benchmarks demonstrate that after block\nfine-tuning, the Block-Attention model achieves performance comparable to\nself-attention models (68.4\\% vs 67.9\\% on Llama3) or even superior performance\n(62.8\\% vs 59.6\\% on Mistral). Notably, Block-Attention significantly reduces\nthe time to first token (TTFT) and floating point operations (FLOPs) to a very\nlow level. It only takes 45 ms to output the first token for an input sequence\nwith a total length of 32K. Compared to the self-attention models, the time\nconsumption and corresponding FLOPs are reduced by 98.7\\% and 99.8\\%,\nrespectively.\n","authors":["East Sun","Yan Wang","Lan Tian"],"pdf_url":"https://arxiv.org/pdf/2409.15355v4.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.13666v1","updated":"2024-10-17T15:27:17Z","published":"2024-10-17T15:27:17Z","title":"VL-GLUE: A Suite of Fundamental yet Challenging Visuo-Linguistic\n  Reasoning Tasks","summary":"  Deriving inference from heterogeneous inputs (such as images, text, and\naudio) is an important skill for humans to perform day-to-day tasks. A similar\nability is desirable for the development of advanced Artificial Intelligence\n(AI) systems. While state-of-the-art models are rapidly closing the gap with\nhuman-level performance on diverse computer vision and NLP tasks separately,\nthey struggle to solve tasks that require joint reasoning over visual and\ntextual modalities. Inspired by GLUE (Wang et. al., 2018)- a multitask\nbenchmark for natural language understanding, we propose VL-GLUE in this paper.\nVL-GLUE consists of over 100k samples spanned across seven different tasks,\nwhich at their core require visuo-linguistic reasoning. Moreover, our benchmark\ncomprises of diverse image types (from synthetically rendered figures, and\nday-to-day scenes to charts and complex diagrams) and includes a broad variety\nof domain-specific text (from cooking, politics, and sports to high-school\ncurricula), demonstrating the need for multi-modal understanding in the\nreal-world. We show that this benchmark is quite challenging for existing\nlarge-scale vision-language models and encourage development of systems that\npossess robust visuo-linguistic reasoning capabilities.\n","authors":["Shailaja Keyur Sampat","Mutsumi Nakamura","Shankar Kailas","Kartik Aggarwal","Mandy Zhou","Yezhou Yang","Chitta Baral"],"pdf_url":"https://arxiv.org/pdf/2410.13666v1.pdf","comment":"18 pages, 7 figures"},{"id":"http://arxiv.org/abs/2404.00489v2","updated":"2024-10-17T15:20:23Z","published":"2024-03-30T23:07:58Z","title":"Prompt-SAW: Leveraging Relation-Aware Graphs for Textual Prompt\n  Compression","summary":"  Large Language Models (LLMs) have shown exceptional abilities for multiple\ndifferent natural language processing tasks. While prompting is a crucial tool\nfor LLM inference, we observe that there is a significant cost associated with\nexceedingly lengthy prompts. Existing attempts to compress lengthy prompts lead\nto substandard results in terms of readability/interpretability of the\ncompressed prompt, with a detrimental impact on prompt utility. To address\nthis, we propose PromptSAW: Prompt compresSion via Relation AWare graphs, an\neffective strategy for prompt compression over task-agnostic and task-aware\nprompts. Prompt-SAW uses the prompt's textual information to build a graph and\nlater extracts key information elements in the graph to come up with the\ncompressed prompt. We also propose GSM8K-aug, i.e., an extended version of the\nexisting GSM8K benchmark for task-agnostic prompts in order to provide a\ncomprehensive evaluation platform. Experimental evaluation using benchmark\ndatasets shows that prompts compressed by Prompt-SAW are not only better in\nterms of readability, but they also outperform the best-performing baseline\nmodels by up to 10.1 and 77.1, respectively, for task-agnostic and task-aware\nsettings while compressing the original prompt text by 34.9 and 56.7.\n","authors":["Muhammad Asif Ali","Zhengping Li","Shu Yang","Keyuan Cheng","Yang Cao","Tianhao Huang","Guimin Hu","Weimin Lyu","Lijie Hu","Lu Yu","Di Wang"],"pdf_url":"https://arxiv.org/pdf/2404.00489v2.pdf","comment":"16 pages"},{"id":"http://arxiv.org/abs/2410.13654v1","updated":"2024-10-17T15:19:03Z","published":"2024-10-17T15:19:03Z","title":"Red and blue language: Word choices in the Trump & Harris 2024\n  presidential debate","summary":"  Political debates are a peculiar type of political discourse, in which\ncandidates directly confront one another, addressing not only the the\nmoderator's questions, but also their opponent's statements, as well as the\nconcerns of voters from both parties and undecided voters. Therefore, language\nis adjusted to meet specific expectations and achieve persuasion. We analyse\nhow the language of Trump and Harris during the debate (September 10th 2024)\ndiffers in relation to the following semantic and pragmatic features, for which\nwe formulated targeted hypotheses: framing values and ideology, appealing to\nemotion, using words with different degrees of concreteness and specificity,\naddressing others through singular or plural pronouns. Our findings include:\ndifferences in the use of figurative frames (Harris often framing issues around\nrecovery and empowerment, Trump often focused on crisis and decline); similar\nuse of emotional language, with Trump showing a slight higher tendency toward\nnegativity and toward less subjective language compared to Harris; no\nsignificant difference in the specificity of candidates' responses; similar use\nof abstract language, with Trump showing more variability than Harris,\ndepending on the subject discussed; differences in addressing the opponent,\nwith Trump not mentioning Harris by name, while Harris referring to Trump\nfrequently; different uses of pronouns, with Harris using both singular and\nplural pronouns equally, while Trump using more singular pronouns. The results\nare discussed in relation to previous literature on Red and Blue language,\nwhich refers to distinct linguistic patterns associated with conservative (Red)\nand liberal (Blue) political ideologies.\n","authors":["Philipp Wicke","Marianna M. Bolognesi"],"pdf_url":"https://arxiv.org/pdf/2410.13654v1.pdf","comment":"Submitted to PLOS ONE, under review"},{"id":"http://arxiv.org/abs/2410.13649v1","updated":"2024-10-17T15:15:12Z","published":"2024-10-17T15:15:12Z","title":"A new approach for fine-tuning sentence transformers for intent\n  classification and out-of-scope detection tasks","summary":"  In virtual assistant (VA) systems it is important to reject or redirect user\nqueries that fall outside the scope of the system. One of the most accurate\napproaches for out-of-scope (OOS) rejection is to combine it with the task of\nintent classification on in-scope queries, and to use methods based on the\nsimilarity of embeddings produced by transformer-based sentence encoders.\nTypically, such encoders are fine-tuned for the intent-classification task,\nusing cross-entropy loss. Recent work has shown that while this produces\nsuitable embeddings for the intent-classification task, it also tends to\ndisperse in-scope embeddings over the full sentence embedding space. This\ncauses the in-scope embeddings to potentially overlap with OOS embeddings,\nthereby making OOS rejection difficult. This is compounded when OOS data is\nunknown. To mitigate this issue our work proposes to regularize the\ncross-entropy loss with an in-scope embedding reconstruction loss learned using\nan auto-encoder. Our method achieves a 1-4% improvement in the area under the\nprecision-recall curve for rejecting out-of-sample (OOS) instances, without\ncompromising intent classification performance.\n","authors":["Tianyi Zhang","Atta Norouzian","Aanchan Mohan","Frederick Ducatelle"],"pdf_url":"https://arxiv.org/pdf/2410.13649v1.pdf","comment":"Appearing at Empirical Methods in Natural Language Processing 2025 -\n  Industry Track"},{"id":"http://arxiv.org/abs/2410.13648v1","updated":"2024-10-17T15:15:00Z","published":"2024-10-17T15:15:00Z","title":"SimpleToM: Exposing the Gap between Explicit ToM Inference and Implicit\n  ToM Application in LLMs","summary":"  While prior work has explored whether large language models (LLMs) possess a\n\"theory of mind\" (ToM) - the ability to attribute mental states to oneself and\nothers - there has been little work testing whether LLMs can implicitly apply\nsuch knowledge to predict behavior, or to judge whether an observed behavior is\nrational. Such skills are critical for appropriate interaction in social\nenvironments. We create a new dataset, SimpleTom, containing concise, diverse\nstories (e.g., \"The can of Pringles has moldy chips in it. Mary picks up the\ncan in the supermarket and walks to the cashier.\"), each with three questions\nthat test different degrees of ToM reasoning, asking models to predict (a)\nmental state (\"Is Mary aware of the mold?\"), (b) behavior (\"Will Mary pay for\nthe chips or report the mold?\"), and (c) judgment (\"Mary paid for the chips.\nWas that reasonable?\"). To our knowledge, SimpleToM is the first dataset to\nsystematically explore downstream reasoning requiring knowledge of mental\nstates in realistic scenarios. Our experimental results are intriguing: While\nmost models can reliably predict mental state on our dataset (a), they often\nfail to correctly predict the behavior (b), and fare even worse at judging\nwhether given behaviors are reasonable (c), despite being correctly aware of\nthe protagonist's mental state should make such secondary predictions obvious.\nWe further show that we can help models do better at (b) and (c) via\ninterventions such as reminding the model of its earlier mental state answer\nand mental-state-specific chain-of-thought prompting, raising the action\nprediction accuracies (e.g., from 49.5% to 93.5% for GPT-4o) and judgment\naccuracies (e.g., from 15.3% to 94.7% in GPT-4o). While this shows that models\ncan be coaxed to perform well, it requires task-specific interventions, and the\nnatural model performances remain low, a cautionary tale for LLM deployment.\n","authors":["Yuling Gu","Oyvind Tafjord","Hyunwoo Kim","Jared Moore","Ronan Le Bras","Peter Clark","Yejin Choi"],"pdf_url":"https://arxiv.org/pdf/2410.13648v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.11341v3","updated":"2024-10-17T15:12:21Z","published":"2024-06-17T08:59:04Z","title":"A Systematic Analysis of Large Language Models as Soft Reasoners: The\n  Case of Syllogistic Inferences","summary":"  The reasoning abilities of Large Language Models (LLMs) are becoming a\ncentral focus of study in NLP. In this paper, we consider the case of\nsyllogistic reasoning, an area of deductive reasoning studied extensively in\nlogic and cognitive psychology. Previous research has shown that pre-trained\nLLMs exhibit reasoning biases, such as $\\textit{content effects}$, avoid\nanswering that $\\textit{no conclusion follows}$, display human-like\ndifficulties, and struggle with multi-step reasoning. We contribute to this\nresearch line by systematically investigating the effects of chain-of-thought\nreasoning, in-context learning (ICL), and supervised fine-tuning (SFT) on\nsyllogistic reasoning, considering syllogisms with conclusions that support or\nviolate world knowledge, as well as ones with multiple premises. Crucially, we\ngo beyond the standard focus on accuracy, with an in-depth analysis of the\nconclusions generated by the models. Our results suggest that the behavior of\npre-trained LLMs can be explained by heuristics studied in cognitive science\nand that both ICL and SFT improve model performance on valid inferences,\nalthough only the latter mitigates most reasoning biases without harming model\nconsistency.\n","authors":["Leonardo Bertolazzi","Albert Gatt","Raffaella Bernardi"],"pdf_url":"https://arxiv.org/pdf/2406.11341v3.pdf","comment":"Accepted to EMNLP 2024 (main conference)"},{"id":"http://arxiv.org/abs/2410.13641v1","updated":"2024-10-17T15:09:35Z","published":"2024-10-17T15:09:35Z","title":"An Active Learning Framework for Inclusive Generation by Large Language\n  Models","summary":"  Ensuring that Large Language Models (LLMs) generate text representative of\ndiverse sub-populations is essential, particularly when key concepts related to\nunder-represented groups are scarce in the training data. We address this\nchallenge with a novel clustering-based active learning framework, enhanced\nwith knowledge distillation. The proposed framework transforms the intermediate\noutputs of the learner model, enabling effective active learning for generative\ntasks for the first time. Integration of clustering and knowledge distillation\nyields more representative models without prior knowledge of underlying data\ndistribution and overbearing human efforts. We validate our approach in\npractice through case studies in counter-narration and style transfer. We\nconstruct two new datasets in tandem with model training, showing a performance\nimprovement of 2%-10% over baseline models. Our results also show more\nconsistent performance across various data subgroups and increased lexical\ndiversity, underscoring our model's resilience to skewness in available data.\nFurther, our results show that the data acquired via our approach improves the\nperformance of secondary models not involved in the learning loop, showcasing\npractical utility of the framework.\n","authors":["Sabit Hassan","Anthony Sicilia","Malihe Alikhani"],"pdf_url":"https://arxiv.org/pdf/2410.13641v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.13640v1","updated":"2024-10-17T15:09:24Z","published":"2024-10-17T15:09:24Z","title":"Latent Space Chain-of-Embedding Enables Output-free LLM Self-Evaluation","summary":"  LLM self-evaluation relies on the LLM's own ability to estimate response\ncorrectness, which can greatly improve its deployment reliability. In this\nresearch track, we propose the Chain-of-Embedding (CoE) in the latent space to\nenable LLMs to perform output-free self-evaluation. CoE consists of all\nprogressive hidden states produced during the inference time, which can be\ntreated as the latent thinking path of LLMs. We find that when LLMs respond\ncorrectly and incorrectly, their CoE features differ, these discrepancies\nassist us in estimating LLM response correctness. Experiments in four diverse\ndomains and seven LLMs fully demonstrate the effectiveness of our method.\nMeanwhile, its label-free design intent without any training and\nmillisecond-level computational cost ensure real-time feedback in large-scale\nscenarios. More importantly, we provide interesting insights into LLM response\ncorrectness from the perspective of hidden state changes inside LLMs.\n","authors":["Yiming Wang","Pei Zhang","Baosong Yang","Derek F. Wong","Rui Wang"],"pdf_url":"https://arxiv.org/pdf/2410.13640v1.pdf","comment":"33 pages, 18 figures, 12 tables"},{"id":"http://arxiv.org/abs/2410.13639v1","updated":"2024-10-17T15:09:03Z","published":"2024-10-17T15:09:03Z","title":"A Comparative Study on Reasoning Patterns of OpenAI's o1 Model","summary":"  Enabling Large Language Models (LLMs) to handle a wider range of complex\ntasks (e.g., coding, math) has drawn great attention from many researchers. As\nLLMs continue to evolve, merely increasing the number of model parameters\nyields diminishing performance improvements and heavy computational costs.\nRecently, OpenAI's o1 model has shown that inference strategies (i.e.,\nTest-time Compute methods) can also significantly enhance the reasoning\ncapabilities of LLMs. However, the mechanisms behind these methods are still\nunexplored. In our work, to investigate the reasoning patterns of o1, we\ncompare o1 with existing Test-time Compute methods (BoN, Step-wise BoN, Agent\nWorkflow, and Self-Refine) by using OpenAI's GPT-4o as a backbone on general\nreasoning benchmarks in three domains (i.e., math, coding, commonsense\nreasoning). Specifically, first, our experiments show that the o1 model has\nachieved the best performance on most datasets. Second, as for the methods of\nsearching diverse responses (e.g., BoN), we find the reward models' capability\nand the search space both limit the upper boundary of these methods. Third, as\nfor the methods that break the problem into many sub-problems, the Agent\nWorkflow has achieved better performance than Step-wise BoN due to the\ndomain-specific system prompt for planning better reasoning processes. Fourth,\nit is worth mentioning that we have summarized six reasoning patterns of o1,\nand provided a detailed analysis on several reasoning benchmarks.\n","authors":["Siwei Wu","Zhongyuan Peng","Xinrun Du","Tuney Zheng","Minghao Liu","Jialong Wu","Jiachen Ma","Yizhi Li","Jian Yang","Wangchunshu Zhou","Qunshu Lin","Junbo Zhao","Zhaoxiang Zhang","Wenhao Huang","Ge Zhang","Chenghua Lin","J. H. Liu"],"pdf_url":"https://arxiv.org/pdf/2410.13639v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.14545v2","updated":"2024-10-17T15:06:23Z","published":"2024-06-20T17:54:33Z","title":"Unmasking Database Vulnerabilities: Zero-Knowledge Schema Inference\n  Attacks in Text-to-SQL Systems","summary":"  Text-to-SQL systems empower users to interact with databases using natural\nlanguage, automatically translating queries into executable SQL code. However,\ntheir reliance on database schema information for SQL generation exposes them\nto significant security vulnerabilities, particularly schema inference attacks\nthat can lead to unauthorized data access or manipulation. In this paper, we\nintroduce a novel zero-knowledge framework for reconstructing the underlying\ndatabase schema of text-to-SQL models without any prior knowledge of the\ndatabase. Our approach systematically probes text-to-SQL models with specially\ncrafted questions and leverages a surrogate GPT-4 model to interpret the\noutputs, effectively uncovering hidden schema elements -- including tables,\ncolumns, and data types. We demonstrate that our method achieves high accuracy\nin reconstructing table names, with F1 scores of up to .99 for generative\nmodels and .78 for fine-tuned models, underscoring the severity of schema\nleakage risks. Furthermore, we propose a simple protection mechanism for\ngenerative models and empirically show its limitations in mitigating these\nattacks.\n","authors":["Đorđe Klisura","Anthony Rios"],"pdf_url":"https://arxiv.org/pdf/2406.14545v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.09693v3","updated":"2024-10-17T15:03:11Z","published":"2023-11-16T09:09:22Z","title":"BLT: Can Large Language Models Handle Basic Legal Text?","summary":"  We find that the best publicly available LLMs like GPT-4 and Claude currently\nperform poorly on basic legal text handling. This motivates the creation of a\nbenchmark consisting of examples that lawyers and paralegals would expect LLMs\nto handle zero-shot, such as looking up the text at a line of a witness\ndeposition or at a subsection of a contract. LLMs' poor performance on this\nbenchmark casts into doubt their reliability as-is for legal practice. However,\nfine-tuning on our training set brings even a small model to near-perfect\nperformance. This benchmark will be useful for fine-tuning LLMs for downstream\nlegal tasks, as well as for tracking LLMs' reliability as-is for basic legal\ntasks.\n","authors":["Andrew Blair-Stanek","Nils Holzenberger","Benjamin Van Durme"],"pdf_url":"https://arxiv.org/pdf/2311.09693v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.11382v2","updated":"2024-10-17T14:59:37Z","published":"2024-08-21T07:23:34Z","title":"Towards Inducing Document-Level Abilities in Standard Multilingual\n  Neural Machine Translation Models","summary":"  Neural Machine Translation (NMT) models have traditionally used Sinusoidal\nPositional Embeddings (PEs), which often struggle to capture long-range\ndependencies and are less efficient for handling extended context or\ndocument-level translation tasks. This work addresses the challenge of\ntransitioning pre-trained NMT models from absolute sinusoidal PEs to relative\nPEs, such as Rotary Positional Embeddings (ROPE) and Attention with Linear\nBiases (ALIBI), without compromising performance. We demonstrate that\nparameter-efficient fine-tuning, using only a small amount of high-quality\ndata, can successfully facilitate this transition. Experimental results\nindicate that switching from sinusoidal to relative PEs results in competitive\ntranslation quality on sentence-level evaluation benchmarks. Additionally,\nmodels trained with ROPE consistently outperform those using ALIBI and\nSinusoidal PEs on document-level benchmarks across both string-based metrics\nand qualitative evaluations. Moreover, we find that a small amount of\nlong-context data in a few languages is sufficient for cross-lingual length\ngeneralization, thereby inducing long-context capabilities.\n","authors":["Varun Gumma","Pranjal A. Chitale","Kalika Bali"],"pdf_url":"https://arxiv.org/pdf/2408.11382v2.pdf","comment":"Under Review"},{"id":"http://arxiv.org/abs/2407.04952v2","updated":"2024-10-17T14:58:53Z","published":"2024-07-06T04:06:55Z","title":"Granular Privacy Control for Geolocation with Vision Language Models","summary":"  Vision Language Models (VLMs) are rapidly advancing in their capability to\nanswer information-seeking questions. As these models are widely deployed in\nconsumer applications, they could lead to new privacy risks due to emergent\nabilities to identify people in photos, geolocate images, etc. As we\ndemonstrate, somewhat surprisingly, current open-source and proprietary VLMs\nare very capable image geolocators, making widespread geolocation with VLMs an\nimmediate privacy risk, rather than merely a theoretical future concern. As a\nfirst step to address this challenge, we develop a new benchmark, GPTGeoChat,\nto test the ability of VLMs to moderate geolocation dialogues with users. We\ncollect a set of 1,000 image geolocation conversations between in-house\nannotators and GPT-4v, which are annotated with the granularity of location\ninformation revealed at each turn. Using this new dataset, we evaluate the\nability of various VLMs to moderate GPT-4v geolocation conversations by\ndetermining when too much location information has been revealed. We find that\ncustom fine-tuned models perform on par with prompted API-based models when\nidentifying leaked location information at the country or city level; however,\nfine-tuning on supervised data appears to be needed to accurately moderate\nfiner granularities, such as the name of a restaurant or building.\n","authors":["Ethan Mendes","Yang Chen","James Hays","Sauvik Das","Wei Xu","Alan Ritter"],"pdf_url":"https://arxiv.org/pdf/2407.04952v2.pdf","comment":"Accepted to EMNLP 2024 main conference"},{"id":"http://arxiv.org/abs/2410.13611v1","updated":"2024-10-17T14:46:34Z","published":"2024-10-17T14:46:34Z","title":"H2OVL-Mississippi Vision Language Models Technical Report","summary":"  Smaller vision-language models (VLMs) are becoming increasingly important for\nprivacy-focused, on-device applications due to their ability to run efficiently\non consumer hardware for processing enterprise commercial documents and images.\nThese models require strong language understanding and visual capabilities to\nenhance human-machine interaction. To address this need, we present\nH2OVL-Mississippi, a pair of small VLMs trained on 37 million image-text pairs\nusing 240 hours of compute on 8 x H100 GPUs. H2OVL-Mississippi-0.8B is a tiny\nmodel with 0.8 billion parameters that specializes in text recognition,\nachieving state of the art performance on the Text Recognition portion of\nOCRBench and surpassing much larger models in this area. Additionally, we are\nreleasing H2OVL-Mississippi-2B, a 2 billion parameter model for general use\ncases, exhibiting highly competitive metrics across various academic\nbenchmarks. Both models build upon our prior work with H2O-Danube language\nmodels, extending their capabilities into the visual domain. We release them\nunder the Apache 2.0 license, making VLMs accessible to everyone, democratizing\ndocument AI and visual LLMs.\n","authors":["Shaikat Galib","Shanshan Wang","Guanshuo Xu","Pascal Pfeiffer","Ryan Chesler","Mark Landry","Sri Satish Ambati"],"pdf_url":"https://arxiv.org/pdf/2410.13611v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.13610v1","updated":"2024-10-17T14:46:22Z","published":"2024-10-17T14:46:22Z","title":"MeNTi: Bridging Medical Calculator and LLM Agent with Nested Tool\n  Calling","summary":"  Integrating tools into Large Language Models (LLMs) has facilitated the\nwidespread application. Despite this, in specialized downstream task contexts,\nreliance solely on tools is insufficient to fully address the complexities of\nthe real world. This particularly restricts the effective deployment of LLMs in\nfields such as medicine. In this paper, we focus on the downstream tasks of\nmedical calculators, which use standardized tests to assess an individual's\nhealth status. We introduce MeNTi, a universal agent architecture for LLMs.\nMeNTi integrates a specialized medical toolkit and employs meta-tool and nested\ncalling mechanisms to enhance LLM tool utilization. Specifically, it achieves\nflexible tool selection and nested tool calling to address practical issues\nfaced in intricate medical scenarios, including calculator selection, slot\nfilling, and unit conversion. To assess the capabilities of LLMs for\nquantitative assessment throughout the clinical process of calculator\nscenarios, we introduce CalcQA. This benchmark requires LLMs to use medical\ncalculators to perform calculations and assess patient health status. CalcQA is\nconstructed by professional physicians and includes 100 case-calculator pairs,\ncomplemented by a toolkit of 281 medical tools. The experimental results\ndemonstrate significant performance improvements with our framework. This\nresearch paves new directions for applying LLMs in demanding scenarios of\nmedicine.\n","authors":["Yakun Zhu","Shaohang Wei","Xu Wang","Kui Xue","Xiaofan Zhang","Shaoting Zhang"],"pdf_url":"https://arxiv.org/pdf/2410.13610v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.07991v2","updated":"2024-10-17T14:44:45Z","published":"2024-10-10T14:48:57Z","title":"Human and LLM Biases in Hate Speech Annotations: A Socio-Demographic\n  Analysis of Annotators and Targets","summary":"  The rise of online platforms exacerbated the spread of hate speech, demanding\nscalable and effective detection. However, the accuracy of hate speech\ndetection systems heavily relies on human-labeled data, which is inherently\nsusceptible to biases. While previous work has examined the issue, the\ninterplay between the characteristics of the annotator and those of the target\nof the hate are still unexplored. We fill this gap by leveraging an extensive\ndataset with rich socio-demographic information of both annotators and targets,\nuncovering how human biases manifest in relation to the target's attributes.\nOur analysis surfaces the presence of widespread biases, which we\nquantitatively describe and characterize based on their intensity and\nprevalence, revealing marked differences. Furthermore, we compare human biases\nwith those exhibited by persona-based LLMs. Our findings indicate that while\npersona-based LLMs do exhibit biases, these differ significantly from those of\nhuman annotators. Overall, our work offers new and nuanced results on human\nbiases in hate speech annotations, as well as fresh insights into the design of\nAI-driven hate speech detection systems.\n","authors":["Tommaso Giorgi","Lorenzo Cima","Tiziano Fagni","Marco Avvenuti","Stefano Cresci"],"pdf_url":"https://arxiv.org/pdf/2410.07991v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2409.17648v3","updated":"2024-10-17T14:41:39Z","published":"2024-09-26T08:55:21Z","title":"Efficient In-Domain Question Answering for Resource-Constrained\n  Environments","summary":"  Retrieval Augmented Generation (RAG) is a common method for integrating\nexternal knowledge into pretrained Large Language Models (LLMs) to enhance\naccuracy and relevancy in question answering (QA) tasks. However, prompt\nengineering and resource efficiency remain significant bottlenecks in\ndeveloping optimal and robust RAG solutions for real-world QA applications.\nRecent studies have shown success in using fine tuning to address these\nproblems; in particular, Retrieval Augmented Fine Tuning (RAFT) applied to\nsmaller 7B models has demonstrated superior performance compared to RAG setups\nwith much larger models such as GPT-3.5. The combination of RAFT with\nparameter-efficient fine tuning (PEFT) techniques, such as Low-Rank Adaptation\n(LoRA), promises an even more efficient solution, yet remains an unexplored\narea. In this work, we combine RAFT with LoRA to reduce fine tuning and storage\nrequirements and gain faster inference times while maintaining comparable RAG\nperformance. This results in a more compute-efficient RAFT, or CRAFT, which is\nparticularly useful for knowledge-intensive QA tasks in resource-constrained\nenvironments where internet access may be restricted and hardware resources\nlimited.\n","authors":["Isaac Chung","Phat Vo","Arman C. Kizilkale","Aaron Reite"],"pdf_url":"https://arxiv.org/pdf/2409.17648v3.pdf","comment":"6 pages, 2 tables"},{"id":"http://arxiv.org/abs/2410.13604v1","updated":"2024-10-17T14:39:24Z","published":"2024-10-17T14:39:24Z","title":"Large Language Models as Narrative-Driven Recommenders","summary":"  Narrative-driven recommenders aim to provide personalized suggestions for\nuser requests expressed in free-form text such as \"I want to watch a thriller\nwith a mind-bending story, like Shutter Island.\" Although large language models\n(LLMs) have been shown to excel in processing general natural language queries,\ntheir effectiveness for handling such recommendation requests remains\nrelatively unexplored. To close this gap, we compare the performance of 38\nopen- and closed-source LLMs of various sizes, such as LLama 3.2 and GPT-4o, in\na movie recommendation setting. For this, we utilize a gold-standard,\ncrowdworker-annotated dataset of posts from reddit's movie suggestion community\nand employ various prompting strategies, including zero-shot, identity, and\nfew-shot prompting. Our findings demonstrate the ability of LLMs to generate\ncontextually relevant movie recommendations, significantly outperforming other\nstate-of-the-art approaches, such as doc2vec. While we find that closed-source\nand large-parameterized models generally perform best, medium-sized open-source\nmodels remain competitive, being only slightly outperformed by their more\ncomputationally expensive counterparts. Furthermore, we observe no significant\ndifferences across prompting strategies for most models, underscoring the\neffectiveness of simple approaches such as zero-shot prompting for\nnarrative-driven recommendations. Overall, this work offers valuable insights\nfor recommender system researchers as well as practitioners aiming to integrate\nLLMs into real-world recommendation tools.\n","authors":["Lukas Eberhard","Thorsten Ruprechter","Denis Helic"],"pdf_url":"https://arxiv.org/pdf/2410.13604v1.pdf","comment":"Under review; 19 pages"},{"id":"http://arxiv.org/abs/2410.13562v1","updated":"2024-10-17T14:00:13Z","published":"2024-10-17T14:00:13Z","title":"Enhancing Fact Retrieval in PLMs through Truthfulness","summary":"  Pre-trained Language Models (PLMs) encode various facts about the world at\ntheir pre-training phase as they are trained to predict the next or missing\nword in a sentence. There has a been an interest in quantifying and improving\nthe amount of facts that can be extracted from PLMs, as they have been\nenvisioned to act as soft knowledge bases, which can be queried in natural\nlanguage. Different approaches exist to enhance fact retrieval from PLM. Recent\nwork shows that the hidden states of PLMs can be leveraged to determine the\ntruthfulness of the PLMs' inputs. Leveraging this finding to improve factual\nknowledge retrieval remains unexplored. In this work, we investigate the use of\na helper model to improve fact retrieval. The helper model assesses the\ntruthfulness of an input based on the corresponding hidden states\nrepresentations from the PLMs. We evaluate this approach on several masked PLMs\nand show that it enhances fact retrieval by up to 33\\%. Our findings highlight\nthe potential of hidden states representations from PLMs in improving their\nfactual knowledge retrieval.\n","authors":["Paul Youssef","Jörg Schlötterer","Christin Seifert"],"pdf_url":"https://arxiv.org/pdf/2410.13562v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.13553v1","updated":"2024-10-17T13:51:03Z","published":"2024-10-17T13:51:03Z","title":"Integrating Temporal Representations for Dynamic Memory Retrieval and\n  Management in Large Language Models","summary":"  Conventional dialogue agents often struggle with effective memory recall,\nleading to redundant retrieval and inadequate management of unique user\nassociations. To address this, we propose SynapticRAG, a novel approach\nintegrating synaptic dynamics into Retrieval-Augmented Generation (RAG).\nSynapticRAG integrates temporal representations into memory vectors, mimicking\nbiological synapses by differentiating events based on occurrence times and\ndynamically updating memory significance. This model employs temporal scoring\nfor memory connections and a synaptic-inspired propagation control mechanism.\nExperiments across English, Japanese, and Chinese datasets demonstrate\nSynapticRAG's superiority over existing methods, including traditional RAG,\nwith up to 14.66\\% improvement in memory retrieval accuracy. Our approach\nadvances context-aware dialogue AI systems by enhancing long-term context\nmaintenance and specific information extraction from conversations.\n","authors":["Yuki Hou","Haruki Tamoto","Homei Miyashita"],"pdf_url":"https://arxiv.org/pdf/2410.13553v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2404.16710v3","updated":"2024-10-17T13:50:46Z","published":"2024-04-25T16:20:23Z","title":"LayerSkip: Enabling Early Exit Inference and Self-Speculative Decoding","summary":"  We present LayerSkip, an end-to-end solution to speed-up inference of large\nlanguage models (LLMs). First, during training we apply layer dropout, with low\ndropout rates for earlier layers and higher dropout rates for later layers, and\nan early exit loss where all transformer layers share the same exit. Second,\nduring inference, we show that this training recipe increases the accuracy of\nearly exit at earlier layers, without adding any auxiliary layers or modules to\nthe model. Third, we present a novel self-speculative decoding solution where\nwe exit at early layers and verify and correct with remaining layers of the\nmodel. Our proposed self-speculative decoding approach has less memory\nfootprint than other speculative decoding approaches and benefits from shared\ncompute and activations of the draft and verification stages. We run\nexperiments on different Llama model sizes on different types of training:\npretraining from scratch, continual pretraining, finetuning on specific data\ndomain, and finetuning on specific task. We implement our inference solution\nand show speedups of up to 2.16x on summarization for CNN/DM documents, 1.82x\non coding, and 2.0x on TOPv2 semantic parsing task. We open source our code and\ncheckpoints at https://github.com/facebookresearch/LayerSkip.\n","authors":["Mostafa Elhoushi","Akshat Shrivastava","Diana Liskovich","Basil Hosmer","Bram Wasti","Liangzhen Lai","Anas Mahmoud","Bilge Acun","Saurabh Agarwal","Ahmed Roman","Ahmed A Aly","Beidi Chen","Carole-Jean Wu"],"pdf_url":"https://arxiv.org/pdf/2404.16710v3.pdf","comment":"ACL 2024"},{"id":"http://arxiv.org/abs/2406.03857v2","updated":"2024-10-17T13:08:13Z","published":"2024-06-06T08:42:36Z","title":"MuJo: Multimodal Joint Feature Space Learning for Human Activity\n  Recognition","summary":"  Human Activity Recognition (HAR) is a longstanding problem in AI with\napplications in a broad range of areas, including healthcare, sports and\nfitness, security, and more. The performance of HAR in real-world settings is\nstrongly dependent on the type and quality of the input signal that can be\nacquired. Given an unobstructed, high-quality camera view of a scene, computer\nvision systems, in particular in conjunction with foundation models, can today\nfairly reliably distinguish complex activities. On the other hand, recognition\nusing modalities such as wearable sensors (which are often more broadly\navailable, e.g., in mobile phones and smartwatches) is a more difficult\nproblem, as the signals often contain less information and labeled training\ndata is more difficult to acquire. To alleviate the need for labeled data, we\nintroduce our comprehensive Fitness Multimodal Activity Dataset (FiMAD) in this\nwork, which can be used with the proposed pre-training method MuJo (Multimodal\nJoint Feature Space Learning) to enhance HAR performance across various\nmodalities. FiMAD was created using YouTube fitness videos and contains\nparallel video, language, pose, and simulated IMU sensor data. MuJo utilizes\nthis dataset to learn a joint feature space for these modalities. We show that\nclassifiers pre-trained on FiMAD can increase the performance on real HAR\ndatasets such as MM-Fit, MyoGym, MotionSense, and MHEALTH. For instance, on\nMM-Fit, we achieve an Macro F1-Score of up to 0.855 when fine-tuning on only 2%\nof the training data and 0.942 when utilizing the full training set for\nclassification tasks. We have compared our approach to other self-supervised\nones and showed that, unlike them, ours can consistently improve on the\nbaseline network performance as well as provide a better data-efficiency.\n","authors":["Stefan Gerd Fritsch","Cennet Oguz","Vitor Fortes Rey","Lala Ray","Maximilian Kiefer-Emmanouilidis","Paul Lukowicz"],"pdf_url":"https://arxiv.org/pdf/2406.03857v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.13517v1","updated":"2024-10-17T13:06:02Z","published":"2024-10-17T13:06:02Z","title":"Bias in the Mirror : Are LLMs opinions robust to their own adversarial\n  attacks ?","summary":"  Large language models (LLMs) inherit biases from their training data and\nalignment processes, influencing their responses in subtle ways. While many\nstudies have examined these biases, little work has explored their robustness\nduring interactions. In this paper, we introduce a novel approach where two\ninstances of an LLM engage in self-debate, arguing opposing viewpoints to\npersuade a neutral version of the model. Through this, we evaluate how firmly\nbiases hold and whether models are susceptible to reinforcing misinformation or\nshifting to harmful viewpoints. Our experiments span multiple LLMs of varying\nsizes, origins, and languages, providing deeper insights into bias persistence\nand flexibility across linguistic and cultural contexts.\n","authors":["Virgile Rennard","Christos Xypolopoulos","Michalis Vazirgiannis"],"pdf_url":"https://arxiv.org/pdf/2410.13517v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.13510v1","updated":"2024-10-17T12:56:52Z","published":"2024-10-17T12:56:52Z","title":"GeoCoder: Solving Geometry Problems by Generating Modular Code through\n  Vision-Language Models","summary":"  Geometry problem-solving demands advanced reasoning abilities to process\nmultimodal inputs and employ mathematical knowledge effectively.\nVision-language models (VLMs) have made significant progress in various\nmultimodal tasks. Yet, they still struggle with geometry problems and are\nsignificantly limited by their inability to perform mathematical operations not\nseen during pre-training, such as calculating the cosine of an arbitrary angle,\nand by difficulties in correctly applying relevant geometry formulas. To\novercome these challenges, we present GeoCoder, which leverages modular\ncode-finetuning to generate and execute code using a predefined geometry\nfunction library. By executing the code, we achieve accurate and deterministic\ncalculations, contrasting the stochastic nature of autoregressive token\nprediction, while the function library minimizes errors in formula usage. We\nalso propose a multimodal retrieval-augmented variant of GeoCoder, named\nRAG-GeoCoder, which incorporates a non-parametric memory module for retrieving\nfunctions from the geometry library, thereby reducing reliance on parametric\nmemory. Our modular code-finetuning approach enhances the geometric reasoning\ncapabilities of VLMs, yielding an average improvement of over 16% across\nvarious question complexities on the GeomVerse dataset compared to other\nfinetuning methods.\n","authors":["Aditya Sharma","Aman Dalmia","Mehran Kazemi","Amal Zouaq","Christopher J. Pal"],"pdf_url":"https://arxiv.org/pdf/2410.13510v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.13509v1","updated":"2024-10-17T12:53:29Z","published":"2024-10-17T12:53:29Z","title":"RAG-DDR: Optimizing Retrieval-Augmented Generation Using Differentiable\n  Data Rewards","summary":"  Retrieval-Augmented Generation (RAG) has proven its effectiveness in\nmitigating hallucinations in Large Language Models (LLMs) by retrieving\nknowledge from external resources. To adapt LLMs for RAG pipelines, current\napproaches use instruction tuning to optimize LLMs, improving their ability to\nutilize retrieved knowledge. This supervised fine-tuning (SFT) approach focuses\non equipping LLMs to handle diverse RAG tasks using different instructions.\nHowever, it trains RAG modules to overfit training signals and overlooks the\nvarying data preferences among agents within the RAG system. In this paper, we\npropose a Differentiable Data Rewards (DDR) method, which end-to-end trains RAG\nsystems by aligning data preferences between different RAG modules. DDR works\nby collecting the rewards to optimize each agent with a rollout method. This\nmethod prompts agents to sample some potential responses as perturbations,\nevaluates the impact of these perturbations on the whole RAG system, and\nsubsequently optimizes the agent to produce outputs that improve the\nperformance of the RAG system. Our experiments on various knowledge-intensive\ntasks demonstrate that DDR significantly outperforms the SFT method,\nparticularly for LLMs with smaller-scale parameters that depend more on the\nretrieved knowledge. Additionally, DDR exhibits a stronger capability to align\nthe data preference between RAG modules. The DDR method makes generation module\nmore effective in extracting key information from documents and mitigating\nconflicts between parametric memory and external knowledge. All codes are\navailable at https://github.com/OpenMatch/RAG-DDR.\n","authors":["Xinze Li","Sen Mei","Zhenghao Liu","Yukun Yan","Shuo Wang","Shi Yu","Zheni Zeng","Hao Chen","Ge Yu","Zhiyuan Liu","Maosong Sun","Chenyan Xiong"],"pdf_url":"https://arxiv.org/pdf/2410.13509v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.13502v1","updated":"2024-10-17T12:48:14Z","published":"2024-10-17T12:48:14Z","title":"MathGAP: Out-of-Distribution Evaluation on Problems with Arbitrarily\n  Complex Proofs","summary":"  Large language models (LLMs) can solve arithmetic word problems with high\naccuracy, but little is known about how well they generalize to problems that\nare more complex than the ones on which they have been trained. Empirical\ninvestigations of such questions are impeded by two major flaws of current\nevaluations: (i) much of the evaluation data is contaminated, in the sense that\nit has already been seen during training, and (ii) benchmark datasets do not\ncapture how problem proofs may be arbitrarily complex in various ways. As a\nstep towards addressing these issues, we present a framework for evaluating\nLLMs on problems that have arbitrarily complex arithmetic proofs, called\nMathGAP. MathGAP generates problems that follow fixed proof specifications --\nalong with chain-of-thought reasoning annotations -- enabling systematic\nstudies on generalization with respect to arithmetic proof complexity. We apply\nMathGAP to analyze how in-context learning interacts with generalization to\nproblems that have more complex proofs. We find that among the models tested,\nmost show a significant decrease in performance as proofs get deeper and wider.\nThis effect is more pronounced in complex, nonlinear proof structures, which\nare challenging even for GPT-4o. Surprisingly, providing in-context examples\nfrom the same distribution as the test set is not always beneficial for\nperformance. In particular, zero-shot prompting as well as demonstrating a\ndiverse range of examples that are less complex than the test data sometimes\nyield similar or higher accuracies.\n","authors":["Andreas Opedal","Haruki Shirakami","Bernhard Schölkopf","Abulhair Saparov","Mrinmaya Sachan"],"pdf_url":"https://arxiv.org/pdf/2410.13502v1.pdf","comment":"Preprint"},{"id":"http://arxiv.org/abs/2410.13498v1","updated":"2024-10-17T12:43:49Z","published":"2024-10-17T12:43:49Z","title":"Enhancing Text Generation in Joint NLG/NLU Learning Through Curriculum\n  Learning, Semi-Supervised Training, and Advanced Optimization Techniques","summary":"  Text generation is the automated process of producing written or spoken\nlanguage using computational methods. It involves generating coherent and\ncontextually relevant text based on predefined rules or learned patterns.\nHowever, challenges in text generation arise from maintaining coherence,\nensuring diversity and creativity, and avoiding biases or inappropriate\ncontent. This research paper developed a novel approach to improve text\ngeneration in the context of joint Natural Language Generation (NLG) and\nNatural Language Understanding (NLU) learning. The data is prepared by\ngathering and preprocessing annotated datasets, including cleaning,\ntokenization, stemming, and stop-word removal. Feature extraction techniques\nsuch as POS tagging, Bag of words, and Term Frequency-Inverse Document\nFrequency (TF-IDF) are applied. Transformer-based encoders and decoders,\ncapturing long range dependencies and improving source-target sequence\nmodelling. Pre-trained language models like Optimized BERT are incorporated,\nalong with a Hybrid Redfox Artificial Hummingbird Algorithm (HRAHA).\nReinforcement learning with policy gradient techniques, semi-supervised\ntraining, improved attention mechanisms, and differentiable approximations like\nstraight-through Gumbel SoftMax estimator are employed to fine-tune the models\nand handle complex linguistic tasks effectively. The proposed model is\nimplemented using Python.\n","authors":["Rahimanuddin Shaik","Katikela Sreeharsha Kishore"],"pdf_url":"https://arxiv.org/pdf/2410.13498v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.13497v1","updated":"2024-10-17T12:43:47Z","published":"2024-10-17T12:43:47Z","title":"Repetition Neurons: How Do Language Models Produce Repetitions?","summary":"  This paper introduces repetition neurons, regarded as skill neurons\nresponsible for the repetition problem in text generation tasks. These neurons\nare progressively activated more strongly as repetition continues, indicating\nthat they perceive repetition as a task to copy the previous context\nrepeatedly, similar to in-context learning. We identify these repetition\nneurons by comparing activation values before and after the onset of repetition\nin texts generated by recent pre-trained language models. We analyze the\nrepetition neurons in three English and one Japanese pre-trained language\nmodels and observe similar patterns across them.\n","authors":["Tatsuya Hiraoka","Kentaro Inui"],"pdf_url":"https://arxiv.org/pdf/2410.13497v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.17453v3","updated":"2024-10-17T12:43:21Z","published":"2024-06-25T10:44:01Z","title":"Learning to Ask Informative Questions: Enhancing LLMs with Preference\n  Optimization and Expected Information Gain","summary":"  Questions are essential tools for acquiring the necessary information to\ncomplete information-seeking tasks. However, large language models (LLMs),\nespecially open-source models, often perform poorly in generating informative\nquestions, as measured by expected information gain (EIG). In this paper, we\npropose a method to enhance the informativeness of LLM-generated questions in\n20-question game dialogues. We sample multiple questions from the same model\n(LLAMA 2-CHAT 7B) for each game and create pairs of low-EIG and high-EIG\nquestions to apply a Direct Preference Optimization (DPO) algorithm. Our\nresults show that this method produces more effective questions (in terms of\nEIG), even in domains different from those used to train the DPO model.\n","authors":["Davide Mazzaccara","Alberto Testoni","Raffaella Bernardi"],"pdf_url":"https://arxiv.org/pdf/2406.17453v3.pdf","comment":"Accepted to EMNLP 2024 (Findings)"},{"id":"http://arxiv.org/abs/2405.02933v2","updated":"2024-10-17T12:39:05Z","published":"2024-05-05T13:42:25Z","title":"Relay Decoding: Concatenating Large Language Models for Machine\n  Translation","summary":"  Leveraging large language models for machine translation has demonstrated\npromising results. However, it does require the large language models to\npossess the capability of handling both the source and target languages in\nmachine translation. When it is challenging to find large models that support\nthe desired languages, resorting to continuous learning methods becomes a\ncostly endeavor. To mitigate these expenses, we propose an innovative approach\ncalled RD (Relay Decoding), which entails concatenating two distinct large\nmodels that individually support the source and target languages. By\nincorporating a simple mapping layer to facilitate the connection between these\ntwo models and utilizing a limited amount of parallel data for training, we\nsuccessfully achieve superior results in the machine translation task.\nExperimental results conducted on the Multi30k and WikiMatrix datasets validate\nthe effectiveness of our proposed method.\n","authors":["Chengpeng Fu","Xiaocheng Feng","Yichong Huang","Wenshuai Huo","Baohang Li","Hui Wang","Bin Qin","Ting Liu"],"pdf_url":"https://arxiv.org/pdf/2405.02933v2.pdf","comment":"Work in progress"},{"id":"http://arxiv.org/abs/2410.13488v1","updated":"2024-10-17T12:32:00Z","published":"2024-10-17T12:32:00Z","title":"Seeing Through VisualBERT: A Causal Adventure on Memetic Landscapes","summary":"  Detecting offensive memes is crucial, yet standard deep neural network\nsystems often remain opaque. Various input attribution-based methods attempt to\ninterpret their behavior, but they face challenges with implicitly offensive\nmemes and non-causal attributions. To address these issues, we propose a\nframework based on a Structural Causal Model (SCM). In this framework,\nVisualBERT is trained to predict the class of an input meme based on both meme\ninput and causal concepts, allowing for transparent interpretation. Our\nqualitative evaluation demonstrates the framework's effectiveness in\nunderstanding model behavior, particularly in determining whether the model was\nright due to the right reason, and in identifying reasons behind\nmisclassification. Additionally, quantitative analysis assesses the\nsignificance of proposed modelling choices, such as de-confounding, adversarial\nlearning, and dynamic routing, and compares them with input attribution\nmethods. Surprisingly, we find that input attribution methods do not guarantee\ncausality within our framework, raising questions about their reliability in\nsafety-critical applications. The project page is at:\nhttps://newcodevelop.github.io/causality_adventure/\n","authors":["Dibyanayan Bandyopadhyay","Mohammed Hasanuzzaman","Asif Ekbal"],"pdf_url":"https://arxiv.org/pdf/2410.13488v1.pdf","comment":"Accepted at EMNLP Findings 2024"},{"id":"http://arxiv.org/abs/2410.10850v2","updated":"2024-10-17T11:52:38Z","published":"2024-10-06T07:40:11Z","title":"On the Reliability of Large Language Models to Misinformed and\n  Demographically-Informed Prompts","summary":"  We investigate and observe the behaviour and performance of Large Language\nModel (LLM)-backed chatbots in addressing misinformed prompts and questions\nwith demographic information within the domains of Climate Change and Mental\nHealth. Through a combination of quantitative and qualitative methods, we\nassess the chatbots' ability to discern the veracity of statements, their\nadherence to facts, and the presence of bias or misinformation in their\nresponses. Our quantitative analysis using True/False questions reveals that\nthese chatbots can be relied on to give the right answers to these close-ended\nquestions. However, the qualitative insights, gathered from domain experts,\nshows that there are still concerns regarding privacy, ethical implications,\nand the necessity for chatbots to direct users to professional services. We\nconclude that while these chatbots hold significant promise, their deployment\nin sensitive areas necessitates careful consideration, ethical oversight, and\nrigorous refinement to ensure they serve as a beneficial augmentation to human\nexpertise rather than an autonomous solution.\n","authors":["Toluwani Aremu","Oluwakemi Akinwehinmi","Chukwuemeka Nwagu","Syed Ishtiaque Ahmed","Rita Orji","Pedro Arnau Del Amo","Abdulmotaleb El Saddik"],"pdf_url":"https://arxiv.org/pdf/2410.10850v2.pdf","comment":"Study conducted between August and December 2023. Under review at\n  AAAI-AI Magazine. Submitted for archival purposes only"},{"id":"http://arxiv.org/abs/2410.13464v1","updated":"2024-10-17T11:48:57Z","published":"2024-10-17T11:48:57Z","title":"IterSelectTune: An Iterative Training Framework for Efficient\n  Instruction-Tuning Data Selection","summary":"  As large language models (LLMs) continue to advance, instruction tuning has\nbecome critical for improving their ability to generate accurate and\ncontextually appropriate responses. Although numerous instruction-tuning\ndatasets have been developed to enhance LLM performance, selecting high-quality\ninstruction data from large source datasets typically demands significant human\neffort. In this work, we introduce $\\textbf{IterSelectTune}$, an efficient,\ncost-effective iterative training policy for selecting high-quality instruction\ndata with no human involvement and limited reliance on GPT-4. By fine-tuning on\napproximately 20\\% of the source data, our method consistently outperforms\nmodels fine-tuned on the full dataset across multiple benchmarks and public\ntest datasets. These results highlight the effectiveness of our approach in\nenhancing LLM performance while reducing the computational resources required\nfor instruction tuning.\n","authors":["Jielin Song","Siyu Liu","Bin Zhu","Yanghui Rao"],"pdf_url":"https://arxiv.org/pdf/2410.13464v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.13461v1","updated":"2024-10-17T11:46:33Z","published":"2024-10-17T11:46:33Z","title":"Progressive Mixed-Precision Decoding for Efficient LLM Inference","summary":"  In spite of the great potential of large language models (LLMs) across\nvarious tasks, their deployment on resource-constrained devices remains\nchallenging due to their excessive computational and memory demands.\nQuantization has emerged as an effective solution by storing weights in reduced\nprecision. However, utilizing low precisions (i.e.~2/3-bit) to substantially\nalleviate the memory-boundedness of LLM decoding, still suffers from\nprohibitive performance drop. In this work, we argue that existing approaches\nfail to explore the diversity in computational patterns, redundancy, and\nsensitivity to approximations of the different phases of LLM inference,\nresorting to a uniform quantization policy throughout. Instead, we propose a\nnovel phase-aware method that selectively allocates precision during different\nphases of LLM inference, achieving both strong context extraction during\nprefill and efficient memory bandwidth utilization during decoding. To further\naddress the memory-boundedness of the decoding phase, we introduce Progressive\nMixed-Precision Decoding (PMPD), a technique that enables the gradual lowering\nof precision deeper in the generated sequence, together with a spectrum of\nprecision-switching schedulers that dynamically drive the precision-lowering\ndecisions in either task-adaptive or prompt-adaptive manner. Extensive\nevaluation across diverse language tasks shows that when targeting Nvidia GPUs,\nPMPD achieves 1.4$-$12.2$\\times$ speedup in matrix-vector multiplications over\nfp16 models, while when targeting an LLM-optimized NPU, our approach delivers a\nthroughput gain of 3.8$-$8.0$\\times$ over fp16 models and up to 1.54$\\times$\nover uniform quantization approaches while preserving the output quality.\n","authors":["Hao Mark Chen","Fuwen Tan","Alexandros Kouris","Royson Lee","Hongxiang Fan","Stylianos I. Venieris"],"pdf_url":"https://arxiv.org/pdf/2410.13461v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.16807v2","updated":"2024-10-17T11:46:18Z","published":"2024-06-24T17:19:34Z","title":"Beyond Thumbs Up/Down: Untangling Challenges of Fine-Grained Feedback\n  for Text-to-Image Generation","summary":"  Human feedback plays a critical role in learning and refining reward models\nfor text-to-image generation, but the optimal form the feedback should take for\nlearning an accurate reward function has not been conclusively established.\nThis paper investigates the effectiveness of fine-grained feedback which\ncaptures nuanced distinctions in image quality and prompt-alignment, compared\nto traditional coarse-grained feedback (for example, thumbs up/down or ranking\nbetween a set of options). While fine-grained feedback holds promise,\nparticularly for systems catering to diverse societal preferences, we show that\ndemonstrating its superiority to coarse-grained feedback is not automatic.\nThrough experiments on real and synthetic preference data, we surface the\ncomplexities of building effective models due to the interplay of model choice,\nfeedback type, and the alignment between human judgment and computational\ninterpretation. We identify key challenges in eliciting and utilizing\nfine-grained feedback, prompting a reassessment of its assumed benefits and\npracticality. Our findings -- e.g., that fine-grained feedback can lead to\nworse models for a fixed budget, in some settings; however, in controlled\nsettings with known attributes, fine grained rewards can indeed be more helpful\n-- call for careful consideration of feedback attributes and potentially beckon\nnovel modeling approaches to appropriately unlock the potential value of\nfine-grained feedback in-the-wild.\n","authors":["Katherine M. Collins","Najoung Kim","Yonatan Bitton","Verena Rieser","Shayegan Omidshafiei","Yushi Hu","Sherol Chen","Senjuti Dutta","Minsuk Chang","Kimin Lee","Youwei Liang","Georgina Evans","Sahil Singla","Gang Li","Adrian Weller","Junfeng He","Deepak Ramachandran","Krishnamurthy Dj Dvijotham"],"pdf_url":"https://arxiv.org/pdf/2406.16807v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.13460v1","updated":"2024-10-17T11:43:16Z","published":"2024-10-17T11:43:16Z","title":"Breaking the Manual Annotation Bottleneck: Creating a Comprehensive\n  Legal Case Criticality Dataset through Semi-Automated Labeling","summary":"  Predicting case criticality helps legal professionals in the court system\nmanage large volumes of case law. This paper introduces the Criticality\nPrediction dataset, a new resource for evaluating the potential influence of\nSwiss Federal Supreme Court decisions on future jurisprudence. Unlike existing\napproaches that rely on resource-intensive manual annotations, we\nsemi-automatically derive labels leading to a much larger dataset than\notherwise possible. Our dataset features a two-tier labeling system: (1) the\nLD-Label, which identifies cases published as Leading Decisions (LD), and (2)\nthe Citation-Label, which ranks cases by their citation frequency and recency.\nThis allows for a more nuanced evaluation of case importance. We evaluate\nseveral multilingual models, including fine-tuned variants and large language\nmodels, and find that fine-tuned models consistently outperform zero-shot\nbaselines, demonstrating the need for task-specific adaptation. Our\ncontributions include the introduction of this task and the release of a\nmultilingual dataset to the research community.\n","authors":["Ronja Stern","Ken Kawamura","Matthias Stürmer","Ilias Chalkidis","Joel Niklaus"],"pdf_url":"https://arxiv.org/pdf/2410.13460v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.13458v1","updated":"2024-10-17T11:38:54Z","published":"2024-10-17T11:38:54Z","title":"MedINST: Meta Dataset of Biomedical Instructions","summary":"  The integration of large language model (LLM) techniques in the field of\nmedical analysis has brought about significant advancements, yet the scarcity\nof large, diverse, and well-annotated datasets remains a major challenge.\nMedical data and tasks, which vary in format, size, and other parameters,\nrequire extensive preprocessing and standardization for effective use in\ntraining LLMs. To address these challenges, we introduce MedINST, the Meta\nDataset of Biomedical Instructions, a novel multi-domain, multi-task\ninstructional meta-dataset. MedINST comprises 133 biomedical NLP tasks and over\n7 million training samples, making it the most comprehensive biomedical\ninstruction dataset to date. Using MedINST as the meta dataset, we curate\nMedINST32, a challenging benchmark with different task difficulties aiming to\nevaluate LLMs' generalization ability. We fine-tune several LLMs on MedINST and\nevaluate on MedINST32, showcasing enhanced cross-task generalization.\n","authors":["Wenhan Han","Meng Fang","Zihan Zhang","Yu Yin","Zirui Song","Ling Chen","Mykola Pechenizkiy","Qingyu Chen"],"pdf_url":"https://arxiv.org/pdf/2410.13458v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.13456v1","updated":"2024-10-17T11:34:07Z","published":"2024-10-17T11:34:07Z","title":"Unlocking Legal Knowledge: A Multilingual Dataset for Judicial\n  Summarization in Switzerland","summary":"  Legal research is a time-consuming task that most lawyers face on a daily\nbasis. A large part of legal research entails looking up relevant caselaw and\nbringing it in relation to the case at hand. Lawyers heavily rely on summaries\n(also called headnotes) to find the right cases quickly. However, not all\ndecisions are annotated with headnotes and writing them is time-consuming.\nAutomated headnote creation has the potential to make hundreds of thousands of\ndecisions more accessible for legal research in Switzerland alone. To kickstart\nthis, we introduce the Swiss Leading Decision Summarization ( SLDS) dataset, a\nnovel cross-lingual resource featuring 18K court rulings from the Swiss Federal\nSupreme Court (SFSC), in German, French, and Italian, along with German\nheadnotes. We fine-tune and evaluate three mT5 variants, along with proprietary\nmodels. Our analysis highlights that while proprietary models perform well in\nzero-shot and one-shot settings, fine-tuned smaller models still provide a\nstrong competitive edge. We publicly release the dataset to facilitate further\nresearch in multilingual legal summarization and the development of assistive\ntechnologies for legal professionals\n","authors":["Luca Rolshoven","Vishvaksenan Rasiah","Srinanda Brügger Bose","Matthias Stürmer","Joel Niklaus"],"pdf_url":"https://arxiv.org/pdf/2410.13456v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2407.11843v2","updated":"2024-10-17T11:26:10Z","published":"2024-07-16T15:24:44Z","title":"InferAct: Inferring Safe Actions for LLM-Based Agents Through Preemptive\n  Evaluation and Human Feedback","summary":"  A crucial requirement for deploying LLM-based agents in real-life\napplications is the robustness against risky or even irreversible mistakes.\nHowever, the existing research lacks a focus on preemptive evaluation of\nreasoning trajectories performed by LLM agents, leading to a gap in ensuring\nsafe and reliable operations. To explore better solutions, this paper\nintroduces InferAct, a novel approach that leverages the belief reasoning\nability of LLMs, grounded in Theory-of-Mind, to proactively detect potential\nerrors before risky actions are executed (e.g., `buy-now' in automatic online\ntrading or web shopping). InferAct acts as a human proxy, detecting unsafe\nactions and alerting users for intervention, which helps prevent irreversible\nrisks in time and enhances the actor agent's decision-making process.\nExperiments on three widely-used tasks demonstrate the effectiveness of\nInferAct, presenting a novel solution for safely developing LLM agents in\nenvironments involving critical decision-making.\n","authors":["Haishuo Fang","Xiaodan Zhu","Iryna Gurevych"],"pdf_url":"https://arxiv.org/pdf/2407.11843v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.13445v1","updated":"2024-10-17T11:19:44Z","published":"2024-10-17T11:19:44Z","title":"Parameter-efficient Adaptation of Multilingual Multimodal Models for\n  Low-resource ASR","summary":"  Automatic speech recognition (ASR) for low-resource languages remains a\nchallenge due to the scarcity of labeled training data. Parameter-efficient\nfine-tuning and text-only adaptation are two popular methods that have been\nused to address such low-resource settings. In this work, we investigate how\nthese techniques can be effectively combined using a multilingual multimodal\nmodel like SeamlessM4T. Multimodal models are able to leverage unlabeled text\nvia text-only adaptation with further parameter-efficient ASR fine-tuning, thus\nboosting ASR performance. We also show cross-lingual transfer from a\nhigh-resource language, achieving up to a relative 17% WER reduction over a\nbaseline in a zero-shot setting without any labeled speech.\n","authors":["Abhishek Gupta","Amruta Parulekar","Sameep Chattopadhyay","Preethi Jyothi"],"pdf_url":"https://arxiv.org/pdf/2410.13445v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.13443v1","updated":"2024-10-17T11:18:23Z","published":"2024-10-17T11:18:23Z","title":"NLIP_Lab-IITH Multilingual MT System for WAT24 MT Shared Task","summary":"  This paper describes NLIP Lab's multilingual machine translation system for\nthe WAT24 shared task on multilingual Indic MT task for 22 scheduled languages\nbelonging to 4 language families. We explore pre-training for Indic languages\nusing alignment agreement objectives. We utilize bi-lingual dictionaries to\nsubstitute words from source sentences. Furthermore, we fine-tuned language\ndirection-specific multilingual translation models using small and high-quality\nseed data. Our primary submission is a 243M parameters multilingual translation\nmodel covering 22 Indic languages. In the IN22-Gen benchmark, we achieved an\naverage chrF++ score of 46.80 and 18.19 BLEU score for the En-Indic direction.\nIn the Indic-En direction, we achieved an average chrF++ score of 56.34 and\n30.82 BLEU score. In the In22-Conv benchmark, we achieved an average chrF++\nscore of 43.43 and BLEU score of 16.58 in the En-Indic direction, and in the\nIndic-En direction, we achieved an average of 52.44 and 29.77 for chrF++ and\nBLEU respectively. Our model\\footnote{Our code and models are available at\n\\url{https://github.com/maharajbrahma/WAT2024-MultiIndicMT}} is competitive\nwith IndicTransv1 (474M parameter model).\n","authors":["Maharaj Brahma","Pramit Sahoo","Maunendra Sankar Desarkar"],"pdf_url":"https://arxiv.org/pdf/2410.13443v1.pdf","comment":"WMT 24 WAT Shared Task IndicMultiMT (Best System)"},{"id":"http://arxiv.org/abs/2410.13439v1","updated":"2024-10-17T11:12:55Z","published":"2024-10-17T11:12:55Z","title":"Similarity-Dissimilarity Loss with Supervised Contrastive Learning for\n  Multi-label Classification","summary":"  Supervised contrastive learning has been explored in making use of label\ninformation for multi-label classification, but determining positive samples in\nmulti-label scenario remains challenging. Previous studies have examined\nstrategies for identifying positive samples, considering label overlap\nproportion between anchors and samples. However, they ignore various relations\nbetween given anchors and samples, as well as how to dynamically adjust the\nweights in contrastive loss functions based on different relations, leading to\ngreat ambiguity. In this paper, we introduce five distinct relations between\nmulti-label samples and propose a Similarity-Dissimilarity Loss with\ncontrastive learning for multi-label classification. Our loss function\nre-weights the loss by computing the similarity and dissimilarity between\npositive samples and a given anchor based on the introduced relations. We\nmainly conduct experiments for multi-label text classification on MIMIC\ndatasets, then further extend the evaluation on MS-COCO. The Experimental\nresults show that our proposed loss effectively improves the performance on all\nencoders under supervised contrastive learning paradigm, demonstrating its\neffectiveness and robustness.\n","authors":["Guangming Huang","Yunfei Long","Cunjin Luo","Sheng Liu"],"pdf_url":"https://arxiv.org/pdf/2410.13439v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.14928v2","updated":"2024-10-17T10:30:41Z","published":"2024-06-21T07:37:19Z","title":"Autonomous Agents for Collaborative Task under Information Asymmetry","summary":"  Large Language Model Multi-Agent Systems (LLM-MAS) have achieved great\nprogress in solving complex tasks. It performs communication among agents\nwithin the system to collaboratively solve tasks, under the premise of shared\ninformation. However, when agents' collaborations are leveraged to perform\nmulti-person tasks, a new challenge arises due to information asymmetry, since\neach agent can only access the information of its human user. Previous MAS\nstruggle to complete tasks under this condition. To address this, we propose a\nnew MAS paradigm termed iAgents, which denotes Informative Multi-Agent Systems.\nIn iAgents, the human social network is mirrored in the agent network, where\nagents proactively exchange human information necessary for task resolution,\nthereby overcoming information asymmetry. iAgents employs a novel agent\nreasoning mechanism, InfoNav, to navigate agents' communication toward\neffective information exchange. Together with InfoNav, iAgents organizes human\ninformation in a mixed memory to provide agents with accurate and comprehensive\ninformation for exchange. Additionally, we introduce InformativeBench, the\nfirst benchmark tailored for evaluating LLM agents' task-solving ability under\ninformation asymmetry. Experimental results show that iAgents can collaborate\nwithin a social network of 140 individuals and 588 relationships, autonomously\ncommunicate over 30 turns, and retrieve information from nearly 70,000 messages\nto complete tasks within 3 minutes.\n","authors":["Wei Liu","Chenxi Wang","Yifei Wang","Zihao Xie","Rennai Qiu","Yufan Dang","Zhuoyun Du","Weize Chen","Cheng Yang","Chen Qian"],"pdf_url":"https://arxiv.org/pdf/2406.14928v2.pdf","comment":"32 pages, 12 figures, 6 tables, accepted by NeurIPS 2024, see detail\n  at https://thinkwee.top/iagents"},{"id":"http://arxiv.org/abs/2410.13413v1","updated":"2024-10-17T10:23:24Z","published":"2024-10-17T10:23:24Z","title":"Think Thrice Before You Act: Progressive Thought Refinement in Large\n  Language Models","summary":"  Recent advancements in large language models (LLMs) have demonstrated that\nprogressive refinement, rather than providing a single answer, results in more\naccurate and thoughtful outputs. However, existing methods often rely heavily\non supervision signals to evaluate previous responses, making it difficult to\nassess output quality in more open-ended scenarios effectively. Additionally,\nthese methods are typically designed for specific tasks, which limits their\ngeneralization to new domains. To address these limitations, we propose\nProgressive Thought Refinement (PTR), a framework that enables LLMs to refine\ntheir responses progressively. PTR operates in two phases: (1) Thought data\nconstruction stage: We propose a weak and strong model collaborative selection\nstrategy to build a high-quality progressive refinement dataset to ensure\nlogical consistency from thought to answers, and the answers are gradually\nrefined in each round. (2) Thought-Mask Fine-Tuning Phase: We design a training\nstructure to mask the \"thought\" and adjust loss weights to encourage LLMs to\nrefine prior thought, teaching them to implicitly understand \"how to improve\"\nrather than \"what is correct.\" Experimental results show that PTR significantly\nenhances LLM performance across ten diverse tasks (avg. from 49.6% to 53.5%)\nwithout task-specific fine-tuning. Notably, in more open-ended tasks, LLMs also\ndemonstrate substantial improvements in the quality of responses beyond mere\naccuracy, suggesting that PTR truly teaches LLMs to self-improve over time.\n","authors":["Chengyu Du","Jinyi Han","Yizhou Ying","Aili Chen","Qianyu He","Haokun Zhao","Sirui Xia","Haoran Guo","Jiaqing Liang","Zulong Chen","Liangyue Li","Yanghua Xiao"],"pdf_url":"https://arxiv.org/pdf/2410.13413v1.pdf","comment":"10 pages, 4 figures"},{"id":"http://arxiv.org/abs/2410.13409v1","updated":"2024-10-17T10:16:56Z","published":"2024-10-17T10:16:56Z","title":"Attr-Int: A Simple and Effective Entity Alignment Framework for\n  Heterogeneous Knowledge Graphs","summary":"  Entity alignment (EA) refers to the task of linking entities in different\nknowledge graphs (KGs). Existing EA methods rely heavily on structural\nisomorphism. However, in real-world KGs, aligned entities usually have\nnon-isomorphic neighborhood structures, which paralyses the application of\nthese structure-dependent methods. In this paper, we investigate and tackle the\nproblem of entity alignment between heterogeneous KGs. First, we propose two\nnew benchmarks to closely simulate real-world EA scenarios of heterogeneity.\nThen we conduct extensive experiments to evaluate the performance of\nrepresentative EA methods on the new benchmarks. Finally, we propose a simple\nand effective entity alignment framework called Attr-Int, in which innovative\nattribute information interaction methods can be seamlessly integrated with any\nembedding encoder for entity alignment, improving the performance of existing\nentity alignment techniques. Experiments demonstrate that our framework\noutperforms the state-of-the-art approaches on two new benchmarks.\n","authors":["Linyan Yang","Jingwei Cheng","Chuanhao Xu","Xihao Wang","Jiayi Li","Fu Zhang"],"pdf_url":"https://arxiv.org/pdf/2410.13409v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.13408v1","updated":"2024-10-17T10:14:52Z","published":"2024-10-17T10:14:52Z","title":"MoR: Mixture of Ranks for Low-Rank Adaptation Tuning","summary":"  Low-Rank Adaptation (LoRA) drives research to align its performance with full\nfine-tuning. However, significant challenges remain: (1) Simply increasing the\nrank size of LoRA does not effectively capture high-rank information, which\nleads to a performance bottleneck.(2) MoE-style LoRA methods substantially\nincrease parameters and inference latency, contradicting the goals of efficient\nfine-tuning and ease of application. To address these challenges, we introduce\nMixture of Ranks (MoR), which learns rank-specific information for different\ntasks based on input and efficiently integrates multi-rank information. We\nfirstly propose a new framework that equates the integration of multiple LoRAs\nto expanding the rank of LoRA. Moreover, we hypothesize that low-rank LoRA\nalready captures sufficient intrinsic information, and MoR can derive high-rank\ninformation through mathematical transformations of the low-rank components.\nThus, MoR can reduces the learning difficulty of LoRA and enhances its\nmulti-task capabilities. MoR achieves impressive results, with MoR delivering a\n1.31\\% performance improvement while using only 93.93\\% of the parameters\ncompared to baseline methods.\n","authors":["Chuanyu Tang","Yilong Chen","Zhenyu Zhang","Junyuan Shang","Wenyuan Zhang","Yong Huang","Tingwen Liu"],"pdf_url":"https://arxiv.org/pdf/2410.13408v1.pdf","comment":"11 pages, 7 figures"},{"id":"http://arxiv.org/abs/2410.13400v1","updated":"2024-10-17T09:54:54Z","published":"2024-10-17T09:54:54Z","title":"Towards Hybrid Intelligence in Journalism: Findings and Lessons Learnt\n  from a Collaborative Analysis of Greek Political Rhetoric by ChatGPT and\n  Humans","summary":"  This chapter introduces a research project titled \"Analyzing the Political\nDiscourse: A Collaboration Between Humans and Artificial Intelligence\", which\nwas initiated in preparation for Greece's 2023 general elections. The project\nfocused on the analysis of political leaders' campaign speeches, employing\nArtificial Intelligence (AI), in conjunction with an interdisciplinary team\ncomprising journalists, a political scientist, and data scientists. The chapter\ndelves into various aspects of political discourse analysis, including\nsentiment analysis, polarization, populism, topic detection, and Named Entities\nRecognition (NER). This experimental study investigates the capabilities of\nlarge language model (LLMs), and in particular OpenAI's ChatGPT, for analyzing\npolitical speech, evaluates its strengths and weaknesses, and highlights the\nessential role of human oversight in using AI in journalism projects and\npotentially other societal sectors. The project stands as an innovative example\nof human-AI collaboration (known also as \"hybrid intelligence\") within the\nrealm of digital humanities, offering valuable insights for future initiatives.\n","authors":["Thanasis Troboukis","Kelly Kiki","Antonis Galanopoulos","Pavlos Sermpezis","Stelios Karamanidis","Ilias Dimitriadis","Athena Vakali"],"pdf_url":"https://arxiv.org/pdf/2410.13400v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.13396v1","updated":"2024-10-17T09:48:08Z","published":"2024-10-17T09:48:08Z","title":"Linguistically Grounded Analysis of Language Models using Shapley Head\n  Values","summary":"  Understanding how linguistic knowledge is encoded in language models is\ncrucial for improving their generalisation capabilities. In this paper, we\ninvestigate the processing of morphosyntactic phenomena, by leveraging a\nrecently proposed method for probing language models via Shapley Head Values\n(SHVs). Using the English language BLiMP dataset, we test our approach on two\nwidely used models, BERT and RoBERTa, and compare how linguistic constructions\nsuch as anaphor agreement and filler-gap dependencies are handled. Through\nquantitative pruning and qualitative clustering analysis, we demonstrate that\nattention heads responsible for processing related linguistic phenomena cluster\ntogether. Our results show that SHV-based attributions reveal distinct patterns\nacross both models, providing insights into how language models organize and\nprocess linguistic information. These findings support the hypothesis that\nlanguage models learn subnetworks corresponding to linguistic theory, with\npotential implications for cross-linguistic model analysis and interpretability\nin Natural Language Processing (NLP).\n","authors":["Marcell Fekete","Johannes Bjerva"],"pdf_url":"https://arxiv.org/pdf/2410.13396v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.13394v1","updated":"2024-10-17T09:45:32Z","published":"2024-10-17T09:45:32Z","title":"Cross-Lingual Auto Evaluation for Assessing Multilingual LLMs","summary":"  Evaluating machine-generated text remains a significant challenge in NLP,\nespecially for non-English languages. Current methodologies, including\nautomated metrics, human assessments, and LLM-based evaluations, predominantly\nfocus on English, revealing a significant gap in multilingual evaluation\nframeworks. We introduce the Cross Lingual Auto Evaluation (CIA) Suite, an\nextensible framework that includes evaluator LLMs (Hercule) and a novel test\nset (Recon) specifically designed for multilingual evaluation. Our test set\nfeatures 500 human-annotated instructions spanning various task capabilities\nalong with human judgment scores across six languages. This would enable\nbenchmarking of general-purpose multilingual LLMs and facilitate\nmeta-evaluation of Evaluator LLMs. The proposed model, Hercule, is a\ncross-lingual evaluation model that addresses the scarcity of reference answers\nin the target language by learning to assign scores to responses based on\neasily available reference answers in English. Our experiments demonstrate that\nHercule aligns more closely with human judgments compared to proprietary\nmodels, demonstrating the effectiveness of such cross-lingual evaluation in low\nresource scenarios. Further, it is also effective in zero-shot evaluation on\nunseen languages. This study is the first comprehensive examination of\ncross-lingual evaluation using LLMs, presenting a scalable and effective\napproach for multilingual assessment. All code, datasets, and models will be\npublicly available to enable further research in this important area.\n","authors":["Sumanth Doddapaneni","Mohammed Safi Ur Rahman Khan","Dilip Venkatesh","Raj Dabre","Anoop Kunchukuttan","Mitesh M. Khapra"],"pdf_url":"https://arxiv.org/pdf/2410.13394v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.13392v1","updated":"2024-10-17T09:42:30Z","published":"2024-10-17T09:42:30Z","title":"Metacognitive Monitoring: A Human Ability Beyond Generative Artificial\n  Intelligence","summary":"  Large language models (LLMs) have shown impressive alignment with human\ncognitive processes, raising questions about the extent of their similarity to\nhuman cognition. This study investigates whether LLMs, specifically ChatGPT,\npossess metacognitive monitoring abilities akin to humans-particularly in\npredicting memory performance on an item-by-item basis. We employed a\ncross-agent prediction model to compare the metacognitive performance of humans\nand ChatGPT in a language-based memory task involving garden-path sentences\npreceded by either fitting or unfitting context sentences. Both humans and\nChatGPT rated the memorability of these sentences; humans then completed a\nsurprise recognition memory test. Our findings reveal a significant positive\nrelationship between humans' memorability ratings and their actual recognition\nperformance, indicating reliable metacognitive monitoring. In contrast, ChatGPT\ndid not exhibit a similar predictive capability. Bootstrapping analyses\ndemonstrated that none of the GPT models tested (GPT-3.5-turbo, GPT-4-turbo,\nGPT-4o) could accurately predict human memory performance on a per-item basis.\nThis suggests that, despite their advanced language processing abilities and\nalignment with human cognition at the object level, current LLMs lack the\nmetacognitive mechanisms that enable humans to anticipate their memory\nperformance. These results highlight a fundamental difference between human and\nAI cognition at the metacognitive level. Addressing this gap is crucial for\ndeveloping AI systems capable of effective self-monitoring and adaptation to\nhuman needs, thereby enhancing human-AI interactions across domains such as\neducation and personalized learning.\n","authors":["Markus Huff","Elanur Ulakçı"],"pdf_url":"https://arxiv.org/pdf/2410.13392v1.pdf","comment":"28 pages, 2 figures. arXiv admin note: substantial text overlap with\n  arXiv:2403.05152"},{"id":"http://arxiv.org/abs/2410.13385v1","updated":"2024-10-17T09:37:20Z","published":"2024-10-17T09:37:20Z","title":"On the Use of Audio to Improve Dialogue Policies","summary":"  With the significant progress of speech technologies, spoken goal-oriented\ndialogue systems are becoming increasingly popular. One of the main modules of\na dialogue system is typically the dialogue policy, which is responsible for\ndetermining system actions. This component usually relies only on audio\ntranscriptions, being strongly dependent on their quality and ignoring very\nimportant extralinguistic information embedded in the user's speech. In this\npaper, we propose new architectures to add audio information by combining\nspeech and text embeddings using a Double Multi-Head Attention component. Our\nexperiments show that audio embedding-aware dialogue policies outperform\ntext-based ones, particularly in noisy transcription scenarios, and that how\ntext and audio embeddings are combined is crucial to improve performance. We\nobtained a 9.8% relative improvement in the User Request Score compared to an\nonly-text-based dialogue system on the DSTC2 dataset.\n","authors":["Daniel Roncel","Federico Costa","Javier Hernando"],"pdf_url":"https://arxiv.org/pdf/2410.13385v1.pdf","comment":"IberSpeech 2024"},{"id":"http://arxiv.org/abs/2410.13360v1","updated":"2024-10-17T09:10:26Z","published":"2024-10-17T09:10:26Z","title":"Remember, Retrieve and Generate: Understanding Infinite Visual Concepts\n  as Your Personalized Assistant","summary":"  The development of large language models (LLMs) has significantly enhanced\nthe capabilities of multimodal LLMs (MLLMs) as general assistants. However,\nlack of user-specific knowledge still restricts their application in human's\ndaily life. In this paper, we introduce the Retrieval Augmented Personalization\n(RAP) framework for MLLMs' personalization. Starting from a general MLLM, we\nturn it into a personalized assistant in three steps. (a) Remember: We design a\nkey-value database to store user-related information, e.g., user's name, avatar\nand other attributes. (b) Retrieve: When the user initiates a conversation, RAP\nwill retrieve relevant information from the database using a multimodal\nretriever. (c) Generate: The input query and retrieved concepts' information\nare fed into MLLMs to generate personalized, knowledge-augmented responses.\nUnlike previous methods, RAP allows real-time concept editing via updating the\nexternal database. To further improve generation quality and alignment with\nuser-specific information, we design a pipeline for data collection and create\na specialized dataset for personalized training of MLLMs. Based on the dataset,\nwe train a series of MLLMs as personalized multimodal assistants. By\npretraining on large-scale dataset, RAP-MLLMs can generalize to infinite visual\nconcepts without additional finetuning. Our models demonstrate outstanding\nflexibility and generation quality across a variety of tasks, such as\npersonalized image captioning, question answering and visual recognition. The\ncode, data and models are available at https://github.com/Hoar012/RAP-MLLM.\n","authors":["Haoran Hao","Jiaming Han","Changsheng Li","Yu-Feng Li","Xiangyu Yue"],"pdf_url":"https://arxiv.org/pdf/2410.13360v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.13352v1","updated":"2024-10-17T09:03:38Z","published":"2024-10-17T09:03:38Z","title":"LAR-ECHR: A New Legal Argument Reasoning Task and Dataset for Cases of\n  the European Court of Human Rights","summary":"  We present Legal Argument Reasoning (LAR), a novel task designed to evaluate\nthe legal reasoning capabilities of Large Language Models (LLMs). The task\nrequires selecting the correct next statement (from multiple choice options) in\na chain of legal arguments from court proceedings, given the facts of the case.\nWe constructed a dataset (LAR-ECHR) for this task using cases from the European\nCourt of Human Rights (ECHR). We evaluated seven general-purpose LLMs on\nLAR-ECHR and found that (a) the ranking of the models is aligned with that of\nLegalBench, an established US-based legal reasoning benchmark, even though\nLAR-ECHR is based on EU law, (b) LAR-ECHR distinguishes top models more\nclearly, compared to LegalBench, (c) even the best model (GPT-4o) obtains 75.8%\naccuracy on LAR-ECHR, indicating significant potential for further model\nimprovement. The process followed to construct LAR-ECHR can be replicated with\ncases from other legal systems.\n","authors":["Odysseas S. Chlapanis","Dimitrios Galanis","Ion Androutsopoulos"],"pdf_url":"https://arxiv.org/pdf/2410.13352v1.pdf","comment":"Published in Natural Legal Language Processing (NLLP) 2024 workshop"},{"id":"http://arxiv.org/abs/2410.13351v1","updated":"2024-10-17T09:02:28Z","published":"2024-10-17T09:02:28Z","title":"Representation Learning of Structured Data for Medical Foundation Models","summary":"  Large Language Models (LLMs) have demonstrated remarkable performance across\nvarious domains, including healthcare. However, their ability to effectively\nrepresent structured non-textual data, such as the alphanumeric medical codes\nused in records like ICD-10 or SNOMED-CT, is limited and has been particularly\nexposed in recent research. This paper examines the challenges LLMs face in\nprocessing medical codes due to the shortcomings of current tokenization\nmethods. As a result, we introduce the UniStruct architecture to design a\nmultimodal medical foundation model of unstructured text and structured data,\nwhich addresses these challenges by adapting subword tokenization techniques\nspecifically for the structured medical codes. Our approach is validated\nthrough model pre-training on both an extensive internal medical database and a\npublic repository of structured medical records. Trained on over 1 billion\ntokens on the internal medical database, the proposed model achieves up to a\n23% improvement in evaluation metrics, with around 2% gain attributed to our\nproposed tokenization. Additionally, when evaluated on the EHRSHOT public\nbenchmark with a 1/1000 fraction of the pre-training data, the UniStruct model\nimproves performance on over 42% of the downstream tasks. Our approach not only\nenhances the representation and generalization capabilities of patient-centric\nmodels but also bridges a critical gap in representation learning models'\nability to handle complex structured medical data, alongside unstructured text.\n","authors":["Vijay Prakash Dwivedi","Viktor Schlegel","Andy T. Liu","Thanh-Tung Nguyen","Abhinav Ramesh Kashyap","Jeng Wei","Wei-Hsian Yin","Stefan Winkler","Robby T. Tan"],"pdf_url":"https://arxiv.org/pdf/2410.13351v1.pdf","comment":"NeurIPS 2024 Workshop on Unifying Representations in Neural Models\n  (UniReps 2024)"},{"id":"http://arxiv.org/abs/2404.11916v2","updated":"2024-10-17T09:01:27Z","published":"2024-04-18T05:43:50Z","title":"Skeleton: A New Framework for Accelerating Language Models via Task\n  Neuron Localized Prompt Tuning","summary":"  Prompt tuning methods have shown comparable performance to general training\nmethods as parameter-efficient fine-tuning (PEFT) methods in various natural\nlanguage understanding tasks. However, existing prompt tuning methods still\nutilize the entire model architecture even when solving a specific task, which\nprevents them from accelerating inference speed during the application\nprocedure. In this paper, we propose a novel prompt tuning framework called\nSkeleton to efficiently utilize a language model in terms of memory and time\ncomplexity for solving various tasks, retaining only task-relevant neurons by\nusing an explainability method. From our framework, we can efficiently solve\nvarious tasks by using only task-relevant neurons and prepending adequate\ntask-specific prompt tokens with only a single language model. Experiments\nreveal that our method significantly enhances inference efficiency (at most x\n1.73 speed up) for various widely used benchmarks, showing comparable\nperformance to the prompt tuning method. Moreover, our method is applicable\nacross various transformer-based architectures, confirming its practicality and\nscalability.\n","authors":["Nakyeong Yang","Jiwon Moon","Junseok Kim","Yunah Jang","Kyomin Jung"],"pdf_url":"https://arxiv.org/pdf/2404.11916v2.pdf","comment":"11 pages"},{"id":"http://arxiv.org/abs/2410.13344v1","updated":"2024-10-17T08:55:18Z","published":"2024-10-17T08:55:18Z","title":"Cerberus: Efficient Inference with Adaptive Parallel Decoding and\n  Sequential Knowledge Enhancement","summary":"  Large language models (LLMs) often face a bottleneck in inference speed due\nto their reliance on auto-regressive decoding. Recently, parallel decoding has\nshown significant promise in enhancing inference efficiency. However, we have\nidentified two key issues with existing parallel decoding frameworks: (1)\ndecoding heads fail to balance prediction accuracy and the parallelism of\nexecution, and (2) parallel decoding is not a universal solution, as it can\nbring unnecessary overheads at some challenging decoding steps. To address\nthese issues, we propose Cerberus, an adaptive parallel decoding framework\nintroduces the gating mechanism to enable the LLMs to adaptively choose\nappropriate decoding approaches at each decoding step, along with introducing a\nnew paradigm of decoding heads that introduce the sequential knowledge while\nmaintaining execution parallelism. The experiment results demonstrate that the\nCerberus can achieve up to 2.12x speed up compared to auto-regressive decoding,\nand outperforms one of the leading parallel decoding frameworks, Medusa, with a\n10% - 30% increase in acceleration and superior generation quality.\n","authors":["Yuxuan Liu","Wenyuan Li","Laizhong Cui","Hailiang Yang"],"pdf_url":"https://arxiv.org/pdf/2410.13344v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2404.07979v2","updated":"2024-10-17T08:54:37Z","published":"2024-04-11T17:57:22Z","title":"LLoCO: Learning Long Contexts Offline","summary":"  Processing long contexts remains a challenge for large language models (LLMs)\ndue to the quadratic computational and memory overhead of the self-attention\nmechanism and the substantial KV cache sizes during generation. We propose\nLLoCO, a novel approach to address this problem by learning contexts offline\nthrough context compression and in-domain parameter-efficient finetuning with\nLoRA. Our method enables an LLM to create a concise representation of the\noriginal context and efficiently retrieve relevant information to answer\nquestions accurately. Our approach extends the effective context window of a 4k\ntoken LLaMA2-7B model to handle up to 128k tokens. We evaluate our approach on\nseveral long-context question-answering datasets, demonstrating that LLoCO\nsignificantly outperforms in-context learning while using $30\\times$ fewer\ntokens during inference. LLoCO achieves up to $7.62\\times$ speed-up during\ninference and $11.52\\times$ higher throughput during finetuning, substantially\nreduces the cost of long document question answering. This makes it a promising\nsolution for efficient long context processing. Our code is publicly available\non https://github.com/jeffreysijuntan/lloco.\n","authors":["Sijun Tan","Xiuyu Li","Shishir Patil","Ziyang Wu","Tianjun Zhang","Kurt Keutzer","Joseph E. Gonzalez","Raluca Ada Popa"],"pdf_url":"https://arxiv.org/pdf/2404.07979v2.pdf","comment":"EMNLP 2024. The first two authors contributed equally to this work"},{"id":"http://arxiv.org/abs/2410.13343v1","updated":"2024-10-17T08:52:52Z","published":"2024-10-17T08:52:52Z","title":"Do LLMs Overcome Shortcut Learning? An Evaluation of Shortcut Challenges\n  in Large Language Models","summary":"  Large Language Models (LLMs) have shown remarkable capabilities in various\nnatural language processing tasks. However, LLMs may rely on dataset biases as\nshortcuts for prediction, which can significantly impair their robustness and\ngeneralization capabilities. This paper presents Shortcut Suite, a\ncomprehensive test suite designed to evaluate the impact of shortcuts on LLMs'\nperformance, incorporating six shortcut types, five evaluation metrics, and\nfour prompting strategies. Our extensive experiments yield several key\nfindings: 1) LLMs demonstrate varying reliance on shortcuts for downstream\ntasks, significantly impairing their performance. 2) Larger LLMs are more\nlikely to utilize shortcuts under zero-shot and few-shot in-context learning\nprompts. 3) Chain-of-thought prompting notably reduces shortcut reliance and\noutperforms other prompting strategies, while few-shot prompts generally\nunderperform compared to zero-shot prompts. 4) LLMs often exhibit\noverconfidence in their predictions, especially when dealing with datasets that\ncontain shortcuts. 5) LLMs generally have a lower explanation quality in\nshortcut-laden datasets, with errors falling into three types: distraction,\ndisguised comprehension, and logical fallacy. Our findings offer new insights\nfor evaluating robustness and generalization in LLMs and suggest potential\ndirections for mitigating the reliance on shortcuts. The code is available at\n\\url {https://github.com/yyhappier/ShortcutSuite.git}.\n","authors":["Yu Yuan","Lili Zhao","Kai Zhang","Guangting Zheng","Qi Liu"],"pdf_url":"https://arxiv.org/pdf/2410.13343v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.13339v1","updated":"2024-10-17T08:48:54Z","published":"2024-10-17T08:48:54Z","title":"Probing-RAG: Self-Probing to Guide Language Models in Selective Document\n  Retrieval","summary":"  Retrieval-Augmented Generation (RAG) enhances language models by retrieving\nand incorporating relevant external knowledge. However, traditional\nretrieve-and-generate processes may not be optimized for real-world scenarios,\nwhere queries might require multiple retrieval steps or none at all. In this\npaper, we propose a Probing-RAG, which utilizes the hidden state\nrepresentations from the intermediate layers of language models to adaptively\ndetermine the necessity of additional retrievals for a given query. By\nemploying a pre-trained prober, Probing-RAG effectively captures the model's\ninternal cognition, enabling reliable decision-making about retrieving external\ndocuments. Experimental results across five open-domain QA datasets demonstrate\nthat Probing-RAG outperforms previous methods while reducing the number of\nredundant retrieval steps.\n","authors":["Ingeol Baek","Hwan Chang","Byeongjeong Kim","Jimin Lee","Hwanhee Lee"],"pdf_url":"https://arxiv.org/pdf/2410.13339v1.pdf","comment":"6 figures, 13 tables"},{"id":"http://arxiv.org/abs/2410.13334v1","updated":"2024-10-17T08:46:09Z","published":"2024-10-17T08:46:09Z","title":"Do LLMs Have Political Correctness? Analyzing Ethical Biases and\n  Jailbreak Vulnerabilities in AI Systems","summary":"  Although large language models (LLMs) demonstrate impressive proficiency in\nvarious tasks, they present potential safety risks, such as `jailbreaks', where\nmalicious inputs can coerce LLMs into generating harmful content. To address\nthese issues, many LLM developers have implemented various safety measures to\nalign these models. This alignment involves several techniques, including data\nfiltering during pre-training, supervised fine-tuning, reinforcement learning\nfrom human feedback, and red-teaming exercises. These methods often introduce\ndeliberate and intentional biases similar to Political Correctness (PC) to\nensure the ethical behavior of LLMs. In this paper, we delve into the\nintentional biases injected into LLMs for safety purposes and examine methods\nto circumvent these safety alignment techniques. Notably, these intentional\nbiases result in a jailbreaking success rate in GPT-4o models that differs by\n20% between non-binary and cisgender keywords and by 16% between white and\nblack keywords, even when the other parts of the prompts are identical. We\nintroduce the concept of PCJailbreak, highlighting the inherent risks posed by\nthese safety-induced biases. Additionally, we propose an efficient defense\nmethod PCDefense, which prevents jailbreak attempts by injecting defense\nprompts prior to generation. PCDefense stands as an appealing alternative to\nGuard Models, such as Llama-Guard, that require additional inference cost after\ntext generation. Our findings emphasize the urgent need for LLM developers to\nadopt a more responsible approach when designing and implementing safety\nmeasures.\n","authors":["Isack Lee","Haebin Seong"],"pdf_url":"https://arxiv.org/pdf/2410.13334v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.13332v1","updated":"2024-10-17T08:45:02Z","published":"2024-10-17T08:45:02Z","title":"Fine-Tuning Language Models on Multiple Datasets for Citation Intention\n  Classification","summary":"  Citation intention Classification (CIC) tools classify citations by their\nintention (e.g., background, motivation) and assist readers in evaluating the\ncontribution of scientific literature. Prior research has shown that pretrained\nlanguage models (PLMs) such as SciBERT can achieve state-of-the-art performance\non CIC benchmarks. PLMs are trained via self-supervision tasks on a large\ncorpus of general text and can quickly adapt to CIC tasks via moderate\nfine-tuning on the corresponding dataset. Despite their advantages, PLMs can\neasily overfit small datasets during fine-tuning. In this paper, we propose a\nmulti-task learning (MTL) framework that jointly fine-tunes PLMs on a dataset\nof primary interest together with multiple auxiliary CIC datasets to take\nadvantage of additional supervision signals. We develop a data-driven task\nrelation learning (TRL) method that controls the contribution of auxiliary\ndatasets to avoid negative transfer and expensive hyper-parameter tuning. We\nconduct experiments on three CIC datasets and show that fine-tuning with\nadditional datasets can improve the PLMs' generalization performance on the\nprimary dataset. PLMs fine-tuned with our proposed framework outperform the\ncurrent state-of-the-art models by 7% to 11% on small datasets while aligning\nwith the best-performing model on a large dataset.\n","authors":["Zeren Shui","Petros Karypis","Daniel S. Karls","Mingjian Wen","Saurav Manchanda","Ellad B. Tadmor","George Karypis"],"pdf_url":"https://arxiv.org/pdf/2410.13332v1.pdf","comment":"To be appear as a Findings paper at EMNLP 2024"},{"id":"http://arxiv.org/abs/2410.02028v2","updated":"2024-10-17T08:31:32Z","published":"2024-10-02T20:48:28Z","title":"Are Large Language Models Good Classifiers? A Study on Edit Intent\n  Classification in Scientific Document Revisions","summary":"  Classification is a core NLP task architecture with many potential\napplications. While large language models (LLMs) have brought substantial\nadvancements in text generation, their potential for enhancing classification\ntasks remains underexplored. To address this gap, we propose a framework for\nthoroughly investigating fine-tuning LLMs for classification, including both\ngeneration- and encoding-based approaches. We instantiate this framework in\nedit intent classification (EIC), a challenging and underexplored\nclassification task. Our extensive experiments and systematic comparisons with\nvarious training approaches and a representative selection of LLMs yield new\ninsights into their application for EIC. We investigate the generalizability of\nthese findings on five further classification tasks. To demonstrate the\nproposed methods and address the data shortage for empirical edit analysis, we\nuse our best-performing EIC model to create Re3-Sci2.0, a new large-scale\ndataset of 1,780 scientific document revisions with over 94k labeled edits. The\nquality of the dataset is assessed through human evaluation. The new dataset\nenables an in-depth empirical study of human editing behavior in academic\nwriting. We make our experimental framework, models and data publicly\navailable.\n","authors":["Qian Ruan","Ilia Kuznetsov","Iryna Gurevych"],"pdf_url":"https://arxiv.org/pdf/2410.02028v2.pdf","comment":"EMNLP2024 Main"},{"id":"http://arxiv.org/abs/2410.13321v1","updated":"2024-10-17T08:24:27Z","published":"2024-10-17T08:24:27Z","title":"Mitigating Hallucinations in Large Vision-Language Models via\n  Summary-Guided Decoding","summary":"  Large Vision-Language Models (LVLMs) demonstrate impressive capabilities in\ngenerating detailed and coherent responses from visual inputs. However, they\nare prone to generate hallucinations due to an over-reliance on language\npriors. To address this issue, we investigate the language priors in LVLMs and\nmake two key observations: (1) Even when predicting the tokens associated with\nimage-related part-of-speech (POS), models increasingly rely on linguistic\npriors as the token sequences grow, thereby amplifying hallucinations. (2)\nMethods that directly calibrate LVLM's output distribution to mitigate language\npriors can lead to a degradation in text quality or even exacerbate\nhallucinations. Based on these findings, we propose a novel method,\nSummary-Guided Decoding (SGD). This method naturally encourages the model to\nfocus more on image information by reducing the text context through summaries,\nwhile controlling only the image-related POS tokens to maintain text quality.\nThrough experiments, we demonstrate that SGD achieves state-of-the-art\nperformance on object hallucination benchmarks. Furthermore, in terms of the\ntrade-off between precision and recall, SGD achieves Pareto optimality among\nthe existing methods. Lastly, we observe that although existing methods\nstruggle to balance the reduction of object hallucinations with maintaining\ntext quality, SGD demonstrates robustness in handling this challenge.\n","authors":["Kyungmin Min","Minbeom Kim","Kang-il Lee","Dongryeol Lee","Kyomin Jung"],"pdf_url":"https://arxiv.org/pdf/2410.13321v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.13318v1","updated":"2024-10-17T08:20:29Z","published":"2024-10-17T08:20:29Z","title":"Computational Approaches to Arabic-English Code-Switching","summary":"  Natural Language Processing (NLP) is a vital computational method for\naddressing language processing, analysis, and generation. NLP tasks form the\ncore of many daily applications, from automatic text correction to speech\nrecognition. While significant research has focused on NLP tasks for the\nEnglish language, less attention has been given to Modern Standard Arabic and\nDialectal Arabic. Globalization has also contributed to the rise of\nCode-Switching (CS), where speakers mix languages within conversations and even\nwithin individual words (intra-word CS). This is especially common in Arab\ncountries, where people often switch between dialects or between dialects and a\nforeign language they master. CS between Arabic and English is frequent in\nEgypt, especially on social media. Consequently, a significant amount of\ncode-switched content can be found online. Such code-switched data needs to be\ninvestigated and analyzed for several NLP tasks to tackle the challenges of\nthis multilingual phenomenon and Arabic language challenges. No work has been\ndone before for several integral NLP tasks on Arabic-English CS data. In this\nwork, we focus on the Named Entity Recognition (NER) task and other tasks that\nhelp propose a solution for the NER task on CS data, e.g., Language\nIdentification. This work addresses this gap by proposing and applying\nstate-of-the-art techniques for Modern Standard Arabic and Arabic-English NER.\nWe have created the first annotated CS Arabic-English corpus for the NER task.\nAlso, we apply two enhancement techniques to improve the NER tagger on CS data\nusing CS contextual embeddings and data augmentation techniques. All methods\nshowed improvements in the performance of the NER taggers on CS data. Finally,\nwe propose several intra-word language identification approaches to determine\nthe language type of a mixed text and identify whether it is a named entity or\nnot.\n","authors":["Caroline Sabty"],"pdf_url":"https://arxiv.org/pdf/2410.13318v1.pdf","comment":"PhD thesis"},{"id":"http://arxiv.org/abs/2403.12675v2","updated":"2024-10-17T08:14:21Z","published":"2024-03-19T12:21:20Z","title":"Pragmatic Competence Evaluation of Large Language Models for the Korean\n  Language","summary":"  Benchmarks play a significant role in the current evaluation of Large\nLanguage Models (LLMs), yet they often overlook the models' abilities to\ncapture the nuances of human language, primarily focusing on evaluating\nembedded knowledge and technical skills. To address this gap, our study\nevaluates how well LLMs understand context-dependent expressions from a\npragmatic standpoint, specifically in Korean. We use both Multiple-Choice\nQuestions (MCQs) for automatic evaluation and Open-Ended Questions (OEQs)\nassessed by human experts. Our results show that GPT-4 leads with scores of\n81.11 in MCQs and 85.69 in OEQs, closely followed by HyperCLOVA X.\nAdditionally, while few-shot learning generally improves performance,\nChain-of-Thought (CoT) prompting tends to encourage literal interpretations,\nwhich may limit effective pragmatic inference. Our findings highlight the need\nfor LLMs to better understand and generate language that reflects human\ncommunicative norms.\n","authors":["Dojun Park","Jiwoo Lee","Hyeyun Jeong","Seohyun Park","Sungeun Lee"],"pdf_url":"https://arxiv.org/pdf/2403.12675v2.pdf","comment":"38th Pacific Asia Conference on Language, Information and Computation"},{"id":"http://arxiv.org/abs/2410.13313v1","updated":"2024-10-17T08:10:24Z","published":"2024-10-17T08:10:24Z","title":"Mitigating Biases to Embrace Diversity: A Comprehensive Annotation\n  Benchmark for Toxic Language","summary":"  This study introduces a prescriptive annotation benchmark grounded in\nhumanities research to ensure consistent, unbiased labeling of offensive\nlanguage, particularly for casual and non-mainstream language uses. We\ncontribute two newly annotated datasets that achieve higher inter-annotator\nagreement between human and language model (LLM) annotations compared to\noriginal datasets based on descriptive instructions. Our experiments show that\nLLMs can serve as effective alternatives when professional annotators are\nunavailable. Moreover, smaller models fine-tuned on multi-source LLM-annotated\ndata outperform models trained on larger, single-source human-annotated\ndatasets. These findings highlight the value of structured guidelines in\nreducing subjective variability, maintaining performance with limited data, and\nembracing language diversity.\n  Content Warning: This article only analyzes offensive language for academic\npurposes. Discretion is advised.\n","authors":["Xinmeng Hou"],"pdf_url":"https://arxiv.org/pdf/2410.13313v1.pdf","comment":"12 pages, 9 figures, EMNLP-NLP4DH 2024"},{"id":"http://arxiv.org/abs/2406.12494v2","updated":"2024-10-17T08:09:37Z","published":"2024-06-18T10:57:27Z","title":"LightPAL: Lightweight Passage Retrieval for Open Domain Multi-Document\n  Summarization","summary":"  Open-Domain Multi-Document Summarization (ODMDS) is the task of generating\nsummaries from large document collections in response to user queries. This\ntask is crucial for efficiently addressing diverse information needs from\nusers. Traditional retrieve-then-summarize approaches fall short for open-ended\nqueries in ODMDS tasks. These queries often require broader context than\ninitially retrieved passages provide, making it challenging to retrieve all\nrelevant information in a single search. While iterative retrieval methods has\nbeen explored for multi-hop question answering (MQA), it's impractical for\nODMDS due to high latency from repeated LLM inference. Accordingly, we propose\nLightPAL, a lightweight passage retrieval method for ODMDS. LightPAL leverages\nan LLM to pre-construct a graph representing passage relationships, then\nemploys random walk during retrieval, avoiding iterative LLM inference.\nExperiments demonstrate that LightPAL outperforms naive sparse and pre-trained\ndense retrievers in both retrieval and summarization metrics, while achieving\nhigher efficiency compared to iterative MQA approaches.\n","authors":["Masafumi Enomoto","Kunihiro Takeoka","Kosuke Akimoto","Kiril Gashteovski","Masafumi Oyamada"],"pdf_url":"https://arxiv.org/pdf/2406.12494v2.pdf","comment":"15 pages, 7 figures, 6 tables"},{"id":"http://arxiv.org/abs/2410.13305v1","updated":"2024-10-17T08:05:02Z","published":"2024-10-17T08:05:02Z","title":"Reference-Based Post-OCR Processing with LLM for Diacritic Languages","summary":"  Extracting fine-grained OCR text from aged documents in diacritic languages\nremains challenging due to unexpected artifacts, time-induced degradation, and\nlack of datasets. While standalone spell correction approaches have been\nproposed, they show limited performance for historical documents due to\nnumerous possible OCR error combinations and differences between modern and\nclassical corpus distributions. We propose a method utilizing available\ncontent-focused ebooks as a reference base to correct imperfect OCR-generated\ntext, supported by large language models. This technique generates\nhigh-precision pseudo-page-to-page labels for diacritic languages, where small\nstrokes pose significant challenges in historical conditions. The pipeline\neliminates various types of noise from aged documents and addresses issues such\nas missing characters, words, and disordered sequences. Our post-processing\nmethod, which generated a large OCR dataset of classical Vietnamese books,\nachieved a mean grading score of 8.72 on a 10-point scale. This outperformed\nthe state-of-the-art transformer-based Vietnamese spell correction model, which\nscored 7.03 when evaluated on a sampled subset of the dataset. We also trained\na baseline OCR model to assess and compare it with well-known engines.\nExperimental results demonstrate the strength of our baseline model compared to\nwidely used open-source solutions. The resulting dataset will be released\npublicly to support future studies.\n","authors":["Thao Do"],"pdf_url":"https://arxiv.org/pdf/2410.13305v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.13298v1","updated":"2024-10-17T07:55:33Z","published":"2024-10-17T07:55:33Z","title":"Advancing Large Language Model Attribution through Self-Improving","summary":"  Teaching large language models (LLMs) to generate text with citations to\nevidence sources can mitigate hallucinations and enhance verifiability in\ninformation-seeking systems. However, improving this capability requires\nhigh-quality attribution data, which is costly and labor-intensive. Inspired by\nrecent advances in self-improvement that enhance LLMs without manual\nannotation, we present START, a Self-Taught AttRibuTion framework for\niteratively improving the attribution capability of LLMs. First, to prevent\nmodels from stagnating due to initially insufficient supervision signals, START\nleverages the model to self-construct synthetic training data for warming up.\nTo further self-improve the model's attribution ability, START iteratively\nutilizes fine-grained preference supervision signals constructed from its\nsampled responses to encourage robust, comprehensive, and attributable\ngeneration. Experiments on three open-domain question-answering datasets,\ncovering long-form QA and multi-step reasoning, demonstrate significant\nperformance gains of 25.13% on average without relying on human annotations and\nmore advanced models. Further analysis reveals that START excels in aggregating\ninformation across multiple sources.\n","authors":["Lei Huang","Xiaocheng Feng","Weitao Ma","Liang Zhao","Yuchun Fan","Weihong Zhong","Dongliang Xu","Qing Yang","Hongtao Liu","Bing Qin"],"pdf_url":"https://arxiv.org/pdf/2410.13298v1.pdf","comment":"Accepted by EMNLP 2024 Main Conference"},{"id":"http://arxiv.org/abs/2404.06666v3","updated":"2024-10-17T07:28:23Z","published":"2024-04-10T00:26:08Z","title":"SafeGen: Mitigating Sexually Explicit Content Generation in\n  Text-to-Image Models","summary":"  Text-to-image (T2I) models, such as Stable Diffusion, have exhibited\nremarkable performance in generating high-quality images from text descriptions\nin recent years. However, text-to-image models may be tricked into generating\nnot-safe-for-work (NSFW) content, particularly in sexually explicit scenarios.\nExisting countermeasures mostly focus on filtering inappropriate inputs and\noutputs, or suppressing improper text embeddings, which can block sexually\nexplicit content (e.g., naked) but may still be vulnerable to adversarial\nprompts -- inputs that appear innocent but are ill-intended. In this paper, we\npresent SafeGen, a framework to mitigate sexual content generation by\ntext-to-image models in a text-agnostic manner. The key idea is to eliminate\nexplicit visual representations from the model regardless of the text input. In\nthis way, the text-to-image model is resistant to adversarial prompts since\nsuch unsafe visual representations are obstructed from within. Extensive\nexperiments conducted on four datasets and large-scale user studies demonstrate\nSafeGen's effectiveness in mitigating sexually explicit content generation\nwhile preserving the high-fidelity of benign images. SafeGen outperforms eight\nstate-of-the-art baseline methods and achieves 99.4% sexual content removal\nperformance. Furthermore, our constructed benchmark of adversarial prompts\nprovides a basis for future development and evaluation of anti-NSFW-generation\nmethods.\n","authors":["Xinfeng Li","Yuchen Yang","Jiangyi Deng","Chen Yan","Yanjiao Chen","Xiaoyu Ji","Wenyuan Xu"],"pdf_url":"https://arxiv.org/pdf/2404.06666v3.pdf","comment":"Accepted by ACM CCS 2024. Please cite this paper as \"Xinfeng Li,\n  Yuchen Yang, Jiangyi Deng, Chen Yan, Yanjiao Chen, Xiaoyu Ji, Wenyuan Xu.\n  SafeGen: Mitigating Sexually Explicit Content Generation in Text-to-Image\n  Models. In Proceedings of ACM Conference on Computer and Communications\n  Security (CCS), 2024.\""},{"id":"http://arxiv.org/abs/2410.13284v1","updated":"2024-10-17T07:28:18Z","published":"2024-10-17T07:28:18Z","title":"Learning to Route with Confidence Tokens","summary":"  Large language models (LLMs) have demonstrated impressive performance on\nseveral tasks and are increasingly deployed in real-world applications.\nHowever, especially in high-stakes settings, it becomes vital to know when the\noutput of an LLM may be unreliable. Depending on whether an answer is\ntrustworthy, a system can then choose to route the question to another expert,\nor otherwise fall back on a safe default behavior. In this work, we study the\nextent to which LLMs can reliably indicate confidence in their answers, and how\nthis notion of confidence can translate into downstream accuracy gains. We\npropose Self-REF, a lightweight training strategy to teach LLMs to express\nconfidence in whether their answers are correct in a reliable manner. Self-REF\nintroduces confidence tokens into the LLM, from which a confidence score can be\nextracted. Compared to conventional approaches such as verbalizing confidence\nand examining token probabilities, we demonstrate empirically that confidence\ntokens show significant improvements in downstream routing and rejection\nlearning tasks.\n","authors":["Yu-Neng Chuang","Helen Zhou","Prathusha Kameswara Sarma","Parikshit Gopalan","John Boccio","Sara Bolouki","Xia Hu"],"pdf_url":"https://arxiv.org/pdf/2410.13284v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.14991v2","updated":"2024-10-17T07:23:23Z","published":"2024-06-21T09:06:45Z","title":"SpreadsheetBench: Towards Challenging Real World Spreadsheet\n  Manipulation","summary":"  We introduce SpreadsheetBench, a challenging spreadsheet manipulation\nbenchmark exclusively derived from real-world scenarios, designed to immerse\ncurrent large language models (LLMs) in the actual workflow of spreadsheet\nusers. Unlike existing benchmarks that rely on synthesized queries and\nsimplified spreadsheet files, SpreadsheetBench is built from 912 real questions\ngathered from online Excel forums, which reflect the intricate needs of users.\nThe associated spreadsheets from the forums contain a variety of tabular data\nsuch as multiple tables, non-standard relational tables, and abundant\nnon-textual elements. Furthermore, we propose a more reliable evaluation metric\nakin to online judge platforms, where multiple spreadsheet files are created as\ntest cases for each instruction, ensuring the evaluation of robust solutions\ncapable of handling spreadsheets with varying values. Our comprehensive\nevaluation of various LLMs under both single-round and multi-round inference\nsettings reveals a substantial gap between the state-of-the-art (SOTA) models\nand human performance, highlighting the benchmark's difficulty.\n","authors":["Zeyao Ma","Bohan Zhang","Jing Zhang","Jifan Yu","Xiaokang Zhang","Xiaohan Zhang","Sijia Luo","Xi Wang","Jie Tang"],"pdf_url":"https://arxiv.org/pdf/2406.14991v2.pdf","comment":"Neurips 2024 (Spotlight); Homepage:\n  https://spreadsheetbench.github.io/"},{"id":"http://arxiv.org/abs/2410.13281v1","updated":"2024-10-17T07:15:15Z","published":"2024-10-17T07:15:15Z","title":"BANTH: A Multi-label Hate Speech Detection Dataset for Transliterated\n  Bangla","summary":"  The proliferation of transliterated texts in digital spaces has emphasized\nthe need for detecting and classifying hate speech in languages beyond English,\nparticularly in low-resource languages. As online discourse can perpetuate\ndiscrimination based on target groups, e.g. gender, religion, and origin,\nmulti-label classification of hateful content can help in comprehending hate\nmotivation and enhance content moderation. While previous efforts have focused\non monolingual or binary hate classification tasks, no work has yet addressed\nthe challenge of multi-label hate speech classification in transliterated\nBangla. We introduce BanTH, the first multi-label transliterated Bangla hate\nspeech dataset comprising 37.3k samples. The samples are sourced from YouTube\ncomments, where each instance is labeled with one or more target groups,\nreflecting the regional demographic. We establish novel transformer\nencoder-based baselines by further pre-training on transliterated Bangla\ncorpus. We also propose a novel translation-based LLM prompting strategy for\ntransliterated text. Experiments reveal that our further pre-trained encoders\nare achieving state-of-the-art performance on the BanTH dataset, while our\ntranslation-based prompting outperforms other strategies in the zero-shot\nsetting. The introduction of BanTH not only fills a critical gap in hate speech\nresearch for Bangla but also sets the stage for future exploration into\ncode-mixed and multi-label classification challenges in underrepresented\nlanguages.\n","authors":["Fabiha Haider","Fariha Tanjim Shifat","Md Farhan Ishmam","Deeparghya Dutta Barua","Md Sakib Ul Rahman Sourove","Md Fahim","Md Farhad Alam"],"pdf_url":"https://arxiv.org/pdf/2410.13281v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.13276v1","updated":"2024-10-17T07:07:09Z","published":"2024-10-17T07:07:09Z","title":"SeerAttention: Learning Intrinsic Sparse Attention in Your LLMs","summary":"  Attention is the cornerstone of modern Large Language Models (LLMs). Yet its\nquadratic complexity limits the efficiency and scalability of LLMs, especially\nfor those with a long-context window. A promising approach addressing this\nlimitation is to leverage the sparsity in attention. However, existing\nsparsity-based solutions predominantly rely on predefined patterns or\nheuristics to approximate sparsity. This practice falls short to fully capture\nthe dynamic nature of attention sparsity in language-based tasks. This paper\nargues that attention sparsity should be learned rather than predefined. To\nthis end, we design SeerAttention, a new Attention mechanism that augments the\nconventional attention with a learnable gate that adaptively selects\nsignificant blocks in an attention map and deems the rest blocks sparse. Such\nblock-level sparsity effectively balances accuracy and speedup. To enable\nefficient learning of the gating network, we develop a customized\nFlashAttention implementation that extracts the block-level ground truth of\nattention map with minimum overhead. SeerAttention not only applies to\npost-training, but also excels in long-context fine-tuning. Our results show\nthat at post-training stages, SeerAttention significantly outperforms\nstate-of-the-art static or heuristic-based sparse attention methods, while also\nbeing more versatile and flexible to adapt to varying context lengths and\nsparsity ratios. When applied to long-context fine-tuning with YaRN,\nSeerAttention can achieve a remarkable 90% sparsity ratio at a 32k context\nlength with minimal perplexity loss, offering a 5.67x speedup over\nFlashAttention-2.\n","authors":["Yizhao Gao","Zhichen Zeng","Dayou Du","Shijie Cao","Hayden Kwok-Hay So","Ting Cao","Fan Yang","Mao Yang"],"pdf_url":"https://arxiv.org/pdf/2410.13276v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.13274v1","updated":"2024-10-17T07:00:15Z","published":"2024-10-17T07:00:15Z","title":"Breaking Chains: Unraveling the Links in Multi-Hop Knowledge Unlearning","summary":"  Large language models (LLMs) serve as giant information stores, often\nincluding personal or copyrighted data, and retraining them from scratch is not\na viable option. This has led to the development of various fast, approximate\nunlearning techniques to selectively remove knowledge from LLMs. Prior research\nhas largely focused on minimizing the probabilities of specific token sequences\nby reversing the language modeling objective. However, these methods still\nleave LLMs vulnerable to adversarial attacks that exploit indirect references.\nIn this work, we examine the limitations of current unlearning techniques in\neffectively erasing a particular type of indirect prompt: multi-hop queries.\nOur findings reveal that existing methods fail to completely remove multi-hop\nknowledge when one of the intermediate hops is unlearned. To address this\nissue, we propose MUNCH, a simple uncertainty-based approach that breaks down\nmulti-hop queries into subquestions and leverages the uncertainty of the\nunlearned model in final decision-making. Empirical results demonstrate the\neffectiveness of our framework, and MUNCH can be easily integrated with\nexisting unlearning techniques, making it a flexible and useful solution for\nenhancing unlearning processes.\n","authors":["Minseok Choi","ChaeHun Park","Dohyun Lee","Jaegul Choo"],"pdf_url":"https://arxiv.org/pdf/2410.13274v1.pdf","comment":"16 pages, 5 figures"},{"id":"http://arxiv.org/abs/2410.13268v1","updated":"2024-10-17T06:44:06Z","published":"2024-10-17T06:44:06Z","title":"Roadmap towards Superhuman Speech Understanding using Large Language\n  Models","summary":"  The success of large language models (LLMs) has prompted efforts to integrate\nspeech and audio data, aiming to create general foundation models capable of\nprocessing both textual and non-textual inputs. Recent advances, such as\nGPT-4o, highlight the potential for end-to-end speech LLMs, which preserves\nnon-semantic information and world knowledge for deeper speech understanding.\nTo guide the development of speech LLMs, we propose a five-level roadmap,\nranging from basic automatic speech recognition (ASR) to advanced superhuman\nmodels capable of integrating non-semantic information with abstract acoustic\nknowledge for complex tasks. Moreover, we design a benchmark, SAGI Bechmark,\nthat standardizes critical aspects across various tasks in these five levels,\nuncovering challenges in using abstract acoustic knowledge and completeness of\ncapability. Our findings reveal gaps in handling paralinguistic cues and\nabstract acoustic knowledge, and we offer future directions. This paper\noutlines a roadmap for advancing speech LLMs, introduces a benchmark for\nevaluation, and provides key insights into their current limitations and\npotential.\n","authors":["Fan Bu","Yuhao Zhang","Xidong Wang","Benyou Wang","Qun Liu","Haizhou Li"],"pdf_url":"https://arxiv.org/pdf/2410.13268v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.13267v1","updated":"2024-10-17T06:43:54Z","published":"2024-10-17T06:43:54Z","title":"CLaMP 2: Multimodal Music Information Retrieval Across 101 Languages\n  Using Large Language Models","summary":"  Challenges in managing linguistic diversity and integrating various musical\nmodalities are faced by current music information retrieval systems. These\nlimitations reduce their effectiveness in a global, multimodal music\nenvironment. To address these issues, we introduce CLaMP 2, a system compatible\nwith 101 languages that supports both ABC notation (a text-based musical\nnotation format) and MIDI (Musical Instrument Digital Interface) for music\ninformation retrieval. CLaMP 2, pre-trained on 1.5 million ABC-MIDI-text\ntriplets, includes a multilingual text encoder and a multimodal music encoder\naligned via contrastive learning. By leveraging large language models, we\nobtain refined and consistent multilingual descriptions at scale, significantly\nreducing textual noise and balancing language distribution. Our experiments\nshow that CLaMP 2 achieves state-of-the-art results in both multilingual\nsemantic search and music classification across modalities, thus establishing a\nnew standard for inclusive and global music information retrieval.\n","authors":["Shangda Wu","Yashan Wang","Ruibin Yuan","Zhancheng Guo","Xu Tan","Ge Zhang","Monan Zhou","Jing Chen","Xuefeng Mu","Yuejie Gao","Yuanliang Dong","Jiafeng Liu","Xiaobing Li","Feng Yu","Maosong Sun"],"pdf_url":"https://arxiv.org/pdf/2410.13267v1.pdf","comment":"17 pages, 10 figures, 4 tables"},{"id":"http://arxiv.org/abs/2409.14065v2","updated":"2024-10-17T06:37:44Z","published":"2024-09-21T08:41:08Z","title":"Temporally Consistent Factuality Probing for Large Language Models","summary":"  The prolific use of Large Language Models (LLMs) as an alternate knowledge\nbase requires them to be factually consistent, necessitating both correctness\nand consistency traits for paraphrased queries. Recently, significant attempts\nhave been made to benchmark datasets and metrics to evaluate LLMs for these\ntraits. However, structural simplicity (subject-relation-object) and\ncontemporary association in their query formulation limit the broader\ndefinition of factuality and consistency. In this study, we introduce TeCFaP, a\nnovel Temporally Consistent Factuality Probe task to expand the consistent\nfactuality probe in the temporal dimension. To this end, we propose TEMP-COFAC,\na high-quality dataset of prefix-style English query paraphrases. Subsequently,\nwe extend the definitions of existing metrics to represent consistent\nfactuality across temporal dimension. We experiment with a diverse set of LLMs\nand find most of them performing poorly on TeCFaP. Next, we propose a novel\nsolution CoTSeLF (Consistent-Time-Sensitive Learning Framework) combining\nmulti-task instruction tuning (MT-IT) with consistent-time-sensitive\nreinforcement learning (CTSRL) to improve temporally consistent factuality in\nLLMs. Our experiments demonstrate the efficacy of CoTSeLF over several\nbaselines.\n","authors":["Ashutosh Bajpai","Aaryan Goyal","Atif Anwer","Tanmoy Chakraborty"],"pdf_url":"https://arxiv.org/pdf/2409.14065v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2304.03087v2","updated":"2024-10-17T06:35:00Z","published":"2023-04-06T14:12:02Z","title":"Investigating Chain-of-thought with ChatGPT for Stance Detection on\n  Social Media","summary":"  Stance detection predicts attitudes towards targets in texts and has gained\nattention with the rise of social media. Traditional approaches include\nconventional machine learning, early deep neural networks, and pre-trained\nfine-tuning models. However, with the evolution of very large pre-trained\nlanguage models (VLPLMs) like ChatGPT (GPT-3.5), traditional methods face\ndeployment challenges. The parameter-free Chain-of-Thought (CoT) approach, not\nrequiring backpropagation training, has emerged as a promising alternative.\nThis paper examines CoT's effectiveness in stance detection tasks,\ndemonstrating its superior accuracy and discussing associated challenges.\n","authors":["Bowen Zhang","Xianghua Fu","Daijun Ding","Hu Huang","Genan Dai","Nan Yin","Yangyang Li","Liwen Jing"],"pdf_url":"https://arxiv.org/pdf/2304.03087v2.pdf","comment":"arXiv admin note: text overlap with arXiv:2212.14548"},{"id":"http://arxiv.org/abs/2410.13259v1","updated":"2024-10-17T06:31:49Z","published":"2024-10-17T06:31:49Z","title":"From Babbling to Fluency: Evaluating the Evolution of Language Models in\n  Terms of Human Language Acquisition","summary":"  We examine the language capabilities of language models (LMs) from the\ncritical perspective of human language acquisition. Building on classical\nlanguage development theories, we propose a three-stage framework to assess the\nabilities of LMs, ranging from preliminary word understanding to complex\ngrammar and complex logical reasoning. Using this framework, we evaluate the\ngenerative capacities of LMs using methods from linguistic research. Results\nindicate that although recent LMs outperform earlier models in overall\nperformance, their developmental trajectory does not strictly follow the path\nof human language acquisition. Notably, in generation tasks, LMs are more\nsimilar to human performance in areas where information is easier to extract\nfrom the corpus, such as average word length, clauses, and auxiliary verbs.\nNewer LMs did not exhibit significant progress in terms of specific dimensions,\nsuch as clauses and auxiliary verbs, where the variation across corpora is\nrelatively limited. Register theory offers a plausible explanation for these\nobservations, suggesting that the linguistic features of the training data have\na substantial impact on the models' abilities.\n","authors":["Qiyuan Yang","Pengda Wang","Luke D. Plonsky","Frederick L. Oswald","Hanjie Chen"],"pdf_url":"https://arxiv.org/pdf/2410.13259v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.13258v1","updated":"2024-10-17T06:30:55Z","published":"2024-10-17T06:30:55Z","title":"A Systematic Investigation of Knowledge Retrieval and Selection for\n  Retrieval Augmented Generation","summary":"  Retrieval-augmented generation (RAG) has emerged as a powerful method for\nenhancing natural language generation by integrating external knowledge into a\nmodel's output. While prior work has demonstrated the importance of improving\nknowledge retrieval for boosting generation quality, the role of knowledge\nselection remains less clear. In this paper, we perform a comprehensive\nanalysis of how knowledge retrieval and selection influence downstream\ngeneration performance in RAG systems. By simulating different retrieval and\nselection conditions through a controlled mixture of gold and distractor\nknowledge, we assess the impact of these factors on generation outcomes. Our\nfindings indicate that the downstream generator model's capability, as well as\nthe complexity of the task and dataset, significantly influence the impact of\nknowledge retrieval and selection on the overall RAG system performance. In\ntypical scenarios, improving the knowledge recall score is key to enhancing\ngeneration outcomes, with the knowledge selector providing a limited additional\nbenefit when a strong generator model is used on clear, well-defined tasks. For\nweaker generator models or more ambiguous tasks and datasets, the knowledge F1\nscore becomes a critical factor, and the knowledge selector plays a more\nprominent role in improving overall performance.\n","authors":["Xiangci Li","Jessica Ouyang"],"pdf_url":"https://arxiv.org/pdf/2410.13258v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.13255v1","updated":"2024-10-17T06:21:38Z","published":"2024-10-17T06:21:38Z","title":"Automatic Translation Alignment Pipeline for Multilingual Digital\n  Editions of Literary Works","summary":"  This paper investigates the application of translation alignment algorithms\nin the creation of a Multilingual Digital Edition (MDE) of Alessandro Manzoni's\nItalian novel \"I promessi sposi\" (\"The Betrothed\"), with translations in eight\nlanguages (English, Spanish, French, German, Dutch, Polish, Russian and\nChinese) from the 19th and 20th centuries. We identify key requirements for the\nMDE to improve both the reader experience and support for translation studies.\nOur research highlights the limitations of current state-of-the-art algorithms\nwhen applied to the translation of literary texts and outlines an automated\npipeline for MDE creation. This pipeline transforms raw texts into web-based,\nside-by-side representations of original and translated texts with different\nrendering options. In addition, we propose new metrics for evaluating the\nalignment of literary translations and suggest visualization techniques for\nfuture analysis.\n","authors":["Maria Levchenko"],"pdf_url":"https://arxiv.org/pdf/2410.13255v1.pdf","comment":"18 pages, Computational Humanities Research Conference, December 4-6,\n  2024, Aarhus, Denmark"},{"id":"http://arxiv.org/abs/2410.13248v1","updated":"2024-10-17T06:15:00Z","published":"2024-10-17T06:15:00Z","title":"Disentangling Likes and Dislikes in Personalized Generative Explainable\n  Recommendation","summary":"  Recent research on explainable recommendation generally frames the task as a\nstandard text generation problem, and evaluates models simply based on the\ntextual similarity between the predicted and ground-truth explanations.\nHowever, this approach fails to consider one crucial aspect of the systems:\nwhether their outputs accurately reflect the users' (post-purchase) sentiments,\ni.e., whether and why they would like and/or dislike the recommended items. To\nshed light on this issue, we introduce new datasets and evaluation methods that\nfocus on the users' sentiments. Specifically, we construct the datasets by\nexplicitly extracting users' positive and negative opinions from their\npost-purchase reviews using an LLM, and propose to evaluate systems based on\nwhether the generated explanations 1) align well with the users' sentiments,\nand 2) accurately identify both positive and negative opinions of users on the\ntarget items. We benchmark several recent models on our datasets and\ndemonstrate that achieving strong performance on existing metrics does not\nensure that the generated explanations align well with the users' sentiments.\nLastly, we find that existing models can provide more sentiment-aware\nexplanations when the users' (predicted) ratings for the target items are\ndirectly fed into the models as input. We will release our code and datasets\nupon acceptance.\n","authors":["Ryotaro Shimizu","Takashi Wada","Yu Wang","Johannes Kruse","Sean O'Brien","Sai HtaungKham","Linxin Song","Yuya Yoshikawa","Yuki Saito","Fugee Tsung","Masayuki Goto","Julian McAuley"],"pdf_url":"https://arxiv.org/pdf/2410.13248v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.13246v1","updated":"2024-10-17T06:09:26Z","published":"2024-10-17T06:09:26Z","title":"Atomic Calibration of LLMs in Long-Form Generations","summary":"  Large language models (LLMs) often suffer from hallucinations, posing\nsignificant challenges for real-world applications. Confidence calibration,\nwhich estimates the underlying uncertainty of model predictions, is essential\nto enhance the LLMs' trustworthiness. Existing research on LLM calibration has\nprimarily focused on short-form tasks, providing a single confidence score at\nthe response level (macro calibration). However, this approach is insufficient\nfor long-form generations, where responses often contain more complex\nstatements and may include both accurate and inaccurate information. Therefore,\nwe introduce atomic calibration, a novel approach that evaluates factuality\ncalibration at a fine-grained level by breaking down long responses into atomic\nclaims. We classify confidence elicitation methods into discriminative and\ngenerative types and demonstrate that their combination can enhance\ncalibration. Our extensive experiments on various LLMs and datasets show that\natomic calibration is well-suited for long-form generation and can also improve\nmacro calibration results. Additionally, atomic calibration reveals insightful\npatterns in LLM confidence throughout the generation process.\n","authors":["Caiqi Zhang","Ruihan Yang","Zhisong Zhang","Xinting Huang","Sen Yang","Dong Yu","Nigel Collier"],"pdf_url":"https://arxiv.org/pdf/2410.13246v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.17484v3","updated":"2024-10-17T06:04:54Z","published":"2024-06-25T12:05:56Z","title":"MedCare: Advancing Medical LLMs through Decoupling Clinical Alignment\n  and Knowledge Aggregation","summary":"  Large language models (LLMs) have shown substantial progress in natural\nlanguage understanding and generation, proving valuable especially in the\nmedical field. Despite advancements, challenges persist due to the complexity\nand diversity inherent in medical tasks, which can be categorized as\nknowledge-intensive tasks and alignment-required tasks. Previous approaches\neither ignore the latter task or focus on a minority of tasks and hence lose\ngeneralization. To address these drawbacks, we propose a progressive\nfine-tuning pipeline. This pipeline employs a Knowledge Aggregator and a Noise\naggregator to encode diverse knowledge in the first stage and filter out\ndetrimental information. In the second stage, we drop the Noise Aggregator to\navoid the interference of suboptimal representation and leverage an additional\nalignment module optimized towards an orthogonal direction to the knowledge\nspace to mitigate knowledge forgetting. Based on this two-stage paradigm, we\nproposed a Medical LLM through decoupling Clinical Alignment and Knowledge\nAggregation (MedCare), which is designed to achieve state-of-the-art (SOTA)\nperformance on over 20 medical tasks, as well as SOTA results on specific\nmedical alignment tasks. Various model sizes of MedCare (1.8B, 7B, 14B) all\ndemonstrate significant improvements over existing models with similar model\nsizes.\n","authors":["Yusheng Liao","Shuyang Jiang","Zhe Chen","Yanfeng Wang","Yu Wang"],"pdf_url":"https://arxiv.org/pdf/2406.17484v3.pdf","comment":"EMNLP2024 Findings"},{"id":"http://arxiv.org/abs/2410.13237v1","updated":"2024-10-17T05:43:30Z","published":"2024-10-17T05:43:30Z","title":"Large Language Models are Easily Confused: A Quantitative Metric,\n  Security Implications and Typological Analysis","summary":"  Language Confusion is a phenomenon where Large Language Models (LLMs)\ngenerate text that is neither in the desired language, nor in a contextually\nappropriate language. This phenomenon presents a critical challenge in text\ngeneration by LLMs, often appearing as erratic and unpredictable behavior. We\nhypothesize that there are linguistic regularities to this inherent\nvulnerability in LLMs and shed light on patterns of language confusion across\nLLMs. We introduce a novel metric, Language Confusion Entropy, designed to\ndirectly measure and quantify this confusion, based on language distributions\ninformed by linguistic typology and lexical variation. Comprehensive\ncomparisons with the Language Confusion Benchmark (Marchisio et al., 2024)\nconfirm the effectiveness of our metric, revealing patterns of language\nconfusion across LLMs. We further link language confusion to LLM security, and\nfind patterns in the case of multilingual embedding inversion attacks. Our\nanalysis demonstrates that linguistic typology offers theoretically grounded\ninterpretation, and valuable insights into leveraging language similarities as\na prior for LLM alignment and security.\n","authors":["Yiyi Chen","Qiongxiu Li","Russa Biswas","Johannes Bjerva"],"pdf_url":"https://arxiv.org/pdf/2410.13237v1.pdf","comment":"17 pages, 6 figures, 14 tables"},{"id":"http://arxiv.org/abs/2410.13236v1","updated":"2024-10-17T05:40:54Z","published":"2024-10-17T05:40:54Z","title":"SPIN: Self-Supervised Prompt INjection","summary":"  Large Language Models (LLMs) are increasingly used in a variety of important\napplications, yet their safety and reliability remain as major concerns.\nVarious adversarial and jailbreak attacks have been proposed to bypass the\nsafety alignment and cause the model to produce harmful responses. We introduce\nSelf-supervised Prompt INjection (SPIN) which can detect and reverse these\nvarious attacks on LLMs. As our self-supervised prompt defense is done at\ninference-time, it is also compatible with existing alignment and adds an\nadditional layer of safety for defense. Our benchmarks demonstrate that our\nsystem can reduce the attack success rate by up to 87.9%, while maintaining the\nperformance on benign user requests. In addition, we discuss the situation of\nan adaptive attacker and show that our method is still resilient against\nattackers who are aware of our defense.\n","authors":["Leon Zhou","Junfeng Yang","Chengzhi Mao"],"pdf_url":"https://arxiv.org/pdf/2410.13236v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.13232v1","updated":"2024-10-17T05:37:00Z","published":"2024-10-17T05:37:00Z","title":"Web Agents with World Models: Learning and Leveraging Environment\n  Dynamics in Web Navigation","summary":"  Large language models (LLMs) have recently gained much attention in building\nautonomous agents. However, the performance of current LLM-based web agents in\nlong-horizon tasks is far from optimal, often yielding errors such as\nrepeatedly buying a non-refundable flight ticket. By contrast, humans can avoid\nsuch an irreversible mistake, as we have an awareness of the potential outcomes\n(e.g., losing money) of our actions, also known as the \"world model\". Motivated\nby this, our study first starts with preliminary analyses, confirming the\nabsence of world models in current LLMs (e.g., GPT-4o, Claude-3.5-Sonnet,\netc.). Then, we present a World-model-augmented (WMA) web agent, which\nsimulates the outcomes of its actions for better decision-making. To overcome\nthe challenges in training LLMs as world models predicting next observations,\nsuch as repeated elements across observations and long HTML inputs, we propose\na transition-focused observation abstraction, where the prediction objectives\nare free-form natural language descriptions exclusively highlighting important\nstate differences between time steps. Experiments on WebArena and Mind2Web show\nthat our world models improve agents' policy selection without training and\ndemonstrate our agents' cost- and time-efficiency compared to recent\ntree-search-based agents.\n","authors":["Hyungjoo Chae","Namyoung Kim","Kai Tzu-iunn Ong","Minju Gwak","Gwanwoo Song","Jihoon Kim","Sunghwan Kim","Dongha Lee","Jinyoung Yeo"],"pdf_url":"https://arxiv.org/pdf/2410.13232v1.pdf","comment":"Work in progress"},{"id":"http://arxiv.org/abs/2406.19764v2","updated":"2024-10-17T05:28:24Z","published":"2024-06-28T09:09:36Z","title":"Belief Revision: The Adaptability of Large Language Models Reasoning","summary":"  The capability to reason from text is crucial for real-world NLP\napplications. Real-world scenarios often involve incomplete or evolving data.\nIn response, individuals update their beliefs and understandings accordingly.\nHowever, most existing evaluations assume that language models (LMs) operate\nwith consistent information. We introduce Belief-R, a new dataset designed to\ntest LMs' belief revision ability when presented with new evidence. Inspired by\nhow humans suppress prior inferences, this task assesses LMs within the newly\nproposed delta reasoning ($\\Delta R$) framework. Belief-R features sequences of\npremises designed to simulate scenarios where additional information could\nnecessitate prior conclusions drawn by LMs. We evaluate $\\sim$30 LMs across\ndiverse prompting strategies and found that LMs generally struggle to\nappropriately revise their beliefs in response to new information. Further,\nmodels adept at updating often underperformed in scenarios without necessary\nupdates, highlighting a critical trade-off. These insights underscore the\nimportance of improving LMs' adaptiveness to changing information, a step\ntoward more reliable AI systems.\n","authors":["Bryan Wilie","Samuel Cahyawijaya","Etsuko Ishii","Junxian He","Pascale Fung"],"pdf_url":"https://arxiv.org/pdf/2406.19764v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2404.12897v3","updated":"2024-10-17T05:21:24Z","published":"2024-04-19T14:05:03Z","title":"Enabling Natural Zero-Shot Prompting on Encoder Models via\n  Statement-Tuning","summary":"  While Large Language Models (LLMs) exhibit remarkable capabilities in\nzero-shot and few-shot scenarios, they often require computationally\nprohibitive sizes. Conversely, smaller Masked Language Models (MLMs) like BERT\nand RoBERTa achieve state-of-the-art results through fine-tuning but struggle\nwith extending to few-shot and zero-shot settings due to their architectural\nconstraints. Hence, we propose Statement-Tuning, a technique that models\ndiscriminative tasks as a set of finite statements and trains an encoder model\nto discriminate between the potential statements to determine the label. We do\nStatement-Tuning on multiple tasks to enable cross-task generalization.\nExperimental results demonstrate that Statement-Tuning achieves competitive\nperformance compared to state-of-the-art LLMs with significantly fewer\nparameters. Moreover, the study investigates the impact of several design\nchoices on few-shot and zero-shot generalization, revealing that\nStatement-Tuning can achieve strong performance with modest training data and\nbenefits from task and statement diversity for unseen task generalizability.\n","authors":["Ahmed Elshabrawy","Yongxin Huang","Iryna Gurevych","Alham Fikri Aji"],"pdf_url":"https://arxiv.org/pdf/2404.12897v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.13224v1","updated":"2024-10-17T05:10:12Z","published":"2024-10-17T05:10:12Z","title":"Proof Flow: Preliminary Study on Generative Flow Network Language Model\n  Tuning for Formal Reasoning","summary":"  Reasoning is a fundamental substrate for solving novel and complex problems.\nDeliberate efforts in learning and developing frameworks around System 2\nreasoning have made great strides, yet problems of sufficient complexity remain\nlargely out of reach for open models. To address this gap, we examine the\npotential of Generative Flow Networks as a fine-tuning method for LLMs to\nunlock advanced reasoning capabilities. In this paper, we present a proof of\nconcept in the domain of formal reasoning, specifically in the Neural Theorem\nProving (NTP) setting, where proofs specified in a formal language such as Lean\ncan be deterministically and objectively verified. Unlike classical\nreward-maximization reinforcement learning, which frequently over-exploits\nhigh-reward actions and fails to effectively explore the state space, GFlowNets\nhave emerged as a promising approach for sampling compositional objects,\nimproving generalization, and enabling models to maintain diverse hypotheses.\nOur early results demonstrate GFlowNet fine-tuning's potential for enhancing\nmodel performance in a search setting, which is especially relevant given the\nparadigm shift towards inference time compute scaling and \"thinking slowly.\"\n","authors":["Matthew Ho","Vincent Zhu","Xiaoyin Chen","Moksh Jain","Nikolay Malkin","Edwin Zhang"],"pdf_url":"https://arxiv.org/pdf/2410.13224v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.13218v1","updated":"2024-10-17T04:52:57Z","published":"2024-10-17T04:52:57Z","title":"CBT-Bench: Evaluating Large Language Models on Assisting Cognitive\n  Behavior Therapy","summary":"  There is a significant gap between patient needs and available mental health\nsupport today. In this paper, we aim to thoroughly examine the potential of\nusing Large Language Models (LLMs) to assist professional psychotherapy. To\nthis end, we propose a new benchmark, CBT-BENCH, for the systematic evaluation\nof cognitive behavioral therapy (CBT) assistance. We include three levels of\ntasks in CBT-BENCH: I: Basic CBT knowledge acquisition, with the task of\nmultiple-choice questions; II: Cognitive model understanding, with the tasks of\ncognitive distortion classification, primary core belief classification, and\nfine-grained core belief classification; III: Therapeutic response generation,\nwith the task of generating responses to patient speech in CBT therapy\nsessions. These tasks encompass key aspects of CBT that could potentially be\nenhanced through AI assistance, while also outlining a hierarchy of capability\nrequirements, ranging from basic knowledge recitation to engaging in real\ntherapeutic conversations. We evaluated representative LLMs on our benchmark.\nExperimental results indicate that while LLMs perform well in reciting CBT\nknowledge, they fall short in complex real-world scenarios requiring deep\nanalysis of patients' cognitive structures and generating effective responses,\nsuggesting potential future work.\n","authors":["Mian Zhang","Xianjun Yang","Xinlu Zhang","Travis Labrum","Jamie C. Chiu","Shaun M. Eack","Fei Fang","William Yang Wang","Zhiyu Zoey Chen"],"pdf_url":"https://arxiv.org/pdf/2410.13218v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2409.00138v2","updated":"2024-10-17T04:43:40Z","published":"2024-08-29T17:58:38Z","title":"PrivacyLens: Evaluating Privacy Norm Awareness of Language Models in\n  Action","summary":"  As language models (LMs) are widely utilized in personalized communication\nscenarios (e.g., sending emails, writing social media posts) and endowed with a\ncertain level of agency, ensuring they act in accordance with the contextual\nprivacy norms becomes increasingly critical. However, quantifying the privacy\nnorm awareness of LMs and the emerging privacy risk in LM-mediated\ncommunication is challenging due to (1) the contextual and long-tailed nature\nof privacy-sensitive cases, and (2) the lack of evaluation approaches that\ncapture realistic application scenarios. To address these challenges, we\npropose PrivacyLens, a novel framework designed to extend privacy-sensitive\nseeds into expressive vignettes and further into agent trajectories, enabling\nmulti-level evaluation of privacy leakage in LM agents' actions. We instantiate\nPrivacyLens with a collection of privacy norms grounded in privacy literature\nand crowdsourced seeds. Using this dataset, we reveal a discrepancy between LM\nperformance in answering probing questions and their actual behavior when\nexecuting user instructions in an agent setup. State-of-the-art LMs, like GPT-4\nand Llama-3-70B, leak sensitive information in 25.68% and 38.69% of cases, even\nwhen prompted with privacy-enhancing instructions. We also demonstrate the\ndynamic nature of PrivacyLens by extending each seed into multiple trajectories\nto red-team LM privacy leakage risk. Dataset and code are available at\nhttps://github.com/SALT-NLP/PrivacyLens.\n","authors":["Yijia Shao","Tianshi Li","Weiyan Shi","Yanchen Liu","Diyi Yang"],"pdf_url":"https://arxiv.org/pdf/2409.00138v2.pdf","comment":"NeurIPS 2024 Datasets and Benchmarks Track"},{"id":"http://arxiv.org/abs/2410.13216v1","updated":"2024-10-17T04:42:48Z","published":"2024-10-17T04:42:48Z","title":"Anchored Alignment for Self-Explanations Enhancement","summary":"  In this work, we introduce a methodology for alignment designed to enhance\nthe ability of large language models (LLMs) to articulate their reasoning\n(self-explanation) even in the absence of annotated rationale explanations. Our\nalignment methodology comprises three key components: explanation quality\nassessment, self-instruction dataset generation, and model alignment.\nAdditionally, we present a novel technique called Alignment with Anchor\nPreference Pairs, which improves the selection of preference pairs by\ncategorizing model outputs into three groups: consistently correct,\nconsistently incorrect, and variable. By applying tailored strategies to each\ncategory, we enhance the effectiveness of Direct Preference Optimization (DPO).\nOur experimental results demonstrate that this approach significantly improves\nexplanation quality while maintaining accuracy compared to other fine-tuning\nstrategies.\n","authors":["Luis Felipe Villa-Arenas","Ata Nizamoglu","Qianli Wang","Sebastian Möller","Vera Schmitt"],"pdf_url":"https://arxiv.org/pdf/2410.13216v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.13210v1","updated":"2024-10-17T04:30:46Z","published":"2024-10-17T04:30:46Z","title":"FaithBench: A Diverse Hallucination Benchmark for Summarization by\n  Modern LLMs","summary":"  Summarization is one of the most common tasks performed by large language\nmodels (LLMs), especially in applications like Retrieval-Augmented Generation\n(RAG). However, existing evaluations of hallucinations in LLM-generated\nsummaries, and evaluations of hallucination detection models both suffer from a\nlack of diversity and recency in the LLM and LLM families considered. This\npaper introduces FaithBench, a summarization hallucination benchmark comprising\nchallenging hallucinations made by 10 modern LLMs from 8 different families,\nwith ground truth annotations by human experts. ``Challenging'' here means\nsummaries on which popular, state-of-the-art hallucination detection models,\nincluding GPT-4o-as-a-judge, disagreed on. Our results show GPT-4o and\nGPT-3.5-Turbo produce the least hallucinations. However, even the best\nhallucination detection models have near 50\\% accuracies on FaithBench,\nindicating lots of room for future improvement. The repo is\nhttps://github.com/vectara/FaithBench\n","authors":["Forrest Sheng Bao","Miaoran Li","Renyi Qu","Ge Luo","Erana Wan","Yujia Tang","Weisi Fan","Manveer Singh Tamber","Suleman Kazi","Vivek Sourabh","Mike Qi","Ruixuan Tu","Chenyu Xu","Matthew Gonzales","Ofer Mendelevitch","Amin Ahmad"],"pdf_url":"https://arxiv.org/pdf/2410.13210v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.13206v1","updated":"2024-10-17T04:19:26Z","published":"2024-10-17T04:19:26Z","title":"BQA: Body Language Question Answering Dataset for Video Large Language\n  Models","summary":"  A large part of human communication relies on nonverbal cues such as facial\nexpressions, eye contact, and body language. Unlike language or sign language,\nsuch nonverbal communication lacks formal rules, requiring complex reasoning\nbased on commonsense understanding. Enabling current Video Large Language\nModels (VideoLLMs) to accurately interpret body language is a crucial\nchallenge, as human unconscious actions can easily cause the model to\nmisinterpret their intent. To address this, we propose a dataset, BQA, a body\nlanguage question answering dataset, to validate whether the model can\ncorrectly interpret emotions from short clips of body language comprising 26\nemotion labels of videos of body language. We evaluated various VideoLLMs on\nBQA and revealed that understanding body language is challenging, and our\nanalyses of the wrong answers by VideoLLMs show that certain VideoLLMs made\nsignificantly biased answers depending on the age group and ethnicity of the\nindividuals in the video. The dataset is available.\n","authors":["Shintaro Ozaki","Kazuki Hayashi","Miyu Oba","Yusuke Sakai","Hidetaka Kamigaito","Taro Watanabe"],"pdf_url":"https://arxiv.org/pdf/2410.13206v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.13204v1","updated":"2024-10-17T04:12:17Z","published":"2024-10-17T04:12:17Z","title":"Measuring Free-Form Decision-Making Inconsistency of Language Models in\n  Military Crisis Simulations","summary":"  There is an increasing interest in using language models (LMs) for automated\ndecision-making, with multiple countries actively testing LMs to aid in\nmilitary crisis decision-making. To scrutinize relying on LM decision-making in\nhigh-stakes settings, we examine the inconsistency of responses in a crisis\nsimulation (\"wargame\"), similar to reported tests conducted by the US military.\nPrior work illustrated escalatory tendencies and varying levels of aggression\namong LMs but were constrained to simulations with pre-defined actions. This\nwas due to the challenges associated with quantitatively measuring semantic\ndifferences and evaluating natural language decision-making without relying on\npre-defined actions. In this work, we query LMs for free form responses and use\na metric based on BERTScore to measure response inconsistency quantitatively.\nLeveraging the benefits of BERTScore, we show that the inconsistency metric is\nrobust to linguistic variations that preserve semantic meaning in a\nquestion-answering setting across text lengths. We show that all five tested\nLMs exhibit levels of inconsistency that indicate semantic differences, even\nwhen adjusting the wargame setting, anonymizing involved conflict countries, or\nadjusting the sampling temperature parameter $T$. Further qualitative\nevaluation shows that models recommend courses of action that share few to no\nsimilarities. We also study the impact of different prompt sensitivity\nvariations on inconsistency at temperature $T = 0$. We find that inconsistency\ndue to semantically equivalent prompt variations can exceed response\ninconsistency from temperature sampling for most studied models across\ndifferent levels of ablations. Given the high-stakes nature of military\ndeployment, we recommend further consideration be taken before using LMs to\ninform military decisions or other cases of high-stakes decision-making.\n","authors":["Aryan Shrivastava","Jessica Hullman","Max Lamparth"],"pdf_url":"https://arxiv.org/pdf/2410.13204v1.pdf","comment":null}],"Computer Vision and Pattern Recognition":[{"id":"http://arxiv.org/abs/2410.12686v2","updated":"2024-10-17T12:52:30Z","published":"2024-10-16T15:48:28Z","title":"Automatic Mapping of Anatomical Landmarks from Free-Text Using Large\n  Language Models: Insights from Llama-2","summary":"  Anatomical landmarks are vital in medical imaging for navigation and anomaly\ndetection. Modern large language models (LLMs), like Llama-2, offer promise for\nautomating the mapping of these landmarks in free-text radiology reports to\ncorresponding positions in image data. Recent studies propose LLMs may develop\ncoherent representations of generative processes. Motivated by these insights,\nwe investigated whether LLMs accurately represent the spatial positions of\nanatomical landmarks. Through experiments with Llama-2 models, we found that\nthey can linearly represent anatomical landmarks in space with considerable\nrobustness to different prompts. These results underscore the potential of LLMs\nto enhance the efficiency and accuracy of medical imaging workflows.\n","authors":["Mohamad Abdi","Gerardo Hermosillo Valadez","Halid Ziya Yerebakan"],"pdf_url":"https://arxiv.org/pdf/2410.12686v2.pdf","comment":"6 pages, 2 figures, 1 table"},{"id":"http://arxiv.org/abs/2410.12489v2","updated":"2024-10-17T08:03:34Z","published":"2024-10-16T12:09:38Z","title":"Synthetic Augmentation for Anatomical Landmark Localization using DDPMs","summary":"  Deep learning techniques for anatomical landmark localization (ALL) have\nshown great success, but their reliance on large annotated datasets remains a\nproblem due to the tedious and costly nature of medical data acquisition and\nannotation. While traditional data augmentation, variational autoencoders\n(VAEs), and generative adversarial networks (GANs) have already been used to\nsynthetically expand medical datasets, diffusion-based generative models have\nrecently started to gain attention for their ability to generate high-quality\nsynthetic images. In this study, we explore the use of denoising diffusion\nprobabilistic models (DDPMs) for generating medical images and their\ncorresponding heatmaps of landmarks to enhance the training of a supervised\ndeep learning model for ALL. Our novel approach involves a DDPM with a\n2-channel input, incorporating both the original medical image and its heatmap\nof annotated landmarks. We also propose a novel way to assess the quality of\nthe generated images using a Markov Random Field (MRF) model for landmark\nmatching and a Statistical Shape Model (SSM) to check landmark plausibility,\nbefore we evaluate the DDPM-augmented dataset in the context of an ALL task\ninvolving hand X-Rays.\n","authors":["Arnela Hadzic","Lea Bogensperger","Simon Johannes Joham","Martin Urschler"],"pdf_url":"https://arxiv.org/pdf/2410.12489v2.pdf","comment":"Accepted for the SASHIMI workshop of MICCAI 2024"},{"id":"http://arxiv.org/abs/2410.12407v2","updated":"2024-10-17T15:59:34Z","published":"2024-10-16T09:42:29Z","title":"Beyond Coarse-Grained Matching in Video-Text Retrieval","summary":"  Video-text retrieval has seen significant advancements, yet the ability of\nmodels to discern subtle differences in captions still requires verification.\nIn this paper, we introduce a new approach for fine-grained evaluation. Our\napproach can be applied to existing datasets by automatically generating hard\nnegative test captions with subtle single-word variations across nouns, verbs,\nadjectives, adverbs, and prepositions. We perform comprehensive experiments\nusing four state-of-the-art models across two standard benchmarks (MSR-VTT and\nVATEX) and two specially curated datasets enriched with detailed descriptions\n(VLN-UVO and VLN-OOPS), resulting in a number of novel insights: 1) our\nanalyses show that the current evaluation benchmarks fall short in detecting a\nmodel's ability to perceive subtle single-word differences, 2) our fine-grained\nevaluation highlights the difficulty models face in distinguishing such subtle\nvariations. To enhance fine-grained understanding, we propose a new baseline\nthat can be easily combined with current methods. Experiments on our\nfine-grained evaluations demonstrate that this approach enhances a model's\nability to understand fine-grained differences.\n","authors":["Aozhu Chen","Hazel Doughty","Xirong Li","Cees G. M. Snoek"],"pdf_url":"https://arxiv.org/pdf/2410.12407v2.pdf","comment":"Accepted to ACCV 2024"},{"id":"http://arxiv.org/abs/2409.19454v3","updated":"2024-10-17T05:23:57Z","published":"2024-09-28T20:40:18Z","title":"See Where You Read with Eye Gaze Tracking and Large Language Model","summary":"  Losing track of reading progress during line switching can be frustrating.\nEye gaze tracking technology offers a potential solution by highlighting read\nparagraphs, aiding users in avoiding wrong line switches. However, the gap\nbetween gaze tracking accuracy (2-3 cm) and text line spacing (3-5 mm) makes\ndirect application impractical. Existing methods leverage the linear reading\npattern but fail during jump reading. This paper presents a reading tracking\nand highlighting system that supports both linear and jump reading. Based on\nexperimental insights from the gaze nature study of 16 users, two gaze error\nmodels are designed to enable both jump reading detection and relocation. The\nsystem further leverages the large language model's contextual perception\ncapability in aiding reading tracking. A reading tracking domain-specific\nline-gaze alignment opportunity is also exploited to enable dynamic and\nfrequent calibration of the gaze results. Controlled experiments demonstrate\nreliable linear reading tracking, as well as 84% accuracy in tracking jump\nreading. Furthermore, real field tests with 18 volunteers demonstrated the\nsystem's effectiveness in tracking and highlighting read paragraphs, improving\nreading efficiency, and enhancing user experience.\n","authors":["Sikai Yang","Gang Yan","Wan Du"],"pdf_url":"https://arxiv.org/pdf/2409.19454v3.pdf","comment":"9 pages"},{"id":"http://arxiv.org/abs/2409.19554v3","updated":"2024-10-17T05:34:55Z","published":"2024-09-29T04:43:10Z","title":"Tri-Cam: Practical Eye Gaze Tracking via Camera Network","summary":"  As human eyes serve as conduits of rich information, unveiling emotions,\nintentions, and even aspects of an individual's health and overall well-being,\ngaze tracking also enables various human-computer interaction applications, as\nwell as insights in psychological and medical research. However, existing gaze\ntracking solutions fall short at handling free user movement, and also require\nlaborious user effort in system calibration. We introduce Tri-Cam, a practical\ndeep learning-based gaze tracking system using three affordable RGB webcams. It\nfeatures a split network structure for efficient training, as well as\ndesignated network designs to handle the separated gaze tracking tasks. Tri-Cam\nis also equipped with an implicit calibration module, which makes use of mouse\nclick opportunities to reduce calibration overhead on the user's end. We\nevaluate Tri-Cam against Tobii, the state-of-the-art commercial eye tracker,\nachieving comparable accuracy, while supporting a wider free movement area. In\nconclusion, Tri-Cam provides a user-friendly, affordable, and robust gaze\ntracking solution that could practically enable various applications.\n","authors":["Sikai Yang","Wan Du"],"pdf_url":"https://arxiv.org/pdf/2409.19554v3.pdf","comment":"12 pages"},{"id":"http://arxiv.org/abs/2410.12214v2","updated":"2024-10-17T16:16:33Z","published":"2024-10-16T04:19:28Z","title":"Order-aware Interactive Segmentation","summary":"  Interactive segmentation aims to accurately segment target objects with\nminimal user interactions. However, current methods often fail to accurately\nseparate target objects from the background, due to a limited understanding of\norder, the relative depth between objects in a scene. To address this issue, we\npropose OIS: order-aware interactive segmentation, where we explicitly encode\nthe relative depth between objects into order maps. We introduce a novel\norder-aware attention, where the order maps seamlessly guide the user\ninteractions (in the form of clicks) to attend to the image features. We\nfurther present an object-aware attention module to incorporate a strong\nobject-level understanding to better differentiate objects with similar order.\nOur approach allows both dense and sparse integration of user clicks, enhancing\nboth accuracy and efficiency as compared to prior works. Experimental results\ndemonstrate that OIS achieves state-of-the-art performance, improving mIoU\nafter one click by 7.61 on the HQSeg44K dataset and 1.32 on the DAVIS dataset\nas compared to the previous state-of-the-art SegNext, while also doubling\ninference speed compared to current leading methods. The project page is\nhttps://ukaukaaaa.github.io/projects/OIS/index.html\n","authors":["Bin Wang","Anwesa Choudhuri","Meng Zheng","Zhongpai Gao","Benjamin Planche","Andong Deng","Qin Liu","Terrence Chen","Ulas Bagci","Ziyan Wu"],"pdf_url":"https://arxiv.org/pdf/2410.12214v2.pdf","comment":"Interactive demo can be found in project page:\n  https://ukaukaaaa.github.io/projects/OIS/index.html"},{"id":"http://arxiv.org/abs/2410.12158v2","updated":"2024-10-17T07:15:32Z","published":"2024-10-16T01:38:59Z","title":"SAM-Guided Masked Token Prediction for 3D Scene Understanding","summary":"  Foundation models have significantly enhanced 2D task performance, and recent\nworks like Bridge3D have successfully applied these models to improve 3D scene\nunderstanding through knowledge distillation, marking considerable\nadvancements. Nonetheless, challenges such as the misalignment between 2D and\n3D representations and the persistent long-tail distribution in 3D datasets\nstill restrict the effectiveness of knowledge distillation from 2D to 3D using\nfoundation models. To tackle these issues, we introduce a novel SAM-guided\ntokenization method that seamlessly aligns 3D transformer structures with\nregion-level knowledge distillation, replacing the traditional KNN-based\ntokenization techniques. Additionally, we implement a group-balanced\nre-weighting strategy to effectively address the long-tail problem in knowledge\ndistillation. Furthermore, inspired by the recent success of masked feature\nprediction, our framework incorporates a two-stage masked token prediction\nprocess in which the student model predicts both the global embeddings and the\ntoken-wise local embeddings derived from the teacher models trained in the\nfirst stage. Our methodology has been validated across multiple datasets,\nincluding SUN RGB-D, ScanNet, and S3DIS, for tasks like 3D object detection and\nsemantic segmentation. The results demonstrate significant improvements over\ncurrent State-of-the-art self-supervised methods, establishing new benchmarks\nin this field.\n","authors":["Zhimin Chen","Liang Yang","Yingwei Li","Longlong Jing","Bing Li"],"pdf_url":"https://arxiv.org/pdf/2410.12158v2.pdf","comment":"Accepted by NeurIPS 2024"},{"id":"http://arxiv.org/abs/2410.13863v1","updated":"2024-10-17T17:59:59Z","published":"2024-10-17T17:59:59Z","title":"Fluid: Scaling Autoregressive Text-to-image Generative Models with\n  Continuous Tokens","summary":"  Scaling up autoregressive models in vision has not proven as beneficial as in\nlarge language models. In this work, we investigate this scaling problem in the\ncontext of text-to-image generation, focusing on two critical factors: whether\nmodels use discrete or continuous tokens, and whether tokens are generated in a\nrandom or fixed raster order using BERT- or GPT-like transformer architectures.\nOur empirical results show that, while all models scale effectively in terms of\nvalidation loss, their evaluation performance -- measured by FID, GenEval\nscore, and visual quality -- follows different trends. Models based on\ncontinuous tokens achieve significantly better visual quality than those using\ndiscrete tokens. Furthermore, the generation order and attention mechanisms\nsignificantly affect the GenEval score: random-order models achieve notably\nbetter GenEval scores compared to raster-order models. Inspired by these\nfindings, we train Fluid, a random-order autoregressive model on continuous\ntokens. Fluid 10.5B model achieves a new state-of-the-art zero-shot FID of 6.16\non MS-COCO 30K, and 0.69 overall score on the GenEval benchmark. We hope our\nfindings and results will encourage future efforts to further bridge the\nscaling gap between vision and language models.\n","authors":["Lijie Fan","Tianhong Li","Siyang Qin","Yuanzhen Li","Chen Sun","Michael Rubinstein","Deqing Sun","Kaiming He","Yonglong Tian"],"pdf_url":"https://arxiv.org/pdf/2410.13863v1.pdf","comment":"Tech report"},{"id":"http://arxiv.org/abs/2410.13864v1","updated":"2024-10-17T17:59:59Z","published":"2024-10-17T17:59:59Z","title":"UniDrive: Towards Universal Driving Perception Across Camera\n  Configurations","summary":"  Vision-centric autonomous driving has demonstrated excellent performance with\neconomical sensors. As the fundamental step, 3D perception aims to infer 3D\ninformation from 2D images based on 3D-2D projection. This makes driving\nperception models susceptible to sensor configuration (e.g., camera intrinsics\nand extrinsics) variations. However, generalizing across camera configurations\nis important for deploying autonomous driving models on different car models.\nIn this paper, we present UniDrive, a novel framework for vision-centric\nautonomous driving to achieve universal perception across camera\nconfigurations. We deploy a set of unified virtual cameras and propose a\nground-aware projection method to effectively transform the original images\ninto these unified virtual views. We further propose a virtual configuration\noptimization method by minimizing the expected projection error between\noriginal cameras and virtual cameras. The proposed virtual camera projection\ncan be applied to existing 3D perception methods as a plug-and-play module to\nmitigate the challenges posed by camera parameter variability, resulting in\nmore adaptable and reliable driving perception models. To evaluate the\neffectiveness of our framework, we collect a dataset on Carla by driving the\nsame routes while only modifying the camera configurations. Experimental\nresults demonstrate that our method trained on one specific camera\nconfiguration can generalize to varying configurations with minor performance\ndegradation.\n","authors":["Ye Li","Wenzhao Zheng","Xiaonan Huang","Kurt Keutzer"],"pdf_url":"https://arxiv.org/pdf/2410.13864v1.pdf","comment":"Preprint; 14 pages, 5 figures, 2 tables; Code at\n  https://github.com/ywyeli/UniDrive"},{"id":"http://arxiv.org/abs/2410.13862v1","updated":"2024-10-17T17:59:58Z","published":"2024-10-17T17:59:58Z","title":"DepthSplat: Connecting Gaussian Splatting and Depth","summary":"  Gaussian splatting and single/multi-view depth estimation are typically\nstudied in isolation. In this paper, we present DepthSplat to connect Gaussian\nsplatting and depth estimation and study their interactions. More specifically,\nwe first contribute a robust multi-view depth model by leveraging pre-trained\nmonocular depth features, leading to high-quality feed-forward 3D Gaussian\nsplatting reconstructions. We also show that Gaussian splatting can serve as an\nunsupervised pre-training objective for learning powerful depth models from\nlarge-scale unlabelled datasets. We validate the synergy between Gaussian\nsplatting and depth estimation through extensive ablation and cross-task\ntransfer experiments. Our DepthSplat achieves state-of-the-art performance on\nScanNet, RealEstate10K and DL3DV datasets in terms of both depth estimation and\nnovel view synthesis, demonstrating the mutual benefits of connecting both\ntasks. Our code, models, and video results are available at\nhttps://haofeixu.github.io/depthsplat/.\n","authors":["Haofei Xu","Songyou Peng","Fangjinhua Wang","Hermann Blum","Daniel Barath","Andreas Geiger","Marc Pollefeys"],"pdf_url":"https://arxiv.org/pdf/2410.13862v1.pdf","comment":"Project page: https://haofeixu.github.io/depthsplat/"},{"id":"http://arxiv.org/abs/2410.13861v1","updated":"2024-10-17T17:59:57Z","published":"2024-10-17T17:59:57Z","title":"PUMA: Empowering Unified MLLM with Multi-granular Visual Generation","summary":"  Recent advancements in multimodal foundation models have yielded significant\nprogress in vision-language understanding. Initial attempts have also explored\nthe potential of multimodal large language models (MLLMs) for visual content\ngeneration. However, existing works have insufficiently addressed the varying\ngranularity demands of different image generation tasks within a unified MLLM\nparadigm - from the diversity required in text-to-image generation to the\nprecise controllability needed in image manipulation. In this work, we propose\nPUMA, emPowering Unified MLLM with Multi-grAnular visual generation. PUMA\nunifies multi-granular visual features as both inputs and outputs of MLLMs,\nelegantly addressing the different granularity requirements of various image\ngeneration tasks within a unified MLLM framework. Following multimodal\npretraining and task-specific instruction tuning, PUMA demonstrates proficiency\nin a wide range of multimodal tasks. This work represents a significant step\ntowards a truly unified MLLM capable of adapting to the granularity demands of\nvarious visual tasks. The code and model will be released in\nhttps://github.com/rongyaofang/PUMA.\n","authors":["Rongyao Fang","Chengqi Duan","Kun Wang","Hao Li","Hao Tian","Xingyu Zeng","Rui Zhao","Jifeng Dai","Hongsheng Li","Xihui Liu"],"pdf_url":"https://arxiv.org/pdf/2410.13861v1.pdf","comment":"Project page: https://rongyaofang.github.io/puma/"},{"id":"http://arxiv.org/abs/2410.13860v1","updated":"2024-10-17T17:59:55Z","published":"2024-10-17T17:59:55Z","title":"VLM-Grounder: A VLM Agent for Zero-Shot 3D Visual Grounding","summary":"  3D visual grounding is crucial for robots, requiring integration of natural\nlanguage and 3D scene understanding. Traditional methods depending on\nsupervised learning with 3D point clouds are limited by scarce datasets.\nRecently zero-shot methods leveraging LLMs have been proposed to address the\ndata issue. While effective, these methods only use object-centric information,\nlimiting their ability to handle complex queries. In this work, we present\nVLM-Grounder, a novel framework using vision-language models (VLMs) for\nzero-shot 3D visual grounding based solely on 2D images. VLM-Grounder\ndynamically stitches image sequences, employs a grounding and feedback scheme\nto find the target object, and uses a multi-view ensemble projection to\naccurately estimate 3D bounding boxes. Experiments on ScanRefer and Nr3D\ndatasets show VLM-Grounder outperforms previous zero-shot methods, achieving\n51.6% Acc@0.25 on ScanRefer and 48.0% Acc on Nr3D, without relying on 3D\ngeometry or object priors. Codes are available at\nhttps://github.com/OpenRobotLab/VLM-Grounder .\n","authors":["Runsen Xu","Zhiwei Huang","Tai Wang","Yilun Chen","Jiangmiao Pang","Dahua Lin"],"pdf_url":"https://arxiv.org/pdf/2410.13860v1.pdf","comment":"CoRL 2024 Camera Ready. 25 pages. A novel zero-shot 3D visual\n  grounding framework based solely on 2D images"},{"id":"http://arxiv.org/abs/2410.13859v1","updated":"2024-10-17T17:59:53Z","published":"2024-10-17T17:59:53Z","title":"$γ-$MoD: Exploring Mixture-of-Depth Adaptation for Multimodal Large\n  Language Models","summary":"  Despite the significant progress in multimodal large language models (MLLMs),\ntheir high computational cost remains a barrier to real-world deployment.\nInspired by the mixture of depths (MoDs) in natural language processing, we aim\nto address this limitation from the perspective of ``activated tokens''. Our\nkey insight is that if most tokens are redundant for the layer computation,\nthen can be skipped directly via the MoD layer. However, directly converting\nthe dense layers of MLLMs to MoD layers leads to substantial performance\ndegradation. To address this issue, we propose an innovative MoD adaptation\nstrategy for existing MLLMs called $\\gamma$-MoD. In $\\gamma$-MoD, a novel\nmetric is proposed to guide the deployment of MoDs in the MLLM, namely rank of\nattention maps (ARank). Through ARank, we can effectively identify which layer\nis redundant and should be replaced with the MoD layer. Based on ARank, we\nfurther propose two novel designs to maximize the computational sparsity of\nMLLM while maintaining its performance, namely shared vision-language router\nand masked routing learning. With these designs, more than 90% dense layers of\nthe MLLM can be effectively converted to the MoD ones. To validate our method,\nwe apply it to three popular MLLMs, and conduct extensive experiments on 9\nbenchmark datasets. Experimental results not only validate the significant\nefficiency benefit of $\\gamma$-MoD to existing MLLMs but also confirm its\ngeneralization ability on various MLLMs. For example, with a minor performance\ndrop, i.e., -1.5%, $\\gamma$-MoD can reduce the training and inference time of\nLLaVA-HR by 31.0% and 53.2%, respectively.\n","authors":["Yaxin Luo","Gen Luo","Jiayi Ji","Yiyi Zhou","Xiaoshuai Sun","Zhiqiang Shen","Rongrong Ji"],"pdf_url":"https://arxiv.org/pdf/2410.13859v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.13854v1","updated":"2024-10-17T17:59:24Z","published":"2024-10-17T17:59:24Z","title":"Can MLLMs Understand the Deep Implication Behind Chinese Images?","summary":"  As the capabilities of Multimodal Large Language Models (MLLMs) continue to\nimprove, the need for higher-order capability evaluation of MLLMs is\nincreasing. However, there is a lack of work evaluating MLLM for higher-order\nperception and understanding of Chinese visual content. To fill the gap, we\nintroduce the **C**hinese **I**mage **I**mplication understanding\n**Bench**mark, **CII-Bench**, which aims to assess the higher-order perception\nand understanding capabilities of MLLMs for Chinese images. CII-Bench stands\nout in several ways compared to existing benchmarks. Firstly, to ensure the\nauthenticity of the Chinese context, images in CII-Bench are sourced from the\nChinese Internet and manually reviewed, with corresponding answers also\nmanually crafted. Additionally, CII-Bench incorporates images that represent\nChinese traditional culture, such as famous Chinese traditional paintings,\nwhich can deeply reflect the model's understanding of Chinese traditional\nculture. Through extensive experiments on CII-Bench across multiple MLLMs, we\nhave made significant findings. Initially, a substantial gap is observed\nbetween the performance of MLLMs and humans on CII-Bench. The highest accuracy\nof MLLMs attains 64.4%, where as human accuracy averages 78.2%, peaking at an\nimpressive 81.0%. Subsequently, MLLMs perform worse on Chinese traditional\nculture images, suggesting limitations in their ability to understand\nhigh-level semantics and lack a deep knowledge base of Chinese traditional\nculture. Finally, it is observed that most models exhibit enhanced accuracy\nwhen image emotion hints are incorporated into the prompts. We believe that\nCII-Bench will enable MLLMs to gain a better understanding of Chinese semantics\nand Chinese-specific images, advancing the journey towards expert artificial\ngeneral intelligence (AGI). Our project is publicly available at\nhttps://cii-bench.github.io/.\n","authors":["Chenhao Zhang","Xi Feng","Yuelin Bai","Xinrun Du","Jinchang Hou","Kaixin Deng","Guangzeng Han","Qinrui Li","Bingli Wang","Jiaheng Liu","Xingwei Qu","Yifei Zhang","Qixuan Zhao","Yiming Liang","Ziqiang Liu","Feiteng Fang","Min Yang","Wenhao Huang","Chenghua Lin","Ge Zhang","Shiwen Ni"],"pdf_url":"https://arxiv.org/pdf/2410.13854v1.pdf","comment":"32 pages,18 figures. Project Page: https://cii-bench.github.io/ Code:\n  https://github.com/MING_X/CII-Bench Dataset:\n  https://huggingface.co/datasets/m-a-p/CII-Bench"},{"id":"http://arxiv.org/abs/2410.13852v1","updated":"2024-10-17T17:59:03Z","published":"2024-10-17T17:59:03Z","title":"Retrospective Learning from Interactions","summary":"  Multi-turn interactions between large language models (LLMs) and users\nnaturally include implicit feedback signals. If an LLM responds in an\nunexpected way to an instruction, the user is likely to signal it by rephrasing\nthe request, expressing frustration, or pivoting to an alternative task. Such\nsignals are task-independent and occupy a relatively constrained subspace of\nlanguage, allowing the LLM to identify them even if it fails on the actual\ntask. This creates an avenue for continually learning from interactions without\nadditional annotations. We introduce ReSpect, a method to learn from such\nsignals in past interactions via retrospection. We deploy ReSpect in a new\nmultimodal interaction scenario, where humans instruct an LLM to solve an\nabstract reasoning task with a combinatorial solution space. Through thousands\nof interactions with humans, we show how ReSpect gradually improves task\ncompletion rate from 31% to 82%, all without any external annotation.\n","authors":["Zizhao Chen","Mustafa Omer Gul","Yiwei Chen","Gloria Geng","Anne Wu","Yoav Artzi"],"pdf_url":"https://arxiv.org/pdf/2410.13852v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.13851v1","updated":"2024-10-17T17:59:02Z","published":"2024-10-17T17:59:02Z","title":"Differentiable Robot Rendering","summary":"  Vision foundation models trained on massive amounts of visual data have shown\nunprecedented reasoning and planning skills in open-world settings. A key\nchallenge in applying them to robotic tasks is the modality gap between visual\ndata and action data. We introduce differentiable robot rendering, a method\nallowing the visual appearance of a robot body to be directly differentiable\nwith respect to its control parameters. Our model integrates a kinematics-aware\ndeformable model and Gaussians Splatting and is compatible with any robot form\nfactors and degrees of freedom. We demonstrate its capability and usage in\napplications including reconstruction of robot poses from images and\ncontrolling robots through vision language models. Quantitative and qualitative\nresults show that our differentiable rendering model provides effective\ngradients for robotic control directly from pixels, setting the foundation for\nthe future applications of vision foundation models in robotics.\n","authors":["Ruoshi Liu","Alper Canberk","Shuran Song","Carl Vondrick"],"pdf_url":"https://arxiv.org/pdf/2410.13851v1.pdf","comment":"Project Page: https://drrobot.cs.columbia.edu/"},{"id":"http://arxiv.org/abs/2410.13848v1","updated":"2024-10-17T17:58:37Z","published":"2024-10-17T17:58:37Z","title":"Janus: Decoupling Visual Encoding for Unified Multimodal Understanding\n  and Generation","summary":"  In this paper, we introduce Janus, an autoregressive framework that unifies\nmultimodal understanding and generation. Prior research often relies on a\nsingle visual encoder for both tasks, such as Chameleon. However, due to the\ndiffering levels of information granularity required by multimodal\nunderstanding and generation, this approach can lead to suboptimal performance,\nparticularly in multimodal understanding. To address this issue, we decouple\nvisual encoding into separate pathways, while still leveraging a single,\nunified transformer architecture for processing. The decoupling not only\nalleviates the conflict between the visual encoder's roles in understanding and\ngeneration, but also enhances the framework's flexibility. For instance, both\nthe multimodal understanding and generation components can independently select\ntheir most suitable encoding methods. Experiments show that Janus surpasses\nprevious unified model and matches or exceeds the performance of task-specific\nmodels. The simplicity, high flexibility, and effectiveness of Janus make it a\nstrong candidate for next-generation unified multimodal models.\n","authors":["Chengyue Wu","Xiaokang Chen","Zhiyu Wu","Yiyang Ma","Xingchao Liu","Zizheng Pan","Wen Liu","Zhenda Xie","Xingkai Yu","Chong Ruan","Ping Luo"],"pdf_url":"https://arxiv.org/pdf/2410.13848v1.pdf","comment":"Technical Report"},{"id":"http://arxiv.org/abs/2410.13842v1","updated":"2024-10-17T17:57:01Z","published":"2024-10-17T17:57:01Z","title":"D-FINE: Redefine Regression Task in DETRs as Fine-grained Distribution\n  Refinement","summary":"  We introduce D-FINE, a powerful real-time object detector that achieves\noutstanding localization precision by redefining the bounding box regression\ntask in DETR models. D-FINE comprises two key components: Fine-grained\nDistribution Refinement (FDR) and Global Optimal Localization Self-Distillation\n(GO-LSD). FDR transforms the regression process from predicting fixed\ncoordinates to iteratively refining probability distributions, providing a\nfine-grained intermediate representation that significantly enhances\nlocalization accuracy. GO-LSD is a bidirectional optimization strategy that\ntransfers localization knowledge from refined distributions to shallower layers\nthrough self-distillation, while also simplifying the residual prediction tasks\nfor deeper layers. Additionally, D-FINE incorporates lightweight optimizations\nin computationally intensive modules and operations, achieving a better balance\nbetween speed and accuracy. Specifically, D-FINE-L / X achieves 54.0% / 55.8%\nAP on the COCO dataset at 124 / 78 FPS on an NVIDIA T4 GPU. When pretrained on\nObjects365, D-FINE-L / X attains 57.1% / 59.3% AP, surpassing all existing\nreal-time detectors. Furthermore, our method significantly enhances the\nperformance of a wide range of DETR models by up to 5.3% AP with negligible\nextra parameters and training costs. Our code and pretrained models:\nhttps://github.com/Peterande/D-FINE.\n","authors":["Yansong Peng","Hebei Li","Peixi Wu","Yueyi Zhang","Xiaoyan Sun","Feng Wu"],"pdf_url":"https://arxiv.org/pdf/2410.13842v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.13832v1","updated":"2024-10-17T17:53:24Z","published":"2024-10-17T17:53:24Z","title":"VidPanos: Generative Panoramic Videos from Casual Panning Videos","summary":"  Panoramic image stitching provides a unified, wide-angle view of a scene that\nextends beyond the camera's field of view. Stitching frames of a panning video\ninto a panoramic photograph is a well-understood problem for stationary scenes,\nbut when objects are moving, a still panorama cannot capture the scene. We\npresent a method for synthesizing a panoramic video from a casually-captured\npanning video, as if the original video were captured with a wide-angle camera.\nWe pose panorama synthesis as a space-time outpainting problem, where we aim to\ncreate a full panoramic video of the same length as the input video. Consistent\ncompletion of the space-time volume requires a powerful, realistic prior over\nvideo content and motion, for which we adapt generative video models. Existing\ngenerative models do not, however, immediately extend to panorama completion,\nas we show. We instead apply video generation as a component of our panorama\nsynthesis system, and demonstrate how to exploit the strengths of the models\nwhile minimizing their limitations. Our system can create video panoramas for a\nrange of in-the-wild scenes including people, vehicles, and flowing water, as\nwell as stationary background features.\n","authors":["Jingwei Ma","Erika Lu","Roni Paiss","Shiran Zada","Aleksander Holynski","Tali Dekel","Brian Curless","Michael Rubinstein","Forrester Cole"],"pdf_url":"https://arxiv.org/pdf/2410.13832v1.pdf","comment":"Project page at https://vidpanos.github.io/. To appear at SIGGRAPH\n  Asia 2024 (conference track)"},{"id":"http://arxiv.org/abs/2410.13830v1","updated":"2024-10-17T17:52:57Z","published":"2024-10-17T17:52:57Z","title":"DreamVideo-2: Zero-Shot Subject-Driven Video Customization with Precise\n  Motion Control","summary":"  Recent advances in customized video generation have enabled users to create\nvideos tailored to both specific subjects and motion trajectories. However,\nexisting methods often require complicated test-time fine-tuning and struggle\nwith balancing subject learning and motion control, limiting their real-world\napplications. In this paper, we present DreamVideo-2, a zero-shot video\ncustomization framework capable of generating videos with a specific subject\nand motion trajectory, guided by a single image and a bounding box sequence,\nrespectively, and without the need for test-time fine-tuning. Specifically, we\nintroduce reference attention, which leverages the model's inherent\ncapabilities for subject learning, and devise a mask-guided motion module to\nachieve precise motion control by fully utilizing the robust motion signal of\nbox masks derived from bounding boxes. While these two components achieve their\nintended functions, we empirically observe that motion control tends to\ndominate over subject learning. To address this, we propose two key designs: 1)\nthe masked reference attention, which integrates a blended latent mask modeling\nscheme into reference attention to enhance subject representations at the\ndesired positions, and 2) a reweighted diffusion loss, which differentiates the\ncontributions of regions inside and outside the bounding boxes to ensure a\nbalance between subject and motion control. Extensive experimental results on a\nnewly curated dataset demonstrate that DreamVideo-2 outperforms\nstate-of-the-art methods in both subject customization and motion control. The\ndataset, code, and models will be made publicly available.\n","authors":["Yujie Wei","Shiwei Zhang","Hangjie Yuan","Xiang Wang","Haonan Qiu","Rui Zhao","Yutong Feng","Feng Liu","Zhizhong Huang","Jiaxin Ye","Yingya Zhang","Hongming Shan"],"pdf_url":"https://arxiv.org/pdf/2410.13830v1.pdf","comment":"Project page: https://dreamvideo2.github.io/"},{"id":"http://arxiv.org/abs/2410.13826v1","updated":"2024-10-17T17:51:40Z","published":"2024-10-17T17:51:40Z","title":"Unearthing Skill-Level Insights for Understanding Trade-Offs of\n  Foundation Models","summary":"  With models getting stronger, evaluations have grown more complex, testing\nmultiple skills in one benchmark and even in the same instance at once.\nHowever, skill-wise performance is obscured when inspecting aggregate accuracy,\nunder-utilizing the rich signal modern benchmarks contain. We propose an\nautomatic approach to recover the underlying skills relevant for any evaluation\ninstance, by way of inspecting model-generated rationales. After validating the\nrelevance of rationale-parsed skills and inferring skills for $46$k instances\nover $12$ benchmarks, we observe many skills to be common across benchmarks,\nresulting in the curation of hundreds of skill-slices (i.e. sets of instances\ntesting a common skill). Inspecting accuracy over these slices yields novel\ninsights on model trade-offs: e.g., compared to GPT-4o and Claude 3.5 Sonnet,\non average, Gemini 1.5 Pro is $18\\%$ more accurate in \"computing molar mass\",\nbut $19\\%$ less accurate in \"applying constitutional law\", despite the overall\naccuracies of the three models differing by a mere $0.4\\%$. Furthermore, we\ndemonstrate the practical utility of our approach by showing that insights\nderived from skill slice analysis can generalize to held-out instances: when\nrouting each instance to the model strongest on the relevant skills, we see a\n$3\\%$ accuracy improvement over our $12$ dataset corpus. Our skill-slices and\nframework open a new avenue in model evaluation, leveraging skill-specific\nanalyses to unlock a more granular and actionable understanding of model\ncapabilities.\n","authors":["Mazda Moayeri","Vidhisha Balachandran","Varun Chandrasekaran","Safoora Yousefi","Thomas Fel","Soheil Feizi","Besmira Nushi","Neel Joshi","Vibhav Vineet"],"pdf_url":"https://arxiv.org/pdf/2410.13826v1.pdf","comment":"Code at: github.com/microsoft/skill-slice-insights"},{"id":"http://arxiv.org/abs/2410.13824v1","updated":"2024-10-17T17:48:54Z","published":"2024-10-17T17:48:54Z","title":"Harnessing Webpage UIs for Text-Rich Visual Understanding","summary":"  Text-rich visual understanding-the ability to process environments where\ndense textual content is integrated with visuals-is crucial for multimodal\nlarge language models (MLLMs) to interact effectively with structured\nenvironments. To enhance this capability, we propose synthesizing general\nmultimodal instructions from webpage UIs using text-based large language models\n(LLMs). Despite lacking direct visual input, text-based LLMs are able to\nprocess structured text representations from webpage accessibility trees. These\ninstructions are then paired with UI screenshots to train multimodal models. We\nintroduce MultiUI, a dataset containing 7.3 million samples from 1 million\nwebsites, covering diverse multimodal tasks and UI layouts. Models trained on\nMultiUI not only excel in web UI tasks-achieving up to a 48\\% improvement on\nVisualWebBench and a 19.1\\% boost in action accuracy on a web agent dataset\nMind2Web-but also generalize surprisingly well to non-web UI tasks and even to\nnon-UI domains, such as document understanding, OCR, and chart interpretation.\nThese results highlight the broad applicability of web UI data for advancing\ntext-rich visual understanding across various scenarios.\n","authors":["Junpeng Liu","Tianyue Ou","Yifan Song","Yuxiao Qu","Wai Lam","Chenyan Xiong","Wenhu Chen","Graham Neubig","Xiang Yue"],"pdf_url":"https://arxiv.org/pdf/2410.13824v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.13823v1","updated":"2024-10-17T17:48:36Z","published":"2024-10-17T17:48:36Z","title":"Deep Generative Models Unveil Patterns in Medical Images Through\n  Vision-Language Conditioning","summary":"  Deep generative models have significantly advanced medical imaging analysis\nby enhancing dataset size and quality. Beyond mere data augmentation, our\nresearch in this paper highlights an additional, significant capacity of deep\ngenerative models: their ability to reveal and demonstrate patterns in medical\nimages. We employ a generative structure with hybrid conditions, combining\nclinical data and segmentation masks to guide the image synthesis process.\nFurthermore, we innovatively transformed the tabular clinical data into textual\ndescriptions. This approach simplifies the handling of missing values and also\nenables us to leverage large pre-trained vision-language models that\ninvestigate the relations between independent clinical entries and comprehend\ngeneral terms, such as gender and smoking status. Our approach differs from and\npresents a more challenging task than traditional medical report-guided\nsynthesis due to the less visual correlation of our clinical information with\nthe images. To overcome this, we introduce a text-visual embedding mechanism\nthat strengthens the conditions, ensuring the network effectively utilizes the\nprovided information. Our pipeline is generalizable to both GAN-based and\ndiffusion models. Experiments on chest CT, particularly focusing on the smoking\nstatus, demonstrated a consistent intensity shift in the lungs which is in\nagreement with clinical observations, indicating the effectiveness of our\nmethod in capturing and visualizing the impact of specific attributes on\nmedical image patterns. Our methods offer a new avenue for the early detection\nand precise visualization of complex clinical conditions with deep generative\nmodels. All codes are https://github.com/junzhin/DGM-VLC.\n","authors":["Xiaodan Xing","Junzhi Ning","Yang Nan","Guang Yang"],"pdf_url":"https://arxiv.org/pdf/2410.13823v1.pdf","comment":"Accepted by AIM-FM Workshop of NeurIPS2024"},{"id":"http://arxiv.org/abs/2410.13822v1","updated":"2024-10-17T17:48:17Z","published":"2024-10-17T17:48:17Z","title":"Multi-style conversion for semantic segmentation of lesions in fundus\n  images by adversarial attacks","summary":"  The diagnosis of diabetic retinopathy, which relies on fundus images, faces\nchallenges in achieving transparency and interpretability when using a global\nclassification approach. However, segmentation-based databases are\nsignificantly more expensive to acquire and combining them is often\nproblematic. This paper introduces a novel method, termed adversarial style\nconversion, to address the lack of standardization in annotation styles across\ndiverse databases. By training a single architecture on combined databases, the\nmodel spontaneously modifies its segmentation style depending on the input,\ndemonstrating the ability to convert among different labeling styles. The\nproposed methodology adds a linear probe to detect dataset origin based on\nencoder features and employs adversarial attacks to condition the model's\nsegmentation style. Results indicate significant qualitative and quantitative\nthrough dataset combination, offering avenues for improved model\ngeneralization, uncertainty estimation and continuous interpolation between\nannotation styles. Our approach enables training a segmentation model with\ndiverse databases while controlling and leveraging annotation styles for\nimproved retinopathy diagnosis.\n","authors":["Clément Playout","Renaud Duval","Marie Carole Boucher","Farida Cheriet"],"pdf_url":"https://arxiv.org/pdf/2410.13822v1.pdf","comment":"preprint"},{"id":"http://arxiv.org/abs/2410.13807v1","updated":"2024-10-17T17:41:52Z","published":"2024-10-17T17:41:52Z","title":"ConsisSR: Delving Deep into Consistency in Diffusion-based Image\n  Super-Resolution","summary":"  Real-world image super-resolution (Real-ISR) aims at restoring high-quality\n(HQ) images from low-quality (LQ) inputs corrupted by unknown and complex\ndegradations. In particular, pretrained text-to-image (T2I) diffusion models\nprovide strong generative priors to reconstruct credible and intricate details.\nHowever, T2I generation focuses on semantic consistency while Real-ISR\nemphasizes pixel-level reconstruction, which hinders existing methods from\nfully exploiting diffusion priors. To address this challenge, we introduce\nConsisSR to handle both semantic and pixel-level consistency. Specifically,\ncompared to coarse-grained text prompts, we exploit the more powerful CLIP\nimage embedding and effectively leverage both modalities through our Hybrid\nPrompt Adapter (HPA) for semantic guidance. Secondly, we introduce Time-aware\nLatent Augmentation (TALA) to mitigate the inherent gap between T2I generation\nand Real-ISR consistency requirements. By randomly mixing LQ and HQ latent\ninputs, our model not only handle timestep-specific diffusion noise but also\nrefine the accumulated latent representations. Last but not least, our\nGAN-Embedding strategy employs the pretrained Real-ESRGAN model to refine the\ndiffusion start point. This accelerates the inference process to 10 steps while\npreserving sampling quality, in a training-free manner.Our method demonstrates\nstate-of-the-art performance among both full-scale and accelerated models. The\ncode will be made publicly available.\n","authors":["Junhao Gu","Peng-Tao Jiang","Hao Zhang","Mi Zhou","Jinwei Chen","Wenming Yang","Bo Li"],"pdf_url":"https://arxiv.org/pdf/2410.13807v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.13790v1","updated":"2024-10-17T17:31:24Z","published":"2024-10-17T17:31:24Z","title":"MotionBank: A Large-scale Video Motion Benchmark with Disentangled\n  Rule-based Annotations","summary":"  In this paper, we tackle the problem of how to build and benchmark a large\nmotion model (LMM). The ultimate goal of LMM is to serve as a foundation model\nfor versatile motion-related tasks, e.g., human motion generation, with\ninterpretability and generalizability. Though advanced, recent LMM-related\nworks are still limited by small-scale motion data and costly text\ndescriptions. Besides, previous motion benchmarks primarily focus on pure body\nmovements, neglecting the ubiquitous motions in context, i.e., humans\ninteracting with humans, objects, and scenes. To address these limitations, we\nconsolidate large-scale video action datasets as knowledge banks to build\nMotionBank, which comprises 13 video action datasets, 1.24M motion sequences,\nand 132.9M frames of natural and diverse human motions. Different from\nlaboratory-captured motions, in-the-wild human-centric videos contain abundant\nmotions in context. To facilitate better motion text alignment, we also\nmeticulously devise a motion caption generation algorithm to automatically\nproduce rule-based, unbiased, and disentangled text descriptions via the\nkinematic characteristics for each motion. Extensive experiments show that our\nMotionBank is beneficial for general motion-related tasks of human motion\ngeneration, motion in-context generation, and motion understanding. Video\nmotions together with the rule-based text annotations could serve as an\nefficient alternative for larger LMMs. Our dataset, codes, and benchmark will\nbe publicly available at https://github.com/liangxuy/MotionBank.\n","authors":["Liang Xu","Shaoyang Hua","Zili Lin","Yifan Liu","Feipeng Ma","Yichao Yan","Xin Jin","Xiaokang Yang","Wenjun Zeng"],"pdf_url":"https://arxiv.org/pdf/2410.13790v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.13786v1","updated":"2024-10-17T17:22:59Z","published":"2024-10-17T17:22:59Z","title":"Emphasizing Semantic Consistency of Salient Posture for Speech-Driven\n  Gesture Generation","summary":"  Speech-driven gesture generation aims at synthesizing a gesture sequence\nsynchronized with the input speech signal. Previous methods leverage neural\nnetworks to directly map a compact audio representation to the gesture\nsequence, ignoring the semantic association of different modalities and failing\nto deal with salient gestures. In this paper, we propose a novel speech-driven\ngesture generation method by emphasizing the semantic consistency of salient\nposture. Specifically, we first learn a joint manifold space for the individual\nrepresentation of audio and body pose to exploit the inherent semantic\nassociation between two modalities, and propose to enforce semantic consistency\nvia a consistency loss. Furthermore, we emphasize the semantic consistency of\nsalient postures by introducing a weakly-supervised detector to identify\nsalient postures, and reweighting the consistency loss to focus more on\nlearning the correspondence between salient postures and the high-level\nsemantics of speech content. In addition, we propose to extract audio features\ndedicated to facial expression and body gesture separately, and design separate\nbranches for face and body gesture synthesis. Extensive experimental results\ndemonstrate the superiority of our method over the state-of-the-art approaches.\n","authors":["Fengqi Liu","Hexiang Wang","Jingyu Gong","Ran Yi","Qianyu Zhou","Xuequan Lu","Jiangbo Lu","Lizhuang Ma"],"pdf_url":"https://arxiv.org/pdf/2410.13786v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.13569v1","updated":"2024-10-17T17:17:09Z","published":"2024-10-17T17:17:09Z","title":"Representing Model Weights with Language using Tree Experts","summary":"  The increasing availability of public models begs the question: can we train\nneural networks that use other networks as input? This paper learns to\nrepresent models within a joint space that embeds both model weights and\nlanguage. However, machine learning on model weights is challenging as model\nweights often exhibit significant variation unrelated to the models' semantic\nproperties (nuisance variation). We identify a key property of real-world\nmodels: most public models belong to a small set of Model Trees, where all\nmodels within a tree are fine-tuned from a common ancestor (e.g., a foundation\nmodel). Importantly, we find that within each tree there is less nuisance\nvariation between models. For example, while classifying models according to\ntheir training dataset generally requires complex architectures, in our case,\neven a linear classifier trained on a single layer is often effective. While\neffective, linear layers are computationally expensive as model weights are\nvery high dimensional. To address this, we introduce Probing Experts (ProbeX),\na theoretically motivated, lightweight probing method. Notably, ProbeX is the\nfirst probing method designed to learn from the weights of just a single model\nlayer. We also construct and release a dataset that simulates the structure of\npublic model repositories. Our results show that ProbeX can effectively map the\nweights of large models into a shared weight-language embedding space.\nFurthermore, we demonstrate the impressive generalization of our method,\nachieving zero-shot model classification and retrieval.\n","authors":["Eliahu Horwitz","Bar Cavia","Jonathan Kahana","Yedid Hoshen"],"pdf_url":"https://arxiv.org/pdf/2410.13569v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.13760v1","updated":"2024-10-17T16:55:14Z","published":"2024-10-17T16:55:14Z","title":"Eyelid Fold Consistency in Facial Modeling","summary":"  Eyelid shape is integral to identity and likeness in human facial modeling.\nHuman eyelids are diverse in appearance with varied skin fold and epicanthal\nfold morphology between individuals. Existing parametric face models express\neyelid shape variation to an extent, but do not preserve sufficient likeness\nacross a diverse range of individuals. We propose a new definition of eyelid\nfold consistency and implement geometric processing techniques to model diverse\neyelid shapes in a unified topology. Using this method we reprocess data used\nto train a parametric face model and demonstrate significant improvements in\nface-related machine learning tasks.\n","authors":["Lohit Petikam","Charlie Hewitt","Fatemeh Saleh","Tadas Baltrušaitis"],"pdf_url":"https://arxiv.org/pdf/2410.13760v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2402.14015v2","updated":"2024-10-17T16:47:51Z","published":"2024-02-21T18:54:37Z","title":"Corrective Machine Unlearning","summary":"  Machine Learning models increasingly face data integrity challenges due to\nthe use of large-scale training datasets drawn from the Internet. We study what\nmodel developers can do if they detect that some data was manipulated or\nincorrect. Such manipulated data can cause adverse effects including\nvulnerability to backdoored samples, systemic biases, and reduced accuracy on\ncertain input domains. Realistically, all manipulated training samples cannot\nbe identified, and only a small, representative subset of the affected data can\nbe flagged.\n  We formalize Corrective Machine Unlearning as the problem of mitigating the\nimpact of data affected by unknown manipulations on a trained model, only\nhaving identified a subset of the corrupted data. We demonstrate that the\nproblem of corrective unlearning has significantly different requirements from\ntraditional privacy-oriented unlearning. We find most existing unlearning\nmethods, including retraining-from-scratch without the deletion set, require\nmost of the manipulated data to be identified for effective corrective\nunlearning. However, one approach, Selective Synaptic Dampening, achieves\nlimited success, unlearning adverse effects with just a small portion of the\nmanipulated samples in our setting, which shows encouraging signs for future\nprogress. We hope our work spurs research towards developing better methods for\ncorrective unlearning and offers practitioners a new strategy to handle data\nintegrity challenges arising from web-scale training. Code is available at\nhttps://github.com/drimpossible/corrective-unlearning-bench.\n","authors":["Shashwat Goel","Ameya Prabhu","Philip Torr","Ponnurangam Kumaraguru","Amartya Sanyal"],"pdf_url":"https://arxiv.org/pdf/2402.14015v2.pdf","comment":"Published in Transactions of Machine Learning Research (TMLR), 17\n  pages, 7 figures"},{"id":"http://arxiv.org/abs/2410.13733v1","updated":"2024-10-17T16:36:38Z","published":"2024-10-17T16:36:38Z","title":"Improving Multi-modal Large Language Model through Boosting Vision\n  Capabilities","summary":"  We focus on improving the visual understanding capability for boosting the\nvision-language models. We propose \\textbf{Arcana}, a multiModal language\nmodel, which introduces two crucial techniques. First, we present Multimodal\nLoRA (MM-LoRA), a module designed to enhance the decoder. Unlike traditional\nlanguage-driven decoders, MM-LoRA consists of two parallel LoRAs -- one for\nvision and one for language -- each with its own parameters. This disentangled\nparameters design allows for more specialized learning in each modality and\nbetter integration of multimodal information. Second, we introduce the Query\nLadder adapter (QLadder) to improve the visual encoder. QLadder employs a\nlearnable ``\\textit{ladder}'' structure to deeply aggregates the intermediate\nrepresentations from the frozen pretrained visual encoder (e.g., CLIP image\nencoder). This enables the model to learn new and informative visual features,\nas well as remaining the powerful capabilities of the pretrained visual\nencoder. These techniques collectively enhance Arcana's visual perception\npower, enabling it to leverage improved visual information for more accurate\nand contextually relevant outputs across various multimodal scenarios.\nExtensive experiments and ablation studies demonstrate the effectiveness and\ngeneralization capability of our Arcana. The code and re-annotated data are\navailable at \\url{https://arcana-project-page.github.io}.\n","authors":["Yanpeng Sun","Huaxin Zhang","Qiang Chen","Xinyu Zhang","Nong Sang","Gang Zhang","Jingdong Wang","Zechao Li"],"pdf_url":"https://arxiv.org/pdf/2410.13733v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.13726v1","updated":"2024-10-17T16:32:36Z","published":"2024-10-17T16:32:36Z","title":"DAWN: Dynamic Frame Avatar with Non-autoregressive Diffusion Framework\n  for Talking Head Video Generation","summary":"  Talking head generation intends to produce vivid and realistic talking head\nvideos from a single portrait and speech audio clip. Although significant\nprogress has been made in diffusion-based talking head generation, almost all\nmethods rely on autoregressive strategies, which suffer from limited context\nutilization beyond the current generation step, error accumulation, and slower\ngeneration speed. To address these challenges, we present DAWN (Dynamic frame\nAvatar With Non-autoregressive diffusion), a framework that enables all-at-once\ngeneration of dynamic-length video sequences. Specifically, it consists of two\nmain components: (1) audio-driven holistic facial dynamics generation in the\nlatent motion space, and (2) audio-driven head pose and blink generation.\nExtensive experiments demonstrate that our method generates authentic and vivid\nvideos with precise lip motions, and natural pose/blink movements.\nAdditionally, with a high generation speed, DAWN possesses strong extrapolation\ncapabilities, ensuring the stable production of high-quality long videos. These\nresults highlight the considerable promise and potential impact of DAWN in the\nfield of talking head video generation. Furthermore, we hope that DAWN sparks\nfurther exploration of non-autoregressive approaches in diffusion models. Our\ncode will be publicly at https://github.com/Hanbo-Cheng/DAWN-pytorch.\n","authors":["Hanbo Cheng","Limin Lin","Chenyu Liu","Pengcheng Xia","Pengfei Hu","Jiefeng Ma","Jun Du","Jia Pan"],"pdf_url":"https://arxiv.org/pdf/2410.13726v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.13720v1","updated":"2024-10-17T16:22:46Z","published":"2024-10-17T16:22:46Z","title":"Movie Gen: A Cast of Media Foundation Models","summary":"  We present Movie Gen, a cast of foundation models that generates\nhigh-quality, 1080p HD videos with different aspect ratios and synchronized\naudio. We also show additional capabilities such as precise instruction-based\nvideo editing and generation of personalized videos based on a user's image.\nOur models set a new state-of-the-art on multiple tasks: text-to-video\nsynthesis, video personalization, video editing, video-to-audio generation, and\ntext-to-audio generation. Our largest video generation model is a 30B parameter\ntransformer trained with a maximum context length of 73K video tokens,\ncorresponding to a generated video of 16 seconds at 16 frames-per-second. We\nshow multiple technical innovations and simplifications on the architecture,\nlatent spaces, training objectives and recipes, data curation, evaluation\nprotocols, parallelization techniques, and inference optimizations that allow\nus to reap the benefits of scaling pre-training data, model size, and training\ncompute for training large scale media generation models. We hope this paper\nhelps the research community to accelerate progress and innovation in media\ngeneration models. All videos from this paper are available at\nhttps://go.fb.me/MovieGenResearchVideos.\n","authors":["Adam Polyak","Amit Zohar","Andrew Brown","Andros Tjandra","Animesh Sinha","Ann Lee","Apoorv Vyas","Bowen Shi","Chih-Yao Ma","Ching-Yao Chuang","David Yan","Dhruv Choudhary","Dingkang Wang","Geet Sethi","Guan Pang","Haoyu Ma","Ishan Misra","Ji Hou","Jialiang Wang","Kiran Jagadeesh","Kunpeng Li","Luxin Zhang","Mannat Singh","Mary Williamson","Matt Le","Matthew Yu","Mitesh Kumar Singh","Peizhao Zhang","Peter Vajda","Quentin Duval","Rohit Girdhar","Roshan Sumbaly","Sai Saketh Rambhatla","Sam Tsai","Samaneh Azadi","Samyak Datta","Sanyuan Chen","Sean Bell","Sharadh Ramaswamy","Shelly Sheynin","Siddharth Bhattacharya","Simran Motwani","Tao Xu","Tianhe Li","Tingbo Hou","Wei-Ning Hsu","Xi Yin","Xiaoliang Dai","Yaniv Taigman","Yaqiao Luo","Yen-Cheng Liu","Yi-Chiao Wu","Yue Zhao","Yuval Kirstain","Zecheng He","Zijian He","Albert Pumarola","Ali Thabet","Artsiom Sanakoyeu","Arun Mallya","Baishan Guo","Boris Araya","Breena Kerr","Carleigh Wood","Ce Liu","Cen Peng","Dimitry Vengertsev","Edgar Schonfeld","Elliot Blanchard","Felix Juefei-Xu","Fraylie Nord","Jeff Liang","John Hoffman","Jonas Kohler","Kaolin Fire","Karthik Sivakumar","Lawrence Chen","Licheng Yu","Luya Gao","Markos Georgopoulos","Rashel Moritz","Sara K. Sampson","Shikai Li","Simone Parmeggiani","Steve Fine","Tara Fowler","Vladan Petrovic","Yuming Du"],"pdf_url":"https://arxiv.org/pdf/2410.13720v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.11092v2","updated":"2024-10-17T16:13:49Z","published":"2024-10-14T21:10:56Z","title":"EchoApex: A General-Purpose Vision Foundation Model for Echocardiography","summary":"  Quantitative evaluation of echocardiography is essential for precise\nassessment of cardiac condition, monitoring disease progression, and guiding\ntreatment decisions. The diverse nature of echo images, including variations in\nprobe types, manufacturers, and pathologies, poses challenges for developing\nartificial intelligent models that can generalize across different clinical\npractice. We introduce EchoApex, the first general-purpose vision foundation\nmodel echocardiography with applications on a variety of clinical practice.\nLeveraging self-supervised learning, EchoApex is pretrained on over 20 million\necho images from 11 clinical centres. By incorporating task-specific decoders\nand adapter modules, we demonstrate the effectiveness of EchoApex on 4\ndifferent kind of clinical applications with 28 sub-tasks, including view\nclassification, interactive structure segmentation, left ventricle hypertrophy\ndetection and automated ejection fraction estimation from view sequences.\nCompared to state-of-the-art task-specific models, EchoApex attains improved\nperformance with a unified image encoding architecture, demonstrating the\nbenefits of model pretraining at scale with in-domain data. Furthermore,\nEchoApex illustrates the potential for developing a general-purpose vision\nfoundation model tailored specifically for echocardiography, capable of\naddressing a diverse range of clinical applications with high efficiency and\nefficacy.\n","authors":["Abdoul Aziz Amadou","Yue Zhang","Sebastien Piat","Paul Klein","Ingo Schmuecking","Tiziano Passerini","Puneet Sharma"],"pdf_url":"https://arxiv.org/pdf/2410.11092v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2407.12040v5","updated":"2024-10-17T16:11:43Z","published":"2024-07-01T17:59:55Z","title":"Comprehensive Performance Evaluation of YOLO11, YOLOv10, YOLOv9 and\n  YOLOv8 on Detecting and Counting Fruitlet in Complex Orchard Environments","summary":"  This study extensively evaluated You Only Look Once (YOLO) object detection\nalgorithms across all configurations (total 22) of YOLOv8, YOLOv9, YOLOv10, and\nYOLO11 for green fruit detection in commercial orchards. The research also\nvalidated in-field fruitlet counting using an iPhone and machine vision sensors\nacross four apple varieties: Scifresh, Scilate, Honeycrisp and Cosmic Crisp.\nAmong the 22 configurations evaluated, YOLO11s and YOLOv9 gelan-base\noutperformed others with mAP@50 scores of 0.933 and 0.935 respectively. In\nterms of recall, YOLOv9 gelan-base achieved the highest value among YOLOv9\nconfigurations at 0.899, while YOLO11m led YOLO11 variants with 0.897. YOLO11n\nemerged as the fastest model, achieving fastest inference speed of only 2.4 ms,\nsignificantly outpacing the leading configurations of YOLOv10n, YOLOv9 gelan-s,\nand YOLOv8n, with speeds of 5.5, 11.5, and 4.1 ms, respectively. This\ncomparative evaluation highlights the strengths of YOLO11, YOLOv9, and YOLOv10,\noffering researchers essential insights to choose the best-suited model for\nfruitlet detection and possible automation in commercial orchards. For\nreal-time automation related work in relevant datasets, we recommend using\nYOLO11n due to its high detection and image processing speed. Keywords: YOLO11,\nYOLO11 Object Detection, YOLOv10, YOLOv9, YOLOv8, You Only Look Once, Fruitlet\nDetection, Greenfruit Detection, Green Apple Detection, Agricultural\nAutomation, Artificial Intelligence, Deep Learning, Machine Learning, Zero-shot\nDetection\n","authors":["Ranjan Sapkota","Zhichao Meng","Martin Churuvija","Xiaoqiang Du","Zenghong Ma","Manoj Karkee"],"pdf_url":"https://arxiv.org/pdf/2407.12040v5.pdf","comment":"15 figures, 2 tables"},{"id":"http://arxiv.org/abs/2406.10322v2","updated":"2024-10-17T16:06:18Z","published":"2024-06-14T17:41:55Z","title":"LieRE: Generalizing Rotary Position Encodings","summary":"  While Rotary Position Embeddings (RoPE) for large language models have become\nwidely adopted, their application for other modalities has been slower. Here,\nwe introduce Lie group Relative position Encodings (LieRE) that goes beyond\nRoPE in supporting n-dimensional inputs. We evaluate the performance of LieRE\non 2D and 3D image classification tasks and observe that LieRE leads to marked\nrelative improvements in performance (up to 9.7% for 2D and up to 25.5% for\n3D), training efficiency (3.5x reduction), data efficiency (30%) compared to\nthe baselines of DeiT III, RoPE-Mixed and Vision-Llama.\nhttps://github.com/Stanford-AIMI/LieRE\n","authors":["Sophie Ostmeier","Brian Axelrod","Michael E. Moseley","Akshay Chaudhari","Curtis Langlotz"],"pdf_url":"https://arxiv.org/pdf/2406.10322v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.13694v1","updated":"2024-10-17T15:59:52Z","published":"2024-10-17T15:59:52Z","title":"Exploring the Design Space of Visual Context Representation in Video\n  MLLMs","summary":"  Video Multimodal Large Language Models (MLLMs) have shown remarkable\ncapability of understanding the video semantics on various downstream tasks.\nDespite the advancements, there is still a lack of systematic research on\nvisual context representation, which refers to the scheme to select frames from\na video and further select the tokens from a frame. In this paper, we explore\nthe design space for visual context representation, and aim to improve the\nperformance of video MLLMs by finding more effective representation schemes.\nFirstly, we formulate the task of visual context representation as a\nconstrained optimization problem, and model the language modeling loss as a\nfunction of the number of frames and the number of embeddings (or tokens) per\nframe, given the maximum visual context window size. Then, we explore the\nscaling effects in frame selection and token selection respectively, and fit\nthe corresponding function curve by conducting extensive empirical experiments.\nWe examine the effectiveness of typical selection strategies and present\nempirical findings to determine the two factors. Furthermore, we study the\njoint effect of frame selection and token selection, and derive the optimal\nformula for determining the two factors. We demonstrate that the derived\noptimal settings show alignment with the best-performed results of empirical\nexperiments. Our code and model are available at:\nhttps://github.com/RUCAIBox/Opt-Visor.\n","authors":["Yifan Du","Yuqi Huo","Kun Zhou","Zijia Zhao","Haoyu Lu","Han Huang","Wayne Xin Zhao","Bingning Wang","Weipeng Chen","Ji-Rong Wen"],"pdf_url":"https://arxiv.org/pdf/2410.13694v1.pdf","comment":"Long Video MLLM; work in progress"},{"id":"http://arxiv.org/abs/2410.13685v1","updated":"2024-10-17T15:47:12Z","published":"2024-10-17T15:47:12Z","title":"Label-free prediction of fluorescence markers in bovine satellite cells\n  using deep learning","summary":"  Assessing the quality of bovine satellite cells (BSCs) is essential for the\ncultivated meat industry, which aims to address global food sustainability\nchallenges. This study aims to develop a label-free method for predicting\nfluorescence markers in isolated BSCs using deep learning. We employed a\nU-Net-based CNN model to predict multiple fluorescence signals from a single\nbright-field microscopy image of cell culture. Two key biomarkers, DAPI and\nPax7, were used to determine the abundance and quality of BSCs. The image\npre-processing pipeline included fluorescence denoising to improve prediction\nperformance and consistency. A total of 48 biological replicates were used,\nwith statistical performance metrics such as Pearson correlation coefficient\nand SSIM employed for model evaluation. The model exhibited better performance\nwith DAPI predictions due to uniform staining. Pax7 predictions were more\nvariable, reflecting biological heterogeneity. Enhanced visualization\ntechniques, including color mapping and image overlay, improved the\ninterpretability of the predictions by providing better contextual and\nperceptual information. The findings highlight the importance of data\npre-processing and demonstrate the potential of deep learning to advance\nnon-invasive, label-free assessment techniques in the cultivated meat industry,\npaving the way for reliable and actionable AI-driven evaluations.\n","authors":["Sania Sinha","Aarham Wasit","Won Seob Kim","Jongkyoo Kim","Jiyoon Yi"],"pdf_url":"https://arxiv.org/pdf/2410.13685v1.pdf","comment":"11 pages, 4 figures"},{"id":"http://arxiv.org/abs/2402.13251v3","updated":"2024-10-17T15:45:06Z","published":"2024-02-20T18:59:00Z","title":"FlashTex: Fast Relightable Mesh Texturing with LightControlNet","summary":"  Manually creating textures for 3D meshes is time-consuming, even for expert\nvisual content creators. We propose a fast approach for automatically texturing\nan input 3D mesh based on a user-provided text prompt. Importantly, our\napproach disentangles lighting from surface material/reflectance in the\nresulting texture so that the mesh can be properly relit and rendered in any\nlighting environment. We introduce LightControlNet, a new text-to-image model\nbased on the ControlNet architecture, which allows the specification of the\ndesired lighting as a conditioning image to the model. Our text-to-texture\npipeline then constructs the texture in two stages. The first stage produces a\nsparse set of visually consistent reference views of the mesh using\nLightControlNet. The second stage applies a texture optimization based on Score\nDistillation Sampling (SDS) that works with LightControlNet to increase the\ntexture quality while disentangling surface material from lighting. Our\nalgorithm is significantly faster than previous text-to-texture methods, while\nproducing high-quality and relightable textures.\n","authors":["Kangle Deng","Timothy Omernick","Alexander Weiss","Deva Ramanan","Jun-Yan Zhu","Tinghui Zhou","Maneesh Agrawala"],"pdf_url":"https://arxiv.org/pdf/2402.13251v3.pdf","comment":"Project page: https://flashtex.github.io/"},{"id":"http://arxiv.org/abs/2410.13675v1","updated":"2024-10-17T15:33:54Z","published":"2024-10-17T15:33:54Z","title":"Pose-Based Sign Language Appearance Transfer","summary":"  We introduce a method for transferring the signer's appearance in sign\nlanguage skeletal poses while preserving the sign content. Using estimated\nposes, we transfer the appearance of one signer to another, maintaining natural\nmovements and transitions. This approach improves pose-based rendering and sign\nstitching while obfuscating identity. Our experiments show that while the\nmethod reduces signer identification accuracy, it slightly harms sign\nrecognition performance, highlighting a tradeoff between privacy and utility.\nOur code is available at\n\\url{https://github.com/sign-language-processing/pose-anonymization}.\n","authors":["Amit Moryossef","Gerard Sant","Zifan Jiang"],"pdf_url":"https://arxiv.org/pdf/2410.13675v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.13674v1","updated":"2024-10-17T15:33:35Z","published":"2024-10-17T15:33:35Z","title":"Diffusion Curriculum: Synthetic-to-Real Generative Curriculum Learning\n  via Image-Guided Diffusion","summary":"  Low-quality or scarce data has posed significant challenges for training deep\nneural networks in practice. While classical data augmentation cannot\ncontribute very different new data, diffusion models opens up a new door to\nbuild self-evolving AI by generating high-quality and diverse synthetic data\nthrough text-guided prompts. However, text-only guidance cannot control\nsynthetic images' proximity to the original images, resulting in\nout-of-distribution data detrimental to the model performance. To overcome the\nlimitation, we study image guidance to achieve a spectrum of interpolations\nbetween synthetic and real images. With stronger image guidance, the generated\nimages are similar to the training data but hard to learn. While with weaker\nimage guidance, the synthetic images will be easier for model but contribute to\na larger distribution gap with the original data. The generated full spectrum\nof data enables us to build a novel \"Diffusion Curriculum (DisCL)\". DisCL\nadjusts the image guidance level of image synthesis for each training stage: It\nidentifies and focuses on hard samples for the model and assesses the most\neffective guidance level of synthetic images to improve hard data learning. We\napply DisCL to two challenging tasks: long-tail (LT) classification and\nlearning from low-quality data. It focuses on lower-guidance images of\nhigh-quality to learn prototypical features as a warm-up of learning\nhigher-guidance images that might be weak on diversity or quality. Extensive\nexperiments showcase a gain of 2.7% and 2.1% in OOD and ID macro-accuracy when\napplying DisCL to iWildCam dataset. On ImageNet-LT, DisCL improves the base\nmodel's tail-class accuracy from 4.4% to 23.64% and leads to a 4.02%\nimprovement in all-class accuracy.\n","authors":["Yijun Liang","Shweta Bhardwaj","Tianyi Zhou"],"pdf_url":"https://arxiv.org/pdf/2410.13674v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2405.16005v3","updated":"2024-10-17T15:28:15Z","published":"2024-05-25T02:02:08Z","title":"PTQ4DiT: Post-training Quantization for Diffusion Transformers","summary":"  The recent introduction of Diffusion Transformers (DiTs) has demonstrated\nexceptional capabilities in image generation by using a different backbone\narchitecture, departing from traditional U-Nets and embracing the scalable\nnature of transformers. Despite their advanced capabilities, the wide\ndeployment of DiTs, particularly for real-time applications, is currently\nhampered by considerable computational demands at the inference stage.\nPost-training Quantization (PTQ) has emerged as a fast and data-efficient\nsolution that can significantly reduce computation and memory footprint by\nusing low-bit weights and activations. However, its applicability to DiTs has\nnot yet been explored and faces non-trivial difficulties due to the unique\ndesign of DiTs. In this paper, we propose PTQ4DiT, a specifically designed PTQ\nmethod for DiTs. We discover two primary quantization challenges inherent in\nDiTs, notably the presence of salient channels with extreme magnitudes and the\ntemporal variability in distributions of salient activation over multiple\ntimesteps. To tackle these challenges, we propose Channel-wise Salience\nBalancing (CSB) and Spearmen's $\\rho$-guided Salience Calibration (SSC). CSB\nleverages the complementarity property of channel magnitudes to redistribute\nthe extremes, alleviating quantization errors for both activations and weights.\nSSC extends this approach by dynamically adjusting the balanced salience to\ncapture the temporal variations in activation. Additionally, to eliminate extra\ncomputational costs caused by PTQ4DiT during inference, we design an offline\nre-parameterization strategy for DiTs. Experiments demonstrate that our PTQ4DiT\nsuccessfully quantizes DiTs to 8-bit precision (W8A8) while preserving\ncomparable generation ability and further enables effective quantization to\n4-bit weight precision (W4A8) for the first time.\n","authors":["Junyi Wu","Haoxuan Wang","Yuzhang Shang","Mubarak Shah","Yan Yan"],"pdf_url":"https://arxiv.org/pdf/2405.16005v3.pdf","comment":"NeurIPS 2024. Code is available at\n  https://github.com/adreamwu/PTQ4DiT"},{"id":"http://arxiv.org/abs/2410.13666v1","updated":"2024-10-17T15:27:17Z","published":"2024-10-17T15:27:17Z","title":"VL-GLUE: A Suite of Fundamental yet Challenging Visuo-Linguistic\n  Reasoning Tasks","summary":"  Deriving inference from heterogeneous inputs (such as images, text, and\naudio) is an important skill for humans to perform day-to-day tasks. A similar\nability is desirable for the development of advanced Artificial Intelligence\n(AI) systems. While state-of-the-art models are rapidly closing the gap with\nhuman-level performance on diverse computer vision and NLP tasks separately,\nthey struggle to solve tasks that require joint reasoning over visual and\ntextual modalities. Inspired by GLUE (Wang et. al., 2018)- a multitask\nbenchmark for natural language understanding, we propose VL-GLUE in this paper.\nVL-GLUE consists of over 100k samples spanned across seven different tasks,\nwhich at their core require visuo-linguistic reasoning. Moreover, our benchmark\ncomprises of diverse image types (from synthetically rendered figures, and\nday-to-day scenes to charts and complex diagrams) and includes a broad variety\nof domain-specific text (from cooking, politics, and sports to high-school\ncurricula), demonstrating the need for multi-modal understanding in the\nreal-world. We show that this benchmark is quite challenging for existing\nlarge-scale vision-language models and encourage development of systems that\npossess robust visuo-linguistic reasoning capabilities.\n","authors":["Shailaja Keyur Sampat","Mutsumi Nakamura","Shankar Kailas","Kartik Aggarwal","Mandy Zhou","Yezhou Yang","Chitta Baral"],"pdf_url":"https://arxiv.org/pdf/2410.13666v1.pdf","comment":"18 pages, 7 figures"},{"id":"http://arxiv.org/abs/2410.13663v1","updated":"2024-10-17T15:25:13Z","published":"2024-10-17T15:25:13Z","title":"DiRecNetV2: A Transformer-Enhanced Network for Aerial Disaster\n  Recognition","summary":"  The integration of Unmanned Aerial Vehicles (UAVs) with artificial\nintelligence (AI) models for aerial imagery processing in disaster assessment,\nnecessitates models that demonstrate exceptional accuracy, computational\nefficiency, and real-time processing capabilities. Traditionally Convolutional\nNeural Networks (CNNs), demonstrate efficiency in local feature extraction but\nare limited by their potential for global context interpretation. On the other\nhand, Vision Transformers (ViTs) show promise for improved global context\ninterpretation through the use of attention mechanisms, although they still\nremain underinvestigated in UAV-based disaster response applications. Bridging\nthis research gap, we introduce DiRecNetV2, an improved hybrid model that\nutilizes convolutional and transformer layers. It merges the inductive biases\nof CNNs for robust feature extraction with the global context understanding of\nTransformers, maintaining a low computational load ideal for UAV applications.\nAdditionally, we introduce a new, compact multi-label dataset of disasters, to\nset an initial benchmark for future research, exploring how models trained on\nsingle-label data perform in a multi-label test set. The study assesses\nlightweight CNNs and ViTs on the AIDERSv2 dataset, based on the frames per\nsecond (FPS) for efficiency and the weighted F1 scores for classification\nperformance. DiRecNetV2 not only achieves a weighted F1 score of 0.964 on a\nsingle-label test set but also demonstrates adaptability, with a score of 0.614\non a complex multi-label test set, while functioning at 176.13 FPS on the\nNvidia Orin Jetson device.\n","authors":["Demetris Shianios","Panayiotis Kolios","Christos Kyrkou"],"pdf_url":"https://arxiv.org/pdf/2410.13663v1.pdf","comment":"23 pages"},{"id":"http://arxiv.org/abs/2410.13662v1","updated":"2024-10-17T15:22:57Z","published":"2024-10-17T15:22:57Z","title":"ActionCOMET: A Zero-shot Approach to Learn Image-specific Commonsense\n  Concepts about Actions","summary":"  Humans observe various actions being performed by other humans (physically or\nin videos/images) and can draw a wide range of inferences about it beyond what\nthey can visually perceive. Such inferences include determining the aspects of\nthe world that make action execution possible (e.g. liquid objects can undergo\npouring), predicting how the world will change as a result of the action (e.g.\npotatoes being golden and crispy after frying), high-level goals associated\nwith the action (e.g. beat the eggs to make an omelet) and reasoning about\nactions that possibly precede or follow the current action (e.g. crack eggs\nbefore whisking or draining pasta after boiling). Similar reasoning ability is\nhighly desirable in autonomous systems that would assist us in performing\neveryday tasks. To that end, we propose a multi-modal task to learn\naforementioned concepts about actions being performed in images. We develop a\ndataset consisting of 8.5k images and 59.3k inferences about actions grounded\nin those images, collected from an annotated cooking-video dataset. We propose\nActionCOMET, a zero-shot framework to discern knowledge present in language\nmodels specific to the provided visual input. We present baseline results of\nActionCOMET over the collected dataset and compare them with the performance of\nthe best existing VQA approaches.\n","authors":["Shailaja Keyur Sampat","Yezhou Yang","Chitta Baral"],"pdf_url":"https://arxiv.org/pdf/2410.13662v1.pdf","comment":"15 pages, 3 figures. arXiv admin note: text overlap with\n  arXiv:2004.10796 by other authors"},{"id":"http://arxiv.org/abs/2410.13651v1","updated":"2024-10-17T15:16:10Z","published":"2024-10-17T15:16:10Z","title":"Help Me Identify: Is an LLM+VQA System All We Need to Identify Visual\n  Concepts?","summary":"  An ability to learn about new objects from a small amount of visual data and\nproduce convincing linguistic justification about the presence/absence of\ncertain concepts (that collectively compose the object) in novel scenarios is\nan important characteristic of human cognition. This is possible due to\nabstraction of attributes/properties that an object is composed of e.g. an\nobject `bird' can be identified by the presence of a beak, feathers, legs,\nwings, etc. Inspired by this aspect of human reasoning, in this work, we\npresent a zero-shot framework for fine-grained visual concept learning by\nleveraging large language model and Visual Question Answering (VQA) system.\nSpecifically, we prompt GPT-3 to obtain a rich linguistic description of visual\nobjects in the dataset. We convert the obtained concept descriptions into a set\nof binary questions. We pose these questions along with the query image to a\nVQA system and aggregate the answers to determine the presence or absence of an\nobject in the test images. Our experiments demonstrate comparable performance\nwith existing zero-shot visual classification methods and few-shot concept\nlearning approaches, without substantial computational overhead, yet being\nfully explainable from the reasoning perspective.\n","authors":["Shailaja Keyur Sampat","Maitreya Patel","Yezhou Yang","Chitta Baral"],"pdf_url":"https://arxiv.org/pdf/2410.13651v1.pdf","comment":"14 pages, 7 figures"},{"id":"http://arxiv.org/abs/2407.03471v3","updated":"2024-10-17T15:12:44Z","published":"2024-07-03T19:36:33Z","title":"Learning Action and Reasoning-Centric Image Editing from Videos and\n  Simulations","summary":"  An image editing model should be able to perform diverse edits, ranging from\nobject replacement, changing attributes or style, to performing actions or\nmovement, which require many forms of reasoning. Current general\ninstruction-guided editing models have significant shortcomings with action and\nreasoning-centric edits. Object, attribute or stylistic changes can be learned\nfrom visually static datasets. On the other hand, high-quality data for action\nand reasoning-centric edits is scarce and has to come from entirely different\nsources that cover e.g. physical dynamics, temporality and spatial reasoning.\nTo this end, we meticulously curate the AURORA Dataset\n(Action-Reasoning-Object-Attribute), a collection of high-quality training\ndata, human-annotated and curated from videos and simulation engines. We focus\non a key aspect of quality training data: triplets (source image, prompt,\ntarget image) contain a single meaningful visual change described by the\nprompt, i.e., truly minimal changes between source and target images. To\ndemonstrate the value of our dataset, we evaluate an AURORA-finetuned model on\na new expert-curated benchmark (AURORA-Bench) covering 8 diverse editing tasks.\nOur model significantly outperforms previous editing models as judged by human\nraters. For automatic evaluations, we find important flaws in previous metrics\nand caution their use for semantically hard editing tasks. Instead, we propose\na new automatic metric that focuses on discriminative understanding. We hope\nthat our efforts : (1) curating a quality training dataset and an evaluation\nbenchmark, (2) developing critical evaluations, and (3) releasing a\nstate-of-the-art model, will fuel further progress on general image editing.\n","authors":["Benno Krojer","Dheeraj Vattikonda","Luis Lara","Varun Jampani","Eva Portelance","Christopher Pal","Siva Reddy"],"pdf_url":"https://arxiv.org/pdf/2407.03471v3.pdf","comment":"NeurIPS 2024 (Dataset & Benchmarks)"},{"id":"http://arxiv.org/abs/2410.09913v2","updated":"2024-10-17T15:08:08Z","published":"2024-10-13T16:40:48Z","title":"Stratified Domain Adaptation: A Progressive Self-Training Approach for\n  Scene Text Recognition","summary":"  Unsupervised domain adaptation (UDA) has become increasingly prevalent in\nscene text recognition (STR), especially where training and testing data reside\nin different domains. The efficacy of existing UDA approaches tends to degrade\nwhen there is a large gap between the source and target domains. To deal with\nthis problem, gradually shifting or progressively learning to shift from domain\nto domain is the key issue. In this paper, we introduce the Stratified Domain\nAdaptation (StrDA) approach, which examines the gradual escalation of the\ndomain gap for the learning process. The objective is to partition the training\ndata into subsets so that the progressively self-trained model can adapt to\ngradual changes. We stratify the training data by evaluating the proximity of\neach data sample to both the source and target domains. We propose a novel\nmethod for employing domain discriminators to estimate the out-of-distribution\nand domain discriminative levels of data samples. Extensive experiments on\nbenchmark scene-text datasets show that our approach significantly improves the\nperformance of baseline (source-trained) STR models.\n","authors":["Kha Nhat Le","Hoang-Tuan Nguyen","Hung Tien Tran","Thanh Duc Ngo"],"pdf_url":"https://arxiv.org/pdf/2410.09913v2.pdf","comment":"15 pages, 12 figures, 5 tables, include supplementary materials"},{"id":"http://arxiv.org/abs/2407.04952v2","updated":"2024-10-17T14:58:53Z","published":"2024-07-06T04:06:55Z","title":"Granular Privacy Control for Geolocation with Vision Language Models","summary":"  Vision Language Models (VLMs) are rapidly advancing in their capability to\nanswer information-seeking questions. As these models are widely deployed in\nconsumer applications, they could lead to new privacy risks due to emergent\nabilities to identify people in photos, geolocate images, etc. As we\ndemonstrate, somewhat surprisingly, current open-source and proprietary VLMs\nare very capable image geolocators, making widespread geolocation with VLMs an\nimmediate privacy risk, rather than merely a theoretical future concern. As a\nfirst step to address this challenge, we develop a new benchmark, GPTGeoChat,\nto test the ability of VLMs to moderate geolocation dialogues with users. We\ncollect a set of 1,000 image geolocation conversations between in-house\nannotators and GPT-4v, which are annotated with the granularity of location\ninformation revealed at each turn. Using this new dataset, we evaluate the\nability of various VLMs to moderate GPT-4v geolocation conversations by\ndetermining when too much location information has been revealed. We find that\ncustom fine-tuned models perform on par with prompted API-based models when\nidentifying leaked location information at the country or city level; however,\nfine-tuning on supervised data appears to be needed to accurately moderate\nfiner granularities, such as the name of a restaurant or building.\n","authors":["Ethan Mendes","Yang Chen","James Hays","Sauvik Das","Wei Xu","Alan Ritter"],"pdf_url":"https://arxiv.org/pdf/2407.04952v2.pdf","comment":"Accepted to EMNLP 2024 main conference"},{"id":"http://arxiv.org/abs/2410.13621v1","updated":"2024-10-17T14:55:09Z","published":"2024-10-17T14:55:09Z","title":"Enhanced Prompt-leveraged Weakly Supervised Cancer Segmentation based on\n  Segment Anything","summary":"  This work proposes a novel approach beyond supervised learning for effective\npathological image analysis, addressing the challenge of limited robust labeled\ndata. Pathological diagnosis of diseases like cancer has conventionally relied\non the evaluation of morphological features by physicians and pathologists.\nHowever, recent advancements in compute-aided diagnosis (CAD) systems are\ngaining significant attention as diagnostic support tools. Although the\nadvancement of deep learning has improved CAD significantly, segmentation\nmodels typically require large pixel-level annotated dataset, and such labeling\nis expensive. Existing studies not based on supervised approaches still\nstruggle with limited generalization, and no practical approach has emerged\nyet. To address this issue, we present a weakly supervised semantic\nsegmentation (WSSS) model by combining class activation map and Segment\nAnything Model (SAM)-based pseudo-labeling. For effective pretraining, we adopt\nthe SAM-a foundation model that is pretrained on large datasets and operates in\nzero-shot configurations using only coarse prompts. The proposed approach\ntransfer enhanced Attention Dropout Layer's knowledge to SAM, thereby\ngenerating pseudo-labels. To demonstrate the superiority of the proposed\nmethod, experimental studies are conducted on histopathological breast cancer\ndatasets. The proposed method outperformed other WSSS methods across three\ndatasets, demonstrating its efficiency by achieving this with only 12GB of GPU\nmemory during training. Our code is available at :\nhttps://github.com/QI-NemoSong/EPLC-SAM\n","authors":["Joonhyeon Song","Seohwan Yun","Seongho Yoon","Joohyeok Kim","Sangmin Lee"],"pdf_url":"https://arxiv.org/pdf/2410.13621v1.pdf","comment":"10 pages, 7 figures"},{"id":"http://arxiv.org/abs/2410.13618v1","updated":"2024-10-17T14:51:17Z","published":"2024-10-17T14:51:17Z","title":"LoLDU: Low-Rank Adaptation via Lower-Diag-Upper Decomposition for\n  Parameter-Efficient Fine-Tuning","summary":"  The rapid growth of model scale has necessitated substantial computational\nresources for fine-tuning. Existing approach such as Low-Rank Adaptation (LoRA)\nhas sought to address the problem of handling the large updated parameters in\nfull fine-tuning. However, LoRA utilize random initialization and optimization\nof low-rank matrices to approximate updated weights, which can result in\nsuboptimal convergence and an accuracy gap compared to full fine-tuning. To\naddress these issues, we propose LoLDU, a Parameter-Efficient Fine-Tuning\n(PEFT) approach that significantly reduces trainable parameters by 2600 times\ncompared to regular PEFT methods while maintaining comparable performance.\nLoLDU leverages Lower-Diag-Upper Decomposition (LDU) to initialize low-rank\nmatrices for faster convergence and orthogonality. We focus on optimizing the\ndiagonal matrix for scaling transformations. To the best of our knowledge,\nLoLDU has the fewest parameters among all PEFT approaches. We conducted\nextensive experiments across 4 instruction-following datasets, 6 natural\nlanguage understanding (NLU) datasets, 8 image classification datasets, and\nimage generation datasets with multiple model types (LLaMA2, RoBERTa, ViT, and\nStable Diffusion), providing a comprehensive and detailed analysis. Our\nopen-source code can be accessed at\n\\href{https://github.com/SKDDJ/LoLDU}{https://github.com/SKDDJ/LoLDU}.\n","authors":["Yiming Shi","Jiwei Wei","Yujia Wu","Ran Ran","Chengwei Sun","Shiyuan He","Yang Yang"],"pdf_url":"https://arxiv.org/pdf/2410.13618v1.pdf","comment":"13 pages, 7 figures"},{"id":"http://arxiv.org/abs/2410.13616v1","updated":"2024-10-17T14:49:37Z","published":"2024-10-17T14:49:37Z","title":"Spatiotemporal Object Detection for Improved Aerial Vehicle Detection in\n  Traffic Monitoring","summary":"  This work presents advancements in multi-class vehicle detection using UAV\ncameras through the development of spatiotemporal object detection models. The\nstudy introduces a Spatio-Temporal Vehicle Detection Dataset (STVD) containing\n6, 600 annotated sequential frame images captured by UAVs, enabling\ncomprehensive training and evaluation of algorithms for holistic spatiotemporal\nperception. A YOLO-based object detection algorithm is enhanced to incorporate\ntemporal dynamics, resulting in improved performance over single frame models.\nThe integration of attention mechanisms into spatiotemporal models is shown to\nfurther enhance performance. Experimental validation demonstrates significant\nprogress, with the best spatiotemporal model exhibiting a 16.22% improvement\nover single frame models, while it is demonstrated that attention mechanisms\nhold the potential for additional performance gains.\n","authors":["Kristina Telegraph","Christos Kyrkou"],"pdf_url":"https://arxiv.org/pdf/2410.13616v1.pdf","comment":"13 pages"},{"id":"http://arxiv.org/abs/2410.13615v1","updated":"2024-10-17T14:47:53Z","published":"2024-10-17T14:47:53Z","title":"Material Fingerprinting: Identifying and Predicting Perceptual\n  Attributes of Material Appearance","summary":"  The world is abundant with diverse materials, each possessing unique surface\nappearances that play a crucial role in our daily perception and understanding\nof their properties. Despite advancements in technology enabling the capture\nand realistic reproduction of material appearances for visualization and\nquality control, the interoperability of material property information across\nvarious measurement representations and software platforms remains a complex\nchallenge. A key to overcoming this challenge lies in the automatic\nidentification of materials' perceptual features, enabling intuitive\ndifferentiation of properties stored in disparate material data\nrepresentations. We reasoned that for many practical purposes, a compact\nrepresentation of the perceptual appearance is more useful than an exhaustive\nphysical description.This paper introduces a novel approach to material\nidentification by encoding perceptual features obtained from dynamic visual\nstimuli. We conducted a psychophysical experiment to select and validate 16\nparticularly significant perceptual attributes obtained from videos of 347\nmaterials. We then gathered attribute ratings from over twenty participants for\neach material, creating a 'material fingerprint' that encodes the unique\nperceptual properties of each material. Finally, we trained a multi-layer\nperceptron model to predict the relationship between statistical and deep\nlearning image features and their corresponding perceptual properties. We\ndemonstrate the model's performance in material retrieval and filtering\naccording to individual attributes. This model represents a significant step\ntowards simplifying the sharing and understanding of material properties in\ndiverse digital environments regardless of their digital representation,\nenhancing both the accuracy and efficiency of material identification.\n","authors":["Jiri Filip","Filip Dechterenko","Filipp Schmidt","Jiri Lukavsky","Veronika Vilimovska","Jan Kotera","Roland W. Fleming"],"pdf_url":"https://arxiv.org/pdf/2410.13615v1.pdf","comment":"14 pages, 12 figures, 3 tables"},{"id":"http://arxiv.org/abs/2410.13613v1","updated":"2024-10-17T14:47:08Z","published":"2024-10-17T14:47:08Z","title":"MEGA: Memory-Efficient 4D Gaussian Splatting for Dynamic Scenes","summary":"  4D Gaussian Splatting (4DGS) has recently emerged as a promising technique\nfor capturing complex dynamic 3D scenes with high fidelity. It utilizes a 4D\nGaussian representation and a GPU-friendly rasterizer, enabling rapid rendering\nspeeds. Despite its advantages, 4DGS faces significant challenges, notably the\nrequirement of millions of 4D Gaussians, each with extensive associated\nattributes, leading to substantial memory and storage cost. This paper\nintroduces a memory-efficient framework for 4DGS. We streamline the color\nattribute by decomposing it into a per-Gaussian direct color component with\nonly 3 parameters and a shared lightweight alternating current color predictor.\nThis approach eliminates the need for spherical harmonics coefficients, which\ntypically involve up to 144 parameters in classic 4DGS, thereby creating a\nmemory-efficient 4D Gaussian representation. Furthermore, we introduce an\nentropy-constrained Gaussian deformation technique that uses a deformation\nfield to expand the action range of each Gaussian and integrates an\nopacity-based entropy loss to limit the number of Gaussians, thus forcing our\nmodel to use as few Gaussians as possible to fit a dynamic scene well. With\nsimple half-precision storage and zip compression, our framework achieves a\nstorage reduction by approximately 190$\\times$ and 125$\\times$ on the\nTechnicolor and Neural 3D Video datasets, respectively, compared to the\noriginal 4DGS. Meanwhile, it maintains comparable rendering speeds and scene\nrepresentation quality, setting a new standard in the field.\n","authors":["Xinjie Zhang","Zhening Liu","Yifan Zhang","Xingtong Ge","Dailan He","Tongda Xu","Yan Wang","Zehong Lin","Shuicheng Yan","Jun Zhang"],"pdf_url":"https://arxiv.org/pdf/2410.13613v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.13611v1","updated":"2024-10-17T14:46:34Z","published":"2024-10-17T14:46:34Z","title":"H2OVL-Mississippi Vision Language Models Technical Report","summary":"  Smaller vision-language models (VLMs) are becoming increasingly important for\nprivacy-focused, on-device applications due to their ability to run efficiently\non consumer hardware for processing enterprise commercial documents and images.\nThese models require strong language understanding and visual capabilities to\nenhance human-machine interaction. To address this need, we present\nH2OVL-Mississippi, a pair of small VLMs trained on 37 million image-text pairs\nusing 240 hours of compute on 8 x H100 GPUs. H2OVL-Mississippi-0.8B is a tiny\nmodel with 0.8 billion parameters that specializes in text recognition,\nachieving state of the art performance on the Text Recognition portion of\nOCRBench and surpassing much larger models in this area. Additionally, we are\nreleasing H2OVL-Mississippi-2B, a 2 billion parameter model for general use\ncases, exhibiting highly competitive metrics across various academic\nbenchmarks. Both models build upon our prior work with H2O-Danube language\nmodels, extending their capabilities into the visual domain. We release them\nunder the Apache 2.0 license, making VLMs accessible to everyone, democratizing\ndocument AI and visual LLMs.\n","authors":["Shaikat Galib","Shanshan Wang","Guanshuo Xu","Pascal Pfeiffer","Ryan Chesler","Mark Landry","Sri Satish Ambati"],"pdf_url":"https://arxiv.org/pdf/2410.13611v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.13607v1","updated":"2024-10-17T14:43:07Z","published":"2024-10-17T14:43:07Z","title":"DN-4DGS: Denoised Deformable Network with Temporal-Spatial Aggregation\n  for Dynamic Scene Rendering","summary":"  Dynamic scenes rendering is an intriguing yet challenging problem. Although\ncurrent methods based on NeRF have achieved satisfactory performance, they\nstill can not reach real-time levels. Recently, 3D Gaussian Splatting (3DGS)\nhas gar?nered researchers attention due to their outstanding rendering quality\nand real?time speed. Therefore, a new paradigm has been proposed: defining a\ncanonical 3D gaussians and deforming it to individual frames in deformable\nfields. How?ever, since the coordinates of canonical 3D gaussians are filled\nwith noise, which can transfer noise into the deformable fields, and there is\ncurrently no method that adequately considers the aggregation of 4D\ninformation. Therefore, we pro?pose Denoised Deformable Network with\nTemporal-Spatial Aggregation for Dy?namic Scene Rendering (DN-4DGS).\nSpecifically, a Noise Suppression Strategy is introduced to change the\ndistribution of the coordinates of the canonical 3D gaussians and suppress\nnoise. Additionally, a Decoupled Temporal-Spatial Ag?gregation Module is\ndesigned to aggregate information from adjacent points and frames. Extensive\nexperiments on various real-world datasets demonstrate that our method achieves\nstate-of-the-art rendering quality under a real-time level.\n","authors":["Jiahao Lu","Jiacheng Deng","Ruijie Zhu","Yanzhe Liang","Wenfei Yang","Tianzhu Zhang","Xu Zhou"],"pdf_url":"https://arxiv.org/pdf/2410.13607v1.pdf","comment":"Accepted by NeurIPS 2024"},{"id":"http://arxiv.org/abs/2410.13598v1","updated":"2024-10-17T14:31:02Z","published":"2024-10-17T14:31:02Z","title":"Let Me Finish My Sentence: Video Temporal Grounding with Holistic Text\n  Understanding","summary":"  Video Temporal Grounding (VTG) aims to identify visual frames in a video clip\nthat match text queries. Recent studies in VTG employ cross-attention to\ncorrelate visual frames and text queries as individual token sequences.\nHowever, these approaches overlook a crucial aspect of the problem: a holistic\nunderstanding of the query sentence. A model may capture correlations between\nindividual word tokens and arbitrary visual frames while possibly missing out\non the global meaning. To address this, we introduce two primary contributions:\n(1) a visual frame-level gate mechanism that incorporates holistic textual\ninformation, (2) cross-modal alignment loss to learn the fine-grained\ncorrelation between query and relevant frames. As a result, we regularize the\neffect of individual word tokens and suppress irrelevant visual frames. We\ndemonstrate that our method outperforms state-of-the-art approaches in VTG\nbenchmarks, indicating that holistic text understanding guides the model to\nfocus on the semantically important parts within the video.\n","authors":["Jongbhin Woo","Hyeonggon Ryu","Youngjoon Jang","Jae Won Cho","Joon Son Chung"],"pdf_url":"https://arxiv.org/pdf/2410.13598v1.pdf","comment":"Accepted by ACMMM 24"},{"id":"http://arxiv.org/abs/2410.13594v1","updated":"2024-10-17T14:28:11Z","published":"2024-10-17T14:28:11Z","title":"Deep-learning recognition and tracking of individual nanotubes in\n  low-contrast microscopy videos","summary":"  This study addresses the challenge of analyzing the growth kinetics of carbon\nnanotubes using in-situ homodyne polarization microscopy (HPM) by developing an\nautomated deep learning (DL) approach. A Mask-RCNN architecture, enhanced with\na ResNet-50 backbone, was employed to recognize and track individual nanotubes\nin microscopy videos, significantly improving the efficiency and\nreproducibility of kinetic data extraction. The method involves a series of\nvideo processing steps to enhance contrast and used differential treatment\ntechniques to manage low signal and fast kinetics. The DL model demonstrates\nconsistency with manual measurements and increased throughput, laying the\nfoundation for statistical studies of nanotube growth. The approach can be\nadapted for other types of in-situ microscopy studies, emphasizing the\nimportance of automation in high-throughput data acquisition for research on\nindividual nano-objects.\n","authors":["Vladimir Pimonov","Said Tahir","Vincent Jourdain"],"pdf_url":"https://arxiv.org/pdf/2410.13594v1.pdf","comment":"13 pages, 5 Figures, No supporting information included"},{"id":"http://arxiv.org/abs/2410.13585v1","updated":"2024-10-17T14:21:22Z","published":"2024-10-17T14:21:22Z","title":"Pseudo Dataset Generation for Out-of-Domain Multi-Camera View\n  Recommendation","summary":"  Multi-camera systems are indispensable in movies, TV shows, and other media.\nSelecting the appropriate camera at every timestamp has a decisive impact on\nproduction quality and audience preferences. Learning-based view recommendation\nframeworks can assist professionals in decision-making. However, they often\nstruggle outside of their training domains. The scarcity of labeled\nmulti-camera view recommendation datasets exacerbates the issue. Based on the\ninsight that many videos are edited from the original multi-camera videos, we\npropose transforming regular videos into pseudo-labeled multi-camera view\nrecommendation datasets. Promisingly, by training the model on pseudo-labeled\ndatasets stemming from videos in the target domain, we achieve a 68% relative\nimprovement in the model's accuracy in the target domain and bridge the\naccuracy gap between in-domain and never-before-seen domains.\n","authors":["Kuan-Ying Lee","Qian Zhou","Klara Nahrstedt"],"pdf_url":"https://arxiv.org/pdf/2410.13585v1.pdf","comment":"Accepted to VCIP 2024. Project page:\n  https://eric11220.github.io/publication/VCIP24/"},{"id":"http://arxiv.org/abs/2410.13582v1","updated":"2024-10-17T14:16:45Z","published":"2024-10-17T14:16:45Z","title":"Co-Segmentation without any Pixel-level Supervision with Application to\n  Large-Scale Sketch Classification","summary":"  This work proposes a novel method for object co-segmentation, i.e.\npixel-level localization of a common object in a set of images, that uses no\npixel-level supervision for training. Two pre-trained Vision Transformer (ViT)\nmodels are exploited: ImageNet classification-trained ViT, whose features are\nused to estimate rough object localization through intra-class token relevance,\nand a self-supervised DINO-ViT for intra-image token relevance. On recent\nchallenging benchmarks, the method achieves state-of-the-art performance among\nmethods trained with the same level of supervision (image labels) while being\ncompetitive with methods trained with pixel-level supervision (binary masks).\nThe benefits of the proposed co-segmentation method are further demonstrated in\nthe task of large-scale sketch recognition, that is, the classification of\nsketches into a wide range of categories. The limited amount of hand-drawn\nsketch training data is leveraged by exploiting readily available\nimage-level-annotated datasets of natural images containing a large number of\nclasses. To bridge the domain gap, the classifier is trained on a sketch-like\nproxy domain derived from edges detected on natural images. We show that sketch\nrecognition significantly benefits when the classifier is trained on\nsketch-like structures extracted from the co-segmented area rather than from\nthe full image. Code: https://github.com/nikosips/CBNC .\n","authors":["Nikolaos-Antonios Ypsilantis","Ondřej Chum"],"pdf_url":"https://arxiv.org/pdf/2410.13582v1.pdf","comment":"ACCV 2024 Main Paper + Supplementary (Appendix)"},{"id":"http://arxiv.org/abs/2402.06165v5","updated":"2024-10-17T14:10:16Z","published":"2024-02-09T03:48:20Z","title":"Learning Contrastive Feature Representations for Facial Action Unit\n  Detection","summary":"  Facial action unit (AU) detection has long encountered the challenge of\ndetecting subtle feature differences when AUs activate. Existing methods often\nrely on encoding pixel-level information of AUs, which not only encodes\nadditional redundant information but also leads to increased model complexity\nand limited generalizability. Additionally, the accuracy of AU detection is\nnegatively impacted by the class imbalance issue of each AU type, and the\npresence of noisy and false AU labels. In this paper, we introduce a novel\ncontrastive learning framework aimed for AU detection that incorporates both\nself-supervised and supervised signals, thereby enhancing the learning of\ndiscriminative features for accurate AU detection. To tackle the class\nimbalance issue, we employ a negative sample re-weighting strategy that adjusts\nthe step size of updating parameters for minority and majority class samples.\nMoreover, to address the challenges posed by noisy and false AU labels, we\nemploy a sampling technique that encompasses three distinct types of positive\nsample pairs. This enables us to inject self-supervised signals into the\nsupervised signal, effectively mitigating the adverse effects of noisy labels.\nOur experimental assessments, conducted on four widely-utilized benchmark\ndatasets (BP4D, DISFA, GFT and Aff-Wild2), underscore the superior performance\nof our approach compared to state-of-the-art methods of AU detection. Our code\nis available at \\url{https://github.com/Ziqiao-Shang/AUNCE}.\n","authors":["Ziqiao Shang","Bin Liu","Fengmao Lv","Fei Teng","Tianrui Li"],"pdf_url":"https://arxiv.org/pdf/2402.06165v5.pdf","comment":"35 pages, 18 figures, submitted to Pattern Recognition (PR)"},{"id":"http://arxiv.org/abs/2410.13571v1","updated":"2024-10-17T14:07:46Z","published":"2024-10-17T14:07:46Z","title":"DriveDreamer4D: World Models Are Effective Data Machines for 4D Driving\n  Scene Representation","summary":"  Closed-loop simulation is essential for advancing end-to-end autonomous\ndriving systems. Contemporary sensor simulation methods, such as NeRF and 3DGS,\nrely predominantly on conditions closely aligned with training data\ndistributions, which are largely confined to forward-driving scenarios.\nConsequently, these methods face limitations when rendering complex maneuvers\n(e.g., lane change, acceleration, deceleration). Recent advancements in\nautonomous-driving world models have demonstrated the potential to generate\ndiverse driving videos. However, these approaches remain constrained to 2D\nvideo generation, inherently lacking the spatiotemporal coherence required to\ncapture intricacies of dynamic driving environments. In this paper, we\nintroduce \\textit{DriveDreamer4D}, which enhances 4D driving scene\nrepresentation leveraging world model priors. Specifically, we utilize the\nworld model as a data machine to synthesize novel trajectory videos based on\nreal-world driving data. Notably, we explicitly leverage structured conditions\nto control the spatial-temporal consistency of foreground and background\nelements, thus the generated data adheres closely to traffic constraints. To\nour knowledge, \\textit{DriveDreamer4D} is the first to utilize video generation\nmodels for improving 4D reconstruction in driving scenarios. Experimental\nresults reveal that \\textit{DriveDreamer4D} significantly enhances generation\nquality under novel trajectory views, achieving a relative improvement in FID\nby 24.5\\%, 39.0\\%, and 10.5\\% compared to PVG, $\\text{S}^3$Gaussian, and\nDeformable-GS. Moreover, \\textit{DriveDreamer4D} markedly enhances the\nspatiotemporal coherence of driving agents, which is verified by a\ncomprehensive user study and the relative increases of 20.3\\%, 42.0\\%, and\n13.7\\% in the NTA-IoU metric.\n","authors":["Guosheng Zhao","Chaojun Ni","Xiaofeng Wang","Zheng Zhu","Guan Huang","Xinze Chen","Boyuan Wang","Youyi Zhang","Wenjun Mei","Xingang Wang"],"pdf_url":"https://arxiv.org/pdf/2410.13571v1.pdf","comment":"https://drivedreamer4d.github.io"},{"id":"http://arxiv.org/abs/2410.13570v1","updated":"2024-10-17T14:05:41Z","published":"2024-10-17T14:05:41Z","title":"RGB to Hyperspectral: Spectral Reconstruction for Enhanced Surgical\n  Imaging","summary":"  This study investigates the reconstruction of hyperspectral signatures from\nRGB data to enhance surgical imaging, utilizing the publicly available\nHeiPorSPECTRAL dataset from porcine surgery and an in-house neurosurgery\ndataset. Various architectures based on convolutional neural networks (CNNs)\nand transformer models are evaluated using comprehensive metrics. Transformer\nmodels exhibit superior performance in terms of RMSE, SAM, PSNR and SSIM by\neffectively integrating spatial information to predict accurate spectral\nprofiles, encompassing both visible and extended spectral ranges. Qualitative\nassessments demonstrate the capability to predict spectral profiles critical\nfor informed surgical decision-making during procedures. Challenges associated\nwith capturing both the visible and extended hyperspectral ranges are\nhighlighted using the MAE, emphasizing the complexities involved. The findings\nopen up the new research direction of hyperspectral reconstruction for surgical\napplications and clinical use cases in real-time surgical environments.\n","authors":["Tobias Czempiel","Alfie Roddan","Maria Leiloglou","Zepeng Hu","Kevin O'Neill","Giulio Anichini","Danail Stoyanov","Daniel Elson"],"pdf_url":"https://arxiv.org/pdf/2410.13570v1.pdf","comment":"10 pages, 4 figures, 3 tables"},{"id":"http://arxiv.org/abs/2410.13567v1","updated":"2024-10-17T14:04:02Z","published":"2024-10-17T14:04:02Z","title":"CCUP: A Controllable Synthetic Data Generation Pipeline for Pretraining\n  Cloth-Changing Person Re-Identification Models","summary":"  Cloth-changing person re-identification (CC-ReID), also known as Long-Term\nPerson Re-Identification (LT-ReID) is a critical and challenging research topic\nin computer vision that has recently garnered significant attention. However,\ndue to the high cost of constructing CC-ReID data, the existing data-driven\nmodels are hard to train efficiently on limited data, causing overfitting\nissue. To address this challenge, we propose a low-cost and efficient pipeline\nfor generating controllable and high-quality synthetic data simulating the\nsurveillance of real scenarios specific to the CC-ReID task. Particularly, we\nconstruct a new self-annotated CC-ReID dataset named Cloth-Changing Unreal\nPerson (CCUP), containing 6,000 IDs, 1,179,976 images, 100 cameras, and 26.5\noutfits per individual. Based on this large-scale dataset, we introduce an\neffective and scalable pretrain-finetune framework for enhancing the\ngeneralization capabilities of the traditional CC-ReID models. The extensive\nexperiments demonstrate that two typical models namely TransReID and FIRe^2,\nwhen integrated into our framework, outperform other state-of-the-art models\nafter pretraining on CCUP and finetuning on the benchmarks such as PRCC,\nVC-Clothes and NKUP. The CCUP is available at:\nhttps://github.com/yjzhao1019/CCUP.\n","authors":["Yujian Zhao","Chengru Wu","Yinong Xu","Xuanzheng Du","Ruiyu Li","Guanglin Niu"],"pdf_url":"https://arxiv.org/pdf/2410.13567v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.08551v2","updated":"2024-10-17T14:04:01Z","published":"2024-10-11T06:04:30Z","title":"Context-Aware Full Body Anonymization using Text-to-Image Diffusion\n  Models","summary":"  Anonymization plays a key role in protecting sensible information of\nindividuals in real world datasets. Self-driving cars for example need high\nresolution facial features to track people and their viewing direction to\npredict future behaviour and react accordingly. In order to protect people's\nprivacy whilst keeping important features in the dataset, it is important to\nreplace the full body of a person with a highly detailed anonymized one. In\ncontrast to doing face anonymization, full body replacement decreases the\nability of recognizing people by their hairstyle or clothes. In this paper, we\npropose a workflow for full body person anonymization utilizing Stable\nDiffusion as a generative backend. Text-to-image diffusion models, like Stable\nDiffusion, OpenAI's DALL-E or Midjourney, have become very popular in recent\ntime, being able to create photorealistic images from a single text prompt. We\nshow that our method outperforms state-of-the art anonymization pipelines with\nrespect to image quality, resolution, Inception Score (IS) and Frechet\nInception Distance (FID). Additionally, our method is invariant with respect to\nthe image generator and thus able to be used with the latest models available.\n","authors":["Pascal Zwick","Kevin Roesch","Marvin Klemp","Oliver Bringmann"],"pdf_url":"https://arxiv.org/pdf/2410.08551v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.13566v1","updated":"2024-10-17T14:03:53Z","published":"2024-10-17T14:03:53Z","title":"360U-Former: HDR Illumination Estimation with Panoramic Adapted Vision\n  Transformers","summary":"  Recent illumination estimation methods have focused on enhancing the\nresolution and improving the quality and diversity of the generated textures.\nHowever, few have explored tailoring the neural network architecture to the\nEquirectangular Panorama (ERP) format utilised in image-based lighting.\nConsequently, high dynamic range images (HDRI) results usually exhibit a seam\nat the side borders and textures or objects that are warped at the poles. To\naddress this shortcoming we propose a novel architecture, 360U-Former, based on\na U-Net style Vision-Transformer which leverages the work of PanoSWIN, an\nadapted shifted window attention tailored to the ERP format. To the best of our\nknowledge, this is the first purely Vision-Transformer model used in the field\nof illumination estimation. We train 360U-Former as a GAN to generate HDRI from\na limited field of view low dynamic range image (LDRI). We evaluate our method\nusing current illumination estimation evaluation protocols and datasets,\ndemonstrating that our approach outperforms existing and state-of-the-art\nmethods without the artefacts typically associated with the use of the ERP\nformat.\n","authors":["Jack Hilliard","Adrian Hilton","Jean-Yves Guillemaut"],"pdf_url":"https://arxiv.org/pdf/2410.13566v1.pdf","comment":"Accepted at AIM Workshop 2024 at ECCV 2024, 18 pages, 6 figures"},{"id":"http://arxiv.org/abs/2410.13564v1","updated":"2024-10-17T14:00:41Z","published":"2024-10-17T14:00:41Z","title":"Generative Location Modeling for Spatially Aware Object Insertion","summary":"  Generative models have become a powerful tool for image editing tasks,\nincluding object insertion. However, these methods often lack spatial\nawareness, generating objects with unrealistic locations and scales, or\nunintentionally altering the scene background. A key challenge lies in\nmaintaining visual coherence, which requires both a geometrically suitable\nobject location and a high-quality image edit. In this paper, we focus on the\nformer, creating a location model dedicated to identifying realistic object\nlocations. Specifically, we train an autoregressive model that generates\nbounding box coordinates, conditioned on the background image and the desired\nobject class. This formulation allows to effectively handle sparse placement\nannotations and to incorporate implausible locations into a preference dataset\nby performing direct preference optimization. Our extensive experiments\ndemonstrate that our generative location model, when paired with an inpainting\nmethod, substantially outperforms state-of-the-art instruction-tuned models and\nlocation modeling baselines in object insertion tasks, delivering accurate and\nvisually coherent results.\n","authors":["Jooyeol Yun","Davide Abati","Mohamed Omran","Jaegul Choo","Amirhossein Habibian","Auke Wiggers"],"pdf_url":"https://arxiv.org/pdf/2410.13564v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.13532v1","updated":"2024-10-17T13:20:20Z","published":"2024-10-17T13:20:20Z","title":"RemoteDet-Mamba: A Hybrid Mamba-CNN Network for Multi-modal Object\n  Detection in Remote Sensing Images","summary":"  Unmanned aerial vehicle (UAV) remote sensing is widely applied in fields such\nas emergency response, owing to its advantages of rapid information acquisition\nand low cost. However, due to the effects of shooting distance and imaging\nmechanisms, the objects in the images present challenges such as small size,\ndense distribution, and low inter-class differentiation. To this end, we\npropose a multimodal remote sensing detection network that employs a\nquad-directional selective scanning fusion strategy called RemoteDet-Mamba.\nRemoteDet-Mamba simultaneously facilitates the learning of single-modal local\nfeatures and the integration of patch-level global features across modalities,\nenhancing the distinguishability for small objects and utilizing local\ninformation to improve discrimination between different classes. Additionally,\nthe use of Mamba's serial processing significantly increases detection speed.\nExperimental results on the DroneVehicle dataset demonstrate the effectiveness\nof RemoteDet-Mamba, which achieves superior detection accuracy compared to\nstate-of-the-art methods while maintaining computational efficiency and\nparameter count.\n","authors":["Kejun Ren","Xin Wu","Lianming Xu","Li Wang"],"pdf_url":"https://arxiv.org/pdf/2410.13532v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.13530v1","updated":"2024-10-17T13:19:32Z","published":"2024-10-17T13:19:32Z","title":"L3DG: Latent 3D Gaussian Diffusion","summary":"  We propose L3DG, the first approach for generative 3D modeling of 3D\nGaussians through a latent 3D Gaussian diffusion formulation. This enables\neffective generative 3D modeling, scaling to generation of entire room-scale\nscenes which can be very efficiently rendered. To enable effective synthesis of\n3D Gaussians, we propose a latent diffusion formulation, operating in a\ncompressed latent space of 3D Gaussians. This compressed latent space is\nlearned by a vector-quantized variational autoencoder (VQ-VAE), for which we\nemploy a sparse convolutional architecture to efficiently operate on room-scale\nscenes. This way, the complexity of the costly generation process via diffusion\nis substantially reduced, allowing higher detail on object-level generation, as\nwell as scalability to large scenes. By leveraging the 3D Gaussian\nrepresentation, the generated scenes can be rendered from arbitrary viewpoints\nin real-time. We demonstrate that our approach significantly improves visual\nquality over prior work on unconditional object-level radiance field synthesis\nand showcase its applicability to room-scale scene generation.\n","authors":["Barbara Roessle","Norman Müller","Lorenzo Porzi","Samuel Rota Bulò","Peter Kontschieder","Angela Dai","Matthias Nießner"],"pdf_url":"https://arxiv.org/pdf/2410.13530v1.pdf","comment":"SIGGRAPH Asia 2024, project page:\n  https://barbararoessle.github.io/l3dg , video: https://youtu.be/UHEEiXCYeLU"},{"id":"http://arxiv.org/abs/2410.13526v1","updated":"2024-10-17T13:14:25Z","published":"2024-10-17T13:14:25Z","title":"Generative Adversarial Synthesis of Radar Point Cloud Scenes","summary":"  For the validation and verification of automotive radars, datasets of\nrealistic traffic scenarios are required, which, how ever, are laborious to\nacquire. In this paper, we introduce radar scene synthesis using GANs as an\nalternative to the real dataset acquisition and simulation-based approaches. We\ntrain a PointNet++ based GAN model to generate realistic radar point cloud\nscenes and use a binary classifier to evaluate the performance of scenes\ngenerated using this model against a test set of real scenes. We demonstrate\nthat our GAN model achieves similar performance (~87%) to the real scenes test\nset.\n","authors":["Muhammad Saad Nawaz","Thomas Dallmann","Torsten Schoen","Dirk Heberling"],"pdf_url":"https://arxiv.org/pdf/2410.13526v1.pdf","comment":"ICMIM 2024; 7th IEEE MTT Conference"},{"id":"http://arxiv.org/abs/2410.13523v1","updated":"2024-10-17T13:11:07Z","published":"2024-10-17T13:11:07Z","title":"Can Medical Vision-Language Pre-training Succeed with Purely Synthetic\n  Data?","summary":"  Medical Vision-Language Pre-training (MedVLP) has made significant progress\nin enabling zero-shot tasks for medical image understanding. However, training\nMedVLP models typically requires large-scale datasets with paired, high-quality\nimage-text data, which are scarce in the medical domain. Recent advancements in\nLarge Language Models (LLMs) and diffusion models have made it possible to\ngenerate large-scale synthetic image-text pairs. This raises the question: *Can\nMedVLP succeed using purely synthetic data?* To address this, we use\noff-the-shelf generative models to create synthetic radiology reports and\npaired Chest X-ray (CXR) images, and propose an automated pipeline to build a\ndiverse, high-quality synthetic dataset, enabling a rigorous study that\nisolates model and training settings, focusing entirely from the data\nperspective. Our results show that MedVLP models trained *exclusively on\nsynthetic data* outperform those trained on real data by **3.8%** in averaged\nAUC on zero-shot classification. Moreover, using a combination of synthetic and\nreal data leads to a further improvement of **9.07%**. Additionally, MedVLP\nmodels trained on synthetic or mixed data consistently outperform those trained\non real data in zero-shot grounding, as well as in fine-tuned classification\nand segmentation tasks. Our analysis suggests MedVLP trained on well-designed\nsynthetic data can outperform models trained on real datasets, which may be\nlimited by low-quality samples and long-tailed distributions.\n","authors":["Che Liu","Zhongwei Wan","Haozhe Wang","Yinda Chen","Talha Qaiser","Chen Jin","Fariba Yousefi","Nikolay Burlutskiy","Rossella Arcucci"],"pdf_url":"https://arxiv.org/pdf/2410.13523v1.pdf","comment":"Under Review"},{"id":"http://arxiv.org/abs/2406.03857v2","updated":"2024-10-17T13:08:13Z","published":"2024-06-06T08:42:36Z","title":"MuJo: Multimodal Joint Feature Space Learning for Human Activity\n  Recognition","summary":"  Human Activity Recognition (HAR) is a longstanding problem in AI with\napplications in a broad range of areas, including healthcare, sports and\nfitness, security, and more. The performance of HAR in real-world settings is\nstrongly dependent on the type and quality of the input signal that can be\nacquired. Given an unobstructed, high-quality camera view of a scene, computer\nvision systems, in particular in conjunction with foundation models, can today\nfairly reliably distinguish complex activities. On the other hand, recognition\nusing modalities such as wearable sensors (which are often more broadly\navailable, e.g., in mobile phones and smartwatches) is a more difficult\nproblem, as the signals often contain less information and labeled training\ndata is more difficult to acquire. To alleviate the need for labeled data, we\nintroduce our comprehensive Fitness Multimodal Activity Dataset (FiMAD) in this\nwork, which can be used with the proposed pre-training method MuJo (Multimodal\nJoint Feature Space Learning) to enhance HAR performance across various\nmodalities. FiMAD was created using YouTube fitness videos and contains\nparallel video, language, pose, and simulated IMU sensor data. MuJo utilizes\nthis dataset to learn a joint feature space for these modalities. We show that\nclassifiers pre-trained on FiMAD can increase the performance on real HAR\ndatasets such as MM-Fit, MyoGym, MotionSense, and MHEALTH. For instance, on\nMM-Fit, we achieve an Macro F1-Score of up to 0.855 when fine-tuning on only 2%\nof the training data and 0.942 when utilizing the full training set for\nclassification tasks. We have compared our approach to other self-supervised\nones and showed that, unlike them, ours can consistently improve on the\nbaseline network performance as well as provide a better data-efficiency.\n","authors":["Stefan Gerd Fritsch","Cennet Oguz","Vitor Fortes Rey","Lala Ray","Maximilian Kiefer-Emmanouilidis","Paul Lukowicz"],"pdf_url":"https://arxiv.org/pdf/2406.03857v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.13510v1","updated":"2024-10-17T12:56:52Z","published":"2024-10-17T12:56:52Z","title":"GeoCoder: Solving Geometry Problems by Generating Modular Code through\n  Vision-Language Models","summary":"  Geometry problem-solving demands advanced reasoning abilities to process\nmultimodal inputs and employ mathematical knowledge effectively.\nVision-language models (VLMs) have made significant progress in various\nmultimodal tasks. Yet, they still struggle with geometry problems and are\nsignificantly limited by their inability to perform mathematical operations not\nseen during pre-training, such as calculating the cosine of an arbitrary angle,\nand by difficulties in correctly applying relevant geometry formulas. To\novercome these challenges, we present GeoCoder, which leverages modular\ncode-finetuning to generate and execute code using a predefined geometry\nfunction library. By executing the code, we achieve accurate and deterministic\ncalculations, contrasting the stochastic nature of autoregressive token\nprediction, while the function library minimizes errors in formula usage. We\nalso propose a multimodal retrieval-augmented variant of GeoCoder, named\nRAG-GeoCoder, which incorporates a non-parametric memory module for retrieving\nfunctions from the geometry library, thereby reducing reliance on parametric\nmemory. Our modular code-finetuning approach enhances the geometric reasoning\ncapabilities of VLMs, yielding an average improvement of over 16% across\nvarious question complexities on the GeomVerse dataset compared to other\nfinetuning methods.\n","authors":["Aditya Sharma","Aman Dalmia","Mehran Kazemi","Amal Zouaq","Christopher J. Pal"],"pdf_url":"https://arxiv.org/pdf/2410.13510v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.13500v1","updated":"2024-10-17T12:46:26Z","published":"2024-10-17T12:46:26Z","title":"SAda-Net: A Self-Supervised Adaptive Stereo Estimation CNN For Remote\n  Sensing Image Data","summary":"  Stereo estimation has made many advancements in recent years with the\nintroduction of deep-learning. However the traditional supervised approach to\ndeep-learning requires the creation of accurate and plentiful ground-truth\ndata, which is expensive to create and not available in many situations. This\nis especially true for remote sensing applications, where there is an excess of\navailable data without proper ground truth. To tackle this problem, we propose\na self-supervised CNN with self-improving adaptive abilities. In the first\niteration, the created disparity map is inaccurate and noisy. Leveraging the\nleft-right consistency check, we get a sparse but more accurate disparity map\nwhich is used as an initial pseudo ground-truth. This pseudo ground-truth is\nthen adapted and updated after every epoch in the training step of the network.\nWe use the sum of inconsistent points in order to track the network\nconvergence. The code for our method is publicly available at:\nhttps://github.com/thedodo/SAda-Net}{https://github.com/thedodo/SAda-Net\n","authors":["Dominik Hirner","Friedrich Fraundorfer"],"pdf_url":"https://arxiv.org/pdf/2410.13500v1.pdf","comment":"Will be presented at ICPR2024 in December 2024 in Kolkata, India"},{"id":"http://arxiv.org/abs/2410.13486v1","updated":"2024-10-17T12:31:37Z","published":"2024-10-17T12:31:37Z","title":"SemSim: Revisiting Weak-to-Strong Consistency from a Semantic Similarity\n  Perspective for Semi-supervised Medical Image Segmentation","summary":"  Semi-supervised learning (SSL) for medical image segmentation is a\nchallenging yet highly practical task, which reduces reliance on large-scale\nlabeled dataset by leveraging unlabeled samples. Among SSL techniques, the\nweak-to-strong consistency framework, popularized by FixMatch, has emerged as a\nstate-of-the-art method in classification tasks. Notably, such a simple\npipeline has also shown competitive performance in medical image segmentation.\nHowever, two key limitations still persist, impeding its efficient adaptation:\n(1) the neglect of contextual dependencies results in inconsistent predictions\nfor similar semantic features, leading to incomplete object segmentation; (2)\nthe lack of exploitation of semantic similarity between labeled and unlabeled\ndata induces considerable class-distribution discrepancy. To address these\nlimitations, we propose a novel semi-supervised framework based on FixMatch,\nnamed SemSim, powered by two appealing designs from semantic similarity\nperspective: (1) rectifying pixel-wise prediction by reasoning about the\nintra-image pair-wise affinity map, thus integrating contextual dependencies\nexplicitly into the final prediction; (2) bridging labeled and unlabeled data\nvia a feature querying mechanism for compact class representation learning,\nwhich fully considers cross-image anatomical similarities. As the reliable\nsemantic similarity extraction depends on robust features, we further introduce\nan effective spatial-aware fusion module (SFM) to explore distinctive\ninformation from multiple scales. Extensive experiments show that SemSim yields\nconsistent improvements over the state-of-the-art methods across three public\nsegmentation benchmarks.\n","authors":["Shiao Xie","Hongyi Wang","Ziwei Niu","Hao Sun","Shuyi Ouyang","Yen-Wei Chen","Lanfen Lin"],"pdf_url":"https://arxiv.org/pdf/2410.13486v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2409.07961v3","updated":"2024-10-17T12:23:54Z","published":"2024-09-12T11:42:40Z","title":"Estimating Atmospheric Variables from Digital Typhoon Satellite Images\n  via Conditional Denoising Diffusion Models","summary":"  This study explores the application of diffusion models in the field of\ntyphoons, predicting multiple ERA5 meteorological variables simultaneously from\nDigital Typhoon satellite images. The focus of this study is taken to be\nTaiwan, an area very vulnerable to typhoons. By comparing the performance of\nConditional Denoising Diffusion Probability Model (CDDPM) with Convolutional\nNeural Networks (CNN) and Squeeze-and-Excitation Networks (SENet), results\nsuggest that the CDDPM performs best in generating accurate and realistic\nmeteorological data. Specifically, CDDPM achieved a PSNR of 32.807, which is\napproximately 7.9% higher than CNN and 5.5% higher than SENet. Furthermore,\nCDDPM recorded an RMSE of 0.032, showing a 11.1% improvement over CNN and 8.6%\nimprovement over SENet. A key application of this research can be for\nimputation purposes in missing meteorological datasets and generate additional\nhigh-quality meteorological data using satellite images. It is hoped that the\nresults of this analysis will enable more robust and detailed forecasting,\nreducing the impact of severe weather events on vulnerable regions. Code\naccessible at https://github.com/TammyLing/Typhoon-forecasting.\n","authors":["Zhangyue Ling","Pritthijit Nath","César Quilodrán-Casas"],"pdf_url":"https://arxiv.org/pdf/2409.07961v3.pdf","comment":"Accepted for spotlight presentation at the NeurIPS 2024 workshop on\n  Tackling Climate Change with Machine Learning. 8 pages, 5 figures"},{"id":"http://arxiv.org/abs/2406.08845v3","updated":"2024-10-17T12:11:36Z","published":"2024-06-13T06:09:22Z","title":"Rethinking Human Evaluation Protocol for Text-to-Video Models: Enhancing\n  Reliability,Reproducibility, and Practicality","summary":"  Recent text-to-video (T2V) technology advancements, as demonstrated by models\nsuch as Gen2, Pika, and Sora, have significantly broadened its applicability\nand popularity. Despite these strides, evaluating these models poses\nsubstantial challenges. Primarily, due to the limitations inherent in automatic\nmetrics, manual evaluation is often considered a superior method for assessing\nT2V generation. However, existing manual evaluation protocols face\nreproducibility, reliability, and practicality issues. To address these\nchallenges, this paper introduces the Text-to-Video Human Evaluation (T2VHE)\nprotocol, a comprehensive and standardized protocol for T2V models. The T2VHE\nprotocol includes well-defined metrics, thorough annotator training, and an\neffective dynamic evaluation module. Experimental results demonstrate that this\nprotocol not only ensures high-quality annotations but can also reduce\nevaluation costs by nearly 50\\%. We will open-source the entire setup of the\nT2VHE protocol, including the complete protocol workflow, the dynamic\nevaluation component details, and the annotation interface code. This will help\ncommunities establish more sophisticated human assessment protocols.\n","authors":["Tianle Zhang","Langtian Ma","Yuchen Yan","Yuchen Zhang","Kai Wang","Yue Yang","Ziyao Guo","Wenqi Shao","Yang You","Yu Qiao","Ping Luo","Kaipeng Zhang"],"pdf_url":"https://arxiv.org/pdf/2406.08845v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.13472v1","updated":"2024-10-17T12:02:29Z","published":"2024-10-17T12:02:29Z","title":"Day-Night Adaptation: An Innovative Source-free Adaptation Framework for\n  Medical Image Segmentation","summary":"  Distribution shifts widely exist in medical images acquired from different\nmedical centers, hindering the deployment of semantic segmentation models\ntrained on data from one center (source domain) to another (target domain).\nWhile unsupervised domain adaptation (UDA) has shown significant promise in\nmitigating these shifts, it poses privacy risks due to sharing data between\ncenters. To facilitate adaptation while preserving data privacy, source-free\ndomain adaptation (SFDA) and test-time adaptation (TTA) have emerged as\neffective paradigms, relying solely on target domain data. However, the\nscenarios currently addressed by SFDA and TTA are limited, making them less\nsuitable for clinical applications. In a more realistic clinical scenario, the\npre-trained model is deployed in a medical centre to assist with clinical tasks\nduring the day and rest at night. During the daytime process, TTA can be\nemployed to enhance inference performance. During the nighttime process, after\ncollecting the test data from the day, the model can be fine-tuned utilizing\nSFDA to further adapt to the target domain. With above insights, we propose a\nnovel adaptation framework called Day-Night Adaptation (DyNA). This framework\nadapts the model to the target domain through day-night loops without requiring\naccess to source data. Specifically, we implement distinct adaptation\nstrategies for daytime and nighttime to better meet the demands of clinical\nsettings. During the daytime, model parameters are frozen, and a specific\nlow-frequency prompt is trained for each test sample. Additionally, we\nconstruct a memory bank for prompt initialization and develop a warm-up\nmechanism to enhance prompt training. During nighttime, we integrate a global\nstudent model into the traditional teacher-student self-training paradigm to\nfine-tune the model while ensuring training stability...\n","authors":["Ziyang Chen","Yiwen Ye","Yongsheng Pan","Yong Xia"],"pdf_url":"https://arxiv.org/pdf/2410.13472v1.pdf","comment":"10 pages, 4 figures, 6 tables"},{"id":"http://arxiv.org/abs/2410.13471v1","updated":"2024-10-17T11:59:39Z","published":"2024-10-17T11:59:39Z","title":"SiamSeg: Self-Training with Contrastive Learning for Unsupervised Domain\n  Adaptation in Remote Sensing","summary":"  Semantic segmentation of remote sensing (RS) images is a challenging task\nwith significant potential across various applications. Deep learning,\nespecially supervised learning with large-scale labeled datasets, has greatly\nadvanced this field. However, acquiring high-quality labeled data is expensive\nand time-consuming. Moreover, variations in ground sampling distance (GSD),\nimaging equipment, and geographic diversity contribute to domain shifts between\ndatasets, which pose significant challenges to models trained solely on source\ndomain data, leading to poor cross-domain performance. Domain shift is\nwell-known for undermining a model's generalization ability in the target\ndomain. To address this, unsupervised domain adaptation (UDA) has emerged as a\npromising solution, enabling models to learn from unlabeled target domain data\nwhile training on labeled source domain data. Recent advancements, particularly\nin self-supervised learning via pseudo-label generation, have shown potential\nin mitigating domain discrepancies. Strategies combining source and target\ndomain images with their true and pseudo labels for self-supervised training\nhave been effective in addressing domain bias. Despite progress in computer\nvision, the application of pseudo-labeling methods to RS image segmentation\nremains underexplored.\n","authors":["Bin Wang","Fei Deng","Shuang Wang","Wen Luo","Zhixuan Zhang"],"pdf_url":"https://arxiv.org/pdf/2410.13471v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.13465v1","updated":"2024-10-17T11:51:12Z","published":"2024-10-17T11:51:12Z","title":"Object Pose Estimation Using Implicit Representation For Transparent\n  Objects","summary":"  Object pose estimation is a prominent task in computer vision. The object\npose gives the orientation and translation of the object in real-world space,\nwhich allows various applications such as manipulation, augmented reality, etc.\nVarious objects exhibit different properties with light, such as reflections,\nabsorption, etc. This makes it challenging to understand the object's structure\nin RGB and depth channels. Recent research has been moving toward\nlearning-based methods, which provide a more flexible and generalizable\napproach to object pose estimation utilizing deep learning. One such approach\nis the render-and-compare method, which renders the object from multiple views\nand compares it against the given 2D image, which often requires an object\nrepresentation in the form of a CAD model. We reason that the synthetic texture\nof the CAD model may not be ideal for rendering and comparing operations. We\nshowed that if the object is represented as an implicit (neural) representation\nin the form of Neural Radiance Field (NeRF), it exhibits a more realistic\nrendering of the actual scene and retains the crucial spatial features, which\nmakes the comparison more versatile. We evaluated our NeRF implementation of\nthe render-and-compare method on transparent datasets and found that it\nsurpassed the current state-of-the-art results.\n","authors":["Varun Burde","Artem Moroz","Vit Zeman","Pavel Burget"],"pdf_url":"https://arxiv.org/pdf/2410.13465v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.09250v2","updated":"2024-10-17T11:46:45Z","published":"2024-06-13T15:55:04Z","title":"MirrorCheck: Efficient Adversarial Defense for Vision-Language Models","summary":"  Vision-Language Models (VLMs) are becoming increasingly vulnerable to\nadversarial attacks as various novel attack strategies are being proposed\nagainst these models. While existing defenses excel in unimodal contexts, they\ncurrently fall short in safeguarding VLMs against adversarial threats. To\nmitigate this vulnerability, we propose a novel, yet elegantly simple approach\nfor detecting adversarial samples in VLMs. Our method leverages Text-to-Image\n(T2I) models to generate images based on captions produced by target VLMs.\nSubsequently, we calculate the similarities of the embeddings of both input and\ngenerated images in the feature space to identify adversarial samples.\nEmpirical evaluations conducted on different datasets validate the efficacy of\nour approach, outperforming baseline methods adapted from image classification\ndomains. Furthermore, we extend our methodology to classification tasks,\nshowcasing its adaptability and model-agnostic nature. Theoretical analyses and\nempirical findings also show the resilience of our approach against adaptive\nattacks, positioning it as an excellent defense mechanism for real-world\ndeployment against adversarial threats.\n","authors":["Samar Fares","Klea Ziu","Toluwani Aremu","Nikita Durasov","Martin Takáč","Pascal Fua","Karthik Nandakumar","Ivan Laptev"],"pdf_url":"https://arxiv.org/pdf/2406.09250v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.16807v2","updated":"2024-10-17T11:46:18Z","published":"2024-06-24T17:19:34Z","title":"Beyond Thumbs Up/Down: Untangling Challenges of Fine-Grained Feedback\n  for Text-to-Image Generation","summary":"  Human feedback plays a critical role in learning and refining reward models\nfor text-to-image generation, but the optimal form the feedback should take for\nlearning an accurate reward function has not been conclusively established.\nThis paper investigates the effectiveness of fine-grained feedback which\ncaptures nuanced distinctions in image quality and prompt-alignment, compared\nto traditional coarse-grained feedback (for example, thumbs up/down or ranking\nbetween a set of options). While fine-grained feedback holds promise,\nparticularly for systems catering to diverse societal preferences, we show that\ndemonstrating its superiority to coarse-grained feedback is not automatic.\nThrough experiments on real and synthetic preference data, we surface the\ncomplexities of building effective models due to the interplay of model choice,\nfeedback type, and the alignment between human judgment and computational\ninterpretation. We identify key challenges in eliciting and utilizing\nfine-grained feedback, prompting a reassessment of its assumed benefits and\npracticality. Our findings -- e.g., that fine-grained feedback can lead to\nworse models for a fixed budget, in some settings; however, in controlled\nsettings with known attributes, fine grained rewards can indeed be more helpful\n-- call for careful consideration of feedback attributes and potentially beckon\nnovel modeling approaches to appropriately unlock the potential value of\nfine-grained feedback in-the-wild.\n","authors":["Katherine M. Collins","Najoung Kim","Yonatan Bitton","Verena Rieser","Shayegan Omidshafiei","Yushi Hu","Sherol Chen","Senjuti Dutta","Minsuk Chang","Kimin Lee","Youwei Liang","Georgina Evans","Sahil Singla","Gang Li","Adrian Weller","Junfeng He","Deepak Ramachandran","Krishnamurthy Dj Dvijotham"],"pdf_url":"https://arxiv.org/pdf/2406.16807v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2312.01522v3","updated":"2024-10-17T11:33:09Z","published":"2023-12-03T22:44:04Z","title":"G2D: From Global to Dense Radiography Representation Learning via\n  Vision-Language Pre-training","summary":"  Recently, medical vision-language pre-training (VLP) has reached substantial\nprogress to learn global visual representation from medical images and their\npaired radiology reports. However, medical imaging tasks in real world usually\nrequire finer granularity in visual features. These tasks include visual\nlocalization tasks (e.g., semantic segmentation, object detection) and visual\ngrounding task. Yet, current medical VLP methods face challenges in learning\nthese fine-grained features, as they primarily focus on brute-force alignment\nbetween image patches and individual text tokens for local visual feature\nlearning, which is suboptimal for downstream dense prediction tasks. In this\nwork, we propose a new VLP framework, named \\textbf{G}lobal to \\textbf{D}ense\nlevel representation learning (G2D) that achieves significantly improved\ngranularity and more accurate grounding for the learned features, compared to\nexisting medical VLP approaches. In particular, G2D learns dense and\nsemantically-grounded image representations via a pseudo segmentation task\nparallel with the global vision-language alignment. Notably, generating pseudo\nsegmentation targets does not incur extra trainable parameters: they are\nobtained on the fly during VLP with a parameter-free processor. G2D achieves\nsuperior performance across 6 medical imaging tasks and 25 diseases,\nparticularly in semantic segmentation, which necessitates fine-grained,\nsemantically-grounded image features. In this task, G2D surpasses peer models\neven when fine-tuned with just 1\\% of the training data, compared to the 100\\%\nused by these models. The code will be released upon acceptance.\n","authors":["Che Liu","Cheng Ouyang","Sibo Cheng","Anand Shah","Wenjia Bai","Rossella Arcucci"],"pdf_url":"https://arxiv.org/pdf/2312.01522v3.pdf","comment":"Accepted by NeurIPS2024"},{"id":"http://arxiv.org/abs/2410.13453v1","updated":"2024-10-17T11:26:10Z","published":"2024-10-17T11:26:10Z","title":"Augmentation Policy Generation for Image Classification Using Large\n  Language Models","summary":"  Automated data augmentation methods have significantly improved the\nperformance and generalization capability of deep learning models in image\nclassification. Yet, most state-of-the-art methods are optimized on common\nbenchmark datasets, limiting their applicability to more diverse or\ndomain-specific data, such as medical datasets. In this paper, we propose a\nstrategy that uses large language models to automatically generate efficient\naugmentation policies, customized to fit the specific characteristics of any\ndataset and model architecture. The proposed method iteratively interacts with\nan LLM to obtain and refine the augmentation policies on model performance\nfeedback, creating a dataset-agnostic data augmentation pipeline. The proposed\nmethod was evaluated on medical imaging datasets, showing a clear improvement\nover state-of-the-art methods. The proposed approach offers an adaptive and\nscalable solution. Although it increases computational cost, it significantly\nboosts model robustness, automates the process, and minimizes the need for\nhuman involvement during model development.\n","authors":["Ant Duru","Alptekin Temizel"],"pdf_url":"https://arxiv.org/pdf/2410.13453v1.pdf","comment":"5 pages, 2 figures, 4 tables, submitted for consideration to the\n  International Workshop on Computational Intelligence for Multimedia\n  Understanding (IWCIM), ISCAS 2025"},{"id":"http://arxiv.org/abs/2410.09747v2","updated":"2024-10-17T11:14:37Z","published":"2024-10-13T06:53:58Z","title":"t-READi: Transformer-Powered Robust and Efficient Multimodal Inference\n  for Autonomous Driving","summary":"  Given the wide adoption of multimodal sensors (e.g., camera, lidar, radar) by\nautonomous vehicles (AVs), deep analytics to fuse their outputs for a robust\nperception become imperative. However, existing fusion methods often make two\nassumptions rarely holding in practice: i) similar data distributions for all\ninputs and ii) constant availability for all sensors. Because, for example,\nlidars have various resolutions and failures of radars may occur, such\nvariability often results in significant performance degradation in fusion. To\nthis end, we present tREADi, an adaptive inference system that accommodates the\nvariability of multimodal sensory data and thus enables robust and efficient\nperception. t-READi identifies variation-sensitive yet structure-specific model\nparameters; it then adapts only these parameters while keeping the rest intact.\nt-READi also leverages a cross-modality contrastive learning method to\ncompensate for the loss from missing modalities. Both functions are implemented\nto maintain compatibility with existing multimodal deep fusion methods. The\nextensive experiments evidently demonstrate that compared with the status quo\napproaches, t-READi not only improves the average inference accuracy by more\nthan 6% but also reduces the inference latency by almost 15x with the cost of\nonly 5% extra memory overhead in the worst case under realistic data and modal\nvariations.\n","authors":["Pengfei Hu","Yuhang Qian","Tianyue Zheng","Ang Li","Zhe Chen","Yue Gao","Xiuzhen Cheng","Jun Luo"],"pdf_url":"https://arxiv.org/pdf/2410.09747v2.pdf","comment":"14 pages, 16 figures"},{"id":"http://arxiv.org/abs/2410.13439v1","updated":"2024-10-17T11:12:55Z","published":"2024-10-17T11:12:55Z","title":"Similarity-Dissimilarity Loss with Supervised Contrastive Learning for\n  Multi-label Classification","summary":"  Supervised contrastive learning has been explored in making use of label\ninformation for multi-label classification, but determining positive samples in\nmulti-label scenario remains challenging. Previous studies have examined\nstrategies for identifying positive samples, considering label overlap\nproportion between anchors and samples. However, they ignore various relations\nbetween given anchors and samples, as well as how to dynamically adjust the\nweights in contrastive loss functions based on different relations, leading to\ngreat ambiguity. In this paper, we introduce five distinct relations between\nmulti-label samples and propose a Similarity-Dissimilarity Loss with\ncontrastive learning for multi-label classification. Our loss function\nre-weights the loss by computing the similarity and dissimilarity between\npositive samples and a given anchor based on the introduced relations. We\nmainly conduct experiments for multi-label text classification on MIMIC\ndatasets, then further extend the evaluation on MS-COCO. The Experimental\nresults show that our proposed loss effectively improves the performance on all\nencoders under supervised contrastive learning paradigm, demonstrating its\neffectiveness and robustness.\n","authors":["Guangming Huang","Yunfei Long","Cunjin Luo","Sheng Liu"],"pdf_url":"https://arxiv.org/pdf/2410.13439v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.13437v1","updated":"2024-10-17T11:07:05Z","published":"2024-10-17T11:07:05Z","title":"Temporal-Enhanced Multimodal Transformer for Referring Multi-Object\n  Tracking and Segmentation","summary":"  Referring multi-object tracking (RMOT) is an emerging cross-modal task that\naims to locate an arbitrary number of target objects and maintain their\nidentities referred by a language expression in a video. This intricate task\ninvolves the reasoning of linguistic and visual modalities, along with the\ntemporal association of target objects. However, the seminal work employs only\nloose feature fusion and overlooks the utilization of long-term information on\ntracked objects. In this study, we introduce a compact Transformer-based\nmethod, termed TenRMOT. We conduct feature fusion at both encoding and decoding\nstages to fully exploit the advantages of Transformer architecture.\nSpecifically, we incrementally perform cross-modal fusion layer-by-layer during\nthe encoding phase. In the decoding phase, we utilize language-guided queries\nto probe memory features for accurate prediction of the desired objects.\nMoreover, we introduce a query update module that explicitly leverages temporal\nprior information of the tracked objects to enhance the consistency of their\ntrajectories. In addition, we introduce a novel task called Referring\nMulti-Object Tracking and Segmentation (RMOTS) and construct a new dataset\nnamed Ref-KITTI Segmentation. Our dataset consists of 18 videos with 818\nexpressions, and each expression averages 10.7 masks, which poses a greater\nchallenge compared to the typical single mask in most existing referring video\nsegmentation datasets. TenRMOT demonstrates superior performance on both the\nreferring multi-object tracking and the segmentation tasks.\n","authors":["Changcheng Xiao","Qiong Cao","Yujie Zhong","Xiang Zhang","Tao Wang","Canqun Yang","Long Lan"],"pdf_url":"https://arxiv.org/pdf/2410.13437v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2405.14271v2","updated":"2024-10-17T11:06:26Z","published":"2024-05-23T07:48:19Z","title":"Fine-grained Image-to-LiDAR Contrastive Distillation with Visual\n  Foundation Models","summary":"  Contrastive image-to-LiDAR knowledge transfer, commonly used for learning 3D\nrepresentations with synchronized images and point clouds, often faces a\nself-conflict dilemma. This issue arises as contrastive losses unintentionally\ndissociate features of unmatched points and pixels that share semantic labels,\ncompromising the integrity of learned representations. To overcome this, we\nharness Visual Foundation Models (VFMs), which have revolutionized the\nacquisition of pixel-level semantics, to enhance 3D representation learning.\nSpecifically, we utilize off-the-shelf VFMs to generate semantic labels for\nweakly-supervised pixel-to-point contrastive distillation. Additionally, we\nemploy von Mises-Fisher distributions to structure the feature space, ensuring\nsemantic embeddings within the same class remain consistent across varying\ninputs. Furthermore, we adapt sampling probabilities of points to address\nimbalances in spatial distribution and category frequency, promoting\ncomprehensive and balanced learning. Extensive experiments demonstrate that our\napproach mitigates the challenges posed by traditional methods and consistently\nsurpasses existing image-to-LiDAR contrastive distillation methods in\ndownstream tasks. The source code is available at\n\\href{https://github.com/Eaphan/OLIVINE.}{\\color{black}https://github.com/Eaphan/OLIVINE}.\n","authors":["Yifan Zhang","Junhui Hou"],"pdf_url":"https://arxiv.org/pdf/2405.14271v2.pdf","comment":"Accepted to NeurIPS 2024"},{"id":"http://arxiv.org/abs/2410.13427v1","updated":"2024-10-17T10:51:08Z","published":"2024-10-17T10:51:08Z","title":"Unsupervised Skull Segmentation via Contrastive MR-to-CT Modality\n  Translation","summary":"  The skull segmentation from CT scans can be seen as an already solved\nproblem. However, in MR this task has a significantly greater complexity due to\nthe presence of soft tissues rather than bones. Capturing the bone structures\nfrom MR images of the head, where the main visualization objective is the\nbrain, is very demanding. The attempts that make use of skull stripping seem to\nnot be well suited for this task and fail to work in many cases. On the other\nhand, supervised approaches require costly and time-consuming skull\nannotations. To overcome the difficulties we propose a fully unsupervised\napproach, where we do not perform the segmentation directly on MR images, but\nwe rather perform a synthetic CT data generation via MR-to-CT translation and\nperform the segmentation there. We address many issues associated with\nunsupervised skull segmentation including the unpaired nature of MR and CT\ndatasets (contrastive learning), low resolution and poor quality\n(super-resolution), and generalization capabilities. The research has a\nsignificant value for downstream tasks requiring skull segmentation from MR\nvolumes such as craniectomy or surgery planning and can be seen as an important\nstep towards the utilization of synthetic data in medical imaging.\n","authors":["Kamil Kwarciak","Mateusz Daniol","Daria Hemmerling","Marek Wodzinski"],"pdf_url":"https://arxiv.org/pdf/2410.13427v1.pdf","comment":"16 pages, 5 figures, ACCV 2024 - GAISynMeD Workshop"},{"id":"http://arxiv.org/abs/2410.13421v1","updated":"2024-10-17T10:43:43Z","published":"2024-10-17T10:43:43Z","title":"Performance of Gaussian Mixture Model Classifiers on Embedded Feature\n  Spaces","summary":"  Data embeddings with CLIP and ImageBind provide powerful features for the\nanalysis of multimedia and/or multimodal data. We assess their performance here\nfor classification using a Gaussian Mixture models (GMMs) based layer as an\nalternative to the standard Softmax layer. GMMs based classifiers have recently\nbeen shown to have interesting performances as part of deep learning pipelines\ntrained end-to-end. Our first contribution is to investigate GMM based\nclassification performance taking advantage of the embedded spaces CLIP and\nImageBind. Our second contribution is in proposing our own GMM based classifier\nwith a lower parameters count than previously proposed. Our findings are, that\nin most cases, on these tested embedded spaces, one gaussian component in the\nGMMs is often enough for capturing each class, and we hypothesize that this may\nbe due to the contrastive loss used for training these embedded spaces that\nnaturally concentrates features together for each class. We also observed that\nImageBind often provides better performance than CLIP for classification of\nimage datasets even when these embedded spaces are compressed using PCA.\n","authors":["Jeremy Chopin","Rozenn Dahyot"],"pdf_url":"https://arxiv.org/pdf/2410.13421v1.pdf","comment":"8 pages"},{"id":"http://arxiv.org/abs/2308.02935v4","updated":"2024-10-17T09:53:57Z","published":"2023-08-05T18:32:49Z","title":"Bias Behind the Wheel: Fairness Testing of Autonomous Driving Systems","summary":"  This paper conducts fairness testing of automated pedestrian detection, a\ncrucial but under-explored issue in autonomous driving systems. We evaluate\neight state-of-the-art deep learning-based pedestrian detectors across\ndemographic groups on large-scale real-world datasets. To enable thorough\nfairness testing, we provide extensive annotations for the datasets, resulting\nin 8,311 images with 16,070 gender labels, 20,115 age labels, and 3,513 skin\ntone labels. Our findings reveal significant fairness issues, particularly\nrelated to age. The proportion of undetected children is 20.14% higher compared\nto adults. Furthermore, we explore how various driving scenarios affect the\nfairness of pedestrian detectors. We find that pedestrian detectors demonstrate\nsignificant gender biases during night time, potentially exacerbating the\nprevalent societal issue of female safety concerns during nighttime out.\nMoreover, we observe that pedestrian detectors can demonstrate both enhanced\nfairness and superior performance under specific driving conditions, which\nchallenges the fairness-performance trade-off theory widely acknowledged in the\nfairness literature. We publicly release the code, data, and results to support\nfuture research on fairness in autonomous driving.\n","authors":["Xinyue Li","Zhenpeng Chen","Jie M. Zhang","Federica Sarro","Ying Zhang","Xuanzhe Liu"],"pdf_url":"https://arxiv.org/pdf/2308.02935v4.pdf","comment":"Accepted by ACM Transactions on Software Engineering and Methodology\n  (TOSEM)"},{"id":"http://arxiv.org/abs/2410.13384v1","updated":"2024-10-17T09:36:52Z","published":"2024-10-17T09:36:52Z","title":"RescueADI: Adaptive Disaster Interpretation in Remote Sensing Images\n  with Autonomous Agents","summary":"  Current methods for disaster scene interpretation in remote sensing images\n(RSIs) mostly focus on isolated tasks such as segmentation, detection, or\nvisual question-answering (VQA). However, current interpretation methods often\nfail at tasks that require the combination of multiple perception methods and\nspecialized tools. To fill this gap, this paper introduces Adaptive Disaster\nInterpretation (ADI), a novel task designed to solve requests by planning and\nexecuting multiple sequentially correlative interpretation tasks to provide a\ncomprehensive analysis of disaster scenes. To facilitate research and\napplication in this area, we present a new dataset named RescueADI, which\ncontains high-resolution RSIs with annotations for three connected aspects:\nplanning, perception, and recognition. The dataset includes 4,044 RSIs, 16,949\nsemantic masks, 14,483 object bounding boxes, and 13,424 interpretation\nrequests across nine challenging request types. Moreover, we propose a new\ndisaster interpretation method employing autonomous agents driven by large\nlanguage models (LLMs) for task planning and execution, proving its efficacy in\nhandling complex disaster interpretations. The proposed agent-based method\nsolves various complex interpretation requests such as counting, area\ncalculation, and path-finding without human intervention, which traditional\nsingle-task approaches cannot handle effectively. Experimental results on\nRescueADI demonstrate the feasibility of the proposed task and show that our\nmethod achieves an accuracy 9% higher than existing VQA methods, highlighting\nits advantages over conventional disaster interpretation approaches. The\ndataset will be publicly available.\n","authors":["Zhuoran Liu","Danpei Zhao","Bo Yuan"],"pdf_url":"https://arxiv.org/pdf/2410.13384v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.13383v1","updated":"2024-10-17T09:36:19Z","published":"2024-10-17T09:36:19Z","title":"Railway LiDAR semantic segmentation based on intelligent semi-automated\n  data annotation","summary":"  Automated vehicles rely on an accurate and robust perception of the\nenvironment. Similarly to automated cars, highly automated trains require an\nenvironmental perception. Although there is a lot of research based on either\ncamera or LiDAR sensors in the automotive domain, very few contributions for\nthis task exist yet for automated trains. Additionally, no public dataset or\ndescribed approach for a 3D LiDAR semantic segmentation in the railway\nenvironment exists yet. Thus, we propose an approach for a point-wise 3D\nsemantic segmentation based on the 2DPass network architecture using scans and\nimages jointly. In addition, we present a semi-automated intelligent data\nannotation approach, which we use to efficiently and accurately label the\nrequired dataset recorded on a railway track in Germany. To improve performance\ndespite a still small number of labeled scans, we apply an active learning\napproach to intelligently select scans for the training dataset. Our\ncontributions are threefold: We annotate rail data including camera and LiDAR\ndata from the railway environment, transfer label the raw LiDAR point clouds\nusing an image segmentation network, and train a state-of-the-art 3D LiDAR\nsemantic segmentation network efficiently leveraging active learning. The\ntrained network achieves good segmentation results with a mean IoU of 71.48% of\n9 classes.\n","authors":["Florian Wulff","Bernd Schaeufele","Julian Pfeifer","Ilja Radusch"],"pdf_url":"https://arxiv.org/pdf/2410.13383v1.pdf","comment":"This article has been accepted for publication in the IEEE VTC Fall\n  2024"},{"id":"http://arxiv.org/abs/2410.13371v1","updated":"2024-10-17T09:23:30Z","published":"2024-10-17T09:23:30Z","title":"Accurate Checkerboard Corner Detection under Defoucs","summary":"  Camera calibration is a critical process in 3D vision, im pacting\napplications in autonomous driving, robotics, ar chitecture, and so on. This\npaper focuses on enhancing feature extraction for chessboard corner detection,\na key step in calibration. We analyze existing methods, high lighting their\nlimitations and propose a novel sub-pixel refinement approach based on\nsymmetry, which signifi cantly improves accuracy for visible light cameras. Un\nlike prior symmetry based method that assume a contin uous physical pattern,\nour approach accounts for abrupt changes in visible light camera images and\ndefocus ef fects. We introduce a simplified objective function that reduces\ncomputation time and mitigates overfitting risks. Furthermore, we derive an\nexplicit expression for the pixel value of a blurred edge, providing insights\ninto the relationship between pixel value and center intensity. Our method\ndemonstrates superior performance, achiev ing substantial accuracy improvements\nover existing tech niques, particularly in the context of visible light cam era\ncalibration. Our code is available from https:\n//github.com/spdfghi/Accurate-Checkerboard Corner-Detection-under-Defoucs.git.\n","authors":["Zezhun Shi"],"pdf_url":"https://arxiv.org/pdf/2410.13371v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.13370v1","updated":"2024-10-17T09:22:53Z","published":"2024-10-17T09:22:53Z","title":"MagicTailor: Component-Controllable Personalization in Text-to-Image\n  Diffusion Models","summary":"  Recent advancements in text-to-image (T2I) diffusion models have enabled the\ncreation of high-quality images from text prompts, but they still struggle to\ngenerate images with precise control over specific visual concepts. Existing\napproaches can replicate a given concept by learning from reference images, yet\nthey lack the flexibility for fine-grained customization of the individual\ncomponent within the concept. In this paper, we introduce\ncomponent-controllable personalization, a novel task that pushes the boundaries\nof T2I models by allowing users to reconfigure specific components when\npersonalizing visual concepts. This task is particularly challenging due to two\nprimary obstacles: semantic pollution, where unwanted visual elements corrupt\nthe personalized concept, and semantic imbalance, which causes disproportionate\nlearning of the concept and component. To overcome these challenges, we design\nMagicTailor, an innovative framework that leverages Dynamic Masked Degradation\n(DM-Deg) to dynamically perturb undesired visual semantics and Dual-Stream\nBalancing (DS-Bal) to establish a balanced learning paradigm for desired visual\nsemantics. Extensive comparisons, ablations, and analyses demonstrate that\nMagicTailor not only excels in this challenging task but also holds significant\npromise for practical applications, paving the way for more nuanced and\ncreative image generation.\n","authors":["Donghao Zhou","Jiancheng Huang","Jinbin Bai","Jiaze Wang","Hao Chen","Guangyong Chen","Xiaowei Hu","Pheng-Ann Heng"],"pdf_url":"https://arxiv.org/pdf/2410.13370v1.pdf","comment":"Project page: https://correr-zhou.github.io/MagicTailor"},{"id":"http://arxiv.org/abs/2410.13360v1","updated":"2024-10-17T09:10:26Z","published":"2024-10-17T09:10:26Z","title":"Remember, Retrieve and Generate: Understanding Infinite Visual Concepts\n  as Your Personalized Assistant","summary":"  The development of large language models (LLMs) has significantly enhanced\nthe capabilities of multimodal LLMs (MLLMs) as general assistants. However,\nlack of user-specific knowledge still restricts their application in human's\ndaily life. In this paper, we introduce the Retrieval Augmented Personalization\n(RAP) framework for MLLMs' personalization. Starting from a general MLLM, we\nturn it into a personalized assistant in three steps. (a) Remember: We design a\nkey-value database to store user-related information, e.g., user's name, avatar\nand other attributes. (b) Retrieve: When the user initiates a conversation, RAP\nwill retrieve relevant information from the database using a multimodal\nretriever. (c) Generate: The input query and retrieved concepts' information\nare fed into MLLMs to generate personalized, knowledge-augmented responses.\nUnlike previous methods, RAP allows real-time concept editing via updating the\nexternal database. To further improve generation quality and alignment with\nuser-specific information, we design a pipeline for data collection and create\na specialized dataset for personalized training of MLLMs. Based on the dataset,\nwe train a series of MLLMs as personalized multimodal assistants. By\npretraining on large-scale dataset, RAP-MLLMs can generalize to infinite visual\nconcepts without additional finetuning. Our models demonstrate outstanding\nflexibility and generation quality across a variety of tasks, such as\npersonalized image captioning, question answering and visual recognition. The\ncode, data and models are available at https://github.com/Hoar012/RAP-MLLM.\n","authors":["Haoran Hao","Jiaming Han","Changsheng Li","Yu-Feng Li","Xiangyu Yue"],"pdf_url":"https://arxiv.org/pdf/2410.13360v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.13355v1","updated":"2024-10-17T09:05:15Z","published":"2024-10-17T09:05:15Z","title":"Self-Supervised Scene Flow Estimation with Point-Voxel Fusion and\n  Surface Representation","summary":"  Scene flow estimation aims to generate the 3D motion field of points between\ntwo consecutive frames of point clouds, which has wide applications in various\nfields. Existing point-based methods ignore the irregularity of point clouds\nand have difficulty capturing long-range dependencies due to the inefficiency\nof point-level computation. Voxel-based methods suffer from the loss of detail\ninformation. In this paper, we propose a point-voxel fusion method, where we\nutilize a voxel branch based on sparse grid attention and the shifted window\nstrategy to capture long-range dependencies and a point branch to capture\nfine-grained features to compensate for the information loss in the voxel\nbranch. In addition, since xyz coordinates are difficult to describe the\ngeometric structure of complex 3D objects in the scene, we explicitly encode\nthe local surface information of the point cloud through the umbrella surface\nfeature extraction (USFE) module. We verify the effectiveness of our method by\nconducting experiments on the Flyingthings3D and KITTI datasets. Our method\noutperforms all other self-supervised methods and achieves highly competitive\nresults compared to fully supervised methods. We achieve improvements in all\nmetrics, especially EPE, which is reduced by 8.51% and 10.52% on the KITTIo and\nKITTIs datasets, respectively.\n","authors":["Xuezhi Xiang","Xi Wang","Lei Zhang","Denis Ombati","Himaloy Himu","Xiantong Zhen"],"pdf_url":"https://arxiv.org/pdf/2410.13355v1.pdf","comment":"The paper is under consideration at 2025 IEEE International\n  Conference on Acoustics, Speech, and Signal Processing (ICASSP 2025)"},{"id":"http://arxiv.org/abs/2410.13349v1","updated":"2024-10-17T09:00:29Z","published":"2024-10-17T09:00:29Z","title":"GlossyGS: Inverse Rendering of Glossy Objects with 3D Gaussian Splatting","summary":"  Reconstructing objects from posed images is a crucial and complex task in\ncomputer graphics and computer vision. While NeRF-based neural reconstruction\nmethods have exhibited impressive reconstruction ability, they tend to be\ntime-comsuming. Recent strategies have adopted 3D Gaussian Splatting (3D-GS)\nfor inverse rendering, which have led to quick and effective outcomes. However,\nthese techniques generally have difficulty in producing believable geometries\nand materials for glossy objects, a challenge that stems from the inherent\nambiguities of inverse rendering. To address this, we introduce GlossyGS, an\ninnovative 3D-GS-based inverse rendering framework that aims to precisely\nreconstruct the geometry and materials of glossy objects by integrating\nmaterial priors. The key idea is the use of micro-facet geometry segmentation\nprior, which helps to reduce the intrinsic ambiguities and improve the\ndecomposition of geometries and materials. Additionally, we introduce a normal\nmap prefiltering strategy to more accurately simulate the normal distribution\nof reflective surfaces. These strategies are integrated into a hybrid geometry\nand material representation that employs both explicit and implicit methods to\ndepict glossy objects. We demonstrate through quantitative analysis and\nqualitative visualization that the proposed method is effective to reconstruct\nhigh-fidelity geometries and materials of glossy objects, and performs\nfavorably against state-of-the-arts.\n","authors":["Shuichang Lai","Letian Huang","Jie Guo","Kai Cheng","Bowen Pan","Xiaoxiao Long","Jiangjing Lyu","Chengfei Lv","Yanwen Guo"],"pdf_url":"https://arxiv.org/pdf/2410.13349v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.11553v4","updated":"2024-10-17T08:58:47Z","published":"2024-08-21T12:04:32Z","title":"AnyDesign: Versatile Area Fashion Editing via Mask-Free Diffusion","summary":"  Fashion image editing aims to modify a person's appearance based on a given\ninstruction. Existing methods require auxiliary tools like segmenters and\nkeypoint extractors, lacking a flexible and unified framework. Moreover, these\nmethods are limited in the variety of clothing types they can handle, as most\ndatasets focus on people in clean backgrounds and only include generic garments\nsuch as tops, pants, and dresses. These limitations restrict their\napplicability in real-world scenarios. In this paper, we first extend an\nexisting dataset for human generation to include a wider range of apparel and\nmore complex backgrounds. This extended dataset features people wearing diverse\nitems such as tops, pants, dresses, skirts, headwear, scarves, shoes, socks,\nand bags. Additionally, we propose AnyDesign, a diffusion-based method that\nenables mask-free editing on versatile areas. Users can simply input a human\nimage along with a corresponding prompt in either text or image format. Our\napproach incorporates Fashion DiT, equipped with a Fashion-Guidance Attention\n(FGA) module designed to fuse explicit apparel types and CLIP-encoded apparel\nfeatures. Both Qualitative and quantitative experiments demonstrate that our\nmethod delivers high-quality fashion editing and outperforms contemporary\ntext-guided fashion editing methods.\n","authors":["Yunfang Niu","Lingxiang Wu","Dong Yi","Jie Peng","Ning Jiang","Haiying Wu","Jinqiao Wang"],"pdf_url":"https://arxiv.org/pdf/2408.11553v4.pdf","comment":null},{"id":"http://arxiv.org/abs/2304.02278v3","updated":"2024-10-17T08:57:50Z","published":"2023-04-05T07:50:16Z","title":"SCMM: Calibrating Cross-modal Representations for Text-Based Person\n  Search","summary":"  Text-Based Person Search (TBPS) is a crucial task that enables accurate\nretrieval of target individuals from large-scale galleries with only given\ntextual caption. For cross-modal TBPS tasks, it is critical to obtain\nwell-distributed representation in the common embedding space to reduce the\ninter-modal gap. Furthermore, learning detailed image-text correspondences is\nessential to discriminate similar targets and enable fine-grained search. To\naddress these challenges, we present a simple yet effective method named Sew\nCalibration and Masked Modeling (SCMM) that calibrates cross-modal\nrepresentations by learning compact and well-aligned embeddings. SCMM is\ndistinguished by two novel losses to provide fine-grained cross-modal\nrepresentations: 1) a Sew calibration loss that takes the quality of textual\ncaptions as guidance and aligns features between image and text modalities, and\n2) a Masked Caption Modeling (MCM) loss that leverages a masked caption\nprediction task to establish detailed and generic relationships between textual\nand visual parts. The dual-pronged strategy refines feature alignment and\nenriches cross-modal correspondences, enabling the accurate distinction of\nsimilar individuals. Consequently, its streamlined dual-encoder architecture\navoids complex branches and interactions and facilitates high-speed inference\nsuitable for real-time requirements. Consequently, high-speed inference is\nachieved, which is essential for resource-limited applications often demanding\nreal-time processing. Extensive experiments on three popular TBPS benchmarks\ndemonstrate the superiority of SCMM, achieving top results with 73.81%, 74.25%,\nand 57.35% Rank-1 accuracy on CUHK-PEDES, ICFG-PEDES, and RSTPReID,\nrespectively. We hope SCMM's scalable and cost-effective design will serve as a\nstrong baseline and facilitate future research in this field.\n","authors":["Jing Liu","Donglai Wei","Yang Liu","Sipeng Zhang","Tong Yang","Victor C. M. Leung"],"pdf_url":"https://arxiv.org/pdf/2304.02278v3.pdf","comment":"This version of manuscript is under IEEE TMM review"},{"id":"http://arxiv.org/abs/2410.03320v2","updated":"2024-10-17T08:43:29Z","published":"2024-10-04T11:14:31Z","title":"Lost in Tracking: Uncertainty-guided Cardiac Cine MRI Segmentation at\n  Right Ventricle Base","summary":"  Accurate biventricular segmentation of cardiac magnetic resonance (CMR) cine\nimages is essential for the clinical evaluation of heart function. However,\ncompared to left ventricle (LV), right ventricle (RV) segmentation is still\nmore challenging and less reproducible. Degenerate performance frequently\noccurs at the RV base, where the in-plane anatomical structures are complex\n(with atria, valve, and aorta) and vary due to the strong interplanar motion.\nIn this work, we propose to address the currently unsolved issues in CMR\nsegmentation, specifically at the RV base, with two strategies: first, we\ncomplemented the public resource by reannotating the RV base in the ACDC\ndataset, with refined delineation of the right ventricle outflow tract (RVOT),\nunder the guidance of an expert cardiologist. Second, we proposed a novel dual\nencoder U-Net architecture that leverages temporal incoherence to inform the\nsegmentation when interplanar motions occur. The inter-planar motion is\ncharacterized by loss-of-tracking, via Bayesian uncertainty of a\nmotion-tracking model. Our experiments showed that our method significantly\nimproved RV base segmentation taking into account temporal incoherence.\nFurthermore, we investigated the reproducibility of deep learning-based\nsegmentation and showed that the combination of consistent annotation and loss\nof tracking could enhance the reproducibility of RV segmentation, potentially\nfacilitating a large number of clinical studies focusing on RV.\n","authors":["Yidong Zhao","Yi Zhang","Orlando Simonetti","Yuchi Han","Qian Tao"],"pdf_url":"https://arxiv.org/pdf/2410.03320v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2407.11781v2","updated":"2024-10-17T08:28:50Z","published":"2024-07-16T14:38:13Z","title":"Sliding Gaussian ball adaptive growth (SlingBAG): point cloud-based\n  iterative algorithm for large-scale 3D photoacoustic imaging","summary":"  Large-scale photoacoustic (PA) 3D imaging has become increasingly important\nfor both clinical and pre-clinical applications. Limited by resource and\napplication constrains, only sparsely-distributed transducer arrays can be\napplied, which necessitates advanced image reconstruction algorithms to\novercome artifacts caused by using back-projection algorithm. However, high\ncomputing memory consumption of traditional iterative algorithms for\nlarge-scale 3D cases is practically unacceptable. Here, we propose a point\ncloud-based iterative algorithm that reduces memory consumption by several\norders, wherein a 3D photoacoustic scene is modeled as a series of\nGaussian-distributed spherical sources. During the iterative reconstruction\nprocess, the properties of each Gaussian source, including peak intensities,\nstandard deviations and means are stored in form of point cloud, then\ncontinuously optimized and adaptively undergoing destroying, splitting, and\nduplication along the gradient direction, thus manifesting the sliding ball\nadaptive growth effect. This method, named the sliding Gaussian ball adaptive\ngrowth (SlingBAG) algorithm, enables high-quality 3D large-scale PA\nreconstruction with fast iteration and extremely less memory usage. We\nvalidated SlingBAG algorithm in both simulation study and in vivo animal\nexperiments.\n","authors":["Shuang Li","Yibing Wang","Jian Gao","Chulhong Kim","Seongwook Choi","Yu Zhang","Qian Chen","Yao Yao","Changhui Li"],"pdf_url":"https://arxiv.org/pdf/2407.11781v2.pdf","comment":"Added SlingBAG reconstruction of rat kidney and rat liver results;\n  updated methods; added references"},{"id":"http://arxiv.org/abs/2308.14409v2","updated":"2024-10-17T08:25:06Z","published":"2023-08-28T08:47:06Z","title":"Steerable Conditional Diffusion for Out-of-Distribution Adaptation in\n  Medical Image Reconstruction","summary":"  Denoising diffusion models have emerged as the go-to generative framework for\nsolving inverse problems in imaging. A critical concern regarding these models\nis their performance on out-of-distribution tasks, which remains an\nunder-explored challenge. Using a diffusion model on an out-of-distribution\ndataset, realistic reconstructions can be generated, but with hallucinating\nimage features that are uniquely present in the training dataset. To address\nthis discrepancy during train-test time and improve reconstruction accuracy, we\nintroduce a novel sampling framework called Steerable Conditional Diffusion.\nSpecifically, this framework adapts the diffusion model, concurrently with\nimage reconstruction, based solely on the information provided by the available\nmeasurement. Utilising our proposed method, we achieve substantial enhancements\nin out-of-distribution performance across diverse imaging modalities, advancing\nthe robust deployment of denoising diffusion models in real-world applications.\n","authors":["Riccardo Barbano","Alexander Denker","Hyungjin Chung","Tae Hoon Roh","Simon Arridge","Peter Maass","Bangti Jin","Jong Chul Ye"],"pdf_url":"https://arxiv.org/pdf/2308.14409v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.13321v1","updated":"2024-10-17T08:24:27Z","published":"2024-10-17T08:24:27Z","title":"Mitigating Hallucinations in Large Vision-Language Models via\n  Summary-Guided Decoding","summary":"  Large Vision-Language Models (LVLMs) demonstrate impressive capabilities in\ngenerating detailed and coherent responses from visual inputs. However, they\nare prone to generate hallucinations due to an over-reliance on language\npriors. To address this issue, we investigate the language priors in LVLMs and\nmake two key observations: (1) Even when predicting the tokens associated with\nimage-related part-of-speech (POS), models increasingly rely on linguistic\npriors as the token sequences grow, thereby amplifying hallucinations. (2)\nMethods that directly calibrate LVLM's output distribution to mitigate language\npriors can lead to a degradation in text quality or even exacerbate\nhallucinations. Based on these findings, we propose a novel method,\nSummary-Guided Decoding (SGD). This method naturally encourages the model to\nfocus more on image information by reducing the text context through summaries,\nwhile controlling only the image-related POS tokens to maintain text quality.\nThrough experiments, we demonstrate that SGD achieves state-of-the-art\nperformance on object hallucination benchmarks. Furthermore, in terms of the\ntrade-off between precision and recall, SGD achieves Pareto optimality among\nthe existing methods. Lastly, we observe that although existing methods\nstruggle to balance the reduction of object hallucinations with maintaining\ntext quality, SGD demonstrates robustness in handling this challenge.\n","authors":["Kyungmin Min","Minbeom Kim","Kang-il Lee","Dongryeol Lee","Kyomin Jung"],"pdf_url":"https://arxiv.org/pdf/2410.13321v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.13320v1","updated":"2024-10-17T08:23:09Z","published":"2024-10-17T08:23:09Z","title":"Inadequate contrast ratio of road markings as an indicator for ADAS\n  failure","summary":"  Road markings were reported as critical road safety features, equally needed\nfor both human drivers and for machine vision technologies utilised by advanced\ndriver assistance systems (ADAS) and in driving automation. Visibility of road\nmarkings is achieved because of their colour contrasting with the roadway\nsurface. During recent testing of an open-source camera-based ADAS under\nseveral visibility conditions (day, night, rain, glare), significant failures\nin trajectory planning were recorded and quantified. Consistently, better ADAS\nreliability under poor visibility conditions was achieved with Type II road\nmarkings (i.e. structured markings, facilitating moisture drainage) as compared\nto Type I road marking (i.e. flat lines). To further understand these failures,\nanalysis of contrast ratio of road markings, which the tested ADAS was\ndetecting for traffic lane recognition, was performed. The highest contrast\nratio (greater than 0.5, calculated per Michelson equation) was measured at\nnight in the absence of confounding factors, with statistically significant\ndifference of 0.1 in favour of Type II road markings over Type I. Under\ndaylight conditions, contrast ratio was reduced, with slightly higher values\nmeasured with Type I. The presence of rain or wet roads caused the\ndeterioration of the contrast ratio, with Type II road markings exhibiting\nsignificantly higher contrast ratio than Type I, even though the values were\nlow (less than 0.1). These findings matched the output of the ADAS related to\ntraffic lane detection and underlined the importance of road marking\nvisibility. Inadequate lane recognition by ADAS was associated with very low\ncontrast ratio of road markings indeed. Importantly, specific minimum contrast\nratio value could not be found, which was due to the complexity of ADAS\nalgorithms...\n","authors":["Novel Certad","Cristina Olaverri-Monreal","Friedrich Wiesinger","Tomasz E. Burghardt"],"pdf_url":"https://arxiv.org/pdf/2410.13320v1.pdf","comment":"IRF World Congress 2024"},{"id":"http://arxiv.org/abs/2410.10929v2","updated":"2024-10-17T08:10:53Z","published":"2024-10-14T16:35:27Z","title":"ASTM :Autonomous Smart Traffic Management System Using Artificial\n  Intelligence CNN and LSTM","summary":"  In the modern world, the development of Artificial Intelligence (AI) has\ncontributed to improvements in various areas, including automation, computer\nvision, fraud detection, and more. AI can be leveraged to enhance the\nefficiency of Autonomous Smart Traffic Management (ASTM) systems and reduce\ntraffic congestion rates. This paper presents an Autonomous Smart Traffic\nManagement (STM) system that uses AI to improve traffic flow rates. The system\nemploys the YOLO V5 Convolutional Neural Network to detect vehicles in traffic\nmanagement images. Additionally, it predicts the number of vehicles for the\nnext 12 hours using a Recurrent Neural Network with Long Short-Term Memory\n(RNN-LSTM). The Smart Traffic Management Cycle Length Analysis manages the\ntraffic cycle length based on these vehicle predictions, aided by AI. From the\nresults of the RNN-LSTM model for predicting vehicle numbers over the next 12\nhours, we observe that the model predicts traffic with a Mean Squared Error\n(MSE) of 4.521 vehicles and a Root Mean Squared Error (RMSE) of 2.232 vehicles.\nAfter simulating the STM system in the CARLA simulation environment, we found\nthat the Traffic Management Congestion Flow Rate with ASTM (21 vehicles per\nminute) is 50\\% higher than the rate without STM (around 15 vehicles per\nminute). Additionally, the Traffic Management Vehicle Pass Delay with STM (5\nseconds per vehicle) is 70\\% lower than without STM (around 12 seconds per\nvehicle). These results demonstrate that the STM system using AI can increase\ntraffic flow by 50\\% and reduce vehicle pass delays by 70\\%.\n","authors":["Christofel Rio Goenawan"],"pdf_url":"https://arxiv.org/pdf/2410.10929v2.pdf","comment":"In process to IEEE Intelligent Vehicle Symposium 2025"},{"id":"http://arxiv.org/abs/2410.13314v1","updated":"2024-10-17T08:10:41Z","published":"2024-10-17T08:10:41Z","title":"Precipitation Nowcasting Using Diffusion Transformer with Causal\n  Attention","summary":"  Short-term precipitation forecasting remains challenging due to the\ndifficulty in capturing long-term spatiotemporal dependencies. Current deep\nlearning methods fall short in establishing effective dependencies between\nconditions and forecast results, while also lacking interpretability. To\naddress this issue, we propose a Precipitation Nowcasting Using Diffusion\nTransformer with Causal Attention model. Our model leverages Transformer and\ncombines causal attention mechanisms to establish spatiotemporal queries\nbetween conditional information (causes) and forecast results (results). This\ndesign enables the model to effectively capture long-term dependencies,\nallowing forecast results to maintain strong causal relationships with input\nconditions over a wide range of time and space. We explore four variants of\nspatiotemporal information interactions for DTCA, demonstrating that global\nspatiotemporal labeling interactions yield the best performance. In addition,\nwe introduce a Channel-To-Batch shift operation to further enhance the model's\nability to represent complex rainfall dynamics. We conducted experiments on two\ndatasets. Compared to state-of-the-art U-Net-based methods, our approach\nimproved the CSI (Critical Success Index) for predicting heavy precipitation by\napproximately 15% and 8% respectively, achieving state-of-the-art performance.\n","authors":["ChaoRong Li","XuDong Ling","YiLan Xue","Wenjie Luo","LiHong Zhu","FengQing Qin","Yaodong Zhou","Yuanyuan Huang"],"pdf_url":"https://arxiv.org/pdf/2410.13314v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2409.02097v3","updated":"2024-10-17T08:09:37Z","published":"2024-09-03T17:54:39Z","title":"LinFusion: 1 GPU, 1 Minute, 16K Image","summary":"  Modern diffusion models, particularly those utilizing a Transformer-based\nUNet for denoising, rely heavily on self-attention operations to manage complex\nspatial relationships, thus achieving impressive generation performance.\nHowever, this existing paradigm faces significant challenges in generating\nhigh-resolution visual content due to its quadratic time and memory complexity\nwith respect to the number of spatial tokens. To address this limitation, we\naim at a novel linear attention mechanism as an alternative in this paper.\nSpecifically, we begin our exploration from recently introduced models with\nlinear complexity, e.g., Mamba2, RWKV6, Gated Linear Attention, etc, and\nidentify two key features--attention normalization and non-causal\ninference--that enhance high-resolution visual generation performance. Building\non these insights, we introduce a generalized linear attention paradigm, which\nserves as a low-rank approximation of a wide spectrum of popular linear token\nmixers. To save the training cost and better leverage pre-trained models, we\ninitialize our models and distill the knowledge from pre-trained\nStableDiffusion (SD). We find that the distilled model, termed LinFusion,\nachieves performance on par with or superior to the original SD after only\nmodest training, while significantly reducing time and memory complexity.\nExtensive experiments on SD-v1.5, SD-v2.1, and SD-XL demonstrate that LinFusion\nenables satisfactory and efficient zero-shot cross-resolution generation,\naccommodating ultra-resolution images like 16K on a single GPU. Moreover, it is\nhighly compatible with pre-trained SD components and pipelines, such as\nControlNet, IP-Adapter, DemoFusion, DistriFusion, etc, requiring no adaptation\nefforts. Codes are available at https://github.com/Huage001/LinFusion.\n","authors":["Songhua Liu","Weihao Yu","Zhenxiong Tan","Xinchao Wang"],"pdf_url":"https://arxiv.org/pdf/2409.02097v3.pdf","comment":"Work in Progress. Codes are available at\n  https://github.com/Huage001/LinFusion"},{"id":"http://arxiv.org/abs/2410.13311v1","updated":"2024-10-17T08:09:28Z","published":"2024-10-17T08:09:28Z","title":"Enhancing Dataset Distillation via Label Inconsistency Elimination and\n  Learning Pattern Refinement","summary":"  Dataset Distillation (DD) seeks to create a condensed dataset that, when used\nto train a model, enables the model to achieve performance similar to that of a\nmodel trained on the entire original dataset. It relieves the model training\nfrom processing massive data and thus reduces the computation resources,\nstorage, and time costs. This paper illustrates our solution that ranks 1st in\nthe ECCV-2024 Data Distillation Challenge (track 1). Our solution, Modified\nDifficulty-Aligned Trajectory Matching (M-DATM), introduces two key\nmodifications to the original state-of-the-art method DATM: (1) the soft labels\nlearned by DATM do not achieve one-to-one correspondence with the counterparts\ngenerated by the official evaluation script, so we remove the soft labels\ntechnique to alleviate such inconsistency; (2) since the removal of soft labels\nmakes it harder for the synthetic dataset to learn late trajectory information,\nparticularly on Tiny ImageNet, we reduce the matching range, allowing the\nsynthetic data to concentrate more on the easier patterns. In the final\nevaluation, our M-DATM achieved accuracies of 0.4061 and 0.1831 on the\nCIFAR-100 and Tiny ImageNet datasets, ranking 1st in the Fixed Images Per Class\n(IPC) Track.\n","authors":["Chuhao Zhou","Chenxi Jiang","Yi Xie","Haozhi Cao","Jianfei Yang"],"pdf_url":"https://arxiv.org/pdf/2410.13311v1.pdf","comment":"ECCV 2024 Dataset Distillation Challenge"},{"id":"http://arxiv.org/abs/2410.13305v1","updated":"2024-10-17T08:05:02Z","published":"2024-10-17T08:05:02Z","title":"Reference-Based Post-OCR Processing with LLM for Diacritic Languages","summary":"  Extracting fine-grained OCR text from aged documents in diacritic languages\nremains challenging due to unexpected artifacts, time-induced degradation, and\nlack of datasets. While standalone spell correction approaches have been\nproposed, they show limited performance for historical documents due to\nnumerous possible OCR error combinations and differences between modern and\nclassical corpus distributions. We propose a method utilizing available\ncontent-focused ebooks as a reference base to correct imperfect OCR-generated\ntext, supported by large language models. This technique generates\nhigh-precision pseudo-page-to-page labels for diacritic languages, where small\nstrokes pose significant challenges in historical conditions. The pipeline\neliminates various types of noise from aged documents and addresses issues such\nas missing characters, words, and disordered sequences. Our post-processing\nmethod, which generated a large OCR dataset of classical Vietnamese books,\nachieved a mean grading score of 8.72 on a 10-point scale. This outperformed\nthe state-of-the-art transformer-based Vietnamese spell correction model, which\nscored 7.03 when evaluated on a sampled subset of the dataset. We also trained\na baseline OCR model to assess and compare it with well-known engines.\nExperimental results demonstrate the strength of our baseline model compared to\nwidely used open-source solutions. The resulting dataset will be released\npublicly to support future studies.\n","authors":["Thao Do"],"pdf_url":"https://arxiv.org/pdf/2410.13305v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2312.05349v2","updated":"2024-10-17T07:53:51Z","published":"2023-12-08T20:12:26Z","title":"PixLore: A Dataset-driven Approach to Rich Image Captioning","summary":"  In the domain of vision-language integration, generating detailed image\ncaptions poses a significant challenge due to the lack of curated and rich\ndatasets. This study introduces PixLore, a novel method that leverages Querying\nTransformers through the fine-tuning of the BLIP-2 model using the LoRa method\non a standard commercial GPU. The followed approach, which involves training on\na carefully assembled dataset from state-of-the-art Computer Vision models\ncombined and augmented by ChatGPT, addresses the question of whether intricate\nimage understanding can be achieved with an ensemble of smaller-scale models,\nreferred to as Knowledge Stitching. Comparative evaluations against major\nmodels such as GPT-4 and Google Bard demonstrate that PixLore-2.7B, despite\nhaving considerably fewer parameters, is rated higher than the existing\nState-of-the-Art models in over half of the assessments. Precisely, PixLore\noutperform Bard and BLIP-2, which score approximately 35.18% and 27.98% lower\nthan PixLore in the task of image captioning. This research not only presents a\ngroundbreaking approach but also highlights the importance of well-curated\ndatasets in enhancing the performance of smaller models.\n","authors":["Diego Bonilla"],"pdf_url":"https://arxiv.org/pdf/2312.05349v2.pdf","comment":"Paper in preprint pending of publication"},{"id":"http://arxiv.org/abs/2410.13295v1","updated":"2024-10-17T07:49:23Z","published":"2024-10-17T07:49:23Z","title":"PiLocNet: Physics-informed neural network on 3D localization with\n  rotating point spread function","summary":"  For the 3D localization problem using point spread function (PSF)\nengineering, we propose a novel enhancement of our previously introduced\nlocalization neural network, LocNet. The improved network is a physics-informed\nneural network (PINN) that we call PiLocNet. Previous works on the localization\nproblem may be categorized separately into model-based optimization and neural\nnetwork approaches. Our PiLocNet combines the unique strengths of both\napproaches by incorporating forward-model-based information into the network\nvia a data-fitting loss term that constrains the neural network to yield\nresults that are physically sensible. We additionally incorporate certain\nregularization terms from the variational method, which further improves the\nrobustness of the network in the presence of image noise, as we show for the\nPoisson and Gaussian noise models. This framework accords interpretability to\nthe neural network, and the results we obtain show its superiority. Although\nthe paper focuses on the use of single-lobe rotating PSF to encode the full 3D\nsource location, we expect the method to be widely applicable to other PSFs and\nimaging problems that are constrained by known forward processes.\n","authors":["Mingda Lu","Zitian Ao","Chao Wang","Sudhakar Prasad","Raymond H. Chan"],"pdf_url":"https://arxiv.org/pdf/2410.13295v1.pdf","comment":"25 pages, 4 figures"},{"id":"http://arxiv.org/abs/2410.13294v1","updated":"2024-10-17T07:47:41Z","published":"2024-10-17T07:47:41Z","title":"LESS: Label-Efficient and Single-Stage Referring 3D Segmentation","summary":"  Referring 3D Segmentation is a visual-language task that segments all points\nof the specified object from a 3D point cloud described by a sentence of query.\nPrevious works perform a two-stage paradigm, first conducting language-agnostic\ninstance segmentation then matching with given text query. However, the\nsemantic concepts from text query and visual cues are separately interacted\nduring the training, and both instance and semantic labels for each object are\nrequired, which is time consuming and human-labor intensive. To mitigate these\nissues, we propose a novel Referring 3D Segmentation pipeline, Label-Efficient\nand Single-Stage, dubbed LESS, which is only under the supervision of efficient\nbinary mask. Specifically, we design a Point-Word Cross-Modal Alignment module\nfor aligning the fine-grained features of points and textual embedding. Query\nMask Predictor module and Query-Sentence Alignment module are introduced for\ncoarse-grained alignment between masks and query. Furthermore, we propose an\narea regularization loss, which coarsely reduces irrelevant background\npredictions on a large scale. Besides, a point-to-point contrastive loss is\nproposed concentrating on distinguishing points with subtly similar features.\nThrough extensive experiments, we achieve state-of-the-art performance on\nScanRefer dataset by surpassing the previous methods about 3.7% mIoU using only\nbinary labels.\n","authors":["Xuexun Liu","Xiaoxu Xu","Jinlong Li","Qiudan Zhang","Xu Wang","Nicu Sebe","Lin Ma"],"pdf_url":"https://arxiv.org/pdf/2410.13294v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.02240v3","updated":"2024-10-17T07:46:59Z","published":"2024-10-03T06:25:53Z","title":"SCA: Highly Efficient Semantic-Consistent Unrestricted Adversarial\n  Attack","summary":"  Deep neural network based systems deployed in sensitive environments are\nvulnerable to adversarial attacks. Unrestricted adversarial attacks typically\nmanipulate the semantic content of an image (e.g., color or texture) to create\nadversarial examples that are both effective and photorealistic. Recent works\nhave utilized the diffusion inversion process to map images into a latent\nspace, where high-level semantics are manipulated by introducing perturbations.\nHowever, they often results in substantial semantic distortions in the denoised\noutput and suffers from low efficiency. In this study, we propose a novel\nframework called Semantic-Consistent Unrestricted Adversarial Attacks (SCA),\nwhich employs an inversion method to extract edit-friendly noise maps and\nutilizes Multimodal Large Language Model (MLLM) to provide semantic guidance\nthroughout the process. Under the condition of rich semantic information\nprovided by MLLM, we perform the DDPM denoising process of each step using a\nseries of edit-friendly noise maps, and leverage DPM Solver++ to accelerate\nthis process, enabling efficient sampling with semantic consistency. Compared\nto existing methods, our framework enables the efficient generation of\nadversarial examples that exhibit minimal discernible semantic changes.\nConsequently, we for the first time introduce Semantic-Consistent Adversarial\nExamples (SCAE). Extensive experiments and visualizations have demonstrated the\nhigh efficiency of SCA, particularly in being on average 12 times faster than\nthe state-of-the-art attacks. Our research can further draw attention to the\nsecurity of multimedia information.\n","authors":["Zihao Pan","Weibin Wu","Yuhang Cao","Zibin Zheng"],"pdf_url":"https://arxiv.org/pdf/2410.02240v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.13285v1","updated":"2024-10-17T07:30:20Z","published":"2024-10-17T07:30:20Z","title":"Composing Novel Classes: A Concept-Driven Approach to Generalized\n  Category Discovery","summary":"  We tackle the generalized category discovery (GCD) problem, which aims to\ndiscover novel classes in unlabeled datasets by leveraging the knowledge of\nknown classes. Previous works utilize the known class knowledge through shared\nrepresentation spaces. Despite their progress, our analysis experiments show\nthat novel classes can achieve impressive clustering results on the feature\nspace of a known class pre-trained model, suggesting that existing methods may\nnot fully utilize known class knowledge. To address it, we introduce a novel\nconcept learning framework for GCD, named ConceptGCD, that categorizes concepts\ninto two types: derivable and underivable from known class concepts, and adopts\na stage-wise learning strategy to learn them separately. Specifically, our\nframework first extracts known class concepts by a known class pre-trained\nmodel and then produces derivable concepts from them by a generator layer with\na covariance-augmented loss. Subsequently, we expand the generator layer to\nlearn underivable concepts in a balanced manner ensured by a concept score\nnormalization strategy and integrate a contrastive loss to preserve previously\nlearned concepts. Extensive experiments on various benchmark datasets\ndemonstrate the superiority of our approach over the previous state-of-the-art\nmethods. Code will be available soon.\n","authors":["Chuyu Zhang","Peiyan Gu","Xueyang Yu","Xuming He"],"pdf_url":"https://arxiv.org/pdf/2410.13285v1.pdf","comment":"Underreview. The first two authors contribute equally"},{"id":"http://arxiv.org/abs/2404.06666v3","updated":"2024-10-17T07:28:23Z","published":"2024-04-10T00:26:08Z","title":"SafeGen: Mitigating Sexually Explicit Content Generation in\n  Text-to-Image Models","summary":"  Text-to-image (T2I) models, such as Stable Diffusion, have exhibited\nremarkable performance in generating high-quality images from text descriptions\nin recent years. However, text-to-image models may be tricked into generating\nnot-safe-for-work (NSFW) content, particularly in sexually explicit scenarios.\nExisting countermeasures mostly focus on filtering inappropriate inputs and\noutputs, or suppressing improper text embeddings, which can block sexually\nexplicit content (e.g., naked) but may still be vulnerable to adversarial\nprompts -- inputs that appear innocent but are ill-intended. In this paper, we\npresent SafeGen, a framework to mitigate sexual content generation by\ntext-to-image models in a text-agnostic manner. The key idea is to eliminate\nexplicit visual representations from the model regardless of the text input. In\nthis way, the text-to-image model is resistant to adversarial prompts since\nsuch unsafe visual representations are obstructed from within. Extensive\nexperiments conducted on four datasets and large-scale user studies demonstrate\nSafeGen's effectiveness in mitigating sexually explicit content generation\nwhile preserving the high-fidelity of benign images. SafeGen outperforms eight\nstate-of-the-art baseline methods and achieves 99.4% sexual content removal\nperformance. Furthermore, our constructed benchmark of adversarial prompts\nprovides a basis for future development and evaluation of anti-NSFW-generation\nmethods.\n","authors":["Xinfeng Li","Yuchen Yang","Jiangyi Deng","Chen Yan","Yanjiao Chen","Xiaoyu Ji","Wenyuan Xu"],"pdf_url":"https://arxiv.org/pdf/2404.06666v3.pdf","comment":"Accepted by ACM CCS 2024. Please cite this paper as \"Xinfeng Li,\n  Yuchen Yang, Jiangyi Deng, Chen Yan, Yanjiao Chen, Xiaoyu Ji, Wenyuan Xu.\n  SafeGen: Mitigating Sexually Explicit Content Generation in Text-to-Image\n  Models. In Proceedings of ACM Conference on Computer and Communications\n  Security (CCS), 2024.\""},{"id":"http://arxiv.org/abs/2409.06704v2","updated":"2024-10-17T07:14:12Z","published":"2024-09-10T17:59:55Z","title":"GeoCalib: Learning Single-image Calibration with Geometric Optimization","summary":"  From a single image, visual cues can help deduce intrinsic and extrinsic\ncamera parameters like the focal length and the gravity direction. This\nsingle-image calibration can benefit various downstream applications like image\nediting and 3D mapping. Current approaches to this problem are based on either\nclassical geometry with lines and vanishing points or on deep neural networks\ntrained end-to-end. The learned approaches are more robust but struggle to\ngeneralize to new environments and are less accurate than their classical\ncounterparts. We hypothesize that they lack the constraints that 3D geometry\nprovides. In this work, we introduce GeoCalib, a deep neural network that\nleverages universal rules of 3D geometry through an optimization process.\nGeoCalib is trained end-to-end to estimate camera parameters and learns to find\nuseful visual cues from the data. Experiments on various benchmarks show that\nGeoCalib is more robust and more accurate than existing classical and learned\napproaches. Its internal optimization estimates uncertainties, which help flag\nfailure cases and benefit downstream applications like visual localization. The\ncode and trained models are publicly available at\nhttps://github.com/cvg/GeoCalib.\n","authors":["Alexander Veicht","Paul-Edouard Sarlin","Philipp Lindenberger","Marc Pollefeys"],"pdf_url":"https://arxiv.org/pdf/2409.06704v2.pdf","comment":"Presented at ECCV 2024"},{"id":"http://arxiv.org/abs/2410.13280v1","updated":"2024-10-17T07:13:00Z","published":"2024-10-17T07:13:00Z","title":"Hybrid bundle-adjusting 3D Gaussians for view consistent rendering with\n  pose optimization","summary":"  Novel view synthesis has made significant progress in the field of 3D\ncomputer vision. However, the rendering of view-consistent novel views from\nimperfect camera poses remains challenging. In this paper, we introduce a\nhybrid bundle-adjusting 3D Gaussians model that enables view-consistent\nrendering with pose optimization. This model jointly extract image-based and\nneural 3D representations to simultaneously generate view-consistent images and\ncamera poses within forward-facing scenes. The effective of our model is\ndemonstrated through extensive experiments conducted on both real and synthetic\ndatasets. These experiments clearly illustrate that our model can effectively\noptimize neural scene representations while simultaneously resolving\nsignificant camera pose misalignments. The source code is available at\nhttps://github.com/Bistu3DV/hybridBA.\n","authors":["Yanan Guo","Ying Xie","Ying Chang","Benkui Zhang","Bo Jia","Lin Cao"],"pdf_url":"https://arxiv.org/pdf/2410.13280v1.pdf","comment":"Photonics Asia 2024"},{"id":"http://arxiv.org/abs/2403.17898v2","updated":"2024-10-17T07:11:31Z","published":"2024-03-26T17:39:36Z","title":"Octree-GS: Towards Consistent Real-time Rendering with LOD-Structured 3D\n  Gaussians","summary":"  The recent 3D Gaussian splatting (3D-GS) has shown remarkable rendering\nfidelity and efficiency compared to NeRF-based neural scene representations.\nWhile demonstrating the potential for real-time rendering, 3D-GS encounters\nrendering bottlenecks in large scenes with complex details due to an excessive\nnumber of Gaussian primitives located within the viewing frustum. This\nlimitation is particularly noticeable in zoom-out views and can lead to\ninconsistent rendering speeds in scenes with varying details. Moreover, it\noften struggles to capture the corresponding level of details at different\nscales with its heuristic density control operation. Inspired by the\nLevel-of-Detail (LOD) techniques, we introduce Octree-GS, featuring an\nLOD-structured 3D Gaussian approach supporting level-of-detail decomposition\nfor scene representation that contributes to the final rendering results. Our\nmodel dynamically selects the appropriate level from the set of\nmulti-resolution anchor points, ensuring consistent rendering performance with\nadaptive LOD adjustments while maintaining high-fidelity rendering results.\n","authors":["Kerui Ren","Lihan Jiang","Tao Lu","Mulin Yu","Linning Xu","Zhangkai Ni","Bo Dai"],"pdf_url":"https://arxiv.org/pdf/2403.17898v2.pdf","comment":"Project page: https://city-super.github.io/octree-gs/"},{"id":"http://arxiv.org/abs/2405.20141v3","updated":"2024-10-17T06:54:04Z","published":"2024-05-30T15:16:06Z","title":"OpenDAS: Open-Vocabulary Domain Adaptation for Segmentation","summary":"  Recently, Vision-Language Models (VLMs) have advanced segmentation techniques\nby shifting from the traditional segmentation of a closed-set of predefined\nobject classes to open-vocabulary segmentation (OVS), allowing users to segment\nnovel classes and concepts unseen during training of the segmentation model.\nHowever, this flexibility comes with a trade-off: fully-supervised closed-set\nmethods still outperform OVS methods on base classes, that is on classes on\nwhich they have been explicitly trained. This is due to the lack of\npixel-aligned training masks for VLMs (which are trained on image-caption\npairs), and the absence of domain-specific knowledge, such as autonomous\ndriving. Therefore, we propose the task of open-vocabulary domain adaptation to\ninfuse domain-specific knowledge into VLMs while preserving their\nopen-vocabulary nature. By doing so, we achieve improved performance in base\nand novel classes. Existing VLM adaptation methods improve performance on base\n(training) queries, but fail to fully preserve the open-set capabilities of\nVLMs on novel queries. To address this shortcoming, we combine\nparameter-efficient prompt tuning with a triplet-loss-based training strategy\nthat uses auxiliary negative queries. Notably, our approach is the only\nparameter-efficient method that consistently surpasses the original VLM on\nnovel classes. Our adapted VLMs can seamlessly be integrated into existing OVS\npipelines, e.g., improving OVSeg by +6.0% mIoU on ADE20K for open-vocabulary 2D\nsegmentation, and OpenMask3D by +4.1% AP on ScanNet++ Offices for\nopen-vocabulary 3D instance segmentation without other changes.\n","authors":["Gonca Yilmaz","Songyou Peng","Marc Pollefeys","Francis Engelmann","Hermann Blum"],"pdf_url":"https://arxiv.org/pdf/2405.20141v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.13271v1","updated":"2024-10-17T06:51:10Z","published":"2024-10-17T06:51:10Z","title":"Inductive Gradient Adjustment For Spectral Bias In Implicit Neural\n  Representations","summary":"  Implicit Neural Representations (INRs), as a versatile representation\nparadigm, have achieved success in various computer vision tasks. Due to the\nspectral bias of the vanilla multi-layer perceptrons (MLPs), existing methods\nfocus on designing MLPs with sophisticated architectures or repurposing\ntraining techniques for highly accurate INRs. In this paper, we delve into the\nlinear dynamics model of MLPs and theoretically identify the empirical Neural\nTangent Kernel (eNTK) matrix as a reliable link between spectral bias and\ntraining dynamics. Based on eNTK matrix, we propose a practical inductive\ngradient adjustment method, which could purposefully improve the spectral bias\nvia inductive generalization of eNTK-based gradient transformation matrix. We\nevaluate our method on different INRs tasks with various INR architectures and\ncompare to existing training techniques. The superior representation\nperformance clearly validates the advantage of our proposed method. Armed with\nour gradient adjustment method, better INRs with more enhanced texture details\nand sharpened edges can be learned from data by tailored improvements on\nspectral bias.\n","authors":["Kexuan Shi","Hai Chen","Leheng Zhang","Shuhang Gu"],"pdf_url":"https://arxiv.org/pdf/2410.13271v1.pdf","comment":"28 pages, 12 figures"},{"id":"http://arxiv.org/abs/2410.13242v1","updated":"2024-10-17T05:53:13Z","published":"2024-10-17T05:53:13Z","title":"Fundus to Fluorescein Angiography Video Generation as a Retinal\n  Generative Foundation Model","summary":"  Fundus fluorescein angiography (FFA) is crucial for diagnosing and monitoring\nretinal vascular issues but is limited by its invasive nature and restricted\naccessibility compared to color fundus (CF) imaging. Existing methods that\nconvert CF images to FFA are confined to static image generation, missing the\ndynamic lesional changes. We introduce Fundus2Video, an autoregressive\ngenerative adversarial network (GAN) model that generates dynamic FFA videos\nfrom single CF images. Fundus2Video excels in video generation, achieving an\nFVD of 1497.12 and a PSNR of 11.77. Clinical experts have validated the\nfidelity of the generated videos. Additionally, the model's generator\ndemonstrates remarkable downstream transferability across ten external public\ndatasets, including blood vessel segmentation, retinal disease diagnosis,\nsystemic disease prediction, and multimodal retrieval, showcasing impressive\nzero-shot and few-shot capabilities. These findings position Fundus2Video as a\npowerful, non-invasive alternative to FFA exams and a versatile retinal\ngenerative foundation model that captures both static and temporal retinal\nfeatures, enabling the representation of complex inter-modality relationships.\n","authors":["Weiyi Zhang","Jiancheng Yang","Ruoyu Chen","Siyu Huang","Pusheng Xu","Xiaolan Chen","Shanfu Lu","Hongyu Cao","Mingguang He","Danli Shi"],"pdf_url":"https://arxiv.org/pdf/2410.13242v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.13227v1","updated":"2024-10-17T05:27:44Z","published":"2024-10-17T05:27:44Z","title":"Latent Image and Video Resolution Prediction using Convolutional Neural\n  Networks","summary":"  This paper introduces a Video Quality Assessment (VQA) problem that has\nreceived little attention in the literature, called the latent resolution\nprediction problem. The problem arises when images or videos are upscaled from\ntheir native resolution and are reported as having a higher resolution than\ntheir native resolution. This paper formulates the problem, constructs a\ndataset for training and evaluation, and introduces several machine learning\nalgorithms, including two Convolutional Neural Networks (CNNs), to address this\nproblem. Experiments indicate that some proposed methods can predict the latent\nvideo resolution with about 95% accuracy.\n","authors":["Rittwika Kansabanik","Adrian Barbu"],"pdf_url":"https://arxiv.org/pdf/2410.13227v1.pdf","comment":"Submitted in ICIP conference"},{"id":"http://arxiv.org/abs/2410.13195v1","updated":"2024-10-17T03:48:02Z","published":"2024-10-17T03:48:02Z","title":"UniG: Modelling Unitary 3D Gaussians for View-consistent 3D\n  Reconstruction","summary":"  In this work, we present UniG, a view-consistent 3D reconstruction and novel\nview synthesis model that generates a high-fidelity representation of 3D\nGaussians from sparse images. Existing 3D Gaussians-based methods usually\nregress Gaussians per-pixel of each view, create 3D Gaussians per view\nseparately, and merge them through point concatenation. Such a view-independent\nreconstruction approach often results in a view inconsistency issue, where the\npredicted positions of the same 3D point from different views may have\ndiscrepancies. To address this problem, we develop a DETR (DEtection\nTRansformer)-like framework, which treats 3D Gaussians as decoder queries and\nupdates their parameters layer by layer by performing multi-view\ncross-attention (MVDFA) over multiple input images. In this way, multiple views\nnaturally contribute to modeling a unitary representation of 3D Gaussians,\nthereby making 3D reconstruction more view-consistent. Moreover, as the number\nof 3D Gaussians used as decoder queries is irrespective of the number of input\nviews, allow an arbitrary number of input images without causing memory\nexplosion. Extensive experiments validate the advantages of our approach,\nshowcasing superior performance over existing methods quantitatively (improving\nPSNR by 4.2 dB when trained on Objaverse and tested on the GSO benchmark) and\nqualitatively.\n","authors":["Jiamin Wu","Kenkun Liu","Yukai Shi","Xiaoke Jiang","Yuan Yao","Lei Zhang"],"pdf_url":"https://arxiv.org/pdf/2410.13195v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.13193v1","updated":"2024-10-17T03:42:06Z","published":"2024-10-17T03:42:06Z","title":"Golyadkin's Torment: Doppelgängers and Adversarial Vulnerability","summary":"  Many machine learning (ML) classifiers are claimed to outperform humans, but\nthey still make mistakes that humans do not. The most notorious examples of\nsuch mistakes are adversarial visual metamers. This paper aims to define and\ninvestigate the phenomenon of adversarial Doppelgangers (AD), which includes\nadversarial visual metamers, and to compare the performance and robustness of\nML classifiers to human performance.\n  We find that AD are inputs that are close to each other with respect to a\nperceptual metric defined in this paper. AD are qualitatively different from\nthe usual adversarial examples. The vast majority of classifiers are vulnerable\nto AD and robustness-accuracy trade-offs may not improve them. Some\nclassification problems may not admit any AD robust classifiers because the\nunderlying classes are ambiguous. We provide criteria that can be used to\ndetermine whether a classification problem is well defined or not; describe the\nstructure and attributes of an AD-robust classifier; introduce and explore the\nnotions of conceptual entropy and regions of conceptual ambiguity for\nclassifiers that are vulnerable to AD attacks, along with methods to bound the\nAD fooling rate of an attack. We define the notion of classifiers that exhibit\nhypersensitive behavior, that is, classifiers whose only mistakes are\nadversarial Doppelgangers. Improving the AD robustness of hyper-sensitive\nclassifiers is equivalent to improving accuracy. We identify conditions\nguaranteeing that all classifiers with sufficiently high accuracy are\nhyper-sensitive.\n  Our findings are aimed at significant improvements in the reliability and\nsecurity of machine learning systems.\n","authors":["George I. Kamberov"],"pdf_url":"https://arxiv.org/pdf/2410.13193v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2402.12424v5","updated":"2024-10-17T03:39:59Z","published":"2024-02-19T16:34:50Z","title":"Tables as Texts or Images: Evaluating the Table Reasoning Ability of\n  LLMs and MLLMs","summary":"  In this paper, we investigate the effectiveness of various LLMs in\ninterpreting tabular data through different prompting strategies and data\nformats. Our analyses extend across six benchmarks for table-related tasks such\nas question-answering and fact-checking. We introduce for the first time the\nassessment of LLMs' performance on image-based table representations.\nSpecifically, we compare five text-based and three image-based table\nrepresentations, demonstrating the role of representation and prompting on LLM\nperformance. Our study provides insights into the effective use of LLMs on\ntable-related tasks.\n","authors":["Naihao Deng","Zhenjie Sun","Ruiqi He","Aman Sikka","Yulong Chen","Lin Ma","Yue Zhang","Rada Mihalcea"],"pdf_url":"https://arxiv.org/pdf/2402.12424v5.pdf","comment":"Accepted to ACL 2024 Findings; Naihao and Zhenjie contributed equally\n  to the project; Data available at:\n  https://github.com/dnaihao/Tables-as-Texts-or-Images"},{"id":"http://arxiv.org/abs/2309.14122v3","updated":"2024-10-17T03:34:21Z","published":"2023-09-25T13:20:15Z","title":"SurrogatePrompt: Bypassing the Safety Filter of Text-to-Image Models via\n  Substitution","summary":"  Advanced text-to-image models such as DALL$\\cdot$E 2 and Midjourney possess\nthe capacity to generate highly realistic images, raising significant concerns\nregarding the potential proliferation of unsafe content. This includes adult,\nviolent, or deceptive imagery of political figures. Despite claims of rigorous\nsafety mechanisms implemented in these models to restrict the generation of\nnot-safe-for-work (NSFW) content, we successfully devise and exhibit the first\nprompt attacks on Midjourney, resulting in the production of abundant\nphotorealistic NSFW images. We reveal the fundamental principles of such prompt\nattacks and suggest strategically substituting high-risk sections within a\nsuspect prompt to evade closed-source safety measures. Our novel framework,\nSurrogatePrompt, systematically generates attack prompts, utilizing large\nlanguage models, image-to-text, and image-to-image modules to automate attack\nprompt creation at scale. Evaluation results disclose an 88% success rate in\nbypassing Midjourney's proprietary safety filter with our attack prompts,\nleading to the generation of counterfeit images depicting political figures in\nviolent scenarios. Both subjective and objective assessments validate that the\nimages generated from our attack prompts present considerable safety hazards.\n","authors":["Zhongjie Ba","Jieming Zhong","Jiachen Lei","Peng Cheng","Qinglong Wang","Zhan Qin","Zhibo Wang","Kui Ren"],"pdf_url":"https://arxiv.org/pdf/2309.14122v3.pdf","comment":"To appear in the the 31st ACM Conference on Computer and\n  Communications Security (CCS)"},{"id":"http://arxiv.org/abs/2406.18572v2","updated":"2024-10-17T03:25:47Z","published":"2024-06-03T18:08:56Z","title":"GeoReasoner: Geo-localization with Reasoning in Street Views using a\n  Large Vision-Language Model","summary":"  This work tackles the problem of geo-localization with a new paradigm using a\nlarge vision-language model (LVLM) augmented with human inference knowledge. A\nprimary challenge here is the scarcity of data for training the LVLM - existing\nstreet-view datasets often contain numerous low-quality images lacking visual\nclues, and lack any reasoning inference. To address the data-quality issue, we\ndevise a CLIP-based network to quantify the degree of street-view images being\nlocatable, leading to the creation of a new dataset comprising highly locatable\nstreet views. To enhance reasoning inference, we integrate external knowledge\nobtained from real geo-localization games, tapping into valuable human\ninference capabilities. The data are utilized to train GeoReasoner, which\nundergoes fine-tuning through dedicated reasoning and location-tuning stages.\nQualitative and quantitative evaluations illustrate that GeoReasoner\noutperforms counterpart LVLMs by more than 25% at country-level and 38% at\ncity-level geo-localization tasks, and surpasses StreetCLIP performance while\nrequiring fewer training resources. The data and code are available at\nhttps://github.com/lingli1996/GeoReasoner.\n","authors":["Ling Li","Yu Ye","Bingchuan Jiang","Wei Zeng"],"pdf_url":"https://arxiv.org/pdf/2406.18572v2.pdf","comment":"ICML 2024"},{"id":"http://arxiv.org/abs/2410.07266v3","updated":"2024-10-17T03:25:01Z","published":"2024-10-09T01:39:26Z","title":"Spiking GS: Towards High-Accuracy and Low-Cost Surface Reconstruction\n  via Spiking Neuron-based Gaussian Splatting","summary":"  3D Gaussian Splatting is capable of reconstructing 3D scenes in minutes.\nDespite recent advances in improving surface reconstruction accuracy, the\nreconstructed results still exhibit bias and suffer from inefficiency in\nstorage and training. This paper provides a different observation on the cause\nof the inefficiency and the reconstruction bias, which is attributed to the\nintegration of the low-opacity parts (LOPs) of the generated Gaussians. We show\nthat LOPs consist of Gaussians with overall low-opacity (LOGs) and the\nlow-opacity tails (LOTs) of Gaussians. We propose Spiking GS to reduce such two\ntypes of LOPs by integrating spiking neurons into the Gaussian Splatting\npipeline. Specifically, we introduce global and local full-precision\nintegrate-and-fire spiking neurons to the opacity and representation function\nof flattened 3D Gaussians, respectively. Furthermore, we enhance the density\ncontrol strategy with spiking neurons' thresholds and a new criterion on the\nscale of Gaussians. Our method can represent more accurate reconstructed\nsurfaces at a lower cost. The supplementary material and code are available at\nhttps://github.com/zju-bmi-lab/SpikingGS.\n","authors":["Weixing Zhang","Zongrui Li","De Ma","Huajin Tang","Xudong Jiang","Qian Zheng","Gang Pan"],"pdf_url":"https://arxiv.org/pdf/2410.07266v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.05771v2","updated":"2024-10-17T03:16:52Z","published":"2024-10-08T07:53:06Z","title":"Cefdet: Cognitive Effectiveness Network Based on Fuzzy Inference for\n  Action Detection","summary":"  Action detection and understanding provide the foundation for the generation\nand interaction of multimedia content. However, existing methods mainly focus\non constructing complex relational inference networks, overlooking the judgment\nof detection effectiveness. Moreover, these methods frequently generate\ndetection results with cognitive abnormalities. To solve the above problems,\nthis study proposes a cognitive effectiveness network based on fuzzy inference\n(Cefdet), which introduces the concept of \"cognition-based detection\" to\nsimulate human cognition. First, a fuzzy-driven cognitive effectiveness\nevaluation module (FCM) is established to introduce fuzzy inference into action\ndetection. FCM is combined with human action features to simulate the\ncognition-based detection process, which clearly locates the position of frames\nwith cognitive abnormalities. Then, a fuzzy cognitive update strategy (FCS) is\nproposed based on the FCM, which utilizes fuzzy logic to re-detect the\ncognition-based detection results and effectively update the results with\ncognitive abnormalities. Experimental results demonstrate that Cefdet exhibits\nsuperior performance against several mainstream algorithms on the public\ndatasets, validating its effectiveness and superiority. Code is available at\nhttps://github.com/12sakura/Cefdet.\n","authors":["Zhe Luo","Weina Fu","Shuai Liu","Saeed Anwar","Muhammad Saqib","Sambit Bakshi","Khan Muhammad"],"pdf_url":"https://arxiv.org/pdf/2410.05771v2.pdf","comment":"The paper has been accepted by ACM MM. If you find this work helpful,\n  please consider citing our paper. Zhe Luo, Weina Fu, Shuai Liu, Saeed Anwar,\n  Muhammad Saqib, Sambit Bakshi, Khan Muhammad (2024) Cefdet: Cognitive\n  Effectiveness Network Based on Fuzzy Inference for Action Detection, 32nd ACM\n  International Conference on Multimedia, online first, 10.1145/3664647.3681226"},{"id":"http://arxiv.org/abs/2401.15883v2","updated":"2024-10-17T03:00:14Z","published":"2024-01-29T04:35:48Z","title":"Model Supply Chain Poisoning: Backdooring Pre-trained Models via\n  Embedding Indistinguishability","summary":"  Pre-trained models (PTMs) are widely adopted across various downstream tasks\nin the machine learning supply chain. Adopting untrustworthy PTMs introduces\nsignificant security risks, where adversaries can poison the model supply chain\nby embedding hidden malicious behaviors (backdoors) into PTMs. However,\nexisting backdoor attacks to PTMs can only achieve partially task-agnostic and\nthe embedded backdoors are easily erased during the fine-tuning process. This\nmakes it challenging for the backdoors to persist and propagate through the\nsupply chain. In this paper, we propose a novel and severer backdoor attack,\nTransTroj, which enables the backdoors embedded in PTMs to efficiently transfer\nin the model supply chain. In particular, we first formalize this attack as an\nindistinguishability problem between poisoned and clean samples in the\nembedding space. We decompose embedding indistinguishability into pre- and\npost-indistinguishability, representing the similarity of the poisoned and\nreference embeddings before and after the attack. Then, we propose a two-stage\noptimization that separately optimizes triggers and victim PTMs to achieve\nembedding indistinguishability. We evaluate TransTroj on four PTMs and six\ndownstream tasks. Experimental results show that our method significantly\noutperforms SOTA task-agnostic backdoor attacks -- achieving nearly 100\\%\nattack success rate on most downstream tasks -- and demonstrates robustness\nunder various system settings. Our findings underscore the urgent need to\nsecure the model supply chain against such transferable backdoor attacks. The\ncode is available at https://github.com/haowang-cqu/TransTroj .\n","authors":["Hao Wang","Shangwei Guo","Jialing He","Hangcheng Liu","Tianwei Zhang","Tao Xiang"],"pdf_url":"https://arxiv.org/pdf/2401.15883v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.13174v1","updated":"2024-10-17T02:57:35Z","published":"2024-10-17T02:57:35Z","title":"Scalable Drift Monitoring in Medical Imaging AI","summary":"  The integration of artificial intelligence (AI) into medical imaging has\nadvanced clinical diagnostics but poses challenges in managing model drift and\nensuring long-term reliability. To address these challenges, we develop MMC+,\nan enhanced framework for scalable drift monitoring, building upon the\nCheXstray framework that introduced real-time drift detection for medical\nimaging AI models using multi-modal data concordance. This work extends the\noriginal framework's methodologies, providing a more scalable and adaptable\nsolution for real-world healthcare settings and offers a reliable and\ncost-effective alternative to continuous performance monitoring addressing\nlimitations of both continuous and periodic monitoring methods. MMC+ introduces\ncritical improvements to the original framework, including more robust handling\nof diverse data streams, improved scalability with the integration of\nfoundation models like MedImageInsight for high-dimensional image embeddings\nwithout site-specific training, and the introduction of uncertainty bounds to\nbetter capture drift in dynamic clinical environments. Validated with\nreal-world data from Massachusetts General Hospital during the COVID-19\npandemic, MMC+ effectively detects significant data shifts and correlates them\nwith model performance changes. While not directly predicting performance\ndegradation, MMC+ serves as an early warning system, indicating when AI systems\nmay deviate from acceptable performance bounds and enabling timely\ninterventions. By emphasizing the importance of monitoring diverse data streams\nand evaluating data shifts alongside model performance, this work contributes\nto the broader adoption and integration of AI solutions in clinical settings.\n","authors":["Jameson Merkow","Felix J. Dorfner","Xiyu Yang","Alexander Ersoy","Giridhar Dasegowda","Mannudeep Kalra","Matthew P. Lungren","Christopher P. Bridge","Ivan Tarapov"],"pdf_url":"https://arxiv.org/pdf/2410.13174v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.05799v3","updated":"2024-10-17T02:41:16Z","published":"2024-10-08T08:33:47Z","title":"SeeClear: Semantic Distillation Enhances Pixel Condensation for Video\n  Super-Resolution","summary":"  Diffusion-based Video Super-Resolution (VSR) is renowned for generating\nperceptually realistic videos, yet it grapples with maintaining detail\nconsistency across frames due to stochastic fluctuations. The traditional\napproach of pixel-level alignment is ineffective for diffusion-processed frames\nbecause of iterative disruptions. To overcome this, we introduce SeeClear--a\nnovel VSR framework leveraging conditional video generation, orchestrated by\ninstance-centric and channel-wise semantic controls. This framework integrates\na Semantic Distiller and a Pixel Condenser, which synergize to extract and\nupscale semantic details from low-resolution frames. The Instance-Centric\nAlignment Module (InCAM) utilizes video-clip-wise tokens to dynamically relate\npixels within and across frames, enhancing coherency. Additionally, the\nChannel-wise Texture Aggregation Memory (CaTeGory) infuses extrinsic knowledge,\ncapitalizing on long-standing semantic textures. Our method also innovates the\nblurring diffusion process with the ResShift mechanism, finely balancing\nbetween sharpness and diffusion effects. Comprehensive experiments confirm our\nframework's advantage over state-of-the-art diffusion-based VSR techniques. The\ncode is available: https://github.com/Tang1705/SeeClear-NeurIPS24.\n","authors":["Qi Tang","Yao Zhao","Meiqin Liu","Chao Yao"],"pdf_url":"https://arxiv.org/pdf/2410.05799v3.pdf","comment":"Accepted to NeurIPS 2024"},{"id":"http://arxiv.org/abs/2410.06997v2","updated":"2024-10-17T02:36:38Z","published":"2024-10-09T15:44:34Z","title":"A Diffusion-based Xray2MRI Model: Generating Pseudo-MRI Volumes From one\n  Single X-ray","summary":"  Knee osteoarthritis (KOA) is a prevalent musculoskeletal disorder, and X-rays\nare commonly used for its diagnosis due to their cost-effectiveness. Magnetic\nResonance Imaging (MRI), on the other hand, offers detailed soft tissue\nvisualization and has become a valuable supplementary diagnostic tool for KOA.\nUnfortunately, the high cost and limited accessibility of MRI hinders its\nwidespread use, leaving many patients with KOA to rely solely on X-ray imaging.\nIn this study, we introduce a novel diffusion-based Xray2MRI model capable of\ngenerating pseudo-MRI volumes from a single X-ray image. In addition to using\nX-rays as conditional input, our model integrates target depth, KOA probability\ndistribution, and image intensity distribution modules to guide the synthesis\nprocess, ensuring that the generated corresponding slices accurately correspond\nto the anatomical structures. Experimental results demonstrate that by\nintegrating information from X-rays with additional input data, our proposed\napproach is capable of generating pseudo-MRI sequences that approximate real\nMRI scans. In addition, by increasing the number of inference steps, the model\nachieves effective interpolation, which further improves the continuity and\nsmoothness of the generated MRI sequences, representing a promising first\nattempt at cost-effective medical imaging solutions. This study is available on\nhttps://zwang78.github.io/.\n","authors":["Zhe Wang","Rachid Jennane","Aladine Chetouani","Yung Hsin Chen","Fabian Bauer","Mohamed Jarraya"],"pdf_url":"https://arxiv.org/pdf/2410.06997v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.11125v2","updated":"2024-10-17T02:34:39Z","published":"2024-10-14T22:24:11Z","title":"UAV3D: A Large-scale 3D Perception Benchmark for Unmanned Aerial\n  Vehicles","summary":"  Unmanned Aerial Vehicles (UAVs), equipped with cameras, are employed in\nnumerous applications, including aerial photography, surveillance, and\nagriculture. In these applications, robust object detection and tracking are\nessential for the effective deployment of UAVs. However, existing benchmarks\nfor UAV applications are mainly designed for traditional 2D perception tasks,\nrestricting the development of real-world applications that require a 3D\nunderstanding of the environment. Furthermore, despite recent advancements in\nsingle-UAV perception, limited views of a single UAV platform significantly\nconstrain its perception capabilities over long distances or in occluded areas.\nTo address these challenges, we introduce UAV3D, a benchmark designed to\nadvance research in both 3D and collaborative 3D perception tasks with UAVs.\nUAV3D comprises 1,000 scenes, each of which has 20 frames with fully annotated\n3D bounding boxes on vehicles. We provide the benchmark for four 3D perception\ntasks: single-UAV 3D object detection, single-UAV object tracking,\ncollaborative-UAV 3D object detection, and collaborative-UAV object tracking.\nOur dataset and code are available at\nhttps://huiyegit.github.io/UAV3D_Benchmark/.\n","authors":["Hui Ye","Rajshekhar Sunderraman","Shihao Ji"],"pdf_url":"https://arxiv.org/pdf/2410.11125v2.pdf","comment":"Accepted at NeurIPS 2024"},{"id":"http://arxiv.org/abs/2410.13156v1","updated":"2024-10-17T02:21:43Z","published":"2024-10-17T02:21:43Z","title":"FAMSeC: A Few-shot-sample-based General AI-generated Image Detection\n  Method","summary":"  The explosive growth of generative AI has saturated the internet with\nAI-generated images, raising security concerns and increasing the need for\nreliable detection methods. The primary requirement for such detection is\ngeneralizability, typically achieved by training on numerous fake images from\nvarious models. However, practical limitations, such as closed-source models\nand restricted access, often result in limited training samples. Therefore,\ntraining a general detector with few-shot samples is essential for modern\ndetection mechanisms. To address this challenge, we propose FAMSeC, a general\nAI-generated image detection method based on LoRA-based Forgery Awareness\nModule and Semantic feature-guided Contrastive learning strategy. To\neffectively learn from limited samples and prevent overfitting, we developed a\nForgery Awareness Module (FAM) based on LoRA, maintaining the generalization of\npre-trained features. Additionally, to cooperate with FAM, we designed a\nSemantic feature-guided Contrastive learning strategy (SeC), making the FAM\nfocus more on the differences between real/fake image than on the features of\nthe samples themselves. Experiments show that FAMSeC outperforms\nstate-of-the-art method, enhancing classification accuracy by 14.55% with just\n0.56% of the training samples.\n","authors":["Juncong Xu","Yang Yang","Han Fang","Honggu Liu","Weiming Zhang"],"pdf_url":"https://arxiv.org/pdf/2410.13156v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.13147v1","updated":"2024-10-17T02:04:57Z","published":"2024-10-17T02:04:57Z","title":"Utilizing Large Language Models in An Iterative Paradigm with Domain\n  Feedback for Molecule Optimization","summary":"  Molecule optimization is a critical task in drug discovery to optimize\ndesired properties of a given molecule through chemical modification. Despite\nLarge Language Models (LLMs) holding the potential to efficiently simulate this\ntask by using natural language to direct the optimization, straightforwardly\nutilizing shows limited performance. In this work, we facilitate utilizing LLMs\nin an iterative paradigm by proposing a simple yet highly effective domain\nfeedback provider, namely $\\text{Re}^2$DF. In detail, $\\text{Re}^2$DF harnesses\nan external toolkit, RDKit, to handle the molecule hallucination, if the\nmodified molecule is chemically invalid. Otherwise, its desired properties are\ncomputed and compared to the original one, establishing reliable domain\nfeedback with correct direction and distance towards the objective, followed by\na retrieved example, to explicitly guide the LLM to refine the modified\nmolecule. We conduct experiments across both single- and multi-property\nobjectives with 2 thresholds, where $\\text{Re}^2$DF shows significant\nimprovements. Particularly, for 20 single-property objectives, $\\text{Re}^2$DF\nenhances the Hit ratio by 16.95\\% and 20.76\\% under loose and strict\nthresholds, respectively. For 32 multi-property objectives, $\\text{Re}^2$DF\nenhances the Hit ratio by 6.04\\% and 5.25\\%.\n","authors":["Khiem Le","Nitesh V. Chawla"],"pdf_url":"https://arxiv.org/pdf/2410.13147v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.13146v1","updated":"2024-10-17T02:03:27Z","published":"2024-10-17T02:03:27Z","title":"Mapping Bias in Vision Language Models: Signposts, Pitfalls, and the\n  Road Ahead","summary":"  As Vision Language Models (VLMs) gain widespread use, their fairness remains\nunder-explored. In this paper, we analyze demographic biases across five models\nand six datasets. We find that portrait datasets like UTKFace and CelebA are\nthe best tools for bias detection, finding gaps in performance and fairness\nbetween LLaVa and CLIP models. However, scene based datasets like PATA,\nVLStereoSet fail to be useful benchmarks for bias due to their construction. As\nfor pronoun based datasets like VisoGender, we receive mixed signals as only\nsome subsets of the data are useful in providing insights. To alleviate this\nproblem, we introduce a more difficult version of VisoGender to serve as a more\nrigorous evaluation. Based on these results, we call for more effective and\ncarefully designed datasets to ensure VLMs are both fair and reliable.\n","authors":["Kuleen Sasse","Shan Chen","Jackson Pond","Danielle Bitterman","John Osborne"],"pdf_url":"https://arxiv.org/pdf/2410.13146v1.pdf","comment":"Under Review at NAACL 2025"},{"id":"http://arxiv.org/abs/2407.05131v2","updated":"2024-10-17T01:55:28Z","published":"2024-07-06T16:45:07Z","title":"RULE: Reliable Multimodal RAG for Factuality in Medical Vision Language\n  Models","summary":"  The recent emergence of Medical Large Vision Language Models (Med-LVLMs) has\nenhanced medical diagnosis. However, current Med-LVLMs frequently encounter\nfactual issues, often generating responses that do not align with established\nmedical facts. Retrieval-Augmented Generation (RAG), which utilizes external\nknowledge, can improve the factual accuracy of these models but introduces two\nmajor challenges. First, limited retrieved contexts might not cover all\nnecessary information, while excessive retrieval can introduce irrelevant and\ninaccurate references, interfering with the model's generation. Second, in\ncases where the model originally responds correctly, applying RAG can lead to\nan over-reliance on retrieved contexts, resulting in incorrect answers. To\naddress these issues, we propose RULE, which consists of two components. First,\nwe introduce a provably effective strategy for controlling factuality risk\nthrough the calibrated selection of the number of retrieved contexts. Second,\nbased on samples where over-reliance on retrieved contexts led to errors, we\ncurate a preference dataset to fine-tune the model, balancing its dependence on\ninherent knowledge and retrieved contexts for generation. We demonstrate the\neffectiveness of RULE on medical VQA and report generation tasks across three\ndatasets, achieving an average improvement of 47.4% in factual accuracy. We\npublicly release our benchmark and code in\nhttps://github.com/richard-peng-xia/RULE.\n","authors":["Peng Xia","Kangyu Zhu","Haoran Li","Hongtu Zhu","Yun Li","Gang Li","Linjun Zhang","Huaxiu Yao"],"pdf_url":"https://arxiv.org/pdf/2407.05131v2.pdf","comment":"EMNLP 2024 main"},{"id":"http://arxiv.org/abs/2410.13139v1","updated":"2024-10-17T01:51:58Z","published":"2024-10-17T01:51:58Z","title":"See Behind Walls in Real-time Using Aerial Drones and Augmented Reality","summary":"  This work presents ARD2, a framework that enables real-time through-wall\nsurveillance using two aerial drones and an augmented reality (AR) device. ARD2\nconsists of two main steps: target direction estimation and contour\nreconstruction. In the first stage, ARD2 leverages geometric relationships\nbetween the drones, the user, and the target to project the target's direction\nonto the user's AR display. In the second stage, images from the drones are\nsynthesized to reconstruct the target's contour, allowing the user to visualize\nthe target behind walls. Experimental results demonstrate the system's accuracy\nin both direction estimation and contour reconstruction.\n","authors":["Sikai Yang","Kang Yang","Yuning Chen","Fan Zhao","Wan Du"],"pdf_url":"https://arxiv.org/pdf/2410.13139v1.pdf","comment":"6 pages"},{"id":"http://arxiv.org/abs/2410.13136v1","updated":"2024-10-17T01:48:05Z","published":"2024-10-17T01:48:05Z","title":"Unlocking the Capabilities of Masked Generative Models for Image\n  Synthesis via Self-Guidance","summary":"  Masked generative models (MGMs) have shown impressive generative ability\nwhile providing an order of magnitude efficient sampling steps compared to\ncontinuous diffusion models. However, MGMs still underperform in image\nsynthesis compared to recent well-developed continuous diffusion models with\nsimilar size in terms of quality and diversity of generated samples. A key\nfactor in the performance of continuous diffusion models stems from the\nguidance methods, which enhance the sample quality at the expense of diversity.\nIn this paper, we extend these guidance methods to generalized guidance\nformulation for MGMs and propose a self-guidance sampling method, which leads\nto better generation quality. The proposed approach leverages an auxiliary task\nfor semantic smoothing in vector-quantized token space, analogous to the\nGaussian blur in continuous pixel space. Equipped with the parameter-efficient\nfine-tuning method and high-temperature sampling, MGMs with the proposed\nself-guidance achieve a superior quality-diversity trade-off, outperforming\nexisting sampling methods in MGMs with more efficient training and sampling\ncosts. Extensive experiments with the various sampling hyperparameters confirm\nthe effectiveness of the proposed self-guidance.\n","authors":["Jiwan Hur","Dong-Jae Lee","Gyojin Han","Jaehyun Choi","Yunho Jeon","Junmo Kim"],"pdf_url":"https://arxiv.org/pdf/2410.13136v1.pdf","comment":"NeurIPS 2024. Code is available at:\n  https://github.com/JiwanHur/UnlockMGM"},{"id":"http://arxiv.org/abs/2312.06738v4","updated":"2024-10-17T01:30:33Z","published":"2023-12-11T17:53:45Z","title":"InstructAny2Pix: Flexible Visual Editing via Multimodal Instruction\n  Following","summary":"  The ability to provide fine-grained control for generating and editing visual\nimagery has profound implications for computer vision and its applications.\nPrevious works have explored extending controllability in two directions:\ninstruction tuning with text-based prompts and multi-modal conditioning.\nHowever, these works make one or more unnatural assumptions on the number\nand/or type of modality inputs used to express controllability. We propose\nInstructAny2Pix, a flexible multi-modal instruction-following system that\nenables users to edit an input image using instructions involving audio,\nimages, and text. InstructAny2Pix consists of three building blocks that\nfacilitate this capability: a multi-modal encoder that encodes different\nmodalities such as images and audio into a unified latent space, a diffusion\nmodel that learns to decode representations in this latent space into images,\nand a multi-modal LLM that can understand instructions involving multiple\nimages and audio pieces and generate a conditional embedding of the desired\noutput, which can be used by the diffusion decoder. Additionally, to facilitate\ntraining efficiency and improve generation quality, we include an additional\nrefinement prior module that enhances the visual quality of LLM outputs. These\ndesigns are critical to the performance of our system. We demonstrate that our\nsystem can perform a series of novel instruction-guided editing tasks. The code\nis available at https://github.com/jacklishufan/InstructAny2Pix.git\n","authors":["Shufan Li","Harkanwar Singh","Aditya Grover"],"pdf_url":"https://arxiv.org/pdf/2312.06738v4.pdf","comment":"25 pages, 19 figures"},{"id":"http://arxiv.org/abs/2410.13122v1","updated":"2024-10-17T01:22:11Z","published":"2024-10-17T01:22:11Z","title":"Boosting Imperceptibility of Stable Diffusion-based Adversarial Examples\n  Generation with Momentum","summary":"  We propose a novel framework, Stable Diffusion-based Momentum Integrated\nAdversarial Examples (SD-MIAE), for generating adversarial examples that can\neffectively mislead neural network classifiers while maintaining visual\nimperceptibility and preserving the semantic similarity to the original class\nlabel. Our method leverages the text-to-image generation capabilities of the\nStable Diffusion model by manipulating token embeddings corresponding to the\nspecified class in its latent space. These token embeddings guide the\ngeneration of adversarial images that maintain high visual fidelity. The\nSD-MIAE framework consists of two phases: (1) an initial adversarial\noptimization phase that modifies token embeddings to produce misclassified yet\nnatural-looking images and (2) a momentum-based optimization phase that refines\nthe adversarial perturbations. By introducing momentum, our approach stabilizes\nthe optimization of perturbations across iterations, enhancing both the\nmisclassification rate and visual fidelity of the generated adversarial\nexamples. Experimental results demonstrate that SD-MIAE achieves a high\nmisclassification rate of 79%, improving by 35% over the state-of-the-art\nmethod while preserving the imperceptibility of adversarial perturbations and\nthe semantic similarity to the original class label, making it a practical\nmethod for robust adversarial evaluation.\n","authors":["Nashrah Haque","Xiang Li","Zhehui Chen","Yanzhao Wu","Lei Yu","Arun Iyengar","Wenqi Wei"],"pdf_url":"https://arxiv.org/pdf/2410.13122v1.pdf","comment":"10 pages, 12 figures. To be published in IEEE TPS 2024 Proceedings.\n  Code available on GitHub: https://github.com/nashrahhaque/SD-MIAE"},{"id":"http://arxiv.org/abs/2410.13121v1","updated":"2024-10-17T01:19:18Z","published":"2024-10-17T01:19:18Z","title":"Trust but Verify: Programmatic VLM Evaluation in the Wild","summary":"  Vision-Language Models (VLMs) often generate plausible but incorrect\nresponses to visual queries. However, reliably quantifying the effect of such\nhallucinations in free-form responses to open-ended queries is challenging as\nit requires visually verifying each claim within the response. We propose\nProgrammatic VLM Evaluation (PROVE), a new benchmarking paradigm for evaluating\nVLM responses to open-ended queries. To construct PROVE, we provide a large\nlanguage model (LLM) with a high-fidelity scene-graph representation\nconstructed from a hyper-detailed image caption, and prompt it to generate\ndiverse question-answer (QA) pairs, as well as programs that can be executed\nover the scene graph object to verify each QA pair. We thus construct a\nbenchmark of 10.5k challenging but visually grounded QA pairs. Next, to\nevaluate free-form model responses to queries in PROVE, we propose a\nprogrammatic evaluation strategy that measures both the helpfulness and\ntruthfulness of a response within a unified scene graph-based framework. We\nbenchmark the helpfulness-truthfulness trade-offs of a range of VLMs on PROVE,\nfinding that very few are in-fact able to achieve a good balance between the\ntwo. Project page: \\url{https://prove-explorer.netlify.app/}.\n","authors":["Viraj Prabhu","Senthil Purushwalkam","An Yan","Caiming Xiong","Ran Xu"],"pdf_url":"https://arxiv.org/pdf/2410.13121v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.06579v3","updated":"2024-10-17T01:17:25Z","published":"2024-06-04T13:52:54Z","title":"From Redundancy to Relevance: Information Flow in LVLMs Across Reasoning\n  Tasks","summary":"  Large Vision Language Models (LVLMs) achieve great performance on\nvisual-language reasoning tasks, however, the black-box nature of LVLMs hinders\nin-depth research on the reasoning mechanism. As all images need to be\nconverted into image tokens to fit the input format of large language models\n(LLMs) along with natural language prompts, sequential visual representation is\nessential to the performance of LVLMs, and the information flow analysis\napproach can be an effective tool for determining interactions between these\nrepresentations. In this paper, we propose integrating attention analysis with\nLLaVA-CAM, concretely, attention scores highlight relevant regions during\nforward propagation, while LLaVA-CAM captures gradient changes through backward\npropagation, revealing key image features. By exploring the information flow\nfrom the perspective of visual representation contribution, we observe that it\ntends to converge in shallow layers but diversify in deeper layers. To validate\nour analysis, we conduct comprehensive experiments with truncation strategies\nacross various LVLMs for visual question answering and image captioning tasks,\nand experimental results not only verify our hypothesis but also reveal a\nconsistent pattern of information flow convergence in the corresponding layers,\nand the information flow cliff layer will be different due to different\ncontexts. The paper's source code can be accessed from\n\\url{https://github.com/zhangbaijin/From-Redundancy-to-Relevance}\n","authors":["Xiaofeng Zhang","Yihao Quan","Chen Shen","Xiaosong Yuan","Shaotian Yan","Liang Xie","Wenxiao Wang","Chaochen Gu","Hao Tang","Jieping Ye"],"pdf_url":"https://arxiv.org/pdf/2406.06579v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.10674v2","updated":"2024-10-17T00:51:28Z","published":"2024-03-15T20:49:43Z","title":"D-Net: Dynamic Large Kernel with Dynamic Feature Fusion for Volumetric\n  Medical Image Segmentation","summary":"  Hierarchical transformers have achieved significant success in medical image\nsegmentation due to their large receptive field and capabilities of effectively\nleveraging global long-range contextual information. Convolutional neural\nnetworks (CNNs) can also deliver a large receptive field by using large\nkernels, enabling them to achieve competitive performance with fewer model\nparameters. However, CNNs incorporated with large convolutional kernels remain\nconstrained in adaptively capturing multi-scale features from organs with large\nvariations in shape and size due to the employment of fixed-sized kernels.\nAdditionally, they are unable to utilize global contextual information\nefficiently. To address these limitations, we propose Dynamic Large Kernel\n(DLK) and Dynamic Feature Fusion (DFF) modules. The DLK module employs multiple\nlarge kernels with varying kernel sizes and dilation rates to capture\nmulti-scale features. Subsequently, a dynamic selection mechanism is utilized\nto adaptively highlight the most important spatial features based on global\ninformation. Additionally, the DFF module is proposed to adaptively fuse\nmulti-scale local feature maps based on their global information. We integrate\nDLK and DFF in a hierarchical transformer architecture to develop a novel\narchitecture, termed D-Net. D-Net is able to effectively utilize a multi-scale\nlarge receptive field and adaptively harness global contextual information.\nExtensive experimental results demonstrate that D-Net outperforms other\nstate-of-the-art models in the two volumetric segmentation tasks, including\nabdominal multi-organ segmentation and multi-modality brain tumor segmentation.\nOur code is available at https://github.com/sotiraslab/DLK.\n","authors":["Jin Yang","Peijie Qiu","Yichi Zhang","Daniel S. Marcus","Aristeidis Sotiras"],"pdf_url":"https://arxiv.org/pdf/2403.10674v2.pdf","comment":"18 pages, 8 figures, 9 tables"},{"id":"http://arxiv.org/abs/2306.04955v2","updated":"2024-10-17T00:27:09Z","published":"2023-06-08T06:02:39Z","title":"Degraded Polygons Raise Fundamental Questions of Neural Network\n  Perception","summary":"  It is well-known that modern computer vision systems often exhibit behaviors\nmisaligned with those of humans: from adversarial attacks to image corruptions,\ndeep learning vision models suffer in a variety of settings that humans capably\nhandle. In light of these phenomena, here we introduce another, orthogonal\nperspective studying the human-machine vision gap. We revisit the task of\nrecovering images under degradation, first introduced over 30 years ago in the\nRecognition-by-Components theory of human vision. Specifically, we study the\nperformance and behavior of neural networks on the seemingly simple task of\nclassifying regular polygons at varying orders of degradation along their\nperimeters. To this end, we implement the Automated Shape Recoverability Test\nfor rapidly generating large-scale datasets of perimeter-degraded regular\npolygons, modernizing the historically manual creation of image recoverability\nexperiments. We then investigate the capacity of neural networks to recognize\nand recover such degraded shapes when initialized with different priors.\nUltimately, we find that neural networks' behavior on this simple task\nconflicts with human behavior, raising a fundamental question of the robustness\nand learning capabilities of modern computer vision models.\n","authors":["Leonard Tang","Dan Ley"],"pdf_url":"https://arxiv.org/pdf/2306.04955v2.pdf","comment":"Accepted as a conference paper to NeurIPS 2023 (Datasets & Benchmarks\n  Track)"},{"id":"http://arxiv.org/abs/2410.13099v1","updated":"2024-10-17T00:05:05Z","published":"2024-10-17T00:05:05Z","title":"Adversarial Neural Networks in Medical Imaging Advancements and\n  Challenges in Semantic Segmentation","summary":"  Recent advancements in artificial intelligence (AI) have precipitated a\nparadigm shift in medical imaging, particularly revolutionizing the domain of\nbrain imaging. This paper systematically investigates the integration of deep\nlearning -- a principal branch of AI -- into the semantic segmentation of brain\nimages. Semantic segmentation serves as an indispensable technique for the\ndelineation of discrete anatomical structures and the identification of\npathological markers, essential for the diagnosis of complex neurological\ndisorders. Historically, the reliance on manual interpretation by radiologists,\nwhile noteworthy for its accuracy, is plagued by inherent subjectivity and\ninter-observer variability. This limitation becomes more pronounced with the\nexponential increase in imaging data, which traditional methods struggle to\nprocess efficiently and effectively. In response to these challenges, this\nstudy introduces the application of adversarial neural networks, a novel AI\napproach that not only automates but also refines the semantic segmentation\nprocess. By leveraging these advanced neural networks, our approach enhances\nthe precision of diagnostic outputs, reducing human error and increasing the\nthroughput of imaging data analysis. The paper provides a detailed discussion\non how adversarial neural networks facilitate a more robust, objective, and\nscalable solution, thereby significantly improving diagnostic accuracies in\nneurological evaluations. This exploration highlights the transformative impact\nof AI on medical imaging, setting a new benchmark for future research and\nclinical practice in neurology.\n","authors":["Houze Liu","Bo Zhang","Yanlin Xiang","Yuxiang Hu","Aoran Shen","Yang Lin"],"pdf_url":"https://arxiv.org/pdf/2410.13099v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.13807v1","updated":"2024-10-17T17:41:52Z","published":"2024-10-17T17:41:52Z","title":"ConsisSR: Delving Deep into Consistency in Diffusion-based Image\n  Super-Resolution","summary":"  Real-world image super-resolution (Real-ISR) aims at restoring high-quality\n(HQ) images from low-quality (LQ) inputs corrupted by unknown and complex\ndegradations. In particular, pretrained text-to-image (T2I) diffusion models\nprovide strong generative priors to reconstruct credible and intricate details.\nHowever, T2I generation focuses on semantic consistency while Real-ISR\nemphasizes pixel-level reconstruction, which hinders existing methods from\nfully exploiting diffusion priors. To address this challenge, we introduce\nConsisSR to handle both semantic and pixel-level consistency. Specifically,\ncompared to coarse-grained text prompts, we exploit the more powerful CLIP\nimage embedding and effectively leverage both modalities through our Hybrid\nPrompt Adapter (HPA) for semantic guidance. Secondly, we introduce Time-aware\nLatent Augmentation (TALA) to mitigate the inherent gap between T2I generation\nand Real-ISR consistency requirements. By randomly mixing LQ and HQ latent\ninputs, our model not only handle timestep-specific diffusion noise but also\nrefine the accumulated latent representations. Last but not least, our\nGAN-Embedding strategy employs the pretrained Real-ESRGAN model to refine the\ndiffusion start point. This accelerates the inference process to 10 steps while\npreserving sampling quality, in a training-free manner. Our method demonstrates\nstate-of-the-art performance among both full-scale and accelerated models. The\ncode will be made publicly available.\n","authors":["Junhao Gu","Peng-Tao Jiang","Hao Zhang","Mi Zhou","Jinwei Chen","Wenming Yang","Bo Li"],"pdf_url":"https://arxiv.org/pdf/2410.13807v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2107.02791v3","updated":"2024-10-17T16:11:28Z","published":"2021-07-06T17:58:35Z","title":"Depth-supervised NeRF: Fewer Views and Faster Training for Free","summary":"  A commonly observed failure mode of Neural Radiance Field (NeRF) is fitting\nincorrect geometries when given an insufficient number of input views. One\npotential reason is that standard volumetric rendering does not enforce the\nconstraint that most of a scene's geometry consist of empty space and opaque\nsurfaces. We formalize the above assumption through DS-NeRF (Depth-supervised\nNeural Radiance Fields), a loss for learning radiance fields that takes\nadvantage of readily-available depth supervision. We leverage the fact that\ncurrent NeRF pipelines require images with known camera poses that are\ntypically estimated by running structure-from-motion (SFM). Crucially, SFM also\nproduces sparse 3D points that can be used as \"free\" depth supervision during\ntraining: we add a loss to encourage the distribution of a ray's terminating\ndepth matches a given 3D keypoint, incorporating depth uncertainty. DS-NeRF can\nrender better images given fewer training views while training 2-3x faster.\nFurther, we show that our loss is compatible with other recently proposed NeRF\nmethods, demonstrating that depth is a cheap and easily digestible supervisory\nsignal. And finally, we find that DS-NeRF can support other types of depth\nsupervision such as scanned depth sensors and RGB-D reconstruction outputs.\n","authors":["Kangle Deng","Andrew Liu","Jun-Yan Zhu","Deva Ramanan"],"pdf_url":"https://arxiv.org/pdf/2107.02791v3.pdf","comment":"Project page: http://www.cs.cmu.edu/~dsnerf/ GitHub:\n  https://github.com/dunbar12138/DSNeRF"},{"id":"http://arxiv.org/abs/2009.09231v2","updated":"2024-10-17T13:30:22Z","published":"2020-09-19T13:47:33Z","title":"Adversarial Exposure Attack on Diabetic Retinopathy Imagery Grading","summary":"  Diabetic Retinopathy (DR) is a leading cause of vision loss around the world.\nTo help diagnose it, numerous cutting-edge works have built powerful deep\nneural networks (DNNs) to automatically grade DR via retinal fundus images\n(RFIs). However, RFIs are commonly affected by camera exposure issues that may\nlead to incorrect grades. The mis-graded results can potentially pose high\nrisks to an aggravation of the condition. In this paper, we study this problem\nfrom the viewpoint of adversarial attacks. We identify and introduce a novel\nsolution to an entirely new task, termed as adversarial exposure attack, which\nis able to produce natural exposure images and mislead the state-of-the-art\nDNNs. We validate our proposed method on a real-world public DR dataset with\nthree DNNs, e.g., ResNet50, MobileNet, and EfficientNet, demonstrating that our\nmethod achieves high image quality and success rate in transferring the\nattacks. Our method reveals the potential threats to DNN-based automatic DR\ngrading and would benefit the development of exposure-robust DR grading methods\nin the future.\n","authors":["Yupeng Cheng","Qing Guo","Felix Juefei-Xu","Huazhu Fu","Shang-Wei Lin","Weisi Lin"],"pdf_url":"https://arxiv.org/pdf/2009.09231v2.pdf","comment":"13 pages, 7 figures"},{"id":"http://arxiv.org/abs/2410.14089v1","updated":"2024-10-17T23:52:39Z","published":"2024-10-17T23:52:39Z","title":"MMAD-Purify: A Precision-Optimized Framework for Efficient and Scalable\n  Multi-Modal Attacks","summary":"  Neural networks have achieved remarkable performance across a wide range of\ntasks, yet they remain susceptible to adversarial perturbations, which pose\nsignificant risks in safety-critical applications. With the rise of\nmultimodality, diffusion models have emerged as powerful tools not only for\ngenerative tasks but also for various applications such as image editing,\ninpainting, and super-resolution. However, these models still lack robustness\ndue to limited research on attacking them to enhance their resilience.\nTraditional attack techniques, such as gradient-based adversarial attacks and\ndiffusion model-based methods, are hindered by computational inefficiencies and\nscalability issues due to their iterative nature. To address these challenges,\nwe introduce an innovative framework that leverages the distilled backbone of\ndiffusion models and incorporates a precision-optimized noise predictor to\nenhance the effectiveness of our attack framework. This approach not only\nenhances the attack's potency but also significantly reduces computational\ncosts. Our framework provides a cutting-edge solution for multi-modal\nadversarial attacks, ensuring reduced latency and the generation of\nhigh-fidelity adversarial examples with superior success rates. Furthermore, we\ndemonstrate that our framework achieves outstanding transferability and\nrobustness against purification defenses, outperforming existing gradient-based\nattack models in both effectiveness and efficiency.\n","authors":["Xinxin Liu","Zhongliang Guo","Siyuan Huang","Chun Pong Lau"],"pdf_url":"https://arxiv.org/pdf/2410.14089v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.14087v1","updated":"2024-10-17T23:37:58Z","published":"2024-10-17T23:37:58Z","title":"Your Interest, Your Summaries: Query-Focused Long Video Summarization","summary":"  Generating a concise and informative video summary from a long video is\nimportant, yet subjective due to varying scene importance. Users' ability to\nspecify scene importance through text queries enhances the relevance of such\nsummaries. This paper introduces an approach for query-focused video\nsummarization, aiming to align video summaries closely with user queries. To\nthis end, we propose the Fully Convolutional Sequence Network with Attention\n(FCSNA-QFVS), a novel approach designed for this task. Leveraging temporal\nconvolutional and attention mechanisms, our model effectively extracts and\nhighlights relevant content based on user-specified queries. Experimental\nvalidation on a benchmark dataset for query-focused video summarization\ndemonstrates the effectiveness of our approach.\n","authors":["Nirav Patel","Payal Prajapati","Maitrik Shah"],"pdf_url":"https://arxiv.org/pdf/2410.14087v1.pdf","comment":"To appear at the 18th International Conference on Control,\n  Automation, Robotics and Vision (ICARCV), December 2024, Dubai, UAE"},{"id":"http://arxiv.org/abs/2410.14084v1","updated":"2024-10-17T23:26:55Z","published":"2024-10-17T23:26:55Z","title":"Self Supervised Deep Learning for Robot Grasping","summary":"  Learning Based Robot Grasping currently involves the use of labeled data.\nThis approach has two major disadvantages. Firstly, labeling data for grasp\npoints and angles is a strenuous process, so the dataset remains limited.\nSecondly, human labeling is prone to bias due to semantics.\n  In order to solve these problems we propose a simpler self-supervised robotic\nsetup, that will train a Convolutional Neural Network (CNN). The robot will\nlabel and collect the data during the training process. The idea is to make a\nrobot that is less costly, small and easily maintainable in a lab setup. The\nrobot will be trained on a large data set for several hundred hours and then\nthe trained Neural Network can be mapped onto a larger grasping robot.\n","authors":["Danyal Saqib","Wajahat Hussain"],"pdf_url":"https://arxiv.org/pdf/2410.14084v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.14083v1","updated":"2024-10-17T23:23:48Z","published":"2024-10-17T23:23:48Z","title":"SAMReg: SAM-enabled Image Registration with ROI-based Correspondence","summary":"  This paper describes a new spatial correspondence representation based on\npaired regions-of-interest (ROIs), for medical image registration. The distinct\nproperties of the proposed ROI-based correspondence are discussed, in the\ncontext of potential benefits in clinical applications following image\nregistration, compared with alternative correspondence-representing approaches,\nsuch as those based on sampled displacements and spatial transformation\nfunctions. These benefits include a clear connection between learning-based\nimage registration and segmentation, which in turn motivates two cases of image\nregistration approaches using (pre-)trained segmentation networks. Based on the\nsegment anything model (SAM), a vision foundation model for segmentation, we\ndevelop a new registration algorithm SAMReg, which does not require any\ntraining (or training data), gradient-based fine-tuning or prompt engineering.\nThe proposed SAMReg models are evaluated across five real-world applications,\nincluding intra-subject registration tasks with cardiac MR and lung CT,\nchallenging inter-subject registration scenarios with prostate MR and retinal\nimaging, and an additional evaluation with a non-clinical example with aerial\nimage registration. The proposed methods outperform both intensity-based\niterative algorithms and DDF-predicting learning-based networks across tested\nmetrics including Dice and target registration errors on anatomical structures,\nand further demonstrates competitive performance compared to weakly-supervised\nregistration approaches that rely on fully-segmented training data. Open source\ncode and examples are available at: https://github.com/sqhuang0103/SAMReg.git.\n","authors":["Shiqi Huang","Tingfa Xu","Ziyi Shen","Shaheer Ullah Saeed","Wen Yan","Dean Barratt","Yipeng Hu"],"pdf_url":"https://arxiv.org/pdf/2410.14083v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.10551v3","updated":"2024-10-17T23:07:02Z","published":"2024-10-14T14:32:05Z","title":"Preserving Cardiac Integrity: A Topology-Infused Approach to Whole Heart\n  Segmentation","summary":"  Whole heart segmentation (WHS) supports cardiovascular disease (CVD)\ndiagnosis, disease monitoring, treatment planning, and prognosis. Deep learning\nhas become the most widely used method for WHS applications in recent years.\nHowever, segmentation of whole-heart structures faces numerous challenges\nincluding heart shape variability during the cardiac cycle, clinical artifacts\nlike motion and poor contrast-to-noise ratio, domain shifts in multi-center\ndata, and the distinct modalities of CT and MRI. To address these limitations\nand improve segmentation quality, this paper introduces a new\ntopology-preserving module that is integrated into deep neural networks. The\nimplementation achieves anatomically plausible segmentation by using learned\ntopology-preserving fields, which are based entirely on 3D convolution and are\ntherefore very effective for 3D voxel data. We incorporate natural constraints\nbetween structures into the end-to-end training and enrich the feature\nrepresentation of the neural network. The effectiveness of the proposed method\nis validated on an open-source medical heart dataset, specifically using the\nWHS++ data. The results demonstrate that the architecture performs\nexceptionally well, achieving a Dice coefficient of 0.939 during testing. This\nindicates full topology preservation for individual structures and\nsignificantly outperforms other baselines in preserving the overall scene\ntopology.\n","authors":["Chenyu Zhang","Wenxue Guan","Xiaodan Xing","Guang Yang"],"pdf_url":"https://arxiv.org/pdf/2410.10551v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.09087v2","updated":"2024-10-17T23:02:17Z","published":"2024-06-13T13:13:17Z","title":"Suitability of KANs for Computer Vision: A preliminary investigation","summary":"  Kolmogorov-Arnold Networks (KANs) introduce a paradigm of neural modeling\nthat implements learnable functions on the edges of the networks, diverging\nfrom the traditional node-centric activations in neural networks. This work\nassesses the applicability and efficacy of KANs in visual modeling, focusing on\nfundamental recognition and segmentation tasks. We mainly analyze the\nperformance and efficiency of different network architectures built using KAN\nconcepts along with conventional building blocks of convolutional and linear\nlayers, enabling a comparative analysis with the conventional models. Our\nfindings are aimed at contributing to understanding the potential of KANs in\ncomputer vision, highlighting both their strengths and areas for further\nresearch. Our evaluation point toward the fact that while KAN-based\narchitectures perform in line with the original claims, it may often be\nimportant to employ more complex functions on the network edges to retain the\nperformance advantage of KANs on more complex visual data.\n","authors":["Basim Azam","Naveed Akhtar"],"pdf_url":"https://arxiv.org/pdf/2406.09087v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.14072v1","updated":"2024-10-17T22:45:13Z","published":"2024-10-17T22:45:13Z","title":"Efficient Vision-Language Models by Summarizing Visual Tokens into\n  Compact Registers","summary":"  Recent advancements in vision-language models (VLMs) have expanded their\npotential for real-world applications, enabling these models to perform complex\nreasoning on images. In the widely used fully autoregressive transformer-based\nmodels like LLaVA, projected visual tokens are prepended to textual tokens.\nOftentimes, visual tokens are significantly more than prompt tokens, resulting\nin increased computational overhead during both training and inference. In this\npaper, we propose Visual Compact Token Registers (Victor), a method that\nreduces the number of visual tokens by summarizing them into a smaller set of\nregister tokens. Victor adds a few learnable register tokens after the visual\ntokens and summarizes the visual information into these registers using the\nfirst few layers in the language tower of VLMs. After these few layers, all\nvisual tokens are discarded, significantly improving computational efficiency\nfor both training and inference. Notably, our method is easy to implement and\nrequires a small number of new trainable parameters with minimal impact on\nmodel performance. In our experiment, with merely 8 visual registers--about 1%\nof the original tokens--Victor shows less than a 4% accuracy drop while\nreducing the total training time by 43% and boosting the inference throughput\nby 3.3X.\n","authors":["Yuxin Wen","Qingqing Cao","Qichen Fu","Sachin Mehta","Mahyar Najibi"],"pdf_url":"https://arxiv.org/pdf/2410.14072v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.14070v1","updated":"2024-10-17T22:36:52Z","published":"2024-10-17T22:36:52Z","title":"FaceSaliencyAug: Mitigating Geographic, Gender and Stereotypical Biases\n  via Saliency-Based Data Augmentation","summary":"  Geographical, gender and stereotypical biases in computer vision models pose\nsignificant challenges to their performance and fairness. {In this study, we\npresent an approach named FaceSaliencyAug aimed at addressing the gender bias\nin} {Convolutional Neural Networks (CNNs) and Vision Transformers (ViTs).\nLeveraging the salient regions} { of faces detected by saliency, the propose\napproach mitigates geographical and stereotypical biases } {in the datasets.\nFaceSaliencyAug} randomly selects masks from a predefined search space and\napplies them to the salient region of face images, subsequently restoring the\noriginal image with masked salient region. {The proposed} augmentation strategy\nenhances data diversity, thereby improving model performance and debiasing\neffects. We quantify dataset diversity using Image Similarity Score (ISS)\nacross five datasets, including Flickr Faces HQ (FFHQ), WIKI, IMDB, Labelled\nFaces in the Wild (LFW), UTK Faces, and Diverse Dataset. The proposed approach\ndemonstrates superior diversity metrics, as evaluated by ISS-intra and\nISS-inter algorithms. Furthermore, we evaluate the effectiveness of our\napproach in mitigating gender bias on CEO, Engineer, Nurse, and School Teacher\ndatasets. We use the Image-Image Association Score (IIAS) to measure gender\nbias in these occupations. Our experiments reveal a reduction in gender bias\nfor both CNNs and ViTs, indicating the efficacy of our method in promoting\nfairness and inclusivity in computer vision models.\n","authors":["Teerath Kumar","Alessandra Mileo","Malika Bendechache"],"pdf_url":"https://arxiv.org/pdf/2410.14070v1.pdf","comment":"Accepted at Image Signal and Video processing"},{"id":"http://arxiv.org/abs/2410.14060v1","updated":"2024-10-17T22:06:34Z","published":"2024-10-17T22:06:34Z","title":"On Partial Prototype Collapse in the DINO Family of Self-Supervised\n  Methods","summary":"  A prominent self-supervised learning paradigm is to model the representations\nas clusters, or more generally as a mixture model. Learning to map the data\nsamples to compact representations and fitting the mixture model simultaneously\nleads to the representation collapse problem. Regularizing the distribution of\ndata points over the clusters is the prevalent strategy to avoid this issue.\nWhile this is sufficient to prevent full representation collapse, we show that\na partial prototype collapse problem still exists in the DINO family of\nmethods, that leads to significant redundancies in the prototypes. Such\nprototype redundancies serve as shortcuts for the method to achieve a marginal\nlatent class distribution that matches the prescribed prior. We show that by\nencouraging the model to use diverse prototypes, the partial prototype collapse\ncan be mitigated. Effective utilization of the prototypes enables the methods\nto learn more fine-grained clusters, encouraging more informative\nrepresentations. We demonstrate that this is especially beneficial when\npre-training on a long-tailed fine-grained dataset.\n","authors":["Hariprasath Govindarajan","Per Sidén","Jacob Roll","Fredrik Lindsten"],"pdf_url":"https://arxiv.org/pdf/2410.14060v1.pdf","comment":"First version of the paper appeared in OpenReview on 22 Sep 2023.\n  Accepted to BMVC 2024"},{"id":"http://arxiv.org/abs/2111.14259v5","updated":"2024-10-17T21:57:15Z","published":"2021-11-28T22:58:00Z","title":"Performance of a GPU- and Time-Efficient Pseudo 3D Network for Magnetic\n  Resonance Image Super-Resolution and Motion Artifact Reduction","summary":"  Shortening acquisition time and reducing motion artifacts are the most\ncritical challenges in magnetic resonance imaging (MRI). Deep learning-based\nimage restoration has emerged as a promising solution capable of generating\nhigh-resolution and motion-artifact-free MRI images from low-resolution images\nacquired with shortened acquisition times or from motion-artifact-corrupted\nimages. To facilitate clinical integration, a time- and GPU-efficient network\nwith reliable accuracy is essential. In this study, we adopted a unified 2D\ndeep learning framework for pseudo-3D MRI image super-resolution reconstruction\n(SRR) and motion artifact reduction (MAR). The optimal down-sampling factors to\noptimize the acquisition time in SRR were identified. Training for MAR was\nperformed using publicly available in vivo data, employing a novel standardized\nmethod to induce motion artifacts of varying severity in a controlled way. The\naccuracy of the network was evaluated through a pixel-wise uncertainty map, and\nperformance was benchmarked against state-of-the-art methods. The results\ndemonstrated that the down-sampling factor of 1x1x2 for x2 acceleration and\n2x2x2 for x4 acceleration was optimal. For SRR, the proposed TS-RCAN\noutperformed the 3D networks of mDCSRN and ReCNN, with an improvement of more\nthan 0.01 in SSIM and 1.5 dB in PSNR while reducing GPU load by up to and\ninference time by up to 90%. For MAR, TS-RCAN exceeded UNet's performance by up\nto 0.014 in SSIM and 1.48 dB in PSNR. Additionally, TS-RCAN provided\nuncertainty information, which can be used to estimate the quality of the\nreconstructed images. TS-RCAN has potential use for SRR and MAR in the clinical\nsetting.\n","authors":["Hao Li","Jianan Liu","Marianne Schell","Tao Huang","Arne Lauer","Katharina Schregel","Jessica Jesser","Dominik F Vollherbst","Martin Bendszus","Sabine Heiland","Tim Hilgenfeld"],"pdf_url":"https://arxiv.org/pdf/2111.14259v5.pdf","comment":"16 pages, 9 figures"},{"id":"http://arxiv.org/abs/2410.14050v1","updated":"2024-10-17T21:46:00Z","published":"2024-10-17T21:46:00Z","title":"Learning Multimodal Cues of Children's Uncertainty","summary":"  Understanding uncertainty plays a critical role in achieving common ground\n(Clark et al.,1983). This is especially important for multimodal AI systems\nthat collaborate with users to solve a problem or guide the user through a\nchallenging concept. In this work, for the first time, we present a dataset\nannotated in collaboration with developmental and cognitive psychologists for\nthe purpose of studying nonverbal cues of uncertainty. We then present an\nanalysis of the data, studying different roles of uncertainty and its\nrelationship with task difficulty and performance. Lastly, we present a\nmultimodal machine learning model that can predict uncertainty given a\nreal-time video clip of a participant, which we find improves upon a baseline\nmultimodal transformer model. This work informs research on cognitive\ncoordination between human-human and human-AI and has broad implications for\ngesture understanding and generation. The anonymized version of our data and\ncode will be publicly available upon the completion of the required consent\nforms and data sheets.\n","authors":["Qi Cheng","Mert İnan","Rahma Mbarki","Grace Grmek","Theresa Choi","Yiming Sun","Kimele Persaud","Jenny Wang","Malihe Alikhani"],"pdf_url":"https://arxiv.org/pdf/2410.14050v1.pdf","comment":"SIGDIAL 2023"},{"id":"http://arxiv.org/abs/2410.14045v1","updated":"2024-10-17T21:37:40Z","published":"2024-10-17T21:37:40Z","title":"Human Action Anticipation: A Survey","summary":"  Predicting future human behavior is an increasingly popular topic in computer\nvision, driven by the interest in applications such as autonomous vehicles,\ndigital assistants and human-robot interactions. The literature on behavior\nprediction spans various tasks, including action anticipation, activity\nforecasting, intent prediction, goal prediction, and so on. Our survey aims to\ntie together this fragmented literature, covering recent technical innovations\nas well as the development of new large-scale datasets for model training and\nevaluation. We also summarize the widely-used metrics for different tasks and\nprovide a comprehensive performance comparison of existing approaches on eleven\naction anticipation datasets. This survey serves as not only a reference for\ncontemporary methodologies in action anticipation, but also a guideline for\nfuture research direction of this evolving landscape.\n","authors":["Bolin Lai","Sam Toyer","Tushar Nagarajan","Rohit Girdhar","Shengxin Zha","James M. Rehg","Kris Kitani","Kristen Grauman","Ruta Desai","Miao Liu"],"pdf_url":"https://arxiv.org/pdf/2410.14045v1.pdf","comment":"30 pages, 9 figures, 12 tables"},{"id":"http://arxiv.org/abs/2406.11579v2","updated":"2024-10-17T21:05:16Z","published":"2024-06-17T14:16:12Z","title":"Duoduo CLIP: Efficient 3D Understanding with Multi-View Images","summary":"  We introduce Duoduo CLIP, a model for 3D representation learning that learns\nshape encodings from multi-view images instead of point-clouds. The choice of\nmulti-view images allows us to leverage 2D priors from off-the-shelf CLIP\nmodels to facilitate fine-tuning with 3D data. Our approach not only shows\nbetter generalization compared to existing point cloud methods, but also\nreduces GPU requirements and training time. In addition, the model is modified\nwith cross-view attention to leverage information across multiple frames of the\nobject which further boosts performance. Notably, our model is permutation\ninvariant to the order of multi-view images while being pose-free. Compared to\nthe current SOTA point cloud method that requires 480 A100 hours to train 1\nbillion model parameters we only require 57 A5000 hours and 87 million\nparameters. Multi-view images also provide more flexibility including being\nable to encode objects with a variable number of images, and performance scales\nwhen more views are used. In contrast, point cloud based methods require an\nentire scan or model of the object. We showcase this flexibility with\nbenchmarks from images of real-world objects. Our model also achieves better\nperformance in more fine-grained text to shape retrieval, demonstrating better\ntext-and-shape alignment than point cloud based models.\n","authors":["Han-Hung Lee","Yiming Zhang","Angel X. Chang"],"pdf_url":"https://arxiv.org/pdf/2406.11579v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.03665v2","updated":"2024-10-17T20:51:19Z","published":"2024-10-04T17:59:57Z","title":"Estimating Body and Hand Motion in an Ego-sensed World","summary":"  We present EgoAllo, a system for human motion estimation from a head-mounted\ndevice. Using only egocentric SLAM poses and images, EgoAllo guides sampling\nfrom a conditional diffusion model to estimate 3D body pose, height, and hand\nparameters that capture the wearer's actions in the allocentric coordinate\nframe of the scene. To achieve this, our key insight is in representation: we\npropose spatial and temporal invariance criteria for improving model\nperformance, from which we derive a head motion conditioning parameterization\nthat improves estimation by up to 18%. We also show how the bodies estimated by\nour system can improve the hands: the resulting kinematic and temporal\nconstraints result in over 40% lower hand estimation errors compared to noisy\nmonocular estimates. Project page: https://egoallo.github.io/\n","authors":["Brent Yi","Vickie Ye","Maya Zheng","Lea Müller","Georgios Pavlakos","Yi Ma","Jitendra Malik","Angjoo Kanazawa"],"pdf_url":"https://arxiv.org/pdf/2410.03665v2.pdf","comment":"v2: fixed figures for Safari, typos"},{"id":"http://arxiv.org/abs/2410.14020v1","updated":"2024-10-17T20:46:13Z","published":"2024-10-17T20:46:13Z","title":"Segmentation of Pediatric Brain Tumors using a Radiologically informed,\n  Deep Learning Cascade","summary":"  Monitoring of Diffuse Intrinsic Pontine Glioma (DIPG) and Diffuse Midline\nGlioma (DMG) brain tumors in pediatric patients is key for assessment of\ntreatment response. Response Assessment in Pediatric Neuro-Oncology (RAPNO)\nguidelines recommend the volumetric measurement of these tumors using MRI.\nSegmentation challenges, such as the Brain Tumor Segmentation (BraTS)\nChallenge, promote development of automated approaches which are replicable,\ngeneralizable and accurate, to aid in these tasks. The current study presents a\nnovel adaptation of existing nnU-Net approaches for pediatric brain tumor\nsegmentation, submitted to the BraTS-PEDs 2024 challenge. We apply an adapted\nnnU-Net with hierarchical cascades to the segmentation task of the BraTS-PEDs\n2024 challenge. The residual encoder variant of nnU-Net, used as our baseline\nmodel, already provides high quality segmentations. We incorporate multiple\nchanges to the implementation of nnU-Net and devise a novel two-stage cascaded\nnnU-Net to segment the substructures of brain tumors from coarse to fine. Using\noutputs from the nnU-Net Residual Encoder (trained to segment CC, ED, ET and\nNET tumor labels from T1w, T1w-CE, T2w and T2-FLAIR MRI), these are passed to\ntwo additional models one classifying ET versus NET and a second classifying CC\nvs ED using cascade learning. We use radiological guidelines to steer which\nmulti parametric MRI (mpMRI) to use in these cascading models. Compared to a\ndefault nnU-Net and an ensembled nnU-net as baseline approaches, our novel\nmethod provides robust segmentations for the BraTS-PEDs 2024 challenge,\nachieving mean Dice scores of 0.657, 0.904, 0.703, and 0.967, and HD95 of 76.2,\n10.1, 111.0, and 12.3 for the ET, NET, CC and ED, respectively.\n","authors":["Timothy Mulvany","Daniel Griffiths-King","Jan Novak","Heather Rose"],"pdf_url":"https://arxiv.org/pdf/2410.14020v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.14017v1","updated":"2024-10-17T20:32:43Z","published":"2024-10-17T20:32:43Z","title":"Probabilistic U-Net with Kendall Shape Spaces for Geometry-Aware\n  Segmentations of Images","summary":"  One of the fundamental problems in computer vision is image segmentation, the\ntask of detecting distinct regions or objects in given images. Deep Neural\nNetworks (DNN) have been shown to be very effective in segmenting challenging\nimages, producing convincing segmentations. There is further need for\nprobabilistic DNNs that can reflect the uncertainties from the input images and\nthe models into the computed segmentations, in other words, new DNNs that can\ngenerate multiple plausible segmentations and their distributions depending on\nthe input or the model uncertainties. While there are existing probabilistic\nsegmentation models, many of them do not take into account the geometry or\nshape underlying the segmented regions. In this paper, we propose a\nprobabilistic image segmentation model that can incorporate the geometry of a\nsegmentation. Our proposed model builds on the Probabilistic U-Net of\n\\cite{kohl2018probabilistic} to generate probabilistic segmentations, i.e.\\!\nmultiple likely segmentations for an input image. Our model also adopts the\nKendall Shape Variational Auto-Encoder of \\cite{vadgama2023kendall} to encode a\nKendall shape space in the latent variable layers of the prior and posterior\nnetworks of the Probabilistic U-Net. Incorporating the shape space in this\nmanner leads to a more robust segmentation with spatially coherent regions,\nrespecting the underlying geometry in the input images.\n","authors":["Jiyoung Park","Günay Doğan"],"pdf_url":"https://arxiv.org/pdf/2410.14017v1.pdf","comment":"22 pages, 13 figures"},{"id":"http://arxiv.org/abs/2410.13989v1","updated":"2024-10-17T19:41:34Z","published":"2024-10-17T19:41:34Z","title":"Reproducibility study of \"LICO: Explainable Models with Language-Image\n  Consistency\"","summary":"  The growing reproducibility crisis in machine learning has brought forward a\nneed for careful examination of research findings. This paper investigates the\nclaims made by Lei et al. (2023) regarding their proposed method, LICO, for\nenhancing post-hoc interpretability techniques and improving image\nclassification performance. LICO leverages natural language supervision from a\nvision-language model to enrich feature representations and guide the learning\nprocess. We conduct a comprehensive reproducibility study, employing (Wide)\nResNets and established interpretability methods like Grad-CAM and RISE. We\nwere mostly unable to reproduce the authors' results. In particular, we did not\nfind that LICO consistently led to improved classification performance or\nimprovements in quantitative and qualitative measures of interpretability.\nThus, our findings highlight the importance of rigorous evaluation and\ntransparent reporting in interpretability research.\n","authors":["Luan Fletcher","Robert van der Klis","Martin Sedláček","Stefan Vasilev","Christos Athanasiadis"],"pdf_url":"https://arxiv.org/pdf/2410.13989v1.pdf","comment":"15 pages, 2 figures, Machine Learning Reproducibility Challenge 2024"},{"id":"http://arxiv.org/abs/2309.17329v3","updated":"2024-10-17T19:23:45Z","published":"2023-09-29T15:40:58Z","title":"Efficient Anatomical Labeling of Pulmonary Tree Structures via Deep\n  Point-Graph Representation-based Implicit Fields","summary":"  Pulmonary diseases rank prominently among the principal causes of death\nworldwide. Curing them will require, among other things, a better understanding\nof the complex 3D tree-shaped structures within the pulmonary system, such as\nairways, arteries, and veins. Traditional approaches using high-resolution\nimage stacks and standard CNNs on dense voxel grids face challenges in\ncomputational efficiency, limited resolution, local context, and inadequate\npreservation of shape topology. Our method addresses these issues by shifting\nfrom dense voxel to sparse point representation, offering better memory\nefficiency and global context utilization. However, the inherent sparsity in\npoint representation can lead to a loss of crucial connectivity in tree-shaped\nstructures. To mitigate this, we introduce graph learning on skeletonized\nstructures, incorporating differentiable feature fusion for improved topology\nand long-distance context capture. Furthermore, we employ an implicit function\nfor efficient conversion of sparse representations into dense reconstructions\nend-to-end. The proposed method not only delivers state-of-the-art performance\nin labeling accuracy, both overall and at key locations, but also enables\nefficient inference and the generation of closed surface shapes. Addressing\ndata scarcity in this field, we have also curated a comprehensive dataset to\nvalidate our approach. Data and code are available at\n\\url{https://github.com/M3DV/pulmonary-tree-labeling}.\n","authors":["Kangxian Xie","Jiancheng Yang","Donglai Wei","Ziqiao Weng","Pascal Fua"],"pdf_url":"https://arxiv.org/pdf/2309.17329v3.pdf","comment":"Accepted by Medical Image Analysis"},{"id":"http://arxiv.org/abs/2406.01029v4","updated":"2024-10-17T19:05:50Z","published":"2024-06-03T06:24:55Z","title":"CYCLO: Cyclic Graph Transformer Approach to Multi-Object Relationship\n  Modeling in Aerial Videos","summary":"  Video scene graph generation (VidSGG) has emerged as a transformative\napproach to capturing and interpreting the intricate relationships among\nobjects and their temporal dynamics in video sequences. In this paper, we\nintroduce the new AeroEye dataset that focuses on multi-object relationship\nmodeling in aerial videos. Our AeroEye dataset features various drone scenes\nand includes a visually comprehensive and precise collection of predicates that\ncapture the intricate relationships and spatial arrangements among objects. To\nthis end, we propose the novel Cyclic Graph Transformer (CYCLO) approach that\nallows the model to capture both direct and long-range temporal dependencies by\ncontinuously updating the history of interactions in a circular manner. The\nproposed approach also allows one to handle sequences with inherent cyclical\npatterns and process object relationships in the correct sequential order.\nTherefore, it can effectively capture periodic and overlapping relationships\nwhile minimizing information loss. The extensive experiments on the AeroEye\ndataset demonstrate the effectiveness of the proposed CYCLO model,\ndemonstrating its potential to perform scene understanding on drone videos.\nFinally, the CYCLO method consistently achieves State-of-the-Art (SOTA) results\non two in-the-wild scene graph generation benchmarks, i.e., PVSG and ASPIRe.\n","authors":["Trong-Thuan Nguyen","Pha Nguyen","Xin Li","Jackson Cothren","Alper Yilmaz","Khoa Luu"],"pdf_url":"https://arxiv.org/pdf/2406.01029v4.pdf","comment":"Accepted to NeurIPS 2024"},{"id":"http://arxiv.org/abs/2410.13976v1","updated":"2024-10-17T19:02:31Z","published":"2024-10-17T19:02:31Z","title":"Debiasing Large Vision-Language Models by Ablating Protected Attribute\n  Representations","summary":"  Large Vision Language Models (LVLMs) such as LLaVA have demonstrated\nimpressive capabilities as general-purpose chatbots that can engage in\nconversations about a provided input image. However, their responses are\ninfluenced by societal biases present in their training datasets, leading to\nundesirable differences in how the model responds when presented with images\ndepicting people of different demographics. In this work, we propose a novel\ndebiasing framework for LVLMs by directly ablating biased attributes during\ntext generation to avoid generating text related to protected attributes, or\neven representing them internally. Our method requires no training and a\nrelatively small amount of representative biased outputs (~1000 samples). Our\nexperiments show that not only can we can minimize the propensity of LVLMs to\ngenerate text related to protected attributes, but we can even use synthetic\ndata to inform the ablation while retaining captioning performance on real data\nsuch as COCO. Furthermore, we find the resulting generations from a debiased\nLVLM exhibit similar accuracy as a baseline biased model, showing that\ndebiasing effects can be achieved without sacrificing model performance.\n","authors":["Neale Ratzlaff","Matthew Lyle Olson","Musashi Hinck","Shao-Yen Tseng","Vasudev Lal","Phillip Howard"],"pdf_url":"https://arxiv.org/pdf/2410.13976v1.pdf","comment":"NeurIPS workshop on SafeGenAI, 10 pages, 2 figures"},{"id":"http://arxiv.org/abs/2410.13952v1","updated":"2024-10-17T18:22:50Z","published":"2024-10-17T18:22:50Z","title":"Satellite Streaming Video QoE Prediction: A Real-World Subjective\n  Database and Network-Level Prediction Models","summary":"  Demand for streaming services, including satellite, continues to exhibit\nunprecedented growth. Internet Service Providers find themselves at the\ncrossroads of technological advancements and rising customer expectations. To\nstay relevant and competitive, these ISPs must ensure their networks deliver\noptimal video streaming quality, a key determinant of user satisfaction.\nTowards this end, it is important to have accurate Quality of Experience\nprediction models in place. However, achieving robust performance by these\nmodels requires extensive data sets labeled by subjective opinion scores on\nvideos impaired by diverse playback disruptions. To bridge this data gap, we\nintroduce the LIVE-Viasat Real-World Satellite QoE Database. This database\nconsists of 179 videos recorded from real-world streaming services affected by\nvarious authentic distortion patterns. We also conducted a comprehensive\nsubjective study involving 54 participants, who contributed both\ncontinuous-time opinion scores and endpoint (retrospective) QoE scores. Our\nanalysis sheds light on various determinants influencing subjective QoE, such\nas stall events, spatial resolutions, bitrate, and certain network parameters.\nWe demonstrate the usefulness of this unique new resource by evaluating the\nefficacy of prevalent QoE-prediction models on it. We also created a new model\nthat maps the network parameters to predicted human perception scores, which\ncan be used by ISPs to optimize the video streaming quality of their networks.\nOur proposed model, which we call SatQA, is able to accurately predict QoE\nusing only network parameters, without any access to pixel data or\nvideo-specific metadata, estimated by Spearman's Rank Order Correlation\nCoefficient (SROCC), Pearson Linear Correlation Coefficient (PLCC), and Root\nMean Squared Error (RMSE), indicating high accuracy and reliability.\n","authors":["Bowen Chen","Zaixi Shang","Jae Won Chung","David Lerner","Werner Robitza","Rakesh Rao Ramachandra Rao","Alexander Raake","Alan C. Bovik"],"pdf_url":"https://arxiv.org/pdf/2410.13952v1.pdf","comment":null}],"Machine Learning":[{"id":"http://arxiv.org/abs/2410.12735v2","updated":"2024-10-17T02:47:35Z","published":"2024-10-16T16:51:01Z","title":"CREAM: Consistency Regularized Self-Rewarding Language Models","summary":"  Recent self-rewarding large language models (LLM) have successfully applied\nLLM-as-a-Judge to iteratively improve the alignment performance without the\nneed of human annotations for preference data. These methods commonly utilize\nthe same LLM to act as both the policy model (which generates responses) and\nthe reward model (which scores and ranks those responses). The ranked responses\nare then used as preference pairs to train the LLM via direct alignment\ntechnologies (e.g. DPO). However, it is noteworthy that throughout this\nprocess, there is no guarantee of accuracy in the rewarding and ranking, which\nis critical for ensuring accurate rewards and high-quality preference data.\nEmpirical results from relatively small LLMs (e.g., 7B parameters) also\nindicate that improvements from self-rewarding may diminish after several\niterations in certain situations, which we hypothesize is due to accumulated\nbias in the reward system. This bias can lead to unreliable preference data for\ntraining the LLM. To address this issue, we first formulate and analyze the\ngeneralized iterative preference fine-tuning framework for self-rewarding\nlanguage model. We then introduce the regularization to this generalized\nframework to mitigate the overconfident preference labeling in the\nself-rewarding process. Based on this theoretical insight, we propose a\nConsistency Regularized sElf-rewarding lAnguage Model (CREAM) that leverages\nthe rewarding consistency across different iterations to regularize the\nself-rewarding training, helping the model to learn from more reliable\npreference data. With this explicit regularization, our empirical results\ndemonstrate the superiority of CREAM in improving both reward consistency and\nalignment performance. The code is publicly available at\nhttps://github.com/Raibows/CREAM.\n","authors":["Zhaoyang Wang","Weilei He","Zhiyuan Liang","Xuchao Zhang","Chetan Bansal","Ying Wei","Weitong Zhang","Huaxiu Yao"],"pdf_url":"https://arxiv.org/pdf/2410.12735v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2405.14106v3","updated":"2024-10-17T01:15:29Z","published":"2024-05-23T02:24:52Z","title":"Nearly Tight Black-Box Auditing of Differentially Private Machine\n  Learning","summary":"  This paper presents an auditing procedure for the Differentially Private\nStochastic Gradient Descent (DP-SGD) algorithm in the black-box threat model\nthat is substantially tighter than prior work. The main intuition is to craft\nworst-case initial model parameters, as DP-SGD's privacy analysis is agnostic\nto the choice of the initial model parameters. For models trained on MNIST and\nCIFAR-10 at theoretical $\\varepsilon=10.0$, our auditing procedure yields\nempirical estimates of $\\varepsilon_{emp} = 7.21$ and $6.95$, respectively, on\na 1,000-record sample and $\\varepsilon_{emp}= 6.48$ and $4.96$ on the full\ndatasets. By contrast, previous audits were only (relatively) tight in stronger\nwhite-box models, where the adversary can access the model's inner parameters\nand insert arbitrary gradients. Overall, our auditing procedure can offer\nvaluable insight into how the privacy analysis of DP-SGD could be improved and\ndetect bugs and DP violations in real-world implementations. The source code\nneeded to reproduce our experiments is available at\nhttps://github.com/spalabucr/bb-audit-dpsgd.\n","authors":["Meenatchi Sundaram Muthu Selva Annamalai","Emiliano De Cristofaro"],"pdf_url":"https://arxiv.org/pdf/2405.14106v3.pdf","comment":"To appear in the Proceedings of the Thirty-eighth Annual Conference\n  on Neural Information Processing Systems (NeurIPS 2024). Please cite\n  accordingly"},{"id":"http://arxiv.org/abs/2410.12690v2","updated":"2024-10-17T01:53:56Z","published":"2024-10-16T15:50:57Z","title":"Local transfer learning Gaussian process modeling, with applications to\n  surrogate modeling of expensive computer simulators","summary":"  A critical bottleneck for scientific progress is the costly nature of\ncomputer simulations for complex systems. Surrogate models provide an appealing\nsolution: such models are trained on simulator evaluations, then used to\nemulate and quantify uncertainty on the expensive simulator at unexplored\ninputs. In many applications, one often has available data on related systems.\nFor example, in designing a new jet turbine, there may be existing studies on\nturbines with similar configurations. A key question is how information from\nsuch \"source\" systems can be transferred for effective surrogate training on\nthe \"target\" system of interest. We thus propose a new LOcal transfer Learning\nGaussian Process (LOL-GP) model, which leverages a carefully-designed Gaussian\nprocess to transfer such information for surrogate modeling. The key novelty of\nthe LOL-GP is a latent regularization model, which identifies regions where\ntransfer should be performed and regions where it should be avoided. This\n\"local transfer\" property is desirable in scientific systems: at certain\nparameters, such systems may behave similarly and thus transfer is beneficial;\nat other parameters, they may behave differently and thus transfer is\ndetrimental. By accounting for local transfer, the LOL-GP can rectify a\ncritical limitation of \"negative transfer\" in existing transfer learning\nmodels, where the transfer of information worsens predictive performance. We\nderive a Gibbs sampling algorithm for efficient posterior predictive sampling\non the LOL-GP, for both the multi-source and multi-fidelity transfer settings.\nWe then show, via a suite of numerical experiments and an application for jet\nturbine design, the improved surrogate performance of the LOL-GP over existing\nmethods.\n","authors":["Xinming Wang","Simon Mak","John Miller","Jianguo Wu"],"pdf_url":"https://arxiv.org/pdf/2410.12690v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.12686v2","updated":"2024-10-17T12:52:30Z","published":"2024-10-16T15:48:28Z","title":"Automatic Mapping of Anatomical Landmarks from Free-Text Using Large\n  Language Models: Insights from Llama-2","summary":"  Anatomical landmarks are vital in medical imaging for navigation and anomaly\ndetection. Modern large language models (LLMs), like Llama-2, offer promise for\nautomating the mapping of these landmarks in free-text radiology reports to\ncorresponding positions in image data. Recent studies propose LLMs may develop\ncoherent representations of generative processes. Motivated by these insights,\nwe investigated whether LLMs accurately represent the spatial positions of\nanatomical landmarks. Through experiments with Llama-2 models, we found that\nthey can linearly represent anatomical landmarks in space with considerable\nrobustness to different prompts. These results underscore the potential of LLMs\nto enhance the efficiency and accuracy of medical imaging workflows.\n","authors":["Mohamad Abdi","Gerardo Hermosillo Valadez","Halid Ziya Yerebakan"],"pdf_url":"https://arxiv.org/pdf/2410.12686v2.pdf","comment":"6 pages, 2 figures, 1 table"},{"id":"http://arxiv.org/abs/2410.12672v2","updated":"2024-10-17T04:46:29Z","published":"2024-10-16T15:36:13Z","title":"Context Matters: Leveraging Contextual Features for Time Series\n  Forecasting","summary":"  Time series forecasts are often influenced by exogenous contextual features\nin addition to their corresponding history. For example, in financial settings,\nit is hard to accurately predict a stock price without considering public\nsentiments and policy decisions in the form of news articles, tweets, etc.\nThough this is common knowledge, the current state-of-the-art (SOTA)\nforecasting models fail to incorporate such contextual information, owing to\nits heterogeneity and multimodal nature. To address this, we introduce\nContextFormer, a novel plug-and-play method to surgically integrate multimodal\ncontextual information into existing pre-trained forecasting models.\nContextFormer effectively distills forecast-specific information from rich\nmultimodal contexts, including categorical, continuous, time-varying, and even\ntextual information, to significantly enhance the performance of existing base\nforecasters. ContextFormer outperforms SOTA forecasting models by up to 30% on\na range of real-world datasets spanning energy, traffic, environmental, and\nfinancial domains.\n","authors":["Sameep Chattopadhyay","Pulkit Paliwal","Sai Shankar Narasimhan","Shubhankar Agarwal","Sandeep P. Chinchali"],"pdf_url":"https://arxiv.org/pdf/2410.12672v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.12455v2","updated":"2024-10-17T07:23:17Z","published":"2024-10-16T11:05:43Z","title":"Loss Landscape Characterization of Neural Networks without\n  Over-Parametrization","summary":"  Optimization methods play a crucial role in modern machine learning, powering\nthe remarkable empirical achievements of deep learning models. These successes\nare even more remarkable given the complex non-convex nature of the loss\nlandscape of these models. Yet, ensuring the convergence of optimization\nmethods requires specific structural conditions on the objective function that\nare rarely satisfied in practice. One prominent example is the widely\nrecognized Polyak-Lojasiewicz (PL) inequality, which has gained considerable\nattention in recent years. However, validating such assumptions for deep neural\nnetworks entails substantial and often impractical levels of\nover-parametrization. In order to address this limitation, we propose a novel\nclass of functions that can characterize the loss landscape of modern deep\nmodels without requiring extensive over-parametrization and can also include\nsaddle points. Crucially, we prove that gradient-based optimizers possess\ntheoretical guarantees of convergence under this assumption. Finally, we\nvalidate the soundness of our new function class through both theoretical\nanalysis and empirical experimentation across a diverse range of deep learning\nmodels.\n","authors":["Rustem Islamov","Niccolò Ajroldi","Antonio Orvieto","Aurelien Lucchi"],"pdf_url":"https://arxiv.org/pdf/2410.12455v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.13863v1","updated":"2024-10-17T17:59:59Z","published":"2024-10-17T17:59:59Z","title":"Fluid: Scaling Autoregressive Text-to-image Generative Models with\n  Continuous Tokens","summary":"  Scaling up autoregressive models in vision has not proven as beneficial as in\nlarge language models. In this work, we investigate this scaling problem in the\ncontext of text-to-image generation, focusing on two critical factors: whether\nmodels use discrete or continuous tokens, and whether tokens are generated in a\nrandom or fixed raster order using BERT- or GPT-like transformer architectures.\nOur empirical results show that, while all models scale effectively in terms of\nvalidation loss, their evaluation performance -- measured by FID, GenEval\nscore, and visual quality -- follows different trends. Models based on\ncontinuous tokens achieve significantly better visual quality than those using\ndiscrete tokens. Furthermore, the generation order and attention mechanisms\nsignificantly affect the GenEval score: random-order models achieve notably\nbetter GenEval scores compared to raster-order models. Inspired by these\nfindings, we train Fluid, a random-order autoregressive model on continuous\ntokens. Fluid 10.5B model achieves a new state-of-the-art zero-shot FID of 6.16\non MS-COCO 30K, and 0.69 overall score on the GenEval benchmark. We hope our\nfindings and results will encourage future efforts to further bridge the\nscaling gap between vision and language models.\n","authors":["Lijie Fan","Tianhong Li","Siyang Qin","Yuanzhen Li","Chen Sun","Michael Rubinstein","Deqing Sun","Kaiming He","Yonglong Tian"],"pdf_url":"https://arxiv.org/pdf/2410.13863v1.pdf","comment":"Tech report"},{"id":"http://arxiv.org/abs/2410.13857v1","updated":"2024-10-17T17:59:35Z","published":"2024-10-17T17:59:35Z","title":"How Numerical Precision Affects Mathematical Reasoning Capabilities of\n  LLMs","summary":"  Despite the remarkable success of Transformer-based Large Language Models\n(LLMs) across various domains, understanding and enhancing their mathematical\ncapabilities remains a significant challenge. In this paper, we conduct a\nrigorous theoretical analysis of LLMs' mathematical abilities, with a specific\nfocus on their arithmetic performances. We identify numerical precision as a\nkey factor that influences their effectiveness in mathematical tasks. Our\nresults show that Transformers operating with low numerical precision fail to\naddress arithmetic tasks, such as iterated addition and integer multiplication,\nunless the model size grows super-polynomially with respect to the input\nlength. In contrast, Transformers with standard numerical precision can\nefficiently handle these tasks with significantly smaller model sizes. We\nfurther support our theoretical findings through empirical experiments that\nexplore the impact of varying numerical precision on arithmetic tasks,\nproviding valuable insights for improving the mathematical reasoning\ncapabilities of LLMs.\n","authors":["Guhao Feng","Kai Yang","Yuntian Gu","Xinyue Ai","Shengjie Luo","Jiacheng Sun","Di He","Zhenguo Li","Liwei Wang"],"pdf_url":"https://arxiv.org/pdf/2410.13857v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.13855v1","updated":"2024-10-17T17:59:25Z","published":"2024-10-17T17:59:25Z","title":"Diffusing States and Matching Scores: A New Framework for Imitation\n  Learning","summary":"  Adversarial Imitation Learning is traditionally framed as a two-player\nzero-sum game between a learner and an adversarially chosen cost function, and\ncan therefore be thought of as the sequential generalization of a Generative\nAdversarial Network (GAN). A prominent example of this framework is Generative\nAdversarial Imitation Learning (GAIL). However, in recent years, diffusion\nmodels have emerged as a non-adversarial alternative to GANs that merely\nrequire training a score function via regression, yet produce generations of a\nhigher quality. In response, we investigate how to lift insights from diffusion\nmodeling to the sequential setting. We propose diffusing states and performing\nscore-matching along diffused states to measure the discrepancy between the\nexpert's and learner's states. Thus, our approach only requires training score\nfunctions to predict noises via standard regression, making it significantly\neasier and more stable to train than adversarial methods. Theoretically, we\nprove first- and second-order instance-dependent bounds with linear scaling in\nthe horizon, proving that our approach avoids the compounding errors that\nstymie offline approaches to imitation learning. Empirically, we show our\napproach outperforms GAN-style imitation learning baselines across various\ncontinuous control problems, including complex tasks like controlling humanoids\nto walk, sit, and crawl.\n","authors":["Runzhe Wu","Yiding Chen","Gokul Swamy","Kianté Brantley","Wen Sun"],"pdf_url":"https://arxiv.org/pdf/2410.13855v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.13853v1","updated":"2024-10-17T17:59:09Z","published":"2024-10-17T17:59:09Z","title":"AutoAL: Automated Active Learning with Differentiable Query Strategy\n  Search","summary":"  As deep learning continues to evolve, the need for data efficiency becomes\nincreasingly important. Considering labeling large datasets is both\ntime-consuming and expensive, active learning (AL) provides a promising\nsolution to this challenge by iteratively selecting the most informative\nsubsets of examples to train deep neural networks, thereby reducing the\nlabeling cost. However, the effectiveness of different AL algorithms can vary\nsignificantly across data scenarios, and determining which AL algorithm best\nfits a given task remains a challenging problem. This work presents the first\ndifferentiable AL strategy search method, named AutoAL, which is designed on\ntop of existing AL sampling strategies. AutoAL consists of two neural nets,\nnamed SearchNet and FitNet, which are optimized concurrently under a\ndifferentiable bi-level optimization framework. For any given task, SearchNet\nand FitNet are iteratively co-optimized using the labeled data, learning how\nwell a set of candidate AL algorithms perform on that task. With the optimal AL\nstrategies identified, SearchNet selects a small subset from the unlabeled pool\nfor querying their annotations, enabling efficient training of the task model.\nExperimental results demonstrate that AutoAL consistently achieves superior\naccuracy compared to all candidate AL algorithms and other selective AL\napproaches, showcasing its potential for adapting and integrating multiple\nexisting AL methods across diverse tasks and domains. Code will be available\nat: https://github.com/haizailache999/AutoAL.\n","authors":["Yifeng Wang","Xueying Zhan","Siyu Huang"],"pdf_url":"https://arxiv.org/pdf/2410.13853v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.13852v1","updated":"2024-10-17T17:59:03Z","published":"2024-10-17T17:59:03Z","title":"Retrospective Learning from Interactions","summary":"  Multi-turn interactions between large language models (LLMs) and users\nnaturally include implicit feedback signals. If an LLM responds in an\nunexpected way to an instruction, the user is likely to signal it by rephrasing\nthe request, expressing frustration, or pivoting to an alternative task. Such\nsignals are task-independent and occupy a relatively constrained subspace of\nlanguage, allowing the LLM to identify them even if it fails on the actual\ntask. This creates an avenue for continually learning from interactions without\nadditional annotations. We introduce ReSpect, a method to learn from such\nsignals in past interactions via retrospection. We deploy ReSpect in a new\nmultimodal interaction scenario, where humans instruct an LLM to solve an\nabstract reasoning task with a combinatorial solution space. Through thousands\nof interactions with humans, we show how ReSpect gradually improves task\ncompletion rate from 31% to 82%, all without any external annotation.\n","authors":["Zizhao Chen","Mustafa Omer Gul","Yiwei Chen","Gloria Geng","Anne Wu","Yoav Artzi"],"pdf_url":"https://arxiv.org/pdf/2410.13852v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.13850v1","updated":"2024-10-17T17:59:02Z","published":"2024-10-17T17:59:02Z","title":"Influence Functions for Scalable Data Attribution in Diffusion Models","summary":"  Diffusion models have led to significant advancements in generative\nmodelling. Yet their widespread adoption poses challenges regarding data\nattribution and interpretability. In this paper, we aim to help address such\nchallenges in diffusion models by developing an \\textit{influence functions}\nframework. Influence function-based data attribution methods approximate how a\nmodel's output would have changed if some training data were removed. In\nsupervised learning, this is usually used for predicting how the loss on a\nparticular example would change. For diffusion models, we focus on predicting\nthe change in the probability of generating a particular example via several\nproxy measurements. We show how to formulate influence functions for such\nquantities and how previously proposed methods can be interpreted as particular\ndesign choices in our framework. To ensure scalability of the Hessian\ncomputations in influence functions, we systematically develop K-FAC\napproximations based on generalised Gauss-Newton matrices specifically tailored\nto diffusion models. We recast previously proposed methods as specific design\nchoices in our framework and show that our recommended method outperforms\nprevious data attribution approaches on common evaluations, such as the Linear\nData-modelling Score (LDS) or retraining without top influences, without the\nneed for method-specific hyperparameter tuning.\n","authors":["Bruno Mlodozeniec","Runa Eschenhagen","Juhan Bae","Alexander Immer","David Krueger","Richard Turner"],"pdf_url":"https://arxiv.org/pdf/2410.13850v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.13849v1","updated":"2024-10-17T17:59:01Z","published":"2024-10-17T17:59:01Z","title":"From Gradient Clipping to Normalization for Heavy Tailed SGD","summary":"  Recent empirical evidence indicates that many machine learning applications\ninvolve heavy-tailed gradient noise, which challenges the standard assumptions\nof bounded variance in stochastic optimization. Gradient clipping has emerged\nas a popular tool to handle this heavy-tailed noise, as it achieves good\nperformance in this setting both theoretically and practically. However, our\ncurrent theoretical understanding of non-convex gradient clipping has three\nmain shortcomings. First, the theory hinges on large, increasing clipping\nthresholds, which are in stark contrast to the small constant clipping\nthresholds employed in practice. Second, clipping thresholds require knowledge\nof problem-dependent parameters to guarantee convergence. Lastly, even with\nthis knowledge, current sampling complexity upper bounds for the method are\nsub-optimal in nearly all parameters. To address these issues, we study\nconvergence of Normalized SGD (NSGD). First, we establish a parameter-free\nsample complexity for NSGD of\n$\\mathcal{O}\\left(\\varepsilon^{-\\frac{2p}{p-1}}\\right)$ to find an\n$\\varepsilon$-stationary point. Furthermore, we prove tightness of this result,\nby providing a matching algorithm-specific lower bound. In the setting where\nall problem parameters are known, we show this complexity is improved to\n$\\mathcal{O}\\left(\\varepsilon^{-\\frac{3p-2}{p-1}}\\right)$, matching the\npreviously known lower bound for all first-order methods in all problem\ndependent parameters. Finally, we establish high-probability convergence of\nNSGD with a mild logarithmic dependence on the failure probability. Our work\ncomplements the studies of gradient clipping under heavy tailed noise improving\nthe sample complexities of existing algorithms and offering an alternative\nmechanism to achieve high probability convergence.\n","authors":["Florian Hübler","Ilyas Fatkhullin","Niao He"],"pdf_url":"https://arxiv.org/pdf/2410.13849v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.08928v2","updated":"2024-10-17T17:58:53Z","published":"2024-10-11T15:53:24Z","title":"Towards Multilingual LLM Evaluation for European Languages","summary":"  The rise of Large Language Models (LLMs) has revolutionized natural language\nprocessing across numerous languages and tasks. However, evaluating LLM\nperformance in a consistent and meaningful way across multiple European\nlanguages remains challenging, especially due to the scarcity of\nlanguage-parallel multilingual benchmarks. We introduce a multilingual\nevaluation approach tailored for European languages. We employ translated\nversions of five widely-used benchmarks to assess the capabilities of 40 LLMs\nacross 21 European languages. Our contributions include examining the\neffectiveness of translated benchmarks, assessing the impact of different\ntranslation services, and offering a multilingual evaluation framework for LLMs\nthat includes newly created datasets: EU20-MMLU, EU20-HellaSwag, EU20-ARC,\nEU20-TruthfulQA, and EU20-GSM8K. The benchmarks and results are made publicly\navailable to encourage further research in multilingual LLM evaluation.\n","authors":["Klaudia Thellmann","Bernhard Stadler","Michael Fromm","Jasper Schulze Buschhoff","Alex Jude","Fabio Barth","Johannes Leveling","Nicolas Flores-Herr","Joachim Köhler","René Jäkel","Mehdi Ali"],"pdf_url":"https://arxiv.org/pdf/2410.08928v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.13846v1","updated":"2024-10-17T17:58:14Z","published":"2024-10-17T17:58:14Z","title":"SimLayerKV: A Simple Framework for Layer-Level KV Cache Reduction","summary":"  Recent advancements in large language models (LLMs) have extended their\ncapabilities to handle long contexts. However, increasing the number of model\nlayers and the length of input sequences significantly escalates the memory\nrequired to store key-value (KV) cache, posing challenges for efficient\ninference. To mitigate this issue, we present SimLayerKV, a simple yet\neffective method that reduces inter-layer KV cache redundancies by selectively\ndropping cache in identified lazy layers. Our approach is based on the\nobservation that certain layers in long-context LLMs exhibit \"lazy\" behavior,\ncontributing less to modeling long-range dependencies compared to non-lazy\nlayers. By analyzing attention weight patterns, we find that the behavior of\nthese lazy layers is consistent across tokens during generation for a given\ninput. This insight motivates our SimLayerKV, which identifies lazy layers and\nreduces their KV cache accordingly. SimLayerKV is training-free, generalizable,\nand can be implemented with only seven lines of code. We conduct extensive\nexperiments on three representative LLMs, e.g., LLaMA2-7B, LLaMA3-8B, and\nMistral-7B across 16 tasks from the LongBench benchmark. The results\ndemonstrate that SimLayerKV achieves a KV cache compression ratio of 5$\\times$\nwith only a 1.2% performance drop when combined with 4-bit quantization. Our\ncode is available at https://github.com/sail-sg/SimLayerKV.\n","authors":["Xuan Zhang","Cunxiao Du","Chao Du","Tianyu Pang","Wei Gao","Min Lin"],"pdf_url":"https://arxiv.org/pdf/2410.13846v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.13841v1","updated":"2024-10-17T17:56:53Z","published":"2024-10-17T17:56:53Z","title":"A Unified View of Delta Parameter Editing in Post-Trained Large-Scale\n  Models","summary":"  Post-training has emerged as a crucial paradigm for adapting large-scale\npre-trained models to various tasks, whose effects are fully reflected by delta\nparameters (i.e., the disparity between post-trained and pre-trained\nparameters). While numerous studies have explored delta parameter properties\nvia operations like pruning, quantization, low-rank approximation, and\nextrapolation, a unified framework for systematically examining these\ncharacteristics has been lacking. In this paper, we propose a novel perspective\nbased on Riemann sum approximation of the loss function to elucidate delta\nparameter editing operations. Our analysis categorizes existing methods into\nthree classes based on their post-editing performance: competitive, decreased,\nand improved, explaining how they are expressed by the Riemann sum\napproximation term and how they alter the model performance. Extensive\nexperiments on both visual and language models, including ViT, LLaMA 3, Qwen 2,\nand Mistral, corroborate our theoretical findings. Furthermore, we introduce\nextensions to existing techniques like DARE and BitDelta, highlighting their\nlimitations in leveraging the properties of delta parameters and reorganizing\nthem into general expressions to enhance the applicability and effectiveness of\ndelta parameter editing in post-trained models.\n","authors":["Qiaoyu Tang","Le Yu","Bowen Yu","Hongyu Lin","Keming Lu","Yaojie Lu","Xianpei Han","Le Sun"],"pdf_url":"https://arxiv.org/pdf/2410.13841v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.13837v1","updated":"2024-10-17T17:55:05Z","published":"2024-10-17T17:55:05Z","title":"ORSO: Accelerating Reward Design via Online Reward Selection and Policy\n  Optimization","summary":"  Reward shaping is a critical component in reinforcement learning (RL),\nparticularly for complex tasks where sparse rewards can hinder learning. While\nshaping rewards have been introduced to provide additional guidance, selecting\neffective shaping functions remains challenging and computationally expensive.\nThis paper introduces Online Reward Selection and Policy Optimization (ORSO), a\nnovel approach that frames shaping reward selection as an online model\nselection problem. ORSO employs principled exploration strategies to\nautomatically identify promising shaping reward functions without human\nintervention, balancing exploration and exploitation with provable regret\nguarantees. We demonstrate ORSO's effectiveness across various continuous\ncontrol tasks using the Isaac Gym simulator. Compared to traditional methods\nthat fully evaluate each shaping reward function, ORSO significantly improves\nsample efficiency, reduces computational time, and consistently identifies\nhigh-quality reward functions that produce policies comparable to those\ngenerated by domain experts through hand-engineered rewards.\n","authors":["Chen Bo Calvin Zhang","Zhang-Wei Hong","Aldo Pacchiano","Pulkit Agrawal"],"pdf_url":"https://arxiv.org/pdf/2410.13837v1.pdf","comment":"preprint, 35 pages, 23 figures"},{"id":"http://arxiv.org/abs/2410.13835v1","updated":"2024-10-17T17:54:06Z","published":"2024-10-17T17:54:06Z","title":"Active-Dormant Attention Heads: Mechanistically Demystifying\n  Extreme-Token Phenomena in LLMs","summary":"  Practitioners have consistently observed three puzzling phenomena in\ntransformer-based large language models (LLMs): attention sinks, value-state\ndrains, and residual-state peaks, collectively referred to as extreme-token\nphenomena. These phenomena are characterized by certain so-called \"sink tokens\"\nreceiving disproportionately high attention weights, exhibiting significantly\nsmaller value states, and having much larger residual-state norms than those of\nother tokens. These extreme tokens give rise to various challenges in LLM\ninference, quantization, and interpretability.\n  We elucidate the mechanisms behind extreme-token phenomena. First, we show\nthat these phenomena arise in very simple architectures -- transformers with\none to three layers -- trained on a toy model, the Bigram-Backcopy (BB) task.\nIn this setting, we identify an active-dormant mechanism, where attention heads\nbecome sinks for specific input domains while remaining non-sinks for others.\nOur theoretical analysis of the training dynamics reveals that these phenomena\nare driven by a mutual reinforcement mechanism. Building on these insights, we\npropose strategies to mitigate extreme-token phenomena during pretraining,\nincluding replacing softmax with ReLU and Adam with SGD. Next, we extend our\nanalysis to pretrained LLMs, including Llama and OLMo, showing that many\nattention heads exhibit a similar active-dormant mechanism as in the BB task,\nand that the mutual reinforcement mechanism also governs the emergence of\nextreme-token phenomena during LLM pretraining. Our results reveal that many of\nthe static and dynamic properties of extreme-token phenomena predicted by the\nBB task align with observations in pretrained LLMs.\n","authors":["Tianyu Guo","Druv Pai","Yu Bai","Jiantao Jiao","Michael I. Jordan","Song Mei"],"pdf_url":"https://arxiv.org/pdf/2410.13835v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.13831v1","updated":"2024-10-17T17:53:01Z","published":"2024-10-17T17:53:01Z","title":"The Disparate Benefits of Deep Ensembles","summary":"  Ensembles of Deep Neural Networks, Deep Ensembles, are widely used as a\nsimple way to boost predictive performance. However, their impact on\nalgorithmic fairness is not well understood yet. Algorithmic fairness\ninvestigates how a model's performance varies across different groups,\ntypically defined by protected attributes such as age, gender, or race. In this\nwork, we investigate the interplay between the performance gains from Deep\nEnsembles and fairness. Our analysis reveals that they unevenly favor different\ngroups in what we refer to as a disparate benefits effect. We empirically\ninvestigate this effect with Deep Ensembles applied to popular facial analysis\nand medical imaging datasets, where protected group attributes are given and\nfind that it occurs for multiple established group fairness metrics, including\nstatistical parity and equal opportunity. Furthermore, we identify the\nper-group difference in predictive diversity of ensemble members as the\npotential cause of the disparate benefits effect. Finally, we evaluate\ndifferent approaches to reduce unfairness due to the disparate benefits effect.\nOur findings show that post-processing is an effective method to mitigate this\nunfairness while preserving the improved performance of Deep Ensembles.\n","authors":["Kajetan Schweighofer","Adrian Arnaiz-Rodriguez","Sepp Hochreiter","Nuria Oliver"],"pdf_url":"https://arxiv.org/pdf/2410.13831v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.13828v1","updated":"2024-10-17T17:52:01Z","published":"2024-10-17T17:52:01Z","title":"A Common Pitfall of Margin-based Language Model Alignment: Gradient\n  Entanglement","summary":"  Reinforcement Learning from Human Feedback (RLHF) has become the predominant\napproach for language model (LM) alignment. At its core, RLHF uses a\nmargin-based loss for preference optimization, specifying ideal LM behavior\nonly by the difference between preferred and dispreferred responses. In this\npaper, we identify a common pitfall of margin-based methods -- the\nunder-specification of ideal LM behavior on preferred and dispreferred\nresponses individually, which leads to two unintended consequences as the\nmargin increases: (1) The probability of dispreferred (e.g., unsafe) responses\nmay increase, resulting in potential safety alignment failures. (2) The\nprobability of preferred responses may decrease, even when those responses are\nideal. We demystify the reasons behind these problematic behaviors:\nmargin-based losses couple the change in the preferred probability to the\ngradient of the dispreferred one, and vice versa, often preventing the\npreferred probability from increasing while the dispreferred one decreases, and\nthus causing a synchronized increase or decrease in both probabilities. We term\nthis effect, inherent in margin-based objectives, gradient entanglement.\nFormally, we derive conditions for general margin-based alignment objectives\nunder which gradient entanglement becomes concerning: the inner product of the\ngradients of preferred and dispreferred log-probabilities is large relative to\nthe individual gradient norms. We theoretically investigate why such inner\nproducts can be large when aligning language models and empirically validate\nour findings. Empirical implications of our framework extend to explaining\nimportant differences in the training dynamics of various preference\noptimization algorithms, and suggesting potential algorithm designs to mitigate\nthe under-specification issue of margin-based methods and thereby improving\nlanguage model alignment.\n","authors":["Hui Yuan","Yifan Zeng","Yue Wu","Huazheng Wang","Mengdi Wang","Liu Leqi"],"pdf_url":"https://arxiv.org/pdf/2410.13828v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.13826v1","updated":"2024-10-17T17:51:40Z","published":"2024-10-17T17:51:40Z","title":"Unearthing Skill-Level Insights for Understanding Trade-Offs of\n  Foundation Models","summary":"  With models getting stronger, evaluations have grown more complex, testing\nmultiple skills in one benchmark and even in the same instance at once.\nHowever, skill-wise performance is obscured when inspecting aggregate accuracy,\nunder-utilizing the rich signal modern benchmarks contain. We propose an\nautomatic approach to recover the underlying skills relevant for any evaluation\ninstance, by way of inspecting model-generated rationales. After validating the\nrelevance of rationale-parsed skills and inferring skills for $46$k instances\nover $12$ benchmarks, we observe many skills to be common across benchmarks,\nresulting in the curation of hundreds of skill-slices (i.e. sets of instances\ntesting a common skill). Inspecting accuracy over these slices yields novel\ninsights on model trade-offs: e.g., compared to GPT-4o and Claude 3.5 Sonnet,\non average, Gemini 1.5 Pro is $18\\%$ more accurate in \"computing molar mass\",\nbut $19\\%$ less accurate in \"applying constitutional law\", despite the overall\naccuracies of the three models differing by a mere $0.4\\%$. Furthermore, we\ndemonstrate the practical utility of our approach by showing that insights\nderived from skill slice analysis can generalize to held-out instances: when\nrouting each instance to the model strongest on the relevant skills, we see a\n$3\\%$ accuracy improvement over our $12$ dataset corpus. Our skill-slices and\nframework open a new avenue in model evaluation, leveraging skill-specific\nanalyses to unlock a more granular and actionable understanding of model\ncapabilities.\n","authors":["Mazda Moayeri","Vidhisha Balachandran","Varun Chandrasekaran","Safoora Yousefi","Thomas Fel","Soheil Feizi","Besmira Nushi","Neel Joshi","Vibhav Vineet"],"pdf_url":"https://arxiv.org/pdf/2410.13826v1.pdf","comment":"Code at: github.com/microsoft/skill-slice-insights"},{"id":"http://arxiv.org/abs/2407.16833v2","updated":"2024-10-17T17:51:19Z","published":"2024-07-23T20:51:52Z","title":"Retrieval Augmented Generation or Long-Context LLMs? A Comprehensive\n  Study and Hybrid Approach","summary":"  Retrieval Augmented Generation (RAG) has been a powerful tool for Large\nLanguage Models (LLMs) to efficiently process overly lengthy contexts. However,\nrecent LLMs like Gemini-1.5 and GPT-4 show exceptional capabilities to\nunderstand long contexts directly. We conduct a comprehensive comparison\nbetween RAG and long-context (LC) LLMs, aiming to leverage the strengths of\nboth. We benchmark RAG and LC across various public datasets using three latest\nLLMs. Results reveal that when resourced sufficiently, LC consistently\noutperforms RAG in terms of average performance. However, RAG's significantly\nlower cost remains a distinct advantage. Based on this observation, we propose\nSelf-Route, a simple yet effective method that routes queries to RAG or LC\nbased on model self-reflection. Self-Route significantly reduces the\ncomputation cost while maintaining a comparable performance to LC. Our findings\nprovide a guideline for long-context applications of LLMs using RAG and LC.\n","authors":["Zhuowan Li","Cheng Li","Mingyang Zhang","Qiaozhu Mei","Michael Bendersky"],"pdf_url":"https://arxiv.org/pdf/2407.16833v2.pdf","comment":"Accepted to EMNLP 2024 industry track"},{"id":"http://arxiv.org/abs/2410.13821v1","updated":"2024-10-17T17:47:54Z","published":"2024-10-17T17:47:54Z","title":"Artificial Kuramoto Oscillatory Neurons","summary":"  It has long been known in both neuroscience and AI that ``binding'' between\nneurons leads to a form of competitive learning where representations are\ncompressed in order to represent more abstract concepts in deeper layers of the\nnetwork. More recently, it was also hypothesized that dynamic (spatiotemporal)\nrepresentations play an important role in both neuroscience and AI. Building on\nthese ideas, we introduce Artificial Kuramoto Oscillatory Neurons (AKOrN) as a\ndynamical alternative to threshold units, which can be combined with arbitrary\nconnectivity designs such as fully connected, convolutional, or attentive\nmechanisms. Our generalized Kuramoto updates bind neurons together through\ntheir synchronization dynamics. We show that this idea provides performance\nimprovements across a wide spectrum of tasks such as unsupervised object\ndiscovery, adversarial robustness, calibrated uncertainty quantification, and\nreasoning. We believe that these empirical results show the importance of\nrethinking our assumptions at the most basic neuronal level of neural\nrepresentation, and in particular show the importance of dynamical\nrepresentations.\n","authors":["Takeru Miyato","Sindy Löwe","Andreas Geiger","Max Welling"],"pdf_url":"https://arxiv.org/pdf/2410.13821v1.pdf","comment":"Code: https://github.com/autonomousvision/akorn"},{"id":"http://arxiv.org/abs/2410.13816v1","updated":"2024-10-17T17:46:26Z","published":"2024-10-17T17:46:26Z","title":"Steering Your Generalists: Improving Robotic Foundation Models via Value\n  Guidance","summary":"  Large, general-purpose robotic policies trained on diverse demonstration\ndatasets have been shown to be remarkably effective both for controlling a\nvariety of robots in a range of different scenes, and for acquiring broad\nrepertoires of manipulation skills. However, the data that such policies are\ntrained on is generally of mixed quality -- not only are human-collected\ndemonstrations unlikely to perform the task perfectly, but the larger the\ndataset is, the harder it is to curate only the highest quality examples. It\nalso remains unclear how optimal data from one embodiment is for training on\nanother embodiment. In this paper, we present a general and broadly applicable\napproach that enhances the performance of such generalist robot policies at\ndeployment time by re-ranking their actions according to a value function\nlearned via offline RL. This approach, which we call Value-Guided Policy\nSteering (V-GPS), is compatible with a wide range of different generalist\npolicies, without needing to fine-tune or even access the weights of the\npolicy. We show that the same value function can improve the performance of\nfive different state-of-the-art policies with different architectures, even\nthough they were trained on distinct datasets, attaining consistent performance\nimprovement on multiple robotic platforms across a total of 12 tasks. Code and\nvideos can be found at: https://nakamotoo.github.io/V-GPS\n","authors":["Mitsuhiko Nakamoto","Oier Mees","Aviral Kumar","Sergey Levine"],"pdf_url":"https://arxiv.org/pdf/2410.13816v1.pdf","comment":"Conference on Robot Learning (CoRL) 2024. Project Page:\n  https://nakamotoo.github.io/V-GPS"},{"id":"http://arxiv.org/abs/2404.11018v3","updated":"2024-10-17T17:45:09Z","published":"2024-04-17T02:49:26Z","title":"Many-Shot In-Context Learning","summary":"  Large language models (LLMs) excel at few-shot in-context learning (ICL) --\nlearning from a few examples provided in context at inference, without any\nweight updates. Newly expanded context windows allow us to investigate ICL with\nhundreds or thousands of examples -- the many-shot regime. Going from few-shot\nto many-shot, we observe significant performance gains across a wide variety of\ngenerative and discriminative tasks. While promising, many-shot ICL can be\nbottlenecked by the available amount of human-generated examples. To mitigate\nthis limitation, we explore two new settings: Reinforced and Unsupervised ICL.\nReinforced ICL uses model-generated chain-of-thought rationales in place of\nhuman examples. Unsupervised ICL removes rationales from the prompt altogether,\nand prompts the model only with domain-specific questions. We find that both\nReinforced and Unsupervised ICL can be quite effective in the many-shot regime,\nparticularly on complex reasoning tasks. Finally, we demonstrate that, unlike\nfew-shot learning, many-shot learning is effective at overriding pretraining\nbiases, can learn high-dimensional functions with numerical inputs, and\nperforms comparably to fine-tuning. We also find that inference cost increases\nlinearly in the many-shot regime, and frontier LLMs benefit from many-shot ICL\nto varying degrees. Our analysis also reveals the limitations of next-token\nprediction loss as an indicator of downstream ICL performance.\n","authors":["Rishabh Agarwal","Avi Singh","Lei M. Zhang","Bernd Bohnet","Luis Rosias","Stephanie Chan","Biao Zhang","Ankesh Anand","Zaheer Abbas","Azade Nova","John D. Co-Reyes","Eric Chu","Feryal Behbahani","Aleksandra Faust","Hugo Larochelle"],"pdf_url":"https://arxiv.org/pdf/2404.11018v3.pdf","comment":"NeurIPS (Spotlight)"},{"id":"http://arxiv.org/abs/2410.13812v1","updated":"2024-10-17T17:45:07Z","published":"2024-10-17T17:45:07Z","title":"Private Counterfactual Retrieval","summary":"  Transparency and explainability are two extremely important aspects to be\nconsidered when employing black-box machine learning models in high-stake\napplications. Providing counterfactual explanations is one way of catering this\nrequirement. However, this also poses a threat to the privacy of both the\ninstitution that is providing the explanation as well as the user who is\nrequesting it. In this work, we propose multiple schemes inspired by private\ninformation retrieval (PIR) techniques which ensure the \\emph{user's privacy}\nwhen retrieving counterfactual explanations. We present a scheme which\nretrieves the \\emph{exact} nearest neighbor counterfactual explanation from a\ndatabase of accepted points while achieving perfect (information-theoretic)\nprivacy for the user. While the scheme achieves perfect privacy for the user,\nsome leakage on the database is inevitable which we quantify using a mutual\ninformation based metric. Furthermore, we propose strategies to reduce this\nleakage to achieve an advanced degree of database privacy. We extend these\nschemes to incorporate user's preference on transforming their attributes, so\nthat a more actionable explanation can be received. Since our schemes rely on\nfinite field arithmetic, we empirically validate our schemes on real datasets\nto understand the trade-off between the accuracy and the finite field sizes.\n","authors":["Mohamed Nomeir","Pasan Dissanayake","Shreya Meel","Sanghamitra Dutta","Sennur Ulukus"],"pdf_url":"https://arxiv.org/pdf/2410.13812v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.06615v2","updated":"2024-10-17T17:40:25Z","published":"2023-01-16T21:36:49Z","title":"Data-Driven Estimation of Heterogeneous Treatment Effects","summary":"  Estimating how a treatment affects different individuals, known as\nheterogeneous treatment effect estimation, is an important problem in empirical\nsciences. In the last few years, there has been a considerable interest in\nadapting machine learning algorithms to the problem of estimating heterogeneous\neffects from observational and experimental data. However, these algorithms\noften make strong assumptions about the observed features in the data and\nignore the structure of the underlying causal model, which can lead to biased\nestimation. At the same time, the underlying causal mechanism is rarely known\nin real-world datasets, making it hard to take it into consideration. In this\nwork, we provide a survey of state-of-the-art data-driven methods for\nheterogeneous treatment effect estimation using machine learning, broadly\ncategorizing them as methods that focus on counterfactual prediction and\nmethods that directly estimate the causal effect. We also provide an overview\nof a third category of methods which rely on structural causal models and learn\nthe model structure from data. Our empirical evaluation under various\nunderlying structural model mechanisms shows the advantages and deficiencies of\nexisting estimators and of the metrics for measuring their performance.\n","authors":["Christopher Tran","Keith Burghardt","Kristina Lerman","Elena Zheleva"],"pdf_url":"https://arxiv.org/pdf/2301.06615v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.13802v1","updated":"2024-10-17T17:39:46Z","published":"2024-10-17T17:39:46Z","title":"Adversarial Testing as a Tool for Interpretability: Length-based\n  Overfitting of Elementary Functions in Transformers","summary":"  The Transformer model has a tendency to overfit various aspects of the\ntraining data, such as the overall sequence length. We study elementary string\nedit functions using a defined set of error indicators to interpret the\nbehaviour of the sequence-to-sequence Transformer. We show that generalization\nto shorter sequences is often possible, but confirm that longer sequences are\nhighly problematic, although partially correct answers are often obtained.\nAdditionally, we find that other structural characteristics of the sequences,\nsuch as subsegment length, may be equally important. We hypothesize that the\nmodels learn algorithmic aspects of the tasks simultaneously with structural\naspects but adhering to the structural aspects is unfortunately often preferred\nby Transformer when they come into conflict.\n","authors":["Patrik Zavoral","Dušan Variš","Ondřej Bojar"],"pdf_url":"https://arxiv.org/pdf/2410.13802v1.pdf","comment":"9 pages, 8 figures, 2 tables; to be published"},{"id":"http://arxiv.org/abs/2410.13799v1","updated":"2024-10-17T17:38:44Z","published":"2024-10-17T17:38:44Z","title":"Machine-Learning Analysis of Radiative Decays to Dark Matter at the LHC","summary":"  The search for weakly interacting matter particles (WIMPs) is one of the main\nobjectives of the High Luminosity Large Hadron Collider (HL-LHC). In this work\nwe use Machine Learning (ML) techniques to explore WIMP radiative decays into a\nDark Matter (DM) candidate in a supersymmetric framework. The minimal\nsupersymmetric WIMP sector includes the lightest neutralino that can provide\nthe observed DM relic density through its co-annihilation with the second\nlightest neutralino and lightest chargino. Moreover, the direct DM detection\ncross section rates fulfill current experimental bounds and provide discovery\ntargets for the same region of model parameters in which the radiative decay of\nthe second lightest neutralino into a photon and the lightest neutralino is\nenhanced. This strongly motivates the search for radiatively decaying\nneutralinos which, however, suffers from strong backgrounds. We investigate the\nLHC reach in the search for these radiatively decaying particles by means of\ncut-based and ML methods and estimate its discovery potential in this\nwell-motivated, new physics scenario.\n","authors":["Ernesto Arganda","Marcela Carena","Martín de los Rios","Andres D. Perez","Duncan Rocha","Rosa M. Sandá Seoane","Carlos E. M. Wagner"],"pdf_url":"https://arxiv.org/pdf/2410.13799v1.pdf","comment":"32 pages, 9 figures, 3 tables, 4 appendices"},{"id":"http://arxiv.org/abs/2410.13800v1","updated":"2024-10-17T17:38:44Z","published":"2024-10-17T17:38:44Z","title":"Discrete distributions are learnable from metastable samples","summary":"  Markov chain samplers designed to sample from multi-variable distributions\noften undesirably get stuck in specific regions of their state space. This\ncauses such samplers to approximately sample from a metastable distribution\nwhich is usually quite different from the desired, stationary distribution of\nthe chain. We show that single-variable conditionals of metastable\ndistributions of reversible Markov chain samplers that satisfy a strong\nmetastability condition are on average very close to those of the true\ndistribution. This holds even when the metastable distribution is far away from\nthe true model in terms of global metrics like Kullback-Leibler divergence or\ntotal variation distance. This property allows us to learn the true model using\na conditional likelihood based estimator, even when the samples come from a\nmetastable distribution concentrated in a small region of the state space.\nExplicit examples of such metastable states can be constructed from regions\nthat effectively bottleneck the probability flow and cause poor mixing of the\nMarkov chain. For specific cases of binary pairwise undirected graphical\nmodels, we extend our results to further rigorously show that data coming from\nmetastable states can be used to learn the parameters of the energy function\nand recover the structure of the model.\n","authors":["Abhijith Jayakumar","Andrey Y. Lokhov","Sidhant Misra","Marc Vuffray"],"pdf_url":"https://arxiv.org/pdf/2410.13800v1.pdf","comment":"Preliminary version, 26 pages"},{"id":"http://arxiv.org/abs/2410.13798v1","updated":"2024-10-17T17:38:24Z","published":"2024-10-17T17:38:24Z","title":"Learning Graph Quantized Tokenizers for Transformers","summary":"  Transformers serve as the backbone architectures of Foundational Models,\nwhere a domain-specific tokenizer helps them adapt to various domains. Graph\nTransformers (GTs) have recently emerged as a leading model in geometric deep\nlearning, outperforming Graph Neural Networks (GNNs) in various graph learning\ntasks. However, the development of tokenizers for graphs has lagged behind\nother modalities, with existing approaches relying on heuristics or GNNs\nco-trained with Transformers. To address this, we introduce GQT (\\textbf{G}raph\n\\textbf{Q}uantized \\textbf{T}okenizer), which decouples tokenizer training from\nTransformer training by leveraging multi-task graph self-supervised learning,\nyielding robust and generalizable graph tokens. Furthermore, the GQT utilizes\nResidual Vector Quantization (RVQ) to learn hierarchical discrete tokens,\nresulting in significantly reduced memory requirements and improved\ngeneralization capabilities. By combining the GQT with token modulation, a\nTransformer encoder achieves state-of-the-art performance on 16 out of 18\nbenchmarks, including large-scale homophilic and heterophilic datasets. The\ncode is available at: https://github.com/limei0307/graph-tokenizer\n","authors":["Limei Wang","Kaveh Hassani","Si Zhang","Dongqi Fu","Baichuan Yuan","Weilin Cong","Zhigang Hua","Hao Wu","Ning Yao","Bo Long"],"pdf_url":"https://arxiv.org/pdf/2410.13798v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2312.14180v2","updated":"2024-10-17T17:38:00Z","published":"2023-12-19T00:36:53Z","title":"Dynamic Topic Language Model on Heterogeneous Children's Mental Health\n  Clinical Notes","summary":"  Mental health diseases affect children's lives and well-beings which have\nreceived increased attention since the COVID-19 pandemic. Analyzing psychiatric\nclinical notes with topic models is critical to evaluating children's mental\nstatus over time. However, few topic models are built for longitudinal\nsettings, and most existing approaches fail to capture temporal trajectories\nfor each document. To address these challenges, we develop a dynamic topic\nmodel with consistent topics and individualized temporal dependencies on the\nevolving document metadata. Our model preserves the semantic meaning of\ndiscovered topics over time and incorporates heterogeneity among documents. In\nparticular, when documents can be categorized, we propose a classifier-free\napproach to maximize topic heterogeneity across different document groups. We\nalso present an efficient variational optimization procedure adapted for the\nmultistage longitudinal setting. In this case study, we apply our method to the\npsychiatric clinical notes from a large tertiary pediatric hospital in Southern\nCalifornia and achieve a 38% increase in the overall coherence of extracted\ntopics. Our real data analysis reveals that children tend to express more\nnegative emotions during state shutdowns and more positive when schools reopen.\nFurthermore, it suggests that sexual and gender minority (SGM) children display\nmore pronounced reactions to major COVID-19 events and a greater sensitivity to\nvaccine-related news than non-SGM children. This study examines children's\nmental health progression during the pandemic and offers clinicians valuable\ninsights to recognize disparities in children's mental health related to their\nsexual and gender identities.\n","authors":["Hanwen Ye","Tatiana Moreno","Adrianne Alpern","Louis Ehwerhemuepha","Annie Qu"],"pdf_url":"https://arxiv.org/pdf/2312.14180v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.13794v1","updated":"2024-10-17T17:34:06Z","published":"2024-10-17T17:34:06Z","title":"Arbitrarily-Conditioned Multi-Functional Diffusion for Multi-Physics\n  Emulation","summary":"  Modern physics simulation often involves multiple functions of interests, and\ntraditional numerical approaches are known to be complex and computationally\ncostly. While machine learning-based surrogate models can offer significant\ncost reductions, most focus on a single task, such as forward prediction, and\ntypically lack uncertainty quantification -- an essential component in many\napplications. To overcome these limitations, we propose Arbitrarily-Conditioned\nMulti-Functional Diffusion (ACMFD), a versatile probabilistic surrogate model\nfor multi-physics emulation. ACMFD can perform a wide range of tasks within a\nsingle framework, including forward prediction, various inverse problems, and\nsimulating data for entire systems or subsets of quantities conditioned on\nothers. Specifically, we extend the standard Denoising Diffusion Probabilistic\nModel (DDPM) for multi-functional generation by modeling noise as Gaussian\nprocesses (GP). We then introduce an innovative denoising loss. The training\ninvolves randomly sampling the conditioned part and fitting the corresponding\npredicted noise to zero, enabling ACMFD to flexibly generate function values\nconditioned on any other functions or quantities. To enable efficient training\nand sampling, and to flexibly handle irregularly sampled data, we use GPs to\ninterpolate function samples onto a grid, inducing a Kronecker product\nstructure for efficient computation. We demonstrate the advantages of ACMFD\nacross several fundamental multi-physics systems.\n","authors":["Da Long","Zhitong Xu","Guang Yang","Akil Narayan","Shandian Zhe"],"pdf_url":"https://arxiv.org/pdf/2410.13794v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.13792v1","updated":"2024-10-17T17:32:35Z","published":"2024-10-17T17:32:35Z","title":"Analyzing Deep Transformer Models for Time Series Forecasting via\n  Manifold Learning","summary":"  Transformer models have consistently achieved remarkable results in various\ndomains such as natural language processing and computer vision. However,\ndespite ongoing research efforts to better understand these models, the field\nstill lacks a comprehensive understanding. This is particularly true for deep\ntime series forecasting methods, where analysis and understanding work is\nrelatively limited. Time series data, unlike image and text information, can be\nmore challenging to interpret and analyze. To address this, we approach the\nproblem from a manifold learning perspective, assuming that the latent\nrepresentations of time series forecasting models lie next to a low-dimensional\nmanifold. In our study, we focus on analyzing the geometric features of these\nlatent data manifolds, including intrinsic dimension and principal curvatures.\nOur findings reveal that deep transformer models exhibit similar geometric\nbehavior across layers, and these geometric features are correlated with model\nperformance. Additionally, we observe that untrained models initially have\ndifferent structures, but they rapidly converge during training. By leveraging\nour geometric analysis and differentiable tools, we can potentially design new\nand improved deep forecasting neural networks. This approach complements\nexisting analysis studies and contributes to a better understanding of\ntransformer models in the context of time series forecasting. Code is released\nat https://github.com/azencot-group/GATLM.\n","authors":["Ilya Kaufman","Omri Azencot"],"pdf_url":"https://arxiv.org/pdf/2410.13792v1.pdf","comment":"Accepted to TMLR 2024"},{"id":"http://arxiv.org/abs/2405.17882v2","updated":"2024-10-17T17:28:16Z","published":"2024-05-28T07:08:29Z","title":"Achieving Exponential Asymptotic Optimality in Average-Reward Restless\n  Bandits without Global Attractor Assumption","summary":"  We consider the infinite-horizon average-reward restless bandit problem. We\npropose a novel \\emph{two-set policy} that maintains two dynamic subsets of\narms: one subset of arms has a nearly optimal state distribution and takes\nactions according to an Optimal Local Control routine; the other subset of arms\nis driven towards the optimal state distribution and gradually merged into the\nfirst subset. We show that our two-set policy is asymptotically optimal with an\n$O(\\exp(-C N))$ optimality gap for an $N$-armed problem, under the mild\nassumptions of aperiodic-unichain, non-degeneracy, and local stability. Our\npolicy is the first to achieve \\emph{exponential asymptotic optimality} under\nthe above set of easy-to-verify assumptions, whereas prior work either requires\na strong \\emph{global attractor} assumption or only achieves an $O(1/\\sqrt{N})$\noptimality gap. We further discuss obstacles in weakening the assumptions by\ndemonstrating examples where exponential asymptotic optimality is not\nachievable when any of the three assumptions is violated. Notably, we prove a\nlower bound for a large class of locally unstable restless bandits, showing\nthat local stability is particularly fundamental for exponential asymptotic\noptimality. Finally, we use simulations to demonstrate that the two-set policy\noutperforms previous policies on certain RB problems and performs competitively\noverall.\n","authors":["Yige Hong","Qiaomin Xie","Yudong Chen","Weina Wang"],"pdf_url":"https://arxiv.org/pdf/2405.17882v2.pdf","comment":"55 pages, 4 figures. In this version we included simulations"},{"id":"http://arxiv.org/abs/2410.13782v1","updated":"2024-10-17T17:20:24Z","published":"2024-10-17T17:20:24Z","title":"DPLM-2: A Multimodal Diffusion Protein Language Model","summary":"  Proteins are essential macromolecules defined by their amino acid sequences,\nwhich determine their three-dimensional structures and, consequently, their\nfunctions in all living organisms. Therefore, generative protein modeling\nnecessitates a multimodal approach to simultaneously model, understand, and\ngenerate both sequences and structures. However, existing methods typically use\nseparate models for each modality, limiting their ability to capture the\nintricate relationships between sequence and structure. This results in\nsuboptimal performance in tasks that requires joint understanding and\ngeneration of both modalities. In this paper, we introduce DPLM-2, a multimodal\nprotein foundation model that extends discrete diffusion protein language model\n(DPLM) to accommodate both sequences and structures. To enable structural\nlearning with the language model, 3D coordinates are converted to discrete\ntokens using a lookup-free quantization-based tokenizer. By training on both\nexperimental and high-quality synthetic structures, DPLM-2 learns the joint\ndistribution of sequence and structure, as well as their marginals and\nconditionals. We also implement an efficient warm-up strategy to exploit the\nconnection between large-scale evolutionary data and structural inductive\nbiases from pre-trained sequence-based protein language models. Empirical\nevaluation shows that DPLM-2 can simultaneously generate highly compatible\namino acid sequences and their corresponding 3D structures eliminating the need\nfor a two-stage generation approach. Moreover, DPLM-2 demonstrates competitive\nperformance in various conditional generation tasks, including folding, inverse\nfolding, and scaffolding with multimodal motif inputs, as well as providing\nstructure-aware representations for predictive tasks.\n","authors":["Xinyou Wang","Zaixiang Zheng","Fei Ye","Dongyu Xue","Shujian Huang","Quanquan Gu"],"pdf_url":"https://arxiv.org/pdf/2410.13782v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.13780v1","updated":"2024-10-17T17:19:48Z","published":"2024-10-17T17:19:48Z","title":"Optimal Quantization for Matrix Multiplication","summary":"  Recent work in machine learning community proposed multiple methods for\nperforming lossy compression (quantization) of large matrices. This\nquantization is important for accelerating matrix multiplication (main\ncomponent of large language models), which is often bottlenecked by the speed\nof loading these matrices from memory. Unlike classical vector quantization and\nrate-distortion theory, the goal of these new compression algorithms is to be\nable to approximate not the matrices themselves, but their matrix product.\nSpecifically, given a pair of real matrices $A,B$ an encoder (compressor) is\napplied to each of them independently producing descriptions with $R$ bits per\nentry. These representations subsequently are used by the decoder to estimate\nmatrix product $A^\\top B$. In this work, we provide a non-asymptotic lower\nbound on the mean squared error of this approximation (as a function of rate\n$R$) for the case of matrices $A,B$ with iid Gaussian entries. Algorithmically,\nwe construct a universal quantizer based on nested lattices with an explicit\nguarantee of approximation error for any (non-random) pair of matrices $A$, $B$\nin terms of only Frobenius norms $\\|A\\|_F, \\|B\\|_F$ and $\\|A^\\top B\\|_F$. For\niid Gaussian matrices our quantizer achieves the lower bound and is, thus,\nasymptotically optimal. A practical low-complexity version of our quantizer\nachieves performance quite close to optimal. In information-theoretic terms we\nderive rate-distortion function for matrix multiplication of iid Gaussian\nmatrices.\n","authors":["Or Ordentlich","Yury Polyanskiy"],"pdf_url":"https://arxiv.org/pdf/2410.13780v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.13779v1","updated":"2024-10-17T17:18:30Z","published":"2024-10-17T17:18:30Z","title":"The Mystery of the Pathological Path-star Task for Language Models","summary":"  The recently introduced path-star task is a minimal task designed to\nexemplify limitations to the abilities of language models (Bachmann and\nNagarajan, 2024). It involves a path-star graph where multiple arms radiate\nfrom a single starting node and each node is unique. Given the start node and a\nspecified target node that ends an arm, the task is to generate the arm\ncontaining that target node. This is straightforward for a human but\nsurprisingly difficult for language models, which did not outperform the random\nbaseline. The authors hypothesized this is due to a deficiency in\nteacher-forcing and the next-token prediction paradigm.\n  We demonstrate the task is learnable using teacher-forcing in alternative\nsettings and that the issue is partially due to representation. We introduce a\nregularization method using structured samples of the same graph but with\ndiffering target nodes, improving results across a variety of model types. We\nprovide RASP proofs showing the task is theoretically solvable. Finally, we\nfind settings where an encoder-only model can consistently solve the task.\n","authors":["Arvid Frydenlund"],"pdf_url":"https://arxiv.org/pdf/2410.13779v1.pdf","comment":"EMNLP 2024 Main"},{"id":"http://arxiv.org/abs/2410.13778v1","updated":"2024-10-17T17:17:38Z","published":"2024-10-17T17:17:38Z","title":"Change Detection in Multivariate data streams: Online Analysis with\n  Kernel-QuantTree","summary":"  We present Kernel-QuantTree Exponentially Weighted Moving Average (KQT-EWMA),\na non-parametric change-detection algorithm that combines the Kernel-QuantTree\n(KQT) histogram and the EWMA statistic to monitor multivariate data streams\nonline. The resulting monitoring scheme is very flexible, since histograms can\nbe used to model any stationary distribution, and practical, since the\ndistribution of test statistics does not depend on the distribution of\ndatastream in stationary conditions (non-parametric monitoring). KQT-EWMA\nenables controlling false alarms by operating at a pre-determined Average Run\nLength ($ARL_0$), which measures the expected number of stationary samples to\nbe monitored before triggering a false alarm. The latter peculiarity is in\ncontrast with most non-parametric change-detection tests, which rarely can\ncontrol the $ARL_0$ a priori. Our experiments on synthetic and real-world\ndatasets demonstrate that KQT-EWMA can control $ARL_0$ while achieving\ndetection delays comparable to or lower than state-of-the-art methods designed\nto work in the same conditions.\n","authors":["Michelangelo Olmo Nogara Notarianni","Filippo Leveni","Diego Stucchi","Luca Frittoli","Giacomo Boracchi"],"pdf_url":"https://arxiv.org/pdf/2410.13778v1.pdf","comment":"AALTD workshop at ECML 2024 (https://ecml-aaltd.github.io/aaltd2024/)"},{"id":"http://arxiv.org/abs/2410.13569v1","updated":"2024-10-17T17:17:09Z","published":"2024-10-17T17:17:09Z","title":"Representing Model Weights with Language using Tree Experts","summary":"  The increasing availability of public models begs the question: can we train\nneural networks that use other networks as input? This paper learns to\nrepresent models within a joint space that embeds both model weights and\nlanguage. However, machine learning on model weights is challenging as model\nweights often exhibit significant variation unrelated to the models' semantic\nproperties (nuisance variation). We identify a key property of real-world\nmodels: most public models belong to a small set of Model Trees, where all\nmodels within a tree are fine-tuned from a common ancestor (e.g., a foundation\nmodel). Importantly, we find that within each tree there is less nuisance\nvariation between models. For example, while classifying models according to\ntheir training dataset generally requires complex architectures, in our case,\neven a linear classifier trained on a single layer is often effective. While\neffective, linear layers are computationally expensive as model weights are\nvery high dimensional. To address this, we introduce Probing Experts (ProbeX),\na theoretically motivated, lightweight probing method. Notably, ProbeX is the\nfirst probing method designed to learn from the weights of just a single model\nlayer. We also construct and release a dataset that simulates the structure of\npublic model repositories. Our results show that ProbeX can effectively map the\nweights of large models into a shared weight-language embedding space.\nFurthermore, we demonstrate the impressive generalization of our method,\nachieving zero-shot model classification and retrieval.\n","authors":["Eliahu Horwitz","Bar Cavia","Jonathan Kahana","Yedid Hoshen"],"pdf_url":"https://arxiv.org/pdf/2410.13569v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.13773v1","updated":"2024-10-17T17:11:33Z","published":"2024-10-17T17:11:33Z","title":"Enhancing Retail Sales Forecasting with Optimized Machine Learning\n  Models","summary":"  In retail sales forecasting, accurately predicting future sales is crucial\nfor inventory management and strategic planning. Traditional methods like LR\noften fall short due to the complexity of sales data, which includes\nseasonality and numerous product families. Recent advancements in machine\nlearning (ML) provide more robust alternatives. This research benefits from the\npower of ML, particularly Random Forest (RF), Gradient Boosting (GB), Support\nVector Regression (SVR), and XGBoost, to improve prediction accuracy. Despite\nadvancements, a significant gap exists in handling complex datasets with high\nseasonality and multiple product families. The proposed solution involves\nimplementing and optimizing a RF model, leveraging hyperparameter tuning\nthrough randomized search cross-validation. This approach addresses the\ncomplexities of the dataset, capturing intricate patterns that traditional\nmethods miss. The optimized RF model achieved an R-squared value of 0.945,\nsubstantially higher than the initial RF model and traditional LR, which had an\nR-squared of 0.531. The model reduced the root mean squared logarithmic error\n(RMSLE) to 1.172, demonstrating its superior predictive capability. The\noptimized RF model did better than cutting-edge models like Gradient Boosting\n(R-squared: 0.942), SVR (R-squared: 0.940), and XGBoost (R-squared: 0.939),\nwith more minor mean squared error (MSE) and mean absolute error (MAE) numbers.\nThe results demonstrate that the optimized RF model excels in forecasting\nretail sales, handling the datasets complexity with higher accuracy and\nreliability. This research highlights the importance of advanced ML techniques\nin predictive analytics, offering a significant improvement over traditional\nmethods and other contemporary models.\n","authors":["Priyam Ganguly","Isha Mukherjee"],"pdf_url":"https://arxiv.org/pdf/2410.13773v1.pdf","comment":"IEEE 4th ICSES 2024"},{"id":"http://arxiv.org/abs/2410.13772v1","updated":"2024-10-17T17:09:56Z","published":"2024-10-17T17:09:56Z","title":"Is Prior-Free Black-Box Non-Stationary Reinforcement Learning Feasible?","summary":"  We study the problem of Non-Stationary Reinforcement Learning (NS-RL) without\nprior knowledge about the system's non-stationarity. A state-of-the-art,\nblack-box algorithm, known as MASTER, is considered, with a focus on\nidentifying the conditions under which it can achieve its stated goals.\nSpecifically, we prove that MASTER's non-stationarity detection mechanism is\nnot triggered for practical choices of horizon, leading to performance akin to\na random restarting algorithm. Moreover, we show that the regret bound for\nMASTER, while being order optimal, stays above the worst-case linear regret\nuntil unreasonably large values of the horizon. To validate these observations,\nMASTER is tested for the special case of piecewise stationary multi-armed\nbandits, along with methods that employ random restarting, and others that use\nquickest change detection to restart. A simple, order optimal random restarting\nalgorithm, that has prior knowledge of the non-stationarity is proposed as a\nbaseline. The behavior of the MASTER algorithm is validated in simulations, and\nit is shown that methods employing quickest change detection are more robust\nand consistently outperform MASTER and other random restarting approaches.\n","authors":["Argyrios Gerogiannis","Yu-Han Huang","Venugopal V. Veeravalli"],"pdf_url":"https://arxiv.org/pdf/2410.13772v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.13770v1","updated":"2024-10-17T17:08:39Z","published":"2024-10-17T17:08:39Z","title":"Probing the Latent Hierarchical Structure of Data via Diffusion Models","summary":"  High-dimensional data must be highly structured to be learnable. Although the\ncompositional and hierarchical nature of data is often put forward to explain\nlearnability, quantitative measurements establishing these properties are\nscarce. Likewise, accessing the latent variables underlying such a data\nstructure remains a challenge. In this work, we show that forward-backward\nexperiments in diffusion-based models, where data is noised and then denoised\nto generate new samples, are a promising tool to probe the latent structure of\ndata. We predict in simple hierarchical models that, in this process, changes\nin data occur by correlated chunks, with a length scale that diverges at a\nnoise level where a phase transition is known to take place. Remarkably, we\nconfirm this prediction in both text and image datasets using state-of-the-art\ndiffusion models. Our results show how latent variable changes manifest in the\ndata and establish how to measure these effects in real data using diffusion\nmodels.\n","authors":["Antonio Sclocchi","Alessandro Favero","Noam Itzhak Levi","Matthieu Wyart"],"pdf_url":"https://arxiv.org/pdf/2410.13770v1.pdf","comment":"11 pages, 6 figures"},{"id":"http://arxiv.org/abs/2405.11785v2","updated":"2024-10-17T17:00:37Z","published":"2024-05-20T05:08:55Z","title":"Guided Multi-objective Generative AI to Enhance Structure-based Drug\n  Design","summary":"  Generative AI has the potential to revolutionize drug discovery. Yet, despite\nrecent advances in deep learning, existing models cannot generate molecules\nthat satisfy all desired physicochemical properties. Herein, we describe\nIDOLpro, a generative chemistry AI combining diffusion with multi-objective\noptimization for structure-based drug design. Differentiable scoring functions\nguide the latent variables of the diffusion model to explore uncharted chemical\nspace and generate novel ligands in silico, optimizing a plurality of target\nphysicochemical properties. We demonstrate our platform's effectiveness by\ngenerating ligands with optimized binding affinity and synthetic accessibility\non two benchmark sets. IDOLpro produces ligands with binding affinities over\n10%-20% better than the next best state-of-the-art method on each test set,\nproducing more drug-like molecules with generally better synthetic\naccessibility scores than other methods. We do a head-to-head comparison of\nIDOLpro against a classic virtual screen of a large database of drug-like\nmolecules. We show that IDOLpro can generate molecules for a range of important\ndisease-related targets with better binding affinity and synthetic\naccessibility than any molecule found in the virtual screen while being over\n100x faster and less expensive to run. On a test set of experimental complexes,\nIDOLpro is the first to produce molecules with better binding affinities than\nexperimentally observed ligands. IDOLpro can accommodate other scoring\nfunctions (e.g. ADME-Tox) to accelerate hit-finding, hit-to-lead, and lead\noptimization for drug discovery.\n","authors":["Amit Kadan","Kevin Ryczko","Erika Lloyd","Adrian Roitberg","Takeshi Yamazaki"],"pdf_url":"https://arxiv.org/pdf/2405.11785v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2310.19300v2","updated":"2024-10-17T16:59:19Z","published":"2023-10-30T06:35:31Z","title":"Stage-Aware Learning for Dynamic Treatments","summary":"  Recent advances in dynamic treatment regimes (DTRs) facilitate the search for\noptimal treatments, which are tailored to individuals' specific needs and able\nto maximize their expected clinical benefits. However, existing algorithms\nrelying on consistent trajectories, such as inverse probability weighting\nestimators (IPWEs), could suffer from insufficient sample size under optimal\ntreatments and a growing number of decision-making stages, particularly in the\ncontext of chronic diseases. To address these challenges, we propose a novel\nindividualized learning method which estimates the DTR with a focus on\nprioritizing alignment between the observed treatment trajectory and the one\nobtained by the optimal regime across decision stages. By relaxing the\nrestriction that the observed trajectory must be fully aligned with the optimal\ntreatments, our approach substantially improves the sample efficiency and\nstability of IPWE-based methods. In particular, the proposed learning scheme\nbuilds a more general framework which includes the popular outcome weighted\nlearning framework as a special case of ours. Moreover, we introduce the notion\nof stage importance scores along with an attention mechanism to explicitly\naccount for heterogeneity among decision stages. We establish the theoretical\nproperties of the proposed approach, including the Fisher consistency and\nfinite-sample performance bound. Empirically, we evaluate the proposed method\nin extensive simulated environments and a real case study for the COVID-19\npandemic.\n","authors":["Hanwen Ye","Wenzhuo Zhou","Ruoqing Zhu","Annie Qu"],"pdf_url":"https://arxiv.org/pdf/2310.19300v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.13762v1","updated":"2024-10-17T16:56:04Z","published":"2024-10-17T16:56:04Z","title":"Virtual Sensing for Real-Time Degradation Monitoring of Nuclear Systems:\n  Leveraging DeepONet for Enhanced Sensing Coverage for Digital Twin-Enabling\n  Technology","summary":"  Effective real-time monitoring technique is crucial for detecting material\ndegradation and maintaining the structural integrity of nuclear systems to\nensure both safety and operational efficiency. Traditional physical sensor\nsystems face limitations such as installation challenges, high costs, and\ndifficulties in measuring critical parameters in hard-to-reach or harsh\nenvironments, often resulting in incomplete data coverage. Machine\nlearning-driven virtual sensors offer a promising solution by enhancing\nphysical sensor capabilities to monitor critical degradation indicators like\npressure, velocity, and turbulence. However, conventional machine learning\nmodels struggle with real-time monitoring due to the high-dimensional nature of\nreactor data and the need for frequent retraining. This paper explores the use\nof Deep Operator Networks (DeepONet) within a digital twin (DT) framework to\npredict key thermal-hydraulic parameters in the hot leg of an AP-1000\nPressurized Water Reactor (PWR). In this study, DeepONet is trained with\ndifferent operational conditions, which relaxes the requirement of continuous\nretraining, making it suitable for online and real-time prediction components\nfor DT. Our results show that DeepONet achieves accurate predictions with low\nmean squared error and relative L2 error and can make predictions on unknown\ndata 160,000 times faster than traditional finite element (FE) simulations.\nThis speed and accuracy make DeepONet a powerful tool for tracking conditions\nthat contribute to material degradation in real-time, enhancing reactor safety\nand longevity.\n","authors":["Raisa Bentay Hossain","Farid Ahmed","Kazuma Kobayashi","Seid Koric","Diab Abueidda","Syed Bahauddin Alam"],"pdf_url":"https://arxiv.org/pdf/2410.13762v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.13761v1","updated":"2024-10-17T16:56:01Z","published":"2024-10-17T16:56:01Z","title":"GDeR: Safeguarding Efficiency, Balancing, and Robustness via\n  Prototypical Graph Pruning","summary":"  Training high-quality deep models necessitates vast amounts of data,\nresulting in overwhelming computational and memory demands. Recently, data\npruning, distillation, and coreset selection have been developed to streamline\ndata volume by retaining, synthesizing, or selecting a small yet informative\nsubset from the full set. Among these methods, data pruning incurs the least\nadditional training cost and offers the most practical acceleration benefits.\nHowever, it is the most vulnerable, often suffering significant performance\ndegradation with imbalanced or biased data schema, thus raising concerns about\nits accuracy and reliability in on-device deployment. Therefore, there is a\nlooming need for a new data pruning paradigm that maintains the efficiency of\nprevious practices while ensuring balance and robustness. Unlike the fields of\ncomputer vision and natural language processing, where mature solutions have\nbeen developed to address these issues, graph neural networks (GNNs) continue\nto struggle with increasingly large-scale, imbalanced, and noisy datasets,\nlacking a unified dataset pruning solution. To achieve this, we introduce a\nnovel dynamic soft-pruning method, GDeR, designed to update the training\n``basket'' during the process using trainable prototypes. GDeR first constructs\na well-modeled graph embedding hypersphere and then samples\n\\textit{representative, balanced, and unbiased subsets} from this embedding\nspace, which achieves the goal we called Graph Training Debugging. Extensive\nexperiments on five datasets across three GNN backbones, demonstrate that GDeR\n(I) achieves or surpasses the performance of the full dataset with 30%~50%\nfewer training samples, (II) attains up to a 2.81x lossless training speedup,\nand (III) outperforms state-of-the-art pruning methods in imbalanced training\nand noisy training scenarios by 0.3%~4.3% and 3.6%~7.8%, respectively.\n","authors":["Guibin Zhang","Haonan Dong","Yuchen Zhang","Zhixun Li","Dingshuo Chen","Kai Wang","Tianlong Chen","Yuxuan Liang","Dawei Cheng","Kun Wang"],"pdf_url":"https://arxiv.org/pdf/2410.13761v1.pdf","comment":"NeurIPS 2024"},{"id":"http://arxiv.org/abs/2410.13756v1","updated":"2024-10-17T16:53:43Z","published":"2024-10-17T16:53:43Z","title":"CLIMB: Language-Guided Continual Learning for Task Planning with\n  Iterative Model Building","summary":"  Intelligent and reliable task planning is a core capability for generalized\nrobotics, requiring a descriptive domain representation that sufficiently\nmodels all object and state information for the scene. We present CLIMB, a\ncontinual learning framework for robot task planning that leverages foundation\nmodels and execution feedback to guide domain model construction. CLIMB can\nbuild a model from a natural language description, learn non-obvious predicates\nwhile solving tasks, and store that information for future problems. We\ndemonstrate the ability of CLIMB to improve performance in common planning\nenvironments compared to baseline methods. We also develop the BlocksWorld++\ndomain, a simulated environment with an easily usable real counterpart,\ntogether with a curriculum of tasks with progressing difficulty for evaluating\ncontinual learning. Additional details and demonstrations for this system can\nbe found at https://plan-with-climb.github.io/ .\n","authors":["Walker Byrnes","Miroslav Bogdanovic","Avi Balakirsky","Stephen Balakirsky","Animesh Garg"],"pdf_url":"https://arxiv.org/pdf/2410.13756v1.pdf","comment":"6 pages, 6 figures"},{"id":"http://arxiv.org/abs/2410.13754v1","updated":"2024-10-17T16:52:28Z","published":"2024-10-17T16:52:28Z","title":"MixEval-X: Any-to-Any Evaluations from Real-World Data Mixtures","summary":"  Perceiving and generating diverse modalities are crucial for AI models to\neffectively learn from and engage with real-world signals, necessitating\nreliable evaluations for their development. We identify two major issues in\ncurrent evaluations: (1) inconsistent standards, shaped by different\ncommunities with varying protocols and maturity levels; and (2) significant\nquery, grading, and generalization biases. To address these, we introduce\nMixEval-X, the first any-to-any real-world benchmark designed to optimize and\nstandardize evaluations across input and output modalities. We propose\nmulti-modal benchmark mixture and adaptation-rectification pipelines to\nreconstruct real-world task distributions, ensuring evaluations generalize\neffectively to real-world use cases. Extensive meta-evaluations show our\napproach effectively aligns benchmark samples with real-world task\ndistributions and the model rankings correlate strongly with that of\ncrowd-sourced real-world evaluations (up to 0.98). We provide comprehensive\nleaderboards to rerank existing models and organizations and offer insights to\nenhance understanding of multi-modal evaluations and inform future research.\n","authors":["Jinjie Ni","Yifan Song","Deepanway Ghosal","Bo Li","David Junhao Zhang","Xiang Yue","Fuzhao Xue","Zian Zheng","Kaichen Zhang","Mahir Shah","Kabir Jain","Yang You","Michael Shieh"],"pdf_url":"https://arxiv.org/pdf/2410.13754v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.13749v1","updated":"2024-10-17T16:48:51Z","published":"2024-10-17T16:48:51Z","title":"Supervised Kernel Thinning","summary":"  The kernel thinning algorithm of Dwivedi & Mackey (2024) provides a\nbetter-than-i.i.d. compression of a generic set of points. By generating\nhigh-fidelity coresets of size significantly smaller than the input points, KT\nis known to speed up unsupervised tasks like Monte Carlo integration,\nuncertainty quantification, and non-parametric hypothesis testing, with minimal\nloss in statistical accuracy. In this work, we generalize the KT algorithm to\nspeed up supervised learning problems involving kernel methods. Specifically,\nwe combine two classical algorithms--Nadaraya-Watson (NW) regression or kernel\nsmoothing, and kernel ridge regression (KRR)--with KT to provide a quadratic\nspeed-up in both training and inference times. We show how distribution\ncompression with KT in each setting reduces to constructing an appropriate\nkernel, and introduce the Kernel-Thinned NW and Kernel-Thinned KRR estimators.\nWe prove that KT-based regression estimators enjoy significantly superior\ncomputational efficiency over the full-data estimators and improved statistical\nefficiency over i.i.d. subsampling of the training data. En route, we also\nprovide a novel multiplicative error guarantee for compressing with KT. We\nvalidate our design choices with both simulations and real data experiments.\n","authors":["Albert Gong","Kyuseong Choi","Raaz Dwivedi"],"pdf_url":"https://arxiv.org/pdf/2410.13749v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2402.14015v2","updated":"2024-10-17T16:47:51Z","published":"2024-02-21T18:54:37Z","title":"Corrective Machine Unlearning","summary":"  Machine Learning models increasingly face data integrity challenges due to\nthe use of large-scale training datasets drawn from the Internet. We study what\nmodel developers can do if they detect that some data was manipulated or\nincorrect. Such manipulated data can cause adverse effects including\nvulnerability to backdoored samples, systemic biases, and reduced accuracy on\ncertain input domains. Realistically, all manipulated training samples cannot\nbe identified, and only a small, representative subset of the affected data can\nbe flagged.\n  We formalize Corrective Machine Unlearning as the problem of mitigating the\nimpact of data affected by unknown manipulations on a trained model, only\nhaving identified a subset of the corrupted data. We demonstrate that the\nproblem of corrective unlearning has significantly different requirements from\ntraditional privacy-oriented unlearning. We find most existing unlearning\nmethods, including retraining-from-scratch without the deletion set, require\nmost of the manipulated data to be identified for effective corrective\nunlearning. However, one approach, Selective Synaptic Dampening, achieves\nlimited success, unlearning adverse effects with just a small portion of the\nmanipulated samples in our setting, which shows encouraging signs for future\nprogress. We hope our work spurs research towards developing better methods for\ncorrective unlearning and offers practitioners a new strategy to handle data\nintegrity challenges arising from web-scale training. Code is available at\nhttps://github.com/drimpossible/corrective-unlearning-bench.\n","authors":["Shashwat Goel","Ameya Prabhu","Philip Torr","Ponnurangam Kumaraguru","Amartya Sanyal"],"pdf_url":"https://arxiv.org/pdf/2402.14015v2.pdf","comment":"Published in Transactions of Machine Learning Research (TMLR), 17\n  pages, 7 figures"},{"id":"http://arxiv.org/abs/2410.01024v2","updated":"2024-10-17T16:45:16Z","published":"2024-10-01T19:33:39Z","title":"GPTreeO: An R package for continual regression with dividing local\n  Gaussian processes","summary":"  We introduce GPTreeO, a flexible R package for scalable Gaussian process (GP)\nregression, particularly tailored to continual learning problems. GPTreeO\nbuilds upon the Dividing Local Gaussian Processes (DLGP) algorithm, in which a\nbinary tree of local GP regressors is dynamically constructed using a continual\nstream of input data. In GPTreeO we extend the original DLGP algorithm by\nallowing continual optimisation of the GP hyperparameters, incorporating\nuncertainty calibration, and introducing new strategies for how the local\npartitions are created. Moreover, the modular code structure allows users to\ninterface their favourite GP library to perform the local GP regression in\nGPTreeO. The flexibility of GPTreeO gives the user fine-grained control of the\nbalance between computational speed, accuracy, stability and smoothness. We\nconduct a sensitivity analysis to show how GPTreeO's configurable features\nimpact the regression performance in a continual learning setting.\n","authors":["Timo Braun","Anders Kvellestad","Riccardo De Bin"],"pdf_url":"https://arxiv.org/pdf/2410.01024v2.pdf","comment":"Updated the bibliography, and is now equivalent to the journal\n  submission"},{"id":"http://arxiv.org/abs/2410.13746v1","updated":"2024-10-17T16:42:12Z","published":"2024-10-17T16:42:12Z","title":"Theory on Score-Mismatched Diffusion Models and Zero-Shot Conditional\n  Samplers","summary":"  The denoising diffusion model has recently emerged as a powerful generative\ntechnique, capable of transforming noise into meaningful data. While\ntheoretical convergence guarantees for diffusion models are well established\nwhen the target distribution aligns with the training distribution, practical\nscenarios often present mismatches. One common case is in zero-shot conditional\ndiffusion sampling, where the target conditional distribution is different from\nthe (unconditional) training distribution. These score-mismatched diffusion\nmodels remain largely unexplored from a theoretical perspective. In this paper,\nwe present the first performance guarantee with explicit dimensional\ndependencies for general score-mismatched diffusion samplers, focusing on\ntarget distributions with finite second moments. We show that score mismatches\nresult in an asymptotic distributional bias between the target and sampling\ndistributions, proportional to the accumulated mismatch between the target and\ntraining distributions. This result can be directly applied to zero-shot\nconditional samplers for any conditional model, irrespective of measurement\nnoise. Interestingly, the derived convergence upper bound offers useful\nguidance for designing a novel bias-optimal zero-shot sampler in linear\nconditional models that minimizes the asymptotic bias. For such bias-optimal\nsamplers, we further establish convergence guarantees with explicit\ndependencies on dimension and conditioning, applied to several interesting\ntarget distributions, including those with bounded support and Gaussian\nmixtures. Our findings are supported by numerical studies.\n","authors":["Yuchen Liang","Peizhong Ju","Yingbin Liang","Ness Shroff"],"pdf_url":"https://arxiv.org/pdf/2410.13746v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.13743v1","updated":"2024-10-17T16:39:53Z","published":"2024-10-17T16:39:53Z","title":"Single-Timescale Multi-Sequence Stochastic Approximation Without Fixed\n  Point Smoothness: Theories and Applications","summary":"  Stochastic approximation (SA) that involves multiple coupled sequences, known\nas multiple-sequence SA (MSSA), finds diverse applications in the fields of\nsignal processing and machine learning. However, existing theoretical\nunderstandings {of} MSSA are limited: the multi-timescale analysis implies a\nslow convergence rate, whereas the single-timescale analysis relies on a\nstringent fixed point smoothness assumption. This paper establishes tighter\nsingle-timescale analysis for MSSA, without assuming smoothness of the fixed\npoints. Our theoretical findings reveal that, when all involved operators are\nstrongly monotone, MSSA converges at a rate of $\\tilde{\\mathcal{O}}(K^{-1})$,\nwhere $K$ denotes the total number of iterations. In addition, when all\ninvolved operators are strongly monotone except for the main one, MSSA\nconverges at a rate of $\\mathcal{O}(K^{-\\frac{1}{2}})$. These theoretical\nfindings align with those established for single-sequence SA. Applying these\ntheoretical findings to bilevel optimization and communication-efficient\ndistributed learning offers relaxed assumptions and/or simpler algorithms with\nperformance guarantees, as validated by numerical experiments.\n","authors":["Yue Huang","Zhaoxian Wu","Shiqian Ma","Qing Ling"],"pdf_url":"https://arxiv.org/pdf/2410.13743v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.13738v1","updated":"2024-10-17T16:37:33Z","published":"2024-10-17T16:37:33Z","title":"Improved Convergence Rate for Diffusion Probabilistic Models","summary":"  Score-based diffusion models have achieved remarkable empirical performance\nin the field of machine learning and artificial intelligence for their ability\nto generate high-quality new data instances from complex distributions.\nImproving our understanding of diffusion models, including mainly convergence\nanalysis for such models, has attracted a lot of interests. Despite a lot of\ntheoretical attempts, there still exists significant gap between theory and\npractice. Towards to close this gap, we establish an iteration complexity at\nthe order of $d^{1/3}\\varepsilon^{-2/3}$, which is better than\n$d^{5/12}\\varepsilon^{-1}$, the best known complexity achieved before our work.\nThis convergence analysis is based on a randomized midpoint method, which is\nfirst proposed for log-concave sampling (Shen and Lee, 2019), and then extended\nto diffusion models by Gupta et al. (2024). Our theory accommodates\n$\\varepsilon$-accurate score estimates, and does not require log-concavity on\nthe target distribution. Moreover, the algorithm can also be parallelized to\nrun in only $O(\\log^2(d/\\varepsilon))$ parallel rounds in a similar way to\nprior works.\n","authors":["Gen Li","Yuchen Jiao"],"pdf_url":"https://arxiv.org/pdf/2410.13738v1.pdf","comment":"20 pages"},{"id":"http://arxiv.org/abs/2410.13735v1","updated":"2024-10-17T16:37:03Z","published":"2024-10-17T16:37:03Z","title":"Optimizing Probabilistic Conformal Prediction with Vectorized\n  Non-Conformity Scores","summary":"  Generative models have shown significant promise in critical domains such as\nmedical diagnosis, autonomous driving, and climate science, where reliable\ndecision-making hinges on accurate uncertainty quantification. While\nprobabilistic conformal prediction (PCP) offers a powerful framework for this\npurpose, its coverage efficiency -- the size of the uncertainty set -- is\nlimited when dealing with complex underlying distributions and a finite number\nof generated samples. In this paper, we propose a novel PCP framework that\nenhances efficiency by first vectorizing the non-conformity scores with ranked\nsamples and then optimizing the shape of the prediction set by varying the\nquantiles for samples at the same rank. Our method delivers valid coverage\nwhile producing discontinuous and more efficient prediction sets, making it\nparticularly suited for high-stakes applications. We demonstrate the\neffectiveness of our approach through experiments on both synthetic and\nreal-world datasets.\n","authors":["Minxing Zheng","Shixiang Zhu"],"pdf_url":"https://arxiv.org/pdf/2410.13735v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.13732v1","updated":"2024-10-17T16:36:14Z","published":"2024-10-17T16:36:14Z","title":"Reducing the Transformer Architecture to a Minimum","summary":"  Transformers are a widespread and successful model architecture, particularly\nin Natural Language Processing (NLP) and Computer Vision (CV). The essential\ninnovation of this architecture is the Attention Mechanism, which solves the\nproblem of extracting relevant context information from long sequences in NLP\nand realistic scenes in CV. A classical neural network component, a Multi-Layer\nPerceptron (MLP), complements the attention mechanism. Its necessity is\nfrequently justified by its capability of modeling nonlinear relationships.\nHowever, the attention mechanism itself is nonlinear through its internal use\nof similarity measures. A possible hypothesis is that this nonlinearity is\nsufficient for modeling typical application problems. As the MLPs usually\ncontain the most trainable parameters of the whole model, their omission would\nsubstantially reduce the parameter set size. Further components can also be\nreorganized to reduce the number of parameters. Under some conditions, query\nand key matrices can be collapsed into a single matrix of the same size. The\nsame is true about value and projection matrices, which can also be omitted\nwithout eliminating the substance of the attention mechanism. Initially, the\nsimilarity measure was defined asymmetrically, with peculiar properties such as\nthat a token is possibly dissimilar to itself. A possible symmetric definition\nrequires only half of the parameters. We have laid the groundwork by testing\nwidespread CV benchmarks: MNIST and CIFAR-10. The tests have shown that\nsimplified transformer architectures (a) without MLP, (b) with collapsed\nmatrices, and (c) symmetric similarity matrices exhibit similar performance as\nthe original architecture, saving up to 90% of parameters without hurting the\nclassification performance.\n","authors":["Bernhard Bermeitinger","Tomas Hrycej","Massimo Pavone","Julianus Kath","Siegfried Handschuh"],"pdf_url":"https://arxiv.org/pdf/2410.13732v1.pdf","comment":"8 pages, to appear in KDIR2024"},{"id":"http://arxiv.org/abs/2403.08854v2","updated":"2024-10-17T16:23:42Z","published":"2024-03-13T18:00:01Z","title":"Moments of Clarity: Streamlining Latent Spaces in Machine Learning using\n  Moment Pooling","summary":"  Many machine learning applications involve learning a latent representation\nof data, which is often high-dimensional and difficult to directly interpret.\nIn this work, we propose \"Moment Pooling\", a natural extension of Deep Sets\nnetworks which drastically decrease latent space dimensionality of these\nnetworks while maintaining or even improving performance. Moment Pooling\ngeneralizes the summation in Deep Sets to arbitrary multivariate moments, which\nenables the model to achieve a much higher effective latent dimensionality for\na fixed latent dimension. We demonstrate Moment Pooling on the collider physics\ntask of quark/gluon jet classification by extending Energy Flow Networks (EFNs)\nto Moment EFNs. We find that Moment EFNs with latent dimensions as small as 1\nperform similarly to ordinary EFNs with higher latent dimension. This small\nlatent dimension allows for the internal representation to be directly\nvisualized and interpreted, which in turn enables the learned internal jet\nrepresentation to be extracted in closed form.\n","authors":["Rikab Gambhir","Athis Osathapan","Jesse Thaler"],"pdf_url":"https://arxiv.org/pdf/2403.08854v2.pdf","comment":"15+7 pages, 14 figures, 7 tables. Code available at\n  https://github.com/athiso/moment and https://github.com/rikab/MomentAnalysis;\n  v2: Updated to match journal version"},{"id":"http://arxiv.org/abs/2402.14877v2","updated":"2024-10-17T16:22:48Z","published":"2024-02-21T20:59:19Z","title":"Machine-learning prediction of tipping with applications to the Atlantic\n  Meridional Overturning Circulation","summary":"  Anticipating a tipping point, a transition from one stable steady state to\nanother, is a problem of broad relevance due to the ubiquity of the phenomenon\nin diverse fields. The steady-state nature of the dynamics about a tipping\npoint makes its prediction significantly more challenging than predicting other\ntypes of critical transitions from oscillatory or chaotic dynamics. Exploiting\nthe benefits of noise, we develop a general data-driven and machine-learning\napproach to predicting potential future tipping in nonautonomous dynamical\nsystems and validate the framework using examples from different fields. As an\napplication, we address the problem of predicting the potential collapse of the\nAtlantic Meridional Overturning Circulation (AMOC), possibly driven by\nclimate-induced changes in the freshwater input to the North Atlantic. Our\npredictions based on synthetic and currently available empirical data place a\npotential collapse window spanning from 2040 to 2065, in consistency with the\nresults in the current literature.\n","authors":["Shirin Panahi","Ling-Wei Kong","Mohammadamin Moradi","Zheng-Meng Zhai","Bryan Glaz","Mulugeta Haile","Ying-Cheng Lai"],"pdf_url":"https://arxiv.org/pdf/2402.14877v2.pdf","comment":"11 pages, 7 figures"},{"id":"http://arxiv.org/abs/2410.13720v1","updated":"2024-10-17T16:22:46Z","published":"2024-10-17T16:22:46Z","title":"Movie Gen: A Cast of Media Foundation Models","summary":"  We present Movie Gen, a cast of foundation models that generates\nhigh-quality, 1080p HD videos with different aspect ratios and synchronized\naudio. We also show additional capabilities such as precise instruction-based\nvideo editing and generation of personalized videos based on a user's image.\nOur models set a new state-of-the-art on multiple tasks: text-to-video\nsynthesis, video personalization, video editing, video-to-audio generation, and\ntext-to-audio generation. Our largest video generation model is a 30B parameter\ntransformer trained with a maximum context length of 73K video tokens,\ncorresponding to a generated video of 16 seconds at 16 frames-per-second. We\nshow multiple technical innovations and simplifications on the architecture,\nlatent spaces, training objectives and recipes, data curation, evaluation\nprotocols, parallelization techniques, and inference optimizations that allow\nus to reap the benefits of scaling pre-training data, model size, and training\ncompute for training large scale media generation models. We hope this paper\nhelps the research community to accelerate progress and innovation in media\ngeneration models. All videos from this paper are available at\nhttps://go.fb.me/MovieGenResearchVideos.\n","authors":["Adam Polyak","Amit Zohar","Andrew Brown","Andros Tjandra","Animesh Sinha","Ann Lee","Apoorv Vyas","Bowen Shi","Chih-Yao Ma","Ching-Yao Chuang","David Yan","Dhruv Choudhary","Dingkang Wang","Geet Sethi","Guan Pang","Haoyu Ma","Ishan Misra","Ji Hou","Jialiang Wang","Kiran Jagadeesh","Kunpeng Li","Luxin Zhang","Mannat Singh","Mary Williamson","Matt Le","Matthew Yu","Mitesh Kumar Singh","Peizhao Zhang","Peter Vajda","Quentin Duval","Rohit Girdhar","Roshan Sumbaly","Sai Saketh Rambhatla","Sam Tsai","Samaneh Azadi","Samyak Datta","Sanyuan Chen","Sean Bell","Sharadh Ramaswamy","Shelly Sheynin","Siddharth Bhattacharya","Simran Motwani","Tao Xu","Tianhe Li","Tingbo Hou","Wei-Ning Hsu","Xi Yin","Xiaoliang Dai","Yaniv Taigman","Yaqiao Luo","Yen-Cheng Liu","Yi-Chiao Wu","Yue Zhao","Yuval Kirstain","Zecheng He","Zijian He","Albert Pumarola","Ali Thabet","Artsiom Sanakoyeu","Arun Mallya","Baishan Guo","Boris Araya","Breena Kerr","Carleigh Wood","Ce Liu","Cen Peng","Dimitry Vengertsev","Edgar Schonfeld","Elliot Blanchard","Felix Juefei-Xu","Fraylie Nord","Jeff Liang","John Hoffman","Jonas Kohler","Kaolin Fire","Karthik Sivakumar","Lawrence Chen","Licheng Yu","Luya Gao","Markos Georgopoulos","Rashel Moritz","Sara K. Sampson","Shikai Li","Simone Parmeggiani","Steve Fine","Tara Fowler","Vladan Petrovic","Yuming Du"],"pdf_url":"https://arxiv.org/pdf/2410.13720v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.13714v1","updated":"2024-10-17T16:14:49Z","published":"2024-10-17T16:14:49Z","title":"Generation through the lens of learning theory","summary":"  We study generation through the lens of statistical learning theory. First,\nwe abstract and formalize the results of Gold [1967], Angluin [1979, 1980], and\nKleinberg and Mullainathan [2024] for language identification/generation in the\nlimit in terms of a binary hypothesis class defined over an abstract instance\nspace. Then, we formalize a different paradigm of generation studied by\nKleinberg and Mullainathan [2024], which we call ``uniform generation,\" and\nprovide a characterization of which hypothesis classes are uniformly\ngeneratable. As is standard in statistical learning theory, our\ncharacterization is in terms of the finiteness of a new combinatorial dimension\nwe call the Closure dimension. By doing so, we are able to compare\ngeneratability with predictability (captured via PAC and online learnability)\nand show that these two properties of hypothesis classes are\n\\emph{incompatible} - there are classes that are generatable but not\npredictable and vice versa.\n","authors":["Vinod Raman","Ambuj Tewari"],"pdf_url":"https://arxiv.org/pdf/2410.13714v1.pdf","comment":"16 pages"},{"id":"http://arxiv.org/abs/2410.13713v1","updated":"2024-10-17T16:12:55Z","published":"2024-10-17T16:12:55Z","title":"CrystalX: Ultra-Precision Crystal Structure Resolution and Error\n  Correction Using Deep Learning","summary":"  Atomic structure analysis of crystalline materials is a paramount endeavor in\nboth chemical and material sciences. This sophisticated technique necessitates\nnot only a solid foundation in crystallography but also a profound\ncomprehension of the intricacies of the accompanying software, posing a\nsignificant challenge in meeting the rigorous daily demands. For the first\ntime, we confront this challenge head-on by harnessing the power of deep\nlearning for ultra-precise structural analysis at the full-atom level. To\nvalidate the performance of the model, named CrystalX, we employed a vast\ndataset comprising over 50,000 X-ray diffraction measurements derived from\nauthentic experiments, demonstrating performance that is commensurate with\nhuman experts and adept at deciphering intricate geometric patterns.\nRemarkably, CrystalX revealed that even peer-reviewed publications can harbor\nerrors that are stealthy to human scrutiny, yet CrystalX adeptly rectifies\nthem. This deep learning model revolutionizes the time frame for crystal\nstructure analysis, slashing it down to seconds. It has already been\nsuccessfully applied in the structure analysis of newly discovered compounds in\nthe latest research without human intervention. Overall, CrystalX marks the\nbeginning of a new era in automating routine structural analysis within\nself-driving laboratories.\n","authors":["Kaipeng Zheng","Weiran Huang","Wanli Ouyang","Han-Sen Zhong","Yuqiang Li"],"pdf_url":"https://arxiv.org/pdf/2410.13713v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.13709v1","updated":"2024-10-17T16:09:32Z","published":"2024-10-17T16:09:32Z","title":"On-device Federated Learning in Smartphones for Detecting Depression\n  from Reddit Posts","summary":"  Depression detection using deep learning models has been widely explored in\nprevious studies, especially due to the large amounts of data available from\nsocial media posts. These posts provide valuable information about individuals'\nmental health conditions and can be leveraged to train models and identify\npatterns in the data. However, distributed learning approaches have not been\nextensively explored in this domain. In this study, we adopt Federated Learning\n(FL) to facilitate decentralized training on smartphones while protecting user\ndata privacy. We train three neural network architectures--GRU, RNN, and LSTM\non Reddit posts to detect signs of depression and evaluate their performance\nunder heterogeneous FL settings. To optimize the training process, we leverage\na common tokenizer across all client devices, which reduces the computational\nload. Additionally, we analyze resource consumption and communication costs on\nsmartphones to assess their impact in a real-world FL environment. Our\nexperimental results demonstrate that the federated models achieve comparable\nperformance to the centralized models. This study highlights the potential of\nFL for decentralized mental health prediction by providing a secure and\nefficient model training process on edge devices.\n","authors":["Mustofa Ahmed","Abdul Muntakim","Nawrin Tabassum","Mohammad Asifur Rahim","Faisal Muhammad Shah"],"pdf_url":"https://arxiv.org/pdf/2410.13709v1.pdf","comment":"11 pages, 7 figures, Submitted to IEEE"},{"id":"http://arxiv.org/abs/2410.13708v1","updated":"2024-10-17T16:08:06Z","published":"2024-10-17T16:08:06Z","title":"On the Role of Attention Heads in Large Language Model Safety","summary":"  Large language models (LLMs) achieve state-of-the-art performance on multiple\nlanguage tasks, yet their safety guardrails can be circumvented, leading to\nharmful generations. In light of this, recent research on safety mechanisms has\nemerged, revealing that when safety representations or component are\nsuppressed, the safety capability of LLMs are compromised. However, existing\nresearch tends to overlook the safety impact of multi-head attention\nmechanisms, despite their crucial role in various model functionalities. Hence,\nin this paper, we aim to explore the connection between standard attention\nmechanisms and safety capability to fill this gap in the safety-related\nmechanistic interpretability. We propose a novel metric which tailored for\nmulti-head attention, the Safety Head ImPortant Score (Ships), to assess the\nindividual heads' contributions to model safety. Based on this, we generalize\nShips to the dataset level and further introduce the Safety Attention Head\nAttRibution Algorithm (Sahara) to attribute the critical safety attention heads\ninside the model. Our findings show that the special attention head has a\nsignificant impact on safety. Ablating a single safety head allows aligned\nmodel (e.g., Llama-2-7b-chat) to respond to 16 times more harmful queries,\nwhile only modifying 0.006% of the parameters, in contrast to the ~ 5%\nmodification required in previous studies. More importantly, we demonstrate\nthat attention heads primarily function as feature extractors for safety and\nmodels fine-tuned from the same base model exhibit overlapping safety heads\nthrough comprehensive experiments. Together, our attribution approach and\nfindings provide a novel perspective for unpacking the black box of safety\nmechanisms within large models.\n","authors":["Zhenhong Zhou","Haiyang Yu","Xinghua Zhang","Rongwu Xu","Fei Huang","Kun Wang","Yang Liu","Junfeng Fang","Yongbin Li"],"pdf_url":"https://arxiv.org/pdf/2410.13708v1.pdf","comment":"28 pages, 18 figures, 7 tables"},{"id":"http://arxiv.org/abs/2406.10322v2","updated":"2024-10-17T16:06:18Z","published":"2024-06-14T17:41:55Z","title":"LieRE: Generalizing Rotary Position Encodings","summary":"  While Rotary Position Embeddings (RoPE) for large language models have become\nwidely adopted, their application for other modalities has been slower. Here,\nwe introduce Lie group Relative position Encodings (LieRE) that goes beyond\nRoPE in supporting n-dimensional inputs. We evaluate the performance of LieRE\non 2D and 3D image classification tasks and observe that LieRE leads to marked\nrelative improvements in performance (up to 9.7% for 2D and up to 25.5% for\n3D), training efficiency (3.5x reduction), data efficiency (30%) compared to\nthe baselines of DeiT III, RoPE-Mixed and Vision-Llama.\nhttps://github.com/Stanford-AIMI/LieRE\n","authors":["Sophie Ostmeier","Brian Axelrod","Michael E. Moseley","Akshay Chaudhari","Curtis Langlotz"],"pdf_url":"https://arxiv.org/pdf/2406.10322v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.13696v1","updated":"2024-10-17T16:03:43Z","published":"2024-10-17T16:03:43Z","title":"Efficient Function Placement in Virtual Networks: An Online Learning\n  Approach","summary":"  We propose a model for the virtual function placement problem and several\nnovel algorithms using ideas based on multi-armed bandits. We prove that these\nalgorithms learn the optimal placement policy rapidly, and their regret grows\nat a rate at most $O( N M \\sqrt{T\\ln T} )$ while respecting the feasibility\nconstraints with high probability. We show through numerical experiments that\nthose algorithms both have good practical performance and modest computational\ncomplexity. Using the proposed acceleration technique, they can be used to\nlearn in large networks where computational power is limited. Our experiments\nare fully reproducible, and the code is publicly available.\n","authors":["Wei Huang","Richard Combes","Hind Castel-Taleb","Badii Jouaber"],"pdf_url":"https://arxiv.org/pdf/2410.13696v1.pdf","comment":"19 pages"},{"id":"http://arxiv.org/abs/2406.16635v2","updated":"2024-10-17T15:45:10Z","published":"2024-06-24T13:41:08Z","title":"ShadowLLM: Predictor-based Contextual Sparsity for Large Language Models","summary":"  The high power consumption and latency-sensitive deployments of large\nlanguage models (LLMs) have motivated efficiency techniques like quantization\nand sparsity. Contextual sparsity, where the sparsity pattern is\ninput-dependent, is crucial in LLMs because the permanent removal of attention\nheads or neurons from LLMs can significantly degrade accuracy. Prior work has\nattempted to model contextual sparsity using neural networks trained to predict\nactivation magnitudes, which can be used to dynamically prune structures with\nlow predicted activation magnitude. In this paper, we look beyond\nmagnitude-based pruning criteria to assess attention head and neuron importance\nin LLMs. We develop a novel predictor called ShadowLLM, which can shadow the\nLLM behavior and enforce better sparsity patterns, resulting in over 15%\nimprovement in end-to-end accuracy compared to prior methods. In addition,\nShadowLLM achieves up to a 20% speed-up over the state-of-the-art DejaVu\nframework. These enhancements are validated on Llama-2 and OPT models with up\nto 30 billion parameters. Our code is available at\n\\href{https://github.com/abdelfattah-lab/shadow_llm/}{ShadowLLM}.\n","authors":["Yash Akhauri","Ahmed F AbouElhamayed","Jordan Dotzel","Zhiru Zhang","Alexander M Rush","Safeen Huda","Mohamed S Abdelfattah"],"pdf_url":"https://arxiv.org/pdf/2406.16635v2.pdf","comment":"Accepted to EMNLP 2024 (Main, Long Paper)"},{"id":"http://arxiv.org/abs/2402.13251v3","updated":"2024-10-17T15:45:06Z","published":"2024-02-20T18:59:00Z","title":"FlashTex: Fast Relightable Mesh Texturing with LightControlNet","summary":"  Manually creating textures for 3D meshes is time-consuming, even for expert\nvisual content creators. We propose a fast approach for automatically texturing\nan input 3D mesh based on a user-provided text prompt. Importantly, our\napproach disentangles lighting from surface material/reflectance in the\nresulting texture so that the mesh can be properly relit and rendered in any\nlighting environment. We introduce LightControlNet, a new text-to-image model\nbased on the ControlNet architecture, which allows the specification of the\ndesired lighting as a conditioning image to the model. Our text-to-texture\npipeline then constructs the texture in two stages. The first stage produces a\nsparse set of visually consistent reference views of the mesh using\nLightControlNet. The second stage applies a texture optimization based on Score\nDistillation Sampling (SDS) that works with LightControlNet to increase the\ntexture quality while disentangling surface material from lighting. Our\nalgorithm is significantly faster than previous text-to-texture methods, while\nproducing high-quality and relightable textures.\n","authors":["Kangle Deng","Timothy Omernick","Alexander Weiss","Deva Ramanan","Jun-Yan Zhu","Tinghui Zhou","Maneesh Agrawala"],"pdf_url":"https://arxiv.org/pdf/2402.13251v3.pdf","comment":"Project page: https://flashtex.github.io/"},{"id":"http://arxiv.org/abs/2410.13681v1","updated":"2024-10-17T15:41:06Z","published":"2024-10-17T15:41:06Z","title":"Ab initio nonparametric variable selection for scalable Symbolic\n  Regression with large $p$","summary":"  Symbolic regression (SR) is a powerful technique for discovering symbolic\nexpressions that characterize nonlinear relationships in data, gaining\nincreasing attention for its interpretability, compactness, and robustness.\nHowever, existing SR methods do not scale to datasets with a large number of\ninput variables (referred to as extreme-scale SR), which are common in modern\nscientific applications. This ``large $p$'' setting, often accompanied by\nmeasurement error, leads to slow performance of SR methods and overly complex\nexpressions that are difficult to interpret. To address this scalability\nchallenge, we propose a method called PAN+SR, which combines a key idea of ab\ninitio nonparametric variable selection with SR to efficiently pre-screen large\ninput spaces and reduce search complexity while maintaining accuracy. The use\nof nonparametric methods eliminates model misspecification, supporting a\nstrategy called parametric-assisted nonparametric (PAN). We also extend\nSRBench, an open-source benchmarking platform, by incorporating\nhigh-dimensional regression problems with various signal-to-noise ratios. Our\nresults demonstrate that PAN+SR consistently enhances the performance of 17\ncontemporary SR methods, enabling several to achieve state-of-the-art\nperformance on these challenging datasets.\n","authors":["Shengbin Ye","Meng Li"],"pdf_url":"https://arxiv.org/pdf/2410.13681v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2409.15355v4","updated":"2024-10-17T15:27:30Z","published":"2024-09-14T02:34:26Z","title":"Block-Attention for Efficient RAG","summary":"  We introduce Block-Attention, an attention mechanism designed to address the\nincreased inference latency and cost in Retrieval-Augmented Generation (RAG)\nscenarios. Traditional approaches often encode the entire context. Instead,\nBlock-Attention divides retrieved documents into discrete blocks, with each\nblock independently calculating key-value (KV) states except for the final\nblock. In RAG scenarios, by defining each passage as a block, Block-Attention\nenables us to reuse the KV states of passages that have been seen before,\nthereby significantly reducing the latency and the computation overhead during\ninference. The implementation of Block-Attention involves block segmentation,\nposition re-encoding, and fine-tuning the LLM to adapt to the Block-Attention\nmechanism. Experiments on four RAG benchmarks demonstrate that after block\nfine-tuning, the Block-Attention model achieves performance comparable to\nself-attention models (68.4\\% vs 67.9\\% on Llama3) or even superior performance\n(62.8\\% vs 59.6\\% on Mistral). Notably, Block-Attention significantly reduces\nthe time to first token (TTFT) and floating point operations (FLOPs) to a very\nlow level. It only takes 45 ms to output the first token for an input sequence\nwith a total length of 32K. Compared to the self-attention models, the time\nconsumption and corresponding FLOPs are reduced by 98.7\\% and 99.8\\%,\nrespectively.\n","authors":["East Sun","Yan Wang","Lan Tian"],"pdf_url":"https://arxiv.org/pdf/2409.15355v4.pdf","comment":null},{"id":"http://arxiv.org/abs/2404.00489v2","updated":"2024-10-17T15:20:23Z","published":"2024-03-30T23:07:58Z","title":"Prompt-SAW: Leveraging Relation-Aware Graphs for Textual Prompt\n  Compression","summary":"  Large Language Models (LLMs) have shown exceptional abilities for multiple\ndifferent natural language processing tasks. While prompting is a crucial tool\nfor LLM inference, we observe that there is a significant cost associated with\nexceedingly lengthy prompts. Existing attempts to compress lengthy prompts lead\nto substandard results in terms of readability/interpretability of the\ncompressed prompt, with a detrimental impact on prompt utility. To address\nthis, we propose PromptSAW: Prompt compresSion via Relation AWare graphs, an\neffective strategy for prompt compression over task-agnostic and task-aware\nprompts. Prompt-SAW uses the prompt's textual information to build a graph and\nlater extracts key information elements in the graph to come up with the\ncompressed prompt. We also propose GSM8K-aug, i.e., an extended version of the\nexisting GSM8K benchmark for task-agnostic prompts in order to provide a\ncomprehensive evaluation platform. Experimental evaluation using benchmark\ndatasets shows that prompts compressed by Prompt-SAW are not only better in\nterms of readability, but they also outperform the best-performing baseline\nmodels by up to 10.1 and 77.1, respectively, for task-agnostic and task-aware\nsettings while compressing the original prompt text by 34.9 and 56.7.\n","authors":["Muhammad Asif Ali","Zhengping Li","Shu Yang","Keyuan Cheng","Yang Cao","Tianhao Huang","Guimin Hu","Weimin Lyu","Lijie Hu","Lu Yu","Di Wang"],"pdf_url":"https://arxiv.org/pdf/2404.00489v2.pdf","comment":"16 pages"},{"id":"http://arxiv.org/abs/2410.12176v2","updated":"2024-10-17T15:18:31Z","published":"2024-10-16T02:44:36Z","title":"Expected Sliced Transport Plans","summary":"  The optimal transport (OT) problem has gained significant traction in modern\nmachine learning for its ability to: (1) provide versatile metrics, such as\nWasserstein distances and their variants, and (2) determine optimal couplings\nbetween probability measures. To reduce the computational complexity of OT\nsolvers, methods like entropic regularization and sliced optimal transport have\nbeen proposed. The sliced OT framework improves efficiency by comparing\none-dimensional projections (slices) of high-dimensional distributions.\nHowever, despite their computational efficiency, sliced-Wasserstein approaches\nlack a transportation plan between the input measures, limiting their use in\nscenarios requiring explicit coupling. In this paper, we address two key\nquestions: Can a transportation plan be constructed between two probability\nmeasures using the sliced transport framework? If so, can this plan be used to\ndefine a metric between the measures? We propose a \"lifting\" operation to\nextend one-dimensional optimal transport plans back to the original space of\nthe measures. By computing the expectation of these lifted plans, we derive a\nnew transportation plan, termed expected sliced transport (EST) plans. We prove\nthat using the EST plan to weight the sum of the individual Euclidean costs for\nmoving from one point to another results in a valid metric between the input\ndiscrete probability measures. We demonstrate the connection between our\napproach and the recently proposed min-SWGG, along with illustrative numerical\nexamples that support our theoretical findings.\n","authors":["Xinran Liu","Rocío Díaz Martín","Yikun Bai","Ashkan Shahbazi","Matthew Thorpe","Akram Aldroubi","Soheil Kolouri"],"pdf_url":"https://arxiv.org/pdf/2410.12176v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.13645v1","updated":"2024-10-17T15:12:55Z","published":"2024-10-17T15:12:55Z","title":"Automated Model Discovery for Tensional Homeostasis: Constitutive\n  Machine Learning in Growth and Remodeling","summary":"  Soft biological tissues exhibit a tendency to maintain a preferred state of\ntensile stress, known as tensional homeostasis, which is restored even after\nexternal mechanical stimuli. This macroscopic behavior can be described using\nthe theory of kinematic growth, where the deformation gradient is\nmultiplicatively decomposed into an elastic part and a part related to growth\nand remodeling. Recently, the concept of homeostatic surfaces was introduced to\ndefine the state of homeostasis and the evolution equations for inelastic\ndeformations.\n  However, identifying the optimal model and material parameters to accurately\ncapture the macroscopic behavior of inelastic materials can only be\naccomplished with significant expertise, is often time-consuming, and prone to\nerror, regardless of the specific inelastic phenomenon. To address this\nchallenge, built-in physics machine learning algorithms offer significant\npotential.\n  In this work, we extend our inelastic Constitutive Artificial Neural Networks\n(iCANNs) by incorporating kinematic growth and homeostatic surfaces to discover\nthe scalar model equations, namely the Helmholtz free energy and the pseudo\npotential. The latter describes the state of homeostasis in a smeared sense. We\nevaluate the ability of the proposed network to learn from experimentally\nobtained tissue equivalent data at the material point level, assess its\npredictive accuracy beyond the training regime, and discuss its current\nlimitations when applied at the structural level.\n  Our source code, data, examples, and an implementation of the corresponding\nmaterial subroutine are made accessible to the public at\nhttps://doi.org/10.5281/zenodo.13946282.\n","authors":["Hagen Holthusen","Tim Brepols","Kevin Linka","Ellen Kuhl"],"pdf_url":"https://arxiv.org/pdf/2410.13645v1.pdf","comment":"46 pages, 12 figures, 5 tables"},{"id":"http://arxiv.org/abs/2410.13643v1","updated":"2024-10-17T15:10:13Z","published":"2024-10-17T15:10:13Z","title":"Fine-Tuning Discrete Diffusion Models via Reward Optimization with\n  Applications to DNA and Protein Design","summary":"  Recent studies have demonstrated the strong empirical performance of\ndiffusion models on discrete sequences across domains from natural language to\nbiological sequence generation. For example, in the protein inverse folding\ntask, conditional diffusion models have achieved impressive results in\ngenerating natural-like sequences that fold back into the original structure.\nHowever, practical design tasks often require not only modeling a conditional\ndistribution but also optimizing specific task objectives. For instance, we may\nprefer protein sequences with high stability. To address this, we consider the\nscenario where we have pre-trained discrete diffusion models that can generate\nnatural-like sequences, as well as reward models that map sequences to task\nobjectives. We then formulate the reward maximization problem within discrete\ndiffusion models, analogous to reinforcement learning (RL), while minimizing\nthe KL divergence against pretrained diffusion models to preserve naturalness.\nTo solve this RL problem, we propose a novel algorithm, DRAKES, that enables\ndirect backpropagation of rewards through entire trajectories generated by\ndiffusion models, by making the originally non-differentiable trajectories\ndifferentiable using the Gumbel-Softmax trick. Our theoretical analysis\nindicates that our approach can generate sequences that are both natural-like\nand yield high rewards. While similar tasks have been recently explored in\ndiffusion models for continuous domains, our work addresses unique algorithmic\nand theoretical challenges specific to discrete diffusion models, which arise\nfrom their foundation in continuous-time Markov chains rather than Brownian\nmotion. Finally, we demonstrate the effectiveness of DRAKES in generating DNA\nand protein sequences that optimize enhancer activity and protein stability,\nrespectively, important tasks for gene therapies and protein-based\ntherapeutics.\n","authors":["Chenyu Wang","Masatoshi Uehara","Yichun He","Amy Wang","Tommaso Biancalani","Avantika Lal","Tommi Jaakkola","Sergey Levine","Hanchen Wang","Aviv Regev"],"pdf_url":"https://arxiv.org/pdf/2410.13643v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.13640v1","updated":"2024-10-17T15:09:24Z","published":"2024-10-17T15:09:24Z","title":"Latent Space Chain-of-Embedding Enables Output-free LLM Self-Evaluation","summary":"  LLM self-evaluation relies on the LLM's own ability to estimate response\ncorrectness, which can greatly improve its deployment reliability. In this\nresearch track, we propose the Chain-of-Embedding (CoE) in the latent space to\nenable LLMs to perform output-free self-evaluation. CoE consists of all\nprogressive hidden states produced during the inference time, which can be\ntreated as the latent thinking path of LLMs. We find that when LLMs respond\ncorrectly and incorrectly, their CoE features differ, these discrepancies\nassist us in estimating LLM response correctness. Experiments in four diverse\ndomains and seven LLMs fully demonstrate the effectiveness of our method.\nMeanwhile, its label-free design intent without any training and\nmillisecond-level computational cost ensure real-time feedback in large-scale\nscenarios. More importantly, we provide interesting insights into LLM response\ncorrectness from the perspective of hidden state changes inside LLMs.\n","authors":["Yiming Wang","Pei Zhang","Baosong Yang","Derek F. Wong","Rui Wang"],"pdf_url":"https://arxiv.org/pdf/2410.13640v1.pdf","comment":"33 pages, 18 figures, 12 tables"},{"id":"http://arxiv.org/abs/2410.13638v1","updated":"2024-10-17T15:08:21Z","published":"2024-10-17T15:08:21Z","title":"Scaling Wearable Foundation Models","summary":"  Wearable sensors have become ubiquitous thanks to a variety of health\ntracking features. The resulting continuous and longitudinal measurements from\neveryday life generate large volumes of data; however, making sense of these\nobservations for scientific and actionable insights is non-trivial. Inspired by\nthe empirical success of generative modeling, where large neural networks learn\npowerful representations from vast amounts of text, image, video, or audio\ndata, we investigate the scaling properties of sensor foundation models across\ncompute, data, and model size. Using a dataset of up to 40 million hours of\nin-situ heart rate, heart rate variability, electrodermal activity,\naccelerometer, skin temperature, and altimeter per-minute data from over\n165,000 people, we create LSM, a multimodal foundation model built on the\nlargest wearable-signals dataset with the most extensive range of sensor\nmodalities to date. Our results establish the scaling laws of LSM for tasks\nsuch as imputation, interpolation and extrapolation, both across time and\nsensor modalities. Moreover, we highlight how LSM enables sample-efficient\ndownstream learning for tasks like exercise and activity recognition.\n","authors":["Girish Narayanswamy","Xin Liu","Kumar Ayush","Yuzhe Yang","Xuhai Xu","Shun Liao","Jake Garrison","Shyam Tailor","Jake Sunshine","Yun Liu","Tim Althoff","Shrikanth Narayanan","Pushmeet Kohli","Jiening Zhan","Mark Malhotra","Shwetak Patel","Samy Abdel-Ghaffar","Daniel McDuff"],"pdf_url":"https://arxiv.org/pdf/2410.13638v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.13637v1","updated":"2024-10-17T15:07:56Z","published":"2024-10-17T15:07:56Z","title":"Normalizing self-supervised learning for provably reliable Change Point\n  Detection","summary":"  Change point detection (CPD) methods aim to identify abrupt shifts in the\ndistribution of input data streams. Accurate estimators for this task are\ncrucial across various real-world scenarios. Yet, traditional unsupervised CPD\ntechniques face significant limitations, often relying on strong assumptions or\nsuffering from low expressive power due to inherent model simplicity. In\ncontrast, representation learning methods overcome these drawbacks by offering\nflexibility and the ability to capture the full complexity of the data without\nimposing restrictive assumptions. However, these approaches are still emerging\nin the CPD field and lack robust theoretical foundations to ensure their\nreliability. Our work addresses this gap by integrating the expressive power of\nrepresentation learning with the groundedness of traditional CPD techniques. We\nadopt spectral normalization (SN) for deep representation learning in CPD tasks\nand prove that the embeddings after SN are highly informative for CPD. Our\nmethod significantly outperforms current state-of-the-art methods during the\ncomprehensive evaluation via three standard CPD datasets.\n","authors":["Alexandra Bazarova","Evgenia Romanenkova","Alexey Zaytsev"],"pdf_url":"https://arxiv.org/pdf/2410.13637v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.13611v1","updated":"2024-10-17T14:46:34Z","published":"2024-10-17T14:46:34Z","title":"H2OVL-Mississippi Vision Language Models Technical Report","summary":"  Smaller vision-language models (VLMs) are becoming increasingly important for\nprivacy-focused, on-device applications due to their ability to run efficiently\non consumer hardware for processing enterprise commercial documents and images.\nThese models require strong language understanding and visual capabilities to\nenhance human-machine interaction. To address this need, we present\nH2OVL-Mississippi, a pair of small VLMs trained on 37 million image-text pairs\nusing 240 hours of compute on 8 x H100 GPUs. H2OVL-Mississippi-0.8B is a tiny\nmodel with 0.8 billion parameters that specializes in text recognition,\nachieving state of the art performance on the Text Recognition portion of\nOCRBench and surpassing much larger models in this area. Additionally, we are\nreleasing H2OVL-Mississippi-2B, a 2 billion parameter model for general use\ncases, exhibiting highly competitive metrics across various academic\nbenchmarks. Both models build upon our prior work with H2O-Danube language\nmodels, extending their capabilities into the visual domain. We release them\nunder the Apache 2.0 license, making VLMs accessible to everyone, democratizing\ndocument AI and visual LLMs.\n","authors":["Shaikat Galib","Shanshan Wang","Guanshuo Xu","Pascal Pfeiffer","Ryan Chesler","Mark Landry","Sri Satish Ambati"],"pdf_url":"https://arxiv.org/pdf/2410.13611v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.13609v1","updated":"2024-10-17T14:45:56Z","published":"2024-10-17T14:45:56Z","title":"All models are wrong, some are useful: Model Selection with Limited\n  Labels","summary":"  With the multitude of pretrained models available thanks to the advancements\nin large-scale supervised and self-supervised learning, choosing the right\nmodel is becoming increasingly pivotal in the machine learning lifecycle.\nHowever, much like the training process, choosing the best pretrained\noff-the-shelf model for raw, unlabeled data is a labor-intensive task. To\novercome this, we introduce MODEL SELECTOR, a framework for label-efficient\nselection of pretrained classifiers. Given a pool of unlabeled target data,\nMODEL SELECTOR samples a small subset of highly informative examples for\nlabeling, in order to efficiently identify the best pretrained model for\ndeployment on this target dataset. Through extensive experiments, we\ndemonstrate that MODEL SELECTOR drastically reduces the need for labeled data\nwhile consistently picking the best or near-best performing model. Across 18\nmodel collections on 16 different datasets, comprising over 1,500 pretrained\nmodels, MODEL SELECTOR reduces the labeling cost by up to 94.15% to identify\nthe best model compared to the cost of the strongest baseline. Our results\nfurther highlight the robustness of MODEL SELECTOR in model selection, as it\nreduces the labeling cost by up to 72.41% when selecting a near-best model,\nwhose accuracy is only within 1% of the best model.\n","authors":["Patrik Okanovic","Andreas Kirsch","Jannes Kasper","Torsten Hoefler","Andreas Krause","Nezihe Merve Gürel"],"pdf_url":"https://arxiv.org/pdf/2410.13609v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.13605v1","updated":"2024-10-17T14:39:55Z","published":"2024-10-17T14:39:55Z","title":"Transformer-Based Approaches for Sensor-Based Human Activity\n  Recognition: Opportunities and Challenges","summary":"  Transformers have excelled in natural language processing and computer\nvision, paving their way to sensor-based Human Activity Recognition (HAR).\nPrevious studies show that transformers outperform their counterparts\nexclusively when they harness abundant data or employ compute-intensive\noptimization algorithms. However, neither of these scenarios is viable in\nsensor-based HAR due to the scarcity of data in this field and the frequent\nneed to perform training and inference on resource-constrained devices. Our\nextensive investigation into various implementations of transformer-based\nversus non-transformer-based HAR using wearable sensors, encompassing more than\n500 experiments, corroborates these concerns. We observe that transformer-based\nsolutions pose higher computational demands, consistently yield inferior\nperformance, and experience significant performance degradation when quantized\nto accommodate resource-constrained devices. Additionally, transformers\ndemonstrate lower robustness to adversarial attacks, posing a potential threat\nto user trust in HAR.\n","authors":["Clayton Souza Leite","Henry Mauranen","Aziza Zhanabatyrova","Yu Xiao"],"pdf_url":"https://arxiv.org/pdf/2410.13605v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.13602v1","updated":"2024-10-17T14:36:58Z","published":"2024-10-17T14:36:58Z","title":"Towards Satellite Non-IID Imagery: A Spectral Clustering-Assisted\n  Federated Learning Approach","summary":"  Low Earth orbit (LEO) satellites are capable of gathering abundant Earth\nobservation data (EOD) to enable different Internet of Things (IoT)\napplications. However, to accomplish an effective EOD processing mechanism, it\nis imperative to investigate: 1) the challenge of processing the observed data\nwithout transmitting those large-size data to the ground because the connection\nbetween the satellites and the ground stations is intermittent, and 2) the\nchallenge of processing the non-independent and identically distributed\n(non-IID) satellite data. In this paper, to cope with those challenges, we\npropose an orbit-based spectral clustering-assisted clustered federated\nself-knowledge distillation (OSC-FSKD) approach for each orbit of an LEO\nsatellite constellation, which retains the advantage of FL that the observed\ndata does not need to be sent to the ground. Specifically, we introduce\nnormalized Laplacian-based spectral clustering (NLSC) into federated learning\n(FL) to create clustered FL in each round to address the challenge resulting\nfrom non-IID data. Particularly, NLSC is adopted to dynamically group clients\ninto several clusters based on cosine similarities calculated by model updates.\nIn addition, self-knowledge distillation is utilized to construct each local\nclient, where the most recent updated local model is used to guide current\nlocal model training. Experiments demonstrate that the observation accuracy\nobtained by the proposed method is separately 1.01x, 2.15x, 1.10x, and 1.03x\nhigher than that of pFedSD, FedProx, FedAU, and FedALA approaches using the\nSAT4 dataset. The proposed method also shows superiority when using other\ndatasets.\n","authors":["Luyao Zou","Yu Min Park","Chu Myaet Thwal","Yan Kyaw Tun","Zhu Han","Choong Seon Hong"],"pdf_url":"https://arxiv.org/pdf/2410.13602v1.pdf","comment":"10 pages, 5 figures"},{"id":"http://arxiv.org/abs/2410.13597v1","updated":"2024-10-17T14:30:27Z","published":"2024-10-17T14:30:27Z","title":"Text-Guided Multi-Property Molecular Optimization with a Diffusion\n  Language Model","summary":"  Molecular optimization (MO) is a crucial stage in drug discovery in which\ntask-oriented generated molecules are optimized to meet practical industrial\nrequirements. Existing mainstream MO approaches primarily utilize external\nproperty predictors to guide iterative property optimization. However, learning\nall molecular samples in the vast chemical space is unrealistic for predictors.\nAs a result, errors and noise are inevitably introduced during property\nprediction due to the nature of approximation. This leads to discrepancy\naccumulation, generalization reduction and suboptimal molecular candidates. In\nthis paper, we propose a text-guided multi-property molecular optimization\nmethod utilizing transformer-based diffusion language model (TransDLM).\nTransDLM leverages standardized chemical nomenclature as semantic\nrepresentations of molecules and implicitly embeds property requirements into\ntextual descriptions, thereby preventing error propagation during diffusion\nprocess. Guided by physically and chemically detailed textual descriptions,\nTransDLM samples and optimizes encoded source molecules, retaining core\nscaffolds of source molecules and ensuring structural similarities. Moreover,\nTransDLM enables simultaneous sampling of multiple molecules, making it ideal\nfor scalable, efficient large-scale optimization through distributed\ncomputation on web platforms. Furthermore, our approach surpasses\nstate-of-the-art methods in optimizing molecular structural similarity and\nenhancing chemical properties on the benchmark dataset. The code is available\nat: https://anonymous.4open.science/r/TransDLM-A901.\n","authors":["Yida Xiong","Kun Li","Weiwei Liu","Jia Wu","Bo Du","Shirui Pan","Wenbin Hu"],"pdf_url":"https://arxiv.org/pdf/2410.13597v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.13579v1","updated":"2024-10-17T14:12:57Z","published":"2024-10-17T14:12:57Z","title":"Towards Better Performance in Incomplete LDL: Addressing Data Imbalance","summary":"  Label Distribution Learning (LDL) is a novel machine learning paradigm that\naddresses the problem of label ambiguity and has found widespread applications.\nObtaining complete label distributions in real-world scenarios is challenging,\nwhich has led to the emergence of Incomplete Label Distribution Learning\n(InLDL). However, the existing InLDL methods overlook a crucial aspect of LDL\ndata: the inherent imbalance in label distributions. To address this\nlimitation, we propose \\textbf{Incomplete and Imbalance Label Distribution\nLearning (I\\(^2\\)LDL)}, a framework that simultaneously handles incomplete\nlabels and imbalanced label distributions. Our method decomposes the label\ndistribution matrix into a low-rank component for frequent labels and a sparse\ncomponent for rare labels, effectively capturing the structure of both head and\ntail labels. We optimize the model using the Alternating Direction Method of\nMultipliers (ADMM) and derive generalization error bounds via Rademacher\ncomplexity, providing strong theoretical guarantees. Extensive experiments on\n15 real-world datasets demonstrate the effectiveness and robustness of our\nproposed framework compared to existing InLDL methods.\n","authors":["Zhiqiang Kou","Haoyuan Xuan","Jing Wang","Yuheng Jia","Xin Geng"],"pdf_url":"https://arxiv.org/pdf/2410.13579v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.13577v1","updated":"2024-10-17T14:12:35Z","published":"2024-10-17T14:12:35Z","title":"Sample Compression Hypernetworks: From Generalization Bounds to\n  Meta-Learning","summary":"  Reconstruction functions are pivotal in sample compression theory, a\nframework for deriving tight generalization bounds. From a small sample of the\ntraining set (the compression set) and an optional stream of information (the\nmessage), they recover a predictor previously learned from the whole training\nset. While usually fixed, we propose to learn reconstruction functions. To\nfacilitate the optimization and increase the expressiveness of the message, we\nderive a new sample compression generalization bound for real-valued messages.\nFrom this theoretical analysis, we then present a new hypernetwork architecture\nthat outputs predictors with tight generalization guarantees when trained using\nan original meta-learning framework. The results of promising preliminary\nexperiments are then reported.\n","authors":["Benjamin Leblanc","Mathieu Bazinet","Nathaniel D'Amours","Alexandre Drouin","Pascal Germain"],"pdf_url":"https://arxiv.org/pdf/2410.13577v1.pdf","comment":"Accepted at the NeurIPS 2024 workshop on Compression in Machine\n  Learning"},{"id":"http://arxiv.org/abs/2402.06165v5","updated":"2024-10-17T14:10:16Z","published":"2024-02-09T03:48:20Z","title":"Learning Contrastive Feature Representations for Facial Action Unit\n  Detection","summary":"  Facial action unit (AU) detection has long encountered the challenge of\ndetecting subtle feature differences when AUs activate. Existing methods often\nrely on encoding pixel-level information of AUs, which not only encodes\nadditional redundant information but also leads to increased model complexity\nand limited generalizability. Additionally, the accuracy of AU detection is\nnegatively impacted by the class imbalance issue of each AU type, and the\npresence of noisy and false AU labels. In this paper, we introduce a novel\ncontrastive learning framework aimed for AU detection that incorporates both\nself-supervised and supervised signals, thereby enhancing the learning of\ndiscriminative features for accurate AU detection. To tackle the class\nimbalance issue, we employ a negative sample re-weighting strategy that adjusts\nthe step size of updating parameters for minority and majority class samples.\nMoreover, to address the challenges posed by noisy and false AU labels, we\nemploy a sampling technique that encompasses three distinct types of positive\nsample pairs. This enables us to inject self-supervised signals into the\nsupervised signal, effectively mitigating the adverse effects of noisy labels.\nOur experimental assessments, conducted on four widely-utilized benchmark\ndatasets (BP4D, DISFA, GFT and Aff-Wild2), underscore the superior performance\nof our approach compared to state-of-the-art methods of AU detection. Our code\nis available at \\url{https://github.com/Ziqiao-Shang/AUNCE}.\n","authors":["Ziqiao Shang","Bin Liu","Fengmao Lv","Fei Teng","Tianrui Li"],"pdf_url":"https://arxiv.org/pdf/2402.06165v5.pdf","comment":"35 pages, 18 figures, submitted to Pattern Recognition (PR)"},{"id":"http://arxiv.org/abs/2410.13563v1","updated":"2024-10-17T14:00:18Z","published":"2024-10-17T14:00:18Z","title":"Ornstein-Uhlenbeck Adaptation as a Mechanism for Learning in Brains and\n  Machines","summary":"  Learning is a fundamental property of intelligent systems, observed across\nbiological organisms and engineered systems. While modern intelligent systems\ntypically rely on gradient descent for learning, the need for exact gradients\nand complex information flow makes its implementation in biological and\nneuromorphic systems challenging. This has motivated the exploration of\nalternative learning mechanisms that can operate locally and do not rely on\nexact gradients. In this work, we introduce a novel approach that leverages\nnoise in the parameters of the system and global reinforcement signals. Using\nan Ornstein-Uhlenbeck process with adaptive dynamics, our method balances\nexploration and exploitation during learning, driven by deviations from error\npredictions, akin to reward prediction error. Operating in continuous time,\nOrstein-Uhlenbeck adaptation (OUA) is proposed as a general mechanism for\nlearning dynamic, time-evolving environments. We validate our approach across\ndiverse tasks, including supervised learning and reinforcement learning in\nfeedforward and recurrent systems. Additionally, we demonstrate that it can\nperform meta-learning, adjusting hyper-parameters autonomously. Our results\nindicate that OUA provides a viable alternative to traditional gradient-based\nmethods, with potential applications in neuromorphic computing. It also hints\nat a possible mechanism for noise-driven learning in the brain, where\nstochastic neurotransmitter release may guide synaptic adjustments.\n","authors":["Jesus Garcia Fernandez","Nasir Ahmad","Marcel van Gerven"],"pdf_url":"https://arxiv.org/pdf/2410.13563v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2404.16710v3","updated":"2024-10-17T13:50:46Z","published":"2024-04-25T16:20:23Z","title":"LayerSkip: Enabling Early Exit Inference and Self-Speculative Decoding","summary":"  We present LayerSkip, an end-to-end solution to speed-up inference of large\nlanguage models (LLMs). First, during training we apply layer dropout, with low\ndropout rates for earlier layers and higher dropout rates for later layers, and\nan early exit loss where all transformer layers share the same exit. Second,\nduring inference, we show that this training recipe increases the accuracy of\nearly exit at earlier layers, without adding any auxiliary layers or modules to\nthe model. Third, we present a novel self-speculative decoding solution where\nwe exit at early layers and verify and correct with remaining layers of the\nmodel. Our proposed self-speculative decoding approach has less memory\nfootprint than other speculative decoding approaches and benefits from shared\ncompute and activations of the draft and verification stages. We run\nexperiments on different Llama model sizes on different types of training:\npretraining from scratch, continual pretraining, finetuning on specific data\ndomain, and finetuning on specific task. We implement our inference solution\nand show speedups of up to 2.16x on summarization for CNN/DM documents, 1.82x\non coding, and 2.0x on TOPv2 semantic parsing task. We open source our code and\ncheckpoints at https://github.com/facebookresearch/LayerSkip.\n","authors":["Mostafa Elhoushi","Akshat Shrivastava","Diana Liskovich","Basil Hosmer","Bram Wasti","Liangzhen Lai","Anas Mahmoud","Bilge Acun","Saurabh Agarwal","Ahmed Roman","Ahmed A Aly","Beidi Chen","Carole-Jean Wu"],"pdf_url":"https://arxiv.org/pdf/2404.16710v3.pdf","comment":"ACL 2024"},{"id":"http://arxiv.org/abs/2410.13548v1","updated":"2024-10-17T13:42:56Z","published":"2024-10-17T13:42:56Z","title":"Adaptive and oblivious statistical adversaries are equivalent","summary":"  We resolve a fundamental question about the ability to perform a statistical\ntask, such as learning, when an adversary corrupts the sample. Such adversaries\nare specified by the types of corruption they can make and their level of\nknowledge about the sample. The latter distinguishes between sample-adaptive\nadversaries which know the contents of the sample when choosing the corruption,\nand sample-oblivious adversaries, which do not. We prove that for all types of\ncorruptions, sample-adaptive and sample-oblivious adversaries are\n\\emph{equivalent} up to polynomial factors in the sample size. This resolves\nthe main open question introduced by \\cite{BLMT22} and further explored in\n\\cite{CHLLN23}.\n  Specifically, consider any algorithm $A$ that solves a statistical task even\nwhen a sample-oblivious adversary corrupts its input. We show that there is an\nalgorithm $A'$ that solves the same task when the corresponding sample-adaptive\nadversary corrupts its input. The construction of $A'$ is simple and maintains\nthe computational efficiency of $A$: It requests a polynomially larger sample\nthan $A$ uses and then runs $A$ on a uniformly random subsample.\n  One of our main technical tools is a new structural result relating two\ndistributions defined on sunflowers which may be of independent interest.\n","authors":["Guy Blanc","Gregory Valiant"],"pdf_url":"https://arxiv.org/pdf/2410.13548v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.12294v2","updated":"2024-10-17T13:27:43Z","published":"2024-10-16T06:51:09Z","title":"LLM-based Cognitive Models of Students with Misconceptions","summary":"  Accurately modeling student cognition is crucial for developing effective\nAI-driven educational technologies. A key challenge is creating realistic\nstudent models that satisfy two essential properties: (1) accurately\nreplicating specific misconceptions, and (2) correctly solving problems where\nthese misconceptions are not applicable. This dual requirement reflects the\ncomplex nature of student understanding, where misconceptions coexist with\ncorrect knowledge. This paper investigates whether Large Language Models (LLMs)\ncan be instruction-tuned to meet this dual requirement and effectively simulate\nstudent thinking in algebra. We introduce MalAlgoPy, a novel Python library\nthat generates datasets reflecting authentic student solution patterns through\na graph-based representation of algebraic problem-solving. Utilizing MalAlgoPy,\nwe define and examine Cognitive Student Models (CSMs) - LLMs instruction tuned\nto faithfully emulate realistic student behavior. Our findings reveal that LLMs\ntrained on misconception examples can efficiently learn to replicate errors.\nHowever, the training diminishes the model's ability to solve problems\ncorrectly, particularly for problem types where the misconceptions are not\napplicable, thus failing to satisfy second property of CSMs. We demonstrate\nthat by carefully calibrating the ratio of correct to misconception examples in\nthe training data - sometimes as low as 0.25 - it is possible to develop CSMs\nthat satisfy both properties. Our insights enhance our understanding of\nAI-based student models and pave the way for effective adaptive learning\nsystems.\n","authors":["Shashank Sonkar","Xinghe Chen","Naiming Liu","Richard G. Baraniuk","Mrinmaya Sachan"],"pdf_url":"https://arxiv.org/pdf/2410.12294v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.13526v1","updated":"2024-10-17T13:14:25Z","published":"2024-10-17T13:14:25Z","title":"Generative Adversarial Synthesis of Radar Point Cloud Scenes","summary":"  For the validation and verification of automotive radars, datasets of\nrealistic traffic scenarios are required, which, how ever, are laborious to\nacquire. In this paper, we introduce radar scene synthesis using GANs as an\nalternative to the real dataset acquisition and simulation-based approaches. We\ntrain a PointNet++ based GAN model to generate realistic radar point cloud\nscenes and use a binary classifier to evaluate the performance of scenes\ngenerated using this model against a test set of real scenes. We demonstrate\nthat our GAN model achieves similar performance (~87%) to the real scenes test\nset.\n","authors":["Muhammad Saad Nawaz","Thomas Dallmann","Torsten Schoen","Dirk Heberling"],"pdf_url":"https://arxiv.org/pdf/2410.13526v1.pdf","comment":"ICMIM 2024; 7th IEEE MTT Conference"},{"id":"http://arxiv.org/abs/2406.03857v2","updated":"2024-10-17T13:08:13Z","published":"2024-06-06T08:42:36Z","title":"MuJo: Multimodal Joint Feature Space Learning for Human Activity\n  Recognition","summary":"  Human Activity Recognition (HAR) is a longstanding problem in AI with\napplications in a broad range of areas, including healthcare, sports and\nfitness, security, and more. The performance of HAR in real-world settings is\nstrongly dependent on the type and quality of the input signal that can be\nacquired. Given an unobstructed, high-quality camera view of a scene, computer\nvision systems, in particular in conjunction with foundation models, can today\nfairly reliably distinguish complex activities. On the other hand, recognition\nusing modalities such as wearable sensors (which are often more broadly\navailable, e.g., in mobile phones and smartwatches) is a more difficult\nproblem, as the signals often contain less information and labeled training\ndata is more difficult to acquire. To alleviate the need for labeled data, we\nintroduce our comprehensive Fitness Multimodal Activity Dataset (FiMAD) in this\nwork, which can be used with the proposed pre-training method MuJo (Multimodal\nJoint Feature Space Learning) to enhance HAR performance across various\nmodalities. FiMAD was created using YouTube fitness videos and contains\nparallel video, language, pose, and simulated IMU sensor data. MuJo utilizes\nthis dataset to learn a joint feature space for these modalities. We show that\nclassifiers pre-trained on FiMAD can increase the performance on real HAR\ndatasets such as MM-Fit, MyoGym, MotionSense, and MHEALTH. For instance, on\nMM-Fit, we achieve an Macro F1-Score of up to 0.855 when fine-tuning on only 2%\nof the training data and 0.942 when utilizing the full training set for\nclassification tasks. We have compared our approach to other self-supervised\nones and showed that, unlike them, ours can consistently improve on the\nbaseline network performance as well as provide a better data-efficiency.\n","authors":["Stefan Gerd Fritsch","Cennet Oguz","Vitor Fortes Rey","Lala Ray","Maximilian Kiefer-Emmanouilidis","Paul Lukowicz"],"pdf_url":"https://arxiv.org/pdf/2406.03857v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.13516v1","updated":"2024-10-17T13:05:44Z","published":"2024-10-17T13:05:44Z","title":"PORTAL: Scalable Tabular Foundation Models via Content-Specific\n  Tokenization","summary":"  Self-supervised learning on tabular data seeks to apply advances from natural\nlanguage and image domains to the diverse domain of tables. However, current\ntechniques often struggle with integrating multi-domain data and require data\ncleaning or specific structural requirements, limiting the scalability of\npre-training datasets. We introduce PORTAL (Pretraining One-Row-at-a-Time for\nAll tabLes), a framework that handles various data modalities without the need\nfor cleaning or preprocessing. This simple yet powerful approach can be\neffectively pre-trained on online-collected datasets and fine-tuned to match\nstate-of-the-art methods on complex classification and regression tasks. This\nwork offers a practical advancement in self-supervised learning for large-scale\ntabular data.\n","authors":["Marco Spinaci","Marek Polewczyk","Johannes Hoffart","Markus C. Kohler","Sam Thelin","Tassilo Klein"],"pdf_url":"https://arxiv.org/pdf/2410.13516v1.pdf","comment":"Accepted at Table Representation Learning Workshop at NeurIPS 2024"},{"id":"http://arxiv.org/abs/2410.13514v1","updated":"2024-10-17T13:02:06Z","published":"2024-10-17T13:02:06Z","title":"CERES: Critical-Event Reconstruction via Temporal Scene Graph Completion","summary":"  This paper proposes a method for on-demand scenario generation in simulation,\ngrounded on real-world data. Evaluating the behaviour of Autonomous Vehicles\n(AVs) in both safety-critical and regular scenarios is essential for assessing\ntheir robustness before real-world deployment. By integrating scenarios derived\nfrom real-world datasets into the simulation, we enhance the plausibility and\nvalidity of testing sets. This work introduces a novel approach that employs\ntemporal scene graphs to capture evolving spatiotemporal relationships among\nscene entities from a real-world dataset, enabling the generation of dynamic\nscenarios in simulation through Graph Neural Networks (GNNs). User-defined\naction and criticality conditioning are used to ensure flexible, tailored\nscenario creation. Our model significantly outperforms the benchmarks in\naccurately predicting links corresponding to the requested scenarios. We\nfurther evaluate the validity and compatibility of our generated scenarios in\nan off-the-shelf simulator.\n","authors":["Efimia Panagiotaki","Georgi Pramatarov","Lars Kunze","Daniele De Martini"],"pdf_url":"https://arxiv.org/pdf/2410.13514v1.pdf","comment":"7 pages, 8 figures"},{"id":"http://arxiv.org/abs/2410.10905v2","updated":"2024-10-17T12:59:03Z","published":"2024-10-13T19:28:41Z","title":"Improving Generalization on the ProcGen Benchmark with Simple\n  Architectural Changes and Scale","summary":"  We demonstrate that recent advances in reinforcement learning (RL) combined\nwith simple architectural changes significantly improves generalization on the\nProcGen benchmark. These changes are frame stacking, replacing 2D convolutional\nlayers with 3D convolutional layers, and scaling up the number of convolutional\nkernels per layer. Experimental results using a single set of hyperparameters\nacross all environments show a 37.9\\% reduction in the optimality gap compared\nto the baseline (from 0.58 to 0.36). This performance matches or exceeds\ncurrent state-of-the-art methods. The proposed changes are largely orthogonal\nand therefore complementary to the existing approaches for improving\ngeneralization in RL, and our results suggest that further exploration in this\ndirection could yield substantial improvements in addressing generalization\nchallenges in deep reinforcement learning.\n","authors":["Andrew Jesson","Yiding Jiang"],"pdf_url":"https://arxiv.org/pdf/2410.10905v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.01186v2","updated":"2024-10-17T12:50:06Z","published":"2024-10-02T02:38:33Z","title":"Efficient PAC Learning of Halfspaces with Constant Malicious Noise Rate","summary":"  Understanding noise tolerance of learning algorithms under certain conditions\nis a central quest in learning theory. In this work, we study the problem of\ncomputationally efficient PAC learning of halfspaces in the presence of\nmalicious noise, where an adversary can corrupt both instances and labels of\ntraining samples. The best-known noise tolerance either depends on a target\nerror rate under distributional assumptions or on a margin parameter under\nlarge-margin conditions. In this work, we show that when both types of\nconditions are satisfied, it is possible to achieve {\\em constant} noise\ntolerance by minimizing a reweighted hinge loss. Our key ingredients include:\n1) an efficient algorithm that finds weights to control the gradient\ndeterioration from corrupted samples, and 2) a new analysis on the robustness\nof the hinge loss equipped with such weights.\n","authors":["Jie Shen","Xiaoyu Li"],"pdf_url":"https://arxiv.org/pdf/2410.01186v2.pdf","comment":"author list in contribution order"},{"id":"http://arxiv.org/abs/2410.13502v1","updated":"2024-10-17T12:48:14Z","published":"2024-10-17T12:48:14Z","title":"MathGAP: Out-of-Distribution Evaluation on Problems with Arbitrarily\n  Complex Proofs","summary":"  Large language models (LLMs) can solve arithmetic word problems with high\naccuracy, but little is known about how well they generalize to problems that\nare more complex than the ones on which they have been trained. Empirical\ninvestigations of such questions are impeded by two major flaws of current\nevaluations: (i) much of the evaluation data is contaminated, in the sense that\nit has already been seen during training, and (ii) benchmark datasets do not\ncapture how problem proofs may be arbitrarily complex in various ways. As a\nstep towards addressing these issues, we present a framework for evaluating\nLLMs on problems that have arbitrarily complex arithmetic proofs, called\nMathGAP. MathGAP generates problems that follow fixed proof specifications --\nalong with chain-of-thought reasoning annotations -- enabling systematic\nstudies on generalization with respect to arithmetic proof complexity. We apply\nMathGAP to analyze how in-context learning interacts with generalization to\nproblems that have more complex proofs. We find that among the models tested,\nmost show a significant decrease in performance as proofs get deeper and wider.\nThis effect is more pronounced in complex, nonlinear proof structures, which\nare challenging even for GPT-4o. Surprisingly, providing in-context examples\nfrom the same distribution as the test set is not always beneficial for\nperformance. In particular, zero-shot prompting as well as demonstrating a\ndiverse range of examples that are less complex than the test data sometimes\nyield similar or higher accuracies.\n","authors":["Andreas Opedal","Haruki Shirakami","Bernhard Schölkopf","Abulhair Saparov","Mrinmaya Sachan"],"pdf_url":"https://arxiv.org/pdf/2410.13502v1.pdf","comment":"Preprint"},{"id":"http://arxiv.org/abs/2410.13501v1","updated":"2024-10-17T12:47:31Z","published":"2024-10-17T12:47:31Z","title":"Integrating Large Language Models and Reinforcement Learning for\n  Non-Linear Reasoning","summary":"  Large Language Models (LLMs) were shown to struggle with long-term planning,\nwhich may be caused by the limited way in which they explore the space of\npossible solutions. We propose an architecture where a Reinforcement Learning\n(RL) Agent guides an LLM's space exploration: (1) the Agent has access to\ndomain-specific information, and can therefore make decisions about the quality\nof candidate solutions based on specific and relevant metrics, which were not\nexplicitly considered by the LLM's training objective; (2) the LLM can focus on\ngenerating immediate next steps, without the need for long-term planning. We\nallow non-linear reasoning by exploring alternative paths and backtracking. We\nevaluate this architecture on the program equivalence task, and compare it\nagainst Chain of Thought (CoT) and Tree of Thoughts (ToT). We assess both the\ndownstream task, denoting the binary classification, and the intermediate\nreasoning steps. Our approach compares positively against CoT and ToT.\n","authors":["Yoav Alon","Cristina David"],"pdf_url":"https://arxiv.org/pdf/2410.13501v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.13500v1","updated":"2024-10-17T12:46:26Z","published":"2024-10-17T12:46:26Z","title":"SAda-Net: A Self-Supervised Adaptive Stereo Estimation CNN For Remote\n  Sensing Image Data","summary":"  Stereo estimation has made many advancements in recent years with the\nintroduction of deep-learning. However the traditional supervised approach to\ndeep-learning requires the creation of accurate and plentiful ground-truth\ndata, which is expensive to create and not available in many situations. This\nis especially true for remote sensing applications, where there is an excess of\navailable data without proper ground truth. To tackle this problem, we propose\na self-supervised CNN with self-improving adaptive abilities. In the first\niteration, the created disparity map is inaccurate and noisy. Leveraging the\nleft-right consistency check, we get a sparse but more accurate disparity map\nwhich is used as an initial pseudo ground-truth. This pseudo ground-truth is\nthen adapted and updated after every epoch in the training step of the network.\nWe use the sum of inconsistent points in order to track the network\nconvergence. The code for our method is publicly available at:\nhttps://github.com/thedodo/SAda-Net}{https://github.com/thedodo/SAda-Net\n","authors":["Dominik Hirner","Friedrich Fraundorfer"],"pdf_url":"https://arxiv.org/pdf/2410.13500v1.pdf","comment":"Will be presented at ICPR2024 in December 2024 in Kolkata, India"},{"id":"http://arxiv.org/abs/2410.13498v1","updated":"2024-10-17T12:43:49Z","published":"2024-10-17T12:43:49Z","title":"Enhancing Text Generation in Joint NLG/NLU Learning Through Curriculum\n  Learning, Semi-Supervised Training, and Advanced Optimization Techniques","summary":"  Text generation is the automated process of producing written or spoken\nlanguage using computational methods. It involves generating coherent and\ncontextually relevant text based on predefined rules or learned patterns.\nHowever, challenges in text generation arise from maintaining coherence,\nensuring diversity and creativity, and avoiding biases or inappropriate\ncontent. This research paper developed a novel approach to improve text\ngeneration in the context of joint Natural Language Generation (NLG) and\nNatural Language Understanding (NLU) learning. The data is prepared by\ngathering and preprocessing annotated datasets, including cleaning,\ntokenization, stemming, and stop-word removal. Feature extraction techniques\nsuch as POS tagging, Bag of words, and Term Frequency-Inverse Document\nFrequency (TF-IDF) are applied. Transformer-based encoders and decoders,\ncapturing long range dependencies and improving source-target sequence\nmodelling. Pre-trained language models like Optimized BERT are incorporated,\nalong with a Hybrid Redfox Artificial Hummingbird Algorithm (HRAHA).\nReinforcement learning with policy gradient techniques, semi-supervised\ntraining, improved attention mechanisms, and differentiable approximations like\nstraight-through Gumbel SoftMax estimator are employed to fine-tune the models\nand handle complex linguistic tasks effectively. The proposed model is\nimplemented using Python.\n","authors":["Rahimanuddin Shaik","Katikela Sreeharsha Kishore"],"pdf_url":"https://arxiv.org/pdf/2410.13498v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.13493v1","updated":"2024-10-17T12:38:08Z","published":"2024-10-17T12:38:08Z","title":"Deep Reinforcement Learning for Online Optimal Execution Strategies","summary":"  This paper tackles the challenge of learning non-Markovian optimal execution\nstrategies in dynamic financial markets. We introduce a novel actor-critic\nalgorithm based on Deep Deterministic Policy Gradient (DDPG) to address this\nissue, with a focus on transient price impact modeled by a general decay\nkernel. Through numerical experiments with various decay kernels, we show that\nour algorithm successfully approximates the optimal execution strategy.\nAdditionally, the proposed algorithm demonstrates adaptability to evolving\nmarket conditions, where parameters fluctuate over time. Our findings also show\nthat modern reinforcement learning algorithms can provide a solution that\nreduces the need for frequent and inefficient human intervention in optimal\nexecution tasks.\n","authors":["Alessandro Micheli","Mélodie Monod"],"pdf_url":"https://arxiv.org/pdf/2410.13493v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.13490v1","updated":"2024-10-17T12:34:37Z","published":"2024-10-17T12:34:37Z","title":"Novelty-based Sample Reuse for Continuous Robotics Control","summary":"  In reinforcement learning, agents collect state information and rewards\nthrough environmental interactions, essential for policy refinement. This\nprocess is notably time-consuming, especially in complex robotic simulations\nand real-world applications. Traditional algorithms usually re-engage with the\nenvironment after processing a single batch of samples, thereby failing to\nfully capitalize on historical data. However, frequently observed states, with\nreliable value estimates, require minimal updates; in contrast, rare observed\nstates necessitate more intensive updates for achieving accurate value\nestimations. To address uneven sample utilization, we propose Novelty-guided\nSample Reuse (NSR). NSR provides extra updates for infrequent, novel states and\nskips additional updates for frequent states, maximizing sample use before\ninteracting with the environment again. Our experiments show that NSR improves\nthe convergence rate and success rate of algorithms without significantly\nincreasing time consumption. Our code is publicly available at\nhttps://github.com/ppksigs/NSR-DDPG-HER.\n","authors":["Ke Duan","Kai Yang","Houde Liu","Xueqian Wang"],"pdf_url":"https://arxiv.org/pdf/2410.13490v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.13488v1","updated":"2024-10-17T12:32:00Z","published":"2024-10-17T12:32:00Z","title":"Seeing Through VisualBERT: A Causal Adventure on Memetic Landscapes","summary":"  Detecting offensive memes is crucial, yet standard deep neural network\nsystems often remain opaque. Various input attribution-based methods attempt to\ninterpret their behavior, but they face challenges with implicitly offensive\nmemes and non-causal attributions. To address these issues, we propose a\nframework based on a Structural Causal Model (SCM). In this framework,\nVisualBERT is trained to predict the class of an input meme based on both meme\ninput and causal concepts, allowing for transparent interpretation. Our\nqualitative evaluation demonstrates the framework's effectiveness in\nunderstanding model behavior, particularly in determining whether the model was\nright due to the right reason, and in identifying reasons behind\nmisclassification. Additionally, quantitative analysis assesses the\nsignificance of proposed modelling choices, such as de-confounding, adversarial\nlearning, and dynamic routing, and compares them with input attribution\nmethods. Surprisingly, we find that input attribution methods do not guarantee\ncausality within our framework, raising questions about their reliability in\nsafety-critical applications. The project page is at:\nhttps://newcodevelop.github.io/causality_adventure/\n","authors":["Dibyanayan Bandyopadhyay","Mohammed Hasanuzzaman","Asif Ekbal"],"pdf_url":"https://arxiv.org/pdf/2410.13488v1.pdf","comment":"Accepted at EMNLP Findings 2024"},{"id":"http://arxiv.org/abs/2409.19431v2","updated":"2024-10-17T12:23:07Z","published":"2024-09-28T18:31:51Z","title":"Generalization Error of the Tilted Empirical Risk","summary":"  The generalization error (risk) of a supervised statistical learning\nalgorithm quantifies its prediction ability on previously unseen data. Inspired\nby exponential tilting, Li et al. (2021) proposed the tilted empirical risk as\na non-linear risk metric for machine learning applications such as\nclassification and regression problems. In this work, we examine the\ngeneralization error of the tilted empirical risk. In particular, we provide\nuniform and information-theoretic bounds on the tilted generalization error,\ndefined as the difference between the population risk and the tilted empirical\nrisk, with a convergence rate of $O(1/\\sqrt{n})$ where $n$ is the number of\ntraining samples. Furthermore, we study the solution to the KL-regularized\nexpected tilted empirical risk minimization problem and derive an upper bound\non the expected tilted generalization error with a convergence rate of\n$O(1/n)$.\n","authors":["Gholamali Aminian","Amir R. Asadi","Tian Li","Ahmad Beirami","Gesine Reinert","Samuel N. Cohen"],"pdf_url":"https://arxiv.org/pdf/2409.19431v2.pdf","comment":"New results are added"},{"id":"http://arxiv.org/abs/2407.18402v2","updated":"2024-10-17T12:19:26Z","published":"2024-07-25T21:33:54Z","title":"RECOVAR: Representation Covariances on Deep Latent Spaces for Seismic\n  Event Detection","summary":"  While modern deep learning methods have shown great promise in the problem of\nearthquake detection, the most successful methods so far have been based on\nsupervised learning, which requires large datasets with ground-truth labels.\nThe curation of such datasets is both time consuming and prone to systematic\nbiases, which result in difficulties with cross-dataset generalization,\nhindering general applicability. In this paper, we develop an unsupervised\nmethod for earthquake detection that learns to detect earthquakes from raw\nwaveforms, without access to ground truth labels. The performance is comparable\nto, and in some cases better than, some state-of-the-art supervised methods.\nMoreover, the method has strong \\emph{cross-dataset generalization}\nperformance. The algorithm utilizes deep autoencoders that learn to reproduce\nthe waveforms after a data-compressive bottleneck and uses a simple,\ncross-covariance-based triggering algorithm at the bottleneck for labeling. The\napproach has the potential to be useful for time series datasets from other\ndomains.\n","authors":["Onur Efe","Arkadas Ozakin"],"pdf_url":"https://arxiv.org/pdf/2407.18402v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2405.18392v3","updated":"2024-10-17T12:01:15Z","published":"2024-05-28T17:33:54Z","title":"Scaling Laws and Compute-Optimal Training Beyond Fixed Training\n  Durations","summary":"  Scale has become a main ingredient in obtaining strong machine learning\nmodels. As a result, understanding a model's scaling properties is key to\neffectively designing both the right training setup as well as future\ngenerations of architectures. In this work, we argue that scale and training\nresearch has been needlessly complex due to reliance on the cosine schedule,\nwhich prevents training across different lengths for the same model size. We\ninvestigate the training behavior of a direct alternative -- constant learning\nrate and cooldowns -- and find that it scales predictably and reliably similar\nto cosine. Additionally, we show that stochastic weight averaging yields\nimproved performance along the training trajectory, without additional training\ncosts, across different scales. Importantly, with these findings we demonstrate\nthat scaling experiments can be performed with significantly reduced compute\nand GPU hours by utilizing fewer but reusable training runs. Our code is\navailable at \\url{https://github.com/epfml/schedules-and-scaling/}.\n","authors":["Alexander Hägele","Elie Bakouch","Atli Kosson","Loubna Ben Allal","Leandro Von Werra","Martin Jaggi"],"pdf_url":"https://arxiv.org/pdf/2405.18392v3.pdf","comment":"Spotlight at NeurIPS 2024"},{"id":"http://arxiv.org/abs/2410.13469v1","updated":"2024-10-17T11:56:33Z","published":"2024-10-17T11:56:33Z","title":"Interpreting Temporal Graph Neural Networks with Koopman Theory","summary":"  Spatiotemporal graph neural networks (STGNNs) have shown promising results in\nmany domains, from forecasting to epidemiology. However, understanding the\ndynamics learned by these models and explaining their behaviour is\nsignificantly more complex than for models dealing with static data. Inspired\nby Koopman theory, which allows a simpler description of intricate, nonlinear\ndynamical systems, we introduce an explainability approach for temporal graphs.\nWe present two methods to interpret the STGNN's decision process and identify\nthe most relevant spatial and temporal patterns in the input for the task at\nhand. The first relies on dynamic mode decomposition (DMD), a Koopman-inspired\ndimensionality reduction method. The second relies on sparse identification of\nnonlinear dynamics (SINDy), a popular method for discovering governing\nequations, which we use for the first time as a general tool for\nexplainability. We show how our methods can correctly identify interpretable\nfeatures such as infection times and infected nodes in the context of\ndissemination processes.\n","authors":["Michele Guerra","Simone Scardapane","Filippo Maria Bianchi"],"pdf_url":"https://arxiv.org/pdf/2410.13469v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.10874v3","updated":"2024-10-17T11:50:03Z","published":"2023-01-25T23:47:34Z","title":"Recursive deep learning framework for forecasting the decadal world\n  economic outlook","summary":"  The gross domestic product (GDP) is the most widely used indicator in\nmacroeconomics and the main tool for measuring a country's economic output. Due\nto the diversity and complexity of the world economy, a wide range of models\nhave been used, but there are challenges in making decadal GDP forecasts given\nunexpected changes such as emergence of catastrophic world events including\npandemics and wars. Deep learning models are well suited for modelling temporal\nsequences and time series forecasting. In this paper, we develop a deep\nlearning framework to forecast the GDP growth rate of the world economy over a\ndecade. We use the Penn World Table as the data source featuring 13 countries\nprior to the COVID-19 pandemic, such as Australia, China, India, and the United\nStates. We present a recursive deep learning framework to predict the GDP\ngrowth rate in the next ten years. We test prominent deep learning models and\ncompare their results with traditional econometric models for selected\ndeveloped and developing countries. Our decadal forecasts reveal that that most\nof the developed countries would experience economic growth slowdown,\nstagnation and even recession within five years (2020-2024). Furthermore, our\nmodel forecasts show that only China, France, and India would experience stable\nGDP growth.\n","authors":["Tianyi Wang","Rodney Beard","John Hawkins","Rohitash Chandra"],"pdf_url":"https://arxiv.org/pdf/2301.10874v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.09760v2","updated":"2024-10-17T11:49:06Z","published":"2024-10-13T07:36:45Z","title":"Targeted Vaccine: Safety Alignment for Large Language Models against\n  Harmful Fine-Tuning via Layer-wise Perturbation","summary":"  Harmful fine-tuning attack poses a serious threat to the online fine-tuning\nservice. Vaccine, a recent alignment-stage defense, applies uniform\nperturbation to all layers of embedding to make the model robust to the\nsimulated embedding drift. However, applying layer-wise uniform perturbation\nmay lead to excess perturbations for some particular safety-irrelevant layers,\nresulting in defense performance degradation and unnecessary memory\nconsumption. To address this limitation, we propose Targeted Vaccine\n(T-Vaccine), a memory-efficient safety alignment method that applies\nperturbation to only selected layers of the model. T-Vaccine follows two core\nsteps: First, it uses gradient norm as a statistical metric to identify the\nsafety-critical layers. Second, instead of applying uniform perturbation across\nall layers, T-Vaccine only applies perturbation to the safety-critical layers\nwhile keeping other layers frozen during training. Results show that T-Vaccine\noutperforms Vaccine in terms of both defense effectiveness and resource\nefficiency. Comparison with other defense baselines, e.g., RepNoise and TAR\nalso demonstrate the superiority of T-Vaccine. Notably, T-Vaccine is the first\ndefense that can address harmful fine-tuning issues for a 7B pre-trained models\ntrained on consumer GPUs with limited memory (e.g., RTX 4090). Our code is\navailable at https://github.com/Lslland/T-Vaccine.\n","authors":["Guozhi Liu","Weiwei Lin","Tiansheng Huang","Ruichao Mo","Qi Mu","Li Shen"],"pdf_url":"https://arxiv.org/pdf/2410.09760v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.13463v1","updated":"2024-10-17T11:47:56Z","published":"2024-10-17T11:47:56Z","title":"Truncating Trajectories in Monte Carlo Policy Evaluation: an Adaptive\n  Approach","summary":"  Policy evaluation via Monte Carlo (MC) simulation is at the core of many MC\nReinforcement Learning (RL) algorithms (e.g., policy gradient methods). In this\ncontext, the designer of the learning system specifies an interaction budget\nthat the agent usually spends by collecting trajectories of fixed length within\na simulator. However, is this data collection strategy the best option? To\nanswer this question, in this paper, we propose as a quality index a surrogate\nof the mean squared error of a return estimator that uses trajectories of\ndifferent lengths, i.e., \\emph{truncated}. Specifically, this surrogate shows\nthe sub-optimality of the fixed-length trajectory schedule. Furthermore, it\nsuggests that adaptive data collection strategies that spend the available\nbudget sequentially can allocate a larger portion of transitions in timesteps\nin which more accurate sampling is required to reduce the error of the final\nestimate. Building on these findings, we present an adaptive algorithm called\nRobust and Iterative Data collection strategy Optimization (RIDO). The main\nintuition behind RIDO is to split the available interaction budget into\nmini-batches. At each round, the agent determines the most convenient schedule\nof trajectories that minimizes an empirical and robust version of the surrogate\nof the estimator's error. After discussing the theoretical properties of our\nmethod, we conclude by assessing its performance across multiple domains. Our\nresults show that RIDO can adapt its trajectory schedule toward timesteps where\nmore sampling is required to increase the quality of the final estimation.\n","authors":["Riccardo Poiani","Nicole Nobili","Alberto Maria Metelli","Marcello Restelli"],"pdf_url":"https://arxiv.org/pdf/2410.13463v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.09250v2","updated":"2024-10-17T11:46:45Z","published":"2024-06-13T15:55:04Z","title":"MirrorCheck: Efficient Adversarial Defense for Vision-Language Models","summary":"  Vision-Language Models (VLMs) are becoming increasingly vulnerable to\nadversarial attacks as various novel attack strategies are being proposed\nagainst these models. While existing defenses excel in unimodal contexts, they\ncurrently fall short in safeguarding VLMs against adversarial threats. To\nmitigate this vulnerability, we propose a novel, yet elegantly simple approach\nfor detecting adversarial samples in VLMs. Our method leverages Text-to-Image\n(T2I) models to generate images based on captions produced by target VLMs.\nSubsequently, we calculate the similarities of the embeddings of both input and\ngenerated images in the feature space to identify adversarial samples.\nEmpirical evaluations conducted on different datasets validate the efficacy of\nour approach, outperforming baseline methods adapted from image classification\ndomains. Furthermore, we extend our methodology to classification tasks,\nshowcasing its adaptability and model-agnostic nature. Theoretical analyses and\nempirical findings also show the resilience of our approach against adaptive\nattacks, positioning it as an excellent defense mechanism for real-world\ndeployment against adversarial threats.\n","authors":["Samar Fares","Klea Ziu","Toluwani Aremu","Nikita Durasov","Martin Takáč","Pascal Fua","Karthik Nandakumar","Ivan Laptev"],"pdf_url":"https://arxiv.org/pdf/2406.09250v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.13461v1","updated":"2024-10-17T11:46:33Z","published":"2024-10-17T11:46:33Z","title":"Progressive Mixed-Precision Decoding for Efficient LLM Inference","summary":"  In spite of the great potential of large language models (LLMs) across\nvarious tasks, their deployment on resource-constrained devices remains\nchallenging due to their excessive computational and memory demands.\nQuantization has emerged as an effective solution by storing weights in reduced\nprecision. However, utilizing low precisions (i.e.~2/3-bit) to substantially\nalleviate the memory-boundedness of LLM decoding, still suffers from\nprohibitive performance drop. In this work, we argue that existing approaches\nfail to explore the diversity in computational patterns, redundancy, and\nsensitivity to approximations of the different phases of LLM inference,\nresorting to a uniform quantization policy throughout. Instead, we propose a\nnovel phase-aware method that selectively allocates precision during different\nphases of LLM inference, achieving both strong context extraction during\nprefill and efficient memory bandwidth utilization during decoding. To further\naddress the memory-boundedness of the decoding phase, we introduce Progressive\nMixed-Precision Decoding (PMPD), a technique that enables the gradual lowering\nof precision deeper in the generated sequence, together with a spectrum of\nprecision-switching schedulers that dynamically drive the precision-lowering\ndecisions in either task-adaptive or prompt-adaptive manner. Extensive\nevaluation across diverse language tasks shows that when targeting Nvidia GPUs,\nPMPD achieves 1.4$-$12.2$\\times$ speedup in matrix-vector multiplications over\nfp16 models, while when targeting an LLM-optimized NPU, our approach delivers a\nthroughput gain of 3.8$-$8.0$\\times$ over fp16 models and up to 1.54$\\times$\nover uniform quantization approaches while preserving the output quality.\n","authors":["Hao Mark Chen","Fuwen Tan","Alexandros Kouris","Royson Lee","Hongxiang Fan","Stylianos I. Venieris"],"pdf_url":"https://arxiv.org/pdf/2410.13461v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.16807v2","updated":"2024-10-17T11:46:18Z","published":"2024-06-24T17:19:34Z","title":"Beyond Thumbs Up/Down: Untangling Challenges of Fine-Grained Feedback\n  for Text-to-Image Generation","summary":"  Human feedback plays a critical role in learning and refining reward models\nfor text-to-image generation, but the optimal form the feedback should take for\nlearning an accurate reward function has not been conclusively established.\nThis paper investigates the effectiveness of fine-grained feedback which\ncaptures nuanced distinctions in image quality and prompt-alignment, compared\nto traditional coarse-grained feedback (for example, thumbs up/down or ranking\nbetween a set of options). While fine-grained feedback holds promise,\nparticularly for systems catering to diverse societal preferences, we show that\ndemonstrating its superiority to coarse-grained feedback is not automatic.\nThrough experiments on real and synthetic preference data, we surface the\ncomplexities of building effective models due to the interplay of model choice,\nfeedback type, and the alignment between human judgment and computational\ninterpretation. We identify key challenges in eliciting and utilizing\nfine-grained feedback, prompting a reassessment of its assumed benefits and\npracticality. Our findings -- e.g., that fine-grained feedback can lead to\nworse models for a fixed budget, in some settings; however, in controlled\nsettings with known attributes, fine grained rewards can indeed be more helpful\n-- call for careful consideration of feedback attributes and potentially beckon\nnovel modeling approaches to appropriately unlock the potential value of\nfine-grained feedback in-the-wild.\n","authors":["Katherine M. Collins","Najoung Kim","Yonatan Bitton","Verena Rieser","Shayegan Omidshafiei","Yushi Hu","Sherol Chen","Senjuti Dutta","Minsuk Chang","Kimin Lee","Youwei Liang","Georgina Evans","Sahil Singla","Gang Li","Adrian Weller","Junfeng He","Deepak Ramachandran","Krishnamurthy Dj Dvijotham"],"pdf_url":"https://arxiv.org/pdf/2406.16807v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.13460v1","updated":"2024-10-17T11:43:16Z","published":"2024-10-17T11:43:16Z","title":"Breaking the Manual Annotation Bottleneck: Creating a Comprehensive\n  Legal Case Criticality Dataset through Semi-Automated Labeling","summary":"  Predicting case criticality helps legal professionals in the court system\nmanage large volumes of case law. This paper introduces the Criticality\nPrediction dataset, a new resource for evaluating the potential influence of\nSwiss Federal Supreme Court decisions on future jurisprudence. Unlike existing\napproaches that rely on resource-intensive manual annotations, we\nsemi-automatically derive labels leading to a much larger dataset than\notherwise possible. Our dataset features a two-tier labeling system: (1) the\nLD-Label, which identifies cases published as Leading Decisions (LD), and (2)\nthe Citation-Label, which ranks cases by their citation frequency and recency.\nThis allows for a more nuanced evaluation of case importance. We evaluate\nseveral multilingual models, including fine-tuned variants and large language\nmodels, and find that fine-tuned models consistently outperform zero-shot\nbaselines, demonstrating the need for task-specific adaptation. Our\ncontributions include the introduction of this task and the release of a\nmultilingual dataset to the research community.\n","authors":["Ronja Stern","Ken Kawamura","Matthias Stürmer","Ilias Chalkidis","Joel Niklaus"],"pdf_url":"https://arxiv.org/pdf/2410.13460v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2405.03089v2","updated":"2024-10-17T11:38:11Z","published":"2024-05-06T00:58:23Z","title":"Structure-Preserving Network Compression Via Low-Rank Induced Training\n  Through Linear Layers Composition","summary":"  Deep Neural Networks (DNNs) have achieved remarkable success in addressing\nmany previously unsolvable tasks. However, the storage and computational\nrequirements associated with DNNs pose a challenge for deploying these trained\nmodels on resource-limited devices. Therefore, a plethora of compression and\npruning techniques have been proposed in recent years. Low-rank decomposition\ntechniques are among the approaches most utilized to address this problem.\nCompared to post-training compression, compression-promoted training is still\nunder-explored. In this paper, we present a theoretically-justified technique\ntermed Low-Rank Induced Training (LoRITa), that promotes low-rankness through\nthe composition of linear layers and compresses by using singular value\ntruncation. This is achieved without the need to change the structure at\ninference time or require constrained and/or additional optimization, other\nthan the standard weight decay regularization. Moreover, LoRITa eliminates the\nneed to (i) initialize with pre-trained models, (ii) specify rank selection\nprior to training, and (iii) compute SVD in each iteration. Our experimental\nresults (i) demonstrate the effectiveness of our approach using MNIST on Fully\nConnected Networks, CIFAR10 on Vision Transformers, and CIFAR10/100 and\nImageNet on Convolutional Neural Networks, and (ii) illustrate that we achieve\neither competitive or state-of-the-art results when compared to leading\nstructured pruning and low-rank training methods in terms of FLOPs and\nparameters drop. Our code is available at\n\\url{https://github.com/XitongSystem/LoRITa/tree/main}.\n","authors":["Xitong Zhang","Ismail R. Alkhouri","Rongrong Wang"],"pdf_url":"https://arxiv.org/pdf/2405.03089v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.13456v1","updated":"2024-10-17T11:34:07Z","published":"2024-10-17T11:34:07Z","title":"Unlocking Legal Knowledge: A Multilingual Dataset for Judicial\n  Summarization in Switzerland","summary":"  Legal research is a time-consuming task that most lawyers face on a daily\nbasis. A large part of legal research entails looking up relevant caselaw and\nbringing it in relation to the case at hand. Lawyers heavily rely on summaries\n(also called headnotes) to find the right cases quickly. However, not all\ndecisions are annotated with headnotes and writing them is time-consuming.\nAutomated headnote creation has the potential to make hundreds of thousands of\ndecisions more accessible for legal research in Switzerland alone. To kickstart\nthis, we introduce the Swiss Leading Decision Summarization ( SLDS) dataset, a\nnovel cross-lingual resource featuring 18K court rulings from the Swiss Federal\nSupreme Court (SFSC), in German, French, and Italian, along with German\nheadnotes. We fine-tune and evaluate three mT5 variants, along with proprietary\nmodels. Our analysis highlights that while proprietary models perform well in\nzero-shot and one-shot settings, fine-tuned smaller models still provide a\nstrong competitive edge. We publicly release the dataset to facilitate further\nresearch in multilingual legal summarization and the development of assistive\ntechnologies for legal professionals\n","authors":["Luca Rolshoven","Vishvaksenan Rasiah","Srinanda Brügger Bose","Matthias Stürmer","Joel Niklaus"],"pdf_url":"https://arxiv.org/pdf/2410.13456v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.07900v2","updated":"2024-10-17T11:33:40Z","published":"2024-10-10T13:29:12Z","title":"CL3: A Collaborative Learning Framework for the Medical Data Ensuring\n  Data Privacy in the Hyperconnected Environment","summary":"  In a hyperconnected environment, medical institutions are particularly\nconcerned with data privacy when sharing and transmitting sensitive patient\ninformation due to the risk of data breaches, where malicious actors could\nintercept sensitive information. A collaborative learning framework, including\ntransfer, federated, and incremental learning, can generate efficient, secure,\nand scalable models while requiring less computation, maintaining patient data\nprivacy, and ensuring an up-to-date model. This study aims to address the\ndetection of COVID-19 using chest X-ray images through a proposed collaborative\nlearning framework called CL3. Initially, transfer learning is employed,\nleveraging knowledge from a pre-trained model as the starting global model.\nLocal models from different medical institutes are then integrated, and a new\nglobal model is constructed to adapt to any data drift observed in the local\nmodels. Additionally, incremental learning is considered, allowing continuous\nadaptation to new medical data without forgetting previously learned\ninformation. Experimental results demonstrate that the CL3 framework achieved a\nglobal accuracy of 89.99% when using Xception with a batch size of 16 after\nbeing trained for six federated communication rounds. A demo of the CL3\nframework is available at\nhttps://github.com/zavidparvez/CL3-Collaborative-Approach to ensure\nreproducibility.\n","authors":["Mohamamd Zavid Parvez","Rafiqul Islam","Md Zahidul Islam"],"pdf_url":"https://arxiv.org/pdf/2410.07900v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2312.01522v3","updated":"2024-10-17T11:33:09Z","published":"2023-12-03T22:44:04Z","title":"G2D: From Global to Dense Radiography Representation Learning via\n  Vision-Language Pre-training","summary":"  Recently, medical vision-language pre-training (VLP) has reached substantial\nprogress to learn global visual representation from medical images and their\npaired radiology reports. However, medical imaging tasks in real world usually\nrequire finer granularity in visual features. These tasks include visual\nlocalization tasks (e.g., semantic segmentation, object detection) and visual\ngrounding task. Yet, current medical VLP methods face challenges in learning\nthese fine-grained features, as they primarily focus on brute-force alignment\nbetween image patches and individual text tokens for local visual feature\nlearning, which is suboptimal for downstream dense prediction tasks. In this\nwork, we propose a new VLP framework, named \\textbf{G}lobal to \\textbf{D}ense\nlevel representation learning (G2D) that achieves significantly improved\ngranularity and more accurate grounding for the learned features, compared to\nexisting medical VLP approaches. In particular, G2D learns dense and\nsemantically-grounded image representations via a pseudo segmentation task\nparallel with the global vision-language alignment. Notably, generating pseudo\nsegmentation targets does not incur extra trainable parameters: they are\nobtained on the fly during VLP with a parameter-free processor. G2D achieves\nsuperior performance across 6 medical imaging tasks and 25 diseases,\nparticularly in semantic segmentation, which necessitates fine-grained,\nsemantically-grounded image features. In this task, G2D surpasses peer models\neven when fine-tuned with just 1\\% of the training data, compared to the 100\\%\nused by these models. The code will be released upon acceptance.\n","authors":["Che Liu","Cheng Ouyang","Sibo Cheng","Anand Shah","Wenjia Bai","Rossella Arcucci"],"pdf_url":"https://arxiv.org/pdf/2312.01522v3.pdf","comment":"Accepted by NeurIPS2024"},{"id":"http://arxiv.org/abs/2410.13448v1","updated":"2024-10-17T11:21:47Z","published":"2024-10-17T11:21:47Z","title":"Fast Estimation of Partial Dependence Functions using Trees","summary":"  Many existing interpretation methods are based on Partial Dependence (PD)\nfunctions that, for a pre-trained machine learning model, capture how a subset\nof the features affects the predictions by averaging over the remaining\nfeatures. Notable methods include Shapley additive explanations (SHAP) which\ncomputes feature contributions based on a game theoretical interpretation and\nPD plots (i.e., 1-dim PD functions) that capture average marginal main effects.\nRecent work has connected these approaches using a functional decomposition and\nargues that SHAP values can be misleading since they merge main and interaction\neffects into a single local effect. A major advantage of SHAP compared to other\nPD-based interpretations, however, has been the availability of fast estimation\ntechniques, such as \\texttt{TreeSHAP}. In this paper, we propose a new\ntree-based estimator, \\texttt{FastPD}, which efficiently estimates arbitrary PD\nfunctions. We show that \\texttt{FastPD} consistently estimates the desired\npopulation quantity -- in contrast to path-dependent \\texttt{TreeSHAP} which is\ninconsistent when features are correlated. For moderately deep trees,\n\\texttt{FastPD} improves the complexity of existing methods from quadratic to\nlinear in the number of observations. By estimating PD functions for arbitrary\nfeature subsets, \\texttt{FastPD} can be used to extract PD-based\ninterpretations such as SHAP, PD plots and higher order interaction effects.\n","authors":["Jinyang Liu","Tessa Steensgaard","Marvin N. Wright","Niklas Pfister","Munir Hiabu"],"pdf_url":"https://arxiv.org/pdf/2410.13448v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.13445v1","updated":"2024-10-17T11:19:44Z","published":"2024-10-17T11:19:44Z","title":"Parameter-efficient Adaptation of Multilingual Multimodal Models for\n  Low-resource ASR","summary":"  Automatic speech recognition (ASR) for low-resource languages remains a\nchallenge due to the scarcity of labeled training data. Parameter-efficient\nfine-tuning and text-only adaptation are two popular methods that have been\nused to address such low-resource settings. In this work, we investigate how\nthese techniques can be effectively combined using a multilingual multimodal\nmodel like SeamlessM4T. Multimodal models are able to leverage unlabeled text\nvia text-only adaptation with further parameter-efficient ASR fine-tuning, thus\nboosting ASR performance. We also show cross-lingual transfer from a\nhigh-resource language, achieving up to a relative 17% WER reduction over a\nbaseline in a zero-shot setting without any labeled speech.\n","authors":["Abhishek Gupta","Amruta Parulekar","Sameep Chattopadhyay","Preethi Jyothi"],"pdf_url":"https://arxiv.org/pdf/2410.13445v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.05966v2","updated":"2024-10-17T11:15:39Z","published":"2024-10-08T12:16:12Z","title":"FLOPS: Forward Learning with OPtimal Sampling","summary":"  Given the limitations of backpropagation, perturbation-based gradient\ncomputation methods have recently gained focus for learning with only forward\npasses, also referred to as queries. Conventional forward learning consumes\nenormous queries on each data point for accurate gradient estimation through\nMonte Carlo sampling, which hinders the scalability of those algorithms.\nHowever, not all data points deserve equal queries for gradient estimation. In\nthis paper, we study the problem of improving the forward learning efficiency\nfrom a novel perspective: how to reduce the gradient estimation variance with\nminimum cost? For this, we propose to allocate the optimal number of queries\nover each data in one batch during training to achieve a good balance between\nestimation accuracy and computational efficiency. Specifically, with a\nsimplified proxy objective and a reparameterization technique, we derive a\nnovel plug-and-play query allocator with minimal parameters. Theoretical\nresults are carried out to verify its optimality. We conduct extensive\nexperiments for fine-tuning Vision Transformers on various datasets and further\ndeploy the allocator to two black-box applications: prompt tuning and\nmultimodal alignment for foundation models. All findings demonstrate that our\nproposed allocator significantly enhances the scalability of forward-learning\nalgorithms, paving the way for real-world applications.\n","authors":["Tao Ren","Zishi Zhang","Jinyang Jiang","Guanghao Li","Zeliang Zhang","Mingqian Feng","Yijie Peng"],"pdf_url":"https://arxiv.org/pdf/2410.05966v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.09747v2","updated":"2024-10-17T11:14:37Z","published":"2024-10-13T06:53:58Z","title":"t-READi: Transformer-Powered Robust and Efficient Multimodal Inference\n  for Autonomous Driving","summary":"  Given the wide adoption of multimodal sensors (e.g., camera, lidar, radar) by\nautonomous vehicles (AVs), deep analytics to fuse their outputs for a robust\nperception become imperative. However, existing fusion methods often make two\nassumptions rarely holding in practice: i) similar data distributions for all\ninputs and ii) constant availability for all sensors. Because, for example,\nlidars have various resolutions and failures of radars may occur, such\nvariability often results in significant performance degradation in fusion. To\nthis end, we present tREADi, an adaptive inference system that accommodates the\nvariability of multimodal sensory data and thus enables robust and efficient\nperception. t-READi identifies variation-sensitive yet structure-specific model\nparameters; it then adapts only these parameters while keeping the rest intact.\nt-READi also leverages a cross-modality contrastive learning method to\ncompensate for the loss from missing modalities. Both functions are implemented\nto maintain compatibility with existing multimodal deep fusion methods. The\nextensive experiments evidently demonstrate that compared with the status quo\napproaches, t-READi not only improves the average inference accuracy by more\nthan 6% but also reduces the inference latency by almost 15x with the cost of\nonly 5% extra memory overhead in the worst case under realistic data and modal\nvariations.\n","authors":["Pengfei Hu","Yuhang Qian","Tianyue Zheng","Ang Li","Zhe Chen","Yue Gao","Xiuzhen Cheng","Jun Luo"],"pdf_url":"https://arxiv.org/pdf/2410.09747v2.pdf","comment":"14 pages, 16 figures"},{"id":"http://arxiv.org/abs/2410.13439v1","updated":"2024-10-17T11:12:55Z","published":"2024-10-17T11:12:55Z","title":"Similarity-Dissimilarity Loss with Supervised Contrastive Learning for\n  Multi-label Classification","summary":"  Supervised contrastive learning has been explored in making use of label\ninformation for multi-label classification, but determining positive samples in\nmulti-label scenario remains challenging. Previous studies have examined\nstrategies for identifying positive samples, considering label overlap\nproportion between anchors and samples. However, they ignore various relations\nbetween given anchors and samples, as well as how to dynamically adjust the\nweights in contrastive loss functions based on different relations, leading to\ngreat ambiguity. In this paper, we introduce five distinct relations between\nmulti-label samples and propose a Similarity-Dissimilarity Loss with\ncontrastive learning for multi-label classification. Our loss function\nre-weights the loss by computing the similarity and dissimilarity between\npositive samples and a given anchor based on the introduced relations. We\nmainly conduct experiments for multi-label text classification on MIMIC\ndatasets, then further extend the evaluation on MS-COCO. The Experimental\nresults show that our proposed loss effectively improves the performance on all\nencoders under supervised contrastive learning paradigm, demonstrating its\neffectiveness and robustness.\n","authors":["Guangming Huang","Yunfei Long","Cunjin Luo","Sheng Liu"],"pdf_url":"https://arxiv.org/pdf/2410.13439v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.13431v1","updated":"2024-10-17T10:54:55Z","published":"2024-10-17T10:54:55Z","title":"Solving Prior Distribution Mismatch in Diffusion Models via Optimal\n  Transport","summary":"  In recent years, the knowledge surrounding diffusion models(DMs) has grown\nsignificantly, though several theoretical gaps remain. Particularly noteworthy\nis prior error, defined as the discrepancy between the termination distribution\nof the forward process and the initial distribution of the reverse process. To\naddress these deficiencies, this paper explores the deeper relationship between\noptimal transport(OT) theory and DMs with discrete initial distribution.\nSpecifically, we demonstrate that the two stages of DMs fundamentally involve\ncomputing time-dependent OT. However, unavoidable prior error result in\ndeviation during the reverse process under quadratic transport cost. By proving\nthat as the diffusion termination time increases, the probability flow\nexponentially converges to the gradient of the solution to the classical\nMonge-Amp\\`ere equation, we establish a vital link between these fields.\nTherefore, static OT emerges as the most intrinsic single-step method for\nbridging this theoretical potential gap. Additionally, we apply these insights\nto accelerate sampling in both unconditional and conditional generation\nscenarios. Experimental results across multiple image datasets validate the\neffectiveness of our approach.\n","authors":["Zhanpeng Wang","Shenghao Li","Chen Wang","Shuting Cao","Na Lei","Zhongxuan Luo"],"pdf_url":"https://arxiv.org/pdf/2410.13431v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2305.19674v2","updated":"2024-10-17T10:51:50Z","published":"2023-05-31T09:15:39Z","title":"Online-to-PAC Conversions: Generalization Bounds via Regret Analysis","summary":"  We present a new framework for deriving bounds on the generalization bound of\nstatistical learning algorithms from the perspective of online learning.\nSpecifically, we construct an online learning game called the \"generalization\ngame\", where an online learner is trying to compete with a fixed statistical\nlearning algorithm in predicting the sequence of generalization gaps on a\ntraining set of i.i.d. data points. We establish a connection between the\nonline and statistical learning setting by showing that the existence of an\nonline learning algorithm with bounded regret in this game implies a bound on\nthe generalization error of the statistical learning algorithm, up to a\nmartingale concentration term that is independent of the complexity of the\nstatistical learning method. This technique allows us to recover several\nstandard generalization bounds including a range of PAC-Bayesian and\ninformation-theoretic guarantees, as well as generalizations thereof.\n","authors":["Gábor Lugosi","Gergely Neu"],"pdf_url":"https://arxiv.org/pdf/2305.19674v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.13416v1","updated":"2024-10-17T10:35:18Z","published":"2024-10-17T10:35:18Z","title":"Partially Trained Graph Convolutional Networks Resist Oversmoothing","summary":"  In this work we investigate an observation made by Kipf \\& Welling, who\nsuggested that untrained GCNs can generate meaningful node embeddings. In\nparticular, we investigate the effect of training only a single layer of a GCN,\nwhile keeping the rest of the layers frozen. We propose a basis on which the\neffect of the untrained layers and their contribution to the generation of\nembeddings can be predicted. Moreover, we show that network width influences\nthe dissimilarity of node embeddings produced after the initial node features\npass through the untrained part of the model. Additionally, we establish a\nconnection between partially trained GCNs and oversmoothing, showing that they\nare capable of reducing it. We verify our theoretical results experimentally\nand show the benefits of using deep networks that resist oversmoothing, in a\n``cold start'' scenario, where there is a lack of feature information for\nunlabeled nodes.\n","authors":["Dimitrios Kelesis","Dimitris Fotakis","Georgios Paliouras"],"pdf_url":"https://arxiv.org/pdf/2410.13416v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2407.19523v2","updated":"2024-10-17T10:27:49Z","published":"2024-07-28T16:23:55Z","title":"Robust Fast Adaptation from Adversarially Explicit Task Distribution\n  Generation","summary":"  Meta-learning is a practical learning paradigm to transfer skills across\ntasks from a few examples. Nevertheless, the existence of task distribution\nshifts tends to weaken meta-learners' generalization capability, particularly\nwhen the task distribution is naively hand-crafted or based on simple priors\nthat fail to cover typical scenarios sufficiently. Here, we consider explicitly\ngenerative modeling task distributions placed over task identifiers and propose\nrobustifying fast adaptation from adversarial training. Our approach, which can\nbe interpreted as a model of a Stackelberg game, not only uncovers the task\nstructure during problem-solving from an explicit generative model but also\ntheoretically increases the adaptation robustness in worst cases. This work has\npractical implications, particularly in dealing with task distribution shifts\nin meta-learning, and contributes to theoretical insights in the field. Our\nmethod demonstrates its robustness in the presence of task subpopulation shifts\nand improved performance over SOTA baselines in extensive experiments. The\nproject is available at https://sites.google.com/view/ar-metalearn.\n","authors":["Cheems Wang","Yiqin Lv","Yixiu Mao","Yun Qu","Yi Xu","Xiangyang Ji"],"pdf_url":"https://arxiv.org/pdf/2407.19523v2.pdf","comment":"The project is available at\n  https://sites.google.com/view/ar-metalearn"},{"id":"http://arxiv.org/abs/2410.13412v1","updated":"2024-10-17T10:21:28Z","published":"2024-10-17T10:21:28Z","title":"RAMPA: Robotic Augmented Reality for Machine Programming and Automation","summary":"  As robotics continue to enter various sectors beyond traditional industrial\napplications, the need for intuitive robot training and interaction systems\nbecomes increasingly more important. This paper introduces Robotic Augmented\nReality for Machine Programming (RAMPA), a system that utilizes the\ncapabilities of state-of-the-art and commercially available AR headsets, e.g.,\nMeta Quest 3, to facilitate the application of Programming from Demonstration\n(PfD) approaches on industrial robotic arms, such as Universal Robots UR10. Our\napproach enables in-situ data recording, visualization, and fine-tuning of\nskill demonstrations directly within the user's physical environment. RAMPA\naddresses critical challenges of PfD, such as safety concerns, programming\nbarriers, and the inefficiency of collecting demonstrations on the actual\nhardware. The performance of our system is evaluated against the traditional\nmethod of kinesthetic control in teaching three different robotic manipulation\ntasks and analyzed with quantitative metrics, measuring task performance and\ncompletion time, trajectory smoothness, system usability, user experience, and\ntask load using standardized surveys. Our findings indicate a substantial\nadvancement in how robotic tasks are taught and refined, promising improvements\nin operational safety, efficiency, and user engagement in robotic programming.\n","authors":["Fatih Dogangun","Serdar Bahar","Yigit Yildirim","Bora Toprak Temir","Emre Ugur","Mustafa Doga Dogan"],"pdf_url":"https://arxiv.org/pdf/2410.13412v1.pdf","comment":"This work has been submitted to the IEEE for possible publication.\n  Copyright may be transferred without notice, after which this version may no\n  longer be accessible"},{"id":"http://arxiv.org/abs/2408.09490v2","updated":"2024-10-17T10:15:38Z","published":"2024-08-18T14:10:34Z","title":"Leveraging Invariant Principle for Heterophilic Graph Structure\n  Distribution Shifts","summary":"  Heterophilic Graph Neural Networks (HGNNs) have shown promising results for\nsemi-supervised learning tasks on graphs. Notably, most real-world heterophilic\ngraphs are composed of a mixture of nodes with different neighbor patterns,\nexhibiting local node-level homophilic and heterophilic structures. However,\nexisting works are only devoted to designing better HGNN backbones or\narchitectures for node classification tasks on heterophilic and homophilic\ngraph benchmarks simultaneously, and their analyses of HGNN performance with\nrespect to nodes are only based on the determined data distribution without\nexploring the effect caused by this structural difference between training and\ntesting nodes. How to learn invariant node representations on heterophilic\ngraphs to handle this structure difference or distribution shifts remains\nunexplored. In this paper, we first discuss the limitations of previous\ngraph-based invariant learning methods from the perspective of data\naugmentation. Then, we propose \\textbf{HEI}, a framework capable of generating\ninvariant node representations through incorporating heterophily information to\ninfer latent environments without augmentation, which are then used for\ninvariant prediction, under heterophilic graph structure distribution shifts.\nWe theoretically show that our proposed method can achieve guaranteed\nperformance under heterophilic graph structure distribution shifts. Extensive\nexperiments on various benchmarks and backbones can also demonstrate the\neffectiveness of our method compared with existing state-of-the-art baselines.\n","authors":["Jinluan Yang","Zhengyu Chen","Teng Xiao","Wenqiao Zhang","Yong Lin","Kun Kuang"],"pdf_url":"https://arxiv.org/pdf/2408.09490v2.pdf","comment":"15 pages, 7 figures"},{"id":"http://arxiv.org/abs/2410.13408v1","updated":"2024-10-17T10:14:52Z","published":"2024-10-17T10:14:52Z","title":"MoR: Mixture of Ranks for Low-Rank Adaptation Tuning","summary":"  Low-Rank Adaptation (LoRA) drives research to align its performance with full\nfine-tuning. However, significant challenges remain: (1) Simply increasing the\nrank size of LoRA does not effectively capture high-rank information, which\nleads to a performance bottleneck.(2) MoE-style LoRA methods substantially\nincrease parameters and inference latency, contradicting the goals of efficient\nfine-tuning and ease of application. To address these challenges, we introduce\nMixture of Ranks (MoR), which learns rank-specific information for different\ntasks based on input and efficiently integrates multi-rank information. We\nfirstly propose a new framework that equates the integration of multiple LoRAs\nto expanding the rank of LoRA. Moreover, we hypothesize that low-rank LoRA\nalready captures sufficient intrinsic information, and MoR can derive high-rank\ninformation through mathematical transformations of the low-rank components.\nThus, MoR can reduces the learning difficulty of LoRA and enhances its\nmulti-task capabilities. MoR achieves impressive results, with MoR delivering a\n1.31\\% performance improvement while using only 93.93\\% of the parameters\ncompared to baseline methods.\n","authors":["Chuanyu Tang","Yilong Chen","Zhenyu Zhang","Junyuan Shang","Wenyuan Zhang","Yong Huang","Tingwen Liu"],"pdf_url":"https://arxiv.org/pdf/2410.13408v1.pdf","comment":"11 pages, 7 figures"},{"id":"http://arxiv.org/abs/2410.00510v2","updated":"2024-10-17T10:12:54Z","published":"2024-10-01T08:48:05Z","title":"Advancing RVFL networks: Robust classification with the HawkEye loss\n  function","summary":"  Random vector functional link (RVFL), a variant of single-layer feedforward\nneural network (SLFN), has garnered significant attention due to its lower\ncomputational cost and robustness to overfitting. Despite its advantages, the\nRVFL network's reliance on the square error loss function makes it highly\nsensitive to outliers and noise, leading to degraded model performance in\nreal-world applications. To remedy it, we propose the incorporation of the\nHawkEye loss (H-loss) function into the RVFL framework. The H-loss function\nfeatures nice mathematical properties, including smoothness and boundedness,\nwhile simultaneously incorporating an insensitive zone. Each characteristic\nbrings its own advantages: 1) Boundedness limits the impact of extreme errors,\nenhancing robustness against outliers; 2) Smoothness facilitates the use of\ngradient-based optimization algorithms, ensuring stable and efficient\nconvergence; and 3) The insensitive zone mitigates the effect of minor\ndiscrepancies and noise. Leveraging the H-loss function, we embed it into the\nRVFL framework and develop a novel robust RVFL model termed H-RVFL. Notably,\nthis work addresses a significant gap, as no bounded loss function has been\nincorporated into RVFL to date. The non-convex optimization of the proposed\nH-RVFL is effectively addressed by the Nesterov accelerated gradient (NAG)\nalgorithm, whose computational complexity is also discussed. The proposed\nH-RVFL model's effectiveness is validated through extensive experiments on $40$\nbenchmark datasets from UCI and KEEL repositories, with and without label\nnoise. The results highlight significant improvements in robustness and\nefficiency, establishing the H-RVFL model as a powerful tool for applications\nin noisy and outlier-prone environments.\n","authors":["Mushir Akhtar","Ritik Mishra","M. Tanveer","Mohd. Arshad"],"pdf_url":"https://arxiv.org/pdf/2410.00510v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.13404v1","updated":"2024-10-17T10:01:22Z","published":"2024-10-17T10:01:22Z","title":"Predicting Breast Cancer Survival: A Survival Analysis Approach Using\n  Log Odds and Clinical Variables","summary":"  Breast cancer remains a significant global health challenge, with prognosis\nand treatment decisions largely dependent on clinical characteristics. Accurate\nprediction of patient outcomes is crucial for personalized treatment\nstrategies. This study employs survival analysis techniques, including Cox\nproportional hazards and parametric survival models, to enhance the prediction\nof the log odds of survival in breast cancer patients. Clinical variables such\nas tumor size, hormone receptor status, HER2 status, age, and treatment history\nwere analyzed to assess their impact on survival outcomes. Data from 1557\nbreast cancer patients were obtained from a publicly available dataset provided\nby the University College Hospital, Ibadan, Nigeria. This dataset was\npreprocessed and analyzed using both univariate and multivariate approaches to\nevaluate survival outcomes. Kaplan-Meier survival curves were generated to\nvisualize survival probabilities, while the Cox proportional hazards model\nidentified key risk factors influencing mortality. The results showed that\nolder age, larger tumor size, and HER2-positive status were significantly\nassociated with an increased risk of mortality. In contrast, estrogen receptor\npositivity and breast-conserving surgery were linked to better survival\noutcomes. The findings suggest that integrating these clinical variables into\npredictive models improvesthe accuracy of survival predictions, helping to\nidentify high-risk patients who may benefit from more aggressive interventions.\nThis study demonstrates the potential of survival analysis in optimizing breast\ncancer care, particularly in resource-limited settings. Future research should\nfocus on integrating genomic data and real-world clinical outcomes to further\nrefine these models.\n","authors":["Opeyemi Sheu Alamu","Bismar Jorge Gutierrez Choque","Syed Wajeeh Abbs Rizvi","Samah Badr Hammed","Isameldin Elamin Medani","Md Kamrul Siam","Waqar Ahmad Tahir"],"pdf_url":"https://arxiv.org/pdf/2410.13404v1.pdf","comment":"17 pages"},{"id":"http://arxiv.org/abs/2406.02447v2","updated":"2024-10-17T09:52:10Z","published":"2024-06-04T16:12:27Z","title":"Reducing Bias in Federated Class-Incremental Learning with Hierarchical\n  Generative Prototypes","summary":"  Federated Learning (FL) aims at unburdening the training of deep models by\ndistributing computation across multiple devices (clients) while safeguarding\ndata privacy. On top of that, Federated Continual Learning (FCL) also accounts\nfor data distribution evolving over time, mirroring the dynamic nature of\nreal-world environments. In this work, we shed light on the Incremental and\nFederated biases that naturally emerge in FCL. While the former is a known\nproblem in Continual Learning, stemming from the prioritization of recently\nintroduced classes, the latter (i.e., the bias towards local distributions)\nremains relatively unexplored. Our proposal constrains both biases in the last\nlayer by efficiently fine-tuning a pre-trained backbone using learnable\nprompts, resulting in clients that produce less biased representations and more\nbiased classifiers. Therefore, instead of solely relying on parameter\naggregation, we also leverage generative prototypes to effectively balance the\npredictions of the global model. Our method improves on the current State Of\nThe Art, providing an average increase of +7.9% in accuracy.\n","authors":["Riccardo Salami","Pietro Buzzega","Matteo Mosconi","Mattia Verasani","Simone Calderara"],"pdf_url":"https://arxiv.org/pdf/2406.02447v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2405.07943v2","updated":"2024-10-17T09:48:06Z","published":"2024-05-13T17:18:08Z","title":"Decision Mamba Architectures","summary":"  Recent advancements in imitation learning have been largely fueled by the\nintegration of sequence models, which provide a structured flow of information\nto effectively mimic task behaviours. Currently, Decision Transformer (DT) and\nsubsequently, the Hierarchical Decision Transformer (HDT), presented\nTransformer-based approaches to learn task policies. Recently, the Mamba\narchitecture has shown to outperform Transformers across various task domains.\nIn this work, we introduce two novel methods, Decision Mamba (DM) and\nHierarchical Decision Mamba (HDM), aimed at enhancing the performance of the\nTransformer models. Through extensive experimentation across diverse\nenvironments such as OpenAI Gym and D4RL, leveraging varying demonstration data\nsets, we demonstrate the superiority of Mamba models over their Transformer\ncounterparts in a majority of tasks. Results show that DM outperforms other\nmethods in most settings. The code can be found at\nhttps://github.com/meowatthemoon/DecisionMamba.\n","authors":["André Correia","Luís A. Alexandre"],"pdf_url":"https://arxiv.org/pdf/2405.07943v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.13390v1","updated":"2024-10-17T09:41:54Z","published":"2024-10-17T09:41:54Z","title":"A Self-Constructing Multi-Expert Fuzzy System for High-dimensional Data\n  Classification","summary":"  Fuzzy Neural Networks (FNNs) are effective machine learning models for\nclassification tasks, commonly based on the Takagi-Sugeno-Kang (TSK) fuzzy\nsystem. However, when faced with high-dimensional data, especially with noise,\nFNNs encounter challenges such as vanishing gradients, excessive fuzzy rules,\nand limited access to prior knowledge. To address these challenges, we propose\na novel fuzzy system, the Self-Constructing Multi-Expert Fuzzy System\n(SOME-FS). It combines two learning strategies: mixed structure learning and\nmulti-expert advanced learning. The former enables each base classifier to\neffectively determine its structure without requiring prior knowledge, while\nthe latter tackles the issue of vanishing gradients by enabling each rule to\nfocus on its local region, thereby enhancing the robustness of the fuzzy\nclassifiers. The overall ensemble architecture enhances the stability and\nprediction performance of the fuzzy system. Our experimental results\ndemonstrate that the proposed SOME-FS is effective in high-dimensional tabular\ndata, especially in dealing with uncertainty. Moreover, our stable rule mining\nprocess can identify concise and core rules learned by the SOME-FS.\n","authors":["Yingtao Ren","Yu-Cheng Chang","Thomas Do","Zehong Cao","Chin-Teng Lin"],"pdf_url":"https://arxiv.org/pdf/2410.13390v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.13381v1","updated":"2024-10-17T09:36:01Z","published":"2024-10-17T09:36:01Z","title":"Learning Counterfactual Distributions via Kernel Nearest Neighbors","summary":"  Consider a setting with multiple units (e.g., individuals, cohorts,\ngeographic locations) and outcomes (e.g., treatments, times, items), where the\ngoal is to learn a multivariate distribution for each unit-outcome entry, such\nas the distribution of a user's weekly spend and engagement under a specific\nmobile app version. A common challenge is the prevalence of missing not at\nrandom data, where observations are available only for certain unit-outcome\ncombinations and the observation availability can be correlated with the\nproperties of distributions themselves, i.e., there is unobserved confounding.\nAn additional challenge is that for any observed unit-outcome entry, we only\nhave a finite number of samples from the underlying distribution. We tackle\nthese two challenges by casting the problem into a novel distributional matrix\ncompletion framework and introduce a kernel based distributional generalization\nof nearest neighbors to estimate the underlying distributions. By leveraging\nmaximum mean discrepancies and a suitable factor model on the kernel mean\nembeddings of the underlying distributions, we establish consistent recovery of\nthe underlying distributions even when data is missing not at random and\npositivity constraints are violated. Furthermore, we demonstrate that our\nnearest neighbors approach is robust to heteroscedastic noise, provided we have\naccess to two or more measurements for the observed unit-outcome entries, a\nrobustness not present in prior works on nearest neighbors with single\nmeasurements.\n","authors":["Kyuseong Choi","Jacob Feitelberg","Anish Agarwal","Raaz Dwivedi"],"pdf_url":"https://arxiv.org/pdf/2410.13381v1.pdf","comment":"33 pages, 2 figures"},{"id":"http://arxiv.org/abs/2410.13376v1","updated":"2024-10-17T09:26:14Z","published":"2024-10-17T09:26:14Z","title":"Data-Augmented Predictive Deep Neural Network: Enhancing the\n  extrapolation capabilities of non-intrusive surrogate models","summary":"  Numerically solving a large parametric nonlinear dynamical system is\nchallenging due to its high complexity and the high computational costs. In\nrecent years, machine-learning-aided surrogates are being actively researched.\nHowever, many methods fail in accurately generalizing in the entire time\ninterval $[0, T]$, when the training data is available only in a training time\ninterval $[0, T_0]$, with $T_0<T$.\n  To improve the extrapolation capabilities of the surrogate models in the\nentire time domain, we propose a new deep learning framework, where kernel\ndynamic mode decomposition (KDMD) is employed to evolve the dynamics of the\nlatent space generated by the encoder part of a convolutional autoencoder\n(CAE). After adding the KDMD-decoder-extrapolated data into the original data\nset, we train the CAE along with a feed-forward deep neural network using the\naugmented data. The trained network can predict future states outside the\ntraining time interval at any out-of-training parameter samples. The proposed\nmethod is tested on two numerical examples: a FitzHugh-Nagumo model and a model\nof incompressible flow past a cylinder. Numerical results show accurate and\nfast prediction performance in both the time and the parameter domain.\n","authors":["Shuwen Sun","Lihong Feng","Peter Benner"],"pdf_url":"https://arxiv.org/pdf/2410.13376v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.13373v1","updated":"2024-10-17T09:23:53Z","published":"2024-10-17T09:23:53Z","title":"Addressing Heterogeneity and Heterophily in Graphs: A Heterogeneous\n  Heterophilic Spectral Graph Neural Network","summary":"  Graph Neural Networks (GNNs) have garnered significant scholarly attention\nfor their powerful capabilities in modeling graph structures. Despite this, two\nprimary challenges persist: heterogeneity and heterophily. Existing studies\noften address heterogeneous and heterophilic graphs separately, leaving a\nresearch gap in the understanding of heterogeneous heterophilic graphs-those\nthat feature diverse node or relation types with dissimilar connected nodes. To\naddress this gap, we investigate the application of spectral graph filters\nwithin heterogeneous graphs. Specifically, we propose a Heterogeneous\nHeterophilic Spectral Graph Neural Network (H2SGNN), which employs a\ndual-module approach: local independent filtering and global hybrid filtering.\nThe local independent filtering module applies polynomial filters to each\nsubgraph independently to adapt to different homophily, while the global hybrid\nfiltering module captures interactions across different subgraphs. Extensive\nempirical evaluations on four real-world datasets demonstrate the superiority\nof H2SGNN compared to state-of-the-art methods.\n","authors":["Kangkang Lu","Yanhua Yu","Zhiyong Huang","Jia Li","Yuling Wang","Meiyu Liang","Xiting Qin","Yimeng Ren","Tat-Seng Chua","Xidian Wang"],"pdf_url":"https://arxiv.org/pdf/2410.13373v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.13363v1","updated":"2024-10-17T09:15:09Z","published":"2024-10-17T09:15:09Z","title":"Statistical testing on generative AI anomaly detection tools in\n  Alzheimer's Disease diagnosis","summary":"  Alzheimer's Disease is challenging to diagnose due to our limited\nunderstanding of its mechanism and large heterogeneity among patients.\nNeurodegeneration is studied widely as a biomarker for clinical diagnosis,\nwhich can be measured from time series MRI progression. On the other hand,\ngenerative AI has shown promise in anomaly detection in medical imaging and\nused for tasks including tumor detection. However, testing the reliability of\nsuch data-driven methods is non-trivial due to the issue of double-dipping in\nhypothesis testing. In this work, we propose to solve this issue with selective\ninference and develop a reliable generative AI method for Alzheimer's\nprediction. We show that compared to traditional statistical methods with\nhighly inflated p-values, selective inference successfully controls the false\ndiscovery rate under the desired alpha level while retaining statistical power.\nIn practice, our pipeline could assist clinicians in Alzheimer's diagnosis and\nearly intervention.\n","authors":["Rosemary He","Ichiro Takeuchi"],"pdf_url":"https://arxiv.org/pdf/2410.13363v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.13360v1","updated":"2024-10-17T09:10:26Z","published":"2024-10-17T09:10:26Z","title":"Remember, Retrieve and Generate: Understanding Infinite Visual Concepts\n  as Your Personalized Assistant","summary":"  The development of large language models (LLMs) has significantly enhanced\nthe capabilities of multimodal LLMs (MLLMs) as general assistants. However,\nlack of user-specific knowledge still restricts their application in human's\ndaily life. In this paper, we introduce the Retrieval Augmented Personalization\n(RAP) framework for MLLMs' personalization. Starting from a general MLLM, we\nturn it into a personalized assistant in three steps. (a) Remember: We design a\nkey-value database to store user-related information, e.g., user's name, avatar\nand other attributes. (b) Retrieve: When the user initiates a conversation, RAP\nwill retrieve relevant information from the database using a multimodal\nretriever. (c) Generate: The input query and retrieved concepts' information\nare fed into MLLMs to generate personalized, knowledge-augmented responses.\nUnlike previous methods, RAP allows real-time concept editing via updating the\nexternal database. To further improve generation quality and alignment with\nuser-specific information, we design a pipeline for data collection and create\na specialized dataset for personalized training of MLLMs. Based on the dataset,\nwe train a series of MLLMs as personalized multimodal assistants. By\npretraining on large-scale dataset, RAP-MLLMs can generalize to infinite visual\nconcepts without additional finetuning. Our models demonstrate outstanding\nflexibility and generation quality across a variety of tasks, such as\npersonalized image captioning, question answering and visual recognition. The\ncode, data and models are available at https://github.com/Hoar012/RAP-MLLM.\n","authors":["Haoran Hao","Jiaming Han","Changsheng Li","Yu-Feng Li","Xiangyu Yue"],"pdf_url":"https://arxiv.org/pdf/2410.13360v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.13351v1","updated":"2024-10-17T09:02:28Z","published":"2024-10-17T09:02:28Z","title":"Representation Learning of Structured Data for Medical Foundation Models","summary":"  Large Language Models (LLMs) have demonstrated remarkable performance across\nvarious domains, including healthcare. However, their ability to effectively\nrepresent structured non-textual data, such as the alphanumeric medical codes\nused in records like ICD-10 or SNOMED-CT, is limited and has been particularly\nexposed in recent research. This paper examines the challenges LLMs face in\nprocessing medical codes due to the shortcomings of current tokenization\nmethods. As a result, we introduce the UniStruct architecture to design a\nmultimodal medical foundation model of unstructured text and structured data,\nwhich addresses these challenges by adapting subword tokenization techniques\nspecifically for the structured medical codes. Our approach is validated\nthrough model pre-training on both an extensive internal medical database and a\npublic repository of structured medical records. Trained on over 1 billion\ntokens on the internal medical database, the proposed model achieves up to a\n23% improvement in evaluation metrics, with around 2% gain attributed to our\nproposed tokenization. Additionally, when evaluated on the EHRSHOT public\nbenchmark with a 1/1000 fraction of the pre-training data, the UniStruct model\nimproves performance on over 42% of the downstream tasks. Our approach not only\nenhances the representation and generalization capabilities of patient-centric\nmodels but also bridges a critical gap in representation learning models'\nability to handle complex structured medical data, alongside unstructured text.\n","authors":["Vijay Prakash Dwivedi","Viktor Schlegel","Andy T. Liu","Thanh-Tung Nguyen","Abhinav Ramesh Kashyap","Jeng Wei","Wei-Hsian Yin","Stefan Winkler","Robby T. Tan"],"pdf_url":"https://arxiv.org/pdf/2410.13351v1.pdf","comment":"NeurIPS 2024 Workshop on Unifying Representations in Neural Models\n  (UniReps 2024)"},{"id":"http://arxiv.org/abs/2405.17525v2","updated":"2024-10-17T08:56:51Z","published":"2024-05-27T14:23:30Z","title":"SmoothGNN: Smoothing-aware GNN for Unsupervised Node Anomaly Detection","summary":"  The smoothing issue in graph learning leads to indistinguishable node\nrepresentations, posing significant challenges for graph-related tasks.\nHowever, our experiments reveal that this problem can uncover underlying\nproperties of node anomaly detection (NAD) that previous research has missed.\nWe introduce Individual Smoothing Patterns (ISP) and Neighborhood Smoothing\nPatterns (NSP), which indicate that the representations of anomalous nodes are\nharder to smooth than those of normal ones. In addition, we explore the\ntheoretical implications of these patterns, demonstrating the potential\nbenefits of ISP and NSP for NAD tasks. Motivated by these findings, we propose\nSmoothGNN, a novel unsupervised NAD framework. First, we design a learning\ncomponent to explicitly capture ISP for detecting node anomalies. Second, we\ndesign a spectral graph neural network to implicitly learn ISP to enhance\ndetection. Third, we design an effective coefficient based on our findings that\nNSP can serve as coefficients for node representations, aiding in the\nidentification of anomalous nodes. Furthermore, we devise a novel anomaly\nmeasure to calculate loss functions and anomalous scores for nodes, reflecting\nthe properties of NAD using ISP and NSP. Extensive experiments on 9 real\ndatasets show that SmoothGNN outperforms the best rival by an average of 14.66%\nin AUC and 7.28% in Average Precision, with 75x running time speedup,\nvalidating the effectiveness and efficiency of our framework.\n","authors":["Xiangyu Dong","Xingyi Zhang","Yanni Sun","Lei Chen","Mingxuan Yuan","Sibo Wang"],"pdf_url":"https://arxiv.org/pdf/2405.17525v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2407.02057v2","updated":"2024-10-17T08:55:31Z","published":"2024-07-02T08:38:32Z","title":"HC-GLAD: Dual Hyperbolic Contrastive Learning for Unsupervised\n  Graph-Level Anomaly Detection","summary":"  Unsupervised graph-level anomaly detection (UGAD) has garnered increasing\nattention in recent years due to its significance. Most existing methods that\nrely on traditional GNNs mainly consider pairwise relationships between\nfirst-order neighbors, which is insufficient to capture the complex high-order\ndependencies often associated with anomalies. This limitation underscores the\nnecessity of exploring high-order node interactions in UGAD. In addition, most\nprevious works ignore the underlying properties (e.g., hierarchy and power-law\nstructure) which are common in real-world graph datasets and therefore are\nindispensable factors in the UGAD task. In this paper, we propose a novel Dual\nHyperbolic Contrastive Learning for Unsupervised Graph-Level Anomaly Detection\n(HC-GLAD in short). To exploit high-order node group information, we construct\nhypergraphs based on pre-designed gold motifs and subsequently perform\nhypergraph convolution. Furthermore, to preserve the hierarchy of real-world\ngraphs, we introduce hyperbolic geometry into this field and conduct both graph\nand hypergraph embedding learning in hyperbolic space with the hyperboloid\nmodel. To the best of our knowledge, this is the first work to simultaneously\napply hypergraph with node group information and hyperbolic geometry in this\nfield. Extensive experiments on 13 real-world datasets of different fields\ndemonstrate the superiority of HC-GLAD on the UGAD task. The code is available\nat https://github.com/Yali-F/HC-GLAD.\n","authors":["Yali Fu","Jindong Li","Jiahong Liu","Qianli Xing","Qi Wang","Irwin King"],"pdf_url":"https://arxiv.org/pdf/2407.02057v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2404.07979v2","updated":"2024-10-17T08:54:37Z","published":"2024-04-11T17:57:22Z","title":"LLoCO: Learning Long Contexts Offline","summary":"  Processing long contexts remains a challenge for large language models (LLMs)\ndue to the quadratic computational and memory overhead of the self-attention\nmechanism and the substantial KV cache sizes during generation. We propose\nLLoCO, a novel approach to address this problem by learning contexts offline\nthrough context compression and in-domain parameter-efficient finetuning with\nLoRA. Our method enables an LLM to create a concise representation of the\noriginal context and efficiently retrieve relevant information to answer\nquestions accurately. Our approach extends the effective context window of a 4k\ntoken LLaMA2-7B model to handle up to 128k tokens. We evaluate our approach on\nseveral long-context question-answering datasets, demonstrating that LLoCO\nsignificantly outperforms in-context learning while using $30\\times$ fewer\ntokens during inference. LLoCO achieves up to $7.62\\times$ speed-up during\ninference and $11.52\\times$ higher throughput during finetuning, substantially\nreduces the cost of long document question answering. This makes it a promising\nsolution for efficient long context processing. Our code is publicly available\non https://github.com/jeffreysijuntan/lloco.\n","authors":["Sijun Tan","Xiuyu Li","Shishir Patil","Ziyang Wu","Tianjun Zhang","Kurt Keutzer","Joseph E. Gonzalez","Raluca Ada Popa"],"pdf_url":"https://arxiv.org/pdf/2404.07979v2.pdf","comment":"EMNLP 2024. The first two authors contributed equally to this work"},{"id":"http://arxiv.org/abs/2410.13343v1","updated":"2024-10-17T08:52:52Z","published":"2024-10-17T08:52:52Z","title":"Do LLMs Overcome Shortcut Learning? An Evaluation of Shortcut Challenges\n  in Large Language Models","summary":"  Large Language Models (LLMs) have shown remarkable capabilities in various\nnatural language processing tasks. However, LLMs may rely on dataset biases as\nshortcuts for prediction, which can significantly impair their robustness and\ngeneralization capabilities. This paper presents Shortcut Suite, a\ncomprehensive test suite designed to evaluate the impact of shortcuts on LLMs'\nperformance, incorporating six shortcut types, five evaluation metrics, and\nfour prompting strategies. Our extensive experiments yield several key\nfindings: 1) LLMs demonstrate varying reliance on shortcuts for downstream\ntasks, significantly impairing their performance. 2) Larger LLMs are more\nlikely to utilize shortcuts under zero-shot and few-shot in-context learning\nprompts. 3) Chain-of-thought prompting notably reduces shortcut reliance and\noutperforms other prompting strategies, while few-shot prompts generally\nunderperform compared to zero-shot prompts. 4) LLMs often exhibit\noverconfidence in their predictions, especially when dealing with datasets that\ncontain shortcuts. 5) LLMs generally have a lower explanation quality in\nshortcut-laden datasets, with errors falling into three types: distraction,\ndisguised comprehension, and logical fallacy. Our findings offer new insights\nfor evaluating robustness and generalization in LLMs and suggest potential\ndirections for mitigating the reliance on shortcuts. The code is available at\n\\url {https://github.com/yyhappier/ShortcutSuite.git}.\n","authors":["Yu Yuan","Lili Zhao","Kai Zhang","Guangting Zheng","Qi Liu"],"pdf_url":"https://arxiv.org/pdf/2410.13343v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.13341v1","updated":"2024-10-17T08:49:42Z","published":"2024-10-17T08:49:42Z","title":"Limits to scalable evaluation at the frontier: LLM as Judge won't beat\n  twice the data","summary":"  High quality annotations are increasingly a bottleneck in the explosively\ngrowing machine learning ecosystem. Scalable evaluation methods that avoid\ncostly annotation have therefore become an important research ambition. Many\nhope to use strong existing models in lieu of costly labels to provide cheap\nmodel evaluations. Unfortunately, this method of using models as judges\nintroduces biases, such as self-preferencing, that can distort model\ncomparisons. An emerging family of debiasing tools promises to fix these issues\nby using a few high quality labels to debias a large number of model judgments.\nIn this paper, we study how far such debiasing methods, in principle, can go.\nOur main result shows that when the judge is no more accurate than the\nevaluated model, no debiasing method can decrease the required amount of ground\ntruth labels by more than half. Our result speaks to the severe limitations of\nthe LLM-as-a-judge paradigm at the evaluation frontier where the goal is to\nassess newly released models that are possibly better than the judge. Through\nan empirical evaluation, we demonstrate that the sample size savings achievable\nin practice are even more modest than what our theoretical limit suggests.\nAlong the way, our work provides new observations about debiasing methods for\nmodel evaluation, and points out promising avenues for future work.\n","authors":["Florian E. Dorner","Vivian Y. Nastl","Moritz Hardt"],"pdf_url":"https://arxiv.org/pdf/2410.13341v1.pdf","comment":"22 pages, 5 figures"},{"id":"http://arxiv.org/abs/2410.13338v1","updated":"2024-10-17T08:48:52Z","published":"2024-10-17T08:48:52Z","title":"DiffImp: Efficient Diffusion Model for Probabilistic Time Series\n  Imputation with Bidirectional Mamba Backbone","summary":"  Probabilistic time series imputation has been widely applied in real-world\nscenarios due to its ability to estimate uncertainty of imputation results.\nMeanwhile, denoising diffusion probabilistic models (DDPMs) have achieved great\nsuccess in probabilistic time series imputation tasks with its power to model\ncomplex distributions. However, current DDPM-based probabilistic time series\nimputation methodologies are confronted with two types of challenges:\n1)~\\textit{~The backbone modules of the denoising parts are not capable of\nachieving sequence modeling with low time complexity.} 2)~\\textit{The\narchitecture of denoising modules can not handle the inter-variable and\nbidirectional dependencies in the time series imputation problem effectively.}\nTo address the first challenge, we integrate the computational efficient state\nspace model, namely Mamba, as the backbone denosing module for DDPMs. To tackle\nthe second challenge, we carefully devise several SSM-based blocks for\nbidirectional modeling and inter-variable relation understanding. Experimental\nresults demonstrate that our approach can achieve state-of-the-art time series\nimputation results on multiple datasets, different missing scenarios and\nmissing ratios.\n","authors":["Hongfan Gao","Wangmeng Shen","Xiangfei Qiu","Ronghui Xu","Jilin Hu","Bin Yang"],"pdf_url":"https://arxiv.org/pdf/2410.13338v1.pdf","comment":"25 pages, 14 figures"},{"id":"http://arxiv.org/abs/2410.13334v1","updated":"2024-10-17T08:46:09Z","published":"2024-10-17T08:46:09Z","title":"Do LLMs Have Political Correctness? Analyzing Ethical Biases and\n  Jailbreak Vulnerabilities in AI Systems","summary":"  Although large language models (LLMs) demonstrate impressive proficiency in\nvarious tasks, they present potential safety risks, such as `jailbreaks', where\nmalicious inputs can coerce LLMs into generating harmful content. To address\nthese issues, many LLM developers have implemented various safety measures to\nalign these models. This alignment involves several techniques, including data\nfiltering during pre-training, supervised fine-tuning, reinforcement learning\nfrom human feedback, and red-teaming exercises. These methods often introduce\ndeliberate and intentional biases similar to Political Correctness (PC) to\nensure the ethical behavior of LLMs. In this paper, we delve into the\nintentional biases injected into LLMs for safety purposes and examine methods\nto circumvent these safety alignment techniques. Notably, these intentional\nbiases result in a jailbreaking success rate in GPT-4o models that differs by\n20% between non-binary and cisgender keywords and by 16% between white and\nblack keywords, even when the other parts of the prompts are identical. We\nintroduce the concept of PCJailbreak, highlighting the inherent risks posed by\nthese safety-induced biases. Additionally, we propose an efficient defense\nmethod PCDefense, which prevents jailbreak attempts by injecting defense\nprompts prior to generation. PCDefense stands as an appealing alternative to\nGuard Models, such as Llama-Guard, that require additional inference cost after\ntext generation. Our findings emphasize the urgent need for LLM developers to\nadopt a more responsible approach when designing and implementing safety\nmeasures.\n","authors":["Isack Lee","Haebin Seong"],"pdf_url":"https://arxiv.org/pdf/2410.13334v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2407.03888v2","updated":"2024-10-17T08:45:44Z","published":"2024-07-04T12:26:31Z","title":"Continuous-time q-Learning for Jump-Diffusion Models under Tsallis\n  Entropy","summary":"  This paper studies the continuous-time reinforcement learning in\njump-diffusion models by featuring the q-learning (the continuous-time\ncounterpart of Q-learning) under Tsallis entropy regularization. Contrary to\nthe Shannon entropy, the general form of Tsallis entropy renders the optimal\npolicy not necessary a Gibbs measure, where the Lagrange and KKT multipliers\nnaturally arise from some constraints to ensure the learnt policy to be a\nprobability density function. As a consequence, the characterization of the\noptimal policy using the q-function also involves a Lagrange multiplier. In\nresponse, we establish the martingale characterization of the q-function under\nTsallis entropy and devise two q-learning algorithms depending on whether the\nLagrange multiplier can be derived explicitly or not. In the latter case, we\nneed to consider different parameterizations of the optimal q-function and the\noptimal policy and update them alternatively in an Actor-Critic manner. We also\nstudy two financial applications, namely, an optimal portfolio liquidation\nproblem and a non-LQ control problem. It is interesting to see therein that the\noptimal policies under the Tsallis entropy regularization can be characterized\nexplicitly, which are distributions concentrated on some compact support. The\nsatisfactory performance of our q-learning algorithms is illustrated in each\nexample.\n","authors":["Lijun Bo","Yijie Huang","Xiang Yu","Tingting Zhang"],"pdf_url":"https://arxiv.org/pdf/2407.03888v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.13331v1","updated":"2024-10-17T08:44:57Z","published":"2024-10-17T08:44:57Z","title":"Improving Discrete Optimisation Via Decoupled Straight-Through\n  Gumbel-Softmax","summary":"  Discrete representations play a crucial role in many deep learning\narchitectures, yet their non-differentiable nature poses significant challenges\nfor gradient-based optimization. To address this issue, various gradient\nestimators have been developed, including the Straight-Through Gumbel-Softmax\n(ST-GS) estimator, which combines the Straight-Through Estimator (STE) and the\nGumbel-based reparameterization trick. However, the performance of ST-GS is\nhighly sensitive to temperature, with its selection often compromising gradient\nfidelity. In this work, we propose a simple yet effective extension to ST-GS by\nemploying decoupled temperatures for forward and backward passes, which we\nrefer to as \"Decoupled ST-GS\". We show that our approach significantly enhances\nthe original ST-GS through extensive experiments across multiple tasks and\ndatasets. We further investigate the impact of our method on gradient fidelity\nfrom multiple perspectives, including the gradient gap and the bias-variance\ntrade-off of estimated gradients. Our findings contribute to the ongoing effort\nto improve discrete optimization in deep learning, offering a practical\nsolution that balances simplicity and effectiveness.\n","authors":["Rushi Shah","Mingyuan Yan","Michael Curtis Mozer","Dianbo Liu"],"pdf_url":"https://arxiv.org/pdf/2410.13331v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.19272v2","updated":"2024-10-17T08:36:58Z","published":"2024-06-27T15:38:37Z","title":"Stochastic Concept Bottleneck Models","summary":"  Concept Bottleneck Models (CBMs) have emerged as a promising interpretable\nmethod whose final prediction is based on intermediate, human-understandable\nconcepts rather than the raw input. Through time-consuming manual\ninterventions, a user can correct wrongly predicted concept values to enhance\nthe model's downstream performance. We propose Stochastic Concept Bottleneck\nModels (SCBMs), a novel approach that models concept dependencies. In SCBMs, a\nsingle-concept intervention affects all correlated concepts, thereby improving\nintervention effectiveness. Unlike previous approaches that model the concept\nrelations via an autoregressive structure, we introduce an explicit,\ndistributional parameterization that allows SCBMs to retain the CBMs' efficient\ntraining and inference procedure. Additionally, we leverage the\nparameterization to derive an effective intervention strategy based on the\nconfidence region. We show empirically on synthetic tabular and natural image\ndatasets that our approach improves intervention effectiveness significantly.\nNotably, we showcase the versatility and usability of SCBMs by examining a\nsetting with CLIP-inferred concepts, alleviating the need for manual concept\nannotations.\n","authors":["Moritz Vandenhirtz","Sonia Laguna","Ričards Marcinkevičs","Julia E. Vogt"],"pdf_url":"https://arxiv.org/pdf/2406.19272v2.pdf","comment":"Published at 38th Conference on Neural Information Processing Systems\n  (NeurIPS 2024)"},{"id":"http://arxiv.org/abs/2402.02249v2","updated":"2024-10-17T08:30:07Z","published":"2024-02-03T19:40:41Z","title":"Don't Label Twice: Quantity Beats Quality when Comparing Binary\n  Classifiers on a Budget","summary":"  We study how to best spend a budget of noisy labels to compare the accuracy\nof two binary classifiers. It's common practice to collect and aggregate\nmultiple noisy labels for a given data point into a less noisy label via a\nmajority vote. We prove a theorem that runs counter to conventional wisdom. If\nthe goal is to identify the better of two classifiers, we show it's best to\nspend the budget on collecting a single label for more samples. Our result\nfollows from a non-trivial application of Cram\\'er's theorem, a staple in the\ntheory of large deviations. We discuss the implications of our work for the\ndesign of machine learning benchmarks, where they overturn some time-honored\nrecommendations. In addition, our results provide sample size bounds superior\nto what follows from Hoeffding's bound.\n","authors":["Florian E. Dorner","Moritz Hardt"],"pdf_url":"https://arxiv.org/pdf/2402.02249v2.pdf","comment":"34 pages, 3 Figures, Published at ICML 2024"},{"id":"http://arxiv.org/abs/2308.14409v2","updated":"2024-10-17T08:25:06Z","published":"2023-08-28T08:47:06Z","title":"Steerable Conditional Diffusion for Out-of-Distribution Adaptation in\n  Medical Image Reconstruction","summary":"  Denoising diffusion models have emerged as the go-to generative framework for\nsolving inverse problems in imaging. A critical concern regarding these models\nis their performance on out-of-distribution tasks, which remains an\nunder-explored challenge. Using a diffusion model on an out-of-distribution\ndataset, realistic reconstructions can be generated, but with hallucinating\nimage features that are uniquely present in the training dataset. To address\nthis discrepancy during train-test time and improve reconstruction accuracy, we\nintroduce a novel sampling framework called Steerable Conditional Diffusion.\nSpecifically, this framework adapts the diffusion model, concurrently with\nimage reconstruction, based solely on the information provided by the available\nmeasurement. Utilising our proposed method, we achieve substantial enhancements\nin out-of-distribution performance across diverse imaging modalities, advancing\nthe robust deployment of denoising diffusion models in real-world applications.\n","authors":["Riccardo Barbano","Alexander Denker","Hyungjin Chung","Tae Hoon Roh","Simon Arridge","Peter Maass","Bangti Jin","Jong Chul Ye"],"pdf_url":"https://arxiv.org/pdf/2308.14409v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.11522v2","updated":"2024-10-17T08:18:14Z","published":"2024-10-15T11:48:31Z","title":"Leveraging LLM Embeddings for Cross Dataset Label Alignment and Zero\n  Shot Music Emotion Prediction","summary":"  In this work, we present a novel method for music emotion recognition that\nleverages Large Language Model (LLM) embeddings for label alignment across\nmultiple datasets and zero-shot prediction on novel categories. First, we\ncompute LLM embeddings for emotion labels and apply non-parametric clustering\nto group similar labels, across multiple datasets containing disjoint labels.\nWe use these cluster centers to map music features (MERT) to the LLM embedding\nspace. To further enhance the model, we introduce an alignment regularization\nthat enables dissociation of MERT embeddings from different clusters. This\nfurther enhances the model's ability to better adaptation to unseen datasets.\nWe demonstrate the effectiveness of our approach by performing zero-shot\ninference on a new dataset, showcasing its ability to generalize to unseen\nlabels without additional training.\n","authors":["Renhang Liu","Abhinaba Roy","Dorien Herremans"],"pdf_url":"https://arxiv.org/pdf/2410.11522v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2401.10721v2","updated":"2024-10-17T08:15:27Z","published":"2024-01-19T14:32:50Z","title":"Generative Model for Constructing Reaction Path from Initial to Final\n  States","summary":"  Mapping the chemical reaction pathways and their corresponding activation\nbarriers is a significant challenge in molecular simulation. Given the inherent\ncomplexities of 3D atomic geometries, even generating an initial guess of these\npaths can be difficult for humans. This paper presents an innovative approach\nthat utilizes neural networks to generate initial guesses for reaction pathways\nbased on the initial state and learning from a database of low-energy\ntransition paths. The proposed method is initiated by inputting the coordinates\nof the initial state, followed by progressive alterations to its structure.\nThis iterative process culminates in the generation of the guess reaction path\nand the coordinates of the final state. The method does not require one-the-fly\ncomputation of the actual potential energy surface, and is therefore\nfast-acting. The application of this geometry-based method extends to complex\nreaction pathways illustrated by organic reactions. Training was executed on\nthe Transition1x dataset of organic reaction pathways. The results revealed the\ngeneration of reactions that bore substantial similarities with the test set of\nchemical reaction paths. The method's flexibility allows for reactions to be\ngenerated either to conform to predetermined conditions or in a randomized\nmanner.\n","authors":["Akihide Hayashi","So Takamoto","Ju Li","Yuta Tsuboi","Daisuke Okanohara"],"pdf_url":"https://arxiv.org/pdf/2401.10721v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.03260v2","updated":"2024-10-17T08:15:09Z","published":"2024-06-05T13:37:42Z","title":"Feature learning in finite-width Bayesian deep linear networks with\n  multiple outputs and convolutional layers","summary":"  Deep linear networks have been extensively studied, as they provide\nsimplified models of deep learning. However, little is known in the case of\nfinite-width architectures with multiple outputs and convolutional layers. In\nthis manuscript, we provide rigorous results for the statistics of functions\nimplemented by the aforementioned class of networks, thus moving closer to a\ncomplete characterization of feature learning in the Bayesian setting. Our\nresults include: (i) an exact and elementary non-asymptotic integral\nrepresentation for the joint prior distribution over the outputs, given in\nterms of a mixture of Gaussians; (ii) an analytical formula for the posterior\ndistribution in the case of squared error loss function (Gaussian likelihood);\n(iii) a quantitative description of the feature learning infinite-width regime,\nusing large deviation theory. From a physical perspective, deep architectures\nwith multiple outputs or convolutional layers represent different\nmanifestations of kernel shape renormalization, and our work provides a\ndictionary that translates this physics intuition and terminology into rigorous\nBayesian statistics.\n","authors":["Federico Bassetti","Marco Gherardi","Alessandro Ingrosso","Mauro Pastore","Pietro Rotondo"],"pdf_url":"https://arxiv.org/pdf/2406.03260v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2107.02791v3","updated":"2024-10-17T16:11:28Z","published":"2021-07-06T17:58:35Z","title":"Depth-supervised NeRF: Fewer Views and Faster Training for Free","summary":"  A commonly observed failure mode of Neural Radiance Field (NeRF) is fitting\nincorrect geometries when given an insufficient number of input views. One\npotential reason is that standard volumetric rendering does not enforce the\nconstraint that most of a scene's geometry consist of empty space and opaque\nsurfaces. We formalize the above assumption through DS-NeRF (Depth-supervised\nNeural Radiance Fields), a loss for learning radiance fields that takes\nadvantage of readily-available depth supervision. We leverage the fact that\ncurrent NeRF pipelines require images with known camera poses that are\ntypically estimated by running structure-from-motion (SFM). Crucially, SFM also\nproduces sparse 3D points that can be used as \"free\" depth supervision during\ntraining: we add a loss to encourage the distribution of a ray's terminating\ndepth matches a given 3D keypoint, incorporating depth uncertainty. DS-NeRF can\nrender better images given fewer training views while training 2-3x faster.\nFurther, we show that our loss is compatible with other recently proposed NeRF\nmethods, demonstrating that depth is a cheap and easily digestible supervisory\nsignal. And finally, we find that DS-NeRF can support other types of depth\nsupervision such as scanned depth sensors and RGB-D reconstruction outputs.\n","authors":["Kangle Deng","Andrew Liu","Jun-Yan Zhu","Deva Ramanan"],"pdf_url":"https://arxiv.org/pdf/2107.02791v3.pdf","comment":"Project page: http://www.cs.cmu.edu/~dsnerf/ GitHub:\n  https://github.com/dunbar12138/DSNeRF"}],"Information Retrieval":[{"id":"http://arxiv.org/abs/2410.13765v1","updated":"2024-10-17T17:03:23Z","published":"2024-10-17T17:03:23Z","title":"Knowledge-Aware Query Expansion with Large Language Models for Textual\n  and Relational Retrieval","summary":"  Large language models (LLMs) have been used to generate query expansions\naugmenting original queries for improving information search. Recent studies\nalso explore providing LLMs with initial retrieval results to generate query\nexpansions more grounded to document corpus. However, these methods mostly\nfocus on enhancing textual similarities between search queries and target\ndocuments, overlooking document relations. For queries like \"Find me a highly\nrated camera for wildlife photography compatible with my Nikon F-Mount lenses\",\nexisting methods may generate expansions that are semantically similar but\nstructurally unrelated to user intents. To handle such semi-structured queries\nwith both textual and relational requirements, in this paper we propose a\nknowledge-aware query expansion framework, augmenting LLMs with structured\ndocument relations from knowledge graph (KG). To further address the limitation\nof entity-based scoring in existing KG-based methods, we leverage document\ntexts as rich KG node representations and use document-based relation filtering\nfor our Knowledge-Aware Retrieval (KAR). Extensive experiments on three\ndatasets of diverse domains show the advantages of our method compared against\nstate-of-the-art baselines on textual and relational semi-structured retrieval.\n","authors":["Yu Xia","Junda Wu","Sungchul Kim","Tong Yu","Ryan A. Rossi","Haoliang Wang","Julian McAuley"],"pdf_url":"https://arxiv.org/pdf/2410.13765v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.13707v1","updated":"2024-10-17T16:07:51Z","published":"2024-10-17T16:07:51Z","title":"Disjointness Violations in Wikidata","summary":"  Disjointness checks are among the most important constraint checks in a\nknowledge base and can be used to help detect and correct incorrect statements\nand internal contradictions. Wikidata is a very large, community-managed\nknowledge base. Because of both its size and construction, Wikidata contains\nmany incorrect statements and internal contradictions. We analyze the current\nmodeling of disjointness on Wikidata, identify patterns that cause these\ndisjointness violations and categorize them. We use SPARQL queries to identify\neach ``culprit'' causing a disjointness violation and lay out formulas to\nidentify and fix conflicting information. We finally discuss how disjointness\ninformation could be better modeled and expanded in Wikidata in the future.\n","authors":["Ege Atacan Doğan","Peter F. Patel-Schneider"],"pdf_url":"https://arxiv.org/pdf/2410.13707v1.pdf","comment":"Sixth International Knowledge Graph and Semantic Web Conference"},{"id":"http://arxiv.org/abs/2410.13680v1","updated":"2024-10-17T15:40:09Z","published":"2024-10-17T15:40:09Z","title":"Pessimistic Evaluation","summary":"  Traditional evaluation of information access systems has focused primarily on\naverage utility across a set of information needs (information retrieval) or\nusers (recommender systems). In this work, we argue that evaluating only with\naverage metric measurements assumes utilitarian values not aligned with\ntraditions of information access based on equal access. We advocate for\npessimistic evaluation of information access systems focusing on worst case\nutility. These methods are (a) grounded in ethical and pragmatic concepts, (b)\ntheoretically complementary to existing robustness and fairness methods, and\n(c) empirically validated across a set of retrieval and recommendation tasks.\nThese results suggest that pessimistic evaluation should be included in\nexisting experimentation processes to better understand the behavior of\nsystems, especially when concerned with principles of social good.\n","authors":["Fernando Diaz"],"pdf_url":"https://arxiv.org/pdf/2410.13680v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.13604v1","updated":"2024-10-17T14:39:24Z","published":"2024-10-17T14:39:24Z","title":"Large Language Models as Narrative-Driven Recommenders","summary":"  Narrative-driven recommenders aim to provide personalized suggestions for\nuser requests expressed in free-form text such as \"I want to watch a thriller\nwith a mind-bending story, like Shutter Island.\" Although large language models\n(LLMs) have been shown to excel in processing general natural language queries,\ntheir effectiveness for handling such recommendation requests remains\nrelatively unexplored. To close this gap, we compare the performance of 38\nopen- and closed-source LLMs of various sizes, such as LLama 3.2 and GPT-4o, in\na movie recommendation setting. For this, we utilize a gold-standard,\ncrowdworker-annotated dataset of posts from reddit's movie suggestion community\nand employ various prompting strategies, including zero-shot, identity, and\nfew-shot prompting. Our findings demonstrate the ability of LLMs to generate\ncontextually relevant movie recommendations, significantly outperforming other\nstate-of-the-art approaches, such as doc2vec. While we find that closed-source\nand large-parameterized models generally perform best, medium-sized open-source\nmodels remain competitive, being only slightly outperformed by their more\ncomputationally expensive counterparts. Furthermore, we observe no significant\ndifferences across prompting strategies for most models, underscoring the\neffectiveness of simple approaches such as zero-shot prompting for\nnarrative-driven recommendations. Overall, this work offers valuable insights\nfor recommender system researchers as well as practitioners aiming to integrate\nLLMs into real-world recommendation tools.\n","authors":["Lukas Eberhard","Thorsten Ruprechter","Denis Helic"],"pdf_url":"https://arxiv.org/pdf/2410.13604v1.pdf","comment":"Under review; 19 pages"},{"id":"http://arxiv.org/abs/2410.13588v1","updated":"2024-10-17T14:22:57Z","published":"2024-10-17T14:22:57Z","title":"Cross-Domain Sequential Recommendation via Neural Process","summary":"  Cross-Domain Sequential Recommendation (CDSR) is a hot topic in\nsequence-based user interest modeling, which aims at utilizing a single model\nto predict the next items for different domains. To tackle the CDSR, many\nmethods are focused on domain overlapped users' behaviors fitting, which\nheavily relies on the same user's different-domain item sequences collaborating\nsignals to capture the synergy of cross-domain item-item correlation. Indeed,\nthese overlapped users occupy a small fraction of the entire user set only,\nwhich introduces a strong assumption that the small group of domain overlapped\nusers is enough to represent all domain user behavior characteristics. However,\nintuitively, such a suggestion is biased, and the insufficient learning\nparadigm in non-overlapped users will inevitably limit model performance.\nFurther, it is not trivial to model non-overlapped user behaviors in CDSR\nbecause there are no other domain behaviors to collaborate with, which causes\nthe observed single-domain users' behavior sequences to be hard to contribute\nto cross-domain knowledge mining. Considering such a phenomenon, we raise a\nchallenging and unexplored question: How to unleash the potential of\nnon-overlapped users' behaviors to empower CDSR?\n","authors":["Haipeng Li","Jiangxia Cao","Yiwen Gao","Yunhuai Liu","Shuchao Pang"],"pdf_url":"https://arxiv.org/pdf/2410.13588v1.pdf","comment":"Work in progress"},{"id":"http://arxiv.org/abs/2409.20305v2","updated":"2024-10-17T13:19:08Z","published":"2024-09-30T14:04:27Z","title":"Mixed-Precision Embeddings for Large-Scale Recommendation Models","summary":"  Embedding techniques have become essential components of large databases in\nthe deep learning era. By encoding discrete entities, such as words, items, or\ngraph nodes, into continuous vector spaces, embeddings facilitate more\nefficient storage, retrieval, and processing in large databases. Especially in\nthe domain of recommender systems, millions of categorical features are encoded\nas unique embedding vectors, which facilitates the modeling of similarities and\ninteractions among features. However, numerous embedding vectors can result in\nsignificant storage overhead. In this paper, we aim to compress the embedding\ntable through quantization techniques. Given that features vary in importance\nlevels, we seek to identify an appropriate precision for each feature to\nbalance model accuracy and memory usage. To this end, we propose a novel\nembedding compression method, termed Mixed-Precision Embeddings (MPE).\nSpecifically, to reduce the size of the search space, we first group features\nby frequency and then search precision for each feature group. MPE further\nlearns the probability distribution over precision levels for each feature\ngroup, which can be used to identify the most suitable precision with a\nspecially designed sampling strategy. Extensive experiments on three public\ndatasets demonstrate that MPE significantly outperforms existing embedding\ncompression methods. Remarkably, MPE achieves about 200x compression on the\nCriteo dataset without comprising the prediction accuracy.\n","authors":["Shiwei Li","Zhuoqi Hu","Xing Tang","Haozhao Wang","Shijie Xu","Weihong Luo","Yuhua Li","Xiuqiang He","Ruixuan Li"],"pdf_url":"https://arxiv.org/pdf/2409.20305v2.pdf","comment":"under submision"},{"id":"http://arxiv.org/abs/2406.16350v2","updated":"2024-10-17T10:59:08Z","published":"2024-06-24T06:46:32Z","title":"A Survey on Intent-aware Recommender Systems","summary":"  Many modern online services feature personalized recommendations. A central\nchallenge when providing such recommendations is that the reason why an\nindividual user accesses the service may change from visit to visit or even\nduring an ongoing usage session. To be effective, a recommender system should\ntherefore aim to take the users' probable intent of using the service at a\ncertain point in time into account. In recent years, researchers have thus\nstarted to address this challenge by incorporating intent-awareness into\nrecommender systems. Correspondingly, a number of technical approaches were put\nforward, including diversification techniques, intent prediction models or\nlatent intent modeling approaches. In this paper, we survey and categorize\nexisting approaches to building the next generation of Intent-Aware Recommender\nSystems (IARS). Based on an analysis of current evaluation practices, we\noutline open gaps and possible future directions in this area, which in\nparticular include the consideration of additional interaction signals and\ncontextual information to further improve the effectiveness of such systems.\n","authors":["Dietmar Jannach","Markus Zanker"],"pdf_url":"https://arxiv.org/pdf/2406.16350v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.13428v1","updated":"2024-10-17T10:51:34Z","published":"2024-10-17T10:51:34Z","title":"Generate and Instantiate What You Prefer: Text-Guided Diffusion for\n  Sequential Recommendation","summary":"  Recent advancements in generative recommendation systems, particularly in the\nrealm of sequential recommendation tasks, have shown promise in enhancing\ngeneralization to new items. Among these approaches, diffusion-based generative\nrecommendation has emerged as an effective tool, leveraging its ability to\ncapture data distributions and generate high-quality samples. Despite\neffectiveness, two primary challenges have been identified: 1) the lack of\nconsistent modeling of data distribution for oracle items; and 2) the\ndifficulty in scaling to more informative control signals beyond historical\ninteractions. These issues stem from the uninformative nature of ID embeddings,\nwhich necessitate random initialization and limit the incorporation of\nadditional control signals. To address these limitations, we propose iDreamRe }\nto involve more concrete prior knowledge to establish item embeddings,\nparticularly through detailed item text descriptions and advanced Text\nEmbedding Models (TEM). More importantly, by converting item descriptions into\nembeddings aligned with TEM, we enable the integration of intention\ninstructions as control signals to guide the generation of oracle items.\nExperimental results on four datasets demonstrate that iDreamRec not only\noutperforms existing diffusion-based generative recommenders but also\nfacilitates the incorporation of intention instructions for more precise and\neffective recommendation generation.\n","authors":["Guoqing Hu","Zhangyi Yang","Zhibo Cai","An Zhang","Xiang Wang"],"pdf_url":"https://arxiv.org/pdf/2410.13428v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.13374v1","updated":"2024-10-17T09:24:40Z","published":"2024-10-17T09:24:40Z","title":"Context-aware adaptive personalised recommendation: a meta-hybrid","summary":"  Recommenders take place on a wide scale of e-commerce systems, reducing the\nproblem of information overload. The most common approach is to choose a\nrecommender used by the system to make predictions. However, users vary from\neach other; thus, a one-fits-all approach seems to be sub-optimal. In this\npaper, we propose a meta-hybrid recommender that uses machine learning to\npredict an optimal algorithm. In this way, the best-performing recommender is\nused for each specific session and user. This selection depends on contextual\nand preferential information collected about the user. We use standard\nMovieLens and The Movie DB datasets for offline evaluation. We show that based\non the proposed model, it is possible to predict which recommender will provide\nthe most precise recommendations to a user. The theoretical performance of our\nmeta-hybrid outperforms separate approaches by 20-50% in normalized Discounted\nGain and Root Mean Square Error metrics. However, it is hard to obtain the\noptimal performance based on widely-used standard information stored about\nusers.\n","authors":["Peter Tibensky","Michal Kompan"],"pdf_url":"https://arxiv.org/pdf/2410.13374v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.00800v2","updated":"2024-10-17T09:13:18Z","published":"2024-07-22T11:58:36Z","title":"Chatbot-Based Ontology Interaction Using Large Language Models and\n  Domain-Specific Standards","summary":"  The following contribution introduces a concept that employs Large Language\nModels (LLMs) and a chatbot interface to enhance SPARQL query generation for\nontologies, thereby facilitating intuitive access to formalized knowledge.\nUtilizing natural language inputs, the system converts user inquiries into\naccurate SPARQL queries that strictly query the factual content of the\nontology, effectively preventing misinformation or fabrication by the LLM. To\nenhance the quality and precision of outcomes, additional textual information\nfrom established domain-specific standards is integrated into the ontology for\nprecise descriptions of its concepts and relationships. An experimental study\nassesses the accuracy of generated SPARQL queries, revealing significant\nbenefits of using LLMs for querying ontologies and highlighting areas for\nfuture research.\n","authors":["Jonathan Reif","Tom Jeleniewski","Milapji Singh Gill","Felix Gehlhoff","Alexander Fay"],"pdf_url":"https://arxiv.org/pdf/2408.00800v2.pdf","comment":"\\c{opyright} 2024 IEEE. Personal use of this material is permitted.\n  Permission from IEEE must be obtained for all other uses, in any current or\n  future media, including reprinting/republishing this material for advertising\n  or promotional purposes, creating new collective works, for resale or\n  redistribution to servers or lists, or reuse of any copyrighted component of\n  this work in other works"},{"id":"http://arxiv.org/abs/2410.13326v1","updated":"2024-10-17T08:37:25Z","published":"2024-10-17T08:37:25Z","title":"Comparing the Utility, Preference, and Performance of Course Material\n  Search Functionality and Retrieval-Augmented Generation Large Language Model\n  (RAG-LLM) AI Chatbots in Information-Seeking Tasks","summary":"  Providing sufficient support for students requires substantial resources,\nespecially considering the growing enrollment numbers. Students need help in a\nvariety of tasks, ranging from information-seeking to requiring support with\ncourse assignments. To explore the utility of recent large language models\n(LLMs) as a support mechanism, we developed an LLM-powered AI chatbot that\naugments the answers that are produced with information from the course\nmaterials. To study the effect of the LLM-powered AI chatbot, we conducted a\nlab-based user study (N=14), in which the participants worked on tasks from a\nweb software development course. The participants were divided into two groups,\nwhere one of the groups first had access to the chatbot and then to a more\ntraditional search functionality, while another group started with the search\nfunctionality and was then given the chatbot. We assessed the participants'\nperformance and perceptions towards the chatbot and the search functionality\nand explored their preferences towards the support functionalities. Our\nfindings highlight that both support mechanisms are seen as useful and that\nsupport mechanisms work well for specific tasks, while less so for other tasks.\nWe also observe that students tended to prefer the second support mechanism\nmore, where students who were first given the chatbot tended to prefer the\nsearch functionality and vice versa.\n","authors":["Leonardo Pasquarelli","Charles Koutcheme","Arto Hellas"],"pdf_url":"https://arxiv.org/pdf/2410.13326v1.pdf","comment":"12 pages, 4 figures"},{"id":"http://arxiv.org/abs/2409.10025v2","updated":"2024-10-17T08:16:52Z","published":"2024-09-16T06:33:26Z","title":"DiffATR: Diffusion-based Generative Modeling for Audio-Text Retrieval","summary":"  Existing audio-text retrieval (ATR) methods are essentially discriminative\nmodels that aim to maximize the conditional likelihood, represented as\np(candidates|query). Nevertheless, this methodology fails to consider the\nintrinsic data distribution p(query), leading to difficulties in discerning\nout-of-distribution data. In this work, we attempt to tackle this constraint\nthrough a generative perspective and model the relationship between audio and\ntext as their joint probability p(candidates,query). To this end, we present a\ndiffusion-based ATR framework (DiffATR), which models ATR as an iterative\nprocedure that progressively generates joint distribution from noise.\nThroughout its training phase, DiffATR is optimized from both generative and\ndiscriminative viewpoints: the generator is refined through a generation loss,\nwhile the feature extractor benefits from a contrastive loss, thus combining\nthe merits of both methodologies. Experiments on the AudioCaps and Clotho\ndatasets with superior performances, verify the effectiveness of our approach.\nNotably, without any alterations, our DiffATR consistently exhibits strong\nperformance in out-of-domain retrieval settings.\n","authors":["Yifei Xin","Xuxin Cheng","Zhihong Zhu","Xusheng Yang","Yuexian Zou"],"pdf_url":"https://arxiv.org/pdf/2409.10025v2.pdf","comment":"Accepted by Interspeech2024"},{"id":"http://arxiv.org/abs/2410.13293v1","updated":"2024-10-17T07:46:49Z","published":"2024-10-17T07:46:49Z","title":"SBI-RAG: Enhancing Math Word Problem Solving for Students through\n  Schema-Based Instruction and Retrieval-Augmented Generation","summary":"  Many students struggle with math word problems (MWPs), often finding it\ndifficult to identify key information and select the appropriate mathematical\noperations.Schema-based instruction (SBI) is an evidence-based strategy that\nhelps students categorize problems based on their structure, improving\nproblem-solving accuracy. Building on this, we propose a Schema-Based\nInstruction Retrieval-Augmented Generation (SBI-RAG) framework that\nincorporates a large language model (LLM).Our approach emphasizes step-by-step\nreasoning by leveraging schemas to guide solution generation. We evaluate its\nperformance on the GSM8K dataset, comparing it with GPT-4 and GPT-3.5 Turbo,\nand introduce a \"reasoning score\" metric to assess solution quality. Our\nfindings suggest that SBI-RAG enhances reasoning clarity and problem-solving\naccuracy, potentially providing educational benefits for students\n","authors":["Prakhar Dixit","Tim Oates"],"pdf_url":"https://arxiv.org/pdf/2410.13293v1.pdf","comment":"Accepted to the 4th MATH-AI Workshop at NeurIPS'24"},{"id":"http://arxiv.org/abs/2410.13248v1","updated":"2024-10-17T06:15:00Z","published":"2024-10-17T06:15:00Z","title":"Disentangling Likes and Dislikes in Personalized Generative Explainable\n  Recommendation","summary":"  Recent research on explainable recommendation generally frames the task as a\nstandard text generation problem, and evaluates models simply based on the\ntextual similarity between the predicted and ground-truth explanations.\nHowever, this approach fails to consider one crucial aspect of the systems:\nwhether their outputs accurately reflect the users' (post-purchase) sentiments,\ni.e., whether and why they would like and/or dislike the recommended items. To\nshed light on this issue, we introduce new datasets and evaluation methods that\nfocus on the users' sentiments. Specifically, we construct the datasets by\nexplicitly extracting users' positive and negative opinions from their\npost-purchase reviews using an LLM, and propose to evaluate systems based on\nwhether the generated explanations 1) align well with the users' sentiments,\nand 2) accurately identify both positive and negative opinions of users on the\ntarget items. We benchmark several recent models on our datasets and\ndemonstrate that achieving strong performance on existing metrics does not\nensure that the generated explanations align well with the users' sentiments.\nLastly, we find that existing models can provide more sentiment-aware\nexplanations when the users' (predicted) ratings for the target items are\ndirectly fed into the models as input. We will release our code and datasets\nupon acceptance.\n","authors":["Ryotaro Shimizu","Takashi Wada","Yu Wang","Johannes Kruse","Sean O'Brien","Sai HtaungKham","Linxin Song","Yuya Yoshikawa","Yuki Saito","Fugee Tsung","Masayuki Goto","Julian McAuley"],"pdf_url":"https://arxiv.org/pdf/2410.13248v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.13230v1","updated":"2024-10-17T05:33:50Z","published":"2024-10-17T05:33:50Z","title":"Starbucks: Improved Training for 2D Matryoshka Embeddings","summary":"  Effective approaches that can scale embedding model depth (i.e. layers) and\nembedding size allow for the creation of models that are highly scalable across\ndifferent computational resources and task requirements. While the recently\nproposed 2D Matryoshka training approach can efficiently produce a single\nembedding model such that its sub-layers and sub-dimensions can measure text\nsimilarity, its effectiveness is significantly worse than if smaller models\nwere trained separately. To address this issue, we propose Starbucks, a new\ntraining strategy for Matryoshka-like embedding models, which encompasses both\nthe fine-tuning and pre-training phases. For the fine-tuning phase, we discover\nthat, rather than sampling a random sub-layer and sub-dimensions for each\ntraining steps, providing a fixed list of layer-dimension pairs, from small\nsize to large sizes, and computing the loss across all pairs significantly\nimproves the effectiveness of 2D Matryoshka embedding models, bringing them on\npar with their separately trained counterparts. To further enhance performance,\nwe introduce a new pre-training strategy, which applies masked autoencoder\nlanguage modelling to sub-layers and sub-dimensions during pre-training,\nresulting in a stronger backbone for subsequent fine-tuning of the embedding\nmodel. Experimental results on both semantic text similarity and retrieval\nbenchmarks demonstrate that the proposed pre-training and fine-tuning\nstrategies significantly improved the effectiveness over 2D Matryoshka models,\nenabling Starbucks models to perform more efficiently and effectively than\nseparately trained models.\n","authors":["Shengyao Zhuang","Shuai Wang","Bevan Koopman","Guido Zuccon"],"pdf_url":"https://arxiv.org/pdf/2410.13230v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.13226v1","updated":"2024-10-17T05:17:01Z","published":"2024-10-17T05:17:01Z","title":"Research on Travel Route Planing Problems Based on Greedy Algorithm","summary":"  The greedy algorithm based route planning problem is a method of finding the\noptimal or near optimal route between a given starting and ending point. This\narticle first uses PCA method to reduce the dimensionality of urban evaluation\nindicators, extracts key principal components, and KMO and TOPSIS algorithms to\nreduce the dimensionality of the data. Secondly, for datasets that have not\npassed the KMO test, a comprehensive evaluation will be conducted using the\nentropy weight method and TOPSIS method. Finally, based on the greedy\nalgorithm, a route planning algorithm was proposed and optimized to provide\npersonalized route customization according to the different needs of tourists.\nWe also took into account the local travel efficiency, the time required to\nvisit tourist attractions, and necessary daily rest time to reduce costs and\navoid falling into the local optimal solution.\n","authors":["Yiquan Wang"],"pdf_url":"https://arxiv.org/pdf/2410.13226v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.13217v1","updated":"2024-10-17T04:48:06Z","published":"2024-10-17T04:48:06Z","title":"MixEHR-Nest: Identifying Subphenotypes within Electronic Health Records\n  through Hierarchical Guided-Topic Modeling","summary":"  Automatic subphenotyping from electronic health records (EHRs)provides\nnumerous opportunities to understand diseases with unique subgroups and enhance\npersonalized medicine for patients. However, existing machine learning\nalgorithms either focus on specific diseases for better interpretability or\nproduce coarse-grained phenotype topics without considering nuanced disease\npatterns. In this study, we propose a guided topic model, MixEHR-Nest, to infer\nsub-phenotype topics from thousands of disease using multi-modal EHR data.\nSpecifically, MixEHR-Nest detects multiple subtopics from each phenotype topic,\nwhose prior is guided by the expert-curated phenotype concepts such as\nPhenotype Codes (PheCodes) or Clinical Classification Software (CCS) codes. We\nevaluated MixEHR-Nest on two EHR datasets: (1) the MIMIC-III dataset consisting\nof over 38 thousand patients from intensive care unit (ICU) from Beth Israel\nDeaconess Medical Center (BIDMC) in Boston, USA; (2) the healthcare\nadministrative database PopHR, comprising 1.3 million patients from Montreal,\nCanada. Experimental results demonstrate that MixEHR-Nest can identify\nsubphenotypes with distinct patterns within each phenotype, which are\npredictive for disease progression and severity. Consequently, MixEHR-Nest\ndistinguishes between type 1 and type 2 diabetes by inferring subphenotypes\nusing CCS codes, which do not differentiate these two subtype concepts.\nAdditionally, MixEHR-Nest not only improved the prediction accuracy of\nshort-term mortality of ICU patients and initial insulin treatment in diabetic\npatients but also revealed the contributions of subphenotypes. For longitudinal\nanalysis, MixEHR-Nest identified subphenotypes of distinct age prevalence under\nthe same phenotypes, such as asthma, leukemia, epilepsy, and depression. The\nMixEHR-Nest software is available at GitHub:\nhttps://github.com/li-lab-mcgill/MixEHR-Nest.\n","authors":["Ruohan Wang","Zilong Wang","Ziyang Song","David Buckeridge","Yue Li"],"pdf_url":"https://arxiv.org/pdf/2410.13217v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.05666v7","updated":"2024-10-17T03:23:49Z","published":"2024-06-09T06:49:22Z","title":"Probability Distribution Learning: A theoretical framework for Deep\n  Learning","summary":"  This paper introduces probability distribution learning (PD learning), a\nnovel theoretical learning framework. Departing from the traditional\nstatistical learning framework, PD learning focuses on learning the underlying\nprobability distribution, which is modeled as a random variable within the\nprobability simplex. Within this framework, the learning error is decomposed\ninto uncertainty, estimation error, and the model's fitting error.\nSubsequently, we present the methodology for calculating uncertainty, along\nwith optimization strategies for both estimation error and fitting error. Given\nthat minimizing the fitting error typically constitutes a non-convex\noptimization problem, we introduce a standard loss function and the gradient\nstructural control (GSC) algorithm, and demonstrate that by employing this\nfunction, the optima of fitting error minimization can be approached by\nreducing the gradient norm and structural error. Furthermore, we apply the PD\nlearning framework to deep learning, elucidating the mechanisms by which\ntechniques such as random parameter initialization, over-parameterization,\nbias-variance trade-off, and dropout influence deep model training. Finally,\nexperimental results on various models validate the effectiveness of the\nproposed framework.\n","authors":["Binchuan Qi","Wei Gong","Li Li"],"pdf_url":"https://arxiv.org/pdf/2406.05666v7.pdf","comment":"arXiv admin note: text overlap with arXiv:2105.04026 by other\n  authors. arXiv admin note: text overlap with arXiv:2105.04026 by other\n  authors"},{"id":"http://arxiv.org/abs/2402.16872v2","updated":"2024-10-17T02:53:23Z","published":"2024-01-29T03:30:15Z","title":"NFT1000: A Cross-Modal Dataset for Non-Fungible Token Retrieval","summary":"  With the rise of \"Metaverse\" and \"Web 3.0\", Non-Fungible Token (NFT) has\nemerged as a kind of pivotal digital asset, garnering significant attention. By\nthe end of March 2024, more than 1.7 billion NFTs have been minted across\nvarious blockchain platforms. To effectively locate a desired NFT, conducting\nsearches within a vast array of NFTs is essential. The challenge in NFT\nretrieval is heightened due to the high degree of similarity among different\nNFTs, regarding regional and semantic aspects. In this paper, we will introduce\na benchmark dataset named \"NFT Top1000 Visual-Text Dataset\" (NFT1000),\ncontaining 7.56 million image-text pairs, and being collected from 1000 most\nfamous PFP1 NFT collections2 by sales volume on the Ethereum blockchain. Based\non this dataset and leveraging the CLIP series of pre-trained models as our\nfoundation, we propose the dynamic masking fine-tuning scheme. This innovative\napproach results in a 7.4\\% improvement in the top1 accuracy rate, while\nutilizing merely 13\\% of the total training data (0.79 million vs. 6.1\nmillion). We also propose a robust metric Comprehensive Variance Index (CVI) to\nassess the similarity and retrieval difficulty of visual-text pairs data. The\ndataset will be released as an open-source resource. For more details, please\nrefer to: https://github.com/ShuxunoO/NFT-Net.git.\n","authors":["Shuxun Wang","Yunfei Lei","Ziqi Zhang","Wei Liu","Haowei Liu","Li Yang","Wenjuan Li","Bing Li","Weiming Hu"],"pdf_url":"https://arxiv.org/pdf/2402.16872v2.pdf","comment":"11 pages,12figures to be published in ACM Multimedia 2024, see\n  https://openreview.net/forum?id=xUtNrKH8iB&noteId=xUtNrKH8iB"},{"id":"http://arxiv.org/abs/2408.01262v4","updated":"2024-10-17T02:20:47Z","published":"2024-08-02T13:35:11Z","title":"RAGEval: Scenario Specific RAG Evaluation Dataset Generation Framework","summary":"  Retrieval-Augmented Generation (RAG) is a powerful approach that enables\nlarge language models (LLMs) to incorporate external knowledge. However,\nevaluating the effectiveness of RAG systems in specialized scenarios remains\nchallenging due to the high costs of data construction and the lack of suitable\nevaluation metrics. This paper introduces RAGEval, a framework designed to\nassess RAG systems across diverse scenarios by generating high-quality\ndocuments, questions, answers, and references through a schema-based pipeline.\nWith a focus on factual accuracy, we propose three novel metrics Completeness,\nHallucination, and Irrelevance to rigorously evaluate LLM-generated responses.\nExperimental results show that RAGEval outperforms zero-shot and one-shot\nmethods in terms of clarity, safety, conformity, and richness of generated\nsamples. Furthermore, the use of LLMs for scoring the proposed metrics\ndemonstrates a high level of consistency with human evaluations. RAGEval\nestablishes a new paradigm for evaluating RAG systems in real-world\napplications.\n","authors":["Kunlun Zhu","Yifan Luo","Dingling Xu","Ruobing Wang","Shi Yu","Shuo Wang","Yukun Yan","Zhenghao Liu","Xu Han","Zhiyuan Liu","Maosong Sun"],"pdf_url":"https://arxiv.org/pdf/2408.01262v4.pdf","comment":"https://github.com/OpenBMB/RAGEval"},{"id":"http://arxiv.org/abs/2406.00944v2","updated":"2024-10-17T02:15:11Z","published":"2024-06-03T02:56:14Z","title":"A Theory for Token-Level Harmonization in Retrieval-Augmented Generation","summary":"  Retrieval-augmented generation (RAG) utilizes retrieved texts to enhance\nlarge language models (LLMs). Studies show that while RAG provides valuable\nexternal information (benefit), it may also mislead LLMs (detriment) with noisy\nor incorrect retrieved texts. Although many existing methods attempt to\npreserve benefit and avoid detriment, they lack a theoretical explanation for\nRAG. The benefit and detriment in the next token prediction of RAG remain a\nblack box that cannot be quantified or compared in an explainable manner, so\nexisting methods are data-driven, need additional utility evaluators or\npost-hoc. This paper takes the first step towards providing a theory to explain\nand trade off the benefit and detriment in RAG. First, we model RAG as the\nfusion between distribution of LLMs knowledge and distribution of retrieved\ntexts. Then, we formalize the trade-off between the value of external knowledge\n(benefit) and its potential risk of misleading LLMs (detriment) in next token\nprediction of RAG by distribution difference in this fusion. Finally, we prove\nthat the actual effect of RAG on the token, which is the comparison between\nbenefit and detriment, can be predicted without any training or accessing the\nutility of retrieval. Based on our theory, we propose a practical novel method,\nTok-RAG, which achieves collaborative generation between the pure LLM and RAG\nat token level to preserve benefit and avoid detriment. Experiments in\nreal-world tasks using LLMs such as OPT, LLaMA-2, and Mistral show the\neffectiveness of our method and support our theoretical findings.\n","authors":["Shicheng Xu","Liang Pang","Huawei Shen","Xueqi Cheng"],"pdf_url":"https://arxiv.org/pdf/2406.00944v2.pdf","comment":"25 pages"},{"id":"http://arxiv.org/abs/2410.13125v1","updated":"2024-10-17T01:27:57Z","published":"2024-10-17T01:27:57Z","title":"Transformers4NewsRec: A Transformer-based News Recommendation Framework","summary":"  Pre-trained transformer models have shown great promise in various natural\nlanguage processing tasks, including personalized news recommendations. To\nharness the power of these models, we introduce Transformers4NewsRec, a new\nPython framework built on the \\textbf{Transformers} library. This framework is\ndesigned to unify and compare the performance of various news recommendation\nmodels, including deep neural networks and graph-based models.\nTransformers4NewsRec offers flexibility in terms of model selection, data\npreprocessing, and evaluation, allowing both quantitative and qualitative\nanalysis.\n","authors":["Dairui Liu","Honghui Du","Boming Yang","Neil Hurley","Aonghus Lawlor","Irene Li","Derek Greene","Ruihai Dong"],"pdf_url":"https://arxiv.org/pdf/2410.13125v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.13118v1","updated":"2024-10-17T01:12:48Z","published":"2024-10-17T01:12:48Z","title":"Retrieval-Enhanced Named Entity Recognition","summary":"  When combined with In-Context Learning, a technique that enables models to\nadapt to new tasks by incorporating task-specific examples or demonstrations\ndirectly within the input prompt, autoregressive language models have achieved\ngood performance in a wide range of tasks and applications. However, this\ncombination has not been properly explored in the context of named entity\nrecognition, where the structure of this task poses unique challenges. We\npropose RENER (Retrieval-Enhanced Named Entity Recognition), a technique for\nnamed entity recognition using autoregressive language models based on\nIn-Context Learning and information retrieval techniques. When presented with\nan input text, RENER fetches similar examples from a dataset of training\nexamples that are used to enhance a language model to recognize named entities\nfrom this input text. RENER is modular and independent of the underlying\nlanguage model and information retrieval algorithms. Experimental results show\nthat in the CrossNER collection we achieve state-of-the-art performance with\nthe proposed technique and that information retrieval can increase the F-score\nby up to 11 percentage points.\n","authors":["Enzo Shiraishi","Raphael Y. de Camargo","Henrique L. P. Silva","Ronaldo C. Prati"],"pdf_url":"https://arxiv.org/pdf/2410.13118v1.pdf","comment":"13 pages, 6 figures, 3 tables"},{"id":"http://arxiv.org/abs/2410.13117v1","updated":"2024-10-17T01:02:04Z","published":"2024-10-17T01:02:04Z","title":"Preference Diffusion for Recommendation","summary":"  Recommender systems predict personalized item rankings based on user\npreference distributions derived from historical behavior data. Recently,\ndiffusion models (DMs) have gained attention in recommendation for their\nability to model complex distributions, yet current DM-based recommenders often\nrely on traditional objectives like mean squared error (MSE) or recommendation\nobjectives, which are not optimized for personalized ranking tasks or fail to\nfully leverage DM's generative potential. To address this, we propose\nPreferDiff, a tailored optimization objective for DM-based recommenders.\nPreferDiff transforms BPR into a log-likelihood ranking objective and\nintegrates multiple negative samples to better capture user preferences.\nSpecifically, we employ variational inference to handle the intractability\nthrough minimizing the variational upper bound and replaces MSE with cosine\nerror to improve alignment with recommendation tasks. Finally, we balance\nlearning generation and preference to enhance the training stability of DMs.\nPreferDiff offers three key benefits: it is the first personalized ranking loss\ndesigned specifically for DM-based recommenders and it improves ranking and\nfaster convergence by addressing hard negatives. We also prove that it is\ntheoretically connected to Direct Preference Optimization which indicates that\nit has the potential to align user preferences in DM-based recommenders via\ngenerative modeling. Extensive experiments across three benchmarks validate its\nsuperior recommendation performance and commendable general sequential\nrecommendation capabilities. Our codes are available at\n\\url{https://github.com/lswhim/PreferDiff}.\n","authors":["Shuo Liu","An Zhang","Guoqing Hu","Hong Qian","Tat-seng Chua"],"pdf_url":"https://arxiv.org/pdf/2410.13117v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.12123v2","updated":"2024-10-17T22:06:32Z","published":"2024-10-15T23:51:04Z","title":"The Moral Case for Using Language Model Agents for Recommendation","summary":"  Our information and communication environment has fallen short of the ideals\nthat networked global communication might have served. Identifying all the\ncauses of its pathologies is difficult, but existing recommender systems very\nlikely play a contributing role. In this paper, which draws on the normative\ntools of philosophy of computing, informed by empirical and technical insights\nfrom natural language processing and recommender systems, we make the moral\ncase for an alternative approach. We argue that existing recommenders\nincentivise mass surveillance, concentrate power, fall prey to narrow\nbehaviourism, and compromise user agency. Rather than just trying to avoid\nalgorithms entirely, or to make incremental improvements to the current\nparadigm, researchers and engineers should explore an alternative paradigm: the\nuse of language model (LM) agents to source and curate content that matches\nusers' preferences and values, expressed in natural language. The use of LM\nagents for recommendation poses its own challenges, including those related to\ncandidate generation, computational efficiency, preference modelling, and\nprompt injection. Nonetheless, if implemented successfully LM agents could:\nguide us through the digital public sphere without relying on mass\nsurveillance; shift power away from platforms towards users; optimise for what\nmatters instead of just for behavioural proxies; and scaffold our agency\ninstead of undermining it.\n","authors":["Seth Lazar","Luke Thorburn","Tian Jin","Luca Belli"],"pdf_url":"https://arxiv.org/pdf/2410.12123v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2210.16953v2","updated":"2024-10-17T22:47:50Z","published":"2022-10-30T21:26:07Z","title":"Improving Bilingual Lexicon Induction with Cross-Encoder Reranking","summary":"  Bilingual lexicon induction (BLI) with limited bilingual supervision is a\ncrucial yet challenging task in multilingual NLP. Current state-of-the-art BLI\nmethods rely on the induction of cross-lingual word embeddings (CLWEs) to\ncapture cross-lingual word similarities; such CLWEs are obtained 1) via\ntraditional static models (e.g., VecMap), or 2) by extracting type-level CLWEs\nfrom multilingual pretrained language models (mPLMs), or 3) through combining\nthe former two options. In this work, we propose a novel semi-supervised\npost-hoc reranking method termed BLICEr (BLI with Cross-Encoder Reranking),\napplicable to any precalculated CLWE space, which improves their BLI\ncapability. The key idea is to 'extract' cross-lingual lexical knowledge from\nmPLMs, and then combine it with the original CLWEs. This crucial step is done\nvia 1) creating a word similarity dataset, comprising positive word pairs\n(i.e., true translations) and hard negative pairs induced from the original\nCLWE space, and then 2) fine-tuning an mPLM (e.g., mBERT or XLM-R) in a\ncross-encoder manner to predict the similarity scores. At inference, we 3)\ncombine the similarity score from the original CLWE space with the score from\nthe BLI-tuned cross-encoder. BLICEr establishes new state-of-the-art results on\ntwo standard BLI benchmarks spanning a wide spectrum of diverse languages: it\nsubstantially outperforms a series of strong baselines across the board. We\nalso validate the robustness of BLICEr with different CLWEs.\n","authors":["Yaoyiran Li","Fangyu Liu","Ivan Vulić","Anna Korhonen"],"pdf_url":"https://arxiv.org/pdf/2210.16953v2.pdf","comment":"Findings of EMNLP 2022"},{"id":"http://arxiv.org/abs/2410.14066v1","updated":"2024-10-17T22:28:07Z","published":"2024-10-17T22:28:07Z","title":"Lightweight Correlation-Aware Table Compression","summary":"  The growing adoption of data lakes for managing relational data necessitates\nefficient, open storage formats that provide high scan performance and\ncompetitive compression ratios. While existing formats achieve fast scans\nthrough lightweight encoding techniques, they have reached a plateau in terms\nof minimizing storage footprint. Recently, correlation-aware compression\nschemes have been shown to reduce file sizes further. Yet, current approaches\neither incur significant scan overheads or require manual specification of\ncorrelations, limiting their practicability. We present $\\texttt{Virtual}$, a\nframework that integrates seamlessly with existing open formats to\nautomatically leverage data correlations, achieving substantial compression\ngains while having minimal scan performance overhead. Experiments on\n$\\texttt{data.gov}$ datasets show that $\\texttt{Virtual}$ reduces file sizes by\nup to 40% compared to Apache Parquet.\n","authors":["Mihail Stoian","Alexander van Renen","Jan Kobiolka","Ping-Lin Kuo","Josif Grabocka","Andreas Kipf"],"pdf_url":"https://arxiv.org/pdf/2410.14066v1.pdf","comment":"Third Table Representation Learning Workshop (TRL 2024)"},{"id":"http://arxiv.org/abs/2203.08307v5","updated":"2024-10-17T21:50:37Z","published":"2022-03-15T22:51:22Z","title":"Improving Word Translation via Two-Stage Contrastive Learning","summary":"  Word translation or bilingual lexicon induction (BLI) is a key cross-lingual\ntask, aiming to bridge the lexical gap between different languages. In this\nwork, we propose a robust and effective two-stage contrastive learning\nframework for the BLI task. At Stage C1, we propose to refine standard\ncross-lingual linear maps between static word embeddings (WEs) via a\ncontrastive learning objective; we also show how to integrate it into the\nself-learning procedure for even more refined cross-lingual maps. In Stage C2,\nwe conduct BLI-oriented contrastive fine-tuning of mBERT, unlocking its word\ntranslation capability. We also show that static WEs induced from the\n`C2-tuned' mBERT complement static WEs from Stage C1. Comprehensive experiments\non standard BLI datasets for diverse languages and different experimental\nsetups demonstrate substantial gains achieved by our framework. While the BLI\nmethod from Stage C1 already yields substantial gains over all state-of-the-art\nBLI methods in our comparison, even stronger improvements are met with the full\ntwo-stage framework: e.g., we report gains for 112/112 BLI setups, spanning 28\nlanguage pairs.\n","authors":["Yaoyiran Li","Fangyu Liu","Nigel Collier","Anna Korhonen","Ivan Vulić"],"pdf_url":"https://arxiv.org/pdf/2203.08307v5.pdf","comment":"ACL 2022 Main"},{"id":"http://arxiv.org/abs/2410.14044v1","updated":"2024-10-17T21:37:08Z","published":"2024-10-17T21:37:08Z","title":"Best in Tau@LLMJudge: Criteria-Based Relevance Evaluation with Llama3","summary":"  Traditional evaluation of information retrieval (IR) systems relies on\nhuman-annotated relevance labels, which can be both biased and costly at scale.\nIn this context, large language models (LLMs) offer an alternative by allowing\nus to directly prompt them to assign relevance labels for passages associated\nwith each query. In this study, we explore alternative methods to directly\nprompt LLMs for assigned relevance labels, by exploring two hypotheses:\n  Hypothesis 1 assumes that it is helpful to break down \"relevance\" into\nspecific criteria - exactness, coverage, topicality, and contextual fit. We\nexplore different approaches that prompt large language models (LLMs) to obtain\ncriteria-level grades for all passages, and we consider various ways to\naggregate criteria-level grades into a relevance label. Hypothesis 2 assumes\nthat differences in linguistic style between queries and passages may\nnegatively impact the automatic relevance label prediction. We explore whether\nimprovements can be achieved by first synthesizing a summary of the passage in\nthe linguistic style of a query, and then using this summary in place of the\npassage to assess its relevance.\n  We include an empirical evaluation of our approaches based on data from the\nLLMJudge challenge run in Summer 2024, where our \"Four Prompts\" approach\nobtained the highest scores in Kendall's tau.\n","authors":["Naghmeh Farzi","Laura Dietz"],"pdf_url":"https://arxiv.org/pdf/2410.14044v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.14043v1","updated":"2024-10-17T21:35:55Z","published":"2024-10-17T21:35:55Z","title":"Efficient Retrieval of Temporal Event Sequences from Textual\n  Descriptions","summary":"  Retrieving temporal event sequences from textual descriptions is essential\nfor applications such as analyzing e-commerce behavior, monitoring social media\nactivities, and tracking criminal incidents. In this paper, we introduce\nTPP-LLM-Embedding, a unified model for efficiently embedding and retrieving\nevent sequences based on natural language descriptions. Built on the TPP-LLM\nframework, which integrates large language models with temporal point\nprocesses, our model encodes both event types and times, generating a\nsequence-level representation through pooling. Textual descriptions are\nembedded using the same architecture, ensuring a shared embedding space for\nboth sequences and descriptions. We optimize a contrastive loss based on\nsimilarity between these embeddings, bringing matching pairs closer and\nseparating non-matching ones. TPP-LLM-Embedding enables efficient retrieval and\ndemonstrates superior performance compared to baseline models across diverse\ndatasets.\n","authors":["Zefang Liu","Yinzhu Quan"],"pdf_url":"https://arxiv.org/pdf/2410.14043v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.15232v2","updated":"2024-10-17T20:43:22Z","published":"2024-08-27T17:50:03Z","title":"Into the Unknown Unknowns: Engaged Human Learning through Participation\n  in Language Model Agent Conversations","summary":"  While language model (LM)-powered chatbots and generative search engines\nexcel at answering concrete queries, discovering information in the terrain of\nunknown unknowns remains challenging for users. To emulate the common\neducational scenario where children/students learn by listening to and\nparticipating in conversations of their parents/teachers, we create\nCollaborative STORM (Co-STORM). Unlike QA systems that require users to ask all\nthe questions, Co-STORM lets users observe and occasionally steer the discourse\namong several LM agents. The agents ask questions on the user's behalf,\nallowing the user to discover unknown unknowns serendipitously. To facilitate\nuser interaction, Co-STORM assists users in tracking the discourse by\norganizing the uncovered information into a dynamic mind map, ultimately\ngenerating a comprehensive report as takeaways. For automatic evaluation, we\nconstruct the WildSeek dataset by collecting real information-seeking records\nwith user goals. Co-STORM outperforms baseline methods on both discourse trace\nand report quality. In a further human evaluation, 70% of participants prefer\nCo-STORM over a search engine, and 78% favor it over a RAG chatbot.\n","authors":["Yucheng Jiang","Yijia Shao","Dekun Ma","Sina J. Semnani","Monica S. Lam"],"pdf_url":"https://arxiv.org/pdf/2408.15232v2.pdf","comment":"EMNLP 2024 Main"},{"id":"http://arxiv.org/abs/2307.08803v3","updated":"2024-10-17T19:09:13Z","published":"2023-07-17T19:38:40Z","title":"Mixed-initiative Query Rewriting in Conversational Passage Retrieval","summary":"  In this paper, we report our methods and experiments for the TREC\nConversational Assistance Track (CAsT) 2022. In this work, we aim to reproduce\nmulti-stage retrieval pipelines and explore one of the potential benefits of\ninvolving mixed-initiative interaction in conversational passage retrieval\nscenarios: reformulating raw queries. Before the first ranking stage of a\nmulti-stage retrieval pipeline, we propose a mixed-initiative query rewriting\nmodule, which achieves query rewriting based on the mixed-initiative\ninteraction between the users and the system, as the replacement for the neural\nrewriting method. Specifically, we design an algorithm to generate appropriate\nquestions related to the ambiguities in raw queries, and another algorithm to\nreformulate raw queries by parsing users' feedback and incorporating it into\nthe raw query. For the first ranking stage of our multi-stage pipelines, we\nadopt a sparse ranking function: BM25, and a dense retrieval method:\nTCT-ColBERT. For the second-ranking step, we adopt a pointwise reranker:\nMonoT5, and a pairwise reranker: DuoT5. Experiments on both TREC CAsT 2021 and\nTREC CAsT 2022 datasets show the effectiveness of our mixed-initiative-based\nquery rewriting (or query reformulation) method on improving retrieval\nperformance compared with two popular reformulators: a neural reformulator:\nCANARD-T5 and a rule-based reformulator: historical query reformulator(HQE).\n","authors":["Dayu Yang","Yue Zhang","Hui Fang"],"pdf_url":"https://arxiv.org/pdf/2307.08803v3.pdf","comment":"https://trec.nist.gov/pubs/trec31/papers/udel_fang.C.pdf"},{"id":"http://arxiv.org/abs/2404.11773v2","updated":"2024-10-17T18:59:18Z","published":"2024-04-17T21:56:27Z","title":"Behavior Alignment: A New Perspective of Evaluating LLM-based\n  Conversational Recommender Systems","summary":"  Large Language Models (LLMs) have demonstrated great potential in\nConversational Recommender Systems (CRS). However, the application of LLMs to\nCRS has exposed a notable discrepancy in behavior between LLM-based CRS and\nhuman recommenders: LLMs often appear inflexible and passive, frequently\nrushing to complete the recommendation task without sufficient inquiry.This\nbehavior discrepancy can lead to decreased accuracy in recommendations and\nlower user satisfaction. Despite its importance, existing studies in CRS lack a\nstudy about how to measure such behavior discrepancy. To fill this gap, we\npropose Behavior Alignment, a new evaluation metric to measure how well the\nrecommendation strategies made by a LLM-based CRS are consistent with human\nrecommenders'. Our experiment results show that the new metric is better\naligned with human preferences and can better differentiate how systems perform\nthan existing evaluation metrics. As Behavior Alignment requires explicit and\ncostly human annotations on the recommendation strategies, we also propose a\nclassification-based method to implicitly measure the Behavior Alignment based\non the responses. The evaluation results confirm the robustness of the method.\n","authors":["Dayu Yang","Fumian Chen","Hui Fang"],"pdf_url":"https://arxiv.org/pdf/2404.11773v2.pdf","comment":"Accepted by the 47th International ACM SIGIR Conference on Research\n  and Development in Information Retrieval"},{"id":"http://arxiv.org/abs/2307.09384v3","updated":"2024-10-17T18:53:54Z","published":"2023-07-18T16:05:25Z","title":"ZeQR: Zero-shot Query Reformulation for Conversational Search","summary":"  As the popularity of voice assistants continues to surge, conversational\nsearch has gained increased attention in Information Retrieval. However, data\nsparsity issues in conversational search significantly hinder the progress of\nsupervised conversational search methods. Consequently, researchers are\nfocusing more on zero-shot conversational search approaches. Nevertheless,\nexisting zero-shot methods face three primary limitations: they are not\nuniversally applicable to all retrievers, their effectiveness lacks sufficient\nexplainability, and they struggle to resolve common conversational ambiguities\ncaused by omission. To address these limitations, we introduce a novel\nZero-shot Query Reformulation (or Query Rewriting) (ZeQR) framework that\nreformulates queries based on previous dialogue contexts without requiring\nsupervision from conversational search data. Specifically, our framework\nutilizes language models designed for machine reading comprehension tasks to\nexplicitly resolve two common ambiguities: coreference and omission, in raw\nqueries. In comparison to existing zero-shot methods, our approach is\nuniversally applicable to any retriever without additional adaptation or\nindexing. It also provides greater explainability and effectively enhances\nquery intent understanding because ambiguities are explicitly and proactively\nresolved. Through extensive experiments on four TREC conversational datasets,\nwe demonstrate the effectiveness of our method, which consistently outperforms\nstate-of-the-art baselines.\n","authors":["Dayu Yang","Yue Zhang","Hui Fang"],"pdf_url":"https://arxiv.org/pdf/2307.09384v3.pdf","comment":"Accepted by the 9th ACM SIGIR International Conference on the Theory\n  of Information Retrieval"},{"id":"http://arxiv.org/abs/2310.01038v2","updated":"2024-10-17T18:35:41Z","published":"2023-10-02T09:30:11Z","title":"Dataset Condensation for Recommendation","summary":"  Training recommendation models on large datasets requires significant time\nand resources. It is desired to construct concise yet informative datasets for\nefficient training. Recent advances in dataset condensation show promise in\naddressing this problem by synthesizing small datasets. However, applying\nexisting methods of dataset condensation to recommendation has limitations: (1)\nthey fail to generate discrete user-item interactions, and (2) they could not\npreserve users' potential preferences. To address the limitations, we propose a\nlightweight condensation framework tailored for recommendation (DConRec),\nfocusing on condensing user-item historical interaction sets. Specifically, we\nmodel the discrete user-item interactions via a probabilistic approach and\ndesign a pre-augmentation module to incorporate the potential preferences of\nusers into the condensed datasets. While the substantial size of datasets leads\nto costly optimization, we propose a lightweight policy gradient estimation to\naccelerate the data synthesis. Experimental results on multiple real-world\ndatasets have demonstrated the effectiveness and efficiency of our framework.\nBesides, we provide a theoretical analysis of the provable convergence of\nDConRec. Our implementation is available at:\nhttps://github.com/JiahaoWuGit/DConRec.\n","authors":["Jiahao Wu","Wenqi Fan","Jingfan Chen","Shengcai Liu","Qijiong Liu","Rui He","Qing Li","Ke Tang"],"pdf_url":"https://arxiv.org/pdf/2310.01038v2.pdf","comment":"Accepted by IEEE TKDE. Also titled as \"Condensing Pre-augmented\n  Recommendation Data via Lightweight Policy Gradient Estimation\""},{"id":"http://arxiv.org/abs/2410.13959v1","updated":"2024-10-17T18:34:43Z","published":"2024-10-17T18:34:43Z","title":"FinQAPT: Empowering Financial Decisions with End-to-End LLM-driven\n  Question Answering Pipeline","summary":"  Financial decision-making hinges on the analysis of relevant information\nembedded in the enormous volume of documents in the financial domain. To\naddress this challenge, we developed FinQAPT, an end-to-end pipeline that\nstreamlines the identification of relevant financial reports based on a query,\nextracts pertinent context, and leverages Large Language Models (LLMs) to\nperform downstream tasks. To evaluate the pipeline, we experimented with\nvarious techniques to optimize the performance of each module using the FinQA\ndataset. We introduced a novel clustering-based negative sampling technique to\nenhance context extraction and a novel prompting method called Dynamic N-shot\nPrompting to boost the numerical question-answering capabilities of LLMs. At\nthe module level, we achieved state-of-the-art accuracy on FinQA, attaining an\naccuracy of 80.6\\%. However, at the pipeline level, we observed decreased\nperformance due to challenges in extracting relevant context from financial\nreports. We conducted a detailed error analysis of each module and the\nend-to-end pipeline, pinpointing specific challenges that must be addressed to\ndevelop a robust solution for handling complex financial tasks.\n","authors":["Kuldeep Singh","Simerjot Kaur","Charese Smiley"],"pdf_url":"https://arxiv.org/pdf/2410.13959v1.pdf","comment":"Accepted in ICAIF 2024, 8 pages, 5 figures, 4 tables"},{"id":"http://arxiv.org/abs/2410.13951v1","updated":"2024-10-17T18:22:42Z","published":"2024-10-17T18:22:42Z","title":"Identifying High Consideration E-Commerce Search Queries","summary":"  In e-commerce, high consideration search missions typically require careful\nand elaborate decision making, and involve a substantial research investment\nfrom customers. We consider the task of identifying High Consideration (HC)\nqueries. Identifying such queries enables e-commerce sites to better serve user\nneeds using targeted experiences such as curated QA widgets that help users\nreach purchase decisions. We explore the task by proposing an Engagement-based\nQuery Ranking (EQR) approach, focusing on query ranking to indicate potential\nengagement levels with query-related shopping knowledge content during product\nsearch. Unlike previous studies on predicting trends, EQR prioritizes\nquery-level features related to customer behavior, finance, and catalog\ninformation rather than popularity signals. We introduce an accurate and\nscalable method for EQR and present experimental results demonstrating its\neffectiveness. Offline experiments show strong ranking performance. Human\nevaluation shows a precision of 96% for HC queries identified by our model. The\nmodel was commercially deployed, and shown to outperform human-selected queries\nin terms of downstream customer impact, as measured through engagement.\n","authors":["Zhiyu Chen","Jason Choi","Besnik Fetahu","Shervin Malmasi"],"pdf_url":"https://arxiv.org/pdf/2410.13951v1.pdf","comment":"Accepted by EMNLP 2024 (Industry Track)"}]},"2024-10-18T00:00:00Z":{"Computation and Language":[{"id":"http://arxiv.org/abs/2410.13824v2","updated":"2024-10-18T09:01:01Z","published":"2024-10-17T17:48:54Z","title":"Harnessing Webpage UIs for Text-Rich Visual Understanding","summary":"  Text-rich visual understanding-the ability to process environments where\ndense textual content is integrated with visuals-is crucial for multimodal\nlarge language models (MLLMs) to interact effectively with structured\nenvironments. To enhance this capability, we propose synthesizing general\nmultimodal instructions from webpage UIs using text-based large language models\n(LLMs). Despite lacking direct visual input, text-based LLMs are able to\nprocess structured text representations from webpage accessibility trees. These\ninstructions are then paired with UI screenshots to train multimodal models. We\nintroduce MultiUI, a dataset containing 7.3 million samples from 1 million\nwebsites, covering diverse multimodal tasks and UI layouts. Models trained on\nMultiUI not only excel in web UI tasks-achieving up to a 48% improvement on\nVisualWebBench and a 19.1% boost in element accuracy on a web agent dataset\nMind2Web-but also generalize surprisingly well to non-web UI tasks and even to\nnon-UI domains, such as document understanding, OCR, and chart interpretation.\nThese results highlight the broad applicability of web UI data for advancing\ntext-rich visual understanding across various scenarios.\n","authors":["Junpeng Liu","Tianyue Ou","Yifan Song","Yuxiao Qu","Wai Lam","Chenyan Xiong","Wenhu Chen","Graham Neubig","Xiang Yue"],"pdf_url":"https://arxiv.org/pdf/2410.13824v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.13804v2","updated":"2024-10-18T03:15:21Z","published":"2024-10-17T17:41:15Z","title":"BenTo: Benchmark Task Reduction with In-Context Transferability","summary":"  Evaluating large language models (LLMs) is costly: it requires the generation\nand examination of LLM outputs on a large-scale benchmark of various tasks.\nThis paper investigates how to efficiently reduce the tasks used to benchmark\nLLMs without affecting the evaluation quality. Our study reveals that task\ntransferability and relevance provide critical information to identify the most\nrepresentative subset of tasks via optimizing a facility location function. We\npropose a practically efficient metric for estimating the transferability\nbetween two tasks via in-context learning (ICL). By analyzing the pairwise\ntransferability, we can reduce tasks in a modern LLM benchmark (e.g., MMLU or\nFLAN) to 5% while inducing only a <4% difference to the evaluation on the\noriginal benchmark. Compared to prior works, our method is training-free,\ngradient-free, and highly efficient requiring ICL only.\n","authors":["Hongyu Zhao","Ming Li","Lichao Sun","Tianyi Zhou"],"pdf_url":"https://arxiv.org/pdf/2410.13804v2.pdf","comment":"https://github.com/tianyi-lab/bento"},{"id":"http://arxiv.org/abs/2404.16710v4","updated":"2024-10-18T04:02:31Z","published":"2024-04-25T16:20:23Z","title":"LayerSkip: Enabling Early Exit Inference and Self-Speculative Decoding","summary":"  We present LayerSkip, an end-to-end solution to speed-up inference of large\nlanguage models (LLMs). First, during training we apply layer dropout, with low\ndropout rates for earlier layers and higher dropout rates for later layers, and\nan early exit loss where all transformer layers share the same exit. Second,\nduring inference, we show that this training recipe increases the accuracy of\nearly exit at earlier layers, without adding any auxiliary layers or modules to\nthe model. Third, we present a novel self-speculative decoding solution where\nwe exit at early layers and verify and correct with remaining layers of the\nmodel. Our proposed self-speculative decoding approach has less memory\nfootprint than other speculative decoding approaches and benefits from shared\ncompute and activations of the draft and verification stages. We run\nexperiments on different Llama model sizes on different types of training:\npretraining from scratch, continual pretraining, finetuning on specific data\ndomain, and finetuning on specific task. We implement our inference solution\nand show speedups of up to 2.16x on summarization for CNN/DM documents, 1.82x\non coding, and 2.0x on TOPv2 semantic parsing task. We open source our code and\ncheckpoints at https://github.com/facebookresearch/LayerSkip.\n","authors":["Mostafa Elhoushi","Akshat Shrivastava","Diana Liskovich","Basil Hosmer","Bram Wasti","Liangzhen Lai","Anas Mahmoud","Bilge Acun","Saurabh Agarwal","Ahmed Roman","Ahmed A Aly","Beidi Chen","Carole-Jean Wu"],"pdf_url":"https://arxiv.org/pdf/2404.16710v4.pdf","comment":"ACL 2024"},{"id":"http://arxiv.org/abs/2410.13408v2","updated":"2024-10-18T03:05:01Z","published":"2024-10-17T10:14:52Z","title":"MoR: Mixture of Ranks for Low-Rank Adaptation Tuning","summary":"  Low-Rank Adaptation (LoRA) drives research to align its performance with full\nfine-tuning. However, significant challenges remain: (1) Simply increasing the\nrank size of LoRA does not effectively capture high-rank information, which\nleads to a performance bottleneck.(2) MoE-style LoRA methods substantially\nincrease parameters and inference latency, contradicting the goals of efficient\nfine-tuning and ease of application. To address these challenges, we introduce\nMixture of Ranks (MoR), which learns rank-specific information for different\ntasks based on input and efficiently integrates multi-rank information. We\nfirstly propose a new framework that equates the integration of multiple LoRAs\nto expanding the rank of LoRA. Moreover, we hypothesize that low-rank LoRA\nalready captures sufficient intrinsic information, and MoR can derive high-rank\ninformation through mathematical transformations of the low-rank components.\nThus, MoR can reduces the learning difficulty of LoRA and enhances its\nmulti-task capabilities. MoR achieves impressive results, with MoR delivering a\n1.31\\% performance improvement while using only 93.93\\% of the parameters\ncompared to baseline methods.\n","authors":["Chuanyu Tang","Yilong Chen","Zhenyu Zhang","Junyuan Shang","Wenyuan Zhang","Yong Huang","Tingwen Liu"],"pdf_url":"https://arxiv.org/pdf/2410.13408v2.pdf","comment":"11 pages, 7 figures"},{"id":"http://arxiv.org/abs/2410.13281v2","updated":"2024-10-18T09:50:41Z","published":"2024-10-17T07:15:15Z","title":"BANTH: A Multi-label Hate Speech Detection Dataset for Transliterated\n  Bangla","summary":"  The proliferation of transliterated texts in digital spaces has emphasized\nthe need for detecting and classifying hate speech in languages beyond English,\nparticularly in low-resource languages. As online discourse can perpetuate\ndiscrimination based on target groups, e.g. gender, religion, and origin,\nmulti-label classification of hateful content can help in comprehending hate\nmotivation and enhance content moderation. While previous efforts have focused\non monolingual or binary hate classification tasks, no work has yet addressed\nthe challenge of multi-label hate speech classification in transliterated\nBangla. We introduce BanTH, the first multi-label transliterated Bangla hate\nspeech dataset comprising 37.3k samples. The samples are sourced from YouTube\ncomments, where each instance is labeled with one or more target groups,\nreflecting the regional demographic. We establish novel transformer\nencoder-based baselines by further pre-training on transliterated Bangla\ncorpus. We also propose a novel translation-based LLM prompting strategy for\ntransliterated text. Experiments reveal that our further pre-trained encoders\nare achieving state-of-the-art performance on the BanTH dataset, while our\ntranslation-based prompting outperforms other strategies in the zero-shot\nsetting. The introduction of BanTH not only fills a critical gap in hate speech\nresearch for Bangla but also sets the stage for future exploration into\ncode-mixed and multi-label classification challenges in underrepresented\nlanguages.\n","authors":["Fabiha Haider","Fariha Tanjim Shifat","Md Farhan Ishmam","Deeparghya Dutta Barua","Md Sakib Ul Rahman Sourove","Md Fahim","Md Farhad Alam"],"pdf_url":"https://arxiv.org/pdf/2410.13281v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.13276v2","updated":"2024-10-18T05:01:11Z","published":"2024-10-17T07:07:09Z","title":"SeerAttention: Learning Intrinsic Sparse Attention in Your LLMs","summary":"  Attention is the cornerstone of modern Large Language Models (LLMs). Yet its\nquadratic complexity limits the efficiency and scalability of LLMs, especially\nfor those with a long-context window. A promising approach addressing this\nlimitation is to leverage the sparsity in attention. However, existing\nsparsity-based solutions predominantly rely on predefined patterns or\nheuristics to approximate sparsity. This practice falls short to fully capture\nthe dynamic nature of attention sparsity in language-based tasks. This paper\nargues that attention sparsity should be learned rather than predefined. To\nthis end, we design SeerAttention, a new Attention mechanism that augments the\nconventional attention with a learnable gate that adaptively selects\nsignificant blocks in an attention map and deems the rest blocks sparse. Such\nblock-level sparsity effectively balances accuracy and speedup. To enable\nefficient learning of the gating network, we develop a customized\nFlashAttention implementation that extracts the block-level ground truth of\nattention map with minimum overhead. SeerAttention not only applies to\npost-training, but also excels in long-context fine-tuning. Our results show\nthat at post-training stages, SeerAttention significantly outperforms\nstate-of-the-art static or heuristic-based sparse attention methods, while also\nbeing more versatile and flexible to adapt to varying context lengths and\nsparsity ratios. When applied to long-context fine-tuning with YaRN,\nSeerAttention can achieve a remarkable 90% sparsity ratio at a 32k context\nlength with minimal perplexity loss, offering a 5.67x speedup over\nFlashAttention-2.\n","authors":["Yizhao Gao","Zhichen Zeng","Dayou Du","Shijie Cao","Hayden Kwok-Hay So","Ting Cao","Fan Yang","Mao Yang"],"pdf_url":"https://arxiv.org/pdf/2410.13276v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.14677v1","updated":"2024-10-18T17:59:57Z","published":"2024-10-18T17:59:57Z","title":"Are AI Detectors Good Enough? A Survey on Quality of Datasets With\n  Machine-Generated Texts","summary":"  The rapid development of autoregressive Large Language Models (LLMs) has\nsignificantly improved the quality of generated texts, necessitating reliable\nmachine-generated text detectors. A huge number of detectors and collections\nwith AI fragments have emerged, and several detection methods even showed\nrecognition quality up to 99.9% according to the target metrics in such\ncollections. However, the quality of such detectors tends to drop dramatically\nin the wild, posing a question: Are detectors actually highly trustworthy or do\ntheir high benchmark scores come from the poor quality of evaluation datasets?\nIn this paper, we emphasise the need for robust and qualitative methods for\nevaluating generated data to be secure against bias and low generalising\nability of future model. We present a systematic review of datasets from\ncompetitions dedicated to AI-generated content detection and propose methods\nfor evaluating the quality of datasets containing AI-generated fragments. In\naddition, we discuss the possibility of using high-quality generated data to\nachieve two goals: improving the training of detection models and improving the\ntraining datasets themselves. Our contribution aims to facilitate a better\nunderstanding of the dynamics between human and machine text, which will\nultimately support the integrity of information in an increasingly automated\nworld.\n","authors":["German Gritsai","Anastasia Voznyuk","Andrey Grabovoy","Yury Chekhovich"],"pdf_url":"https://arxiv.org/pdf/2410.14677v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.14676v1","updated":"2024-10-18T17:59:51Z","published":"2024-10-18T17:59:51Z","title":"SudoLM: Learning Access Control of Parametric Knowledge with\n  Authorization Alignment","summary":"  Existing preference alignment is a one-size-fits-all alignment mechanism,\nwhere the part of the large language model (LLM) parametric knowledge with\nnon-preferred features is uniformly blocked to all the users. However, this\npart of knowledge can be useful to advanced users whose expertise qualifies\nthem to handle these information. The one-size-fits-all alignment mechanism\nundermines LLM's utility for these qualified users. To address this problem, we\npropose SudoLM, a framework that lets LLMs learn access control over specific\nparametric knowledge for users with different credentials via authorization\nalignment. SudoLM allows authorized users to unlock their access to all the\nparametric knowledge with an assigned SUDO key while blocking access to\nnon-qualified users. Experiments on two application scenarios demonstrate that\nSudoLM effectively controls the user's access to the parametric knowledge and\nmaintains its general utility.\n","authors":["Qin Liu","Fei Wang","Chaowei Xiao","Muhao Chen"],"pdf_url":"https://arxiv.org/pdf/2410.14676v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.14675v1","updated":"2024-10-18T17:59:47Z","published":"2024-10-18T17:59:47Z","title":"Enhancing Large Language Models' Situated Faithfulness to External\n  Contexts","summary":"  Large Language Models (LLMs) are often augmented with external information as\ncontexts, but this external information can sometimes be inaccurate or even\nintentionally misleading. We argue that robust LLMs should demonstrate situated\nfaithfulness, dynamically calibrating their trust in external information based\non their confidence in the internal knowledge and the external context. To\nbenchmark this capability, we evaluate LLMs across several QA datasets,\nincluding a newly created dataset called RedditQA featuring in-the-wild\nincorrect contexts sourced from Reddit posts. We show that when provided with\nboth correct and incorrect contexts, both open-source and proprietary models\ntend to overly rely on external information, regardless of its factual\naccuracy. To enhance situated faithfulness, we propose two approaches:\nSelf-Guided Confidence Reasoning (SCR) and Rule-Based Confidence Reasoning\n(RCR). SCR enables models to self-access the confidence of external information\nrelative to their own internal knowledge to produce the most accurate answer.\nRCR, in contrast, extracts explicit confidence signals from the LLM and\ndetermines the final answer using predefined rules. Our results show that for\nLLMs with strong reasoning capabilities, such as GPT-4o and GPT-4o mini, SCR\noutperforms RCR, achieving improvements of up to 24.2% over a direct input\naugmentation baseline. Conversely, for a smaller model like Llama-3-8B, RCR\noutperforms SCR. Fine-tuning SCR with our proposed Confidence Reasoning Direct\nPreference Optimization (CR-DPO) method improves performance on both seen and\nunseen datasets, yielding an average improvement of 8.9% on Llama-3-8B. In\naddition to quantitative results, we offer insights into the relative strengths\nof SCR and RCR. Our findings highlight promising avenues for improving situated\nfaithfulness in LLMs. The data and code are released.\n","authors":["Yukun Huang","Sanxing Chen","Hongyi Cai","Bhuwan Dhingra"],"pdf_url":"https://arxiv.org/pdf/2410.14675v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.14669v1","updated":"2024-10-18T17:58:21Z","published":"2024-10-18T17:58:21Z","title":"NaturalBench: Evaluating Vision-Language Models on Natural Adversarial\n  Samples","summary":"  Vision-language models (VLMs) have made significant progress in recent\nvisual-question-answering (VQA) benchmarks that evaluate complex\nvisio-linguistic reasoning. However, are these models truly effective? In this\nwork, we show that VLMs still struggle with natural images and questions that\nhumans can easily answer, which we term natural adversarial samples. We also\nfind it surprisingly easy to generate these VQA samples from natural image-text\ncorpora using off-the-shelf models like CLIP and ChatGPT. We propose a\nsemi-automated approach to collect a new benchmark, NaturalBench, for reliably\nevaluating VLMs with 10,000 human-verified VQA samples. Crucially, we adopt a\n$\\textbf{vision-centric}$ design by pairing each question with two images that\nyield different answers, preventing blind solutions from answering without\nusing the images. This makes NaturalBench more challenging than previous\nbenchmarks that can be solved with commonsense priors. We evaluate 53\nstate-of-the-art VLMs on NaturalBench, showing that models like\nLLaVA-OneVision, Cambrian-1, Llama3.2-Vision, Molmo, Qwen2-VL, and even GPT-4o\nlag 50%-70% behind human performance (over 90%). We analyze why NaturalBench is\nhard from two angles: (1) Compositionality: Solving NaturalBench requires\ndiverse visio-linguistic skills, including understanding attribute bindings,\nobject relationships, and advanced reasoning like logic and counting. To this\nend, unlike prior work that uses a single tag per sample, we tag each\nNaturalBench sample with 1 to 8 skill tags for fine-grained evaluation. (2)\nBiases: NaturalBench exposes severe biases in VLMs, as models often choose the\nsame answer regardless of the image. Lastly, we apply our benchmark curation\nmethod to diverse data sources, including long captions (over 100 words) and\nnon-English languages like Chinese and Hindi, highlighting its potential for\ndynamic evaluations of VLMs.\n","authors":["Baiqi Li","Zhiqiu Lin","Wenxuan Peng","Jean de Dieu Nyandwi","Daniel Jiang","Zixian Ma","Simran Khanuja","Ranjay Krishna","Graham Neubig","Deva Ramanan"],"pdf_url":"https://arxiv.org/pdf/2410.14669v1.pdf","comment":"Accepted to NeurIPS 24; We open-source our dataset at:\n  https://huggingface.co/datasets/BaiqiL/NaturalBench; Project page at:\n  https://linzhiqiu.github.io/papers/naturalbench/"},{"id":"http://arxiv.org/abs/2410.14668v1","updated":"2024-10-18T17:57:40Z","published":"2024-10-18T17:57:40Z","title":"MiCEval: Unveiling Multimodal Chain of Thought's Quality via Image\n  Description and Reasoning Steps","summary":"  Multimodal Chain of Thought (MCoT) is a popular prompting strategy for\nimproving the performance of multimodal large language models (MLLMs) across a\nrange of complex reasoning tasks. Despite its popularity, there is a notable\nabsence of automated methods for evaluating the quality of reasoning steps in\nMCoT. To address this gap, we propose Multimodal Chain-of-Thought Evaluation\n(MiCEval), a framework designed to assess the correctness of reasoning chains\nby evaluating the quality of both the description and each reasoning step. The\nevaluation of the description component focuses on the accuracy of the image\ndescriptions, while the reasoning step evaluates the quality of each step as it\nis conditionally generated based on the preceding steps. MiCEval is built upon\na fine-grained dataset with annotations that rate each step according to\ncorrectness, relevance, and informativeness. Extensive experiments on four\nstate-of-the-art MLLMs show that step-wise evaluations using MiCEval align more\nclosely with human judgments compared to existing methods based on cosine\nsimilarity or fine-tuning approaches. MiCEval datasets and code can be found in\nhttps://github.com/alenai97/MiCEval.\n","authors":["Xiongtao Zhou","Jie He","Lanyu Chen","jingyu li","Haojing Chen","Victor Gutierrez Basulto","Jeff Z. Pan","Hanjie Chen"],"pdf_url":"https://arxiv.org/pdf/2410.14668v1.pdf","comment":"40 pages"},{"id":"http://arxiv.org/abs/2410.14666v1","updated":"2024-10-18T17:56:11Z","published":"2024-10-18T17:56:11Z","title":"DiscoGraMS: Enhancing Movie Screen-Play Summarization using Movie\n  Character-Aware Discourse Graph","summary":"  Summarizing movie screenplays presents a unique set of challenges compared to\nstandard document summarization. Screenplays are not only lengthy, but also\nfeature a complex interplay of characters, dialogues, and scenes, with numerous\ndirect and subtle relationships and contextual nuances that are difficult for\nmachine learning models to accurately capture and comprehend. Recent attempts\nat screenplay summarization focus on fine-tuning transformer-based pre-trained\nmodels, but these models often fall short in capturing long-term dependencies\nand latent relationships, and frequently encounter the \"lost in the middle\"\nissue. To address these challenges, we introduce DiscoGraMS, a novel resource\nthat represents movie scripts as a movie character-aware discourse graph (CaD\nGraph). This approach is well-suited for various downstream tasks, such as\nsummarization, question-answering, and salience detection. The model aims to\npreserve all salient information, offering a more comprehensive and faithful\nrepresentation of the screenplay's content. We further explore a baseline\nmethod that combines the CaD Graph with the corresponding movie script through\na late fusion of graph and text modalities, and we present very initial\npromising results.\n","authors":["Maitreya Prafulla Chitale","Uday Bindal","Rajakrishnan Rajkumar","Rahul Mishra"],"pdf_url":"https://arxiv.org/pdf/2410.14666v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.06331v2","updated":"2024-10-18T17:53:46Z","published":"2024-10-08T20:12:11Z","title":"Locate-then-edit for Multi-hop Factual Recall under Knowledge Editing","summary":"  The locate-then-edit paradigm has shown significant promise for knowledge\nediting (KE) in Large Language Models (LLMs). While previous methods perform\nwell on single-hop fact recall tasks, they consistently struggle with multi-hop\nfactual recall tasks involving newly edited knowledge. In this paper,\nleveraging tools in mechanistic interpretability, we first identify that in\nmulti-hop tasks, LLMs tend to retrieve implicit subject knowledge from deeper\nMLP layers, unlike single-hop tasks, which rely on earlier layers. This\ndistinction explains the poor performance of current methods in multi-hop\nqueries, as they primarily focus on editing shallow layers, leaving deeper\nlayers unchanged. To address this, we propose IFMET, a novel locate-then-edit\nKE approach designed to edit both shallow and deep MLP layers. IFMET employs\nmulti-hop editing prompts and supplementary sets to locate and modify knowledge\nacross different reasoning stages. Experimental results demonstrate that IFMET\nsignificantly improves performance on multi-hop factual recall tasks,\neffectively overcoming the limitations of previous locate-then-edit methods.\n","authors":["Zhuoran Zhang","Yongxiang Li","Zijian Kan","Keyuan Cheng","Lijie Hu","Di Wang"],"pdf_url":"https://arxiv.org/pdf/2410.06331v2.pdf","comment":"21 pages"},{"id":"http://arxiv.org/abs/2410.14651v1","updated":"2024-10-18T17:47:11Z","published":"2024-10-18T17:47:11Z","title":"Real-time Fake News from Adversarial Feedback","summary":"  We show that existing evaluations for fake news detection based on\nconventional sources, such as claims on fact-checking websites, result in an\nincreasing accuracy over time for LLM-based detectors -- even after their\nknowledge cutoffs. This suggests that recent popular political claims, which\nform the majority of fake news on such sources, are easily classified using\nsurface-level shallow patterns. Instead, we argue that a proper fake news\ndetection dataset should test a model's ability to reason factually about the\ncurrent world by retrieving and reading related evidence. To this end, we\ndevelop a novel pipeline that leverages natural language feedback from a\nRAG-based detector to iteratively modify real-time news into deceptive fake\nnews that challenges LLMs. Our iterative rewrite decreases the binary\nclassification AUC by an absolute 17.5 percent for a strong RAG GPT-4o\ndetector. Our experiments reveal the important role of RAG in both detecting\nand generating fake news, as retrieval-free LLM detectors are vulnerable to\nunseen events and adversarial attacks, while feedback from RAG detection helps\ndiscover more deceitful patterns in fake news.\n","authors":["Sanxing Chen","Yukun Huang","Bhuwan Dhingra"],"pdf_url":"https://arxiv.org/pdf/2410.14651v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.14641v1","updated":"2024-10-18T17:41:19Z","published":"2024-10-18T17:41:19Z","title":"Distance between Relevant Information Pieces Causes Bias in Long-Context\n  LLMs","summary":"  Positional bias in large language models (LLMs) hinders their ability to\neffectively process long inputs. A prominent example is the \"lost in the\nmiddle\" phenomenon, where LLMs struggle to utilize relevant information\nsituated in the middle of the input. While prior research primarily focuses on\nsingle pieces of relevant information, real-world applications often involve\nmultiple relevant information pieces. To bridge this gap, we present\nLongPiBench, a benchmark designed to assess positional bias involving multiple\npieces of relevant information. Thorough experiments are conducted with five\ncommercial and six open-source models. These experiments reveal that while most\ncurrent models are robust against the \"lost in the middle\" issue, there exist\nsignificant biases related to the spacing of relevant information pieces. These\nfindings highlight the importance of evaluating and reducing positional biases\nto advance LLM's capabilities.\n","authors":["Runchu Tian","Yanghao Li","Yuepeng Fu","Siyang Deng","Qinyu Luo","Cheng Qian","Shuo Wang","Xin Cong","Zhong Zhang","Yesai Wu","Yankai Lin","Huadong Wang","Xiaojiang Liu"],"pdf_url":"https://arxiv.org/pdf/2410.14641v1.pdf","comment":"work in progress"},{"id":"http://arxiv.org/abs/2410.14635v1","updated":"2024-10-18T17:36:53Z","published":"2024-10-18T17:36:53Z","title":"GenEOL: Harnessing the Generative Power of LLMs for Training-Free\n  Sentence Embeddings","summary":"  Training-free embedding methods directly leverage pretrained large language\nmodels (LLMs) to embed text, bypassing the costly and complex procedure of\ncontrastive learning. Previous training-free embedding methods have mainly\nfocused on optimizing embedding prompts and have overlooked the benefits of\nutilizing the generative abilities of LLMs. We propose a novel method, GenEOL,\nwhich uses LLMs to generate diverse transformations of a sentence that preserve\nits meaning, and aggregates the resulting embeddings of these transformations\nto enhance the overall sentence embedding. GenEOL significantly outperforms the\nexisting training-free embedding methods by an average of 2.85 points across\nseveral LLMs on the sentence semantic text similarity (STS) benchmark. Our\nanalysis shows that GenEOL stabilizes representation quality across LLM layers\nand is robust to perturbations of embedding prompts. GenEOL also achieves\nnotable gains on multiple clustering, reranking and pair-classification tasks\nfrom the MTEB benchmark.\n","authors":["Raghuveer Thirukovalluru","Bhuwan Dhingra"],"pdf_url":"https://arxiv.org/pdf/2410.14635v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.14632v1","updated":"2024-10-18T17:32:22Z","published":"2024-10-18T17:32:22Z","title":"Diverging Preferences: When do Annotators Disagree and do Models Know?","summary":"  We examine diverging preferences in human-labeled preference datasets. We\ndevelop a taxonomy of disagreement sources spanning 10 categories across four\nhigh-level classes -- task underspecification, response style, refusals, and\nannotation errors. We find that the majority of disagreements are in opposition\nwith standard reward modeling approaches, which are designed with the\nassumption that annotator disagreement is noise. We then explore how these\nfindings impact two areas of LLM development: reward modeling and evaluation.\nIn our experiments, we demonstrate how standard reward modeling methods, like\nthe Bradley-Terry model, fail to differentiate whether a given preference\njudgment is the result of unanimous agreement among annotators or the majority\nopinion among diverging user preferences. We also find that these tendencies\nare also echoed by popular LLM-as-Judge evaluation methods, which consistently\nidentify a winning response in cases of diverging preferences. These findings\nhighlight remaining challenges in LLM evaluations, which are greatly influenced\nby divisive features like response style, and in developing pluralistically\naligned LLMs. To address these issues, we develop methods for identifying\ndiverging preferences to mitigate their influence on evaluation and training.\n","authors":["Michael JQ Zhang","Zhilin Wang","Jena D. Hwang","Yi Dong","Olivier Delalleau","Yejin Choi","Eunsol Choi","Xiang Ren","Valentina Pyatkin"],"pdf_url":"https://arxiv.org/pdf/2410.14632v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.07114v2","updated":"2024-10-18T17:30:04Z","published":"2024-09-19T19:48:31Z","title":"System 2 thinking in OpenAI's o1-preview model: Near-perfect performance\n  on a mathematics exam","summary":"  The processes underlying human cognition are often divided into System 1,\nwhich involves fast, intuitive thinking, and System 2, which involves slow,\ndeliberate reasoning. Previously, large language models were criticized for\nlacking the deeper, more analytical capabilities of System 2. In September\n2024, OpenAI introduced the o1 model series, designed to handle System 2-like\nreasoning. While OpenAI's benchmarks are promising, independent validation is\nstill needed. In this study, we tested the o1-preview model twice on the Dutch\n'Mathematics B' final exam. It scored a near-perfect 76 and 74 out of 76\npoints. For context, only 24 out of 16,414 students in the Netherlands achieved\na perfect score. By comparison, the GPT-4o model scored 66 and 62 out of 76,\nwell above the Dutch average of 40.63 points. Neither model had access to the\nexam figures. Since there was a risk of model contamination (i.e., the\nknowledge cutoff of o1-preview and GPT-4o was after the exam was published\nonline), we repeated the procedure with a new Mathematics B exam that was\npublished after the cutoff date. The results again indicated that o1-preview\nperformed strongly (97.8th percentile), which suggests that contamination was\nnot a factor. We also show that there is some variability in the output of\no1-preview, which means that sometimes there is 'luck' (the answer is correct)\nor 'bad luck' (the output has diverged into something that is incorrect). We\ndemonstrate that a self-consistency approach, where repeated prompts are given\nand the most common answer is selected, is a useful strategy for identifying\nthe correct answer. It is concluded that while OpenAI's new model series holds\ngreat potential, certain risks must be considered.\n","authors":["Joost de Winter","Dimitra Dodou","Yke Bauke Eisma"],"pdf_url":"https://arxiv.org/pdf/2410.07114v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.14627v1","updated":"2024-10-18T17:29:56Z","published":"2024-10-18T17:29:56Z","title":"CELI: Controller-Embedded Language Model Interactions","summary":"  We introduce Controller-Embedded Language Model Interactions (CELI), a\nframework that integrates control logic directly within language model (LM)\nprompts, facilitating complex, multi-stage task execution. CELI addresses\nlimitations of existing prompt engineering and workflow optimization techniques\nby embedding control logic directly within the operational context of language\nmodels, enabling dynamic adaptation to evolving task requirements. Our\nframework transfers control from the traditional programming execution\nenvironment to the LMs, allowing them to autonomously manage computational\nworkflows while maintaining seamless interaction with external systems and\nfunctions. CELI supports arbitrary function calls with variable arguments,\nbridging the gap between LMs' adaptive reasoning capabilities and conventional\nsoftware paradigms' structured control mechanisms. To evaluate CELI's\nversatility and effectiveness, we conducted case studies in two distinct\ndomains: code generation (HumanEval benchmark) and multi-stage content\ngeneration (Wikipedia-style articles). The results demonstrate notable\nperformance improvements across a range of domains. CELI achieved a 4.9\npercentage point improvement over the best reported score of the baseline GPT-4\nmodel on the HumanEval code generation benchmark. In multi-stage content\ngeneration, 94.4% of CELI-produced Wikipedia-style articles met or exceeded\nfirst draft quality when optimally configured, with 44.4% achieving high\nquality. These outcomes underscore CELI's potential for optimizing AI-driven\nworkflows across diverse computational domains.\n","authors":["Jan-Samuel Wagner","Dave DeCaprio","Abishek Chiffon Muthu Raja","Jonathan M. Holman","Lauren K. Brady","Sky C. Cheung","Hosein Barzekar","Eric Yang","Mark Anthony Martinez II","David Soong","Sriram Sridhar","Han Si","Brandon W. Higgs","Hisham Hamadeh","Scott Ogden"],"pdf_url":"https://arxiv.org/pdf/2410.14627v1.pdf","comment":"26 pages, 2 figures"},{"id":"http://arxiv.org/abs/2410.14626v1","updated":"2024-10-18T17:27:38Z","published":"2024-10-18T17:27:38Z","title":"You Shall Know a Tool by the Traces it Leaves: The Predictability of\n  Sentiment Analysis Tools","summary":"  If sentiment analysis tools were valid classifiers, one would expect them to\nprovide comparable results for sentiment classification on different kinds of\ncorpora and for different languages. In line with results of previous studies\nwe show that sentiment analysis tools disagree on the same dataset. Going\nbeyond previous studies we show that the sentiment tool used for sentiment\nannotation can even be predicted from its outcome, revealing an algorithmic\nbias of sentiment analysis. Based on Twitter, Wikipedia and different news\ncorpora from the English, German and French languages, our classifiers separate\nsentiment tools with an averaged F1-score of 0.89 (for the English corpora). We\ntherefore warn against taking sentiment annotations as face value and argue for\nthe need of more and systematic NLP evaluation studies.\n","authors":["Daniel Baumartz","Mevlüt Bagci","Alexander Henlein","Maxim Konca","Andy Lücking","Alexander Mehler"],"pdf_url":"https://arxiv.org/pdf/2410.14626v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.10989v2","updated":"2024-10-18T17:21:17Z","published":"2024-10-14T18:17:01Z","title":"Liger Kernel: Efficient Triton Kernels for LLM Training","summary":"  Training Large Language Models (LLMs) efficiently at scale presents a\nformidable challenge, driven by their ever-increasing computational demands and\nthe need for enhanced performance. In this work, we introduce Liger-Kernel, an\nopen-sourced set of Triton kernels developed specifically for LLM training.\nWith kernel optimization techniques like kernel operation fusing and input\nchunking, our kernels achieve on average a 20% increase in training throughput\nand a 60% reduction in GPU memory usage for popular LLMs compared to\nHuggingFace implementations. In addition, Liger-Kernel is designed with\nmodularity, accessibility, and adaptability in mind, catering to both casual\nand expert users. Comprehensive benchmarks and integration tests are built in\nto ensure compatibility, performance, correctness, and convergence across\ndiverse computing environments and model architectures.\n  The source code is available under a permissive license at:\ngithub.com/linkedin/Liger-Kernel.\n","authors":["Pin-Lun Hsu","Yun Dai","Vignesh Kothapalli","Qingquan Song","Shao Tang","Siyu Zhu","Steven Shimizu","Shivam Sahni","Haowen Ning","Yanning Chen"],"pdf_url":"https://arxiv.org/pdf/2410.10989v2.pdf","comment":"17 pages, 12 figures"},{"id":"http://arxiv.org/abs/2410.02525v3","updated":"2024-10-18T17:18:24Z","published":"2024-10-03T14:33:34Z","title":"Contextual Document Embeddings","summary":"  Dense document embeddings are central to neural retrieval. The dominant\nparadigm is to train and construct embeddings by running encoders directly on\nindividual documents. In this work, we argue that these embeddings, while\neffective, are implicitly out-of-context for targeted use cases of retrieval,\nand that a contextualized document embedding should take into account both the\ndocument and neighboring documents in context - analogous to contextualized\nword embeddings. We propose two complementary methods for contextualized\ndocument embeddings: first, an alternative contrastive learning objective that\nexplicitly incorporates the document neighbors into the intra-batch contextual\nloss; second, a new contextual architecture that explicitly encodes neighbor\ndocument information into the encoded representation. Results show that both\nmethods achieve better performance than biencoders in several settings, with\ndifferences especially pronounced out-of-domain. We achieve state-of-the-art\nresults on the MTEB benchmark with no hard negative mining, score distillation,\ndataset-specific instructions, intra-GPU example-sharing, or extremely large\nbatch sizes. Our method can be applied to improve performance on any\ncontrastive learning dataset and any biencoder.\n","authors":["John X. Morris","Alexander M. Rush"],"pdf_url":"https://arxiv.org/pdf/2410.02525v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.10101v2","updated":"2024-10-18T17:15:09Z","published":"2024-10-14T02:41:01Z","title":"Learning Linear Attention in Polynomial Time","summary":"  Previous research has explored the computational expressivity of Transformer\nmodels in simulating Boolean circuits or Turing machines. However, the\nlearnability of these simulators from observational data has remained an open\nquestion. Our study addresses this gap by providing the first polynomial-time\nlearnability results (specifically strong, agnostic PAC learning) for\nsingle-layer Transformers with linear attention. We show that linear attention\nmay be viewed as a linear predictor in a suitably defined RKHS. As a\nconsequence, the problem of learning any linear transformer may be converted\ninto the problem of learning an ordinary linear predictor in an expanded\nfeature space, and any such predictor may be converted back into a multiheaded\nlinear transformer. Moving to generalization, we show how to efficiently\nidentify training datasets for which every empirical risk minimizer is\nequivalent (up to trivial symmetries) to the linear Transformer that generated\nthe data, thereby guaranteeing the learned model will correctly generalize\nacross all inputs. Finally, we provide examples of computations expressible via\nlinear attention and therefore polynomial-time learnable, including associative\nmemories, finite automata, and a class of Universal Turing Machine (UTMs) with\npolynomially bounded computation histories. We empirically validate our\ntheoretical findings on three tasks: learning random linear attention networks,\nkey--value associations, and learning to execute finite automata. Our findings\nbridge a critical gap between theoretical expressivity and learnability of\nTransformers, and show that flexible and general models of computation are\nefficiently learnable.\n","authors":["Morris Yau","Ekin Akyürek","Jiayuan Mao","Joshua B. Tenenbaum","Stefanie Jegelka","Jacob Andreas"],"pdf_url":"https://arxiv.org/pdf/2410.10101v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.06402v2","updated":"2024-10-18T17:10:05Z","published":"2024-03-11T03:28:13Z","title":"One size doesn't fit all: Predicting the Number of Examples for\n  In-Context Learning","summary":"  In-context learning (ICL) refers to the process of adding a small number of\nlocalized examples (ones that are semantically similar to the input) from a\ntraining set of labelled data to an LLM's prompt with an objective to\neffectively control the generative process seeking to improve the downstream\ntask performance. Existing ICL approaches use an identical number of examples\n(a pre-configured hyper-parameter) for each data instance. Our work alleviates\nthe limitations of this 'one fits all' approach by dynamically predicting the\nnumber of examples for each data instance to be used in few-shot inference with\nLLMs. In particular, we employ a multi-label classifier, the parameters of\nwhich are fitted using a training set, where the label for each instance in the\ntraining set indicates if using a specific value of k (number of most similar\nexamples from 0 up to a maximum value) leads to correct k-shot downstream\npredictions. Our experiments on a number of text classification benchmarks show\nthat AICL substantially outperforms standard ICL by up to 17%.\n","authors":["Manish Chandra","Debasis Ganguly","Iadh Ounis"],"pdf_url":"https://arxiv.org/pdf/2403.06402v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.14609v1","updated":"2024-10-18T17:03:17Z","published":"2024-10-18T17:03:17Z","title":"DiSCo Meets LLMs: A Unified Approach for Sparse Retrieval and Contextual\n  Distillation in Conversational Search","summary":"  Conversational Search (CS) is the task of retrieving relevant documents from\na corpus within a conversational context, combining retrieval with\nconversational context modeling. With the explosion of Large Language Models\n(LLMs), the CS field has seen major improvements with LLMs rewriting user\nqueries, accounting for conversational context. However, engaging LLMs at\ninference time harms efficiency. Current methods address this by distilling\nembeddings from human-rewritten queries to learn the context modeling task.\nYet, these approaches predominantly focus on context modeling, and only treat\nthe contrastive component of the retrieval task within a\ndistillation-independent loss term. To address these limitations, we propose a\nnew distillation method, as a relaxation of the previous objective, unifying\nretrieval and context modeling. We relax the existing training objectives by\ndistilling similarity scores between conversations and documents, rather than\nrelying solely on representation learning. Our proposed distillation objective\nallows for more freedom in the representation space and leverages the\ncontrastive nature of document relevance. Through experiments on Learned Sparse\nRetrieval (LSR) across 5 CS datasets, our approach demonstrates substantial\nimprovements in both in-domain and out-of-domain retrieval performance,\noutperforming state-of-the-art with gains of up to 6 points in recall for\nout-of-domain datasets. Additionally, through the relaxation of the objective,\nwe propose a multi-teacher distillation, using multiple LLMs as teachers,\nyielding additional gains, and outperforming the teachers themselves in\nin-domain experiments. Finally, analysis of the sparsity of the models reveals\nthat our distillation allows for better control over the sparsity of the\ntrained models.\n","authors":["Simon Lupart","Mohammad Aliannejadi","Evangelos Kanoulas"],"pdf_url":"https://arxiv.org/pdf/2410.14609v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.14596v1","updated":"2024-10-18T16:49:36Z","published":"2024-10-18T16:49:36Z","title":"Teaching Models to Balance Resisting and Accepting Persuasion","summary":"  Large language models (LLMs) are susceptible to persuasion, which can pose\nrisks when models are faced with an adversarial interlocutor. We take a first\nstep towards defending models against persuasion while also arguing that\ndefense against adversarial (i.e. negative) persuasion is only half of the\nequation: models should also be able to accept beneficial (i.e. positive)\npersuasion to improve their answers. We show that optimizing models for only\none side results in poor performance on the other. In order to balance positive\nand negative persuasion, we introduce Persuasion-Balanced Training (or PBT),\nwhich leverages multi-agent recursive dialogue trees to create data and trains\nmodels via preference optimization to accept persuasion when appropriate. PBT\nconsistently improves resistance to misinformation and resilience to being\nchallenged while also resulting in the best overall performance on holistic\ndata containing both positive and negative persuasion. Crucially, we show that\nPBT models are better teammates in multi-agent debates. We find that without\nPBT, pairs of stronger and weaker models have unstable performance, with the\norder in which the models present their answers determining whether the team\nobtains the stronger or weaker model's performance. PBT leads to better and\nmore stable results and less order dependence, with the stronger model\nconsistently pulling the weaker one up.\n","authors":["Elias Stengel-Eskin","Peter Hase","Mohit Bansal"],"pdf_url":"https://arxiv.org/pdf/2410.14596v1.pdf","comment":"Code: https://github.com/esteng/persuasion_balanced_training"},{"id":"http://arxiv.org/abs/2410.14594v1","updated":"2024-10-18T16:44:22Z","published":"2024-10-18T16:44:22Z","title":"Toolshed: Scale Tool-Equipped Agents with Advanced RAG-Tool Fusion and\n  Tool Knowledge Bases","summary":"  Recent advancements in tool-equipped Agents (LLMs) have enabled complex tasks\nlike secure database interactions and multi-agent code development. However,\nscaling tool capacity beyond agent reasoning or model limits remains a\nchallenge. In this paper, we address these challenges by introducing Toolshed\nKnowledge Bases, a tool knowledge base (vector database) designed to store\nenhanced tool representations and optimize tool selection for large-scale\ntool-equipped Agents. Additionally, we propose Advanced RAG-Tool Fusion, a\nnovel ensemble of tool-applied advanced retrieval-augmented generation (RAG)\ntechniques across the pre-retrieval, intra-retrieval, and post-retrieval\nphases, without requiring model fine-tuning. During pre-retrieval, tool\ndocuments are enhanced with key information and stored in the Toolshed\nKnowledge Base. Intra-retrieval focuses on query planning and transformation to\nincrease retrieval accuracy. Post-retrieval refines the retrieved tool\ndocuments and enables self-reflection. Furthermore, by varying both the total\nnumber of tools (tool-M) an Agent has access to and the tool selection\nthreshold (top-k), we address trade-offs between retrieval accuracy, agent\nperformance, and token cost. Our approach achieves 46%, 56%, and 47% absolute\nimprovements on the ToolE single-tool, ToolE multi-tool and Seal-Tools\nbenchmark datasets, respectively (Recall@5).\n","authors":["Elias Lumer"],"pdf_url":"https://arxiv.org/pdf/2410.14594v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2404.13370v2","updated":"2024-10-18T16:44:05Z","published":"2024-04-20T13:15:27Z","title":"Movie101v2: Improved Movie Narration Benchmark","summary":"  Automatic movie narration aims to generate video-aligned plot descriptions to\nassist visually impaired audiences. Unlike standard video captioning, it\ninvolves not only describing key visual details but also inferring plots that\nunfold across multiple movie shots, presenting distinct and complex challenges.\nTo advance this field, we introduce Movie101v2, a large-scale, bilingual\ndataset with enhanced data quality specifically designed for movie narration.\nRevisiting the task, we propose breaking down the ultimate goal of automatic\nmovie narration into three progressive stages, offering a clear roadmap with\ncorresponding evaluation metrics. Based on our new benchmark, we baseline a\nrange of large vision-language models, including GPT-4V, and conduct an\nin-depth analysis of the challenges in narration generation. Our findings\nhighlight that achieving applicable movie narration generation is a fascinating\ngoal that requires significant research.\n","authors":["Zihao Yue","Yepeng Zhang","Ziheng Wang","Qin Jin"],"pdf_url":"https://arxiv.org/pdf/2404.13370v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.13191v2","updated":"2024-10-18T16:42:01Z","published":"2024-10-17T03:38:29Z","title":"MCQG-SRefine: Multiple Choice Question Generation and Evaluation with\n  Iterative Self-Critique, Correction, and Comparison Feedback","summary":"  Automatic question generation (QG) is essential for AI and NLP, particularly\nin intelligent tutoring, dialogue systems, and fact verification. Generating\nmultiple-choice questions (MCQG) for professional exams, like the United States\nMedical Licensing Examination (USMLE), is particularly challenging, requiring\ndomain expertise and complex multi-hop reasoning for high-quality questions.\nHowever, current large language models (LLMs) like GPT-4 struggle with\nprofessional MCQG due to outdated knowledge, hallucination issues, and prompt\nsensitivity, resulting in unsatisfactory quality and difficulty. To address\nthese challenges, we propose MCQG-SRefine, an LLM self-refine-based (Critique\nand Correction) framework for converting medical cases into high-quality\nUSMLE-style questions. By integrating expert-driven prompt engineering with\niterative self-critique and self-correction feedback, MCQG-SRefine\nsignificantly enhances human expert satisfaction regarding both the quality and\ndifficulty of the questions. Furthermore, we introduce an LLM-as-Judge-based\nautomatic metric to replace the complex and costly expert evaluation process,\nensuring reliable and expert-aligned assessments.\n","authors":["Zonghai Yao","Aditya Parashar","Huixue Zhou","Won Seok Jang","Feiyun Ouyang","Zhichao Yang","Hong Yu"],"pdf_url":"https://arxiv.org/pdf/2410.13191v2.pdf","comment":"Equal contribution for the first two authors"},{"id":"http://arxiv.org/abs/2410.14589v1","updated":"2024-10-18T16:39:42Z","published":"2024-10-18T16:39:42Z","title":"Dialetto, ma Quanto Dialetto? Transcribing and Evaluating Dialects on a\n  Continuum","summary":"  There is increasing interest in looking at dialects in NLP. However, most\nwork to date still treats dialects as discrete categories. For instance,\nevaluative work in variation-oriented NLP for English often works with Indian\nEnglish or African-American Venacular English as homogeneous categories (Faisal\net al., 2024; Ziems et al., 2023), yet even within one variety there is\nsubstantial variation. We examine within-dialect variation and show that\nperformance critically varies within categories. We measure speech-to-text\nperformance on Italian dialects, and empirically observe a geographical\nperformance disparity. This disparity correlates substantially (-0.5) with\nlinguistic similarity to the highest performing dialect variety. We\ncross-examine our results against dialectometry methods, and interpret the\nperformance disparity to be due to a bias towards dialects that are more\nsimilar to the standard variety in the speech-to-text model examined. We\nadditionally leverage geostatistical methods to predict zero-shot performance\nat unseen sites, and find the incorporation of geographical information to\nsubstantially improve prediction performance, indicating there to be\ngeographical structure in the performance distribution.\n","authors":["Ryan Soh-Eun Shim","Barbara Plank"],"pdf_url":"https://arxiv.org/pdf/2410.14589v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.14582v1","updated":"2024-10-18T16:32:10Z","published":"2024-10-18T16:32:10Z","title":"Do LLMs estimate uncertainty well in instruction-following?","summary":"  Large language models (LLMs) could be valuable personal AI agents across\nvarious domains, provided they can precisely follow user instructions. However,\nrecent studies have shown significant limitations in LLMs'\ninstruction-following capabilities, raising concerns about their reliability in\nhigh-stakes applications. Accurately estimating LLMs' uncertainty in adhering\nto instructions is critical to mitigating deployment risks. We present, to our\nknowledge, the first systematic evaluation of the uncertainty estimation\nabilities of LLMs in the context of instruction-following. Our study identifies\nkey challenges with existing instruction-following benchmarks, where multiple\nfactors are entangled with uncertainty stems from instruction-following,\ncomplicating the isolation and comparison across methods and models. To address\nthese issues, we introduce a controlled evaluation setup with two benchmark\nversions of data, enabling a comprehensive comparison of uncertainty estimation\nmethods under various conditions. Our findings show that existing uncertainty\nmethods struggle, particularly when models make subtle errors in instruction\nfollowing. While internal model states provide some improvement, they remain\ninadequate in more complex scenarios. The insights from our controlled\nevaluation setups provide a crucial understanding of LLMs' limitations and\npotential for uncertainty estimation in instruction-following tasks, paving the\nway for more trustworthy AI agents.\n","authors":["Juyeon Heo","Miao Xiong","Christina Heinze-Deml","Jaya Narain"],"pdf_url":"https://arxiv.org/pdf/2410.14582v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.14581v1","updated":"2024-10-18T16:32:06Z","published":"2024-10-18T16:32:06Z","title":"Optimizing Attention with Mirror Descent: Generalized Max-Margin Token\n  Selection","summary":"  Attention mechanisms have revolutionized several domains of artificial\nintelligence, such as natural language processing and computer vision, by\nenabling models to selectively focus on relevant parts of the input data. While\nrecent work has characterized the optimization dynamics of gradient descent\n(GD) in attention-based models and the structural properties of its preferred\nsolutions, less is known about more general optimization algorithms such as\nmirror descent (MD). In this paper, we investigate the convergence properties\nand implicit biases of a family of MD algorithms tailored for softmax attention\nmechanisms, with the potential function chosen as the $p$-th power of the\n$\\ell_p$-norm. Specifically, we show that these algorithms converge in\ndirection to a generalized hard-margin SVM with an $\\ell_p$-norm objective when\napplied to a classification problem using a softmax attention model. Notably,\nour theoretical results reveal that the convergence rate is comparable to that\nof traditional GD in simpler models, despite the highly nonlinear and nonconvex\nnature of the present problem. Additionally, we delve into the joint\noptimization dynamics of the key-query matrix and the decoder, establishing\nconditions under which this complex joint optimization converges to their\nrespective hard-margin SVM solutions. Lastly, our numerical experiments on real\ndata demonstrate that MD algorithms improve generalization over standard GD and\nexcel in optimal token selection.\n","authors":["Aaron Alvarado Kristanto Julistiono","Davoud Ataee Tarzanagh","Navid Azizan"],"pdf_url":"https://arxiv.org/pdf/2410.14581v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.14578v1","updated":"2024-10-18T16:26:45Z","published":"2024-10-18T16:26:45Z","title":"Large Language Models Are Overparameterized Text Encoders","summary":"  Large language models (LLMs) demonstrate strong performance as text embedding\nmodels when finetuned with supervised contrastive training. However, their\nlarge size balloons inference time and memory requirements. In this paper, we\nshow that by pruning the last $p\\%$ layers of an LLM before supervised training\nfor only 1000 steps, we can achieve a proportional reduction in memory and\ninference time. We evaluate four different state-of-the-art LLMs on text\nembedding tasks and find that our method can prune up to 30\\% of layers with\nnegligible impact on performance and up to 80\\% with only a modest drop. With\nonly three lines of code, our method is easily implemented in any pipeline for\ntransforming LLMs to text encoders. We also propose $\\text{L}^3 \\text{Prune}$,\na novel layer-pruning strategy based on the model's initial loss that provides\ntwo optimal pruning configurations: a large variant with negligible performance\nloss and a small variant for resource-constrained settings. On average, the\nlarge variant prunes 21\\% of the parameters with a $-0.3$ performance drop, and\nthe small variant only suffers from a $-5.1$ decrease while pruning 74\\% of the\nmodel. We consider these results strong evidence that LLMs are\noverparameterized for text embedding tasks, and can be easily pruned.\n","authors":["Thennal D K","Tim Fischer","Chris Biemann"],"pdf_url":"https://arxiv.org/pdf/2410.14578v1.pdf","comment":"8 pages of content + 1 for limitations and ethical considerations, 14\n  pages in total including references and appendix, 5+1 figures"},{"id":"http://arxiv.org/abs/2410.14574v1","updated":"2024-10-18T16:20:22Z","published":"2024-10-18T16:20:22Z","title":"MomentumSMoE: Integrating Momentum into Sparse Mixture of Experts","summary":"  Sparse Mixture of Experts (SMoE) has become the key to unlocking unparalleled\nscalability in deep learning. SMoE has the potential to exponentially increase\nparameter count while maintaining the efficiency of the model by only\nactivating a small subset of these parameters for a given sample. However, it\nhas been observed that SMoE suffers from unstable training and has difficulty\nadapting to new distributions, leading to the model's lack of robustness to\ndata contamination. To overcome these limitations, we first establish a\nconnection between the dynamics of the expert representations in SMoEs and\ngradient descent on a multi-objective optimization problem. Leveraging our\nframework, we then integrate momentum into SMoE and propose a new family of\nSMoEs named MomentumSMoE. We theoretically prove and numerically demonstrate\nthat MomentumSMoE is more stable and robust than SMoE. In particular, we verify\nthe advantages of MomentumSMoE over SMoE on a variety of practical tasks\nincluding ImageNet-1K object recognition and WikiText-103 language modeling. We\ndemonstrate the applicability of MomentumSMoE to many types of SMoE models,\nincluding those in the Sparse MoE model for vision (V-MoE) and the Generalist\nLanguage Model (GLaM). We also show that other advanced momentum-based\noptimization methods, such as Adam, can be easily incorporated into the\nMomentumSMoE framework for designing new SMoE models with even better\nperformance, almost negligible additional computation cost, and simple\nimplementations.\n","authors":["Rachel S. Y. Teo","Tan M. Nguyen"],"pdf_url":"https://arxiv.org/pdf/2410.14574v1.pdf","comment":"10 pages in the main text. Published at NeurIPS 2024. The code is\n  available at https://github.com/rachtsy/MomentumSMoE"},{"id":"http://arxiv.org/abs/2410.14567v1","updated":"2024-10-18T16:11:29Z","published":"2024-10-18T16:11:29Z","title":"RAG-ConfusionQA: A Benchmark for Evaluating LLMs on Confusing Questions","summary":"  Conversational AI agents use Retrieval Augmented Generation (RAG) to provide\nverifiable document-grounded responses to user inquiries. However, many natural\nquestions do not have good answers: about 25\\% contain false\nassumptions~\\cite{Yu2023:CREPE}, and over 50\\% are\nambiguous~\\cite{Min2020:AmbigQA}. RAG agents need high-quality data to improve\ntheir responses to confusing questions. This paper presents a novel synthetic\ndata generation method to efficiently create a diverse set of context-grounded\nconfusing questions from a given document corpus. We conduct an empirical\ncomparative evaluation of several large language models as RAG agents to\nmeasure the accuracy of confusion detection and appropriate response\ngeneration. We contribute a benchmark dataset to the public domain.\n","authors":["Zhiyuan Peng","Jinming Nian","Alexandre Evfimievski","Yi Fang"],"pdf_url":"https://arxiv.org/pdf/2410.14567v1.pdf","comment":"under review"},{"id":"http://arxiv.org/abs/2410.07400v2","updated":"2024-10-18T15:54:56Z","published":"2024-10-09T19:57:07Z","title":"Advocating Character Error Rate for Multilingual ASR Evaluation","summary":"  Automatic speech recognition (ASR) systems have traditionally been evaluated\nusing English datasets, with the word error rate (WER) serving as the\npredominant metric. WER's simplicity and ease of interpretation have\ncontributed to its widespread adoption, particularly for English. However, as\nASR systems expand to multilingual contexts, WER fails in various ways,\nparticularly with morphologically complex languages or those without clear word\nboundaries. Our work documents the limitations of WER as an evaluation metric\nand advocates for the character error rate (CER) as the primary metric in\nmultilingual ASR evaluation. We show that CER avoids many of the challenges WER\nfaces and exhibits greater consistency across writing systems. We support our\nproposition by conducting human evaluations of ASR transcriptions in three\nlanguages: Malayalam, English, and Arabic, which exhibit distinct morphological\ncharacteristics. We show that CER correlates more closely with human judgments\nthan WER, even for English. To facilitate further research, we release our\nhuman evaluation dataset for future benchmarking of ASR metrics. Our findings\nsuggest that CER should be prioritized, or at least supplemented, in\nmultilingual ASR evaluations to account for the varying linguistic\ncharacteristics of different languages.\n","authors":["Thennal D K","Jesin James","Deepa P Gopinath","Muhammed Ashraf K"],"pdf_url":"https://arxiv.org/pdf/2410.07400v2.pdf","comment":"4 pages"},{"id":"http://arxiv.org/abs/2409.15652v3","updated":"2024-10-18T15:45:39Z","published":"2024-09-24T01:29:24Z","title":"English offensive text detection using CNN based Bi-GRU model","summary":"  Over the years, the number of users of social media has increased\ndrastically. People frequently share their thoughts through social platforms,\nand this leads to an increase in hate content. In this virtual community,\nindividuals share their views, express their feelings, and post photos, videos,\nblogs, and more. Social networking sites like Facebook and Twitter provide\nplatforms to share vast amounts of content with a single click. However, these\nplatforms do not impose restrictions on the uploaded content, which may include\nabusive language and explicit images unsuitable for social media. To resolve\nthis issue, a new idea must be implemented to divide the inappropriate content.\nNumerous studies have been done to automate the process. In this paper, we\npropose a new Bi-GRU-CNN model to classify whether the text is offensive or\nnot. The combination of the Bi-GRU and CNN models outperforms the existing\nmodel.\n","authors":["Tonmoy Roy","Md Robiul Islam","Asif Ahammad Miazee","Anika Antara","Al Amin","Sunjim Hossain"],"pdf_url":"https://arxiv.org/pdf/2409.15652v3.pdf","comment":"5 pages and 6 figures"},{"id":"http://arxiv.org/abs/2405.20850v2","updated":"2024-10-18T15:43:02Z","published":"2024-05-31T14:33:07Z","title":"Improving Reward Models with Synthetic Critiques","summary":"  Reward models (RMs) play a critical role in aligning language models through\nthe process of reinforcement learning from human feedback. RMs are trained to\npredict a score reflecting human preference, which requires significant time\nand cost for human annotation. Additionally, RMs tend to quickly overfit on\nsuperficial features in the training set, hindering their generalization\nperformance on unseen distributions. We propose a novel approach using\nsynthetic natural language critiques generated by large language models to\nprovide additional feedback, evaluating aspects such as instruction following,\ncorrectness, and style. This offers richer signals and more robust features for\nRMs to assess and score on. We demonstrate that high-quality critiques improve\nthe performance and data efficiency of RMs initialized from different\npretrained models, reducing the reliance on costly human annotations.\nFurthermore, incorporating critiques improves both the interpretability and\nrobustness of RM training.\n","authors":["Zihuiwen Ye","Fraser Greenlee-Scott","Max Bartolo","Phil Blunsom","Jon Ander Campos","Matthias Gallé"],"pdf_url":"https://arxiv.org/pdf/2405.20850v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2409.14917v2","updated":"2024-10-18T15:42:06Z","published":"2024-09-23T11:13:25Z","title":"With Ears to See and Eyes to Hear: Sound Symbolism Experiments with\n  Multimodal Large Language Models","summary":"  Recently, Large Language Models (LLMs) and Vision Language Models (VLMs) have\ndemonstrated aptitude as potential substitutes for human participants in\nexperiments testing psycholinguistic phenomena. However, an understudied\nquestion is to what extent models that only have access to vision and text\nmodalities are able to implicitly understand sound-based phenomena via abstract\nreasoning from orthography and imagery alone. To investigate this, we analyse\nthe ability of VLMs and LLMs to demonstrate sound symbolism (i.e., to recognise\na non-arbitrary link between sounds and concepts) as well as their ability to\n\"hear\" via the interplay of the language and vision modules of open and\nclosed-source multimodal models. We perform multiple experiments, including\nreplicating the classic Kiki-Bouba and Mil-Mal shape and magnitude symbolism\ntasks, and comparing human judgements of linguistic iconicity with that of\nLLMs. Our results show that VLMs demonstrate varying levels of agreement with\nhuman labels, and more task information may be required for VLMs versus their\nhuman counterparts for in silico experimentation. We additionally see through\nhigher maximum agreement levels that Magnitude Symbolism is an easier pattern\nfor VLMs to identify than Shape Symbolism, and that an understanding of\nlinguistic iconicity is highly dependent on model size.\n","authors":["Tyler Loakman","Yucheng Li","Chenghua Lin"],"pdf_url":"https://arxiv.org/pdf/2409.14917v2.pdf","comment":"Accepted to EMNLP 2024 (Camera Ready)"},{"id":"http://arxiv.org/abs/2410.14545v1","updated":"2024-10-18T15:40:48Z","published":"2024-10-18T15:40:48Z","title":"Tell me what I need to know: Exploring LLM-based (Personalized)\n  Abstractive Multi-Source Meeting Summarization","summary":"  Meeting summarization is crucial in digital communication, but existing\nsolutions struggle with salience identification to generate personalized,\nworkable summaries, and context understanding to fully comprehend the meetings'\ncontent. Previous attempts to address these issues by considering related\nsupplementary resources (e.g., presentation slides) alongside transcripts are\nhindered by models' limited context sizes and handling the additional\ncomplexities of the multi-source tasks, such as identifying relevant\ninformation in additional files and seamlessly aligning it with the meeting\ncontent. This work explores multi-source meeting summarization considering\nsupplementary materials through a three-stage large language model approach:\nidentifying transcript passages needing additional context, inferring relevant\ndetails from supplementary materials and inserting them into the transcript,\nand generating a summary from this enriched transcript. Our multi-source\napproach enhances model understanding, increasing summary relevance by ~9% and\nproducing more content-rich outputs. We introduce a personalization protocol\nthat extracts participant characteristics and tailors summaries accordingly,\nimproving informativeness by ~10%. This work further provides insights on\nperformance-cost trade-offs across four leading model families, including\nedge-device capable options. Our approach can be extended to similar complex\ngenerative tasks benefitting from additional resources and personalization,\nsuch as dialogue systems and action planning.\n","authors":["Frederic Kirstein","Terry Ruas","Robert Kratel","Bela Gipp"],"pdf_url":"https://arxiv.org/pdf/2410.14545v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2407.02067v2","updated":"2024-10-18T15:39:15Z","published":"2024-07-02T08:55:41Z","title":"Crossroads of Continents: Automated Artifact Extraction for Cultural\n  Adaptation with Large Multimodal Models","summary":"  We present a comprehensive three-phase study to examine (1) the cultural\nunderstanding of Large Multimodal Models (LMMs) by introducing DalleStreet, a\nlarge-scale dataset generated by DALL-E 3 and validated by humans, containing\n9,935 images of 67 countries and 10 concept classes; (2) the underlying\nimplicit and potentially stereotypical cultural associations with a cultural\nartifact extraction task; and (3) an approach to adapt cultural representation\nin an image based on extracted associations using a modular pipeline,\nCultureAdapt. We find disparities in cultural understanding at geographic\nsub-region levels with both open-source (LLaVA) and closed-source (GPT-4V)\nmodels on DalleStreet and other existing benchmarks, which we try to understand\nusing over 18,000 artifacts that we identify in association to different\ncountries. Our findings reveal a nuanced picture of the cultural competence of\nLMMs, highlighting the need to develop culture-aware systems. Dataset and code\nare available at https://github.com/iamshnoo/crossroads\n","authors":["Anjishnu Mukherjee","Ziwei Zhu","Antonios Anastasopoulos"],"pdf_url":"https://arxiv.org/pdf/2407.02067v2.pdf","comment":"under review"},{"id":"http://arxiv.org/abs/2404.11124v2","updated":"2024-10-18T15:34:41Z","published":"2024-04-17T07:15:07Z","title":"What's under the hood: Investigating Automatic Metrics on Meeting\n  Summarization","summary":"  Meeting summarization has become a critical task considering the increase in\nonline interactions. While new techniques are introduced regularly, their\nevaluation uses metrics not designed to capture meeting-specific errors,\nundermining effective evaluation. This paper investigates what the frequently\nused automatic metrics capture and which errors they mask by correlating\nautomatic metric scores with human evaluations across a broad error taxonomy.\nWe commence with a comprehensive literature review on English meeting\nsummarization to define key challenges like speaker dynamics and contextual\nturn-taking and error types such as missing information and linguistic\ninaccuracy, concepts previously loosely defined in the field. We examine the\nrelationship between characteristic challenges and errors by using annotated\ntranscripts and summaries from Transformer-based sequence-to-sequence and\nautoregressive models from the general summary QMSum dataset. Through\nexperimental validation, we find that different model architectures respond\nvariably to challenges in meeting transcripts, resulting in different\npronounced links between challenges and errors. Current default-used metrics\nstruggle to capture observable errors, showing weak to mid-correlations, while\na third of the correlations show trends of error masking. Only a subset reacts\naccurately to specific errors, while most correlations show either\nunresponsiveness or failure to reflect the error's impact on summary quality.\n","authors":["Frederic Kirstein","Jan Philip Wahle","Terry Ruas","Bela Gipp"],"pdf_url":"https://arxiv.org/pdf/2404.11124v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.12874v2","updated":"2024-10-18T15:26:55Z","published":"2024-10-14T18:11:53Z","title":"On Debiasing Text Embeddings Through Context Injection","summary":"  Current advances in Natural Language Processing (NLP) have made it\nincreasingly feasible to build applications leveraging textual data. Generally,\nthe core of these applications rely on having a good semantic representation of\ntext into vectors, via embedding models. However, it has been shown that these\nembeddings capture and perpetuate biases already present in text. While a few\ntechniques have been proposed to debias embeddings, they do not take advantage\nof the recent advances in context understanding of modern embedding models. In\nthis paper, we fill this gap by conducting a review of 19 embedding models by\nquantifying their biases and how well they respond to context injection as a\nmean of debiasing. We show that higher performing models are more prone to\ncapturing biases, but are also better at incorporating context. Surprisingly,\nwe find that while models can easily embed affirmative semantics, they fail at\nembedding neutral semantics. Finally, in a retrieval task, we show that biases\nin embeddings can lead to non-desirable outcomes. We use our new-found insights\nto design a simple algorithm for top $k$ retrieval, where $k$ is dynamically\nselected. We show that our algorithm is able to retrieve all relevant gendered\nand neutral chunks.\n","authors":["Thomas Uriot"],"pdf_url":"https://arxiv.org/pdf/2410.12874v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.13901v3","updated":"2024-10-18T15:25:44Z","published":"2024-03-20T18:13:17Z","title":"Train & Constrain: Phonologically Informed Tongue-Twister Generation\n  from Topics and Paraphrases","summary":"  Previous work in phonologically and phonetically grounded language generation\nhas mainly focused on domains such as puns and poetry. In this article, we\npresent new work on the generation of English tongue twisters - a form of\nlanguage that is required to be conditioned on a phoneme level to maximize\nsound overlap, while maintaining semantic consistency with an input topic or\nphrase and still being grammatically correct. We present TwisterLister, a\npipeline for generating phonologically informed tongue twisters from large\nlanguage models (LLMs) that we use to generate TwistList 2.0, the largest\nannotated dataset of tongue twisters to date, consisting of 17K+ examples from\na combination of human and LLM authors. Our generation pipeline involves the\nuse of a phonologically constrained vocabulary alongside LLM prompting to\ngenerate novel, non-derivative tongue twister examples. We additionally present\nthe results of automatic and human evaluation of smaller models trained on our\ngenerated dataset to demonstrate the extent to which phonologically motivated\nlanguage types can be generated without explicit injection of phonological\nknowledge. Additionally, we introduce a phoneme-aware constrained decoding\nmodule (PACD) that can be integrated into an autoregressive language model and\ndemonstrate that this method generates good quality tongue twisters both with\nand without fine-tuning the underlying language model. We also design and\nimplement a range of automatic metrics for the task of tongue twister\ngeneration that is phonologically motivated and captures the unique essence of\ntongue twisters, primarily based on phonemic edit distance (PED)\n","authors":["Tyler Loakman","Chen Tang","Chenghua Lin"],"pdf_url":"https://arxiv.org/pdf/2403.13901v3.pdf","comment":"Accepted Final Version to Computational Linguistics"},{"id":"http://arxiv.org/abs/2406.11580v2","updated":"2024-10-18T15:20:43Z","published":"2024-06-17T14:20:47Z","title":"Error Span Annotation: A Balanced Approach for Human Evaluation of\n  Machine Translation","summary":"  High-quality Machine Translation (MT) evaluation relies heavily on human\njudgments. Comprehensive error classification methods, such as Multidimensional\nQuality Metrics (MQM), are expensive as they are time-consuming and can only be\ndone by experts, whose availability may be limited especially for low-resource\nlanguages. On the other hand, just assigning overall scores, like Direct\nAssessment (DA), is simpler and faster and can be done by translators of any\nlevel, but is less reliable. In this paper, we introduce Error Span Annotation\n(ESA), a human evaluation protocol which combines the continuous rating of DA\nwith the high-level error severity span marking of MQM. We validate ESA by\ncomparing it to MQM and DA for 12 MT systems and one human reference\ntranslation (English to German) from WMT23. The results show that ESA offers\nfaster and cheaper annotations than MQM at the same quality level, without the\nrequirement of expensive MQM experts.\n","authors":["Tom Kocmi","Vilém Zouhar","Eleftherios Avramidis","Roman Grundkiewicz","Marzena Karpinska","Maja Popović","Mrinmaya Sachan","Mariya Shmatova"],"pdf_url":"https://arxiv.org/pdf/2406.11580v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.14516v1","updated":"2024-10-18T14:55:14Z","published":"2024-10-18T14:55:14Z","title":"Do LLMs \"know\" internally when they follow instructions?","summary":"  Instruction-following is crucial for building AI agents with large language\nmodels (LLMs), as these models must adhere strictly to user-provided\nconstraints and guidelines. However, LLMs often fail to follow even simple and\nclear instructions. To improve instruction-following behavior and prevent\nundesirable outputs, a deeper understanding of how LLMs' internal states relate\nto these outcomes is required. Our analysis of LLM internal states reveal a\ndimension in the input embedding space linked to successful\ninstruction-following. We demonstrate that modifying representations along this\ndimension improves instruction-following success rates compared to random\nchanges, without compromising response quality. Further investigation reveals\nthat this dimension is more closely related to the phrasing of prompts rather\nthan the inherent difficulty of the task or instructions. This discovery also\nsuggests explanations for why LLMs sometimes fail to follow clear instructions\nand why prompt engineering is often effective, even when the content remains\nlargely unchanged. This work provides insight into the internal workings of\nLLMs' instruction-following, paving the way for reliable LLM agents.\n","authors":["Juyeon Heo","Christina Heinze-Deml","Oussama Elachqar","Shirley Ren","Udhay Nallasamy","Andy Miller","Kwan Ho Ryan Chan","Jaya Narain"],"pdf_url":"https://arxiv.org/pdf/2410.14516v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.14506v1","updated":"2024-10-18T14:38:37Z","published":"2024-10-18T14:38:37Z","title":"SignAttention: On the Interpretability of Transformer Models for Sign\n  Language Translation","summary":"  This paper presents the first comprehensive interpretability analysis of a\nTransformer-based Sign Language Translation (SLT) model, focusing on the\ntranslation from video-based Greek Sign Language to glosses and text.\nLeveraging the Greek Sign Language Dataset, we examine the attention mechanisms\nwithin the model to understand how it processes and aligns visual input with\nsequential glosses. Our analysis reveals that the model pays attention to\nclusters of frames rather than individual ones, with a diagonal alignment\npattern emerging between poses and glosses, which becomes less distinct as the\nnumber of glosses increases. We also explore the relative contributions of\ncross-attention and self-attention at each decoding step, finding that the\nmodel initially relies on video frames but shifts its focus to previously\npredicted tokens as the translation progresses. This work contributes to a\ndeeper understanding of SLT models, paving the way for the development of more\ntransparent and reliable translation systems essential for real-world\napplications.\n","authors":["Pedro Alejandro Dal Bianco","Oscar Agustín Stanchi","Facundo Manuel Quiroga","Franco Ronchetti","Enzo Ferrante"],"pdf_url":"https://arxiv.org/pdf/2410.14506v1.pdf","comment":"Accepted at IAI Workshop @ NeurIPS 2024"},{"id":"http://arxiv.org/abs/2410.14480v1","updated":"2024-10-18T14:03:52Z","published":"2024-10-18T14:03:52Z","title":"Combining Entropy and Matrix Nuclear Norm for Enhanced Evaluation of\n  Language Models","summary":"  As large language models (LLMs) continue to advance, the need for precise and\nefficient evaluation metrics becomes more pressing. Traditional approaches,\nwhile informative, often face limitations in computational demands and\ninterpretability. In this paper, we introduce a novel hybrid evaluation method\nthat integrates two established techniques: entropy derived from covariance\nmatrices and the Matrix Nuclear Norm (MNN). Our method begins by normalizing\nhidden states from LLMs, then computes the covariance matrix and MNN from these\nrepresentations. We further calculate the entropy of the covariance matrix to\ncapture uncertainty and redundancy in the model's outputs. By combining these\nmetrics into a composite score, we offer a comprehensive evaluation framework\nthat balances accuracy with computational efficiency. Additionally, our\napproach allows for flexibility in adjusting the weightings between entropy and\nMNN, tailoring the evaluation for different objectives. Through a series of\nexperiments on various LLMs, we demonstrate the robustness and efficacy of our\nmethod, offering deeper insights into model performance. This work contributes\nto the ongoing development of LLM evaluation and opens avenues for future\ninnovations in model assessment techniques.\n","authors":["James Vo"],"pdf_url":"https://arxiv.org/pdf/2410.14480v1.pdf","comment":"The method is currently under experimentation"},{"id":"http://arxiv.org/abs/2410.09804v2","updated":"2024-10-18T14:03:05Z","published":"2024-10-13T11:15:38Z","title":"BlackDAN: A Black-Box Multi-Objective Approach for Effective and\n  Contextual Jailbreaking of Large Language Models","summary":"  While large language models (LLMs) exhibit remarkable capabilities across\nvarious tasks, they encounter potential security risks such as jailbreak\nattacks, which exploit vulnerabilities to bypass security measures and generate\nharmful outputs. Existing jailbreak strategies mainly focus on maximizing\nattack success rate (ASR), frequently neglecting other critical factors,\nincluding the relevance of the jailbreak response to the query and the level of\nstealthiness. This narrow focus on single objectives can result in ineffective\nattacks that either lack contextual relevance or are easily recognizable. In\nthis work, we introduce BlackDAN, an innovative black-box attack framework with\nmulti-objective optimization, aiming to generate high-quality prompts that\neffectively facilitate jailbreaking while maintaining contextual relevance and\nminimizing detectability. BlackDAN leverages Multiobjective Evolutionary\nAlgorithms (MOEAs), specifically the NSGA-II algorithm, to optimize jailbreaks\nacross multiple objectives including ASR, stealthiness, and semantic relevance.\nBy integrating mechanisms like mutation, crossover, and Pareto-dominance,\nBlackDAN provides a transparent and interpretable process for generating\njailbreaks. Furthermore, the framework allows customization based on user\npreferences, enabling the selection of prompts that balance harmfulness,\nrelevance, and other factors. Experimental results demonstrate that BlackDAN\noutperforms traditional single-objective methods, yielding higher success rates\nand improved robustness across various LLMs and multimodal LLMs, while ensuring\njailbreak responses are both relevant and less detectable.\n","authors":["Xinyuan Wang","Victor Shea-Jay Huang","Renmiao Chen","Hao Wang","Chengwei Pan","Lei Sha","Minlie Huang"],"pdf_url":"https://arxiv.org/pdf/2410.09804v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2407.14346v2","updated":"2024-10-18T13:59:54Z","published":"2024-07-19T14:28:53Z","title":"Improving Retrieval in Sponsored Search by Leveraging Query Context\n  Signals","summary":"  Accurately retrieving relevant bid keywords for user queries is critical in\nSponsored Search but remains challenging, particularly for short, ambiguous\nqueries. Existing dense and generative retrieval models often fail to capture\nnuanced user intent in these cases. To address this, we propose an approach to\nenhance query understanding by augmenting queries with rich contextual signals\nderived from web search results and large language models, stored in an online\ncache. Specifically, we use web search titles and snippets to ground queries in\nreal-world information and utilize GPT-4 to generate query rewrites and\nexplanations that clarify user intent. These signals are efficiently integrated\nthrough a Fusion-in-Decoder based Unity architecture, enabling both dense and\ngenerative retrieval with serving costs on par with traditional context-free\nmodels. To address scenarios where context is unavailable in the cache, we\nintroduce context glancing, a curriculum learning strategy that improves model\nrobustness and performance even without contextual signals during inference.\nExtensive offline experiments demonstrate that our context-aware approach\nsubstantially outperforms context-free models. Furthermore, online A/B testing\non a prominent search engine across 160+ countries shows significant\nimprovements in user engagement and revenue.\n","authors":["Akash Kumar Mohankumar","Gururaj K","Gagan Madan","Amit Singh"],"pdf_url":"https://arxiv.org/pdf/2407.14346v2.pdf","comment":"Accepted to EMNLP 2024 Industry Track. 10 pages, 10 tables, 1 figure"},{"id":"http://arxiv.org/abs/2406.13663v4","updated":"2024-10-18T13:16:57Z","published":"2024-06-19T16:10:26Z","title":"Model Internals-based Answer Attribution for Trustworthy\n  Retrieval-Augmented Generation","summary":"  Ensuring the verifiability of model answers is a fundamental challenge for\nretrieval-augmented generation (RAG) in the question answering (QA) domain.\nRecently, self-citation prompting was proposed to make large language models\n(LLMs) generate citations to supporting documents along with their answers.\nHowever, self-citing LLMs often struggle to match the required format, refer to\nnon-existent sources, and fail to faithfully reflect LLMs' context usage\nthroughout the generation. In this work, we present MIRAGE --Model\nInternals-based RAG Explanations -- a plug-and-play approach using model\ninternals for faithful answer attribution in RAG applications. MIRAGE detects\ncontext-sensitive answer tokens and pairs them with retrieved documents\ncontributing to their prediction via saliency methods. We evaluate our proposed\napproach on a multilingual extractive QA dataset, finding high agreement with\nhuman answer attribution. On open-ended QA, MIRAGE achieves citation quality\nand efficiency comparable to self-citation while also allowing for a\nfiner-grained control of attribution parameters. Our qualitative evaluation\nhighlights the faithfulness of MIRAGE's attributions and underscores the\npromising application of model internals for RAG answer attribution.\n","authors":["Jirui Qi","Gabriele Sarti","Raquel Fernández","Arianna Bisazza"],"pdf_url":"https://arxiv.org/pdf/2406.13663v4.pdf","comment":"Accepted by EMNLP 2024 Main Conference. Code and data released at\n  https://github.com/Betswish/MIRAGE"},{"id":"http://arxiv.org/abs/2405.11877v5","updated":"2024-10-18T13:03:05Z","published":"2024-05-20T08:41:15Z","title":"A Novel Cartography-Based Curriculum Learning Method Applied on RoNLI:\n  The First Romanian Natural Language Inference Corpus","summary":"  Natural language inference (NLI), the task of recognizing the entailment\nrelationship in sentence pairs, is an actively studied topic serving as a proxy\nfor natural language understanding. Despite the relevance of the task in\nbuilding conversational agents and improving text classification, machine\ntranslation and other NLP tasks, to the best of our knowledge, there is no\npublicly available NLI corpus for the Romanian language. To this end, we\nintroduce the first Romanian NLI corpus (RoNLI) comprising 58K training\nsentence pairs, which are obtained via distant supervision, and 6K validation\nand test sentence pairs, which are manually annotated with the correct labels.\nWe conduct experiments with multiple machine learning methods based on distant\nlearning, ranging from shallow models based on word embeddings to\ntransformer-based neural networks, to establish a set of competitive baselines.\nFurthermore, we improve on the best model by employing a new curriculum\nlearning strategy based on data cartography. Our dataset and code to reproduce\nthe baselines are available at https://github.com/Eduard6421/RONLI.\n","authors":["Eduard Poesina","Cornelia Caragea","Radu Tudor Ionescu"],"pdf_url":"https://arxiv.org/pdf/2405.11877v5.pdf","comment":"Accepted at ACL 2024 (Main)"},{"id":"http://arxiv.org/abs/2410.14442v1","updated":"2024-10-18T13:01:14Z","published":"2024-10-18T13:01:14Z","title":"A Systematic Study of Cross-Layer KV Sharing for Efficient LLM Inference","summary":"  Recently, sharing key-value (KV) cache across layers has been found effective\nin efficient inference of large language models (LLMs). To systematically\ninvestigate different techniques of cross-layer KV sharing, we propose a\nunified framework that covers several recent methods and their novel variants.\nWe conduct comprehensive experiments on all the configurations of the\nframework, evaluating their generation throughput and performance in language\nmodeling and downstream tasks. We find that when reducing the size of the KV\ncache by 2x, most configurations can achieve competitive performance to and\nhigher throughput than standard transformers, but when further reducing the\nsize of the KV cache, pairing queries of all layers with KVs of upper layers\ncan better maintain performance, although it also introduces additional\ntraining cost and prefilling latency. We hope that this work will help users\nchoose the appropriate approach according to their requirements and facilitate\nresearch on the acceleration of LLM inference.\n","authors":["You Wu","Haoyi Wu","Kewei Tu"],"pdf_url":"https://arxiv.org/pdf/2410.14442v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.10996v2","updated":"2024-10-18T12:54:21Z","published":"2024-06-16T16:17:46Z","title":"Towards Lifelong Dialogue Agents via Relation-aware Memory Construction\n  and Timeline-augmented Response Generation","summary":"  To achieve lifelong human-agent interaction, dialogue agents need to\nconstantly memorize perceived information and properly retrieve it for response\ngeneration (RG). While prior work focuses on getting rid of outdated memories\nto improve retrieval quality, we argue that such memories provide rich,\nimportant contextual cues for RG (e.g., changes in user behaviors) in long-term\nconversations. We present Theanine, a framework for LLM-based lifelong dialogue\nagents. Theanine discards memory removal and manages large-scale memories by\nlinking them based on their temporal and cause-effect relation. Enabled by this\nlinking structure, Theanine augments RG with memory timelines - series of\nmemories representing the evolution or causality of relevant past events. Along\nwith Theanine, we introduce TeaFarm, a counterfactual-driven evaluation scheme,\naddressing the limitation of G-Eval and human efforts in measuring\nmemory-augmented dialogue agents. A supplementary video for Theanine and data\nfor TeaFarm are at https://huggingface.co/spaces/ResearcherScholar/Theanine.\n","authors":["Kai Tzu-iunn Ong","Namyoung Kim","Minju Gwak","Hyungjoo Chae","Taeyoon Kwon","Yohan Jo","Seung-won Hwang","Dongha Lee","Jinyoung Yeo"],"pdf_url":"https://arxiv.org/pdf/2406.10996v2.pdf","comment":"Work in Progress"},{"id":"http://arxiv.org/abs/2305.17819v3","updated":"2024-10-18T12:49:35Z","published":"2023-05-28T22:46:21Z","title":"Large Language Models, scientific knowledge and factuality: A framework\n  to streamline human expert evaluation","summary":"  The paper introduces a framework for the evaluation of the encoding of\nfactual scientific knowledge, designed to streamline the manual evaluation\nprocess typically conducted by domain experts. Inferring over and extracting\ninformation from Large Language Models (LLMs) trained on a large corpus of\nscientific literature can potentially define a step change in biomedical\ndiscovery, reducing the barriers for accessing and integrating existing medical\nevidence. This work explores the potential of LLMs for dialoguing with\nbiomedical background knowledge, using the context of antibiotic discovery. The\nframework involves of three evaluation steps, each assessing different aspects\nsequentially: fluency, prompt alignment, semantic coherence, factual knowledge,\nand specificity of the generated responses. By splitting these tasks between\nnon-experts and experts, the framework reduces the effort required from the\nlatter. The work provides a systematic assessment on the ability of eleven\nstate-of-the-art models LLMs, including ChatGPT, GPT-4 and Llama 2, in two\nprompting-based tasks: chemical compound definition generation and chemical\ncompound-fungus relation determination. Although recent models have improved in\nfluency, factual accuracy is still low and models are biased towards\nover-represented entities. The ability of LLMs to serve as biomedical knowledge\nbases is questioned, and the need for additional systematic evaluation\nframeworks is highlighted. While LLMs are currently not fit for purpose to be\nused as biomedical factual knowledge bases in a zero-shot setting, there is a\npromising emerging property in the direction of factuality as the models become\ndomain specialised, scale-up in size and level of human feedback.\n","authors":["Magdalena Wysocka","Oskar Wysocki","Maxime Delmas","Vincent Mutel","Andre Freitas"],"pdf_url":"https://arxiv.org/pdf/2305.17819v3.pdf","comment":"Accepted at the Journal of Biomedical Informatics, Volume 158,\n  October 2024, 104724"},{"id":"http://arxiv.org/abs/2410.14425v1","updated":"2024-10-18T12:39:32Z","published":"2024-10-18T12:39:32Z","title":"Unlearning Backdoor Attacks for LLMs with Weak-to-Strong Knowledge\n  Distillation","summary":"  Parameter-efficient fine-tuning (PEFT) can bridge the gap between large\nlanguage models (LLMs) and downstream tasks. However, PEFT has been proven\nvulnerable to malicious attacks. Research indicates that poisoned LLMs, even\nafter PEFT, retain the capability to activate internalized backdoors when input\nsamples contain predefined triggers. In this paper, we introduce a novel\nweak-to-strong unlearning algorithm to defend against backdoor attacks based on\nfeature alignment knowledge distillation, named W2SDefense. Specifically, we\nfirst train a small-scale language model through full-parameter fine-tuning to\nserve as the clean teacher model. Then, this teacher model guides the\nlarge-scale poisoned student model in unlearning the backdoor, leveraging PEFT.\nTheoretical analysis suggests that W2SDefense has the potential to enhance the\nstudent model's ability to unlearn backdoor features, preventing the activation\nof the backdoor. We conduct experiments on text classification tasks involving\nthree state-of-the-art language models and three different backdoor attack\nalgorithms. Our empirical results demonstrate the outstanding performance of\nW2SDefense in defending against backdoor attacks without compromising model\nperformance.\n","authors":["Shuai Zhao","Xiaobao Wu","Cong-Duy Nguyen","Meihuizi Jia","Yichao Feng","Luu Anh Tuan"],"pdf_url":"https://arxiv.org/pdf/2410.14425v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.10918v5","updated":"2024-10-18T12:27:07Z","published":"2024-06-16T12:46:40Z","title":"Multi-LLM QA with Embodied Exploration","summary":"  Large language models (LLMs) have grown in popularity due to their natural\nlanguage interface and pre trained knowledge, leading to rapidly increasing\nsuccess in question-answering (QA) tasks. More recently, multi-agent systems\nwith LLM-based agents (Multi-LLM) have been utilized increasingly more for QA.\nIn these scenarios, the models may each answer the question and reach a\nconsensus or each model is specialized to answer different domain questions.\nHowever, most prior work dealing with Multi-LLM QA has focused on scenarios\nwhere the models are asked in a zero-shot manner or are given information\nsources to extract the answer. For question answering of an unknown\nenvironment, embodied exploration of the environment is first needed to answer\nthe question. This skill is necessary for personalizing embodied AI to\nenvironments such as households. There is a lack of insight into whether a\nMulti-LLM system can handle question-answering based on observations from\nembodied exploration. In this work, we address this gap by investigating the\nuse of Multi-Embodied LLM Explorers (MELE) for QA in an unknown environment.\nMultiple LLM-based agents independently explore and then answer queries about a\nhousehold environment. We analyze different aggregation methods to generate a\nsingle, final answer for each query: debating, majority voting, and training a\ncentral answer module (CAM). Using CAM, we observe a $46\\%$ higher accuracy\ncompared against the other non-learning-based aggregation methods. We provide\ncode and the query dataset for further research.\n","authors":["Bhrij Patel","Vishnu Sashank Dorbala","Amrit Singh Bedi","Dinesh Manocha"],"pdf_url":"https://arxiv.org/pdf/2406.10918v5.pdf","comment":"16 pages, 9 Figures, 5 Tables"},{"id":"http://arxiv.org/abs/2406.12950v2","updated":"2024-10-18T12:19:41Z","published":"2024-06-18T12:54:47Z","title":"MolecularGPT: Open Large Language Model (LLM) for Few-Shot Molecular\n  Property Prediction","summary":"  Molecular property prediction (MPP) is a fundamental and crucial task in drug\ndiscovery. However, prior methods are limited by the requirement for a large\nnumber of labeled molecules and their restricted ability to generalize for\nunseen and new tasks, both of which are essential for real-world applications.\nTo address these challenges, we present MolecularGPT for few-shot MPP. From a\nperspective on instruction tuning, we fine-tune large language models (LLMs)\nbased on curated molecular instructions spanning over 1000 property prediction\ntasks. This enables building a versatile and specialized LLM that can be\nadapted to novel MPP tasks without any fine-tuning through zero- and few-shot\nin-context learning (ICL). MolecularGPT exhibits competitive in-context\nreasoning capabilities across 10 downstream evaluation datasets, setting new\nbenchmarks for few-shot molecular prediction tasks. More importantly, with just\ntwo-shot examples, MolecularGPT can outperform standard supervised graph neural\nnetwork methods on 4 out of 7 datasets. It also excels state-of-the-art LLM\nbaselines by up to 15.7% increase on classification accuracy and decrease of\n17.9 on regression metrics (e.g., RMSE) under zero-shot. This study\ndemonstrates the potential of LLMs as effective few-shot molecular property\npredictors. The code is available at https://github.com/NYUSHCS/MolecularGPT.\n","authors":["Yuyan Liu","Sirui Ding","Sheng Zhou","Wenqi Fan","Qiaoyu Tan"],"pdf_url":"https://arxiv.org/pdf/2406.12950v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.14405v1","updated":"2024-10-18T12:08:07Z","published":"2024-10-18T12:08:07Z","title":"Fact Recall, Heuristics or Pure Guesswork? Precise Interpretations of\n  Language Models for Fact Completion","summary":"  Previous interpretations of language models (LMs) miss important distinctions\nin how these models process factual information. For example, given the query\n\"Astrid Lindgren was born in\" with the corresponding completion \"Sweden\", no\ndifference is made between whether the prediction was based on having the exact\nknowledge of the birthplace of the Swedish author or assuming that a person\nwith a Swedish-sounding name was born in Sweden. In this paper, we investigate\nfour different prediction scenarios for which the LM can be expected to show\ndistinct behaviors. These scenarios correspond to different levels of model\nreliability and types of information being processed - some being less\ndesirable for factual predictions. To facilitate precise interpretations of LMs\nfor fact completion, we propose a model-specific recipe called PrISM for\nconstructing datasets with examples of each scenario based on a set of\ndiagnostic criteria. We apply a popular interpretability method, causal tracing\n(CT), to the four prediction scenarios and find that while CT produces\ndifferent results for each scenario, aggregations over a set of mixed examples\nmay only represent the results from the scenario with the strongest measured\nsignal. In summary, we contribute tools for a more granular study of fact\ncompletion in language models and analyses that provide a more nuanced\nunderstanding of how LMs process fact-related queries.\n","authors":["Denitsa Saynova","Lovisa Hagström","Moa Johansson","Richard Johansson","Marco Kuhlmann"],"pdf_url":"https://arxiv.org/pdf/2410.14405v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.14399v1","updated":"2024-10-18T12:02:41Z","published":"2024-10-18T12:02:41Z","title":"SylloBio-NLI: Evaluating Large Language Models on Biomedical Syllogistic\n  Reasoning","summary":"  Syllogistic reasoning is crucial for Natural Language Inference (NLI). This\ncapability is particularly significant in specialized domains such as\nbiomedicine, where it can support automatic evidence interpretation and\nscientific discovery. This paper presents SylloBio-NLI, a novel framework that\nleverages external ontologies to systematically instantiate diverse syllogistic\narguments for biomedical NLI. We employ SylloBio-NLI to evaluate Large Language\nModels (LLMs) on identifying valid conclusions and extracting supporting\nevidence across 28 syllogistic schemes instantiated with human genome pathways.\nExtensive experiments reveal that biomedical syllogistic reasoning is\nparticularly challenging for zero-shot LLMs, which achieve an average accuracy\nbetween 70% on generalized modus ponens and 23% on disjunctive syllogism. At\nthe same time, we found that few-shot prompting can boost the performance of\ndifferent LLMs, including Gemma (+14%) and LLama-3 (+43%). However, a deeper\nanalysis shows that both techniques exhibit high sensitivity to superficial\nlexical variations, highlighting a dependency between reliability, models'\narchitecture, and pre-training regime. Overall, our results indicate that,\nwhile in-context examples have the potential to elicit syllogistic reasoning in\nLLMs, existing models are still far from achieving the robustness and\nconsistency required for safe biomedical NLI applications.\n","authors":["Magdalena Wysocka","Danilo S. Carvalho","Oskar Wysocki","Marco Valentino","Andre Freitas"],"pdf_url":"https://arxiv.org/pdf/2410.14399v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.14395v1","updated":"2024-10-18T11:58:03Z","published":"2024-10-18T11:58:03Z","title":"Generative AI, Pragmatics, and Authenticity in Second Language Learning","summary":"  There are obvious benefits to integrating generative AI (artificial\nintelligence) into language learning and teaching. Those include using AI as a\nlanguage tutor, creating learning materials, or assessing learner output.\nHowever, due to how AI systems under-stand human language, based on a\nmathematical model using statistical probability, they lack the lived\nexperience to be able to use language with the same social aware-ness as\nhumans. Additionally, there are built-in linguistic and cultural biases based\non their training data which is mostly in English and predominantly from\nWestern sources. Those facts limit AI suitability for some language learning\ninteractions. Stud-ies have clearly shown that systems such as ChatGPT often do\nnot produce language that is pragmatically appropriate. The lack of linguistic\nand cultural authenticity has important implications for how AI is integrated\ninto second language acquisition as well as in instruction targeting\ndevelopment of intercultural communication compe-tence.\n","authors":["Robert Godwin-Jones`"],"pdf_url":"https://arxiv.org/pdf/2410.14395v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.14391v1","updated":"2024-10-18T11:52:10Z","published":"2024-10-18T11:52:10Z","title":"Analyzing Context Utilization of LLMs in Document-Level Translation","summary":"  Large language models (LLM) are increasingly strong contenders in machine\ntranslation. We study document-level translation, where some words cannot be\ntranslated without context from outside the sentence. We investigate the\nability of prominent LLMs to utilize context by analyzing models' robustness to\nperturbed and randomized document context. We find that LLMs' improved\ndocument-translation performance is not always reflected in pronoun translation\nperformance. We highlight the need for context-aware finetuning of LLMs with a\nfocus on relevant parts of the context to improve their reliability for\ndocument-level translation.\n","authors":["Wafaa Mohammed","Vlad Niculae"],"pdf_url":"https://arxiv.org/pdf/2410.14391v1.pdf","comment":"4 pages, 2 figures, 2 tables"},{"id":"http://arxiv.org/abs/2410.14387v1","updated":"2024-10-18T11:39:34Z","published":"2024-10-18T11:39:34Z","title":"How Do Multilingual Models Remember? Investigating Multilingual Factual\n  Recall Mechanisms","summary":"  Large Language Models (LLMs) store and retrieve vast amounts of factual\nknowledge acquired during pre-training. Prior research has localized and\nidentified mechanisms behind knowledge recall; however, it has primarily\nfocused on English monolingual models. The question of how these processes\ngeneralize to other languages and multilingual LLMs remains unexplored. In this\npaper, we address this gap by conducting a comprehensive analysis of two highly\nmultilingual LLMs. We assess the extent to which previously identified\ncomponents and mechanisms of factual recall in English apply to a multilingual\ncontext. Then, we examine when language plays a role in the recall process,\nuncovering evidence of language-independent and language-dependent mechanisms.\n","authors":["Constanza Fierro","Negar Foroutan","Desmond Elliott","Anders Søgaard"],"pdf_url":"https://arxiv.org/pdf/2410.14387v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.14375v1","updated":"2024-10-18T11:06:23Z","published":"2024-10-18T11:06:23Z","title":"Fine-Tuning Pre-trained Language Models for Robust Causal Representation\n  Learning","summary":"  The fine-tuning of pre-trained language models (PLMs) has been shown to be\neffective across various domains. By using domain-specific supervised data, the\ngeneral-purpose representation derived from PLMs can be transformed into a\ndomain-specific representation. However, these methods often fail to generalize\nto out-of-domain (OOD) data due to their reliance on non-causal\nrepresentations, often described as spurious features. Existing methods either\nmake use of adjustments with strong assumptions about lack of hidden common\ncauses, or mitigate the effect of spurious features using multi-domain data. In\nthis work, we investigate how fine-tuned pre-trained language models aid\ngeneralizability from single-domain scenarios under mild assumptions, targeting\nmore general and practical real-world scenarios. We show that a robust\nrepresentation can be derived through a so-called causal front-door adjustment,\nbased on a decomposition assumption, using fine-tuned representations as a\nsource of data augmentation. Comprehensive experiments in both synthetic and\nreal-world settings demonstrate the superior generalizability of the proposed\nmethod compared to existing approaches. Our work thus sheds light on the domain\ngeneralization problem by introducing links between fine-tuning and causal\nmechanisms into representation learning.\n","authors":["Jialin Yu","Yuxiang Zhou","Yulan He","Nevin L. Zhang","Ricardo Silva"],"pdf_url":"https://arxiv.org/pdf/2410.14375v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.10203v3","updated":"2024-10-18T10:43:40Z","published":"2024-06-14T17:38:21Z","title":"A Fundamental Trade-off in Aligned Language Models and its Relation to\n  Sampling Adaptors","summary":"  The relationship between the quality of a string, as judged by a human\nreader, and its probability, $p(\\boldsymbol{y})$ under a language model\nundergirds the development of better language models. For example, many popular\nalgorithms for sampling from a language model have been conceived with the goal\nof manipulating $p(\\boldsymbol{y})$ to place higher probability on strings that\nhumans deem of high quality. In this article, we examine the\nprobability--quality relationship in language models explicitly aligned to\nhuman preferences, e.g., through reinforcement learning through human feedback.\nWe show that, when sampling corpora from an aligned language model, there\nexists a trade-off between the strings' average reward and average\nlog-likelihood under the prior language model, i.e., the same model before\nalignment with human preferences. We provide a formal treatment of this\nphenomenon and demonstrate how a choice of sampling adaptor allows for a\nselection of how much likelihood we exchange for the reward.\n","authors":["Naaman Tan","Josef Valvoda","Tianyu Liu","Anej Svete","Yanxia Qin","Kan Min-Yen","Ryan Cotterell"],"pdf_url":"https://arxiv.org/pdf/2406.10203v3.pdf","comment":"EMNLP 2024"},{"id":"http://arxiv.org/abs/2410.14361v1","updated":"2024-10-18T10:40:47Z","published":"2024-10-18T10:40:47Z","title":"Efficiently Computing Susceptibility to Context in Language Models","summary":"  One strength of modern language models is their ability to incorporate\ninformation from a user-input context when answering queries. However, they are\nnot equally sensitive to the subtle changes to that context. To quantify this,\nDu et al. (2024) gives an information-theoretic metric to measure such\nsensitivity. Their metric, susceptibility, is defined as the degree to which\ncontexts can influence a model's response to a query at a distributional level.\nHowever, exactly computing susceptibility is difficult and, thus, Du et al.\n(2024) falls back on a Monte Carlo approximation. Due to the large number of\nsamples required, the Monte Carlo approximation is inefficient in practice. As\na faster alternative, we propose Fisher susceptibility, an efficient method to\nestimate the susceptibility based on Fisher information. Empirically, we\nvalidate that Fisher susceptibility is comparable to Monte Carlo estimated\nsusceptibility across a diverse set of query domains despite its being\n$70\\times$ faster. Exploiting the improved efficiency, we apply Fisher\nsusceptibility to analyze factors affecting the susceptibility of language\nmodels. We observe that larger models are as susceptible as smaller ones.\n","authors":["Tianyu Liu","Kevin Du","Mrinmaya Sachan","Ryan Cotterell"],"pdf_url":"https://arxiv.org/pdf/2410.14361v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2310.11244v4","updated":"2024-10-18T10:21:31Z","published":"2023-10-17T13:12:32Z","title":"Entity Matching using Large Language Models","summary":"  Entity matching is the task of deciding whether two entity descriptions refer\nto the same real-world entity. Entity matching is a central step in most data\nintegration pipelines. Many state-of-the-art entity matching methods rely on\npre-trained language models (PLMs) such as BERT or RoBERTa. Two major drawbacks\nof these models for entity matching are that (i) the models require significant\namounts of task-specific training data and (ii) the fine-tuned models are not\nrobust concerning out-of-distribution entities. This paper investigates using\ngenerative large language models (LLMs) as a less task-specific training\ndata-dependent and more robust alternative to PLM-based matchers. The study\ncovers hosted and open-source LLMs which can be run locally. We evaluate these\nmodels in a zero-shot scenario and a scenario where task-specific training data\nis available. We compare different prompt designs and the prompt sensitivity of\nthe models. We show that there is no single best prompt but that the prompt\nneeds to be tuned for each model/dataset combination. We further investigate\n(i) the selection of in-context demonstrations, (ii) the generation of matching\nrules, as well as (iii) fine-tuning LLMs using the same pool of training data.\nOur experiments show that the best LLMs require no or only a few training\nexamples to perform comparably to PLMs that were fine-tuned using thousands of\nexamples. LLM-based matchers further exhibit higher robustness to unseen\nentities. We show that GPT4 can generate structured explanations for matching\ndecisions and can automatically identify potential causes of matching errors by\nanalyzing explanations of wrong decisions. We demonstrate that the model can\ngenerate meaningful textual descriptions of the identified error classes, which\ncan help data engineers to improve entity matching pipelines.\n","authors":["Ralph Peeters","Aaron Steiner","Christian Bizer"],"pdf_url":"https://arxiv.org/pdf/2310.11244v4.pdf","comment":"Published in Proceedings of the 28th International Conference on\n  Extending Database Technology (EDBT), 25th March-28th March, 2025, ISBN\n  978-3-89318-098-1 on OpenProceedings.org"},{"id":"http://arxiv.org/abs/2409.19700v3","updated":"2024-10-18T10:15:29Z","published":"2024-09-29T13:16:37Z","title":"2D-TPE: Two-Dimensional Positional Encoding Enhances Table Understanding\n  for Large Language Models","summary":"  Tables are ubiquitous across various domains for concisely representing\nstructured information. Empowering large language models (LLMs) to reason over\ntabular data represents an actively explored direction. However, since typical\nLLMs only support one-dimensional~(1D) inputs, existing methods often flatten\nthe two-dimensional~(2D) table structure into a sequence of tokens, which can\nseverely disrupt the spatial relationships and result in an inevitable loss of\nvital contextual information. In this paper, we first empirically demonstrate\nthe detrimental impact of such flattening operations on the performance of LLMs\nin capturing the spatial information of tables through two elaborate proxy\ntasks. Subsequently, we introduce a simple yet effective positional encoding\nmethod, termed ``2D-TPE'' (Two-Dimensional Table Positional Encoding), to\naddress this challenge. 2D-TPE enables each attention head to dynamically\nselect a permutation order of tokens within the context for attending to them,\nwhere each permutation represents a distinct traversal mode for the table, such\nas column-wise or row-wise traversal. 2D-TPE effectively mitigates the risk of\nlosing essential spatial information while preserving computational efficiency,\nthus better preserving the table structure. Extensive experiments across five\nbenchmarks demonstrate that 2D-TPE outperforms strong baselines, underscoring\nthe importance of preserving the table structure for accurate table\ncomprehension. Comprehensive analysis further reveals the substantially better\nscalability of 2D-TPE to large tables than baselines.\n","authors":["Jia-Nan Li","Jian Guan","Wei Wu","Zhengtao Yu","Rui Yan"],"pdf_url":"https://arxiv.org/pdf/2409.19700v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.10859v2","updated":"2024-10-18T10:02:03Z","published":"2024-10-07T13:46:06Z","title":"FAME: Towards Factual Multi-Task Model Editing","summary":"  Large language models (LLMs) embed extensive knowledge and utilize it to\nperform exceptionally well across various tasks. Nevertheless, outdated\nknowledge or factual errors within LLMs can lead to misleading or incorrect\nresponses, causing significant issues in practical applications. To rectify the\nfatal flaw without the necessity for costly model retraining, various model\nediting approaches have been proposed to correct inaccurate knowledge within\nLLMs in a cost-efficient way. To evaluate these model editing methods, previous\nwork introduced a series of datasets. However, most of the previous datasets\nonly contain fabricated data in a single format, which diverges from real-world\nmodel editing scenarios, raising doubts about their usability in practice. To\nfacilitate the application of model editing in real-world scenarios, we propose\nthe challenge of practicality. To resolve such challenges and effectively\nenhance the capabilities of LLMs, we present FAME, an factual, comprehensive,\nand multi-task dataset, which is designed to enhance the practicality of model\nediting. We then propose SKEME, a model editing method that uses a novel\ncaching mechanism to ensure synchronization with the real world. The\nexperiments demonstrate that SKEME performs excellently across various tasks\nand scenarios, confirming its practicality.\n","authors":["Li Zeng","Yingyu Shan","Zeming Liu","Jiashu Yao","Yuhang Guo"],"pdf_url":"https://arxiv.org/pdf/2410.10859v2.pdf","comment":"9 pages, 3 figures. This paper has been accepted by EMNLP 2024"},{"id":"http://arxiv.org/abs/2302.08102v2","updated":"2024-10-18T09:58:45Z","published":"2023-02-16T06:01:31Z","title":"Prompt Tuning of Deep Neural Networks for Speaker-adaptive Visual Speech\n  Recognition","summary":"  Visual Speech Recognition (VSR) aims to infer speech into text depending on\nlip movements alone. As it focuses on visual information to model the speech,\nits performance is inherently sensitive to personal lip appearances and\nmovements, and this makes the VSR models show degraded performance when they\nare applied to unseen speakers. In this paper, to remedy the performance\ndegradation of the VSR model on unseen speakers, we propose prompt tuning\nmethods of Deep Neural Networks (DNNs) for speaker-adaptive VSR. Specifically,\nmotivated by recent advances in Natural Language Processing (NLP), we finetune\nprompts on adaptation data of target speakers instead of modifying the\npre-trained model parameters. Different from the previous prompt tuning methods\nmainly limited to Transformer variant architecture, we explore different types\nof prompts, the addition, the padding, and the concatenation form prompts that\ncan be applied to the VSR model which is composed of CNN and Transformer in\ngeneral. With the proposed prompt tuning, we show that the performance of the\npre-trained VSR model on unseen speakers can be largely improved by using a\nsmall amount of adaptation data (e.g., less than 5 minutes), even if the\npre-trained model is already developed with large speaker variations. Moreover,\nby analyzing the performance and parameters of different types of prompts, we\ninvestigate when the prompt tuning is preferred over the finetuning methods.\nThe effectiveness of the proposed method is evaluated on both word- and\nsentence-level VSR databases, LRW-ID and GRID.\n","authors":["Minsu Kim","Hyung-Il Kim","Yong Man Ro"],"pdf_url":"https://arxiv.org/pdf/2302.08102v2.pdf","comment":"IEEE TPAMI"},{"id":"http://arxiv.org/abs/2410.14335v1","updated":"2024-10-18T09:46:38Z","published":"2024-10-18T09:46:38Z","title":"Critical Questions Generation: Motivation and Challenges","summary":"  The development of Large Language Models (LLMs) has brought impressive\nperformances on mitigation strategies against misinformation, such as\ncounterargument generation. However, LLMs are still seriously hindered by\noutdated knowledge and by their tendency to generate hallucinated content. In\norder to circumvent these issues, we propose a new task, namely, Critical\nQuestions Generation, consisting of processing an argumentative text to\ngenerate the critical questions (CQs) raised by it. In argumentation theory CQs\nare tools designed to lay bare the blind spots of an argument by pointing at\nthe information it could be missing. Thus, instead of trying to deploy LLMs to\nproduce knowledgeable and relevant counterarguments, we use them to question\narguments, without requiring any external knowledge. Research on CQs Generation\nusing LLMs requires a reference dataset for large scale experimentation. Thus,\nin this work we investigate two complementary methods to create such a\nresource: (i) instantiating CQs templates as defined by Walton's argumentation\ntheory and (ii), using LLMs as CQs generators. By doing so, we contribute with\na procedure to establish what is a valid CQ and conclude that, while LLMs are\nreasonable CQ generators, they still have a wide margin for improvement in this\ntask.\n","authors":["Blanca Calvo Figueras","Rodrigo Agerri"],"pdf_url":"https://arxiv.org/pdf/2410.14335v1.pdf","comment":"14 pages, 3 figures, 7 tables, to be published in the 28th Conference\n  on Computational Natural Language Learning (CoNLL 2024)"},{"id":"http://arxiv.org/abs/2410.11677v2","updated":"2024-10-18T09:41:53Z","published":"2024-10-15T15:14:22Z","title":"Understanding Likelihood Over-optimisation in Direct Alignment\n  Algorithms","summary":"  Direct Alignment Algorithms (DAAs), such as Direct Preference Optimisation\n(DPO) and Identity Preference Optimisation (IPO), have emerged as alternatives\nto online Reinforcement Learning from Human Feedback (RLHF) algorithms such as\nProximal Policy Optimisation (PPO) for aligning language models to human\npreferences, without the need for explicit reward modelling. These methods\ngenerally aim to increase the likelihood of generating better (preferred)\ncompletions while discouraging worse (non-preferred) ones, while staying close\nto the original model's behaviour. In this work, we explore the relationship\nbetween completion likelihood and model performance in state-of-the-art DAAs,\nand identify a critical issue of likelihood over-optimisation. Contrary to\nexpectations, we find that higher likelihood of better completions and larger\nmargins between better and worse completion likelihoods do not necessarily lead\nto better performance, and may even degrade it. Our analysis reveals that while\nhigher likelihood correlates with better memorisation of factual knowledge\npatterns, a slightly lower completion likelihood tends to improve output\ndiversity, thus leading to better generalisation to unseen scenarios. Moreover,\nwe identify two key indicators that signal when over-optimised output diversity\nbegins to harm performance: Decreasing Entropy over Top-k Tokens and\nDiminishing Top-k Probability Mass. Our experimental results validate that\nthese indicators are reliable signs of declining performance under different\nregularisations, helping prevent over-optimisation and improve alignment with\nhuman preferences.\n","authors":["Zhengyan Shi","Sander Land","Acyr Locatelli","Matthieu Geist","Max Bartolo"],"pdf_url":"https://arxiv.org/pdf/2410.11677v2.pdf","comment":"Preprint Version"},{"id":"http://arxiv.org/abs/2403.05902v2","updated":"2024-10-18T09:39:14Z","published":"2024-03-09T12:46:53Z","title":"MaiBaam Annotation Guidelines","summary":"  This document provides the annotation guidelines for MaiBaam, a Bavarian\ncorpus manually annotated with part-of-speech (POS) tags, syntactic\ndependencies, and German lemmas. MaiBaam belongs to the Universal Dependencies\n(UD) project, and our annotations elaborate on the general and German UD\nversion 2 guidelines. In this document, we detail how to preprocess and\ntokenize Bavarian data, provide an overview of the POS tags and dependencies we\nuse, explain annotation decisions that would also apply to closely related\nlanguages like German, and lastly we introduce and motivate decisions that are\nspecific to Bavarian grammar.\n","authors":["Verena Blaschke","Barbara Kovačić","Siyao Peng","Barbara Plank"],"pdf_url":"https://arxiv.org/pdf/2403.05902v2.pdf","comment":"Updated for UD v2.15 (German lemmas added)"},{"id":"http://arxiv.org/abs/2410.10291v2","updated":"2024-10-18T09:26:46Z","published":"2024-10-14T08:45:35Z","title":"Evaluating Semantic Variation in Text-to-Image Synthesis: A Causal\n  Perspective","summary":"  Accurate interpretation and visualization of human instructions are crucial\nfor text-to-image (T2I) synthesis. However, current models struggle to capture\nsemantic variations from word order changes, and existing evaluations, relying\non indirect metrics like text-image similarity, fail to reliably assess these\nchallenges. This often obscures poor performance on complex or uncommon\nlinguistic patterns by the focus on frequent word combinations. To address\nthese deficiencies, we propose a novel metric called SemVarEffect and a\nbenchmark named SemVarBench, designed to evaluate the causality between\nsemantic variations in inputs and outputs in T2I synthesis. Semantic variations\nare achieved through two types of linguistic permutations, while avoiding\neasily predictable literal variations. Experiments reveal that the\nCogView-3-Plus and Ideogram 2 performed the best, achieving a score of 0.2/1.\nSemantic variations in object relations are less understood than attributes,\nscoring 0.07/1 compared to 0.17-0.19/1. We found that cross-modal alignment in\nUNet or Transformers plays a crucial role in handling semantic variations, a\nfactor previously overlooked by a focus on textual encoders. Our work\nestablishes an effective evaluation framework that advances the T2I synthesis\ncommunity's exploration of human instruction understanding. Our benchmark and\ncode are available at https://github.com/zhuxiangru/SemVarBench .\n","authors":["Xiangru Zhu","Penglei Sun","Yaoxian Song","Yanghua Xiao","Zhixu Li","Chengyu Wang","Jun Huang","Bei Yang","Xiaoxiao Xu"],"pdf_url":"https://arxiv.org/pdf/2410.10291v2.pdf","comment":"The only change in the current version update is the replacement of\n  the template with a more precise one"},{"id":"http://arxiv.org/abs/2410.14309v1","updated":"2024-10-18T09:15:35Z","published":"2024-10-18T09:15:35Z","title":"LoGU: Long-form Generation with Uncertainty Expressions","summary":"  While Large Language Models (LLMs) demonstrate impressive capabilities, they\nstill struggle with generating factually incorrect content (i.e.,\nhallucinations). A promising approach to mitigate this issue is enabling models\nto express uncertainty when unsure. Previous research on uncertainty modeling\nhas primarily focused on short-form QA, but realworld applications often\nrequire much longer responses. In this work, we introduce the task of Long-form\nGeneration with Uncertainty(LoGU). We identify two key challenges: Uncertainty\nSuppression, where models hesitate to express uncertainty, and Uncertainty\nMisalignment, where models convey uncertainty inaccurately. To tackle these\nchallenges, we propose a refinement-based data collection framework and a\ntwo-stage training pipeline. Our framework adopts a divide-and-conquer\nstrategy, refining uncertainty based on atomic claims. The collected data are\nthen used in training through supervised fine-tuning (SFT) and direct\npreference optimization (DPO) to enhance uncertainty expression. Extensive\nexperiments on three long-form instruction following datasets show that our\nmethod significantly improves accuracy, reduces hallucinations, and maintains\nthe comprehensiveness of responses.\n","authors":["Ruihan Yang","Caiqi Zhang","Zhisong Zhang","Xinting Huang","Sen Yang","Nigel Collier","Dong Yu","Deqing Yang"],"pdf_url":"https://arxiv.org/pdf/2410.14309v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.05672v2","updated":"2024-10-18T09:12:45Z","published":"2023-06-09T05:04:13Z","title":"I run as fast as a rabbit, can you? A Multilingual Simile Dialogue\n  Dataset","summary":"  A simile is a figure of speech that compares two different things (called the\ntenor and the vehicle) via shared properties. The tenor and the vehicle are\nusually connected with comparator words such as \"like\" or \"as\". The simile\nphenomena are unique and complex in a real-life dialogue scene where the tenor\nand the vehicle can be verbal phrases or sentences, mentioned by different\nspeakers, exist in different sentences, or occur in reversed order. However,\nthe current simile research usually focuses on similes in a triplet tuple\n(tenor, property, vehicle) or a single sentence where the tenor and vehicle are\nusually entities or noun phrases, which could not reflect complex simile\nphenomena in real scenarios. In this paper, we propose a novel and high-quality\nmultilingual simile dialogue (MSD) dataset to facilitate the study of complex\nsimile phenomena. The MSD is the largest manually annotated simile data\n($\\sim$20K) and it contains both English and Chinese data. Meanwhile, the MSD\ndata can also be used on dialogue tasks to test the ability of dialogue systems\nwhen using similes. We design 3 simile tasks (recognition, interpretation, and\ngeneration) and 2 dialogue tasks (retrieval and generation) with MSD. For each\ntask, we provide experimental results from strong pre-trained or\nstate-of-the-art models. The experiments demonstrate the challenge of MSD and\nwe have released the data/code on GitHub.\n","authors":["Longxuan Ma","Weinan Zhang","Shuhan Zhou","Churui Sun","Changxin Ke","Ting Liu"],"pdf_url":"https://arxiv.org/pdf/2306.05672v2.pdf","comment":"13 Pages, 1 Figure, 12 Tables, ACL 2023 findings"},{"id":"http://arxiv.org/abs/2406.13632v3","updated":"2024-10-18T09:07:53Z","published":"2024-06-19T15:28:29Z","title":"Can Few-shot Work in Long-Context? Recycling the Context to Generate\n  Demonstrations","summary":"  Despite recent advancements in Large Language Models (LLMs), their\nperformance on tasks involving long contexts remains sub-optimal. In-Context\nLearning (ICL) with few-shot examples may be an appealing solution to enhance\nLLM performance in this scenario; However, na\\\"ively adding ICL examples with\nlong context introduces challenges, including substantial token overhead added\nfor each few-shot example and context mismatch between the demonstrations and\nthe target query. In this work, we propose to automatically generate few-shot\nexamples for long context QA tasks by recycling contexts. Specifically, given a\nlong input context (1-3k tokens) and a query, we generate additional\nquery-output pairs from the given context as few-shot examples, while\nintroducing the context only once. This ensures that the demonstrations are\nleveraging the same context as the target query while only adding a small\nnumber of tokens to the prompt. We further enhance each demonstration by\ninstructing the model to explicitly identify the relevant paragraphs before the\nanswer, which improves performance while providing fine-grained attribution to\nthe answer source. We apply our method on multiple LLMs and obtain substantial\nimprovements (+16 absolute points on average across models) on various QA\ndatasets with long context, especially when the answer lies within the middle\nof the context. Surprisingly, despite introducing only single-hop ICL examples,\nLLMs also successfully generalize to multi-hop long-context QA using our\napproach.\n","authors":["Arie Cattan","Alon Jacovi","Alex Fabrikant","Jonathan Herzig","Roee Aharoni","Hannah Rashkin","Dror Marcus","Avinatan Hassidim","Yossi Matias","Idan Szpektor","Avi Caciularu"],"pdf_url":"https://arxiv.org/pdf/2406.13632v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2312.09075v3","updated":"2024-10-18T09:02:46Z","published":"2023-12-14T16:10:56Z","title":"Towards Verifiable Text Generation with Evolving Memory and\n  Self-Reflection","summary":"  Despite the remarkable ability of large language models (LLMs) in language\ncomprehension and generation, they often suffer from producing factually\nincorrect information, also known as hallucination. A promising solution to\nthis issue is verifiable text generation, which prompts LLMs to generate\ncontent with citations for accuracy verification. However, verifiable text\ngeneration is non-trivial due to the focus-shifting phenomenon, the intricate\nreasoning needed to align the claim with correct citations, and the dilemma\nbetween the precision and breadth of retrieved documents. In this paper, we\npresent VTG, an innovative framework for Verifiable Text Generation with\nevolving memory and self-reflection. VTG introduces evolving long short-term\nmemory to retain both valuable documents and recent documents. A two-tier\nverifier equipped with an evidence finder is proposed to rethink and reflect on\nthe relationship between the claim and citations. Furthermore, active retrieval\nand diverse query generation are utilized to enhance both the precision and\nbreadth of the retrieved documents. We conduct extensive experiments on five\ndatasets across three knowledge-intensive tasks and the results reveal that VTG\nsignificantly outperforms baselines.\n","authors":["Hao Sun","Hengyi Cai","Bo Wang","Yingyan Hou","Xiaochi Wei","Shuaiqiang Wang","Yan Zhang","Dawei Yin"],"pdf_url":"https://arxiv.org/pdf/2312.09075v3.pdf","comment":"EMNLP 2024 Main Conference"},{"id":"http://arxiv.org/abs/2407.12013v2","updated":"2024-10-18T08:57:30Z","published":"2024-06-26T12:33:34Z","title":"Dating ancient manuscripts using radiocarbon and AI-based writing style\n  analysis","summary":"  Determining the chronology of ancient handwritten manuscripts is essential\nfor reconstructing the evolution of ideas. For the Dead Sea Scrolls, this is\nparticularly important. However, there is an almost complete lack of\ndate-bearing manuscripts evenly distributed across the timeline and written in\nsimilar scripts available for palaeographic comparison. Here, we present Enoch,\na state-of-the-art AI-based date-prediction model, trained on the basis of new\nradiocarbon-dated samples of the scrolls. Enoch uses established\nhandwriting-style descriptors and applies Bayesian ridge regression. The\nchallenge of this study is that the number of radiocarbon-dated manuscripts is\nsmall, while current machine learning requires an abundance of training data.\nWe show that by using combined angular and allographic writing style feature\nvectors and applying Bayesian ridge regression, Enoch could predict the\nradiocarbon-based dates from style, supported by leave-one-out validation, with\nvaried MAEs of 27.9 to 30.7 years relative to the radiocarbon dating. Enoch was\nthen used to estimate the dates of 135 unseen manuscripts, revealing that 79\nper cent of the samples were considered 'realistic' upon palaeographic post-hoc\nevaluation. We present a new chronology of the scrolls. The radiocarbon ranges\nand Enoch's style-based predictions are often older than the traditionally\nassumed palaeographic estimates. In the range of 300-50 BCE, Enoch's date\nprediction provides an improved granularity. The study is in line with current\ndevelopments in multimodal machine-learning techniques, and the methods can be\nused for date prediction in other partially-dated manuscript collections. This\nresearch shows how Enoch's quantitative, probability-based approach can be a\ntool for palaeographers and historians, re-dating ancient Jewish key texts and\ncontributing to current debates on Jewish and Christian origins.\n","authors":["Mladen Popović","Maruf A. Dhali","Lambert Schomaker","Johannes van der Plicht","Kaare Lund Rasmussen","Jacopo La Nasa","Ilaria Degano","Maria Perla Colombini","Eibert Tigchelaar"],"pdf_url":"https://arxiv.org/pdf/2407.12013v2.pdf","comment":"16 pages of main article, 103 pages of supplementary materials; the\n  first version of this article is originally prepared in July 2023 after the\n  completion of all the experiments"},{"id":"http://arxiv.org/abs/2310.14626v2","updated":"2024-10-18T08:56:18Z","published":"2023-10-23T07:00:51Z","title":"Conversational Recommender System and Large Language Model Are Made for\n  Each Other in E-commerce Pre-sales Dialogue","summary":"  E-commerce pre-sales dialogue aims to understand and elicit user needs and\npreferences for the items they are seeking so as to provide appropriate\nrecommendations. Conversational recommender systems (CRSs) learn user\nrepresentation and provide accurate recommendations based on dialogue context,\nbut rely on external knowledge. Large language models (LLMs) generate responses\nthat mimic pre-sales dialogues after fine-tuning, but lack domain-specific\nknowledge for accurate recommendations. Intuitively, the strengths of LLM and\nCRS in E-commerce pre-sales dialogues are complementary, yet no previous work\nhas explored this. This paper investigates the effectiveness of combining LLM\nand CRS in E-commerce pre-sales dialogues, proposing two collaboration methods:\nCRS assisting LLM and LLM assisting CRS. We conduct extensive experiments on a\nreal-world dataset of Ecommerce pre-sales dialogues. We analyze the impact of\ntwo collaborative approaches with two CRSs and two LLMs on four tasks of\nEcommerce pre-sales dialogue. We find that collaborations between CRS and LLM\ncan be very effective in some cases.\n","authors":["Yuanxing Liu","Wei-Nan Zhang","Yifan Chen","Yuchi Zhang","Haopeng Bai","Fan Feng","Hengbin Cui","Yongbin Li","Wanxiang Che"],"pdf_url":"https://arxiv.org/pdf/2310.14626v2.pdf","comment":"EMNLP 2023 Findings"},{"id":"http://arxiv.org/abs/2405.20680v4","updated":"2024-10-18T08:54:37Z","published":"2024-05-31T08:22:49Z","title":"Unraveling and Mitigating Retriever Inconsistencies in\n  Retrieval-Augmented Large Language Models","summary":"  Although Retrieval-Augmented Large Language Models (RALMs) demonstrate their\nsuperiority in terms of factuality, they do not consistently outperform the\noriginal retrieval-free Language Models (LMs). Our experiments reveal that this\nexample-level performance inconsistency exists not only between\nretrieval-augmented and retrieval-free LM but also among different retrievers.\nTo understand this phenomenon, we investigate the degeneration behavior of\nRALMs and theoretically decompose it into four categories. Further analysis\nbased on our decomposition reveals that the innate difference in knowledge\nsources and the unpredictable degeneration of the reader model contribute most\nto the inconsistency. Drawing from our analysis, we introduce Ensemble of\nRetrievers (EoR), a trainable framework that can adaptively retrieve from\ndifferent knowledge sources and effectively decrease unpredictable reader\nerrors. Our experiments on Open Domain Question Answering show that EoR\nsubstantially improves performance over the RALM with a single retriever by\nconsiderably reducing inconsistent behaviors.\n","authors":["Mingda Li","Xinyu Li","Yifan Chen","Wenfeng Xuan","Weinan Zhang"],"pdf_url":"https://arxiv.org/pdf/2405.20680v4.pdf","comment":"ACL 2024 (findings)"},{"id":"http://arxiv.org/abs/2406.15053v2","updated":"2024-10-18T08:51:55Z","published":"2024-06-21T11:00:38Z","title":"PARIKSHA: A Large-Scale Investigation of Human-LLM Evaluator Agreement\n  on Multilingual and Multi-Cultural Data","summary":"  Evaluation of multilingual Large Language Models (LLMs) is challenging due to\na variety of factors -- the lack of benchmarks with sufficient linguistic\ndiversity, contamination of popular benchmarks into LLM pre-training data and\nthe lack of local, cultural nuances in translated benchmarks. In this work, we\nstudy human and LLM-based evaluation in a multilingual, multi-cultural setting.\nWe evaluate 30 models across 10 Indic languages by conducting 90K human\nevaluations and 30K LLM-based evaluations and find that models such as GPT-4o\nand Llama-3 70B consistently perform best for most Indic languages. We build\nleaderboards for two evaluation settings - pairwise comparison and direct\nassessment and analyze the agreement between humans and LLMs. We find that\nhumans and LLMs agree fairly well in the pairwise setting but the agreement\ndrops for direct assessment evaluation especially for languages such as Bengali\nand Odia. We also check for various biases in human and LLM-based evaluation\nand find evidence of self-bias in the GPT-based evaluator. Our work presents a\nsignificant step towards scaling up multilingual evaluation of LLMs.\n","authors":["Ishaan Watts","Varun Gumma","Aditya Yadavalli","Vivek Seshadri","Manohar Swaminathan","Sunayana Sitaram"],"pdf_url":"https://arxiv.org/pdf/2406.15053v2.pdf","comment":"Accepted to EMNLP 2024"},{"id":"http://arxiv.org/abs/2410.14289v1","updated":"2024-10-18T08:49:24Z","published":"2024-10-18T08:49:24Z","title":"SwaQuAD-24: QA Benchmark Dataset in Swahili","summary":"  This paper proposes the creation of a Swahili Question Answering (QA)\nbenchmark dataset, aimed at addressing the underrepresentation of Swahili in\nnatural language processing (NLP). Drawing from established benchmarks like\nSQuAD, GLUE, KenSwQuAD, and KLUE, the dataset will focus on providing\nhigh-quality, annotated question-answer pairs that capture the linguistic\ndiversity and complexity of Swahili. The dataset is designed to support a\nvariety of applications, including machine translation, information retrieval,\nand social services like healthcare chatbots. Ethical considerations, such as\ndata privacy, bias mitigation, and inclusivity, are central to the dataset\ndevelopment. Additionally, the paper outlines future expansion plans to include\ndomain-specific content, multimodal integration, and broader crowdsourcing\nefforts. The Swahili QA dataset aims to foster technological innovation in East\nAfrica and provide an essential resource for NLP research and applications in\nlow-resource languages.\n","authors":["Alfred Malengo Kondoro"],"pdf_url":"https://arxiv.org/pdf/2410.14289v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.14276v1","updated":"2024-10-18T08:31:22Z","published":"2024-10-18T08:31:22Z","title":"EcomEdit: An Automated E-commerce Knowledge Editing Framework for\n  Enhanced Product and Purchase Intention Understanding","summary":"  Knowledge Editing (KE) aims to correct and update factual information in\nLarge Language Models (LLMs) to ensure accuracy and relevance without\ncomputationally expensive fine-tuning. Though it has been proven effective in\nseveral domains, limited work has focused on its application within the\ne-commerce sector. However, there are naturally occurring scenarios that make\nKE necessary in this domain, such as the timely updating of product features\nand trending purchase intentions by customers, which necessitate further\nexploration. In this paper, we pioneer the application of KE in the e-commerce\ndomain by presenting ECOMEDIT, an automated e-commerce knowledge editing\nframework tailored for e-commerce-related knowledge and tasks. Our framework\nleverages more powerful LLMs as judges to enable automatic knowledge conflict\ndetection and incorporates conceptualization to enhance the semantic coverage\nof the knowledge to be edited. Through extensive experiments, we demonstrate\nthe effectiveness of ECOMEDIT in improving LLMs' understanding of product\ndescriptions and purchase intentions. We also show that LLMs, after our\nediting, can achieve stronger performance on downstream e-commerce tasks.\n","authors":["Ching Ming Samuel Lau","Weiqi Wang","Haochen Shi","Baixuan Xu","Jiaxin Bai","Yangqiu Song"],"pdf_url":"https://arxiv.org/pdf/2410.14276v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.14273v1","updated":"2024-10-18T08:27:02Z","published":"2024-10-18T08:27:02Z","title":"REEF: Representation Encoding Fingerprints for Large Language Models","summary":"  Protecting the intellectual property of open-source Large Language Models\n(LLMs) is very important, because training LLMs costs extensive computational\nresources and data. Therefore, model owners and third parties need to identify\nwhether a suspect model is a subsequent development of the victim model. To\nthis end, we propose a training-free REEF to identify the relationship between\nthe suspect and victim models from the perspective of LLMs' feature\nrepresentations. Specifically, REEF computes and compares the centered kernel\nalignment similarity between the representations of a suspect model and a\nvictim model on the same samples. This training-free REEF does not impair the\nmodel's general capabilities and is robust to sequential fine-tuning, pruning,\nmodel merging, and permutations. In this way, REEF provides a simple and\neffective way for third parties and models' owners to protect LLMs'\nintellectual property together. The code is available at\nhttps://github.com/tmylla/REEF.\n","authors":["Jie Zhang","Dongrui Liu","Chen Qian","Linfeng Zhang","Yong Liu","Yu Qiao","Jing Shao"],"pdf_url":"https://arxiv.org/pdf/2410.14273v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.14268v1","updated":"2024-10-18T08:22:07Z","published":"2024-10-18T08:22:07Z","title":"MoDification: Mixture of Depths Made Easy","summary":"  Long-context efficiency has recently become a trending topic in serving large\nlanguage models (LLMs). And mixture of depths (MoD) is proposed as a perfect\nfit to bring down both latency and memory. In this paper, however, we discover\nthat MoD can barely transform existing LLMs without costly training over an\nextensive number of tokens. To enable the transformations from any LLMs to MoD\nones, we showcase top-k operator in MoD should be promoted to threshold-p\noperator, and refinement to architecture and data should also be crafted along.\nAll these designs form our method termed MoDification. Through a comprehensive\nset of experiments covering model scales from 3B to 70B, we exhibit\nMoDification strikes an excellent balance between efficiency and effectiveness.\nMoDification can achieve up to ~1.2x speedup in latency and ~1.8x reduction in\nmemory compared to original LLMs especially in long-context applications.\n","authors":["Chen Zhang","Meizhi Zhong","Qimeng Wang","Xuantao Lu","Zheyu Ye","Chengqiang Lu","Yan Gao","Yao Hu","Kehai Chen","Min Zhang","Dawei Song"],"pdf_url":"https://arxiv.org/pdf/2410.14268v1.pdf","comment":"12 pages, 9 figures, 5 tables, work in progress"},{"id":"http://arxiv.org/abs/2406.06572v2","updated":"2024-10-18T08:20:38Z","published":"2024-06-03T17:07:46Z","title":"Graph Neural Network Enhanced Retrieval for Question Answering of LLMs","summary":"  Retrieval augmented generation has revolutionized large language model (LLM)\noutputs by providing factual supports. Nevertheless, it struggles to capture\nall the necessary knowledge for complex reasoning questions. Existing retrieval\nmethods typically divide reference documents into passages, treating them in\nisolation. These passages, however, are often interrelated, such as passages\nthat are contiguous or share the same keywords. Therefore, it is crucial to\nrecognize such relatedness for enhancing the retrieval process. In this paper,\nwe propose a novel retrieval method, called GNN-Ret, which leverages graph\nneural networks (GNNs) to enhance retrieval by exploiting the relatedness\nbetween passages. Specifically, we first construct a graph of passages by\nconnecting passages that are structure-related or keyword-related. A graph\nneural network (GNN) is then leveraged to exploit the relationships between\npassages and improve the retrieval of supporting passages. Furthermore, we\nextend our method to handle multi-hop reasoning questions using a recurrent\ngraph neural network (RGNN), named RGNN-Ret. At each step, RGNN-Ret integrates\nthe graphs of passages from previous steps, thereby enhancing the retrieval of\nsupporting passages. Extensive experiments on benchmark datasets demonstrate\nthat GNN-Ret achieves higher accuracy for question answering with a single\nquery of LLMs than strong baselines that require multiple queries, and RGNN-Ret\nfurther improves accuracy and achieves state-of-the-art performance, with up to\n10.4% accuracy improvement on the 2WikiMQA dataset.\n","authors":["Zijian Li","Qingyan Guo","Jiawei Shao","Lei Song","Jiang Bian","Jun Zhang","Rui Wang"],"pdf_url":"https://arxiv.org/pdf/2406.06572v2.pdf","comment":"Under review"},{"id":"http://arxiv.org/abs/2410.14262v1","updated":"2024-10-18T08:18:18Z","published":"2024-10-18T08:18:18Z","title":"Good Parenting is all you need -- Multi-agentic LLM Hallucination\n  Mitigation","summary":"  This study explores the ability of Large Language Model (LLM) agents to\ndetect and correct hallucinations in AI-generated content. A primary agent was\ntasked with creating a blog about a fictional Danish artist named Flipfloppidy,\nwhich was then reviewed by another agent for factual inaccuracies. Most LLMs\nhallucinated the existence of this artist. Across 4,900 test runs involving\nvarious combinations of primary and reviewing agents, advanced AI models such\nas Llama3-70b and GPT-4 variants demonstrated near-perfect accuracy in\nidentifying hallucinations and successfully revised outputs in 85% to 100% of\ncases following feedback. These findings underscore the potential of advanced\nAI models to significantly enhance the accuracy and reliability of generated\ncontent, providing a promising approach to improving AI workflow orchestration.\n","authors":[" Edward"," Kwartler","Matthew Berman","Alan Aqrawi"],"pdf_url":"https://arxiv.org/pdf/2410.14262v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.14259v1","updated":"2024-10-18T08:14:10Z","published":"2024-10-18T08:14:10Z","title":"Beyond Binary: Towards Fine-Grained LLM-Generated Text Detection via\n  Role Recognition and Involvement Measurement","summary":"  The rapid development of large language models (LLMs), like ChatGPT, has\nresulted in the widespread presence of LLM-generated content on social media\nplatforms, raising concerns about misinformation, data biases, and privacy\nviolations, which can undermine trust in online discourse. While detecting\nLLM-generated content is crucial for mitigating these risks, current methods\noften focus on binary classification, failing to address the complexities of\nreal-world scenarios like human-AI collaboration. To move beyond binary\nclassification and address these challenges, we propose a new paradigm for\ndetecting LLM-generated content. This approach introduces two novel tasks: LLM\nRole Recognition (LLM-RR), a multi-class classification task that identifies\nspecific roles of LLM in content generation, and LLM Influence Measurement\n(LLM-IM), a regression task that quantifies the extent of LLM involvement in\ncontent creation. To support these tasks, we propose LLMDetect, a benchmark\ndesigned to evaluate detectors' performance on these new tasks. LLMDetect\nincludes the Hybrid News Detection Corpus (HNDC) for training detectors, as\nwell as DetectEval, a comprehensive evaluation suite that considers five\ndistinct cross-context variations and multi-intensity variations within the\nsame LLM role. This allows for a thorough assessment of detectors'\ngeneralization and robustness across diverse contexts. Our empirical validation\nof 10 baseline detection methods demonstrates that fine-tuned PLM-based models\nconsistently outperform others on both tasks, while advanced LLMs face\nchallenges in accurately detecting their own generated content. Our\nexperimental results and analysis offer insights for developing more effective\ndetection models for LLM-generated content. This research enhances the\nunderstanding of LLM-generated content and establishes a foundation for more\nnuanced detection methodologies.\n","authors":["Zihao Cheng","Li Zhou","Feng Jiang","Benyou Wang","Haizhou Li"],"pdf_url":"https://arxiv.org/pdf/2410.14259v1.pdf","comment":"Social Media, Large Language Models, LLM-generated Text Detection,\n  AI-assisted News Detection"},{"id":"http://arxiv.org/abs/2410.14255v1","updated":"2024-10-18T08:04:36Z","published":"2024-10-18T08:04:36Z","title":"Nova: An Iterative Planning and Search Approach to Enhance Novelty and\n  Diversity of LLM Generated Ideas","summary":"  Scientific innovation is pivotal for humanity, and harnessing large language\nmodels (LLMs) to generate research ideas could transform discovery. However,\nexisting LLMs often produce simplistic and repetitive suggestions due to their\nlimited ability in acquiring external knowledge for innovation. To address this\nproblem, we introduce an enhanced planning and search methodology designed to\nboost the creative potential of LLM-based systems. Our approach involves an\niterative process to purposely plan the retrieval of external knowledge,\nprogressively enriching the idea generation with broader and deeper insights.\nValidation through automated and human assessments indicates that our framework\nsubstantially elevates the quality of generated ideas, particularly in novelty\nand diversity. The number of unique novel ideas produced by our framework is\n3.4 times higher than without it. Moreover, our method outperforms the current\nstate-of-the-art, generating at least 2.5 times more top-rated ideas based on\n170 seed papers in a Swiss Tournament evaluation.\n","authors":["Xiang Hu","Hongyu Fu","Jinge Wang","Yifeng Wang","Zhikun Li","Renjun Xu","Yu Lu","Yaochu Jin","Lili Pan","Zhenzhong Lan"],"pdf_url":"https://arxiv.org/pdf/2410.14255v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2404.17524v4","updated":"2024-10-18T08:03:02Z","published":"2024-04-26T16:41:00Z","title":"On the Use of Large Language Models to Generate Capability Ontologies","summary":"  Capability ontologies are increasingly used to model functionalities of\nsystems or machines. The creation of such ontological models with all\nproperties and constraints of capabilities is very complex and can only be done\nby ontology experts. However, Large Language Models (LLMs) have shown that they\ncan generate machine-interpretable models from natural language text input and\nthus support engineers / ontology experts. Therefore, this paper investigates\nhow LLMs can be used to create capability ontologies. We present a study with a\nseries of experiments in which capabilities with varying complexities are\ngenerated using different prompting techniques and with different LLMs. Errors\nin the generated ontologies are recorded and compared. To analyze the quality\nof the generated ontologies, a semi-automated approach based on RDF syntax\nchecking, OWL reasoning, and SHACL constraints is used. The results of this\nstudy are very promising because even for complex capabilities, the generated\nontologies are almost free of errors.\n","authors":["Luis Miguel Vieira da Silva","Aljosha Köcher","Felix Gehlhoff","Alexander Fay"],"pdf_url":"https://arxiv.org/pdf/2404.17524v4.pdf","comment":"\\c{opyright} 2024 IEEE. Personal use of this material is permitted.\n  Permission from IEEE must be obtained for all other uses, in any current or\n  future media, including reprinting/republishing this material for advertising\n  or promotional purposes, creating new collective works, for resale or\n  redistribution to servers or lists, or reuse of any copyrighted component of\n  this work in other works"},{"id":"http://arxiv.org/abs/2410.14251v1","updated":"2024-10-18T08:01:39Z","published":"2024-10-18T08:01:39Z","title":"Synthesizing Post-Training Data for LLMs through Multi-Agent Simulation","summary":"  Post-training is essential for enabling large language models (LLMs) to\nfollow human instructions. Inspired by the recent success of using LLMs to\nsimulate human society, we leverage multi-agent simulation to automatically\ngenerate diverse text-based scenarios, capturing a wide range of real-world\nhuman needs. We propose MATRIX, a multi-agent simulator that creates realistic\nand scalable scenarios. Leveraging these outputs, we introduce a novel\nscenario-driven instruction generator MATRIX-Gen for controllable and highly\nrealistic data synthesis. Extensive experiments demonstrate that our framework\neffectively generates both general and domain-specific data. Notably, on\nAlpacaEval 2 and Arena-Hard benchmarks, Llama-3-8B-Base, post-trained on\ndatasets synthesized by MATRIX-Gen with just 20K instruction-response pairs,\noutperforms Meta's Llama-3-8B-Instruct model, which was trained on over 10M\npairs; see our project at https://github.com/ShuoTang123/MATRIX-Gen.\n","authors":["Shuo Tang","Xianghe Pang","Zexi Liu","Bohan Tang","Rui Ye","Xiaowen Dong","Yanfeng Wang","Siheng Chen"],"pdf_url":"https://arxiv.org/pdf/2410.14251v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.14248v1","updated":"2024-10-18T07:52:22Z","published":"2024-10-18T07:52:22Z","title":"Addressing Blind Guessing: Calibration of Selection Bias in\n  Multiple-Choice Question Answering by Video Language Models","summary":"  Evaluating Video Language Models (VLMs) is a challenging task. Due to its\ntransparency, Multiple-Choice Question Answering (MCQA) is widely used to\nmeasure the performance of these models through accuracy. However, existing\nMCQA benchmarks fail to capture the full reasoning capabilities of VLMs due to\nselection bias, when models disproportionately favor certain answer options\nbased on positional patterns observed during training. In this work, we conduct\na comprehensive empirical analysis of several VLM architectures across major\ndatasets designed to assess complex video-focused reasoning. We identify where\nthe bias is most pronounced and demonstrate to what extent model responses\nreflect genuine understanding of video content and related questions, as\nopposed to reliance on arbitrary patterns or superficial cues, such as answer\nposition. By decomposing the MCQA task and adapting fairness bias metrics to\nVLMs, we introduce a post-processing calibration technique BOLD to balance this\nbias. Our results show that reducing selection bias improves not only debiasing\nmetrics but also overall model performance, including Accuracy and F1 Mean\nscore. Our method, by suppressing \"blind guessing\", offers a more cost- and\ntime-effective approach to mitigating selection bias compared to existing\ntechniques. This study represents the first focused investigation of selection\nbias in video-to-text LLM-powered models.\n","authors":["Olga Loginova","Oleksandr Bezrukov","Alexey Kravets"],"pdf_url":"https://arxiv.org/pdf/2410.14248v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.14236v1","updated":"2024-10-18T07:36:57Z","published":"2024-10-18T07:36:57Z","title":"A Novel Method to Metigate Demographic and Expert Bias in ICD Coding\n  with Causal Inference","summary":"  ICD(International Classification of Diseases) coding involves assigning ICD\ncodes to patients visit based on their medical notes. Considering ICD coding as\na multi-label text classification task, researchers have developed\nsophisticated methods. Despite progress, these models often suffer from label\nimbalance and may develop spurious correlations with demographic factors.\nAdditionally, while human coders assign ICD codes, the inclusion of irrelevant\ninformation from unrelated experts introduces biases. To combat these issues,\nwe propose a novel method to mitigate Demographic and Expert biases in ICD\ncoding through Causal Inference (DECI). We provide a novel causality-based\ninterpretation in ICD Coding that models make predictions by three distinct\npathways. And based counterfactual reasoning, DECI mitigate demographic and\nexpert biases. Experimental results show that DECI outperforms state-of-the-art\nmodels, offering a significant advancement in accurate and unbiased ICD coding.\n","authors":["Bin Zhang","Junli Wang"],"pdf_url":"https://arxiv.org/pdf/2410.14236v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.07962v2","updated":"2024-10-18T07:34:39Z","published":"2024-06-12T07:41:44Z","title":"Toward a Method to Generate Capability Ontologies from Natural Language\n  Descriptions","summary":"  To achieve a flexible and adaptable system, capability ontologies are\nincreasingly leveraged to describe functions in a machine-interpretable way.\nHowever, modeling such complex ontological descriptions is still a manual and\nerror-prone task that requires a significant amount of effort and ontology\nexpertise. This contribution presents an innovative method to automate\ncapability ontology modeling using Large Language Models (LLMs), which have\nproven to be well suited for such tasks. Our approach requires only a natural\nlanguage description of a capability, which is then automatically inserted into\na predefined prompt using a few-shot prompting technique. After prompting an\nLLM, the resulting capability ontology is automatically verified through\nvarious steps in a loop with the LLM to check the overall correctness of the\ncapability ontology. First, a syntax check is performed, then a check for\ncontradictions, and finally a check for hallucinations and missing ontology\nelements. Our method greatly reduces manual effort, as only the initial natural\nlanguage description and a final human review and possible correction are\nnecessary, thereby streamlining the capability ontology generation process.\n","authors":["Luis Miguel Vieira da Silva","Aljosha Köcher","Felix Gehlhoff","Alexander Fay"],"pdf_url":"https://arxiv.org/pdf/2406.07962v2.pdf","comment":"\\c{opyright} 2024 IEEE. Personal use of this material is permitted.\n  Permission from IEEE must be obtained for all other uses, in any current or\n  future media, including reprinting/republishing this material for advertising\n  or promotional purposes, creating new collective works, for resale or\n  redistribution to servers or lists, or reuse of any copyrighted component of\n  this work in other works"},{"id":"http://arxiv.org/abs/2410.14235v1","updated":"2024-10-18T07:34:21Z","published":"2024-10-18T07:34:21Z","title":"Towards Robust Knowledge Representations in Multilingual LLMs for\n  Equivalence and Inheritance based Consistent Reasoning","summary":"  Reasoning and linguistic skills form the cornerstone of human intelligence,\nfacilitating problem-solving and decision-making. Recent advances in Large\nLanguage Models (LLMs) have led to impressive linguistic capabilities and\nemergent reasoning behaviors, fueling widespread adoption across application\ndomains. However, LLMs still struggle with complex reasoning tasks,\nhighlighting their systemic limitations. In this work, we focus on evaluating\nwhether LLMs have the requisite representations to reason using two\nfoundational relationships: \"equivalence\" and \"inheritance\". We introduce novel\ntasks and benchmarks spanning six languages and observe that current SOTA LLMs\noften produce conflicting answers to the same questions across languages in\n17.3-57.5% of cases and violate inheritance constraints in up to 37.2% cases.\nTo enhance consistency across languages, we propose novel \"Compositional\nRepresentations\" where tokens are represented as composition of equivalent\ntokens across languages, with resulting conflict reduction (up to -4.7%)\nindicating benefits of shared LLM representations.\n","authors":["Gaurav Arora","Srujana Merugu","Shreya Jain","Vaibhav Saxena"],"pdf_url":"https://arxiv.org/pdf/2410.14235v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.14231v1","updated":"2024-10-18T07:25:00Z","published":"2024-10-18T07:25:00Z","title":"Unveiling Large Language Models Generated Texts: A Multi-Level\n  Fine-Grained Detection Framework","summary":"  Large language models (LLMs) have transformed human writing by enhancing\ngrammar correction, content expansion, and stylistic refinement. However, their\nwidespread use raises concerns about authorship, originality, and ethics, even\npotentially threatening scholarly integrity. Existing detection methods, which\nmainly rely on single-feature analysis and binary classification, often fail to\neffectively identify LLM-generated text in academic contexts. To address these\nchallenges, we propose a novel Multi-level Fine-grained Detection (MFD)\nframework that detects LLM-generated text by integrating low-level structural,\nhigh-level semantic, and deep-level linguistic features, while conducting\nsentence-level evaluations of lexicon, grammar, and syntax for comprehensive\nanalysis. To improve detection of subtle differences in LLM-generated text and\nenhance robustness against paraphrasing, we apply two mainstream evasion\ntechniques to rewrite the text. These variations, along with original texts,\nare used to train a text encoder via contrastive learning, extracting\nhigh-level semantic features of sentence to boost detection generalization.\nFurthermore, we leverage advanced LLM to analyze the entire text and extract\ndeep-level linguistic features, enhancing the model's ability to capture\ncomplex patterns and nuances while effectively incorporating contextual\ninformation. Extensive experiments on public datasets show that the MFD model\noutperforms existing methods, achieving an MAE of 0.1346 and an accuracy of\n88.56%. Our research provides institutions and publishers with an effective\nmechanism to detect LLM-generated text, mitigating risks of compromised\nauthorship. Educators and editors can use the model's predictions to refine\nverification and plagiarism prevention protocols, ensuring adherence to\nstandards.\n","authors":["Zhen Tao","Zhiyu Li","Runyu Chen","Dinghao Xi","Wei Xu"],"pdf_url":"https://arxiv.org/pdf/2410.14231v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.14225v1","updated":"2024-10-18T07:14:54Z","published":"2024-10-18T07:14:54Z","title":"Few-Shot Joint Multimodal Entity-Relation Extraction via\n  Knowledge-Enhanced Cross-modal Prompt Model","summary":"  Joint Multimodal Entity-Relation Extraction (JMERE) is a challenging task\nthat aims to extract entities and their relations from text-image pairs in\nsocial media posts. Existing methods for JMERE require large amounts of labeled\ndata. However, gathering and annotating fine-grained multimodal data for JMERE\nposes significant challenges. Initially, we construct diverse and comprehensive\nmultimodal few-shot datasets fitted to the original data distribution. To\naddress the insufficient information in the few-shot setting, we introduce the\n\\textbf{K}nowledge-\\textbf{E}nhanced \\textbf{C}ross-modal \\textbf{P}rompt\n\\textbf{M}odel (KECPM) for JMERE. This method can effectively address the\nproblem of insufficient information in the few-shot setting by guiding a large\nlanguage model to generate supplementary background knowledge. Our proposed\nmethod comprises two stages: (1) a knowledge ingestion stage that dynamically\nformulates prompts based on semantic similarity guide ChatGPT generating\nrelevant knowledge and employs self-reflection to refine the knowledge; (2) a\nknowledge-enhanced language model stage that merges the auxiliary knowledge\nwith the original input and utilizes a transformer-based model to align with\nJMERE's required output format. We extensively evaluate our approach on a\nfew-shot dataset derived from the JMERE dataset, demonstrating its superiority\nover strong baselines in terms of both micro and macro F$_1$ scores.\nAdditionally, we present qualitative analyses and case studies to elucidate the\neffectiveness of our model.\n","authors":["Li Yuan","Yi Cai","Junsheng Huang"],"pdf_url":"https://arxiv.org/pdf/2410.14225v1.pdf","comment":"accepted by ACM MM 2024"},{"id":"http://arxiv.org/abs/2409.09785v3","updated":"2024-10-18T07:11:35Z","published":"2024-09-15T16:32:49Z","title":"Large Language Model Based Generative Error Correction: A Challenge and\n  Baselines for Speech Recognition, Speaker Tagging, and Emotion Recognition","summary":"  Given recent advances in generative AI technology, a key question is how\nlarge language models (LLMs) can enhance acoustic modeling tasks using text\ndecoding results from a frozen, pretrained automatic speech recognition (ASR)\nmodel. To explore new capabilities in language modeling for speech processing,\nwe introduce the generative speech transcription error correction (GenSEC)\nchallenge. This challenge comprises three post-ASR language modeling tasks: (i)\npost-ASR transcription correction, (ii) speaker tagging, and (iii) emotion\nrecognition. These tasks aim to emulate future LLM-based agents handling\nvoice-based interfaces while remaining accessible to a broad audience by\nutilizing open pretrained language models or agent-based APIs. We also discuss\ninsights from baseline evaluations, as well as lessons learned for designing\nfuture evaluations.\n","authors":["Chao-Han Huck Yang","Taejin Park","Yuan Gong","Yuanchao Li","Zhehuai Chen","Yen-Ting Lin","Chen Chen","Yuchen Hu","Kunal Dhawan","Piotr Żelasko","Chao Zhang","Yun-Nung Chen","Yu Tsao","Jagadeesh Balam","Boris Ginsburg","Sabato Marco Siniscalchi","Eng Siong Chng","Peter Bell","Catherine Lai","Shinji Watanabe","Andreas Stolcke"],"pdf_url":"https://arxiv.org/pdf/2409.09785v3.pdf","comment":"IEEE SLT 2024. The initial draft version has been done in December\n  2023. Post-ASR Text Processing and Understanding Community and LlaMA-7B\n  pre-training correction model:\n  https://huggingface.co/GenSEC-LLM/SLT-Task1-Llama2-7b-HyPo-baseline"},{"id":"http://arxiv.org/abs/2410.09421v2","updated":"2024-10-18T07:10:38Z","published":"2024-10-12T07:56:47Z","title":"VLFeedback: A Large-Scale AI Feedback Dataset for Large Vision-Language\n  Models Alignment","summary":"  As large vision-language models (LVLMs) evolve rapidly, the demand for\nhigh-quality and diverse data to align these models becomes increasingly\ncrucial. However, the creation of such data with human supervision proves\ncostly and time-intensive. In this paper, we investigate the efficacy of AI\nfeedback to scale supervision for aligning LVLMs. We introduce VLFeedback, the\nfirst large-scale vision-language feedback dataset, comprising over 82K\nmulti-modal instructions and comprehensive rationales generated by\noff-the-shelf models without human annotations. To evaluate the effectiveness\nof AI feedback for vision-language alignment, we train Silkie, an LVLM\nfine-tuned via direct preference optimization on VLFeedback. Silkie showcases\nexceptional performance regarding helpfulness, visual faithfulness, and safety\nmetrics. It outperforms its base model by 6.9\\% and 9.5\\% in perception and\ncognition tasks, reduces hallucination issues on MMHal-Bench, and exhibits\nenhanced resilience against red-teaming attacks. Furthermore, our analysis\nunderscores the advantage of AI feedback, particularly in fostering preference\ndiversity to deliver more comprehensive improvements. Our dataset, training\ncode and models are available at https://vlf-silkie.github.io.\n","authors":["Lei Li","Zhihui Xie","Mukai Li","Shunian Chen","Peiyi Wang","Liang Chen","Yazheng Yang","Benyou Wang","Lingpeng Kong","Qi Liu"],"pdf_url":"https://arxiv.org/pdf/2410.09421v2.pdf","comment":"EMNLP 2024 Main Conference camera-ready version (fixed small typos).\n  This article supersedes arXiv:2312.10665"},{"id":"http://arxiv.org/abs/2403.04808v3","updated":"2024-10-18T07:05:57Z","published":"2024-03-06T10:55:30Z","title":"WaterMax: breaking the LLM watermark detectability-robustness-quality\n  trade-off","summary":"  Watermarking is a technical means to dissuade malfeasant usage of Large\nLanguage Models. This paper proposes a novel watermarking scheme, so-called\nWaterMax, that enjoys high detectability while sustaining the quality of the\ngenerated text of the original LLM. Its new design leaves the LLM untouched (no\nmodification of the weights, logits, temperature, or sampling technique).\nWaterMax balances robustness and complexity contrary to the watermarking\ntechniques of the literature inherently provoking a trade-off between quality\nand robustness. Its performance is both theoretically proven and experimentally\nvalidated. It outperforms all the SotA techniques under the most complete\nbenchmark suite. Code available at https://github.com/eva-giboulot/WaterMax.\n","authors":["Eva Giboulot","Teddy Furon"],"pdf_url":"https://arxiv.org/pdf/2403.04808v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.14024v4","updated":"2024-10-18T06:59:24Z","published":"2024-06-20T06:42:27Z","title":"LLM Critics Help Catch Bugs in Mathematics: Towards a Better\n  Mathematical Verifier with Natural Language Feedback","summary":"  In recent progress, mathematical verifiers have achieved success in\nmathematical reasoning tasks by validating the correctness of solutions\ngenerated by policy models. However, existing verifiers are trained with binary\nclassification labels, which are not informative enough for the model to\naccurately assess the solutions. To mitigate the aforementioned insufficiency\nof binary labels, we introduce step-wise natural language feedback as rationale\nlabels, that is, the correctness of each step and the detailed explanations. In\nthis paper, we propose Math-Minos, a natural language feedback-enhanced\nverifier by constructing automatically generated training data and a two-stage\ntraining paradigm for effective training and efficient inference. Our\nexperiments reveal that a small set of natural language feedback can\nsignificantly boost the performance of the verifier in both verification and\nreinforcement learning. We have released the code and data for further\nexploration.\n","authors":["Bofei Gao","Zefan Cai","Runxin Xu","Peiyi Wang","Ce Zheng","Runji Lin","Keming Lu","Dayiheng Liu","Chang Zhou","Wen Xiao","Junjie Hu","Tianyu Liu","Baobao Chang"],"pdf_url":"https://arxiv.org/pdf/2406.14024v4.pdf","comment":"15 pages"},{"id":"http://arxiv.org/abs/2410.14211v1","updated":"2024-10-18T06:57:19Z","published":"2024-10-18T06:57:19Z","title":"Paths-over-Graph: Knowledge Graph Enpowered Large Language Model\n  Reasoning","summary":"  Large Language Models (LLMs) have achieved impressive results in various\ntasks but struggle with hallucination problems and lack of relevant knowledge,\nespecially in deep complex reasoning and knowledge-intensive tasks. Knowledge\nGraphs (KGs), which capture vast amounts of facts in a structured format, offer\na reliable source of knowledge for reasoning. However, existing KG-based LLM\nreasoning methods face challenges like handling multi-hop reasoning,\nmulti-entity questions, and effectively utilizing graph structures. To address\nthese issues, we propose Paths-over-Graph (PoG), a novel method that enhances\nLLM reasoning by integrating knowledge reasoning paths from KGs, improving the\ninterpretability and faithfulness of LLM outputs. PoG tackles multi-hop and\nmulti-entity questions through a three-phase dynamic multi-hop path\nexploration, which combines the inherent knowledge of LLMs with factual\nknowledge from KGs. In order to improve the efficiency, PoG prunes irrelevant\ninformation from the graph exploration first and introduces efficient\nthree-step pruning techniques that incorporate graph structures, LLM prompting,\nand a pre-trained language model (e.g., SBERT) to effectively narrow down the\nexplored candidate paths. This ensures all reasoning paths contain highly\nrelevant information captured from KGs, making the reasoning faithful and\ninterpretable in problem-solving. PoG innovatively utilizes graph structure to\nprune the irrelevant noise and represents the first method to implement\nmulti-entity deep path detection on KGs for LLM reasoning tasks. Comprehensive\nexperiments on five benchmark KGQA datasets demonstrate PoG outperforms the\nstate-of-the-art method ToG across GPT-3.5-Turbo and GPT-4, achieving an\naverage accuracy improvement of 18.9%. Notably, PoG with GPT-3.5-Turbo\nsurpasses ToG with GPT-4 by up to 23.9%.\n","authors":["Xingyu Tan","Xiaoyang Wang","Qing Liu","Xiwei Xu","Xin Yuan","Wenjie Zhang"],"pdf_url":"https://arxiv.org/pdf/2410.14211v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2405.19740v2","updated":"2024-10-18T06:57:08Z","published":"2024-05-30T06:38:32Z","title":"PertEval: Unveiling Real Knowledge Capacity of LLMs with\n  Knowledge-Invariant Perturbations","summary":"  Expert-designed close-ended benchmarks are indispensable in assessing the\nknowledge capacity of large language models (LLMs). Despite their widespread\nuse, concerns have mounted regarding their reliability due to limited test\nscenarios and an unavoidable risk of data contamination. To rectify this, we\npresent PertEval, a toolkit devised for in-depth probing of LLMs' knowledge\ncapacity through \\textbf{knowledge-invariant perturbations}. These\nperturbations employ human-like restatement techniques to generate on-the-fly\ntest samples from static benchmarks, meticulously retaining knowledge-critical\ncontent while altering irrelevant details. Our toolkit further includes a suite\nof \\textbf{response consistency analyses} that compare performance on raw vs.\nperturbed test sets to precisely assess LLMs' genuine knowledge capacity. Six\nrepresentative LLMs are re-evaluated using PertEval. Results reveal\nsignificantly inflated performance of the LLMs on raw benchmarks, including an\nabsolute 25.8% overestimation for GPT-4. Additionally, through a nuanced\nresponse pattern analysis, we discover that PertEval retains LLMs' uncertainty\nto specious knowledge, and reveals their potential rote memorization to correct\noptions which leads to overestimated performance. We also find that the\ndetailed response consistency analyses by PertEval could illuminate various\nweaknesses in existing LLMs' knowledge mastery and guide the development of\nrefinement. Our findings provide insights for advancing more robust and\ngenuinely knowledgeable LLMs. Our code is available at\n\\url{https://github.com/aigc-apps/PertEval}.\n","authors":["Jiatong Li","Renjun Hu","Kunzhe Huang","Yan Zhuang","Qi Liu","Mengxiao Zhu","Xing Shi","Wei Lin"],"pdf_url":"https://arxiv.org/pdf/2405.19740v2.pdf","comment":"Accepted by NeurIPS '24 D&B Spotlight; 28 pages, 15 figures, 14\n  tables"},{"id":"http://arxiv.org/abs/2403.01976v5","updated":"2024-10-18T06:52:17Z","published":"2024-03-04T12:19:28Z","title":"SciAssess: Benchmarking LLM Proficiency in Scientific Literature\n  Analysis","summary":"  Recent breakthroughs in Large Language Models (LLMs) have revolutionized\nscientific literature analysis. However, existing benchmarks fail to adequately\nevaluate the proficiency of LLMs in this domain, particularly in scenarios\nrequiring higher-level abilities beyond mere memorization and the handling of\nmultimodal data. In response to this gap, we introduce SciAssess, a benchmark\nspecifically designed for the comprehensive evaluation of LLMs in scientific\nliterature analysis. It aims to thoroughly assess the efficacy of LLMs by\nevaluating their capabilities in Memorization (L1), Comprehension (L2), and\nAnalysis \\& Reasoning (L3). It encompasses a variety of tasks drawn from\ndiverse scientific fields, including biology, chemistry, material, and\nmedicine. To ensure the reliability of SciAssess, rigorous quality control\nmeasures have been implemented, ensuring accuracy, anonymization, and\ncompliance with copyright standards. SciAssess evaluates 11 LLMs, highlighting\ntheir strengths and areas for improvement. We hope this evaluation supports the\nongoing development of LLM applications in scientific literature analysis.\nSciAssess and its resources are available at\n\\url{https://github.com/sci-assess/SciAssess}.\n","authors":["Hengxing Cai","Xiaochen Cai","Junhan Chang","Sihang Li","Lin Yao","Changxin Wang","Zhifeng Gao","Hongshuai Wang","Yongge Li","Mujie Lin","Shuwen Yang","Jiankun Wang","Mingjun Xu","Jin Huang","Xi Fang","Jiaxi Zhuang","Yuqi Yin","Yaqi Li","Changhong Chen","Zheng Cheng","Zifeng Zhao","Linfeng Zhang","Guolin Ke"],"pdf_url":"https://arxiv.org/pdf/2403.01976v5.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.14208v1","updated":"2024-10-18T06:50:15Z","published":"2024-10-18T06:50:15Z","title":"Montessori-Instruct: Generate Influential Training Data Tailored for\n  Student Learning","summary":"  Synthetic data has been widely used to train large language models, but their\ngenerative nature inevitably introduces noisy, non-informative, and misleading\nlearning signals. In this paper, we propose Montessori-Instruct, a novel data\nsynthesis framework that tailors the data synthesis ability of the teacher\nlanguage model toward the student language model's learning process.\nSpecifically, we utilize local data influence of synthetic training data points\non students to characterize students' learning preferences. Then, we train the\nteacher model with Direct Preference Optimization (DPO) to generate synthetic\ndata tailored toward student learning preferences. Experiments with\nLlama3-8B-Instruct (teacher) and Llama3-8B (student) on Alpaca Eval and\nMT-Bench demonstrate that Montessori-Instruct significantly outperforms\nstandard synthesis methods by 18.35\\% and 46.24\\% relatively. Our method also\nbeats data synthesized by a stronger teacher model, GPT-4o. Further analysis\nconfirms the benefits of teacher's learning to generate more influential\ntraining data in the student's improved learning, the advantages of local data\ninfluence in accurately measuring student preferences, and the robustness of\nMontessori-Instruct across different student models. Our code and data are\nopen-sourced at https://github.com/cxcscmu/Montessori-Instruct.\n","authors":["Xiaochuan Li","Zichun Yu","Chenyan Xiong"],"pdf_url":"https://arxiv.org/pdf/2410.14208v1.pdf","comment":"Codes and data are open-sourced at\n  https://github.com/cxcscmu/Montessori-Instruct"},{"id":"http://arxiv.org/abs/2410.14204v1","updated":"2024-10-18T06:38:22Z","published":"2024-10-18T06:38:22Z","title":"MediTOD: An English Dialogue Dataset for Medical History Taking with\n  Comprehensive Annotations","summary":"  Medical task-oriented dialogue systems can assist doctors by collecting\npatient medical history, aiding in diagnosis, or guiding treatment selection,\nthereby reducing doctor burnout and expanding access to medical services.\nHowever, doctor-patient dialogue datasets are not readily available, primarily\ndue to privacy regulations. Moreover, existing datasets lack comprehensive\nannotations involving medical slots and their different attributes, such as\nsymptoms and their onset, progression, and severity. These comprehensive\nannotations are crucial for accurate diagnosis. Finally, most existing datasets\nare non-English, limiting their utility for the larger research community.\n  In response, we introduce MediTOD, a new dataset of doctor-patient dialogues\nin English for the medical history-taking task. Collaborating with doctors, we\ndevise a questionnaire-based labeling scheme tailored to the medical domain.\nThen, medical professionals create the dataset with high-quality comprehensive\nannotations, capturing medical slots and their attributes. We establish\nbenchmarks in supervised and few-shot settings on MediTOD for natural language\nunderstanding, policy learning, and natural language generation subtasks,\nevaluating models from both TOD and biomedical domains. We make MediTOD\npublicly available for future research.\n","authors":["Vishal Vivek Saley","Goonjan Saha","Rocktim Jyoti Das","Dinesh Raghu"," Mausam"],"pdf_url":"https://arxiv.org/pdf/2410.14204v1.pdf","comment":"EMNLP2024 Camera Ready Version"},{"id":"http://arxiv.org/abs/2410.14202v1","updated":"2024-10-18T06:35:17Z","published":"2024-10-18T06:35:17Z","title":"Rationale Behind Essay Scores: Enhancing S-LLM's Multi-Trait Essay\n  Scoring with Rationale Generated by LLMs","summary":"  Existing automated essay scoring (AES) has solely relied on essay text\nwithout using explanatory rationales for the scores, thereby forgoing an\nopportunity to capture the specific aspects evaluated by rubric indicators in a\nfine-grained manner. This paper introduces Rationale-based Multiple Trait\nScoring (RMTS), a novel approach for multi-trait essay scoring that integrates\nprompt-engineering-based large language models (LLMs) with a fine-tuning-based\nessay scoring model using a smaller large language model (S-LLM). RMTS uses an\nLLM-based trait-wise rationale generation system where a separate LLM agent\ngenerates trait-specific rationales based on rubric guidelines, which the\nscoring model uses to accurately predict multi-trait scores. Extensive\nexperiments on benchmark datasets, including ASAP, ASAP++, and Feedback Prize,\nshow that RMTS significantly outperforms state-of-the-art models and vanilla\nS-LLMs in trait-specific scoring. By assisting quantitative assessment with\nfine-grained qualitative rationales, RMTS enhances the trait-wise reliability,\nproviding partial explanations about essays.\n","authors":["SeongYeub Chu","JongWoo Kim","Bryan Wong","MunYong Yi"],"pdf_url":"https://arxiv.org/pdf/2410.14202v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.14200v1","updated":"2024-10-18T06:31:40Z","published":"2024-10-18T06:31:40Z","title":"E3D-GPT: Enhanced 3D Visual Foundation for Medical Vision-Language Model","summary":"  The development of 3D medical vision-language models holds significant\npotential for disease diagnosis and patient treatment. However, compared to 2D\nmedical images, 3D medical images, such as CT scans, face challenges related to\nlimited training data and high dimension, which severely restrict the progress\nof 3D medical vision-language models. To address these issues, we collect a\nlarge amount of unlabeled 3D CT data and utilize self-supervised learning to\nconstruct a 3D visual foundation model for extracting 3D visual features. Then,\nwe apply 3D spatial convolutions to aggregate and project high-level image\nfeatures, reducing computational complexity while preserving spatial\ninformation. We also construct two instruction-tuning datasets based on BIMCV-R\nand CT-RATE to fine-tune the 3D vision-language model. Our model demonstrates\nsuperior performance compared to existing methods in report generation, visual\nquestion answering, and disease diagnosis. Code and data will be made publicly\navailable soon.\n","authors":["Haoran Lai","Zihang Jiang","Qingsong Yao","Rongsheng Wang","Zhiyang He","Xiaodong Tao","Wei Wei","Weifu Lv","S. Kevin Zhou"],"pdf_url":"https://arxiv.org/pdf/2410.14200v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.14198v1","updated":"2024-10-18T06:25:27Z","published":"2024-10-18T06:25:27Z","title":"Supervised Chain of Thought","summary":"  Large Language Models (LLMs) have revolutionized natural language processing\nand hold immense potential for advancing Artificial Intelligence. However, the\ncore architecture of most mainstream LLMs -- the Transformer -- has inherent\nlimitations in computational depth, rendering them theoretically incapable of\nsolving many reasoning tasks that demand increasingly deep computations. Chain\nof Thought (CoT) prompting has emerged as a technique to address these\narchitectural limitations, as evidenced by several theoretical studies. It\noffers a promising approach to solving complex reasoning tasks that were\npreviously beyond the capabilities of these models. Despite its successes, CoT\nand its variants (such as Tree of Thought, Graph of Thought, etc.) rely on a\n\"one-prompt-for-all\" approach, using a single prompt structure (e.g., \"think\nstep by step\") for a wide range of tasks -- from counting and sorting to\nsolving mathematical and algorithmic problems. This approach poses significant\nchallenges for models to generate the correct reasoning steps, as the model\nmust navigate through a vast prompt template space to find the appropriate\ntemplate for each task. In this work, we build upon previous theoretical\nanalyses of CoT to demonstrate how the one-prompt-for-all approach can\nnegatively affect the computability of LLMs. We partition the solution search\nspace into two: the prompt space and the answer space. Our findings show that\ntask-specific supervision is essential for navigating the prompt space\naccurately and achieving optimal performance. Through experiments with\nstate-of-the-art LLMs, we reveal a gap in reasoning performance when\nsupervision is applied versus when it is not.\n","authors":["Xiang Zhang","Dujian Ding"],"pdf_url":"https://arxiv.org/pdf/2410.14198v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2404.06833v2","updated":"2024-10-18T06:19:22Z","published":"2024-04-10T08:49:27Z","title":"Does Mapo Tofu Contain Coffee? Probing LLMs for Food-related Cultural\n  Knowledge","summary":"  Recent studies have highlighted the presence of cultural biases in Large\nLanguage Models (LLMs), yet often lack a robust methodology to dissect these\nphenomena comprehensively. Our work aims to bridge this gap by delving into the\nFood domain, a universally relevant yet culturally diverse aspect of human\nlife. We introduce FmLAMA, a multilingual dataset centered on food-related\ncultural facts and variations in food practices. We analyze LLMs across various\narchitectures and configurations, evaluating their performance in both\nmonolingual and multilingual settings. By leveraging templates in six different\nlanguages, we investigate how LLMs interact with language-specific and cultural\nknowledge. Our findings reveal that (1) LLMs demonstrate a pronounced bias\ntowards food knowledge prevalent in the United States; (2) Incorporating\nrelevant cultural context significantly improves LLMs' ability to access\ncultural knowledge; (3) The efficacy of LLMs in capturing cultural nuances is\nhighly dependent on the interplay between the probing language, the specific\nmodel architecture, and the cultural context in question. This research\nunderscores the complexity of integrating cultural understanding into LLMs and\nemphasizes the importance of culturally diverse datasets to mitigate biases and\nenhance model performance across different cultural domains.\n","authors":["Li Zhou","Taelin Karidi","Wanlong Liu","Nicolas Garneau","Yong Cao","Wenyu Chen","Haizhou Li","Daniel Hershcovich"],"pdf_url":"https://arxiv.org/pdf/2404.06833v2.pdf","comment":"cultural bias analysis, cultural knowledge probing, large language\n  models, cultural NLP"},{"id":"http://arxiv.org/abs/2405.15585v3","updated":"2024-10-18T06:14:50Z","published":"2024-05-24T14:13:54Z","title":"Synergizing In-context Learning with Hints for End-to-end Task-oriented\n  Dialog Systems","summary":"  End-to-end Task-Oriented Dialog (TOD) systems typically require extensive\ntraining datasets to perform well. In contrast, large language model (LLM)\nbased TOD systems can excel even with limited data due to their ability to\nlearn tasks through in-context exemplars. However, these models lack alignment\nwith the style of responses in training data and often generate comprehensive\nresponses, making it difficult for users to grasp the information quickly. In\nresponse, we propose SyncTOD that synergizes LLMs with task-specific hints to\nimprove alignment in low-data settings. SyncTOD employs small auxiliary models\nto provide hints and select exemplars for in-context prompts. With ChatGPT,\nSyncTOD achieves superior performance compared to LLM-based baselines and SoTA\nmodels in low-data settings, while retaining competitive performance in\nfull-data settings.\n","authors":["Vishal Vivek Saley","Rocktim Jyoti Das","Dinesh Raghu"," Mausam"],"pdf_url":"https://arxiv.org/pdf/2405.15585v3.pdf","comment":"EMNLP2024 Camera-Ready Version"},{"id":"http://arxiv.org/abs/2410.14194v1","updated":"2024-10-18T06:09:41Z","published":"2024-10-18T06:09:41Z","title":"Speciesism in Natural Language Processing Research","summary":"  Natural Language Processing (NLP) research on AI Safety and social bias in AI\nhas focused on safety for humans and social bias against human minorities.\nHowever, some AI ethicists have argued that the moral significance of nonhuman\nanimals has been ignored in AI research. Therefore, the purpose of this study\nis to investigate whether there is speciesism, i.e., discrimination against\nnonhuman animals, in NLP research. First, we explain why nonhuman animals are\nrelevant in NLP research. Next, we survey the findings of existing research on\nspeciesism in NLP researchers, data, and models and further investigate this\nproblem in this study. The findings of this study suggest that speciesism\nexists within researchers, data, and models, respectively. Specifically, our\nsurvey and experiments show that (a) among NLP researchers, even those who\nstudy social bias in AI, do not recognize speciesism or speciesist bias; (b)\namong NLP data, speciesist bias is inherent in the data annotated in the\ndatasets used to evaluate NLP models; (c) OpenAI GPTs, recent NLP models,\nexhibit speciesist bias by default. Finally, we discuss how we can reduce\nspeciesism in NLP research.\n","authors":["Masashi Takeshita","Rafal Rzepka"],"pdf_url":"https://arxiv.org/pdf/2410.14194v1.pdf","comment":"This article is a preprint and has not been peer-reviewed. The\n  postprint has been accepted for publication in AI and Ethics. Please cite the\n  final version of the article once it is published"},{"id":"http://arxiv.org/abs/2410.04422v4","updated":"2024-10-18T06:09:31Z","published":"2024-10-06T09:29:19Z","title":"Hyper-multi-step: The Truth Behind Difficult Long-context Tasks","summary":"  Long-context language models (LCLM), characterized by their extensive context\nwindow, is becoming increasingly popular. Meanwhile, many long-context\nbenchmarks present challenging tasks that even the most advanced LCLMs struggle\nto complete. However, the underlying sources of various challenging\nlong-context tasks have seldom been studied. To bridge this gap, we conduct\nexperiments to indicate their difficulty stems primarily from two basic issues:\n\"multi-matching retrieval,\" which requires the simultaneous retrieval of\nmultiple items, and \"logic-based retrieval,\" which necessitates logical\njudgment within retrieval criteria. These two problems, while seemingly\nstraightforward, actually exceed the capabilities of LCLMs because they are\nproven to be hyper-multi-step (demanding numerous steps to solve) in nature.\nThis finding could explain why LLMs struggle with more advanced long-context\ntasks, providing a more accurate perspective for rethinking solutions for them.\n","authors":["Yijiong Yu","Ma Xiufa","Fang Jianwei","Zhi Xu","Su Guangyao","Wang Jiancheng","Yongfeng Huang","Zhixiao Qi","Wei Wang","Weifeng Liu","Ran Chen","Ji Pei"],"pdf_url":"https://arxiv.org/pdf/2410.04422v4.pdf","comment":"Our code is publicly available at\n  https://github.com/yuyijiong/hard_retrieval_for_llm and the datasets is at\n  https://huggingface.co/datasets/yuyijiong/difficult_retrieval"},{"id":"http://arxiv.org/abs/2410.14184v1","updated":"2024-10-18T05:31:13Z","published":"2024-10-18T05:31:13Z","title":"MetaAlign: Align Large Language Models with Diverse Preferences during\n  Inference Time","summary":"  Large Language Models (LLMs) acquire extensive knowledge and remarkable\nabilities from extensive text corpora, making them powerful tools for various\napplications. To make LLMs more usable, aligning them with human preferences is\nessential. Existing alignment techniques, such as Reinforcement Learning from\nHuman Feedback (RLHF) and Direct Preference Optimization (DPO), typically embed\npredefined preferences directly within the model's parameters. These methods,\nhowever, often result in a static alignment that can not account for the\ndiversity of human preferences in practical applications. In response to this\nchallenge, we propose an effective method, \\textbf{MetaAlign}, which aims to\nhelp LLMs dynamically align with various explicit or implicit preferences\nspecified at inference time. Experimental results show that LLMs optimized on\nour meticulously constructed MetaAlign Dataset can effectively align with any\npreferences specified at the inference stage, validating the feasibility of\nMetaAlign. We hope that our work can provide some insights into the alignment\nof language models.\n","authors":["Mozhi Zhang","Pengyu Wang","Chenkun Tan","Mianqiu Huang","Dong Zhang","Yaqian Zhou","Xipeng Qiu"],"pdf_url":"https://arxiv.org/pdf/2410.14184v1.pdf","comment":"19 pages, 6 figures"},{"id":"http://arxiv.org/abs/2410.00131v2","updated":"2024-10-18T05:22:02Z","published":"2024-09-30T18:12:18Z","title":"Fisher Information-based Efficient Curriculum Federated Learning with\n  Large Language Models","summary":"  As a promising paradigm to collaboratively train models with decentralized\ndata, Federated Learning (FL) can be exploited to fine-tune Large Language\nModels (LLMs). While LLMs correspond to huge size, the scale of the training\ndata significantly increases, which leads to tremendous amounts of computation\nand communication costs. The training data is generally non-Independent and\nIdentically Distributed (non-IID), which requires adaptive data processing\nwithin each device. Although Low Rank Adaptation (LoRA) can significantly\nreduce the scale of parameters to update in the fine-tuning process, it still\ntakes unaffordable time to transfer the low-rank parameters of all the layers\nin LLMs. In this paper, we propose a Fisher Information-based Efficient\nCurriculum Federated Learning framework (FibecFed) with two novel methods,\ni.e., adaptive federated curriculum learning and efficient sparse parameter\nupdate. First, we propose a fisher information-based method to adaptively\nsample data within each device to improve the effectiveness of the FL\nfine-tuning process. Second, we dynamically select the proper layers for global\naggregation and sparse parameters for local update with LoRA so as to improve\nthe efficiency of the FL fine-tuning process. Extensive experimental results\nbased on 10 datasets demonstrate that FibecFed yields excellent performance (up\nto 45.35% in terms of accuracy) and superb fine-tuning speed (up to 98.61%\nfaster) compared with 17 baseline approaches).\n","authors":["Ji Liu","Jiaxiang Ren","Ruoming Jin","Zijie Zhang","Yang Zhou","Patrick Valduriez","Dejing Dou"],"pdf_url":"https://arxiv.org/pdf/2410.00131v2.pdf","comment":"27 pages, 8 figures, 14 tables, to appear in EMNLP 2024"},{"id":"http://arxiv.org/abs/2410.14182v1","updated":"2024-10-18T05:21:05Z","published":"2024-10-18T05:21:05Z","title":"LabSafety Bench: Benchmarking LLMs on Safety Issues in Scientific Labs","summary":"  Laboratory accidents pose significant risks to human life and property,\nunderscoring the importance of robust safety protocols. Despite advancements in\nsafety training, laboratory personnel may still unknowingly engage in unsafe\npractices. With the increasing reliance on large language models (LLMs) for\nguidance in various fields, including laboratory settings, there is a growing\nconcern about their reliability in critical safety-related decision-making.\nUnlike trained human researchers, LLMs lack formal lab safety education,\nraising questions about their ability to provide safe and accurate guidance.\nExisting research on LLM trustworthiness primarily focuses on issues such as\nethical compliance, truthfulness, and fairness but fails to fully cover\nsafety-critical real-world applications, like lab safety. To address this gap,\nwe propose the Laboratory Safety Benchmark (LabSafety Bench), a comprehensive\nevaluation framework based on a new taxonomy aligned with Occupational Safety\nand Health Administration (OSHA) protocols. This benchmark includes 765\nmultiple-choice questions verified by human experts, assessing LLMs and vision\nlanguage models (VLMs) performance in lab safety contexts. Our evaluations\ndemonstrate that while GPT-4o outperforms human participants, it is still prone\nto critical errors, highlighting the risks of relying on LLMs in\nsafety-critical environments. Our findings emphasize the need for specialized\nbenchmarks to accurately assess the trustworthiness of LLMs in real-world\nsafety applications.\n","authors":["Yujun Zhou","Jingdong Yang","Kehan Guo","Pin-Yu Chen","Tian Gao","Werner Geyer","Nuno Moniz","Nitesh V Chawla","Xiangliang Zhang"],"pdf_url":"https://arxiv.org/pdf/2410.14182v1.pdf","comment":"50 pages, 19 figures"},{"id":"http://arxiv.org/abs/2410.14180v1","updated":"2024-10-18T05:16:39Z","published":"2024-10-18T05:16:39Z","title":"XForecast: Evaluating Natural Language Explanations for Time Series\n  Forecasting","summary":"  Time series forecasting aids decision-making, especially for stakeholders who\nrely on accurate predictions, making it very important to understand and\nexplain these models to ensure informed decisions. Traditional explainable AI\n(XAI) methods, which underline feature or temporal importance, often require\nexpert knowledge. In contrast, natural language explanations (NLEs) are more\naccessible to laypeople. However, evaluating forecast NLEs is difficult due to\nthe complex causal relationships in time series data. To address this, we\nintroduce two new performance metrics based on simulatability, assessing how\nwell a human surrogate can predict model forecasts using the explanations.\nExperiments show these metrics differentiate good from poor explanations and\nalign with human judgments. Utilizing these metrics, we further evaluate the\nability of state-of-the-art large language models (LLMs) to generate\nexplanations for time series data, finding that numerical reasoning, rather\nthan model size, is the main factor influencing explanation quality.\n","authors":["Taha Aksu","Chenghao Liu","Amrita Saha","Sarah Tan","Caiming Xiong","Doyen Sahoo"],"pdf_url":"https://arxiv.org/pdf/2410.14180v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.14179v1","updated":"2024-10-18T05:15:50Z","published":"2024-10-18T05:15:50Z","title":"MultiChartQA: Benchmarking Vision-Language Models on Multi-Chart\n  Problems","summary":"  Multimodal Large Language Models (MLLMs) have demonstrated impressive\nabilities across various tasks, including visual question answering and chart\ncomprehension, yet existing benchmarks for chart-related tasks fall short in\ncapturing the complexity of real-world multi-chart scenarios. Current\nbenchmarks primarily focus on single-chart tasks, neglecting the multi-hop\nreasoning required to extract and integrate information from multiple charts,\nwhich is essential in practical applications. To fill this gap, we introduce\nMultiChartQA, a benchmark that evaluates MLLMs' capabilities in four key areas:\ndirect question answering, parallel question answering, comparative reasoning,\nand sequential reasoning. Our evaluation of a wide range of MLLMs reveals\nsignificant performance gaps compared to humans. These results highlight the\nchallenges in multi-chart comprehension and the potential of MultiChartQA to\ndrive advancements in this field. Our code and data are available at\nhttps://github.com/Zivenzhu/Multi-chart-QA\n","authors":["Zifeng Zhu","Mengzhao Jia","Zhihan Zhang","Lang Li","Meng Jiang"],"pdf_url":"https://arxiv.org/pdf/2410.14179v1.pdf","comment":"18 pages, 9 figures"},{"id":"http://arxiv.org/abs/2410.10270v2","updated":"2024-10-18T05:07:38Z","published":"2024-10-14T08:21:25Z","title":"QUIS: Question-guided Insights Generation for Automated Exploratory Data\n  Analysis","summary":"  Discovering meaningful insights from a large dataset, known as Exploratory\nData Analysis (EDA), is a challenging task that requires thorough exploration\nand analysis of the data. Automated Data Exploration (ADE) systems use\ngoal-oriented methods with Large Language Models and Reinforcement Learning\ntowards full automation. However, these methods require human involvement to\nanticipate goals that may limit insight extraction, while fully automated\nsystems demand significant computational resources and retraining for new\ndatasets. We introduce QUIS, a fully automated EDA system that operates in two\nstages: insight generation (ISGen) driven by question generation (QUGen). The\nQUGen module generates questions in iterations, refining them from previous\niterations to enhance coverage without human intervention or manually curated\nexamples. The ISGen module analyzes data to produce multiple relevant insights\nin response to each question, requiring no prior training and enabling QUIS to\nadapt to new datasets.\n","authors":["Abhijit Manatkar","Ashlesha Akella","Parthivi Gupta","Krishnasuri Narayanam"],"pdf_url":"https://arxiv.org/pdf/2410.10270v2.pdf","comment":"Accepted for ENLP 2024 Industry Track"},{"id":"http://arxiv.org/abs/2408.15545v3","updated":"2024-10-18T05:04:53Z","published":"2024-08-28T05:41:52Z","title":"SciLitLLM: How to Adapt LLMs for Scientific Literature Understanding","summary":"  Scientific literature understanding is crucial for extracting targeted\ninformation and garnering insights, thereby significantly advancing scientific\ndiscovery. Despite the remarkable success of Large Language Models (LLMs), they\nface challenges in scientific literature understanding, primarily due to (1) a\nlack of scientific knowledge and (2) unfamiliarity with specialized scientific\ntasks.\n  To develop an LLM specialized in scientific literature understanding, we\npropose a hybrid strategy that integrates continual pre-training (CPT) and\nsupervised fine-tuning (SFT), to simultaneously infuse scientific domain\nknowledge and enhance instruction-following capabilities for domain-specific\ntasks.cIn this process, we identify two key challenges: (1) constructing\nhigh-quality CPT corpora, and (2) generating diverse SFT instructions. We\naddress these challenges through a meticulous pipeline, including PDF text\nextraction, parsing content error correction, quality filtering, and synthetic\ninstruction creation. Applying this strategy, we present a suite of LLMs:\nSciLitLLM, specialized in scientific literature understanding. These models\ndemonstrate promising performance on scientific literature understanding\nbenchmarks.\n  Our contributions are threefold: (1) We present an effective framework that\nintegrates CPT and SFT to adapt LLMs to scientific literature understanding,\nwhich can also be easily adapted to other domains. (2) We propose an LLM-based\nsynthesis method to generate diverse and high-quality scientific instructions,\nresulting in a new instruction set -- SciLitIns -- for supervised fine-tuning\nin less-represented scientific domains. (3) SciLitLLM achieves promising\nperformance improvements on scientific literature understanding benchmarks.\n","authors":["Sihang Li","Jin Huang","Jiaxi Zhuang","Yaorui Shi","Xiaochen Cai","Mingjun Xu","Xiang Wang","Linfeng Zhang","Guolin Ke","Hengxing Cai"],"pdf_url":"https://arxiv.org/pdf/2408.15545v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.05541v2","updated":"2024-10-18T04:52:38Z","published":"2024-08-10T12:44:49Z","title":"P3: A Policy-Driven, Pace-Adaptive, and Diversity-Promoted Framework for\n  data pruning in LLM Training","summary":"  In the rapidly advancing field of Large Language Models (LLMs), effectively\nleveraging existing datasets during fine-tuning to maximize the model's\npotential is of paramount importance. This paper introduces P3, an adaptive\nframework aimed at optimizing the task-specific fine-tuning process through\niterative data pruning. P3 consists of three key components: (1) Policy-driven\nDifficulty Measurement, which dynamically assesses data difficulty based on the\nmodel's real-time performance, replacing static metrics with adaptable\nevaluations; (2) Pace-Adaptive Selection, leveraging self-paced learning to\nprogressively introduce more challenging data, thereby enhancing model\ncapability; (3) Diversity Promotion, incorporating Determinantal Point Process\n(DPP) to ensure data diversity across epochs, enriching the learning process.\nWe validate P3 on the reasoning scenarios, APPS and MATH, demonstrating\nsignificant improvements over traditional data pruning methods. By advancing\ndynamic data selection and utilization strategies, P3 contributes both a\ntheoretical framework and concrete approach to fully exploit existing data for\nLLMs' performance improvement, offering utility across diverse tasks.\n","authors":["Yingxuan Yang","Huayi Wang","Muning Wen","Xiaoyun Mo","Qiuying Peng","Jun Wang","Weinan Zhang"],"pdf_url":"https://arxiv.org/pdf/2408.05541v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.14862v4","updated":"2024-10-18T04:39:35Z","published":"2024-06-21T04:39:03Z","title":"LatentExplainer: Explaining Latent Representations in Deep Generative\n  Models with Multi-modal Foundation Models","summary":"  Deep generative models like VAEs and diffusion models have advanced various\ngeneration tasks by leveraging latent variables to learn data distributions and\ngenerate high-quality samples. Despite the field of explainable AI making\nstrides in interpreting machine learning models, understanding latent variables\nin generative models remains challenging. This paper introduces\n\\textit{LatentExplainer}, a framework for automatically generating semantically\nmeaningful explanations of latent variables in deep generative models.\n\\textit{LatentExplainer} tackles three main challenges: inferring the meaning\nof latent variables, aligning explanations with inductive biases, and handling\nvarying degrees of explainability. Our approach perturbs latent variables,\ninterpreting changes in generated data, and uses multi-modal large language\nmodels (MLLMs) to produce human-understandable explanations. We evaluate our\nproposed method on several real-world and synthetic datasets, and the results\ndemonstrate superior performance in generating high-quality explanations for\nlatent variables. The results highlight the effectiveness of incorporating\ninductive biases and uncertainty quantification, significantly enhancing model\ninterpretability.\n","authors":["Mengdan Zhu","Raasikh Kanjiani","Jiahui Lu","Andrew Choi","Qirui Ye","Liang Zhao"],"pdf_url":"https://arxiv.org/pdf/2406.14862v4.pdf","comment":null},{"id":"http://arxiv.org/abs/2409.15820v2","updated":"2024-10-18T04:38:47Z","published":"2024-09-24T07:34:50Z","title":"Supervised Fine-Tuning Achieve Rapid Task Adaption Via Alternating\n  Attention Head Activation Patterns","summary":"  LLMs' performance on complex tasks is still unsatisfactory. A key issue is\nthat presently LLMs learn in a data-driven schema, while the instructions about\nthese complex tasks are both scarce and hard to collect or construct. On the\ncontrary, a prominent phenomenon is that LLMs can learn rather fast on simpler\ntasks with adequate prior knowledge captured during pretraining stage. Thus, if\nthe prerequisite and mechanism of such rapid generalization could be\nelucidated, it could enhance the efficiency and effectiveness of the LLM's\nability to learn complex tasks. Thus, in this paper, we employ a gradient-based\nmethod, to dissect the process that the SFT process adapts LLMs to downstream\ntasks via the perspective of attention patterns. We find that: (1) LLMs\nselectively activate task-specific attention heads during SFT; (2) activation\npatterns for complex tasks are combinations of basic task patterns; and (3)\nchanges in a few parameters can significantly impact activation patterns after\nSFT on a small number of samples.Based on these insights, experiments are\nconducted to actually enhance the efficiency and effectiveness of SFT.\n","authors":["Yang Zhao","Li Du","Xiao Ding","Kai Xiong","Ting Liu","Bing Qin"],"pdf_url":"https://arxiv.org/pdf/2409.15820v2.pdf","comment":"in review"},{"id":"http://arxiv.org/abs/2407.00902v2","updated":"2024-10-18T04:37:33Z","published":"2024-07-01T01:57:21Z","title":"From Introspection to Best Practices: Principled Analysis of\n  Demonstrations in Multimodal In-Context Learning","summary":"  Motivated by in-context learning (ICL) capabilities of Large Language models\n(LLMs), multimodal LLMs with additional visual modality are also exhibited with\nsimilar ICL abilities when multiple image-text pairs are provided as\ndemonstrations. However, relatively less work has been done to investigate the\nprinciples behind how and why multimodal ICL works. We conduct a systematic and\nprincipled evaluation of multimodal ICL for models of different scales on a\nbroad spectrum of new yet critical tasks. Through perturbations over different\nmodality information, we show that modalities matter differently across tasks\nin multimodal ICL. Guided by task-specific modality impact, we recommend\nmodality-driven demonstration strategies to boost ICL performance. We also find\nthat models may follow inductive biases from multimodal ICL even if they are\nrarely seen in or contradict semantic priors from pretraining data. Our\nprincipled analysis provides a comprehensive way of understanding the role of\ndemonstrations in multimodal in-context learning, and sheds light on\neffectively improving multimodal ICL on a wide range of tasks.\n","authors":["Nan Xu","Fei Wang","Sheng Zhang","Hoifung Poon","Muhao Chen"],"pdf_url":"https://arxiv.org/pdf/2407.00902v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2405.15349v2","updated":"2024-10-18T04:32:49Z","published":"2024-05-24T08:42:40Z","title":"Everything is Editable: Extend Knowledge Editing to Unstructured Data in\n  Large Language Models","summary":"  Recent knowledge editing methods have primarily focused on modifying\nstructured knowledge in large language models. However, this task setting\noverlooks the fact that a significant portion of real-world knowledge is stored\nin an unstructured format, characterized by long-form content, noise, and a\ncomplex yet comprehensive nature. Techniques like local layer key-value storage\nand term-driven optimization, as used in previous methods like MEMIT, are not\neffective for handling unstructured knowledge. To address these challenges, we\npropose a novel Unstructured Knowledge Editing method, namely UnKE, which\nextends previous assumptions in the layer dimension and token dimension.\nFirstly, in the layer dimension, we propose non-local block key-value storage\nto replace local layer key-value storage, increasing the representation ability\nof key-value pairs and incorporating attention layer knowledge. Secondly, in\nthe token dimension, we replace term-driven optimization with cause-driven\noptimization, which edits the last token directly while preserving context,\navoiding the need to locate terms and preventing the loss of context\ninformation. Results on newly proposed unstructured knowledge editing dataset\n(UnKEBench) and traditional structured datasets demonstrate that UnKE achieves\nremarkable performance, surpassing strong baselines. In addition, UnKE has\nrobust batch editing and sequential editing capabilities.\n","authors":["Jingcheng Deng","Zihao Wei","Liang Pang","Hanxing Ding","Huawei Shen","Xueqi Cheng"],"pdf_url":"https://arxiv.org/pdf/2405.15349v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.14166v1","updated":"2024-10-18T04:17:16Z","published":"2024-10-18T04:17:16Z","title":"LLM The Genius Paradox: A Linguistic and Math Expert's Struggle with\n  Simple Word-based Counting Problems","summary":"  Interestingly, LLMs yet struggle with some basic tasks that humans find\ntrivial to handle, e.g., counting the number of character r's in the word\n\"strawberry\". There are several popular conjectures (e.g., tokenization,\narchitecture and training data) regarding the reason for deficiency of LLMs in\nsimple word-based counting problems, sharing the similar belief that such\nfailure stems from model pretraining hence probably inevitable during\ndeployment. In this paper, we carefully design multiple evaluation settings to\ninvestigate validity of prevalent conjectures. Meanwhile, we measure\ntransferability of advanced mathematical and coding reasoning capabilities from\nspecialized LLMs to simple counting tasks. Although specialized LLMs suffer\nfrom counting problems as well, we find conjectures about inherent deficiency\nof LLMs invalid and further seek opportunities to elicit knowledge and\ncapabilities from LLMs that are beneficial to counting tasks. Compared with\nstrategies such as finetuning and in-context learning that are commonly adopted\nto enhance performance on new or challenging tasks, we show that engaging\nreasoning is the most robust and efficient way to help LLMs better perceive\ntasks with more accurate responses.\n  We hope our conjecture validation design could provide insights into the\nstudy of future critical failure modes of LLMs. Based on challenges in\ntransferring advanced capabilities to much simpler tasks, we call for more\nattention to model capability acquisition and evaluation. We also highlight the\nimportance of cultivating consciousness of \"reasoning before responding\" during\nmodel pretraining.\n","authors":["Nan Xu","Xuezhe Ma"],"pdf_url":"https://arxiv.org/pdf/2410.14166v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.14165v1","updated":"2024-10-18T04:13:51Z","published":"2024-10-18T04:13:51Z","title":"Automated Genre-Aware Article Scoring and Feedback Using Large Language\n  Models","summary":"  This paper focuses on the development of an advanced intelligent article\nscoring system that not only assesses the overall quality of written work but\nalso offers detailed feature-based scoring tailored to various article genres.\nBy integrating the pre-trained BERT model with the large language model\nChat-GPT, the system gains a deep understanding of both the content and\nstructure of the text, enabling it to provide a thorough evaluation along with\ntargeted suggestions for improvement. Experimental results demonstrate that\nthis system outperforms traditional scoring methods across multiple public\ndatasets, particularly in feature-based assessments, offering a more accurate\nreflection of the quality of different article types. Moreover, the system\ngenerates personalized feedback to assist users in enhancing their writing\nskills, underscoring the potential and practical value of automated scoring\ntechnologies in educational contexts.\n","authors":["Chihang Wang","Yuxin Dong","Zhenhong Zhang","Ruotong Wang","Shuo Wang","Jiajing Chen"],"pdf_url":"https://arxiv.org/pdf/2410.14165v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.13170v2","updated":"2024-10-18T04:13:05Z","published":"2024-06-19T02:53:39Z","title":"Amphista: Bi-directional Multi-head Decoding for Accelerating LLM\n  Inference","summary":"  Large Language Models (LLMs) inherently use autoregressive decoding, which\nlacks parallelism in inference and results in significantly slow inference\nspeed. While methods such as Medusa constructs parallelized heads, they lack\nadequate information interaction across different prediction positions. To\novercome this limitation, we introduce Amphista, an enhanced speculative\ndecoding framework that builds upon Medusa. Specifically, Amphista models an\nAuto-embedding Block capable of parallel inference, incorporating\nbi-directional attention to enable interaction between different drafting\nheads. Additionally, Amphista integrates Staged Adaptation Layers, which ensure\na seamless transition of semantic information from the target model's\nautoregressive inference to the drafting heads' non-autoregressive inference,\neffectively achieving paradigm shift and feature fusion. Experimental results\non Vicuna models using MT-Bench and Spec-Bench demonstrate that Amphista\nachieves substantial acceleration while maintaining generation quality. On\nMT-Bench, Amphista delivers up to 2.75$\\times$ speedup over vanilla\nautoregressive decoding and 1.40$\\times$ over Medusa on Vicuna 33B in\nwall-clock time.\n","authors":["Zeping Li","Xinlong Yang","Ziheng Gao","Ji Liu","Guanchen Li","Zhuang Liu","Dong Li","Jinzhang Peng","Lu Tian","Emad Barsoum"],"pdf_url":"https://arxiv.org/pdf/2406.13170v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.14157v1","updated":"2024-10-18T03:48:53Z","published":"2024-10-18T03:48:53Z","title":"Beyond Autoregression: Discrete Diffusion for Complex Reasoning and\n  Planning","summary":"  Autoregressive language models, despite their impressive capabilities,\nstruggle with complex reasoning and long-term planning tasks. We introduce\ndiscrete diffusion models as a novel solution to these challenges. Through the\nlens of subgoal imbalance, we demonstrate how diffusion models effectively\nlearn difficult subgoals that elude autoregressive approaches. We propose\nMulti-granularity Diffusion Modeling (MDM), which prioritizes subgoals based on\ndifficulty during learning. On complex tasks like Countdown, Sudoku, and\nBoolean Satisfiability Problems, MDM significantly outperforms autoregressive\nmodels without using search techniques. For instance, MDM achieves 91.5\\% and\n100\\% accuracy on Countdown and Sudoku, respectively, compared to 45.8\\% and\n20.7\\% for autoregressive models. Our work highlights the potential of\ndiffusion-based approaches in advancing AI capabilities for sophisticated\nlanguage understanding and problem-solving tasks.\n","authors":["Jiacheng Ye","Jiahui Gao","Shansan Gong","Lin Zheng","Xin Jiang","Zhenguo Li","Lingpeng Kong"],"pdf_url":"https://arxiv.org/pdf/2410.14157v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.14155v1","updated":"2024-10-18T03:45:42Z","published":"2024-10-18T03:45:42Z","title":"Towards Faithful Natural Language Explanations: A Study Using Activation\n  Patching in Large Language Models","summary":"  Large Language Models (LLMs) are capable of generating persuasive Natural\nLanguage Explanations (NLEs) to justify their answers. However, the\nfaithfulness of these explanations should not be readily trusted at face value.\nRecent studies have proposed various methods to measure the faithfulness of\nNLEs, typically by inserting perturbations at the explanation or feature level.\nWe argue that these approaches are neither comprehensive nor correctly designed\naccording to the established definition of faithfulness. Moreover, we highlight\nthe risks of grounding faithfulness findings on out-of-distribution samples. In\nthis work, we leverage a causal mediation technique called activation patching,\nto measure the faithfulness of an explanation towards supporting the explained\nanswer. Our proposed metric, Causal Faithfulness quantifies the consistency of\ncausal attributions between explanations and the corresponding model outputs as\nthe indicator of faithfulness. We experimented across models varying from 2B to\n27B parameters and found that models that underwent alignment tuning tend to\nproduce more faithful and plausible explanations. We find that Causal\nFaithfulness is a promising improvement over existing faithfulness tests by\ntaking into account the model's internal computations and avoiding out of\ndistribution concerns that could otherwise undermine the validity of\nfaithfulness assessments. We release the code in\n\\url{https://github.com/wj210/Causal-Faithfulness}\n","authors":["Wei Jie Yeo","Ranjan Satapthy","Erik Cambria"],"pdf_url":"https://arxiv.org/pdf/2410.14155v1.pdf","comment":"Under review"},{"id":"http://arxiv.org/abs/2410.14152v1","updated":"2024-10-18T03:43:42Z","published":"2024-10-18T03:43:42Z","title":"SRAP-Agent: Simulating and Optimizing Scarce Resource Allocation Policy\n  with LLM-based Agent","summary":"  Public scarce resource allocation plays a crucial role in economics as it\ndirectly influences the efficiency and equity in society. Traditional studies\nincluding theoretical model-based, empirical study-based and simulation-based\nmethods encounter limitations due to the idealized assumption of complete\ninformation and individual rationality, as well as constraints posed by limited\navailable data. In this work, we propose an innovative framework, SRAP-Agent\n(Simulating and Optimizing Scarce Resource Allocation Policy with LLM-based\nAgent), which integrates Large Language Models (LLMs) into economic\nsimulations, aiming to bridge the gap between theoretical models and real-world\ndynamics. Using public housing allocation scenarios as a case study, we conduct\nextensive policy simulation experiments to verify the feasibility and\neffectiveness of the SRAP-Agent and employ the Policy Optimization Algorithm\nwith certain optimization objectives. The source code can be found in\nhttps://github.com/jijiarui-cather/SRAPAgent_Framework\n","authors":["Jiarui Ji","Yang Li","Hongtao Liu","Zhicheng Du","Zhewei Wei","Weiran Shen","Qi Qi","Yankai Lin"],"pdf_url":"https://arxiv.org/pdf/2410.14152v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.14150v1","updated":"2024-10-18T03:40:45Z","published":"2024-10-18T03:40:45Z","title":"Utilizing Large Language Models for Event Deconstruction to Enhance\n  Multimodal Aspect-Based Sentiment Analysis","summary":"  With the rapid development of the internet, the richness of User-Generated\nContentcontinues to increase, making Multimodal Aspect-Based Sentiment Analysis\n(MABSA) a research hotspot. Existing studies have achieved certain results in\nMABSA, but they have not effectively addressed the analytical challenges in\nscenarios where multiple entities and sentiments coexist. This paper\ninnovatively introduces Large Language Models (LLMs) for event decomposition\nand proposes a reinforcement learning framework for Multimodal Aspect-based\nSentiment Analysis (MABSA-RL) framework. This framework decomposes the original\ntext into a set of events using LLMs, reducing the complexity of analysis,\nintroducing reinforcement learning to optimize model parameters. Experimental\nresults show that MABSA-RL outperforms existing advanced methods on two\nbenchmark datasets. This paper provides a new research perspective and method\nfor multimodal aspect-level sentiment analysis.\n","authors":["Xiaoyong Huang","Heli Sun","Qunshu Gao","Wenjie Huang","Ruichen Cao"],"pdf_url":"https://arxiv.org/pdf/2410.14150v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.12151v2","updated":"2024-10-18T03:36:03Z","published":"2024-08-22T06:40:32Z","title":"A Tighter Complexity Analysis of SparseGPT","summary":"  In this work, we improved the analysis of the running time of SparseGPT\n[Frantar, Alistarh ICML 2023] from $O(d^{3})$ to $O(d^{\\omega} + d^{2+a+o(1)} +\nd^{1+\\omega(1,1,a)-a})$ for any $a \\in [0, 1]$, where $\\omega$ is the exponent\nof matrix multiplication. In particular, for the current $\\omega \\approx 2.371$\n[Alman, Duan, Williams, Xu, Xu, Zhou 2024], our running time boils down to\n$O(d^{2.53})$. This running time is due to the analysis of the lazy update\nbehavior in iterative maintenance problems such as [Deng, Song, Weinstein 2022;\nBrand, Song, Zhou ICML 2024].\n","authors":["Xiaoyu Li","Yingyu Liang","Zhenmei Shi","Zhao Song"],"pdf_url":"https://arxiv.org/pdf/2408.12151v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.14148v1","updated":"2024-10-18T03:34:32Z","published":"2024-10-18T03:34:32Z","title":"Fine-Grained Verifiers: Preference Modeling as Next-token Prediction in\n  Vision-Language Alignment","summary":"  The recent advancements in large language models (LLMs) and pre-trained\nvision models have accelerated the development of vision-language large models\n(VLLMs), enhancing the interaction between visual and linguistic modalities.\nDespite their notable success across various domains, VLLMs face challenges in\nmodality alignment, which can lead to issues like hallucinations and unsafe\ncontent generation. Current alignment techniques often rely on coarse feedback\nand external datasets, limiting scalability and performance. In this paper, we\npropose FiSAO (Fine-Grained Self-Alignment Optimization), a novel\nself-alignment method that utilizes the model's own visual encoder as a\nfine-grained verifier to improve vision-language alignment without the need for\nadditional data. By leveraging token-level feedback from the vision encoder,\nFiSAO significantly improves vision-language alignment, even surpassing\ntraditional preference tuning methods that require additional data. Through\nboth theoretical analysis and experimental validation, we demonstrate that\nFiSAO effectively addresses the misalignment problem in VLLMs, marking the\nfirst instance of token-level rewards being applied to such models.\n","authors":["Chenhang Cui","An Zhang","Yiyang Zhou","Zhaorun Chen","Gelei Deng","Huaxiu Yao","Tat-Seng Chua"],"pdf_url":"https://arxiv.org/pdf/2410.14148v1.pdf","comment":"23 pages"},{"id":"http://arxiv.org/abs/2402.13606v3","updated":"2024-10-18T03:34:12Z","published":"2024-02-21T08:20:06Z","title":"A Comprehensive Study of Multilingual Confidence Estimation on Large\n  Language Models","summary":"  The tendency of Large Language Models (LLMs) to generate hallucinations\nraises concerns regarding their reliability. Therefore, confidence estimations\nindicating the extent of trustworthiness of the generations become essential.\nHowever, current LLM confidence estimations in languages other than English\nremain underexplored. This paper addresses this gap by introducing a\ncomprehensive investigation of Multilingual Confidence estimation (MlingConf)\non LLMs, focusing on both language-agnostic (LA) and language-specific (LS)\ntasks to explore the performance and language dominance effects of multilingual\nconfidence estimations on different tasks. The benchmark comprises four\nmeticulously checked and human-evaluate high-quality multilingual datasets for\nLA tasks and one for the LS task tailored to specific social, cultural, and\ngeographical contexts of a language. Our experiments reveal that on LA tasks\nEnglish exhibits notable linguistic dominance in confidence estimations than\nother languages, while on LS tasks, using question-related language to prompt\nLLMs demonstrates better linguistic dominance in multilingual confidence\nestimations. The phenomena inspire a simple yet effective native-tone prompting\nstrategy by employing language-specific prompts for LS tasks, effectively\nimproving LLMs' reliability and accuracy on LS tasks.\n","authors":["Boyang Xue","Hongru Wang","Rui Wang","Sheng Wang","Zezhong Wang","Yiming Du","Bin Liang","Kam-Fai Wong"],"pdf_url":"https://arxiv.org/pdf/2402.13606v3.pdf","comment":"Comments: n pages; Previously this version appeared as\n  arXiv:2410.12478 which was submitted as a new work by accident"},{"id":"http://arxiv.org/abs/2410.14145v1","updated":"2024-10-18T03:33:18Z","published":"2024-10-18T03:33:18Z","title":"CAPE: A Chinese Dataset for Appraisal-based Emotional Generation using\n  Large Language Models","summary":"  Generating emotionally appropriate responses in conversations with large\nlanguage models presents a significant challenge due to the complexities of\nhuman emotions and cognitive processes, which remain largely underexplored in\ntheir critical role in social interactions. In this study, we introduce a\ntwo-stage automatic data generation framework to create CAPE, a Chinese dataset\nnamed Cognitive Appraisal theory-based Emotional corpus. This corpus\nfacilitates the generation of dialogues with contextually appropriate emotional\nresponses by accounting for diverse personal and situational factors. We\npropose two tasks utilizing this dataset: emotion prediction and next utterance\nprediction. Both automated and human evaluations demonstrate that agents\ntrained on our dataset can deliver responses that are more aligned with human\nemotional expressions. Our study shows the potential for advancing emotional\nexpression in conversational agents, paving the way for more nuanced and\nmeaningful human-computer interactions.\n","authors":["June M. Liu","He Cao","Renliang Sun","Rui Wang","Yu Li","Jiaxing Zhang"],"pdf_url":"https://arxiv.org/pdf/2410.14145v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.14144v1","updated":"2024-10-18T03:32:00Z","published":"2024-10-18T03:32:00Z","title":"A Lightweight Multi Aspect Controlled Text Generation Solution For Large\n  Language Models","summary":"  Large language models (LLMs) show remarkable abilities with instruction\ntuning. However, they fail to achieve ideal tasks when lacking high-quality\ninstruction tuning data on target tasks. Multi-Aspect Controllable Text\nGeneration (MCTG) is a representative task for this dilemma, where aspect\ndatasets are usually biased and correlated. Existing work exploits additional\nmodel structures and strategies for solutions, limiting adaptability to LLMs.\nTo activate MCTG ability of LLMs, we propose a lightweight MCTG pipeline based\non data augmentation. We analyze bias and correlations in traditional datasets,\nand address these concerns with augmented control attributes and sentences.\nAugmented datasets are feasible for instruction tuning. In our experiments,\nLLMs perform better in MCTG after data augmentation, with a 20% accuracy rise\nand less aspect correlations.\n","authors":["Chenyang Zhang","Jiayi Lin","Haibo Tong","Bingxuan Hou","Dongyu Zhang","Jialin Li","Junli Wang"],"pdf_url":"https://arxiv.org/pdf/2410.14144v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.02052v3","updated":"2024-10-18T03:27:37Z","published":"2024-10-02T21:42:35Z","title":"ExACT: Teaching AI Agents to Explore with Reflective-MCTS and\n  Exploratory Learning","summary":"  Autonomous agents have demonstrated significant potential in automating\ncomplex multistep decision-making tasks. However, even state-of-the-art\nvision-language models (VLMs), such as GPT-4o, still fall short of human-level\nperformance, particularly in intricate web environments and long-horizon tasks.\nTo address these limitations, we present ExACT, an approach to combine\ntest-time search and self-learning to build o1-like models for agentic\napplications. We first introduce Reflective Monte Carlo Tree Search (R-MCTS), a\nnovel test time algorithm designed to enhance AI agents' ability to explore\ndecision space on the fly. R-MCTS extends traditional MCTS by 1) incorporating\ncontrastive reflection, allowing agents to learn from past interactions and\ndynamically improve their search efficiency; and 2) using multi-agent debate\nfor reliable state evaluation. Next, we introduce Exploratory Learning, a novel\nlearning strategy to teach agents to search at inference time without relying\non any external search algorithms. On the challenging VisualWebArena benchmark,\nour GPT-4o based R-MCTS agent achieves a 6% to 30% relative improvement across\nvarious tasks compared to the previous state-of-the-art. Additionally, we show\nthat the knowledge and experience gained from test-time search can be\neffectively transferred back to GPT-4o via fine-tuning. After Exploratory\nLearning, GPT-4o 1) demonstrates the ability to explore the environment,\nevaluate a state, and backtrack to viable ones when it detects that the current\nstate cannot lead to success, and 2) matches 87% of R-MCTS's performance while\nusing significantly less compute. Notably, our work demonstrates the compute\nscaling properties in both training - data collection with R-MCTS - and testing\ntime. These results suggest a promising research direction to enhance VLMs'\ncapabilities for agentic applications via test-time search and self-learning.\n","authors":["Xiao Yu","Baolin Peng","Vineeth Vajipey","Hao Cheng","Michel Galley","Jianfeng Gao","Zhou Yu"],"pdf_url":"https://arxiv.org/pdf/2410.02052v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.14141v1","updated":"2024-10-18T03:26:06Z","published":"2024-10-18T03:26:06Z","title":"Coherence-Driven Multimodal Safety Dialogue with Active Learning for\n  Embodied Agents","summary":"  When assisting people in daily tasks, robots need to accurately interpret\nvisual cues and respond effectively in diverse safety-critical situations, such\nas sharp objects on the floor. In this context, we present M-CoDAL, a\nmultimodal-dialogue system specifically designed for embodied agents to better\nunderstand and communicate in safety-critical situations. The system leverages\ndiscourse coherence relations to enhance its contextual understanding and\ncommunication abilities. To train this system, we introduce a novel\nclustering-based active learning mechanism that utilizes an external Large\nLanguage Model (LLM) to identify informative instances. Our approach is\nevaluated using a newly created multimodal dataset comprising 1K safety\nviolations extracted from 2K Reddit images. These violations are annotated\nusing a Large Multimodal Model (LMM) and verified by human annotators. Results\nwith this dataset demonstrate that our approach improves resolution of safety\nsituations, user sentiment, as well as safety of the conversation. Next, we\ndeploy our dialogue system on a Hello Robot Stretch robot and conduct a\nwithin-subject user study with real-world participants. In the study,\nparticipants role-play two safety scenarios with different levels of severity\nwith the robot and receive interventions from our model and a baseline system\npowered by OpenAI's ChatGPT. The study results corroborate and extend the\nfindings from automated evaluation, showing that our proposed system is more\npersuasive and competent in a real-world embodied agent setting.\n","authors":["Sabit Hassan","Hye-Young Chung","Xiang Zhi Tan","Malihe Alikhani"],"pdf_url":"https://arxiv.org/pdf/2410.14141v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.12478v2","updated":"2024-10-18T03:19:51Z","published":"2024-10-16T11:46:55Z","title":"MlingConf: A Comprehensive Study of Multilingual Confidence Estimation\n  on Large Language Models","summary":"  The tendency of Large Language Models (LLMs) to generate hallucinations\nraises concerns regarding their reliability. Therefore, confidence estimations\nindicating the extent of trustworthiness of the generations become essential.\nHowever, current LLM confidence estimations in languages other than English\nremain underexplored. This paper addresses this gap by introducing a\ncomprehensive investigation of Multilingual Confidence estimation (MlingConf)\non LLMs, focusing on both language-agnostic (LA) and language-specific (LS)\ntasks to explore the performance and language dominance effects of multilingual\nconfidence estimations on different tasks. The benchmark comprises four\nmeticulously checked and human-evaluate high-quality multilingual datasets for\nLA tasks and one for the LS task tailored to specific social, cultural, and\ngeographical contexts of a language. Our experiments reveal that on LA tasks\nEnglish exhibits notable linguistic dominance in confidence estimations than\nother languages, while on LS tasks, using question-related language to prompt\nLLMs demonstrates better linguistic dominance in multilingual confidence\nestimations. The phenomena inspire a simple yet effective native-tone prompting\nstrategy by employing language-specific prompts for LS tasks, effectively\nimproving LLMs' reliability and accuracy on LS tasks.\n","authors":["Boyang Xue","Hongru Wang","Rui Wang","Sheng Wang","Zezhong Wang","Yiming Du","Bin Liang","Kam-Fai Wong"],"pdf_url":"https://arxiv.org/pdf/2410.12478v2.pdf","comment":"Comments: This work was intended as a replacement of arXiv:2402.13606\n  and any subsequent updates will appear there"},{"id":"http://arxiv.org/abs/2410.04717v3","updated":"2024-10-18T03:18:50Z","published":"2024-10-07T03:15:11Z","title":"$\\textbf{Only-IF}$:Revealing the Decisive Effect of Instruction\n  Diversity on Generalization","summary":"  Understanding and accurately following instructions is critical for large\nlanguage models (LLMs) to be effective across diverse tasks. In this work, we\nrigorously examine the key factors that enable models to generalize to unseen\ninstructions, providing insights to guide the collection of data for\ninstruction-tuning. Through controlled experiments, inspired by the\nTuring-complete Markov algorithm, we demonstrate that such generalization\n$\\textbf{only emerges}$ when training data is diversified enough across\nsemantic domains. Our findings also reveal that merely diversifying within\nlimited domains fails to ensure robust generalization. In contrast,\ncross-domain data diversification, even under constrained data budgets,\nsignificantly enhances a model's adaptability. We further extend our analysis\nto real-world scenarios, including fine-tuning of\n$\\textit{$\\textbf{specialist}$}$ and $\\textit{$\\textbf{generalist}$}$ models.\nIn both cases, we demonstrate that 1) better performance can be achieved by\nincreasing the diversity of an established dataset while keeping the data size\nconstant, and 2) when scaling up the data, diversifying the semantics of\ninstructions is more effective than simply increasing the quantity of similar\ndata. Our research provides important insights for dataset collation,\nparticularly when optimizing model performance by expanding training data for\nboth specialist and generalist scenarios. We show that careful consideration of\ndata diversification is key: training specialist models with data extending\nbeyond their core domain leads to significant performance improvements, while\ngeneralist models benefit from diverse data mixtures that enhance their overall\ninstruction-following capabilities across a wide range of applications. Our\nresults highlight the critical role of strategic diversification and offer\nclear guidelines for improving data quality.\n","authors":["Dylan Zhang","Justin Wang","Francois Charton"],"pdf_url":"https://arxiv.org/pdf/2410.04717v3.pdf","comment":"Fix formatting issues"},{"id":"http://arxiv.org/abs/2409.03258v2","updated":"2024-10-18T03:11:28Z","published":"2024-09-05T05:34:16Z","title":"GraphInsight: Unlocking Insights in Large Language Models for Graph\n  Structure Understanding","summary":"  Although Large Language Models (LLMs) have demonstrated potential in\nprocessing graphs, they struggle with comprehending graphical structure\ninformation through prompts of graph description sequences, especially as the\ngraph size increases. We attribute this challenge to the uneven memory\nperformance of LLMs across different positions in graph description sequences,\nknown as ''positional biases''. To address this, we propose GraphInsight, a\nnovel framework aimed at improving LLMs' comprehension of both macro- and\nmicro-level graphical information. GraphInsight is grounded in two key\nstrategies: 1) placing critical graphical information in positions where LLMs\nexhibit stronger memory performance, and 2) investigating a lightweight\nexternal knowledge base for regions with weaker memory performance, inspired by\nretrieval-augmented generation (RAG). Moreover, GraphInsight explores\nintegrating these two strategies into LLM agent processes for composite graph\ntasks that require multi-step reasoning. Extensive empirical studies on\nbenchmarks with a wide range of evaluation tasks show that GraphInsight\nsignificantly outperforms all other graph description methods (e.g., prompting\ntechniques and reordering strategies) in understanding graph structures of\nvarying sizes.\n","authors":["Yukun Cao","Shuo Han","Zengyi Gao","Zezhong Ding","Xike Xie","S. Kevin Zhou"],"pdf_url":"https://arxiv.org/pdf/2409.03258v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.13960v3","updated":"2024-10-18T03:10:13Z","published":"2024-06-20T03:02:38Z","title":"AutoPal: Autonomous Adaptation to Users for Personal AI Companionship","summary":"  Previous research has demonstrated the potential of AI agents to act as\ncompanions that can provide constant emotional support for humans. In this\npaper, we emphasize the necessity of autonomous adaptation in personal AI\ncompanionship, an underexplored yet promising direction. Such adaptability is\ncrucial as it can facilitate more tailored interactions with users and allow\nthe agent to evolve in response to users' changing needs. However, imbuing\nagents with autonomous adaptability presents unique challenges, including\nidentifying optimal adaptations to meet users' expectations and ensuring a\nsmooth transition during the adaptation process. To address them, we devise a\nhierarchical framework, AutoPal, that enables controllable and authentic\nadjustments to the agent's persona based on user interactions. A\npersonamatching dataset is constructed to facilitate the learning of optimal\npersona adaptations. Extensive experiments demonstrate the effectiveness of\nAutoPal and highlight the importance of autonomous adaptability in AI\ncompanionship.\n","authors":["Yi Cheng","Wenge Liu","Kaishuai Xu","Wenjun Hou","Yi Ouyang","Chak Tou Leong","Xian Wu","Yefeng Zheng"],"pdf_url":"https://arxiv.org/pdf/2406.13960v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.07825v3","updated":"2024-10-18T03:06:39Z","published":"2024-03-12T17:04:28Z","title":"Efficiently Quantifying and Mitigating Ripple Effects in Model Editing","summary":"  Large Language Models have revolutionized numerous tasks with their\nremarkable efficacy. However, editing these models, crucial for rectifying\noutdated or erroneous information, often leads to a complex issue known as the\nripple effect in the hidden space. While difficult to detect, this effect can\nsignificantly impede the efficacy of model editing tasks and deteriorate model\nperformance. This paper addresses this scientific challenge by proposing a\nnovel evaluation methodology, Graphical Impact Evaluation(GIE), which\nquantitatively evaluates the adaptations of the model and the subsequent impact\nof editing. Furthermore, we introduce the Selective Impact Revision(SIR), a\nmodel editing method designed to mitigate this ripple effect. Our comprehensive\nevaluations reveal that the ripple effect in the hidden space is a significant\nissue in all current model editing methods. However, our proposed methods, GIE\nand SIR, effectively identify and alleviate this issue, contributing to the\nadvancement of LLM editing techniques.\n","authors":["Jianchen Wang","Zhouhong Gu","Xiaoxuan Zhu","Lin Zhang","Haoning Ye","Zhuozhi Xiong","Hongwei Feng","Yanghua Xiao"],"pdf_url":"https://arxiv.org/pdf/2403.07825v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.12841v2","updated":"2024-10-18T03:03:01Z","published":"2024-10-09T17:33:15Z","title":"UniAutoML: A Human-Centered Framework for Unified Discriminative and\n  Generative AutoML with Large Language Models","summary":"  Automated Machine Learning (AutoML) has simplified complex ML processes such\nas data pre-processing, model selection, and hyper-parameter searching.\nHowever, traditional AutoML frameworks focus solely on discriminative tasks,\noften falling short in tackling AutoML for generative models. Additionally,\nthese frameworks lack interpretability and user engagement during the training\nprocess, primarily due to the absence of human-centered design. It leads to a\nlack of transparency in final decision-making and limited user control,\npotentially reducing trust and adoption of AutoML methods. To address these\nlimitations, we introduce UniAutoML, a human-centered AutoML framework that\nleverages Large Language Models (LLMs) to unify AutoML for both discriminative\n(e.g., Transformers and CNNs for classification or regression tasks) and\ngenerative tasks (e.g., fine-tuning diffusion models or LLMs). The\nhuman-centered design of UniAutoML innovatively features a conversational user\ninterface (CUI) that facilitates natural language interactions, providing users\nwith real-time guidance, feedback, and progress updates for better\ninterpretability. This design enhances transparency and user control throughout\nthe AutoML training process, allowing users to seamlessly break down or modify\nthe model being trained. To mitigate potential risks associated with LLM\ngenerated content, UniAutoML incorporates a safety guardline that filters\ninputs and censors outputs. We evaluated UniAutoML's performance and usability\nthrough experiments on eight diverse datasets and user studies involving 25\nparticipants, demonstrating that UniAutoML not only enhances performance but\nalso improves user control and trust. Our human-centered design bridges the gap\nbetween AutoML capabilities and user understanding, making ML more accessible\nto a broader audience.\n","authors":["Jiayi Guo","Zan Chen","Yingrui Ji","Liyun Zhang","Daqin Luo","Zhigang Li","Yiqin Shen"],"pdf_url":"https://arxiv.org/pdf/2410.12841v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.14132v1","updated":"2024-10-18T03:00:03Z","published":"2024-10-18T03:00:03Z","title":"ViConsFormer: Constituting Meaningful Phrases of Scene Texts using\n  Transformer-based Method in Vietnamese Text-based Visual Question Answering","summary":"  Text-based VQA is a challenging task that requires machines to use scene\ntexts in given images to yield the most appropriate answer for the given\nquestion. The main challenge of text-based VQA is exploiting the meaning and\ninformation from scene texts. Recent studies tackled this challenge by\nconsidering the spatial information of scene texts in images via embedding 2D\ncoordinates of their bounding boxes. In this study, we follow the definition of\nmeaning from linguistics to introduce a novel method that effectively exploits\nthe information from scene texts written in Vietnamese. Experimental results\nshow that our proposed method obtains state-of-the-art results on two\nlarge-scale Vietnamese Text-based VQA datasets. The implementation can be found\nat this link.\n","authors":["Nghia Hieu Nguyen","Tho Thanh Quan","Ngan Luu-Thuy Nguyen"],"pdf_url":"https://arxiv.org/pdf/2410.14132v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.12847v2","updated":"2024-10-18T02:56:32Z","published":"2024-10-10T07:48:53Z","title":"ACCEPT: Adaptive Codebook for Composite and Efficient Prompt Tuning","summary":"  Prompt Tuning has been a popular Parameter-Efficient Fine-Tuning method\nattributed to its remarkable performance with few updated parameters on various\nlarge-scale pretrained Language Models (PLMs). Traditionally, each prompt has\nbeen considered indivisible and updated independently, leading the parameters\nincrease proportionally as prompt length grows. To address this issue, we\npropose Adaptive Codebook for Composite and Efficient Prompt Tuning (ACCEPT).\nIn our method, we refer to the concept of product quantization (PQ), allowing\nall soft prompts to share a set of learnable codebook vectors in each subspace,\nwith each prompt differentiated by a set of adaptive weights. We achieve the\nsuperior performance on 17 diverse natural language tasks including natural\nlanguage understanding (NLU) and question answering (QA) tasks by tuning only\n0.3% of parameters of the PLMs. Our approach also excels in few-shot and large\nmodel settings, highlighting its significant potential.\n","authors":["Yu-Chen Lin","Wei-Hua Li","Jun-Cheng Chen","Chu-Song Chen"],"pdf_url":"https://arxiv.org/pdf/2410.12847v2.pdf","comment":"EMNLP Findings 2024"},{"id":"http://arxiv.org/abs/2406.05213v2","updated":"2024-10-18T02:55:27Z","published":"2024-06-07T18:54:40Z","title":"On Subjective Uncertainty Quantification and Calibration in Natural\n  Language Generation","summary":"  Applications of large language models often involve the generation of\nfree-form responses, in which case uncertainty quantification becomes\nchallenging. This is due to the need to identify task-specific uncertainties\n(e.g., about the semantics) which appears difficult to define in general cases.\nThis work addresses these challenges from a perspective of Bayesian decision\ntheory, starting from the assumption that our utility is characterized by a\nsimilarity measure that compares a generated response with a hypothetical true\nresponse. We discuss how this assumption enables principled quantification of\nthe model's subjective uncertainty and its calibration. We further derive a\nmeasure for epistemic uncertainty, based on a missing data perspective and its\ncharacterization as an excess risk. The proposed methods can be applied to\nblack-box language models. We illustrate the methods on question answering and\nmachine translation tasks. Our experiments provide a principled evaluation of\ntask-specific calibration, and demonstrate that epistemic uncertainty offers a\npromising deferral strategy for efficient data acquisition in in-context\nlearning.\n","authors":["Ziyu Wang","Chris Holmes"],"pdf_url":"https://arxiv.org/pdf/2406.05213v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.13166v2","updated":"2024-10-18T02:53:14Z","published":"2024-10-17T02:47:10Z","title":"An Evolved Universal Transformer Memory","summary":"  Prior methods propose to offset the escalating costs of modern foundation\nmodels by dropping specific parts of their contexts with hand-designed rules,\nwhile attempting to preserve their original performance. We overcome this\ntrade-off with Neural Attention Memory Models (NAMMs), introducing a learned\nnetwork for memory management that improves both the performance and efficiency\nof transformers. We evolve NAMMs atop pre-trained transformers to provide\ndifferent latent contexts focusing on the most relevant information for\nindividual layers and attention heads. NAMMs are universally applicable to any\nmodel using self-attention as they condition exclusively on the values in the\nproduced attention matrices. Learning NAMMs on a small set of problems, we\nachieve substantial performance improvements across multiple long-context\nbenchmarks while cutting the model's input contexts up to a fraction of the\noriginal sizes. We show the generality of our conditioning enables zero-shot\ntransfer of NAMMs trained only on language to entirely new transformer\narchitectures even across input modalities, with their benefits carrying over\nto vision and reinforcement learning.\n","authors":["Edoardo Cetin","Qi Sun","Tianyu Zhao","Yujin Tang"],"pdf_url":"https://arxiv.org/pdf/2410.13166v2.pdf","comment":"29 pages, 14 figures. Preprint, under submission. Source code is\n  available at https://github.com/SakanaAI/evo-memory"}],"Computer Vision and Pattern Recognition":[{"id":"http://arxiv.org/abs/2410.13824v2","updated":"2024-10-18T09:01:01Z","published":"2024-10-17T17:48:54Z","title":"Harnessing Webpage UIs for Text-Rich Visual Understanding","summary":"  Text-rich visual understanding-the ability to process environments where\ndense textual content is integrated with visuals-is crucial for multimodal\nlarge language models (MLLMs) to interact effectively with structured\nenvironments. To enhance this capability, we propose synthesizing general\nmultimodal instructions from webpage UIs using text-based large language models\n(LLMs). Despite lacking direct visual input, text-based LLMs are able to\nprocess structured text representations from webpage accessibility trees. These\ninstructions are then paired with UI screenshots to train multimodal models. We\nintroduce MultiUI, a dataset containing 7.3 million samples from 1 million\nwebsites, covering diverse multimodal tasks and UI layouts. Models trained on\nMultiUI not only excel in web UI tasks-achieving up to a 48% improvement on\nVisualWebBench and a 19.1% boost in element accuracy on a web agent dataset\nMind2Web-but also generalize surprisingly well to non-web UI tasks and even to\nnon-UI domains, such as document understanding, OCR, and chart interpretation.\nThese results highlight the broad applicability of web UI data for advancing\ntext-rich visual understanding across various scenarios.\n","authors":["Junpeng Liu","Tianyue Ou","Yifan Song","Yuxiao Qu","Wai Lam","Chenyan Xiong","Wenhu Chen","Graham Neubig","Xiang Yue"],"pdf_url":"https://arxiv.org/pdf/2410.13824v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.13726v2","updated":"2024-10-18T04:19:02Z","published":"2024-10-17T16:32:36Z","title":"DAWN: Dynamic Frame Avatar with Non-autoregressive Diffusion Framework\n  for Talking Head Video Generation","summary":"  Talking head generation intends to produce vivid and realistic talking head\nvideos from a single portrait and speech audio clip. Although significant\nprogress has been made in diffusion-based talking head generation, almost all\nmethods rely on autoregressive strategies, which suffer from limited context\nutilization beyond the current generation step, error accumulation, and slower\ngeneration speed. To address these challenges, we present DAWN (Dynamic frame\nAvatar With Non-autoregressive diffusion), a framework that enables all-at-once\ngeneration of dynamic-length video sequences. Specifically, it consists of two\nmain components: (1) audio-driven holistic facial dynamics generation in the\nlatent motion space, and (2) audio-driven head pose and blink generation.\nExtensive experiments demonstrate that our method generates authentic and vivid\nvideos with precise lip motions, and natural pose/blink movements.\nAdditionally, with a high generation speed, DAWN possesses strong extrapolation\ncapabilities, ensuring the stable production of high-quality long videos. These\nresults highlight the considerable promise and potential impact of DAWN in the\nfield of talking head video generation. Furthermore, we hope that DAWN sparks\nfurther exploration of non-autoregressive approaches in diffusion models. Our\ncode will be publicly available at https://github.com/Hanbo-Cheng/DAWN-pytorch.\n","authors":["Hanbo Cheng","Limin Lin","Chenyu Liu","Pengcheng Xia","Pengfei Hu","Jiefeng Ma","Jun Du","Jia Pan"],"pdf_url":"https://arxiv.org/pdf/2410.13726v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.13674v2","updated":"2024-10-18T03:28:38Z","published":"2024-10-17T15:33:35Z","title":"Diffusion Curriculum: Synthetic-to-Real Generative Curriculum Learning\n  via Image-Guided Diffusion","summary":"  Low-quality or scarce data has posed significant challenges for training deep\nneural networks in practice. While classical data augmentation cannot\ncontribute very different new data, diffusion models opens up a new door to\nbuild self-evolving AI by generating high-quality and diverse synthetic data\nthrough text-guided prompts. However, text-only guidance cannot control\nsynthetic images' proximity to the original images, resulting in\nout-of-distribution data detrimental to the model performance. To overcome the\nlimitation, we study image guidance to achieve a spectrum of interpolations\nbetween synthetic and real images. With stronger image guidance, the generated\nimages are similar to the training data but hard to learn. While with weaker\nimage guidance, the synthetic images will be easier for model but contribute to\na larger distribution gap with the original data. The generated full spectrum\nof data enables us to build a novel \"Diffusion Curriculum (DisCL)\". DisCL\nadjusts the image guidance level of image synthesis for each training stage: It\nidentifies and focuses on hard samples for the model and assesses the most\neffective guidance level of synthetic images to improve hard data learning. We\napply DisCL to two challenging tasks: long-tail (LT) classification and\nlearning from low-quality data. It focuses on lower-guidance images of\nhigh-quality to learn prototypical features as a warm-up of learning\nhigher-guidance images that might be weak on diversity or quality. Extensive\nexperiments showcase a gain of 2.7% and 2.1% in OOD and ID macro-accuracy when\napplying DisCL to iWildCam dataset. On ImageNet-LT, DisCL improves the base\nmodel's tail-class accuracy from 4.4% to 23.64% and leads to a 4.02%\nimprovement in all-class accuracy.\n","authors":["Yijun Liang","Shweta Bhardwaj","Tianyi Zhou"],"pdf_url":"https://arxiv.org/pdf/2410.13674v2.pdf","comment":"23 pages, including references and appendix. Code is available at\n  http://github.com/tianyi-lab/DisCL"},{"id":"http://arxiv.org/abs/2410.13621v2","updated":"2024-10-18T08:01:27Z","published":"2024-10-17T14:55:09Z","title":"Enhanced Prompt-leveraged Weakly Supervised Cancer Segmentation based on\n  Segment Anything","summary":"  This work proposes a novel approach beyond supervised learning for effective\npathological image analysis, addressing the challenge of limited robust labeled\ndata. Pathological diagnosis of diseases like cancer has conventionally relied\non the evaluation of morphological features by physicians and pathologists.\nHowever, recent advancements in compute-aided diagnosis (CAD) systems are\ngaining significant attention as diagnostic support tools. Although the\nadvancement of deep learning has improved CAD significantly, segmentation\nmodels typically require large pixel-level annotated dataset, and such labeling\nis expensive. Existing studies not based on supervised approaches still\nstruggle with limited generalization, and no practical approach has emerged\nyet. To address this issue, we present a weakly supervised semantic\nsegmentation (WSSS) model by combining class activation map and Segment\nAnything Model (SAM)-based pseudo-labeling. For effective pretraining, we adopt\nthe SAM-a foundation model that is pretrained on large datasets and operates in\nzero-shot configurations using only coarse prompts. The proposed approach\ntransfer enhanced Attention Dropout Layer's knowledge to SAM, thereby\ngenerating pseudo-labels. To demonstrate the superiority of the proposed\nmethod, experimental studies are conducted on histopathological breast cancer\ndatasets. The proposed method outperformed other WSSS methods across three\ndatasets, demonstrating its efficiency by achieving this with only 12GB of GPU\nmemory during training. Our code is available at :\nhttps://github.com/QI-NemoSong/EPLC-SAM\n","authors":["Joonhyeon Song","Seohwan Yun","Seongho Yoon","Joohyeok Kim","Sangmin Lee"],"pdf_url":"https://arxiv.org/pdf/2410.13621v2.pdf","comment":"10 pages, 7 figures"},{"id":"http://arxiv.org/abs/2410.13242v2","updated":"2024-10-18T15:41:44Z","published":"2024-10-17T05:53:13Z","title":"Fundus to Fluorescein Angiography Video Generation as a Retinal\n  Generative Foundation Model","summary":"  Fundus fluorescein angiography (FFA) is crucial for diagnosing and monitoring\nretinal vascular issues but is limited by its invasive nature and restricted\naccessibility compared to color fundus (CF) imaging. Existing methods that\nconvert CF images to FFA are confined to static image generation, missing the\ndynamic lesional changes. We introduce Fundus2Video, an autoregressive\ngenerative adversarial network (GAN) model that generates dynamic FFA videos\nfrom single CF images. Fundus2Video excels in video generation, achieving an\nFVD of 1497.12 and a PSNR of 11.77. Clinical experts have validated the\nfidelity of the generated videos. Additionally, the model's generator\ndemonstrates remarkable downstream transferability across ten external public\ndatasets, including blood vessel segmentation, retinal disease diagnosis,\nsystemic disease prediction, and multimodal retrieval, showcasing impressive\nzero-shot and few-shot capabilities. These findings position Fundus2Video as a\npowerful, non-invasive alternative to FFA exams and a versatile retinal\ngenerative foundation model that captures both static and temporal retinal\nfeatures, enabling the representation of complex inter-modality relationships.\n","authors":["Weiyi Zhang","Jiancheng Yang","Ruoyu Chen","Siyu Huang","Pusheng Xu","Xiaolan Chen","Shanfu Lu","Hongyu Cao","Mingguang He","Danli Shi"],"pdf_url":"https://arxiv.org/pdf/2410.13242v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.13195v2","updated":"2024-10-18T06:02:28Z","published":"2024-10-17T03:48:02Z","title":"UniG: Modelling Unitary 3D Gaussians for View-consistent 3D\n  Reconstruction","summary":"  In this work, we present UniG, a view-consistent 3D reconstruction and novel\nview synthesis model that generates a high-fidelity representation of 3D\nGaussians from sparse images. Existing 3D Gaussians-based methods usually\nregress Gaussians per-pixel of each view, create 3D Gaussians per view\nseparately, and merge them through point concatenation. Such a view-independent\nreconstruction approach often results in a view inconsistency issue, where the\npredicted positions of the same 3D point from different views may have\ndiscrepancies. To address this problem, we develop a DETR (DEtection\nTRansformer)-like framework, which treats 3D Gaussians as decoder queries and\nupdates their parameters layer by layer by performing multi-view\ncross-attention (MVDFA) over multiple input images. In this way, multiple views\nnaturally contribute to modeling a unitary representation of 3D Gaussians,\nthereby making 3D reconstruction more view-consistent. Moreover, as the number\nof 3D Gaussians used as decoder queries is irrespective of the number of input\nviews, allow an arbitrary number of input images without causing memory\nexplosion. Extensive experiments validate the advantages of our approach,\nshowcasing superior performance over existing methods quantitatively (improving\nPSNR by 4.2 dB when trained on Objaverse and tested on the GSO benchmark) and\nqualitatively. The code will be released at https://github.com/jwubz123/UNIG.\n","authors":["Jiamin Wu","Kenkun Liu","Yukai Shi","Xiaoke Jiang","Yuan Yao","Lei Zhang"],"pdf_url":"https://arxiv.org/pdf/2410.13195v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.13174v2","updated":"2024-10-18T16:26:30Z","published":"2024-10-17T02:57:35Z","title":"Scalable Drift Monitoring in Medical Imaging AI","summary":"  The integration of artificial intelligence (AI) into medical imaging has\nadvanced clinical diagnostics but poses challenges in managing model drift and\nensuring long-term reliability. To address these challenges, we develop MMC+,\nan enhanced framework for scalable drift monitoring, building upon the\nCheXstray framework that introduced real-time drift detection for medical\nimaging AI models using multi-modal data concordance. This work extends the\noriginal framework's methodologies, providing a more scalable and adaptable\nsolution for real-world healthcare settings and offers a reliable and\ncost-effective alternative to continuous performance monitoring addressing\nlimitations of both continuous and periodic monitoring methods. MMC+ introduces\ncritical improvements to the original framework, including more robust handling\nof diverse data streams, improved scalability with the integration of\nfoundation models like MedImageInsight for high-dimensional image embeddings\nwithout site-specific training, and the introduction of uncertainty bounds to\nbetter capture drift in dynamic clinical environments. Validated with\nreal-world data from Massachusetts General Hospital during the COVID-19\npandemic, MMC+ effectively detects significant data shifts and correlates them\nwith model performance changes. While not directly predicting performance\ndegradation, MMC+ serves as an early warning system, indicating when AI systems\nmay deviate from acceptable performance bounds and enabling timely\ninterventions. By emphasizing the importance of monitoring diverse data streams\nand evaluating data shifts alongside model performance, this work contributes\nto the broader adoption and integration of AI solutions in clinical settings.\n","authors":["Jameson Merkow","Felix J. Dorfner","Xiyu Yang","Alexander Ersoy","Giridhar Dasegowda","Mannudeep Kalra","Matthew P. Lungren","Christopher P. Bridge","Ivan Tarapov"],"pdf_url":"https://arxiv.org/pdf/2410.13174v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.14672v1","updated":"2024-10-18T17:59:04Z","published":"2024-10-18T17:59:04Z","title":"BiGR: Harnessing Binary Latent Codes for Image Generation and Improved\n  Visual Representation Capabilities","summary":"  We introduce BiGR, a novel conditional image generation model using compact\nbinary latent codes for generative training, focusing on enhancing both\ngeneration and representation capabilities. BiGR is the first conditional\ngenerative model that unifies generation and discrimination within the same\nframework. BiGR features a binary tokenizer, a masked modeling mechanism, and a\nbinary transcoder for binary code prediction. Additionally, we introduce a\nnovel entropy-ordered sampling method to enable efficient image generation.\nExtensive experiments validate BiGR's superior performance in generation\nquality, as measured by FID-50k, and representation capabilities, as evidenced\nby linear-probe accuracy. Moreover, BiGR showcases zero-shot generalization\nacross various vision tasks, enabling applications such as image inpainting,\noutpainting, editing, interpolation, and enrichment, without the need for\nstructural modifications. Our findings suggest that BiGR unifies generative and\ndiscriminative tasks effectively, paving the way for further advancements in\nthe field.\n","authors":["Shaozhe Hao","Xuantong Liu","Xianbiao Qi","Shihao Zhao","Bojia Zi","Rong Xiao","Kai Han","Kwan-Yee K. Wong"],"pdf_url":"https://arxiv.org/pdf/2410.14672v1.pdf","comment":"Project page: https://haoosz.github.io/BiGR"},{"id":"http://arxiv.org/abs/2410.14669v1","updated":"2024-10-18T17:58:21Z","published":"2024-10-18T17:58:21Z","title":"NaturalBench: Evaluating Vision-Language Models on Natural Adversarial\n  Samples","summary":"  Vision-language models (VLMs) have made significant progress in recent\nvisual-question-answering (VQA) benchmarks that evaluate complex\nvisio-linguistic reasoning. However, are these models truly effective? In this\nwork, we show that VLMs still struggle with natural images and questions that\nhumans can easily answer, which we term natural adversarial samples. We also\nfind it surprisingly easy to generate these VQA samples from natural image-text\ncorpora using off-the-shelf models like CLIP and ChatGPT. We propose a\nsemi-automated approach to collect a new benchmark, NaturalBench, for reliably\nevaluating VLMs with 10,000 human-verified VQA samples. Crucially, we adopt a\n$\\textbf{vision-centric}$ design by pairing each question with two images that\nyield different answers, preventing blind solutions from answering without\nusing the images. This makes NaturalBench more challenging than previous\nbenchmarks that can be solved with commonsense priors. We evaluate 53\nstate-of-the-art VLMs on NaturalBench, showing that models like\nLLaVA-OneVision, Cambrian-1, Llama3.2-Vision, Molmo, Qwen2-VL, and even GPT-4o\nlag 50%-70% behind human performance (over 90%). We analyze why NaturalBench is\nhard from two angles: (1) Compositionality: Solving NaturalBench requires\ndiverse visio-linguistic skills, including understanding attribute bindings,\nobject relationships, and advanced reasoning like logic and counting. To this\nend, unlike prior work that uses a single tag per sample, we tag each\nNaturalBench sample with 1 to 8 skill tags for fine-grained evaluation. (2)\nBiases: NaturalBench exposes severe biases in VLMs, as models often choose the\nsame answer regardless of the image. Lastly, we apply our benchmark curation\nmethod to diverse data sources, including long captions (over 100 words) and\nnon-English languages like Chinese and Hindi, highlighting its potential for\ndynamic evaluations of VLMs.\n","authors":["Baiqi Li","Zhiqiu Lin","Wenxuan Peng","Jean de Dieu Nyandwi","Daniel Jiang","Zixian Ma","Simran Khanuja","Ranjay Krishna","Graham Neubig","Deva Ramanan"],"pdf_url":"https://arxiv.org/pdf/2410.14669v1.pdf","comment":"Accepted to NeurIPS 24; We open-source our dataset at:\n  https://huggingface.co/datasets/BaiqiL/NaturalBench; Project page at:\n  https://linzhiqiu.github.io/papers/naturalbench/"},{"id":"http://arxiv.org/abs/2409.06445v2","updated":"2024-10-18T17:37:51Z","published":"2024-09-10T12:00:40Z","title":"Learning Generative Interactive Environments By Trained Agent\n  Exploration","summary":"  World models are increasingly pivotal in interpreting and simulating the\nrules and actions of complex environments. Genie, a recent model, excels at\nlearning from visually diverse environments but relies on costly\nhuman-collected data. We observe that their alternative method of using random\nagents is too limited to explore the environment. We propose to improve the\nmodel by employing reinforcement learning based agents for data generation.\nThis approach produces diverse datasets that enhance the model's ability to\nadapt and perform well across various scenarios and realistic actions within\nthe environment. In this paper, we first release the model GenieRedux - an\nimplementation based on Genie. Additionally, we introduce GenieRedux-G, a\nvariant that uses the agent's readily available actions to factor out action\nprediction uncertainty during validation. Our evaluation, including a\nreplication of the Coinrun case study, shows that GenieRedux-G achieves\nsuperior visual fidelity and controllability using the trained agent\nexploration. The proposed approach is reproducable, scalable and adaptable to\nnew types of environments. Our codebase is available at\nhttps://github.com/insait-institute/GenieRedux .\n","authors":["Naser Kazemi","Nedko Savov","Danda Paudel","Luc Van Gool"],"pdf_url":"https://arxiv.org/pdf/2409.06445v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.14634v1","updated":"2024-10-18T17:35:33Z","published":"2024-10-18T17:35:33Z","title":"Parallel Backpropagation for Inverse of a Convolution with Application\n  to Normalizing Flows","summary":"  Inverse of an invertible convolution is an important operation that comes up\nin Normalizing Flows, Image Deblurring, etc. The naive algorithm for\nbackpropagation of this operation using Gaussian elimination has running time\n$O(n^3)$ where $n$ is the number of pixels in the image. We give a fast\nparallel backpropagation algorithm with running time $O(\\sqrt{n})$ for a square\nimage and provide a GPU implementation of the same. Inverse Convolutions are\nusually used in Normalizing Flows in the sampling pass, making them slow. We\npropose to use Inverse Convolutions in the forward (image to latent vector)\npass of the Normalizing flow. Since the sampling pass is the inverse of the\nforward pass, it will use convolutions only, resulting in efficient sampling\ntimes. We use our parallel backpropagation algorithm for optimizing the inverse\nconvolution layer resulting in fast training times also. We implement this\napproach in various Normalizing Flow backbones, resulting in our Inverse-Flow\nmodels. We benchmark Inverse-Flow on standard datasets and show significantly\nimproved sampling times with similar bits per dimension compared to previous\nmodels.\n","authors":["Sandeep Nagar","Girish Varma"],"pdf_url":"https://arxiv.org/pdf/2410.14634v1.pdf","comment":"Preprint"},{"id":"http://arxiv.org/abs/2410.14633v1","updated":"2024-10-18T17:32:39Z","published":"2024-10-18T17:32:39Z","title":"Swiss Army Knife: Synergizing Biases in Knowledge from Vision Foundation\n  Models for Multi-Task Learning","summary":"  Vision Foundation Models (VFMs) have demonstrated outstanding performance on\nnumerous downstream tasks. However, due to their inherent representation biases\noriginating from different training paradigms, VFMs exhibit advantages and\ndisadvantages across distinct vision tasks. Although amalgamating the strengths\nof multiple VFMs for downstream tasks is an intuitive strategy, effectively\nexploiting these biases remains a significant challenge. In this paper, we\npropose a novel and versatile \"Swiss Army Knife\" (SAK) solution, which\nadaptively distills knowledge from a committee of VFMs to enhance multi-task\nlearning. Unlike existing methods that use a single backbone for knowledge\ntransfer, our approach preserves the unique representation bias of each teacher\nby collaborating the lightweight Teacher-Specific Adapter Path modules with the\nTeacher-Agnostic Stem. Through dynamic selection and combination of\nrepresentations with Mixture-of-Representations Routers, our SAK is capable of\nsynergizing the complementary strengths of multiple VFMs. Extensive experiments\nshow that our SAK remarkably outperforms prior state of the arts in multi-task\nlearning by 10% on the NYUD-v2 benchmark, while also providing a flexible and\nrobust framework that can readily accommodate more advanced model designs.\n","authors":["Yuxiang Lu","Shengcao Cao","Yu-Xiong Wang"],"pdf_url":"https://arxiv.org/pdf/2410.14633v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.01804v4","updated":"2024-10-18T17:20:20Z","published":"2024-10-02T17:59:09Z","title":"EVER: Exact Volumetric Ellipsoid Rendering for Real-time View Synthesis","summary":"  We present Exact Volumetric Ellipsoid Rendering (EVER), a method for\nreal-time differentiable emission-only volume rendering. Unlike recent\nrasterization based approach by 3D Gaussian Splatting (3DGS), our primitive\nbased representation allows for exact volume rendering, rather than alpha\ncompositing 3D Gaussian billboards. As such, unlike 3DGS our formulation does\nnot suffer from popping artifacts and view dependent density, but still\nachieves frame rates of $\\sim\\!30$ FPS at 720p on an NVIDIA RTX4090. Since our\napproach is built upon ray tracing it enables effects such as defocus blur and\ncamera distortion (e.g. such as from fisheye cameras), which are difficult to\nachieve by rasterization. We show that our method is more accurate with fewer\nblending issues than 3DGS and follow-up work on view-consistent rendering,\nespecially on the challenging large-scale scenes from the Zip-NeRF dataset\nwhere it achieves sharpest results among real-time techniques.\n","authors":["Alexander Mai","Peter Hedman","George Kopanas","Dor Verbin","David Futschik","Qiangeng Xu","Falko Kuester","Jonathan T. Barron","Yinda Zhang"],"pdf_url":"https://arxiv.org/pdf/2410.01804v4.pdf","comment":"Project page: https://half-potato.gitlab.io/posts/ever"},{"id":"http://arxiv.org/abs/2410.14612v1","updated":"2024-10-18T17:05:03Z","published":"2024-10-18T17:05:03Z","title":"MultiOrg: A Multi-rater Organoid-detection Dataset","summary":"  High-throughput image analysis in the biomedical domain has gained\nsignificant attention in recent years, driving advancements in drug discovery,\ndisease prediction, and personalized medicine. Organoids, specifically, are an\nactive area of research, providing excellent models for human organs and their\nfunctions. Automating the quantification of organoids in microscopy images\nwould provide an effective solution to overcome substantial manual\nquantification bottlenecks, particularly in high-throughput image analysis.\nHowever, there is a notable lack of open biomedical datasets, in contrast to\nother domains, such as autonomous driving, and, notably, only few of them have\nattempted to quantify annotation uncertainty. In this work, we present MultiOrg\na comprehensive organoid dataset tailored for object detection tasks with\nuncertainty quantification. This dataset comprises over 400 high-resolution 2d\nmicroscopy images and curated annotations of more than 60,000 organoids. Most\nimportantly, it includes three label sets for the test data, independently\nannotated by two experts at distinct time points. We additionally provide a\nbenchmark for organoid detection, and make the best model available through an\neasily installable, interactive plugin for the popular image visualization tool\nNapari, to perform organoid quantification.\n","authors":["Christina Bukas","Harshavardhan Subramanian","Fenja See","Carina Steinchen","Ivan Ezhov","Gowtham Boosarpu","Sara Asgharpour","Gerald Burgstaller","Mareike Lehmann","Florian Kofler","Marie Piraud"],"pdf_url":"https://arxiv.org/pdf/2410.14612v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.14595v1","updated":"2024-10-18T16:48:31Z","published":"2024-10-18T16:48:31Z","title":"DRACO-DehazeNet: An Efficient Image Dehazing Network Combining Detail\n  Recovery and a Novel Contrastive Learning Paradigm","summary":"  Image dehazing is crucial for clarifying images obscured by haze or fog, but\ncurrent learning-based approaches is dependent on large volumes of training\ndata and hence consumed significant computational power. Additionally, their\nperformance is often inadequate under non-uniform or heavy haze. To address\nthese challenges, we developed the Detail Recovery And Contrastive DehazeNet,\nwhich facilitates efficient and effective dehazing via a dense dilated inverted\nresidual block and an attention-based detail recovery network that tailors\nenhancements to specific dehazed scene contexts. A major innovation is its\nability to train effectively with limited data, achieved through a novel\nquadruplet loss-based contrastive dehazing paradigm. This approach distinctly\nseparates hazy and clear image features while also distinguish lower-quality\nand higher-quality dehazed images obtained from each sub-modules of our\nnetwork, thereby refining the dehazing process to a larger extent. Extensive\ntests on a variety of benchmarked haze datasets demonstrated the superiority of\nour approach. The code repository for this work will be available soon.\n","authors":["Gao Yu Lee","Tanmoy Dam","Md Meftahul Ferdaus","Daniel Puiu Poenar","Vu Duong"],"pdf_url":"https://arxiv.org/pdf/2410.14595v1.pdf","comment":"Submitted to a journal and currently under review. Once the paper is\n  accepted and published, the copyright will be transferred to the\n  corresponding journal"},{"id":"http://arxiv.org/abs/2404.13370v2","updated":"2024-10-18T16:44:05Z","published":"2024-04-20T13:15:27Z","title":"Movie101v2: Improved Movie Narration Benchmark","summary":"  Automatic movie narration aims to generate video-aligned plot descriptions to\nassist visually impaired audiences. Unlike standard video captioning, it\ninvolves not only describing key visual details but also inferring plots that\nunfold across multiple movie shots, presenting distinct and complex challenges.\nTo advance this field, we introduce Movie101v2, a large-scale, bilingual\ndataset with enhanced data quality specifically designed for movie narration.\nRevisiting the task, we propose breaking down the ultimate goal of automatic\nmovie narration into three progressive stages, offering a clear roadmap with\ncorresponding evaluation metrics. Based on our new benchmark, we baseline a\nrange of large vision-language models, including GPT-4V, and conduct an\nin-depth analysis of the challenges in narration generation. Our findings\nhighlight that achieving applicable movie narration generation is a fascinating\ngoal that requires significant research.\n","authors":["Zihao Yue","Yepeng Zhang","Ziheng Wang","Qin Jin"],"pdf_url":"https://arxiv.org/pdf/2404.13370v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2409.17777v2","updated":"2024-10-18T16:31:49Z","published":"2024-09-26T12:15:13Z","title":"Harnessing Shared Relations via Multimodal Mixup Contrastive Learning\n  for Multimodal Classification","summary":"  Deep multimodal learning has shown remarkable success by leveraging\ncontrastive learning to capture explicit one-to-one relations across\nmodalities. However, real-world data often exhibits shared relations beyond\nsimple pairwise associations. We propose M3CoL, a Multimodal Mixup Contrastive\nLearning approach to capture nuanced shared relations inherent in multimodal\ndata. Our key contribution is a Mixup-based contrastive loss that learns robust\nrepresentations by aligning mixed samples from one modality with their\ncorresponding samples from other modalities thereby capturing shared relations\nbetween them. For multimodal classification tasks, we introduce a framework\nthat integrates a fusion module with unimodal prediction modules for auxiliary\nsupervision during training, complemented by our proposed Mixup-based\ncontrastive loss. Through extensive experiments on diverse datasets (N24News,\nROSMAP, BRCA, and Food-101), we demonstrate that M3CoL effectively captures\nshared multimodal relations and generalizes across domains. It outperforms\nstate-of-the-art methods on N24News, ROSMAP, and BRCA, while achieving\ncomparable performance on Food-101. Our work highlights the significance of\nlearning shared relations for robust multimodal learning, opening up promising\navenues for future research.\n","authors":["Raja Kumar","Raghav Singhal","Pranamya Kulkarni","Deval Mehta","Kshitij Jadhav"],"pdf_url":"https://arxiv.org/pdf/2409.17777v2.pdf","comment":"RK and RS contributed equally to this work, 20 Pages, 8 Figures, 9\n  Tables. Another version of the paper accepted at NeurIPS 2024 Workshop on\n  Unifying Representations in Neural Models (UniReps)"},{"id":"http://arxiv.org/abs/2410.08107v2","updated":"2024-10-18T16:26:30Z","published":"2024-10-10T16:54:23Z","title":"IncEventGS: Pose-Free Gaussian Splatting from a Single Event Camera","summary":"  Implicit neural representation and explicit 3D Gaussian Splatting (3D-GS) for\nnovel view synthesis have achieved remarkable progress with frame-based camera\n(e.g. RGB and RGB-D cameras) recently. Compared to frame-based camera, a novel\ntype of bio-inspired visual sensor, i.e. event camera, has demonstrated\nadvantages in high temporal resolution, high dynamic range, low power\nconsumption and low latency. Due to its unique asynchronous and irregular data\ncapturing process, limited work has been proposed to apply neural\nrepresentation or 3D Gaussian splatting for an event camera. In this work, we\npresent IncEventGS, an incremental 3D Gaussian Splatting reconstruction\nalgorithm with a single event camera. To recover the 3D scene representation\nincrementally, we exploit the tracking and mapping paradigm of conventional\nSLAM pipelines for IncEventGS. Given the incoming event stream, the tracker\nfirstly estimates an initial camera motion based on prior reconstructed 3D-GS\nscene representation. The mapper then jointly refines both the 3D scene\nrepresentation and camera motion based on the previously estimated motion\ntrajectory from the tracker. The experimental results demonstrate that\nIncEventGS delivers superior performance compared to prior NeRF-based methods\nand other related baselines, even we do not have the ground-truth camera poses.\nFurthermore, our method can also deliver better performance compared to\nstate-of-the-art event visual odometry methods in terms of camera motion\nestimation. Code is publicly available at:\nhttps://github.com/wu-cvgl/IncEventGS.\n","authors":["Jian Huang","Chengrui Dong","Peidong Liu"],"pdf_url":"https://arxiv.org/pdf/2410.08107v2.pdf","comment":"Code Page: https://github.com/wu-cvgl/IncEventGS"},{"id":"http://arxiv.org/abs/2410.14574v1","updated":"2024-10-18T16:20:22Z","published":"2024-10-18T16:20:22Z","title":"MomentumSMoE: Integrating Momentum into Sparse Mixture of Experts","summary":"  Sparse Mixture of Experts (SMoE) has become the key to unlocking unparalleled\nscalability in deep learning. SMoE has the potential to exponentially increase\nparameter count while maintaining the efficiency of the model by only\nactivating a small subset of these parameters for a given sample. However, it\nhas been observed that SMoE suffers from unstable training and has difficulty\nadapting to new distributions, leading to the model's lack of robustness to\ndata contamination. To overcome these limitations, we first establish a\nconnection between the dynamics of the expert representations in SMoEs and\ngradient descent on a multi-objective optimization problem. Leveraging our\nframework, we then integrate momentum into SMoE and propose a new family of\nSMoEs named MomentumSMoE. We theoretically prove and numerically demonstrate\nthat MomentumSMoE is more stable and robust than SMoE. In particular, we verify\nthe advantages of MomentumSMoE over SMoE on a variety of practical tasks\nincluding ImageNet-1K object recognition and WikiText-103 language modeling. We\ndemonstrate the applicability of MomentumSMoE to many types of SMoE models,\nincluding those in the Sparse MoE model for vision (V-MoE) and the Generalist\nLanguage Model (GLaM). We also show that other advanced momentum-based\noptimization methods, such as Adam, can be easily incorporated into the\nMomentumSMoE framework for designing new SMoE models with even better\nperformance, almost negligible additional computation cost, and simple\nimplementations.\n","authors":["Rachel S. Y. Teo","Tan M. Nguyen"],"pdf_url":"https://arxiv.org/pdf/2410.14574v1.pdf","comment":"10 pages in the main text. Published at NeurIPS 2024. The code is\n  available at https://github.com/rachtsy/MomentumSMoE"},{"id":"http://arxiv.org/abs/2410.14540v1","updated":"2024-10-18T15:29:19Z","published":"2024-10-18T15:29:19Z","title":"Multi-modal Pose Diffuser: A Multimodal Generative Conditional Pose\n  Prior","summary":"  The Skinned Multi-Person Linear (SMPL) model plays a crucial role in 3D human\npose estimation, providing a streamlined yet effective representation of the\nhuman body. However, ensuring the validity of SMPL configurations during tasks\nsuch as human mesh regression remains a significant challenge , highlighting\nthe necessity for a robust human pose prior capable of discerning realistic\nhuman poses. To address this, we introduce MOPED:\n\\underline{M}ulti-m\\underline{O}dal \\underline{P}os\\underline{E}\n\\underline{D}iffuser. MOPED is the first method to leverage a novel multi-modal\nconditional diffusion model as a prior for SMPL pose parameters. Our method\noffers powerful unconditional pose generation with the ability to condition on\nmulti-modal inputs such as images and text. This capability enhances the\napplicability of our approach by incorporating additional context often\noverlooked in traditional pose priors. Extensive experiments across three\ndistinct tasks-pose estimation, pose denoising, and pose completion-demonstrate\nthat our multi-modal diffusion model-based prior significantly outperforms\nexisting methods. These results indicate that our model captures a broader\nspectrum of plausible human poses.\n","authors":["Calvin-Khang Ta","Arindam Dutta","Rohit Kundu","Rohit Lal","Hannah Dela Cruz","Dripta S. Raychaudhuri","Amit Roy-Chowdhury"],"pdf_url":"https://arxiv.org/pdf/2410.14540v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.14536v1","updated":"2024-10-18T15:23:34Z","published":"2024-10-18T15:23:34Z","title":"A Hybrid Feature Fusion Deep Learning Framework for Leukemia Cancer\n  Detection in Microscopic Blood Sample Using Gated Recurrent Unit and\n  Uncertainty Quantification","summary":"  Acute lymphoblastic leukemia (ALL) is the most malignant form of leukemia and\nthe most common cancer in adults and children. Traditionally, leukemia is\ndiagnosed by analyzing blood and bone marrow smears under a microscope, with\nadditional cytochemical tests for confirmation. However, these methods are\nexpensive, time consuming, and highly dependent on expert knowledge. In recent\nyears, deep learning, particularly Convolutional Neural Networks (CNNs), has\nprovided advanced methods for classifying microscopic smear images, aiding in\nthe detection of leukemic cells. These approaches are quick, cost effective,\nand not subject to human bias. However, most methods lack the ability to\nquantify uncertainty, which could lead to critical misdiagnoses. In this\nresearch, hybrid deep learning models (InceptionV3-GRU, EfficientNetB3-GRU,\nMobileNetV2-GRU) were implemented to classify ALL. Bayesian optimization was\nused to fine tune the model's hyperparameters and improve its performance.\nAdditionally, Deep Ensemble uncertainty quantification was applied to address\nuncertainty during leukemia image classification. The proposed models were\ntrained on the publicly available datasets ALL-IDB1 and ALL-IDB2. Their results\nwere then aggregated at the score level using the sum rule. The parallel\narchitecture used in these models offers a high level of confidence in\ndifferentiating between ALL and non-ALL cases. The proposed method achieved a\nremarkable detection accuracy rate of 100% on the ALL-IDB1 dataset, 98.07% on\nthe ALL-IDB2 dataset, and 98.64% on the combined dataset, demonstrating its\npotential for accurate and reliable leukemia diagnosis.\n","authors":["Maksuda Akter","Rabea Khatun","Md Manowarul Islam"],"pdf_url":"https://arxiv.org/pdf/2410.14536v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.14524v1","updated":"2024-10-18T15:08:05Z","published":"2024-10-18T15:08:05Z","title":"Less is More: Selective Reduction of CT Data for Self-Supervised\n  Pre-Training of Deep Learning Models with Contrastive Learning Improves\n  Downstream Classification Performance","summary":"  Self-supervised pre-training of deep learning models with contrastive\nlearning is a widely used technique in image analysis. Current findings\nindicate a strong potential for contrastive pre-training on medical images.\nHowever, further research is necessary to incorporate the particular\ncharacteristics of these images. We hypothesize that the similarity of medical\nimages hinders the success of contrastive learning in the medical imaging\ndomain. To this end, we investigate different strategies based on deep\nembedding, information theory, and hashing in order to identify and reduce\nredundancy in medical pre-training datasets. The effect of these different\nreduction strategies on contrastive learning is evaluated on two pre-training\ndatasets and several downstream classification tasks. In all of our\nexperiments, dataset reduction leads to a considerable performance gain in\ndownstream tasks, e.g., an AUC score improvement from 0.78 to 0.83 for the\nCOVID CT Classification Grand Challenge, 0.97 to 0.98 for the OrganSMNIST\nClassification Challenge and 0.73 to 0.83 for a brain hemorrhage classification\ntask. Furthermore, pre-training is up to nine times faster due to the dataset\nreduction. In conclusion, the proposed approach highlights the importance of\ndataset quality and provides a transferable approach to improve contrastive\npre-training for classification downstream tasks on medical images.\n","authors":["Daniel Wolf","Tristan Payer","Catharina Silvia Lisson","Christoph Gerhard Lisson","Meinrad Beer","Michael Götz","Timo Ropinski"],"pdf_url":"https://arxiv.org/pdf/2410.14524v1.pdf","comment":"Published in Computers in Biology and Medicine"},{"id":"http://arxiv.org/abs/2409.14485v3","updated":"2024-10-18T15:03:08Z","published":"2024-09-22T15:13:31Z","title":"Video-XL: Extra-Long Vision Language Model for Hour-Scale Video\n  Understanding","summary":"  Although current Multi-modal Large Language Models (MLLMs) demonstrate\npromising results in video understanding, processing extremely long videos\nremains an ongoing challenge. Typically, MLLMs struggle with handling thousands\nof visual tokens that exceed the maximum context length, and they suffer from\nthe information decay due to token aggregation. Another challenge is the high\ncomputational cost stemming from the large number of video tokens. To tackle\nthese issues, we propose Video-XL, an extra-long vision language model designed\nfor efficient hour-scale video understanding. Specifically, we argue that LLMs\ncan be adapted as effective visual condensers and propose Visual Context Latent\nSummarization which condenses visual contexts into highly compact forms.\nExtensive experiments demonstrate that our model achieves promising results on\npopular long video understanding benchmarks. For example, Video-XL outperforms\nthe current state-of-the-art method on VNBench by nearly 10\\% in accuracy.\nMoreover, Video-XL presents an impressive balance between efficiency and\neffectiveness, processing 2048 frames on a single 80GB GPU while achieving\nnearly 95% accuracy in the Needle-in-a-Haystack evaluation.\n","authors":["Yan Shu","Peitian Zhang","Zheng Liu","Minghao Qin","Junjie Zhou","Tiejun Huang","Bo Zhao"],"pdf_url":"https://arxiv.org/pdf/2409.14485v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.14509v1","updated":"2024-10-18T14:43:34Z","published":"2024-10-18T14:43:34Z","title":"CLIP-VAD: Exploiting Vision-Language Models for Voice Activity Detection","summary":"  Voice Activity Detection (VAD) is the process of automatically determining\nwhether a person is speaking and identifying the timing of their speech in an\naudiovisual data. Traditionally, this task has been tackled by processing\neither audio signals or visual data, or by combining both modalities through\nfusion or joint learning. In our study, drawing inspiration from recent\nadvancements in visual-language models, we introduce a novel approach\nleveraging Contrastive Language-Image Pretraining (CLIP) models. The CLIP\nvisual encoder analyzes video segments composed of the upper body of an\nindividual, while the text encoder handles textual descriptions automatically\ngenerated through prompt engineering. Subsequently, embeddings from these\nencoders are fused through a deep neural network to perform VAD. Our\nexperimental analysis across three VAD benchmarks showcases the superior\nperformance of our method compared to existing visual VAD approaches. Notably,\nour approach outperforms several audio-visual methods despite its simplicity,\nand without requiring pre-training on extensive audio-visual datasets.\n","authors":["Andrea Appiani","Cigdem Beyan"],"pdf_url":"https://arxiv.org/pdf/2410.14509v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.14508v1","updated":"2024-10-18T14:43:05Z","published":"2024-10-18T14:43:05Z","title":"LEAD: Latent Realignment for Human Motion Diffusion","summary":"  Our goal is to generate realistic human motion from natural language. Modern\nmethods often face a trade-off between model expressiveness and text-to-motion\nalignment. Some align text and motion latent spaces but sacrifice\nexpressiveness; others rely on diffusion models producing impressive motions,\nbut lacking semantic meaning in their latent space. This may compromise\nrealism, diversity, and applicability. Here, we address this by combining\nlatent diffusion with a realignment mechanism, producing a novel, semantically\nstructured space that encodes the semantics of language. Leveraging this\ncapability, we introduce the task of textual motion inversion to capture novel\nmotion concepts from a few examples. For motion synthesis, we evaluate LEAD on\nHumanML3D and KIT-ML and show comparable performance to the state-of-the-art in\nterms of realism, diversity, and text-motion consistency. Our qualitative\nanalysis and user study reveal that our synthesized motions are sharper, more\nhuman-like and comply better with the text compared to modern methods. For\nmotion textual inversion, our method demonstrates improved capacity in\ncapturing out-of-distribution characteristics in comparison to traditional\nVAEs.\n","authors":["Nefeli Andreou","Xi Wang","Victoria Fernández Abrevaya","Marie-Paule Cani","Yiorgos Chrysanthou","Vicky Kalogeiton"],"pdf_url":"https://arxiv.org/pdf/2410.14508v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.04960v2","updated":"2024-10-18T14:42:50Z","published":"2024-10-07T11:59:54Z","title":"On Efficient Variants of Segment Anything Model: A Survey","summary":"  The Segment Anything Model (SAM) is a foundational model for image\nsegmentation tasks, known for its strong generalization across diverse\napplications. However, its impressive performance comes with significant\ncomputational and resource demands, making it challenging to deploy in\nresource-limited environments such as edge devices. To address this, a variety\nof SAM variants have been proposed to enhance efficiency while keeping\naccuracy. This survey provides the first comprehensive review of these\nefficient SAM variants. We begin by exploring the motivations driving this\nresearch. We then present core techniques used in SAM and model acceleration.\nThis is followed by a detailed exploration of SAM acceleration strategies,\ncategorized by approach, and a discussion of several future research\ndirections. Finally, we offer a unified and extensive evaluation of these\nmethods across various hardware, assessing their efficiency and accuracy on\nrepresentative benchmarks, and providing a clear comparison of their overall\nperformance.\n","authors":["Xiaorui Sun","Jun Liu","Heng Tao Shen","Xiaofeng Zhu","Ping Hu"],"pdf_url":"https://arxiv.org/pdf/2410.04960v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.07361v2","updated":"2024-10-18T14:38:03Z","published":"2024-06-11T15:28:48Z","title":"Deep Implicit Optimization for Robust and Flexible Image Registration","summary":"  Deep Learning in Image Registration (DLIR) methods have been tremendously\nsuccessful in image registration due to their speed and ability to incorporate\nweak label supervision at training time. However, DLIR methods forego many of\nthe benefits of classical optimization-based methods. The functional nature of\ndeep networks do not guarantee that the predicted transformation is a local\nminima of the registration objective, the representation of the transformation\n(displacement/velocity field/affine) is fixed, and the networks are not robust\nto domain shift. Our method aims to bridge this gap between classical and\nlearning methods by incorporating optimization as a layer in a deep network. A\ndeep network is trained to predict multi-scale dense feature images that are\nregistered using a black box iterative optimization solver. This optimal warp\nis then used to minimize image and label alignment errors. By implicitly\ndifferentiating end-to-end through an iterative optimization solver, our\nlearned features are registration and label-aware, and the warp functions are\nguaranteed to be local minima of the registration objective in the feature\nspace. Our framework shows excellent performance on in-domain datasets, and is\nagnostic to domain shift such as anisotropy and varying intensity profiles. For\nthe first time, our method allows switching between arbitrary transformation\nrepresentations (free-form to diffeomorphic) at test time with zero retraining.\nEnd-to-end feature learning also facilitates interpretability of features, and\nout-of-the-box promptability using additional label-fidelity terms at\ninference.\n","authors":["Rohit Jena","Pratik Chaudhari","James C. Gee"],"pdf_url":"https://arxiv.org/pdf/2406.07361v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.14505v1","updated":"2024-10-18T14:37:37Z","published":"2024-10-18T14:37:37Z","title":"Neural Real-Time Recalibration for Infrared Multi-Camera Systems","summary":"  Currently, there are no learning-free or neural techniques for real-time\nrecalibration of infrared multi-camera systems. In this paper, we address the\nchallenge of real-time, highly-accurate calibration of multi-camera infrared\nsystems, a critical task for time-sensitive applications. Unlike traditional\ncalibration techniques that lack adaptability and struggle with on-the-fly\nrecalibrations, we propose a neural network-based method capable of dynamic\nreal-time calibration. The proposed method integrates a differentiable\nprojection model that directly correlates 3D geometries with their 2D image\nprojections and facilitates the direct optimization of both intrinsic and\nextrinsic camera parameters. Key to our approach is the dynamic camera pose\nsynthesis with perturbations in camera parameters, emulating realistic\noperational challenges to enhance model robustness. We introduce two model\nvariants: one designed for multi-camera systems with onboard processing of 2D\npoints, utilizing the direct 2D projections of 3D fiducials, and another for\nimage-based systems, employing color-coded projected points for implicitly\nestablishing correspondence. Through rigorous experimentation, we demonstrate\nour method is more accurate than traditional calibration techniques with or\nwithout perturbations while also being real-time, marking a significant leap in\nthe field of real-time multi-camera system calibration. The source code can be\nfound at https://github.com/theICTlab/neural-recalibration\n","authors":["Benyamin Mehmandar","Reza Talakoob","Charalambos Poullis"],"pdf_url":"https://arxiv.org/pdf/2410.14505v1.pdf","comment":"real-time camera calibration, infrared camera, neural calibration"},{"id":"http://arxiv.org/abs/2410.14489v1","updated":"2024-10-18T14:19:13Z","published":"2024-10-18T14:19:13Z","title":"An Integrated Deep Learning Model for Skin Cancer Detection Using Hybrid\n  Feature Fusion Technique","summary":"  Skin cancer is a serious and potentially fatal disease caused by DNA damage.\nEarly detection significantly increases survival rates, making accurate\ndiagnosis crucial. In this groundbreaking study, we present a hybrid framework\nbased on Deep Learning (DL) that achieves precise classification of benign and\nmalignant skin lesions. Our approach begins with dataset preprocessing to\nenhance classification accuracy, followed by training two separate pre-trained\nDL models, InceptionV3 and DenseNet121. By fusing the results of each model\nusing the weighted sum rule, our system achieves exceptional accuracy rates.\nSpecifically, we achieve a 92.27% detection accuracy rate, 92.33% sensitivity,\n92.22% specificity, 90.81% precision, and 91.57% F1-score, outperforming\nexisting models and demonstrating the robustness and trustworthiness of our\nhybrid approach. Our study represents a significant advance in skin cancer\ndiagnosis and provides a promising foundation for further research in the\nfield. With the potential to save countless lives through earlier detection,\nour hybrid deep-learning approach is a game-changer in the fight against skin\ncancer.\n","authors":["Maksuda Akter","Rabea Khatun","Md. Alamin Talukder","Md. Manowarul Islam","Md. Ashraf Uddin"],"pdf_url":"https://arxiv.org/pdf/2410.14489v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.14470v1","updated":"2024-10-18T13:54:46Z","published":"2024-10-18T13:54:46Z","title":"How Do Training Methods Influence the Utilization of Vision Models?","summary":"  Not all learnable parameters (e.g., weights) contribute equally to a neural\nnetwork's decision function. In fact, entire layers' parameters can sometimes\nbe reset to random values with little to no impact on the model's decisions. We\nrevisit earlier studies that examined how architecture and task complexity\ninfluence this phenomenon and ask: is this phenomenon also affected by how we\ntrain the model? We conducted experimental evaluations on a diverse set of\nImageNet-1k classification models to explore this, keeping the architecture and\ntraining data constant but varying the training pipeline. Our findings reveal\nthat the training method strongly influences which layers become critical to\nthe decision function for a given task. For example, improved training regimes\nand self-supervised training increase the importance of early layers while\nsignificantly under-utilizing deeper layers. In contrast, methods such as\nadversarial training display an opposite trend. Our preliminary results extend\nprevious findings, offering a more nuanced understanding of the inner mechanics\nof neural networks.\n  Code: https://github.com/paulgavrikov/layer_criticality\n","authors":["Paul Gavrikov","Shashank Agnihotri","Margret Keuper","Janis Keuper"],"pdf_url":"https://arxiv.org/pdf/2410.14470v1.pdf","comment":"Accepted at the Interpretable AI: Past, Present and Future Workshop\n  at NeurIPS 2024"},{"id":"http://arxiv.org/abs/2403.09939v2","updated":"2024-10-18T13:51:50Z","published":"2024-03-15T00:43:03Z","title":"Quantization Effects on Neural Networks Perception: How would\n  quantization change the perceptual field of vision models?","summary":"  Neural network quantization is a critical technique for deploying models on\nresource-limited devices. Despite its widespread use, the impact of\nquantization on model perceptual fields, particularly in relation to class\nactivation maps (CAMs), remains underexplored. This study investigates how\nquantization influences the spatial recognition abilities of vision models by\nexamining the alignment between CAMs and visual salient objects maps across\nvarious architectures. Utilizing a dataset of 10,000 images from ImageNet, we\nconduct a comprehensive evaluation of six diverse CNN architectures: VGG16,\nResNet50, EfficientNet, MobileNet, SqueezeNet, and DenseNet. Through the\nsystematic application of quantization techniques, we identify subtle changes\nin CAMs and their alignment with Salient object maps. Our results demonstrate\nthe differing sensitivities of these architectures to quantization and\nhighlight its implications for model performance and interpretability in\nreal-world applications. This work primarily contributes to a deeper\nunderstanding of neural network quantization, offering insights essential for\ndeploying efficient and interpretable models in practical settings.\n","authors":["Mohamed Amine Kerkouri","Marouane Tliba","Aladine Chetouani","Alessandro Bruno"],"pdf_url":"https://arxiv.org/pdf/2403.09939v2.pdf","comment":"Accepted & presented at IPTA 2024"},{"id":"http://arxiv.org/abs/2410.14462v1","updated":"2024-10-18T13:44:29Z","published":"2024-10-18T13:44:29Z","title":"LUDVIG: Learning-free Uplifting of 2D Visual features to Gaussian\n  Splatting scenes","summary":"  We address the task of uplifting visual features or semantic masks from 2D\nvision models to 3D scenes represented by Gaussian Splatting. Whereas common\napproaches rely on iterative optimization-based procedures, we show that a\nsimple yet effective aggregation technique yields excellent results. Applied to\nsemantic masks from Segment Anything (SAM), our uplifting approach leads to\nsegmentation quality comparable to the state of the art. We then extend this\nmethod to generic DINOv2 features, integrating 3D scene geometry through graph\ndiffusion, and achieve competitive segmentation results despite DINOv2 not\nbeing trained on millions of annotated masks like SAM.\n","authors":["Juliette Marrie","Romain Ménégaux","Michael Arbel","Diane Larlus","Julien Mairal"],"pdf_url":"https://arxiv.org/pdf/2410.14462v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2404.19525v3","updated":"2024-10-18T13:13:44Z","published":"2024-04-30T12:56:14Z","title":"MicroDreamer: Efficient 3D Generation in $\\sim$20 Seconds by Score-based\n  Iterative Reconstruction","summary":"  Optimization-based approaches, such as score distillation sampling (SDS),\nshow promise in zero-shot 3D generation but suffer from low efficiency,\nprimarily due to the high number of function evaluations (NFEs) required for\neach sample and the limitation of optimization confined to latent space. This\npaper introduces score-based iterative reconstruction (SIR), an efficient and\ngeneral algorithm mimicking a differentiable 3D reconstruction process to\nreduce the NFEs and enable optimization in pixel space. Given a single set of\nimages sampled from a multi-view score-based diffusion model, SIR repeatedly\noptimizes 3D parameters, unlike the single-step optimization in SDS. With other\nimprovements in training, we present an efficient approach called MicroDreamer\nthat generally applies to various 3D representations and 3D generation tasks.\nIn particular, MicroDreamer is 5-20 times faster than SDS in generating neural\nradiance field while retaining a comparable performance and takes about 20\nseconds to create meshes from 3D Gaussian splatting on a single A100 GPU,\nhalving the time of the fastest optimization-based baseline DreamGaussian with\nsignificantly superior performance compared to the measurement standard\ndeviation. Our code is available at https://github.com/ML-GSAI/MicroDreamer.\n","authors":["Luxi Chen","Zhengyi Wang","Zihan Zhou","Tingting Gao","Hang Su","Jun Zhu","Chongxuan Li"],"pdf_url":"https://arxiv.org/pdf/2404.19525v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.14445v1","updated":"2024-10-18T13:04:35Z","published":"2024-10-18T13:04:35Z","title":"Toward Generalizing Visual Brain Decoding to Unseen Subjects","summary":"  Visual brain decoding aims to decode visual information from human brain\nactivities. Despite the great progress, one critical limitation of current\nbrain decoding research lies in the lack of generalization capability to unseen\nsubjects. Prior works typically focus on decoding brain activity of individuals\nbased on the observation that different subjects exhibit different brain\nactivities, while it remains unclear whether brain decoding can be generalized\nto unseen subjects. This study aims to answer this question. We first\nconsolidate an image-fMRI dataset consisting of stimulus-image and\nfMRI-response pairs, involving 177 subjects in the movie-viewing task of the\nHuman Connectome Project (HCP). This dataset allows us to investigate the brain\ndecoding performance with the increase of participants. We then present a\nlearning paradigm that applies uniform processing across all subjects, instead\nof employing different network heads or tokenizers for individuals as in\nprevious methods, which can accommodate a large number of subjects to explore\nthe generalization capability across different subjects. A series of\nexperiments are conducted and we have the following findings. First, the\nnetwork exhibits clear generalization capabilities with the increase of\ntraining subjects. Second, the generalization capability is common to popular\nnetwork architectures (MLP, CNN and Transformer). Third, the generalization\nperformance is affected by the similarity between subjects. Our findings reveal\nthe inherent similarities in brain activities across individuals. With the\nemerging of larger and more comprehensive datasets, it is possible to train a\nbrain decoding foundation model in the future.Codes and models can be found at\nhttps://github.com/Xiangtaokong/TGBD.\n","authors":["Xiangtao Kong","Kexin Huang","Ping Li","Lei Zhang"],"pdf_url":"https://arxiv.org/pdf/2410.14445v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.14429v1","updated":"2024-10-18T12:48:22Z","published":"2024-10-18T12:48:22Z","title":"FashionR2R: Texture-preserving Rendered-to-Real Image Translation with\n  Diffusion Models","summary":"  Modeling and producing lifelike clothed human images has attracted\nresearchers' attention from different areas for decades, with the complexity\nfrom highly articulated and structured content. Rendering algorithms decompose\nand simulate the imaging process of a camera, while are limited by the accuracy\nof modeled variables and the efficiency of computation. Generative models can\nproduce impressively vivid human images, however still lacking in\ncontrollability and editability. This paper studies photorealism enhancement of\nrendered images, leveraging generative power from diffusion models on the\ncontrolled basis of rendering. We introduce a novel framework to translate\nrendered images into their realistic counterparts, which consists of two\nstages: Domain Knowledge Injection (DKI) and Realistic Image Generation (RIG).\nIn DKI, we adopt positive (real) domain finetuning and negative (rendered)\ndomain embedding to inject knowledge into a pretrained Text-to-image (T2I)\ndiffusion model. In RIG, we generate the realistic image corresponding to the\ninput rendered image, with a Texture-preserving Attention Control (TAC) to\npreserve fine-grained clothing textures, exploiting the decoupled features\nencoded in the UNet structure. Additionally, we introduce SynFashion dataset,\nfeaturing high-quality digital clothing images with diverse textures. Extensive\nexperimental results demonstrate the superiority and effectiveness of our\nmethod in rendered-to-real image translation.\n","authors":["Rui Hu","Qian He","Gaofeng He","Jiedong Zhuang","Huang Chen","Huafeng Liu","Huamin Wang"],"pdf_url":"https://arxiv.org/pdf/2410.14429v1.pdf","comment":"Accepted by NeurIPS 2024"},{"id":"http://arxiv.org/abs/2410.14423v1","updated":"2024-10-18T12:37:51Z","published":"2024-10-18T12:37:51Z","title":"Integrating Deep Learning with Fundus and Optical Coherence Tomography\n  for Cardiovascular Disease Prediction","summary":"  Early identification of patients at risk of cardiovascular diseases (CVD) is\ncrucial for effective preventive care, reducing healthcare burden, and\nimproving patients' quality of life. This study demonstrates the potential of\nretinal optical coherence tomography (OCT) imaging combined with fundus\nphotographs for identifying future adverse cardiac events. We used data from\n977 patients who experienced CVD within a 5-year interval post-image\nacquisition, alongside 1,877 control participants without CVD, totaling 2,854\nsubjects. We propose a novel binary classification network based on a\nMulti-channel Variational Autoencoder (MCVAE), which learns a latent embedding\nof patients' fundus and OCT images to classify individuals into two groups:\nthose likely to develop CVD in the future and those who are not. Our model,\ntrained on both imaging modalities, achieved promising results (AUROC 0.78 +/-\n0.02, accuracy 0.68 +/- 0.002, precision 0.74 +/- 0.02, sensitivity 0.73 +/-\n0.02, and specificity 0.68 +/- 0.01), demonstrating its efficacy in identifying\npatients at risk of future CVD events based on their retinal images. This study\nhighlights the potential of retinal OCT imaging and fundus photographs as\ncost-effective, non-invasive alternatives for predicting cardiovascular disease\nrisk. The widespread availability of these imaging techniques in optometry\npractices and hospitals further enhances their potential for large-scale CVD\nrisk screening. Our findings contribute to the development of standardized,\naccessible methods for early CVD risk identification, potentially improving\npreventive care strategies and patient outcomes.\n","authors":["Cynthia Maldonado-Garcia","Arezoo Zakeri","Alejandro F Frangi","Nishant Ravikumar"],"pdf_url":"https://arxiv.org/pdf/2410.14423v1.pdf","comment":"Part of the book series: Lecture Notes in Computer Science\n  ((LNCS,volume 15155))"},{"id":"http://arxiv.org/abs/2405.08431v4","updated":"2024-10-18T12:25:31Z","published":"2024-05-14T08:51:16Z","title":"Similarity and Quality Metrics for MR Image-To-Image Translation","summary":"  Image-to-image translation can create large impact in medical imaging, as\nimages can be synthetically transformed to other modalities, sequence types,\nhigher resolutions or lower noise levels. To ensure patient safety, these\nmethods should be validated by human readers, which requires a considerable\namount of time and costs. Quantitative metrics can effectively complement such\nstudies and provide reproducible and objective assessment of synthetic images.\nIf a reference is available, the similarity of MR images is frequently\nevaluated by SSIM and PSNR metrics, even though these metrics are not or too\nsensitive regarding specific distortions. When reference images to compare with\nare not available, non-reference quality metrics can reliably detect specific\ndistortions, such as blurriness. To provide an overview on distortion\nsensitivity, we quantitatively analyze 11 similarity (reference) and 12 quality\n(non-reference) metrics for assessing synthetic images. We additionally include\na metric on a downstream segmentation task. We investigate the sensitivity\nregarding 11 kinds of distortions and typical MR artifacts, and analyze the\ninfluence of different normalization methods on each metric and distortion.\nFinally, we derive recommendations for effective usage of the analyzed\nsimilarity and quality metrics for evaluation of image-to-image translation\nmodels.\n","authors":["Melanie Dohmen","Mark Klemens","Ivo Baltruschat","Tuan Truong","Matthias Lenga"],"pdf_url":"https://arxiv.org/pdf/2405.08431v4.pdf","comment":"21 pages, 8 figures, supplement with 16 pages, 10 figures, submitted\n  to Nature Scientific Reports"},{"id":"http://arxiv.org/abs/2409.08031v2","updated":"2024-10-18T12:22:11Z","published":"2024-09-12T13:23:24Z","title":"LED: Light Enhanced Depth Estimation at Night","summary":"  Nighttime camera-based depth estimation is a highly challenging task,\nespecially for autonomous driving applications, where accurate depth perception\nis essential for ensuring safe navigation. We aim to improve the reliability of\nperception systems at night time, where models trained on daytime data often\nfail in the absence of precise but costly LiDAR sensors. In this work, we\nintroduce Light Enhanced Depth (LED), a novel cost-effective approach that\nsignificantly improves depth estimation in low-light environments by harnessing\na pattern projected by high definition headlights available in modern vehicles.\nLED leads to significant performance boosts across multiple depth-estimation\narchitectures (encoder-decoder, Adabins, DepthFormer) both on synthetic and\nreal datasets. Furthermore, increased performances beyond illuminated areas\nreveal a holistic enhancement in scene understanding. Finally, we release the\nNighttime Synthetic Drive Dataset, a new synthetic and photo-realistic\nnighttime dataset, which comprises 49,990 comprehensively annotated images.\n","authors":["Simon de Moreau","Yasser Almehio","Andrei Bursuc","Hafid El-Idrissi","Bogdan Stanciulescu","Fabien Moutarde"],"pdf_url":"https://arxiv.org/pdf/2409.08031v2.pdf","comment":"Preprint. Code and dataset available on the project page :\n  https://simondemoreau.github.io/LED/"},{"id":"http://arxiv.org/abs/2406.08552v2","updated":"2024-10-18T12:05:21Z","published":"2024-06-12T18:00:08Z","title":"DiTFastAttn: Attention Compression for Diffusion Transformer Models","summary":"  Diffusion Transformers (DiT) excel at image and video generation but face\ncomputational challenges due to the quadratic complexity of self-attention\noperators. We propose DiTFastAttn, a post-training compression method to\nalleviate the computational bottleneck of DiT. We identify three key\nredundancies in the attention computation during DiT inference: (1) spatial\nredundancy, where many attention heads focus on local information; (2) temporal\nredundancy, with high similarity between the attention outputs of neighboring\nsteps; (3) conditional redundancy, where conditional and unconditional\ninferences exhibit significant similarity. We propose three techniques to\nreduce these redundancies: (1) Window Attention with Residual Sharing to reduce\nspatial redundancy; (2) Attention Sharing across Timesteps to exploit the\nsimilarity between steps; (3) Attention Sharing across CFG to skip redundant\ncomputations during conditional generation. We apply DiTFastAttn to DiT,\nPixArt-Sigma for image generation tasks, and OpenSora for video generation\ntasks. Our results show that for image generation, our method reduces up to 76%\nof the attention FLOPs and achieves up to 1.8x end-to-end speedup at\nhigh-resolution (2k x 2k) generation.\n","authors":["Zhihang Yuan","Hanling Zhang","Pu Lu","Xuefei Ning","Linfeng Zhang","Tianchen Zhao","Shengen Yan","Guohao Dai","Yu Wang"],"pdf_url":"https://arxiv.org/pdf/2406.08552v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.14400v1","updated":"2024-10-18T12:04:23Z","published":"2024-10-18T12:04:23Z","title":"Variable Aperture Bokeh Rendering via Customized Focal Plane Guidance","summary":"  Bokeh rendering is one of the most popular techniques in photography. It can\nmake photographs visually appealing, forcing users to focus their attentions on\nparticular area of image. However, achieving satisfactory bokeh effect usually\npresents significant challenge, since mobile cameras with restricted optical\nsystems are constrained, while expensive high-end DSLR lens with large aperture\nshould be needed. Therefore, many deep learning-based computational photography\nmethods have been developed to mimic the bokeh effect in recent years.\nNevertheless, most of these methods were limited to rendering bokeh effect in\ncertain single aperture. There lacks user-friendly bokeh rendering method that\ncan provide precise focal plane control and customised bokeh generation. There\nas well lacks authentic realistic bokeh dataset that can potentially promote\nbokeh learning on variable apertures. To address these two issues, in this\npaper, we have proposed an effective controllable bokeh rendering method, and\ncontributed a Variable Aperture Bokeh Dataset (VABD). In the proposed method,\nuser can customize focal plane to accurately locate concerned subjects and\nselect target aperture information for bokeh rendering. Experimental results on\npublic EBB! benchmark dataset and our constructed dataset VABD have\ndemonstrated that the customized focal plane together aperture prompt can\nbootstrap model to simulate realistic bokeh effect. The proposed method has\nachieved competitive state-of-the-art performance with only 4.4M parameters,\nwhich is much lighter than mainstream computational bokeh models. The\ncontributed dataset and source codes will be released on github\nhttps://github.com/MoTong-AI-studio/VABM.\n","authors":["Kang Chen","Shijun Yan","Aiwen Jiang","Han Li","Zhifeng Wang"],"pdf_url":"https://arxiv.org/pdf/2410.14400v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.14398v1","updated":"2024-10-18T12:02:21Z","published":"2024-10-18T12:02:21Z","title":"Dynamic Negative Guidance of Diffusion Models","summary":"  Negative Prompting (NP) is widely utilized in diffusion models, particularly\nin text-to-image applications, to prevent the generation of undesired features.\nIn this paper, we show that conventional NP is limited by the assumption of a\nconstant guidance scale, which may lead to highly suboptimal results, or even\ncomplete failure, due to the non-stationarity and state-dependence of the\nreverse process. Based on this analysis, we derive a principled technique\ncalled Dynamic Negative Guidance, which relies on a near-optimal time and state\ndependent modulation of the guidance without requiring additional training.\nUnlike NP, negative guidance requires estimating the posterior class\nprobability during the denoising process, which is achieved with limited\nadditional computational overhead by tracking the discrete Markov Chain during\nthe generative process. We evaluate the performance of DNG class-removal on\nMNIST and CIFAR10, where we show that DNG leads to higher safety, preservation\nof class balance and image quality when compared with baseline methods.\nFurthermore, we show that it is possible to use DNG with Stable Diffusion to\nobtain more accurate and less invasive guidance than NP.\n","authors":["Felix Koulischer","Johannes Deleu","Gabriel Raya","Thomas Demeester","Luca Ambrogioni"],"pdf_url":"https://arxiv.org/pdf/2410.14398v1.pdf","comment":"Paper currently under review. Submitted to ICLR 2025"},{"id":"http://arxiv.org/abs/2410.14389v1","updated":"2024-10-18T11:49:40Z","published":"2024-10-18T11:49:40Z","title":"SurgeryV2: Bridging the Gap Between Model Merging and Multi-Task\n  Learning with Deep Representation Surgery","summary":"  Model merging-based multitask learning (MTL) offers a promising approach for\nperforming MTL by merging multiple expert models without requiring access to\nraw training data. However, in this paper, we examine the merged model's\nrepresentation distribution and uncover a critical issue of \"representation\nbias\". This bias arises from a significant distribution gap between the\nrepresentations of the merged and expert models, leading to the suboptimal\nperformance of the merged MTL model. To address this challenge, we first\npropose a representation surgery solution called Surgery. Surgery is a\nlightweight, task-specific module that aligns the final layer representations\nof the merged model with those of the expert models, effectively alleviating\nbias and improving the merged model's performance. Despite these improvements,\na performance gap remains compared to the traditional MTL method. Further\nanalysis reveals that representation bias phenomena exist at each layer of the\nmerged model, and aligning representations only in the last layer is\ninsufficient for fully reducing systemic bias because biases introduced at each\nlayer can accumulate and interact in complex ways. To tackle this, we then\npropose a more comprehensive solution, deep representation surgery (also called\nSurgeryV2), which mitigates representation bias across all layers, and thus\nbridges the performance gap between model merging-based MTL and traditional\nMTL. Finally, we design an unsupervised optimization objective to optimize both\nthe Surgery and SurgeryV2 modules. Our experimental results show that\nincorporating these modules into state-of-the-art (SOTA) model merging schemes\nleads to significant performance gains. Notably, our SurgeryV2 scheme reaches\nalmost the same level as individual expert models or the traditional MTL model.\nThe code is available at \\url{https://github.com/EnnengYang/SurgeryV2}.\n","authors":["Enneng Yang","Li Shen","Zhenyi Wang","Guibing Guo","Xingwei Wang","Xiaocun Cao","Jie Zhang","Dacheng Tao"],"pdf_url":"https://arxiv.org/pdf/2410.14389v1.pdf","comment":"This paper is an extended version of our previous work\n  [arXiv:2402.02705] presented at ICML 2024"},{"id":"http://arxiv.org/abs/2410.14379v1","updated":"2024-10-18T11:07:12Z","published":"2024-10-18T11:07:12Z","title":"AnomalyNCD: Towards Novel Anomaly Class Discovery in Industrial\n  Scenarios","summary":"  In the industrial scenario, anomaly detection could locate but cannot\nclassify anomalies. To complete their capability, we study to automatically\ndiscover and recognize visual classes of industrial anomalies. In terms of\nmulti-class anomaly classification, previous methods cluster anomalies\nrepresented by frozen pre-trained models but often fail due to poor\ndiscrimination. Novel class discovery (NCD) has the potential to tackle this.\nHowever, it struggles with non-prominent and semantically weak anomalies that\nchallenge network learning focus. To address these, we introduce AnomalyNCD, a\nmulti-class anomaly classification framework compatible with existing anomaly\ndetection methods. This framework learns anomaly-specific features and\nclassifies anomalies in a self-supervised manner. Initially, a technique called\nMain Element Binarization (MEBin) is first designed, which segments primary\nanomaly regions into masks to alleviate the impact of incorrect detections on\nlearning. Subsequently, we employ mask-guided contrastive representation\nlearning to improve feature discrimination, which focuses network attention on\nisolated anomalous regions and reduces the confusion of erroneous inputs\nthrough re-corrected pseudo labels. Finally, to enable flexible classification\nat both region and image levels during inference, we develop a region merging\nstrategy that determines the overall image category based on the classified\nanomaly regions. Our method outperforms the state-of-the-art works on the MVTec\nAD and MTD datasets. Compared with the current methods, AnomalyNCD combined\nwith zero-shot anomaly detection method achieves a 10.8% $F_1$ gain, 8.8% NMI\ngain, and 9.5% ARI gain on MVTec AD, 12.8% $F_1$ gain, 5.7% NMI gain, and 10.8%\nARI gain on MTD. The source code is available at\nhttps://github.com/HUST-SLOW/AnomalyNCD.\n","authors":["Ziming Huang","Xurui Li","Haotian Liu","Feng Xue","Yuzhe Wang","Yu Zhou"],"pdf_url":"https://arxiv.org/pdf/2410.14379v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.14365v1","updated":"2024-10-18T10:51:10Z","published":"2024-10-18T10:51:10Z","title":"Impact of imperfect annotations on CNN training and performance for\n  instance segmentation and classification in digital pathology","summary":"  Segmentation and classification of large numbers of instances, such as cell\nnuclei, are crucial tasks in digital pathology for accurate diagnosis. However,\nthe availability of high-quality datasets for deep learning methods is often\nlimited due to the complexity of the annotation process. In this work, we\ninvestigate the impact of noisy annotations on the training and performance of\na state-of-the-art CNN model for the combined task of detecting, segmenting and\nclassifying nuclei in histopathology images. In this context, we investigate\nthe conditions for determining an appropriate number of training epochs to\nprevent overfitting to annotation noise during training. Our results indicate\nthat the utilisation of a small, correctly annotated validation set is\ninstrumental in avoiding overfitting and maintaining model performance to a\nlarge extent. Additionally, our findings underscore the beneficial role of\npre-training.\n","authors":["Laura Gálvez Jiménez","Christine Decaestecker"],"pdf_url":"https://arxiv.org/pdf/2410.14365v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.08102v2","updated":"2024-10-18T09:58:45Z","published":"2023-02-16T06:01:31Z","title":"Prompt Tuning of Deep Neural Networks for Speaker-adaptive Visual Speech\n  Recognition","summary":"  Visual Speech Recognition (VSR) aims to infer speech into text depending on\nlip movements alone. As it focuses on visual information to model the speech,\nits performance is inherently sensitive to personal lip appearances and\nmovements, and this makes the VSR models show degraded performance when they\nare applied to unseen speakers. In this paper, to remedy the performance\ndegradation of the VSR model on unseen speakers, we propose prompt tuning\nmethods of Deep Neural Networks (DNNs) for speaker-adaptive VSR. Specifically,\nmotivated by recent advances in Natural Language Processing (NLP), we finetune\nprompts on adaptation data of target speakers instead of modifying the\npre-trained model parameters. Different from the previous prompt tuning methods\nmainly limited to Transformer variant architecture, we explore different types\nof prompts, the addition, the padding, and the concatenation form prompts that\ncan be applied to the VSR model which is composed of CNN and Transformer in\ngeneral. With the proposed prompt tuning, we show that the performance of the\npre-trained VSR model on unseen speakers can be largely improved by using a\nsmall amount of adaptation data (e.g., less than 5 minutes), even if the\npre-trained model is already developed with large speaker variations. Moreover,\nby analyzing the performance and parameters of different types of prompts, we\ninvestigate when the prompt tuning is preferred over the finetuning methods.\nThe effectiveness of the proposed method is evaluated on both word- and\nsentence-level VSR databases, LRW-ID and GRID.\n","authors":["Minsu Kim","Hyung-Il Kim","Yong Man Ro"],"pdf_url":"https://arxiv.org/pdf/2302.08102v2.pdf","comment":"IEEE TPAMI"},{"id":"http://arxiv.org/abs/2410.14343v1","updated":"2024-10-18T09:51:43Z","published":"2024-10-18T09:51:43Z","title":"2D-3D Deformable Image Registration of Histology Slide and Micro-CT with\n  ML-based Initialization","summary":"  Recent developments in the registration of histology and micro-computed\ntomography ({\\mu}CT) have broadened the perspective of pathological\napplications such as virtual histology based on {\\mu}CT. This topic remains\nchallenging because of the low image quality of soft tissue CT. Additionally,\nsoft tissue samples usually deform during the histology slide preparation,\nmaking it difficult to correlate the structures between histology slide and\n{\\mu}CT. In this work, we propose a novel 2D-3D multi-modal deformable image\nregistration method. The method uses a machine learning (ML) based\ninitialization followed by the registration. The registration is finalized by\nan analytical out-of-plane deformation refinement. The method is evaluated on\ndatasets acquired from tonsil and tumor tissues. {\\mu}CTs of both\nphase-contrast and conventional absorption modalities are investigated. The\nregistration results from the proposed method are compared with those from\nintensity- and keypoint-based methods. The comparison is conducted using both\nvisual and fiducial-based evaluations. The proposed method demonstrates\nsuperior performance compared to the other two methods.\n","authors":["Junan Chen","Matteo Ronchetti","Verena Stehl","Van Nguyen","Muhannad Al Kallaa","Mahesh Thalwaththe Gedara","Claudia Lölkes","Stefan Moser","Maximilian Seidl","Matthias Wieczorek"],"pdf_url":"https://arxiv.org/pdf/2410.14343v1.pdf","comment":"12 pages, 4 figures"},{"id":"http://arxiv.org/abs/2410.14340v1","updated":"2024-10-18T09:51:14Z","published":"2024-10-18T09:51:14Z","title":"Zero-shot Action Localization via the Confidence of Large\n  Vision-Language Models","summary":"  Precise action localization in untrimmed video is vital for fields such as\nprofessional sports and minimally invasive surgery, where the delineation of\nparticular motions in recordings can dramatically enhance analysis. But in many\ncases, large scale datasets with video-label pairs for localization are\nunavailable, limiting the opportunity to fine-tune video-understanding models.\nRecent developments in large vision-language models (LVLM) address this need\nwith impressive zero-shot capabilities in a variety of video understanding\ntasks. However, the adaptation of image-based LVLMs, with their powerful visual\nquestion answering capabilities, to action localization in long-form video is\nstill relatively unexplored. To this end, we introduce a true ZEro-shot Action\nLocalization method (ZEAL). Specifically, we leverage the built-in action\nknowledge of a large language model (LLM) to inflate actions into\nhighly-detailed descriptions of the archetypal start and end of the action.\nThese descriptions serve as queries to LVLM for generating frame-level\nconfidence scores which can be aggregated to produce localization outputs. The\nsimplicity and flexibility of our method lends it amenable to more capable\nLVLMs as they are developed, and we demonstrate remarkable results in zero-shot\naction localization on a challenging benchmark, without any training.\n","authors":["Josiah Aklilu","Xiaohan Wang","Serena Yeung-Levy"],"pdf_url":"https://arxiv.org/pdf/2410.14340v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.14334v1","updated":"2024-10-18T09:44:35Z","published":"2024-10-18T09:44:35Z","title":"Evaluating the evaluators: Towards human-aligned metrics for missing\n  markers reconstruction","summary":"  Animation data is often obtained through optical motion capture systems,\nwhich utilize a multitude of cameras to establish the position of optical\nmarkers. However, system errors or occlusions can result in missing markers,\nthe manual cleaning of which can be time-consuming. This has sparked interest\nin machine learning-based solutions for missing marker reconstruction in the\nacademic community. Most academic papers utilize a simplistic mean square error\nas the main metric. In this paper, we show that this metric does not correlate\nwith subjective perception of the fill quality. We introduce and evaluate a set\nof better-correlated metrics that can drive progress in the field.\n","authors":["Taras Kucherenko","Derek Peristy","Judith Bütepage"],"pdf_url":"https://arxiv.org/pdf/2410.14334v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.14332v1","updated":"2024-10-18T09:44:25Z","published":"2024-10-18T09:44:25Z","title":"Croc: Pretraining Large Multimodal Models with Cross-Modal Comprehension","summary":"  Recent advances in Large Language Models (LLMs) have catalyzed the\ndevelopment of Large Multimodal Models (LMMs). However, existing research\nprimarily focuses on tuning language and image instructions, ignoring the\ncritical pretraining phase where models learn to process textual and visual\nmodalities jointly. In this paper, we propose a new pretraining paradigm for\nLMMs to enhance the visual comprehension capabilities of LLMs by introducing a\nnovel cross-modal comprehension stage. Specifically, we design a dynamically\nlearnable prompt token pool and employ the Hungarian algorithm to replace part\nof the original visual tokens with the most relevant prompt tokens. Then, we\nconceptualize visual tokens as analogous to a \"foreign language\" for the LLMs\nand propose a mixed attention mechanism with bidirectional visual attention and\nunidirectional textual attention to comprehensively enhance the understanding\nof visual tokens. Meanwhile, we integrate a detailed caption generation task,\nleveraging rich descriptions to further facilitate LLMs in understanding visual\nsemantic information. After pretraining on 1.5 million publicly accessible\ndata, we present a new foundation model called Croc. Experimental results\ndemonstrate that Croc achieves new state-of-the-art performance on massive\nvision-language benchmarks. To support reproducibility and facilitate further\nresearch, we release the training code and pre-trained model weights at\nhttps://github.com/deepglint/Croc.\n","authors":["Yin Xie","Kaicheng Yang","Ninghua Yang","Weimo Deng","Xiangzi Dai","Tiancheng Gu","Yumeng Wang","Xiang An","Yongle Zhao","Ziyong Feng","Jiankang Deng"],"pdf_url":"https://arxiv.org/pdf/2410.14332v1.pdf","comment":"18 pages, 11 figures"},{"id":"http://arxiv.org/abs/2410.14326v1","updated":"2024-10-18T09:37:38Z","published":"2024-10-18T09:37:38Z","title":"Fast proxy centers for Jeffreys centroids: The Jeffreys-Fisher-Rao and\n  the inductive Gauss-Bregman centers","summary":"  The symmetric Kullback-Leibler centroid also called the Jeffreys centroid of\na set of mutually absolutely continuous probability distributions on a measure\nspace provides a notion of centrality which has proven useful in many tasks\nincluding information retrieval, information fusion, and clustering in image,\nvideo and sound processing. However, the Jeffreys centroid is not available in\nclosed-form for sets of categorical or normal distributions, two widely used\nstatistical models, and thus need to be approximated numerically in practice.\nIn this paper, we first propose the new Jeffreys-Fisher-Rao center defined as\nthe Fisher-Rao midpoint of the sided Kullback-Leibler centroids as a plug-in\nreplacement of the Jeffreys centroid. This Jeffreys-Fisher-Rao center admits a\ngeneric formula for uni-parameter exponential family distributions, and\nclosed-form formula for categorical and normal distributions, matches exactly\nthe Jeffreys centroid for same-mean normal distributions, and is experimentally\nobserved in practice to be close to the Jeffreys centroid. Second, we define a\nnew type of inductive centers generalizing the principle of Gauss\narithmetic-geometric double sequence mean for pairs of densities of any given\nexponential family. This center is shown experimentally to approximate very\nwell the Jeffreys centroid and is suggested to use when the Jeffreys-Fisher-Rao\ncenter is not available in closed form. Moreover, this Gauss-Bregman inductive\ncenter always converges and matches the Jeffreys centroid for sets of same-mean\nnormal distributions. We report on our experiments demonstrating the use of the\nJeffreys-Fisher-Rao and Gauss-Bregman centers instead of the Jeffreys centroid.\nFinally, we conclude this work by reinterpreting these fast proxy centers of\nJeffreys centroids under the lens of dually flat spaces in information\ngeometry.\n","authors":["Frank Nielsen"],"pdf_url":"https://arxiv.org/pdf/2410.14326v1.pdf","comment":"35 pages, 10 figures"},{"id":"http://arxiv.org/abs/2410.14324v1","updated":"2024-10-18T09:36:10Z","published":"2024-10-18T09:36:10Z","title":"HiCo: Hierarchical Controllable Diffusion Model for Layout-to-image\n  Generation","summary":"  The task of layout-to-image generation involves synthesizing images based on\nthe captions of objects and their spatial positions. Existing methods still\nstruggle in complex layout generation, where common bad cases include object\nmissing, inconsistent lighting, conflicting view angles, etc. To effectively\naddress these issues, we propose a \\textbf{Hi}erarchical \\textbf{Co}ntrollable\n(HiCo) diffusion model for layout-to-image generation, featuring object\nseperable conditioning branch structure. Our key insight is to achieve spatial\ndisentanglement through hierarchical modeling of layouts. We use a multi branch\nstructure to represent hierarchy and aggregate them in fusion module. To\nevaluate the performance of multi-objective controllable layout generation in\nnatural scenes, we introduce the HiCo-7K benchmark, derived from the GRIT-20M\ndataset and manually cleaned. https://github.com/360CVGroup/HiCo_T2I.\n","authors":["Bo Cheng","Yuhang Ma","Liebucha Wu","Shanyuan Liu","Ao Ma","Xiaoyu Wu","Dawei Leng","Yuhui Yin"],"pdf_url":"https://arxiv.org/pdf/2410.14324v1.pdf","comment":"NeurIPS2024"},{"id":"http://arxiv.org/abs/2407.12013v2","updated":"2024-10-18T08:57:30Z","published":"2024-06-26T12:33:34Z","title":"Dating ancient manuscripts using radiocarbon and AI-based writing style\n  analysis","summary":"  Determining the chronology of ancient handwritten manuscripts is essential\nfor reconstructing the evolution of ideas. For the Dead Sea Scrolls, this is\nparticularly important. However, there is an almost complete lack of\ndate-bearing manuscripts evenly distributed across the timeline and written in\nsimilar scripts available for palaeographic comparison. Here, we present Enoch,\na state-of-the-art AI-based date-prediction model, trained on the basis of new\nradiocarbon-dated samples of the scrolls. Enoch uses established\nhandwriting-style descriptors and applies Bayesian ridge regression. The\nchallenge of this study is that the number of radiocarbon-dated manuscripts is\nsmall, while current machine learning requires an abundance of training data.\nWe show that by using combined angular and allographic writing style feature\nvectors and applying Bayesian ridge regression, Enoch could predict the\nradiocarbon-based dates from style, supported by leave-one-out validation, with\nvaried MAEs of 27.9 to 30.7 years relative to the radiocarbon dating. Enoch was\nthen used to estimate the dates of 135 unseen manuscripts, revealing that 79\nper cent of the samples were considered 'realistic' upon palaeographic post-hoc\nevaluation. We present a new chronology of the scrolls. The radiocarbon ranges\nand Enoch's style-based predictions are often older than the traditionally\nassumed palaeographic estimates. In the range of 300-50 BCE, Enoch's date\nprediction provides an improved granularity. The study is in line with current\ndevelopments in multimodal machine-learning techniques, and the methods can be\nused for date prediction in other partially-dated manuscript collections. This\nresearch shows how Enoch's quantitative, probability-based approach can be a\ntool for palaeographers and historians, re-dating ancient Jewish key texts and\ncontributing to current debates on Jewish and Christian origins.\n","authors":["Mladen Popović","Maruf A. Dhali","Lambert Schomaker","Johannes van der Plicht","Kaare Lund Rasmussen","Jacopo La Nasa","Ilaria Degano","Maria Perla Colombini","Eibert Tigchelaar"],"pdf_url":"https://arxiv.org/pdf/2407.12013v2.pdf","comment":"16 pages of main article, 103 pages of supplementary materials; the\n  first version of this article is originally prepared in July 2023 after the\n  completion of all the experiments"},{"id":"http://arxiv.org/abs/2410.14285v1","updated":"2024-10-18T08:40:26Z","published":"2024-10-18T08:40:26Z","title":"Advanced Underwater Image Quality Enhancement via Hybrid\n  Super-Resolution Convolutional Neural Networks and Multi-Scale Retinex-Based\n  Defogging Techniques","summary":"  The difficulties of underwater image degradation due to light scattering,\nabsorption, and fog-like particles which lead to low resolution and poor\nvisibility are discussed in this study report. We suggest a sophisticated\nhybrid strategy that combines Multi-Scale Retinex (MSR) defogging methods with\nSuper-Resolution Convolutional Neural Networks (SRCNN) to address these\nproblems. The Retinex algorithm mimics human visual perception to reduce uneven\nlighting and fogging, while the SRCNN component improves the spatial resolution\nof underwater photos.Through the combination of these methods, we are able to\nenhance the clarity, contrast, and colour restoration of underwater images,\noffering a reliable way to improve image quality in difficult underwater\nconditions. The research conducts extensive experiments on real-world\nunderwater datasets to further illustrate the efficacy of the suggested\napproach. In terms of sharpness, visibility, and feature retention,\nquantitative evaluation which use metrics like the Structural Similarity Index\nMeasure (SSIM) and Peak Signal-to-Noise Ratio (PSNR) demonstrates notable\nadvances over conventional techniques.In real-time underwater applications like\nmarine exploration, underwater robotics, and autonomous underwater vehicles,\nwhere clear and high-resolution imaging is crucial for operational success, the\ncombination of deep learning and conventional image processing techniques\noffers a computationally efficient framework with superior results.\n","authors":["Yugandhar Reddy Gogireddy","Jithendra Reddy Gogireddy"],"pdf_url":"https://arxiv.org/pdf/2410.14285v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.14283v1","updated":"2024-10-18T08:39:56Z","published":"2024-10-18T08:39:56Z","title":"Takin-ADA: Emotion Controllable Audio-Driven Animation with Canonical\n  and Landmark Loss Optimization","summary":"  Existing audio-driven facial animation methods face critical challenges,\nincluding expression leakage, ineffective subtle expression transfer, and\nimprecise audio-driven synchronization. We discovered that these issues stem\nfrom limitations in motion representation and the lack of fine-grained control\nover facial expressions. To address these problems, we present Takin-ADA, a\nnovel two-stage approach for real-time audio-driven portrait animation. In the\nfirst stage, we introduce a specialized loss function that enhances subtle\nexpression transfer while reducing unwanted expression leakage. The second\nstage utilizes an advanced audio processing technique to improve lip-sync\naccuracy. Our method not only generates precise lip movements but also allows\nflexible control over facial expressions and head motions. Takin-ADA achieves\nhigh-resolution (512x512) facial animations at up to 42 FPS on an RTX 4090 GPU,\noutperforming existing commercial solutions. Extensive experiments demonstrate\nthat our model significantly surpasses previous methods in video quality,\nfacial dynamics realism, and natural head movements, setting a new benchmark in\nthe field of audio-driven facial animation.\n","authors":["Bin Lin","Yanzhen Yu","Jianhao Ye","Ruitao Lv","Yuguang Yang","Ruoye Xie","Pan Yu","Hongbin Zhou"],"pdf_url":"https://arxiv.org/pdf/2410.14283v1.pdf","comment":"under review"},{"id":"http://arxiv.org/abs/2410.14282v1","updated":"2024-10-18T08:39:49Z","published":"2024-10-18T08:39:49Z","title":"You Only Look Twice! for Failure Causes Identification of Drill Bits","summary":"  Efficient identification of the root causes of drill bit failure is crucial\ndue to potential impacts such as operational losses, safety threats, and\ndelays. Early recognition of these failures enables proactive maintenance,\nreducing risks and financial losses associated with unforeseen breakdowns and\nprolonged downtime. Thus, our study investigates various causes of drill bit\nfailure using images of different blades. The process involves annotating\ncutters with their respective locations and damage types, followed by the\ndevelopment of two YOLO Location and Damage Cutter Detection models, as well as\nmulti-class multi-label Decision Tree and Random Forests models to identify the\ncauses of failure by assessing the cutters' location and damage type.\nAdditionally, RRFCI is proposed for the classification of failure causes.\nNotably, the cutter location detection model achieved a high score of 0.97 mPA,\nand the cutter damage detection model yielded a 0.49 mPA. The rule-based\napproach over-performed both DT and RF in failure cause identification,\nachieving a macro-average F1-score of 0.94 across all damage causes. The\nintegration of the complete automated pipeline successfully identified 100\\% of\nthe 24 failure causes when tested on independent sets of ten drill bits,\nshowcasing its potential to efficiently assist experts in identifying the root\ncauses of drill bit damages.\n","authors":["Asma Yamani","Nehal Al-Otaiby","Haifa Al-Shemmeri","Imane Boudellioua"],"pdf_url":"https://arxiv.org/pdf/2410.14282v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.14279v1","updated":"2024-10-18T08:35:57Z","published":"2024-10-18T08:35:57Z","title":"ClearSR: Latent Low-Resolution Image Embeddings Help Diffusion-Based\n  Real-World Super Resolution Models See Clearer","summary":"  We present ClearSR, a new method that can better take advantage of latent\nlow-resolution image (LR) embeddings for diffusion-based real-world image\nsuper-resolution (Real-ISR). Previous Real-ISR models mostly focus on how to\nactivate more generative priors of text-to-image diffusion models to make the\noutput high-resolution (HR) images look better. However, since these methods\nrely too much on the generative priors, the content of the output images is\noften inconsistent with the input LR ones. To mitigate the above issue, in this\nwork, we explore using latent LR embeddings to constrain the control signals\nfrom ControlNet, and extract LR information at both detail and structure\nlevels. We show that the proper use of latent LR embeddings can produce\nhigher-quality control signals, which enables the super-resolution results to\nbe more consistent with the LR image and leads to clearer visual results. In\naddition, we also show that latent LR embeddings can be used to control the\ninference stage, allowing for the improvement of fidelity and generation\nability simultaneously. Experiments demonstrate that our model can achieve\nbetter performance across multiple metrics on several test sets and generate\nmore consistent SR results with LR images than existing methods. Our code will\nbe made publicly available.\n","authors":["Yuhao Wan","Peng-Tao Jiang","Qibin Hou","Hao Zhang","Jinwei Chen","Ming-Ming Cheng","Bo Li"],"pdf_url":"https://arxiv.org/pdf/2410.14279v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.08091v2","updated":"2024-10-18T08:27:05Z","published":"2024-10-10T16:33:27Z","title":"Distribution Guidance Network for Weakly Supervised Point Cloud Semantic\n  Segmentation","summary":"  Despite alleviating the dependence on dense annotations inherent to fully\nsupervised methods, weakly supervised point cloud semantic segmentation suffers\nfrom inadequate supervision signals. In response to this challenge, we\nintroduce a novel perspective that imparts auxiliary constraints by regulating\nthe feature space under weak supervision. Our initial investigation identifies\nwhich distributions accurately characterize the feature space, subsequently\nleveraging this priori to guide the alignment of the weakly supervised\nembeddings. Specifically, we analyze the superiority of the mixture of von\nMises-Fisher distributions (moVMF) among several common distribution\ncandidates. Accordingly, we develop a Distribution Guidance Network (DGNet),\nwhich comprises a weakly supervised learning branch and a distribution\nalignment branch. Leveraging reliable clustering initialization derived from\nthe weakly supervised learning branch, the distribution alignment branch\nalternately updates the parameters of the moVMF and the network, ensuring\nalignment with the moVMF-defined latent space. Extensive experiments validate\nthe rationality and effectiveness of our distribution choice and network\ndesign. Consequently, DGNet achieves state-of-the-art performance under\nmultiple datasets and various weakly supervised settings.\n","authors":["Zhiyi Pan","Wei Gao","Shan Liu","Ge Li"],"pdf_url":"https://arxiv.org/pdf/2410.08091v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2405.02512v2","updated":"2024-10-18T08:25:52Z","published":"2024-05-03T22:55:56Z","title":"SatSwinMAE: Efficient Autoencoding for Multiscale Time-series Satellite\n  Imagery","summary":"  Recent advancements in foundation models have significantly impacted various\nfields, including natural language processing, computer vision, and multi-modal\ntasks. One area that stands to benefit greatly is Earth observation, where\nthese models can efficiently process large-scale, unlabeled geospatial data. In\nthis work we extend the SwinMAE model to integrate temporal information for\nsatellite time-series data. The architecture employs a hierarchical 3D Masked\nAutoencoder (MAE) with Video Swin Transformer blocks to effectively capture\nmulti-scale spatio-temporal dependencies in satellite imagery. To enhance\ntransfer learning, we incorporate both encoder and decoder pretrained weights,\nalong with skip connections to preserve scale-specific information. This forms\nan architecture similar to SwinUNet with an additional temporal component. Our\napproach shows significant performance improvements over existing\nstate-of-the-art foundation models for all the evaluated downstream tasks: land\ncover segmentation, building density prediction, flood mapping, wildfire scar\nmapping and multi-temporal crop segmentation. Particularly, in the land cover\nsegmentation task of the PhilEO Bench dataset, it outperforms other geospatial\nfoundation models with a 10.4% higher accuracy.\n","authors":["Yohei Nakayama","Jiawei Su","Luis M. Pazos-Outón"],"pdf_url":"https://arxiv.org/pdf/2405.02512v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.14265v1","updated":"2024-10-18T08:20:37Z","published":"2024-10-18T08:20:37Z","title":"HYPNOS : Highly Precise Foreground-focused Diffusion Finetuning for\n  Inanimate Objects","summary":"  In recent years, personalized diffusion-based text-to-image generative tasks\nhave been a hot topic in computer vision studies. A robust diffusion model is\ndetermined by its ability to perform near-perfect reconstruction of certain\nproduct outcomes given few related input samples. Unfortunately, the current\nprominent diffusion-based finetuning technique falls short in maintaining the\nforeground object consistency while being constrained to produce diverse\nbackgrounds in the image outcome. In the worst scenario, the overfitting issue\nmay occur, meaning that the foreground object is less controllable due to the\ncondition above, for example, the input prompt information is transferred\nambiguously to both foreground and background regions, instead of the supposed\nbackground region only. To tackle the issues above, we proposed Hypnos, a\nhighly precise foreground-focused diffusion finetuning technique. On the image\nlevel, this strategy works best for inanimate object generation tasks, and to\ndo so, Hypnos implements two main approaches, namely: (i) a content-centric\nprompting strategy and (ii) the utilization of our additional\nforeground-focused discriminative module. The utilized module is connected with\nthe diffusion model and finetuned with our proposed set of supervision\nmechanism. Combining the strategies above yielded to the foreground-background\ndisentanglement capability of the diffusion model. Our experimental results\nshowed that the proposed strategy gave a more robust performance and visually\npleasing results compared to the former technique. For better elaborations, we\nalso provided extensive studies to assess the fruitful outcomes above, which\nreveal how personalization behaves in regard to several training conditions.\n","authors":["Oliverio Theophilus Nathanael","Jonathan Samuel Lumentut","Nicholas Hans Muliawan","Edbert Valencio Angky","Felix Indra Kurniadi","Alfi Yusrotis Zakiyyah","Jeklin Harefa"],"pdf_url":"https://arxiv.org/pdf/2410.14265v1.pdf","comment":"26 pages, 12 figures, to appear on the Rich Media with Generative AI\n  workshop in conjunction with Asian Conference on Computer Vision (ACCV) 2024"},{"id":"http://arxiv.org/abs/2406.00125v3","updated":"2024-10-18T08:18:36Z","published":"2024-05-31T18:32:46Z","title":"TotalVibeSegmentator: Full Body MRI Segmentation for the NAKO and UK\n  Biobank","summary":"  Objectives: To present a publicly available torso segmentation network for\nlarge epidemiology datasets on volumetric interpolated breath-hold examination\n(VIBE) images. Materials & Methods: We extracted preliminary segmentations from\nTotalSegmentator, spine, and body composition networks for VIBE images, then\nimproved them iteratively and retrained a nnUNet network. Using subsets of NAKO\n(85 subjects) and UK Biobank (16 subjects), we evaluated with Dice-score on a\nholdout set (12 subjects) and existing organ segmentation approach (1000\nsubjects), generating 71 semantic segmentation types for VIBE images. We\nprovide an additional network for the vertebra segments 22 individual vertebra\ntypes. Results: We achieved an average Dice score of 0.89 +- 0.07 overall 71\nsegmentation labels. We scored > 0.90 Dice-score on the abdominal organs except\nfor the pancreas with a Dice of 0.70. Conclusion: Our work offers a detailed\nand refined publicly available full torso segmentation on VIBE images.\n","authors":["Robert Graf","Paul-Sören Platzek","Evamaria Olga Riedel","Constanze Ramschütz","Sophie Starck","Hendrik Kristian Möller","Matan Atad","Henry Völzke","Robin Bülow","Carsten Oliver Schmidt","Julia Rüdebusch","Matthias Jung","Marco Reisert","Jakob Weiss","Maximilian Löffler","Fabian Bamberg","Bene Wiestler","Johannes C. Paetzold","Daniel Rueckert","Jan Stefan Kirschke"],"pdf_url":"https://arxiv.org/pdf/2406.00125v3.pdf","comment":"https://github.com/robert-graf/TotalVibeSegmentator"},{"id":"http://arxiv.org/abs/2410.14250v1","updated":"2024-10-18T08:01:36Z","published":"2024-10-18T08:01:36Z","title":"Vision-Language Navigation with Energy-Based Policy","summary":"  Vision-language navigation (VLN) requires an agent to execute actions\nfollowing human instructions. Existing VLN models are optimized through expert\ndemonstrations by supervised behavioural cloning or incorporating manual reward\nengineering. While straightforward, these efforts overlook the accumulation of\nerrors in the Markov decision process, and struggle to match the distribution\nof the expert policy. Going beyond this, we propose an Energy-based Navigation\nPolicy (ENP) to model the joint state-action distribution using an energy-based\nmodel. At each step, low energy values correspond to the state-action pairs\nthat the expert is most likely to perform, and vice versa. Theoretically, the\noptimization objective is equivalent to minimizing the forward divergence\nbetween the occupancy measure of the expert and ours. Consequently, ENP learns\nto globally align with the expert policy by maximizing the likelihood of the\nactions and modeling the dynamics of the navigation states in a collaborative\nmanner. With a variety of VLN architectures, ENP achieves promising\nperformances on R2R, REVERIE, RxR, and R2R-CE, unleashing the power of existing\nVLN models.\n","authors":["Rui Liu","Wenguan Wang","Yi Yang"],"pdf_url":"https://arxiv.org/pdf/2410.14250v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.14247v1","updated":"2024-10-18T07:52:03Z","published":"2024-10-18T07:52:03Z","title":"ERDDCI: Exact Reversible Diffusion via Dual-Chain Inversion for\n  High-Quality Image Editing","summary":"  Diffusion models (DMs) have been successfully applied to real image editing.\nThese models typically invert images into latent noise vectors used to\nreconstruct the original images (known as inversion), and then edit them during\nthe inference process. However, recent popular DMs often rely on the assumption\nof local linearization, where the noise injected during the inversion process\nis expected to approximate the noise removed during the inference process.\nWhile DM efficiently generates images under this assumption, it can also\naccumulate errors during the diffusion process due to the assumption,\nultimately negatively impacting the quality of real image reconstruction and\nediting. To address this issue, we propose a novel method, referred to as\nERDDCI (Exact Reversible Diffusion via Dual-Chain Inversion). ERDDCI uses the\nnew Dual-Chain Inversion (DCI) for joint inference to derive an exact\nreversible diffusion process. By using DCI, our method effectively avoids the\ncumbersome optimization process in existing inversion approaches and achieves\nhigh-quality image editing. Additionally, to accommodate image operations under\nhigh guidance scales, we introduce a dynamic control strategy that enables more\nrefined image reconstruction and editing. Our experiments demonstrate that\nERDDCI significantly outperforms state-of-the-art methods in a 50-step\ndiffusion process. It achieves rapid and precise image reconstruction with an\nSSIM of 0.999 and an LPIPS of 0.001, and also delivers competitive results in\nimage editing.\n","authors":["Jimin Dai","Yingzhen Zhang","Shuo Chen","Jian Yang","Lei Luo"],"pdf_url":"https://arxiv.org/pdf/2410.14247v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.14245v1","updated":"2024-10-18T07:51:31Z","published":"2024-10-18T07:51:31Z","title":"PReP: Efficient context-based shape retrieval for missing parts","summary":"  In this paper we study the problem of shape part retrieval in the point cloud\ndomain. Shape retrieval methods in the literature rely on the presence of an\nexisting query object, but what if the part we are looking for is not\navailable? We present Part Retrieval Pipeline (PReP), a pipeline that\ncreatively utilizes metric learning techniques along with a trained\nclassification model to measure the suitability of potential replacement parts\nfrom a database, as part of an application scenario targeting circular economy.\nThrough an innovative training procedure with increasing difficulty, it is able\nto learn to recognize suitable parts relying only on shape context. Thanks to\nits low parameter size and computational requirements, it can be used to sort\nthrough a warehouse of potentially tens of thousand of spare parts in just a\nfew seconds. We also establish an alternative baseline approach to compare\nagainst, and extensively document the unique challenges associated with this\ntask, as well as identify the design choices to solve them.\n","authors":["Vlassis Fotis","Ioannis Romanelis","Georgios Mylonas","Athanasios Kalogeras","Konstantinos Moustakas"],"pdf_url":"https://arxiv.org/pdf/2410.14245v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.14242v1","updated":"2024-10-18T07:47:59Z","published":"2024-10-18T07:47:59Z","title":"Pseudo-label Refinement for Improving Self-Supervised Learning Systems","summary":"  Self-supervised learning systems have gained significant attention in recent\nyears by leveraging clustering-based pseudo-labels to provide supervision\nwithout the need for human annotations. However, the noise in these\npseudo-labels caused by the clustering methods poses a challenge to the\nlearning process leading to degraded performance. In this work, we propose a\npseudo-label refinement (SLR) algorithm to address this issue. The cluster\nlabels from the previous epoch are projected to the current epoch\ncluster-labels space and a linear combination of the new label and the\nprojected label is computed as a soft refined label containing the information\nfrom the previous epoch clusters as well as from the current epoch. In contrast\nto the common practice of using the maximum value as a cluster/class indicator,\nwe employ hierarchical clustering on these soft pseudo-labels to generate\nrefined hard-labels. This approach better utilizes the information embedded in\nthe soft labels, outperforming the simple maximum value approach for hard label\ngeneration. The effectiveness of the proposed SLR algorithm is evaluated in the\ncontext of person re-identification (Re-ID) using unsupervised domain\nadaptation (UDA). Experimental results demonstrate that the modified Re-ID\nbaseline, incorporating the SLR algorithm, achieves significantly improved mean\nAverage Precision (mAP) performance in various UDA tasks, including\nreal-to-synthetic, synthetic-to-real, and different real-to-real scenarios.\nThese findings highlight the efficacy of the SLR algorithm in enhancing the\nperformance of self-supervised learning systems.\n","authors":[" Zia-ur-Rehman","Arif Mahmood","Wenxiong Kang"],"pdf_url":"https://arxiv.org/pdf/2410.14242v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.14238v1","updated":"2024-10-18T07:40:41Z","published":"2024-10-18T07:40:41Z","title":"Storyboard guided Alignment for Fine-grained Video Action Recognition","summary":"  Fine-grained video action recognition can be conceptualized as a video-text\nmatching problem. Previous approaches often rely on global video semantics to\nconsolidate video embeddings, which can lead to misalignment in video-text\npairs due to a lack of understanding of action semantics at an atomic\ngranularity level. To tackle this challenge, we propose a multi-granularity\nframework based on two observations: (i) videos with different global semantics\nmay share similar atomic actions or appearances, and (ii) atomic actions within\na video can be momentary, slow, or even non-directly related to the global\nvideo semantics. Inspired by the concept of storyboarding, which disassembles a\nscript into individual shots, we enhance global video semantics by generating\nfine-grained descriptions using a pre-trained large language model. These\ndetailed descriptions capture common atomic actions depicted in videos. A\nfiltering metric is proposed to select the descriptions that correspond to the\natomic actions present in both the videos and the descriptions. By employing\nglobal semantics and fine-grained descriptions, we can identify key frames in\nvideos and utilize them to aggregate embeddings, thereby making the embedding\nmore accurate. Extensive experiments on various video action recognition\ndatasets demonstrate superior performance of our proposed method in supervised,\nfew-shot, and zero-shot settings.\n","authors":["Enqi Liu","Liyuan Pan","Yan Yang","Yiran Zhong","Zhijing Wu","Xinxiao Wu","Liu Liu"],"pdf_url":"https://arxiv.org/pdf/2410.14238v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2308.05822v3","updated":"2024-10-18T07:24:54Z","published":"2023-08-10T18:43:44Z","title":"Encode-Store-Retrieve: Augmenting Human Memory through Language-Encoded\n  Egocentric Perception","summary":"  We depend on our own memory to encode, store, and retrieve our experiences.\nHowever, memory lapses can occur. One promising avenue for achieving memory\naugmentation is through the use of augmented reality head-mounted displays to\ncapture and preserve egocentric videos, a practice commonly referred to as\nlifelogging. However, a significant challenge arises from the sheer volume of\nvideo data generated through lifelogging, as the current technology lacks the\ncapability to encode and store such large amounts of data efficiently. Further,\nretrieving specific information from extensive video archives requires\nsubstantial computational power, further complicating the task of quickly\naccessing desired content. To address these challenges, we propose a memory\naugmentation agent that involves leveraging natural language encoding for video\ndata and storing them in a vector database. This approach harnesses the power\nof large vision language models to perform the language encoding process.\nAdditionally, we propose using large language models to facilitate natural\nlanguage querying. Our agent underwent extensive evaluation using the QA-Ego4D\ndataset and achieved state-of-the-art results with a BLEU score of 8.3,\noutperforming conventional machine learning models that scored between 3.4 and\n5.8. Additionally, we conducted a user study in which participants interacted\nwith the human memory augmentation agent through episodic memory and open-ended\nquestions. The results of this study show that the agent results in\nsignificantly better recall performance on episodic memory tasks compared to\nhuman participants. The results also highlight the agent's practical\napplicability and user acceptance.\n","authors":["Junxiao Shen","John Dudley","Per Ola Kristensson"],"pdf_url":"https://arxiv.org/pdf/2308.05822v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.18791v3","updated":"2024-10-18T07:21:56Z","published":"2024-03-27T17:35:24Z","title":"Object Pose Estimation via the Aggregation of Diffusion Features","summary":"  Estimating the pose of objects from images is a crucial task of 3D scene\nunderstanding, and recent approaches have shown promising results on very large\nbenchmarks. However, these methods experience a significant performance drop\nwhen dealing with unseen objects. We believe that it results from the limited\ngeneralizability of image features. To address this problem, we have an\nin-depth analysis on the features of diffusion models, e.g. Stable Diffusion,\nwhich hold substantial potential for modeling unseen objects. Based on this\nanalysis, we then innovatively introduce these diffusion features for object\npose estimation. To achieve this, we propose three distinct architectures that\ncan effectively capture and aggregate diffusion features of different\ngranularity, greatly improving the generalizability of object pose estimation.\nOur approach outperforms the state-of-the-art methods by a considerable margin\non three popular benchmark datasets, LM, O-LM, and T-LESS. In particular, our\nmethod achieves higher accuracy than the previous best arts on unseen objects:\n97.9% vs. 93.5% on Unseen LM, 85.9% vs. 76.3% on Unseen O-LM, showing the\nstrong generalizability of our method. Our code is released at\nhttps://github.com/Tianfu18/diff-feats-pose.\n","authors":["Tianfu Wang","Guosheng Hu","Hongguang Wang"],"pdf_url":"https://arxiv.org/pdf/2403.18791v3.pdf","comment":"Accepted to CVPR2024, fix typo"},{"id":"http://arxiv.org/abs/2410.09421v2","updated":"2024-10-18T07:10:38Z","published":"2024-10-12T07:56:47Z","title":"VLFeedback: A Large-Scale AI Feedback Dataset for Large Vision-Language\n  Models Alignment","summary":"  As large vision-language models (LVLMs) evolve rapidly, the demand for\nhigh-quality and diverse data to align these models becomes increasingly\ncrucial. However, the creation of such data with human supervision proves\ncostly and time-intensive. In this paper, we investigate the efficacy of AI\nfeedback to scale supervision for aligning LVLMs. We introduce VLFeedback, the\nfirst large-scale vision-language feedback dataset, comprising over 82K\nmulti-modal instructions and comprehensive rationales generated by\noff-the-shelf models without human annotations. To evaluate the effectiveness\nof AI feedback for vision-language alignment, we train Silkie, an LVLM\nfine-tuned via direct preference optimization on VLFeedback. Silkie showcases\nexceptional performance regarding helpfulness, visual faithfulness, and safety\nmetrics. It outperforms its base model by 6.9\\% and 9.5\\% in perception and\ncognition tasks, reduces hallucination issues on MMHal-Bench, and exhibits\nenhanced resilience against red-teaming attacks. Furthermore, our analysis\nunderscores the advantage of AI feedback, particularly in fostering preference\ndiversity to deliver more comprehensive improvements. Our dataset, training\ncode and models are available at https://vlf-silkie.github.io.\n","authors":["Lei Li","Zhihui Xie","Mukai Li","Shunian Chen","Peiyi Wang","Liang Chen","Yazheng Yang","Benyou Wang","Lingpeng Kong","Qi Liu"],"pdf_url":"https://arxiv.org/pdf/2410.09421v2.pdf","comment":"EMNLP 2024 Main Conference camera-ready version (fixed small typos).\n  This article supersedes arXiv:2312.10665"},{"id":"http://arxiv.org/abs/2410.14214v1","updated":"2024-10-18T07:02:57Z","published":"2024-10-18T07:02:57Z","title":"MambaSCI: Efficient Mamba-UNet for Quad-Bayer Patterned Video Snapshot\n  Compressive Imaging","summary":"  Color video snapshot compressive imaging (SCI) employs computational imaging\ntechniques to capture multiple sequential video frames in a single\nBayer-patterned measurement. With the increasing popularity of quad-Bayer\npattern in mainstream smartphone cameras for capturing high-resolution videos,\nmobile photography has become more accessible to a wider audience. However,\nexisting color video SCI reconstruction algorithms are designed based on the\ntraditional Bayer pattern. When applied to videos captured by quad-Bayer\ncameras, these algorithms often result in color distortion and ineffective\ndemosaicing, rendering them impractical for primary equipment. To address this\nchallenge, we propose the MambaSCI method, which leverages the Mamba and UNet\narchitectures for efficient reconstruction of quad-Bayer patterned color video\nSCI. To the best of our knowledge, our work presents the first algorithm for\nquad-Bayer patterned SCI reconstruction, and also the initial application of\nthe Mamba model to this task. Specifically, we customize Residual-Mamba-Blocks,\nwhich residually connect the Spatial-Temporal Mamba (STMamba),\nEdge-Detail-Reconstruction (EDR) module, and Channel Attention (CA) module.\nRespectively, STMamba is used to model long-range spatial-temporal dependencies\nwith linear complexity, EDR is for better edge-detail reconstruction, and CA is\nused to compensate for the missing channel information interaction in Mamba\nmodel. Experiments demonstrate that MambaSCI surpasses state-of-the-art methods\nwith lower computational and memory costs. PyTorch style pseudo-code for the\ncore modules is provided in the supplementary materials.\n","authors":["Zhenghao Pan","Haijin Zeng","Jiezhang Cao","Yongyong Chen","Kai Zhang","Yong Xu"],"pdf_url":"https://arxiv.org/pdf/2410.14214v1.pdf","comment":"NeurIPS 2024"},{"id":"http://arxiv.org/abs/2410.10167v2","updated":"2024-10-18T06:57:51Z","published":"2024-10-14T05:23:12Z","title":"X-Fi: A Modality-Invariant Foundation Model for Multimodal Human Sensing","summary":"  Human sensing, which employs various sensors and advanced deep learning\ntechnologies to accurately capture and interpret human body information, has\nsignificantly impacted fields like public security and robotics. However,\ncurrent human sensing primarily depends on modalities such as cameras and\nLiDAR, each of which has its own strengths and limitations. Furthermore,\nexisting multi-modal fusion solutions are typically designed for fixed modality\ncombinations, requiring extensive retraining when modalities are added or\nremoved for diverse scenarios. In this paper, we propose a modality-invariant\nfoundation model for all modalities, X-Fi, to address this issue. X-Fi enables\nthe independent or combinatory use of sensor modalities without additional\ntraining by utilizing a transformer structure to accommodate variable input\nsizes and incorporating a novel \"X-fusion\" mechanism to preserve\nmodality-specific features during multimodal integration. This approach not\nonly enhances adaptability but also facilitates the learning of complementary\nfeatures across modalities. Extensive experiments conducted on the MM-Fi and\nXRF55 datasets, employing six distinct modalities, demonstrate that X-Fi\nachieves state-of-the-art performance in human pose estimation (HPE) and human\nactivity recognition (HAR) tasks. The findings indicate that our proposed model\ncan efficiently support a wide range of human sensing applications, ultimately\ncontributing to the evolution of scalable, multimodal sensing technologies.\n","authors":["Xinyan Chen","Jianfei Yang"],"pdf_url":"https://arxiv.org/pdf/2410.10167v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.14210v1","updated":"2024-10-18T06:52:51Z","published":"2024-10-18T06:52:51Z","title":"Shape Transformation Driven by Active Contour for Class-Imbalanced\n  Semi-Supervised Medical Image Segmentation","summary":"  Annotating 3D medical images demands expert knowledge and is time-consuming.\nAs a result, semi-supervised learning (SSL) approaches have gained significant\ninterest in 3D medical image segmentation. The significant size differences\namong various organs in the human body lead to imbalanced class distribution,\nwhich is a major challenge in the real-world application of these SSL\napproaches. To address this issue, we develop a novel Shape Transformation\ndriven by Active Contour (STAC), that enlarges smaller organs to alleviate\nimbalanced class distribution across different organs. Inspired by curve\nevolution theory in active contour methods, STAC employs a signed distance\nfunction (SDF) as the level set function, to implicitly represent the shape of\norgans, and deforms voxels in the direction of the steepest descent of SDF\n(i.e., the normal vector). To ensure that the voxels far from expansion organs\nremain unchanged, we design an SDF-based weight function to control the degree\nof deformation for each voxel. We then use STAC as a data-augmentation process\nduring the training stage. Experimental results on two benchmark datasets\ndemonstrate that the proposed method significantly outperforms some\nstate-of-the-art methods. Source code is publicly available at\nhttps://github.com/GuGuLL123/STAC.\n","authors":["Yuliang Gu","Yepeng Liu","Zhichao Sun","Jinchi Zhu","Yongchao Xu","Laurent Najman"],"pdf_url":"https://arxiv.org/pdf/2410.14210v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.06719v3","updated":"2024-10-18T06:39:27Z","published":"2024-10-09T09:43:36Z","title":"Suppress Content Shift: Better Diffusion Features via Off-the-Shelf\n  Generation Techniques","summary":"  Diffusion models are powerful generative models, and this capability can also\nbe applied to discrimination. The inner activations of a pre-trained diffusion\nmodel can serve as features for discriminative tasks, namely, diffusion\nfeature. We discover that diffusion feature has been hindered by a hidden yet\nuniversal phenomenon that we call content shift. To be specific, there are\ncontent differences between features and the input image, such as the exact\nshape of a certain object. We locate the cause of content shift as one inherent\ncharacteristic of diffusion models, which suggests the broad existence of this\nphenomenon in diffusion feature. Further empirical study also indicates that\nits negative impact is not negligible even when content shift is not visually\nperceivable. Hence, we propose to suppress content shift to enhance the overall\nquality of diffusion features. Specifically, content shift is related to the\ninformation drift during the process of recovering an image from the noisy\ninput, pointing out the possibility of turning off-the-shelf generation\ntechniques into tools for content shift suppression. We further propose a\npractical guideline named GATE to efficiently evaluate the potential benefit of\na technique and provide an implementation of our methodology. Despite the\nsimplicity, the proposed approach has achieved superior results on various\ntasks and datasets, validating its potential as a generic booster for diffusion\nfeatures. Our code is available at\nhttps://github.com/Darkbblue/diffusion-content-shift.\n","authors":["Benyuan Meng","Qianqian Xu","Zitai Wang","Zhiyong Yang","Xiaochun Cao","Qingming Huang"],"pdf_url":"https://arxiv.org/pdf/2410.06719v3.pdf","comment":"arXiv admin note: substantial text overlap with arXiv:2410.03558"},{"id":"http://arxiv.org/abs/2410.14201v1","updated":"2024-10-18T06:31:57Z","published":"2024-10-18T06:31:57Z","title":"Text-to-Image Representativity Fairness Evaluation Framework","summary":"  Text-to-Image generative systems are progressing rapidly to be a source of\nadvertisement and media and could soon serve as image searches or artists.\nHowever, there is a significant concern about the representativity bias these\nmodels embody and how these biases can propagate in the social fabric after\nfine-tuning them. Therefore, continuously monitoring and evaluating these\nmodels for fairness is important. To address this issue, we propose\nText-to-Image (TTI) Representativity Fairness Evaluation Framework. In this\nframework, we evaluate three aspects of a TTI system; diversity, inclusion, and\nquality. For each aspect, human-based and model-based approaches are proposed\nand evaluated for their ability to capture the bias and whether they can\nsubstitute each other. The framework starts by suggesting the prompts for\ngenerating the images for the evaluation based on the context and the sensitive\nattributes under study. Then the three aspects are evaluated using the proposed\napproaches. Based on the evaluation, a decision is made regarding the\nrepresentativity bias within the TTI system. The evaluation of our framework on\nStable Diffusion shows that the framework can effectively capture the bias in\nTTI systems. The results also confirm that our proposed model based-approaches\ncan substitute human-based approaches in three out of four components with high\ncorrelation, which could potentially reduce costs and automate the process. The\nstudy suggests that continual learning of the model on more inclusive data\nacross disadvantaged minorities such as Indians and Middle Easterners is\nessential to mitigate current stereotyping and lack of inclusiveness.\n","authors":["Asma Yamani","Malak Baslyman"],"pdf_url":"https://arxiv.org/pdf/2410.14201v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.14200v1","updated":"2024-10-18T06:31:40Z","published":"2024-10-18T06:31:40Z","title":"E3D-GPT: Enhanced 3D Visual Foundation for Medical Vision-Language Model","summary":"  The development of 3D medical vision-language models holds significant\npotential for disease diagnosis and patient treatment. However, compared to 2D\nmedical images, 3D medical images, such as CT scans, face challenges related to\nlimited training data and high dimension, which severely restrict the progress\nof 3D medical vision-language models. To address these issues, we collect a\nlarge amount of unlabeled 3D CT data and utilize self-supervised learning to\nconstruct a 3D visual foundation model for extracting 3D visual features. Then,\nwe apply 3D spatial convolutions to aggregate and project high-level image\nfeatures, reducing computational complexity while preserving spatial\ninformation. We also construct two instruction-tuning datasets based on BIMCV-R\nand CT-RATE to fine-tune the 3D vision-language model. Our model demonstrates\nsuperior performance compared to existing methods in report generation, visual\nquestion answering, and disease diagnosis. Code and data will be made publicly\navailable soon.\n","authors":["Haoran Lai","Zihang Jiang","Qingsong Yao","Rongsheng Wang","Zhiyang He","Xiaodong Tao","Wei Wei","Weifu Lv","S. Kevin Zhou"],"pdf_url":"https://arxiv.org/pdf/2410.14200v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.03558v3","updated":"2024-10-18T06:19:45Z","published":"2024-10-04T16:05:14Z","title":"Not All Diffusion Model Activations Have Been Evaluated as\n  Discriminative Features","summary":"  Diffusion models are initially designed for image generation. Recent research\nshows that the internal signals within their backbones, named activations, can\nalso serve as dense features for various discriminative tasks such as semantic\nsegmentation. Given numerous activations, selecting a small yet effective\nsubset poses a fundamental problem. To this end, the early study of this field\nperforms a large-scale quantitative comparison of the discriminative ability of\nthe activations. However, we find that many potential activations have not been\nevaluated, such as the queries and keys used to compute attention scores.\nMoreover, recent advancements in diffusion architectures bring many new\nactivations, such as those within embedded ViT modules. Both combined,\nactivation selection remains unresolved but overlooked. To tackle this issue,\nthis paper takes a further step with a much broader range of activations\nevaluated. Considering the significant increase in activations, a full-scale\nquantitative comparison is no longer operational. Instead, we seek to\nunderstand the properties of these activations, such that the activations that\nare clearly inferior can be filtered out in advance via simple qualitative\nevaluation. After careful analysis, we discover three properties universal\namong diffusion models, enabling this study to go beyond specific models. On\ntop of this, we present effective feature selection solutions for several\npopular diffusion models. Finally, the experiments across multiple\ndiscriminative tasks validate the superiority of our method over the SOTA\ncompetitors. Our code is available at\nhttps://github.com/Darkbblue/generic-diffusion-feature.\n","authors":["Benyuan Meng","Qianqian Xu","Zitai Wang","Xiaochun Cao","Qingming Huang"],"pdf_url":"https://arxiv.org/pdf/2410.03558v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.14195v1","updated":"2024-10-18T06:12:36Z","published":"2024-10-18T06:12:36Z","title":"Rethinking Transformer for Long Contextual Histopathology Whole Slide\n  Image Analysis","summary":"  Histopathology Whole Slide Image (WSI) analysis serves as the gold standard\nfor clinical cancer diagnosis in the daily routines of doctors. To develop\ncomputer-aided diagnosis model for WSIs, previous methods typically employ\nMulti-Instance Learning to enable slide-level prediction given only slide-level\nlabels. Among these models, vanilla attention mechanisms without pairwise\ninteractions have traditionally been employed but are unable to model\ncontextual information. More recently, self-attention models have been utilized\nto address this issue. To alleviate the computational complexity of long\nsequences in large WSIs, methods like HIPT use region-slicing, and TransMIL\nemploys approximation of full self-attention. Both approaches suffer from\nsuboptimal performance due to the loss of key information. Moreover, their use\nof absolute positional embedding struggles to effectively handle long\ncontextual dependencies in shape-varying WSIs. In this paper, we first analyze\nhow the low-rank nature of the long-sequence attention matrix constrains the\nrepresentation ability of WSI modelling. Then, we demonstrate that the rank of\nattention matrix can be improved by focusing on local interactions via a local\nattention mask. Our analysis shows that the local mask aligns with the\nattention patterns in the lower layers of the Transformer. Furthermore, the\nlocal attention mask can be implemented during chunked attention calculation,\nreducing the quadratic computational complexity to linear with a small local\nbandwidth. Building on this, we propose a local-global hybrid Transformer for\nboth computational acceleration and local-global information interactions\nmodelling. Our method, Long-contextual MIL (LongMIL), is evaluated through\nextensive experiments on various WSI tasks to validate its superiority. Our\ncode will be available at github.com/invoker-LL/Long-MIL.\n","authors":["Honglin Li","Yunlong Zhang","Pingyi Chen","Zhongyi Shui","Chenglu Zhu","Lin Yang"],"pdf_url":"https://arxiv.org/pdf/2410.14195v1.pdf","comment":"NeurIPS-2024. arXiv admin note: text overlap with arXiv:2311.12885"},{"id":"http://arxiv.org/abs/2410.14189v1","updated":"2024-10-18T05:48:06Z","published":"2024-10-18T05:48:06Z","title":"Neural Signed Distance Function Inference through Splatting 3D Gaussians\n  Pulled on Zero-Level Set","summary":"  It is vital to infer a signed distance function (SDF) in multi-view based\nsurface reconstruction. 3D Gaussian splatting (3DGS) provides a novel\nperspective for volume rendering, and shows advantages in rendering efficiency\nand quality. Although 3DGS provides a promising neural rendering option, it is\nstill hard to infer SDFs for surface reconstruction with 3DGS due to the\ndiscreteness, the sparseness, and the off-surface drift of 3D Gaussians. To\nresolve these issues, we propose a method that seamlessly merge 3DGS with the\nlearning of neural SDFs. Our key idea is to more effectively constrain the SDF\ninference with the multi-view consistency. To this end, we dynamically align 3D\nGaussians on the zero-level set of the neural SDF using neural pulling, and\nthen render the aligned 3D Gaussians through the differentiable rasterization.\nMeanwhile, we update the neural SDF by pulling neighboring space to the pulled\n3D Gaussians, which progressively refine the signed distance field near the\nsurface. With both differentiable pulling and splatting, we jointly optimize 3D\nGaussians and the neural SDF with both RGB and geometry constraints, which\nrecovers more accurate, smooth, and complete surfaces with more geometry\ndetails. Our numerical and visual comparisons show our superiority over the\nstate-of-the-art results on the widely used benchmarks.\n","authors":["Wenyuan Zhang","Yu-Shen Liu","Zhizhong Han"],"pdf_url":"https://arxiv.org/pdf/2410.14189v1.pdf","comment":"Accepted by NeurIPS 2024. Project page:\n  https://wen-yuan-zhang.github.io/GS-Pull/"},{"id":"http://arxiv.org/abs/2406.13123v2","updated":"2024-10-18T05:20:34Z","published":"2024-06-19T00:38:19Z","title":"ViLCo-Bench: VIdeo Language COntinual learning Benchmark","summary":"  Video language continual learning involves continuously adapting to\ninformation from video and text inputs, enhancing a model's ability to handle\nnew tasks while retaining prior knowledge. This field is a relatively\nunder-explored area, and establishing appropriate datasets is crucial for\nfacilitating communication and research in this field. In this study, we\npresent the first dedicated benchmark, ViLCo-Bench, designed to evaluate\ncontinual learning models across a range of video-text tasks. The dataset\ncomprises ten-minute-long videos and corresponding language queries collected\nfrom publicly available datasets. Additionally, we introduce a novel\nmemory-efficient framework that incorporates self-supervised learning and\nmimics long-term and short-term memory effects. This framework addresses\nchallenges including memory complexity from long video clips, natural language\ncomplexity from open queries, and text-video misalignment. We posit that\nViLCo-Bench, with greater complexity compared to existing continual learning\nbenchmarks, would serve as a critical tool for exploring the video-language\ndomain, extending beyond conventional class-incremental tasks, and addressing\ncomplex and limited annotation issues. The curated data, evaluations, and our\nnovel method are available at https://github.com/cruiseresearchgroup/ViLCo.\n","authors":["Tianqi Tang","Shohreh Deldari","Hao Xue","Celso De Melo","Flora D. Salim"],"pdf_url":"https://arxiv.org/pdf/2406.13123v2.pdf","comment":"14 pages, 4 figures, 8 tables, Accepted at NeurIPS Dataset and\n  Benchmark Track 2024"},{"id":"http://arxiv.org/abs/2404.10210v3","updated":"2024-10-18T05:17:29Z","published":"2024-04-16T01:41:22Z","title":"MK-SGN: A Spiking Graph Convolutional Network with Multimodal Fusion and\n  Knowledge Distillation for Skeleton-based Action Recognition","summary":"  In recent years, skeleton-based action recognition, leveraging multimodal\nGraph Convolutional Networks (GCN), has achieved remarkable results. However,\ndue to their deep structure and reliance on continuous floating-point\noperations, GCN-based methods are energy-intensive. We propose an innovative\nSpiking Graph Convolutional Network with Multimodal Fusion and Knowledge\nDistillation (MK-SGN) to address this issue. By merging the energy efficiency\nof Spiking Neural Network (SNN) with the graph representation capability of\nGCN, the proposed MK-SGN reduces energy consumption while maintaining\nrecognition accuracy. Firstly, we convert Graph Convolutional Networks (GCN)\ninto Spiking Graph Convolutional Networks (SGN) establishing a new benchmark\nand paving the way for future research exploration. During this process, we\nintroduce a spiking attention mechanism and design a Spiking-Spatio Graph\nConvolution module with a Spatial Global Spiking Attention mechanism (SA-SGC),\nenhancing feature learning capability. Secondly, we propose a Spiking\nMultimodal Fusion module (SMF), leveraging mutual information to process\nmultimodal data more efficiently. Lastly, we delve into knowledge distillation\nmethods from multimodal GCN to SGN and propose a novel, integrated method that\nsimultaneously focuses on both intermediate layer distillation and soft label\ndistillation to improve the performance of SGN. MK-SGN outperforms the\nstate-of-the-art GCN-like frameworks on three challenging datasets for\nskeleton-based action recognition in reducing energy consumption. It also\noutperforms the state-of-the-art SNN frameworks in accuracy. Specifically, our\nmethod reduces energy consumption by more than 98% compared to typical\nGCN-based methods, while maintaining competitive accuracy on the NTU-RGB+D 60\ncross-subject split using 4-time steps.\n","authors":["Naichuan Zheng","Hailun Xia","Zeyu Liang","Yuanyuan Chai"],"pdf_url":"https://arxiv.org/pdf/2404.10210v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.14179v1","updated":"2024-10-18T05:15:50Z","published":"2024-10-18T05:15:50Z","title":"MultiChartQA: Benchmarking Vision-Language Models on Multi-Chart\n  Problems","summary":"  Multimodal Large Language Models (MLLMs) have demonstrated impressive\nabilities across various tasks, including visual question answering and chart\ncomprehension, yet existing benchmarks for chart-related tasks fall short in\ncapturing the complexity of real-world multi-chart scenarios. Current\nbenchmarks primarily focus on single-chart tasks, neglecting the multi-hop\nreasoning required to extract and integrate information from multiple charts,\nwhich is essential in practical applications. To fill this gap, we introduce\nMultiChartQA, a benchmark that evaluates MLLMs' capabilities in four key areas:\ndirect question answering, parallel question answering, comparative reasoning,\nand sequential reasoning. Our evaluation of a wide range of MLLMs reveals\nsignificant performance gaps compared to humans. These results highlight the\nchallenges in multi-chart comprehension and the potential of MultiChartQA to\ndrive advancements in this field. Our code and data are available at\nhttps://github.com/Zivenzhu/Multi-chart-QA\n","authors":["Zifeng Zhu","Mengzhao Jia","Zhihan Zhang","Lang Li","Meng Jiang"],"pdf_url":"https://arxiv.org/pdf/2410.14179v1.pdf","comment":"18 pages, 9 figures"},{"id":"http://arxiv.org/abs/2305.19513v2","updated":"2024-10-18T05:14:57Z","published":"2023-05-31T02:52:38Z","title":"Hard Region Aware Network for Remote Sensing Change Detection","summary":"  Change detection (CD) is essential for various real-world applications, such\nas urban management and disaster assessment. Numerous CD methods have been\nproposed, and considerable results have been achieved recently. However,\ndetecting changes in hard regions, i.e., the change boundary and irrelevant\npseudo changes caused by background clutters, remains difficult for these\nmethods, since they pose equal attention for all regions in bi-temporal images.\nThis paper proposes a novel change detection network, termed as HRANet, which\nprovides accurate change maps via hard region mining. Specifically, an online\nhard region estimation branch is constructed to model the pixel-wise hard\nsamples, supervised by the error between predicted change maps and\ncorresponding ground truth during the training process. A cross-layer knowledge\nreview module is introduced to distill temporal change information from\nlow-level to high-level features, thereby enhancing the feature representation\ncapabilities. Finally, the hard region aware features extracted from the online\nhard region estimation branch and multi-level temporal difference features are\naggregated into a unified feature representation to improve the accuracy of CD.\nExperimental results on two benchmark datasets demonstrate the superior\nperformance of HRANet in the CD task.\n","authors":["Zhenglai Li","Chang Tang","Xinwang Liu","Xingchen Hu","Xianju Li","Ning Li","Changdong Li"],"pdf_url":"https://arxiv.org/pdf/2305.19513v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.01701v2","updated":"2024-10-18T05:12:00Z","published":"2024-08-03T07:47:16Z","title":"Signal-SGN: A Spiking Graph Convolutional Network for Skeletal Action\n  Recognition via Learning Temporal-Frequency Dynamics","summary":"  In skeletal-based action recognition, Graph Convolutional Networks (GCNs)\nbased methods face limitations due to their complexity and high energy\nconsumption. Spiking Neural Networks (SNNs) have gained attention in recent\nyears for their low energy consumption, but existing methods combining GCNs and\nSNNs fail to fully utilize the temporal characteristics of skeletal sequences,\nleading to increased storage and computational costs. To address this issue, we\npropose a Signal-SGN(Spiking Graph Convolutional Network), which leverages the\ntemporal dimension of skeletal sequences as the spiking timestep and treats\nfeatures as discrete stochastic signals. The core of the network consists of a\n1D Spiking Graph Convolutional Network (1D-SGN) and a Frequency Spiking\nConvolutional Network (FSN). The SGN performs graph convolution on single\nframes and incorporates spiking network characteristics to capture inter-frame\ntemporal relationships, while the FSN uses Fast Fourier Transform (FFT) and\ncomplex convolution to extract temporal-frequency features. We also introduce a\nmulti-scale wavelet transform feature fusion module(MWTF) to capture spectral\nfeatures of temporal signals, enhancing the model's classification capability.\nWe propose a pluggable temporal-frequency spatial semantic feature extraction\nmodule(TFSM) to enhance the model's ability to distinguish features without\nincreasing inference-phase consumption. Our numerous experiments on the NTU\nRGB+D, NTU RGB+D 120, and NW-UCLA datasets demonstrate that the proposed models\nnot only surpass existing SNN-based methods in accuracy but also reduce\ncomputational and storage costs during training. Furthermore, they achieve\ncompetitive accuracy compared to corresponding GCN-based methods, which is\nquite remarkable.\n","authors":["Naichuan Zheng","Hailun Xia","Dapeng Liu"],"pdf_url":"https://arxiv.org/pdf/2408.01701v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.14178v1","updated":"2024-10-18T05:11:07Z","published":"2024-10-18T05:11:07Z","title":"Feature Augmentation based Test-Time Adaptation","summary":"  Test-time adaptation (TTA) allows a model to be adapted to an unseen domain\nwithout accessing the source data. Due to the nature of practical environments,\nTTA has a limited amount of data for adaptation. Recent TTA methods further\nrestrict this by filtering input data for reliability, making the effective\ndata size even smaller and limiting adaptation potential. To address this\nissue, We propose Feature Augmentation based Test-time Adaptation (FATA), a\nsimple method that fully utilizes the limited amount of input data through\nfeature augmentation. FATA employs Normalization Perturbation to augment\nfeatures and adapts the model using the FATA loss, which makes the outputs of\nthe augmented and original features similar. FATA is model-agnostic and can be\nseamlessly integrated into existing models without altering the model\narchitecture. We demonstrate the effectiveness of FATA on various models and\nscenarios on ImageNet-C and Office-Home, validating its superiority in diverse\nreal-world conditions.\n","authors":["Younggeol Cho","Youngrae Kim","Junho Yoon","Seunghoon Hong","Dongman Lee"],"pdf_url":"https://arxiv.org/pdf/2410.14178v1.pdf","comment":"10 pages"},{"id":"http://arxiv.org/abs/2410.14177v1","updated":"2024-10-18T05:09:07Z","published":"2024-10-18T05:09:07Z","title":"Learning autonomous driving from aerial imagery","summary":"  In this work, we consider the problem of learning end to end perception to\ncontrol for ground vehicles solely from aerial imagery. Photogrammetric\nsimulators allow the synthesis of novel views through the transformation of\npre-generated assets into novel views.However, they have a large setup cost,\nrequire careful collection of data and often human effort to create usable\nsimulators. We use a Neural Radiance Field (NeRF) as an intermediate\nrepresentation to synthesize novel views from the point of view of a ground\nvehicle. These novel viewpoints can then be used for several downstream\nautonomous navigation applications. In this work, we demonstrate the utility of\nnovel view synthesis though the application of training a policy for end to end\nlearning from images and depth data. In a traditional real to sim to real\nframework, the collected data would be transformed into a visual simulator\nwhich could then be used to generate novel views. In contrast, using a NeRF\nallows a compact representation and the ability to optimize over the parameters\nof the visual simulator as more data is gathered in the environment. We\ndemonstrate the efficacy of our method in a custom built mini-city environment\nthrough the deployment of imitation policies on robotic cars. We additionally\nconsider the task of place localization and demonstrate that our method is able\nto relocalize the car in the real world.\n","authors":["Varun Murali","Guy Rosman","Sertac Karaman","Daniela Rus"],"pdf_url":"https://arxiv.org/pdf/2410.14177v1.pdf","comment":"Presented at IROS 2024"},{"id":"http://arxiv.org/abs/2402.13876v3","updated":"2024-10-18T05:04:40Z","published":"2024-02-21T15:35:59Z","title":"Scene Prior Filtering for Depth Super-Resolution","summary":"  Multi-modal fusion is vital to the success of super-resolution of depth maps.\nHowever, commonly used fusion strategies, such as addition and concatenation,\nfall short of effectively bridging the modal gap. As a result, guided image\nfiltering methods have been introduced to mitigate this issue. Nevertheless, it\nis observed that their filter kernels usually encounter significant texture\ninterference and edge inaccuracy. To tackle these two challenges, we introduce\na Scene Prior Filtering network, SPFNet, which utilizes the priors surface\nnormal and semantic map from large-scale models. Specifically, we design an\nAll-in-one Prior Propagation that computes the similarity between multi-modal\nscene priors, i.e., RGB, normal, semantic, and depth, to reduce the texture\ninterference. In addition, we present a One-to-one Prior Embedding that\ncontinuously embeds each single-modal prior into depth using Mutual Guided\nFiltering, further alleviating the texture interference while enhancing edges.\nOur SPFNet has been extensively evaluated on both real and synthetic datasets,\nachieving state-of-the-art performance.\n","authors":["Zhengxue Wang","Zhiqiang Yan","Ming-Hsuan Yang","Jinshan Pan","Guangwei Gao","Ying Tai","Jian Yang"],"pdf_url":"https://arxiv.org/pdf/2402.13876v3.pdf","comment":"13 pages"},{"id":"http://arxiv.org/abs/2406.14862v4","updated":"2024-10-18T04:39:35Z","published":"2024-06-21T04:39:03Z","title":"LatentExplainer: Explaining Latent Representations in Deep Generative\n  Models with Multi-modal Foundation Models","summary":"  Deep generative models like VAEs and diffusion models have advanced various\ngeneration tasks by leveraging latent variables to learn data distributions and\ngenerate high-quality samples. Despite the field of explainable AI making\nstrides in interpreting machine learning models, understanding latent variables\nin generative models remains challenging. This paper introduces\n\\textit{LatentExplainer}, a framework for automatically generating semantically\nmeaningful explanations of latent variables in deep generative models.\n\\textit{LatentExplainer} tackles three main challenges: inferring the meaning\nof latent variables, aligning explanations with inductive biases, and handling\nvarying degrees of explainability. Our approach perturbs latent variables,\ninterpreting changes in generated data, and uses multi-modal large language\nmodels (MLLMs) to produce human-understandable explanations. We evaluate our\nproposed method on several real-world and synthetic datasets, and the results\ndemonstrate superior performance in generating high-quality explanations for\nlatent variables. The results highlight the effectiveness of incorporating\ninductive biases and uncertainty quantification, significantly enhancing model\ninterpretability.\n","authors":["Mengdan Zhu","Raasikh Kanjiani","Jiahui Lu","Andrew Choi","Qirui Ye","Liang Zhao"],"pdf_url":"https://arxiv.org/pdf/2406.14862v4.pdf","comment":null},{"id":"http://arxiv.org/abs/2407.00902v2","updated":"2024-10-18T04:37:33Z","published":"2024-07-01T01:57:21Z","title":"From Introspection to Best Practices: Principled Analysis of\n  Demonstrations in Multimodal In-Context Learning","summary":"  Motivated by in-context learning (ICL) capabilities of Large Language models\n(LLMs), multimodal LLMs with additional visual modality are also exhibited with\nsimilar ICL abilities when multiple image-text pairs are provided as\ndemonstrations. However, relatively less work has been done to investigate the\nprinciples behind how and why multimodal ICL works. We conduct a systematic and\nprincipled evaluation of multimodal ICL for models of different scales on a\nbroad spectrum of new yet critical tasks. Through perturbations over different\nmodality information, we show that modalities matter differently across tasks\nin multimodal ICL. Guided by task-specific modality impact, we recommend\nmodality-driven demonstration strategies to boost ICL performance. We also find\nthat models may follow inductive biases from multimodal ICL even if they are\nrarely seen in or contradict semantic priors from pretraining data. Our\nprincipled analysis provides a comprehensive way of understanding the role of\ndemonstrations in multimodal in-context learning, and sheds light on\neffectively improving multimodal ICL on a wide range of tasks.\n","authors":["Nan Xu","Fei Wang","Sheng Zhang","Hoifung Poon","Muhao Chen"],"pdf_url":"https://arxiv.org/pdf/2407.00902v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.12324v2","updated":"2024-10-18T04:32:34Z","published":"2024-10-16T07:44:56Z","title":"PAPL-SLAM: Principal Axis-Anchored Monocular Point-Line SLAM","summary":"  In point-line SLAM systems, the utilization of line structural information\nand the optimization of lines are two significant problems. The former is\nusually addressed through structural regularities, while the latter typically\ninvolves using minimal parameter representations of lines in optimization.\nHowever, separating these two steps leads to the loss of constraint information\nto each other. We anchor lines with similar directions to a principal axis and\noptimize them with $n+2$ parameters for $n$ lines, solving both problems\ntogether. Our method considers scene structural information, which can be\neasily extended to different world hypotheses while significantly reducing the\nnumber of line parameters to be optimized, enabling rapid and accurate mapping\nand tracking. To further enhance the system's robustness and avoid mismatch, we\nhave modeled the line-axis probabilistic data association and provided the\nalgorithm for axis creation, updating, and optimization. Additionally,\nconsidering that most real-world scenes conform to the Atlanta World\nhypothesis, we provide a structural line detection strategy based on vertical\npriors and vanishing points. Experimental results and ablation studies on\nvarious indoor and outdoor datasets demonstrate the effectiveness of our\nsystem.\n","authors":["Guanghao Li","Yu Cao","Qi Chen","Yifan Yang","Jian Pu"],"pdf_url":"https://arxiv.org/pdf/2410.12324v2.pdf","comment":"8 pages, 4 figures"},{"id":"http://arxiv.org/abs/2410.04733v2","updated":"2024-10-18T04:28:28Z","published":"2024-10-07T03:52:06Z","title":"PredFormer: Transformers Are Effective Spatial-Temporal Predictive\n  Learners","summary":"  Spatiotemporal predictive learning methods generally fall into two\ncategories: recurrent-based approaches, which face challenges in\nparallelization and performance, and recurrent-free methods, which employ\nconvolutional neural networks (CNNs) as encoder-decoder architectures. These\nmethods benefit from strong inductive biases but often at the expense of\nscalability and generalization. This paper proposes PredFormer, a pure\ntransformer-based framework for spatiotemporal predictive learning. Motivated\nby the Vision Transformers (ViT) design, PredFormer leverages carefully\ndesigned Gated Transformer blocks, following a comprehensive analysis of 3D\nattention mechanisms, including full-, factorized-, and\ninterleaved-spatial-temporal attention. With its recurrent-free,\ntransformer-based design, PredFormer is both simple and efficient,\nsignificantly outperforming previous methods by large margins. Extensive\nexperiments on synthetic and real-world datasets demonstrate that PredFormer\nachieves state-of-the-art performance. On Moving MNIST, PredFormer achieves a\n51.3% reduction in MSE relative to SimVP. For TaxiBJ, the model decreases MSE\nby 33.1% and boosts FPS from 533 to 2364. Additionally, on WeatherBench, it\nreduces MSE by 11.1% while enhancing FPS from 196 to 404. These performance\ngains in both accuracy and efficiency demonstrate PredFormer's potential for\nreal-world applications. The source code will be released at\nhttps://github.com/yyyujintang/PredFormer .\n","authors":["Yujin Tang","Lu Qi","Fei Xie","Xiangtai Li","Chao Ma","Ming-Hsuan Yang"],"pdf_url":"https://arxiv.org/pdf/2410.04733v2.pdf","comment":"15 pages, 7 figures"},{"id":"http://arxiv.org/abs/2407.04127v2","updated":"2024-10-18T04:23:00Z","published":"2024-07-04T19:00:34Z","title":"Biometric Authentication Based on Enhanced Remote Photoplethysmography\n  Signal Morphology","summary":"  Remote photoplethysmography (rPPG) is a non-contact method for measuring\ncardiac signals from facial videos, offering a convenient alternative to\ncontact photoplethysmography (cPPG) obtained from contact sensors. Recent\nstudies have shown that each individual possesses a unique cPPG signal\nmorphology that can be utilized as a biometric identifier, which has inspired\nus to utilize the morphology of rPPG signals extracted from facial videos for\nperson authentication. Since the facial appearance and rPPG are mixed in the\nfacial videos, we first de-identify facial videos to remove facial appearance\nwhile preserving the rPPG information, which protects facial privacy and\nguarantees that only rPPG is used for authentication. The de-identified videos\nare fed into an rPPG model to get the rPPG signal morphology for\nauthentication. In the first training stage, unsupervised rPPG training is\nperformed to get coarse rPPG signals. In the second training stage, an\nrPPG-cPPG hybrid training is performed by incorporating external cPPG datasets\nto achieve rPPG biometric authentication and enhance rPPG signal morphology.\nOur approach needs only de-identified facial videos with subject IDs to train\nrPPG authentication models. The experimental results demonstrate that rPPG\nsignal morphology hidden in facial videos can be used for biometric\nauthentication. The code is available at\nhttps://github.com/zhaodongsun/rppg_biometrics.\n","authors":["Zhaodong Sun","Xiaobai Li","Jukka Komulainen","Guoying Zhao"],"pdf_url":"https://arxiv.org/pdf/2407.04127v2.pdf","comment":"accepted by IJCB 2024, Best Paper Runner-Up Award"},{"id":"http://arxiv.org/abs/2410.14169v1","updated":"2024-10-18T04:19:10Z","published":"2024-10-18T04:19:10Z","title":"DaRePlane: Direction-aware Representations for Dynamic Scene\n  Reconstruction","summary":"  Numerous recent approaches to modeling and re-rendering dynamic scenes\nleverage plane-based explicit representations, addressing slow training times\nassociated with models like neural radiance fields (NeRF) and Gaussian\nsplatting (GS). However, merely decomposing 4D dynamic scenes into multiple 2D\nplane-based representations is insufficient for high-fidelity re-rendering of\nscenes with complex motions. In response, we present DaRePlane, a novel\ndirection-aware representation approach that captures scene dynamics from six\ndifferent directions. This learned representation undergoes an inverse\ndual-tree complex wavelet transformation (DTCWT) to recover plane-based\ninformation. Within NeRF pipelines, DaRePlane computes features for each\nspace-time point by fusing vectors from these recovered planes, then passed to\na tiny MLP for color regression. When applied to Gaussian splatting, DaRePlane\ncomputes the features of Gaussian points, followed by a tiny multi-head MLP for\nspatial-time deformation prediction. Notably, to address redundancy introduced\nby the six real and six imaginary direction-aware wavelet coefficients, we\nintroduce a trainable masking approach, mitigating storage issues without\nsignificant performance decline. To demonstrate the generality and efficiency\nof DaRePlane, we test it on both regular and surgical dynamic scenes, for both\nNeRF and GS systems. Extensive experiments show that DaRePlane yields\nstate-of-the-art performance in novel view synthesis for various complex\ndynamic scenes.\n","authors":["Ange Lou","Benjamin Planche","Zhongpai Gao","Yamin Li","Tianyu Luan","Hao Ding","Meng Zheng","Terrence Chen","Ziyan Wu","Jack Noble"],"pdf_url":"https://arxiv.org/pdf/2410.14169v1.pdf","comment":"arXiv admin note: substantial text overlap with arXiv:2403.02265"},{"id":"http://arxiv.org/abs/2410.14164v1","updated":"2024-10-18T04:04:58Z","published":"2024-10-18T04:04:58Z","title":"Optimal DLT-based Solutions for the Perspective-n-Point","summary":"  We propose a modified normalized direct linear transform (DLT) algorithm for\nsolving the perspective-n-point (PnP) problem with much better behavior than\nthe conventional DLT. The modification consists of analytically weighting the\ndifferent measurements in the linear system with a negligible increase in\ncomputational load. Our approach exhibits clear improvements -- in both\nperformance and runtime -- when compared to popular methods such as EPnP, CPnP,\nRPnP, and OPnP. Our new non-iterative solution approaches that of the true\noptimal found via Gauss-Newton optimization, but at a fraction of the\ncomputational cost. Our optimal DLT (oDLT) implementation, as well as the\nexperiments, are released in open source.\n","authors":["Sébastien Henry","John A. Christian"],"pdf_url":"https://arxiv.org/pdf/2410.14164v1.pdf","comment":"8 pages, 6 figures, 2 tables"},{"id":"http://arxiv.org/abs/2410.14161v1","updated":"2024-10-18T04:00:26Z","published":"2024-10-18T04:00:26Z","title":"Unlabeled Action Quality Assessment Based on Multi-dimensional Adaptive\n  Constrained Dynamic Time Warping","summary":"  The growing popularity of online sports and exercise necessitates effective\nmethods for evaluating the quality of online exercise executions. Previous\naction quality assessment methods, which relied on labeled scores from motion\nvideos, exhibited slightly lower accuracy and discriminability. This limitation\nhindered their rapid application to newly added exercises. To address this\nproblem, this paper presents an unlabeled Multi-Dimensional Exercise Distance\nAdaptive Constrained Dynamic Time Warping (MED-ACDTW) method for action quality\nassessment. Our approach uses an athletic version of DTW to compare features\nfrom template and test videos, eliminating the need for score labels during\ntraining. The result shows that utilizing both 2D and 3D spatial dimensions,\nalong with multiple human body features, improves the accuracy by 2-3% compared\nto using either 2D or 3D pose estimation alone. Additionally, employing MED for\nscore calculation enhances the precision of frame distance matching, which\nsignificantly boosts overall discriminability. The adaptive constraint scheme\nenhances the discriminability of action quality assessment by approximately\n30%. Furthermore, to address the absence of a standardized perspective in\nsports class evaluations, we introduce a new dataset called BGym.\n","authors":["Renguang Chen","Guolong Zheng","Xu Yang","Zhide Chen","Jiwu Shu","Wencheng Yang","Kexin Zhu","Chen Feng"],"pdf_url":"https://arxiv.org/pdf/2410.14161v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.14159v1","updated":"2024-10-18T03:58:29Z","published":"2024-10-18T03:58:29Z","title":"Assessing Open-world Forgetting in Generative Image Model Customization","summary":"  Recent advances in diffusion models have significantly enhanced image\ngeneration capabilities. However, customizing these models with new classes\noften leads to unintended consequences that compromise their reliability. We\nintroduce the concept of open-world forgetting to emphasize the vast scope of\nthese unintended alterations, contrasting it with the well-studied closed-world\nforgetting, which is measurable by evaluating performance on a limited set of\nclasses or skills. Our research presents the first comprehensive investigation\ninto open-world forgetting in diffusion models, focusing on semantic and\nappearance drift of representations. We utilize zero-shot classification to\nanalyze semantic drift, revealing that even minor model adaptations lead to\nunpredictable shifts affecting areas far beyond newly introduced concepts, with\ndramatic drops in zero-shot classification of up to 60%. Additionally, we\nobserve significant changes in texture and color of generated content when\nanalyzing appearance drift. To address these issues, we propose a mitigation\nstrategy based on functional regularization, designed to preserve original\ncapabilities while accommodating new concepts. Our study aims to raise\nawareness of unintended changes due to model customization and advocates for\nthe analysis of open-world forgetting in future research on model customization\nand finetuning methods. Furthermore, we provide insights for developing more\nrobust adaptation methodologies.\n","authors":["Héctor Laria","Alex Gomez-Villa","Imad Eddine Marouf","Kai Wang","Bogdan Raducanu","Joost van de Weijer"],"pdf_url":"https://arxiv.org/pdf/2410.14159v1.pdf","comment":"Project page: https://hecoding.github.io/open-world-forgetting/"},{"id":"http://arxiv.org/abs/2410.14148v1","updated":"2024-10-18T03:34:32Z","published":"2024-10-18T03:34:32Z","title":"Fine-Grained Verifiers: Preference Modeling as Next-token Prediction in\n  Vision-Language Alignment","summary":"  The recent advancements in large language models (LLMs) and pre-trained\nvision models have accelerated the development of vision-language large models\n(VLLMs), enhancing the interaction between visual and linguistic modalities.\nDespite their notable success across various domains, VLLMs face challenges in\nmodality alignment, which can lead to issues like hallucinations and unsafe\ncontent generation. Current alignment techniques often rely on coarse feedback\nand external datasets, limiting scalability and performance. In this paper, we\npropose FiSAO (Fine-Grained Self-Alignment Optimization), a novel\nself-alignment method that utilizes the model's own visual encoder as a\nfine-grained verifier to improve vision-language alignment without the need for\nadditional data. By leveraging token-level feedback from the vision encoder,\nFiSAO significantly improves vision-language alignment, even surpassing\ntraditional preference tuning methods that require additional data. Through\nboth theoretical analysis and experimental validation, we demonstrate that\nFiSAO effectively addresses the misalignment problem in VLLMs, marking the\nfirst instance of token-level rewards being applied to such models.\n","authors":["Chenhang Cui","An Zhang","Yiyang Zhou","Zhaorun Chen","Gelei Deng","Huaxiu Yao","Tat-Seng Chua"],"pdf_url":"https://arxiv.org/pdf/2410.14148v1.pdf","comment":"23 pages"},{"id":"http://arxiv.org/abs/2410.14143v1","updated":"2024-10-18T03:31:00Z","published":"2024-10-18T03:31:00Z","title":"Preview-based Category Contrastive Learning for Knowledge Distillation","summary":"  Knowledge distillation is a mainstream algorithm in model compression by\ntransferring knowledge from the larger model (teacher) to the smaller model\n(student) to improve the performance of student. Despite many efforts, existing\nmethods mainly investigate the consistency between instance-level feature\nrepresentation or prediction, which neglects the category-level information and\nthe difficulty of each sample, leading to undesirable performance. To address\nthese issues, we propose a novel preview-based category contrastive learning\nmethod for knowledge distillation (PCKD). It first distills the structural\nknowledge of both instance-level feature correspondence and the relation\nbetween instance features and category centers in a contrastive learning\nfashion, which can explicitly optimize the category representation and explore\nthe distinct correlation between representations of instances and categories,\ncontributing to discriminative category centers and better classification\nresults. Besides, we introduce a novel preview strategy to dynamically\ndetermine how much the student should learn from each sample according to their\ndifficulty. Different from existing methods that treat all samples equally and\ncurriculum learning that simply filters out hard samples, our method assigns a\nsmall weight for hard instances as a preview to better guide the student\ntraining. Extensive experiments on several challenging datasets, including\nCIFAR-100 and ImageNet, demonstrate the superiority over state-of-the-art\nmethods.\n","authors":["Muhe Ding","Jianlong Wu","Xue Dong","Xiaojie Li","Pengda Qin","Tian Gan","Liqiang Nie"],"pdf_url":"https://arxiv.org/pdf/2410.14143v1.pdf","comment":"14 pages, 8 figures, Journal"},{"id":"http://arxiv.org/abs/2410.02052v3","updated":"2024-10-18T03:27:37Z","published":"2024-10-02T21:42:35Z","title":"ExACT: Teaching AI Agents to Explore with Reflective-MCTS and\n  Exploratory Learning","summary":"  Autonomous agents have demonstrated significant potential in automating\ncomplex multistep decision-making tasks. However, even state-of-the-art\nvision-language models (VLMs), such as GPT-4o, still fall short of human-level\nperformance, particularly in intricate web environments and long-horizon tasks.\nTo address these limitations, we present ExACT, an approach to combine\ntest-time search and self-learning to build o1-like models for agentic\napplications. We first introduce Reflective Monte Carlo Tree Search (R-MCTS), a\nnovel test time algorithm designed to enhance AI agents' ability to explore\ndecision space on the fly. R-MCTS extends traditional MCTS by 1) incorporating\ncontrastive reflection, allowing agents to learn from past interactions and\ndynamically improve their search efficiency; and 2) using multi-agent debate\nfor reliable state evaluation. Next, we introduce Exploratory Learning, a novel\nlearning strategy to teach agents to search at inference time without relying\non any external search algorithms. On the challenging VisualWebArena benchmark,\nour GPT-4o based R-MCTS agent achieves a 6% to 30% relative improvement across\nvarious tasks compared to the previous state-of-the-art. Additionally, we show\nthat the knowledge and experience gained from test-time search can be\neffectively transferred back to GPT-4o via fine-tuning. After Exploratory\nLearning, GPT-4o 1) demonstrates the ability to explore the environment,\nevaluate a state, and backtrack to viable ones when it detects that the current\nstate cannot lead to success, and 2) matches 87% of R-MCTS's performance while\nusing significantly less compute. Notably, our work demonstrates the compute\nscaling properties in both training - data collection with R-MCTS - and testing\ntime. These results suggest a promising research direction to enhance VLMs'\ncapabilities for agentic applications via test-time search and self-learning.\n","authors":["Xiao Yu","Baolin Peng","Vineeth Vajipey","Hao Cheng","Michel Galley","Jianfeng Gao","Zhou Yu"],"pdf_url":"https://arxiv.org/pdf/2410.02052v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.14138v1","updated":"2024-10-18T03:22:06Z","published":"2024-10-18T03:22:06Z","title":"ProReason: Multi-Modal Proactive Reasoning with Decoupled Eyesight and\n  Wisdom","summary":"  Large vision-language models (LVLMs) have witnessed significant progress on\nvisual understanding tasks. However, they often prioritize language knowledge\nover image information on visual reasoning tasks, incurring performance\ndegradation. To tackle this issue, we first identify the drawbacks of existing\nsolutions (i.e., insufficient and irrelevant visual descriptions, and limited\nmulti-modal capacities). We then decompose visual reasoning process into two\nstages: visual perception (i.e., eyesight) and textual reasoning (i.e.,\nwisdom), and introduce a novel visual reasoning framework named ProReason. This\nframework features multi-run proactive perception and decoupled\nvision-reasoning capabilities. Briefly, given a multi-modal question, ProReason\niterates proactive information collection and reasoning until the answer can be\nconcluded with necessary and sufficient visual descriptions. Notably, the\ndisassociation of capabilities allows seamless integration of existing large\nlanguage models (LLMs) to compensate for the reasoning deficits of LVLMs. Our\nextensive experiments demonstrate that ProReason outperforms both existing\nmulti-step reasoning frameworks and passive peer methods on a wide range of\nbenchmarks for both open-source and closed-source models. In addition, with the\nassistance of LLMs, ProReason achieves a performance improvement of up to 15%\non MMMU benchmark. Our insights into existing solutions and the decoupled\nperspective for feasible integration of LLMs illuminate future research on\nvisual reasoning techniques, especially LLM-assisted ones.\n","authors":["Jingqi Zhou","Sheng Wang","Jingwei Dong","Lei Li","Jiahui Gao","Lingpeng Kong","Chuan Wu"],"pdf_url":"https://arxiv.org/pdf/2410.14138v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.14132v1","updated":"2024-10-18T03:00:03Z","published":"2024-10-18T03:00:03Z","title":"ViConsFormer: Constituting Meaningful Phrases of Scene Texts using\n  Transformer-based Method in Vietnamese Text-based Visual Question Answering","summary":"  Text-based VQA is a challenging task that requires machines to use scene\ntexts in given images to yield the most appropriate answer for the given\nquestion. The main challenge of text-based VQA is exploiting the meaning and\ninformation from scene texts. Recent studies tackled this challenge by\nconsidering the spatial information of scene texts in images via embedding 2D\ncoordinates of their bounding boxes. In this study, we follow the definition of\nmeaning from linguistics to introduce a novel method that effectively exploits\nthe information from scene texts written in Vietnamese. Experimental results\nshow that our proposed method obtains state-of-the-art results on two\nlarge-scale Vietnamese Text-based VQA datasets. The implementation can be found\nat this link.\n","authors":["Nghia Hieu Nguyen","Tho Thanh Quan","Ngan Luu-Thuy Nguyen"],"pdf_url":"https://arxiv.org/pdf/2410.14132v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.14131v1","updated":"2024-10-18T02:57:14Z","published":"2024-10-18T02:57:14Z","title":"Deep Learning Applications in Medical Image Analysis: Advancements,\n  Challenges, and Future Directions","summary":"  Medical image analysis has emerged as an essential element of contemporary\nhealthcare, facilitating physicians in achieving expedited and precise\ndiagnosis. Recent breakthroughs in deep learning, a subset of artificial\nintelligence, have markedly revolutionized the analysis of medical pictures,\nimproving the accuracy and efficiency of clinical procedures. Deep learning\nalgorithms, especially convolutional neural networks (CNNs), have demonstrated\nremarkable proficiency in autonomously learning features from multidimensional\nmedical pictures, including MRI, CT, and X-ray scans, without the necessity for\nmanual feature extraction. These models have been utilized across multiple\nmedical disciplines, including pathology, radiology, ophthalmology, and\ncardiology, where they aid in illness detection, classification, and\nsegmentation tasks......\n","authors":["Aimina Ali Eli","Abida Ali"],"pdf_url":"https://arxiv.org/pdf/2410.14131v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.11656v2","updated":"2024-10-18T02:34:02Z","published":"2023-11-20T10:45:39Z","title":"Double-Condensing Attention Condenser: Leveraging Attention in Deep\n  Learning to Detect Skin Cancer from Skin Lesion Images","summary":"  Skin cancer is the most common type of cancer in the United States and is\nestimated to affect one in five Americans. Recent advances have demonstrated\nstrong performance on skin cancer detection, as exemplified by state of the art\nperformance in the SIIM-ISIC Melanoma Classification Challenge; however these\nsolutions leverage ensembles of complex deep neural architectures requiring\nimmense storage and compute costs, and therefore may not be tractable. A recent\nmovement for TinyML applications is integrating Double-Condensing Attention\nCondensers (DC-AC) into a self-attention neural network backbone architecture\nto allow for faster and more efficient computation. This paper explores\nleveraging an efficient self-attention structure to detect skin cancer in skin\nlesion images and introduces a deep neural network design with DC-AC customized\nfor skin cancer detection from skin lesion images. The final model is publicly\navailable as a part of a global open-source initiative dedicated to\naccelerating advancement in machine learning to aid clinicians in the fight\nagainst cancer. Future work of this research includes iterating on the design\nof the selected network architecture and refining the approach to generalize to\nother forms of cancer.\n","authors":["Chi-en Amy Tai","Elizabeth Janes","Chris Czarnecki","Alexander Wong"],"pdf_url":"https://arxiv.org/pdf/2311.11656v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.05617v2","updated":"2024-10-18T02:15:51Z","published":"2024-08-10T19:31:21Z","title":"Residual-INR: Communication Efficient On-Device Learning Using Implicit\n  Neural Representation","summary":"  Edge computing is a distributed computing paradigm that collects and\nprocesses data at or near the source of data generation. The on-device learning\nat edge relies on device-to-device wireless communication to facilitate\nreal-time data sharing and collaborative decision-making among multiple\ndevices. This significantly improves the adaptability of the edge computing\nsystem to the changing environments. However, as the scale of the edge\ncomputing system is getting larger, communication among devices is becoming the\nbottleneck because of the limited bandwidth of wireless communication leads to\nlarge data transfer latency. To reduce the amount of device-to-device data\ntransmission and accelerate on-device learning, in this paper, we propose\nResidual-INR, a fog computing-based communication-efficient on-device learning\nframework by utilizing implicit neural representation (INR) to compress\nimages/videos into neural network weights. Residual-INR enhances data transfer\nefficiency by collecting JPEG images from edge devices, compressing them into\nINR format at the fog node, and redistributing them for on-device learning. By\nusing a smaller INR for full image encoding and a separate object INR for\nhigh-quality object region reconstruction through residual encoding, our\ntechnique can reduce the encoding redundancy while maintaining the object\nquality. Residual-INR is a promising solution for edge on-device learning\nbecause it reduces data transmission by up to 5.16 x across a network of 10\nedge devices. It also facilitates CPU-free accelerated on-device learning,\nachieving up to 2.9 x speedup without sacrificing accuracy. Our code is\navailable at: https://github.com/sharclab/Residual-INR.\n","authors":["Hanqiu Chen","Xuebin Yao","Pradeep Subedi","Cong Hao"],"pdf_url":"https://arxiv.org/pdf/2408.05617v2.pdf","comment":"This paper has been accepted by ICCAD 2024"},{"id":"http://arxiv.org/abs/2407.01003v3","updated":"2024-10-18T01:50:27Z","published":"2024-07-01T06:35:53Z","title":"Embedded Prompt Tuning: Towards Enhanced Calibration of Pretrained\n  Models for Medical Images","summary":"  Foundation models pre-trained on large-scale data have been widely witnessed\nto achieve success in various natural imaging downstream tasks.\nParameter-efficient fine-tuning (PEFT) methods aim to adapt foundation models\nto new domains by updating only a small portion of parameters in order to\nreduce computational overhead. However, the effectiveness of these PEFT\nmethods, especially in cross-domain few-shot scenarios, e.g., medical image\nanalysis, has not been fully explored. In this work, we facilitate the study of\nthe performance of PEFT when adapting foundation models to medical image\nclassification tasks. Furthermore, to alleviate the limitations of prompt\nintroducing ways and approximation capabilities on Transformer architectures of\nmainstream prompt tuning methods, we propose the Embedded Prompt Tuning (EPT)\nmethod by embedding prompt tokens into the expanded channels. We also find that\nthere are anomalies in the feature space distribution of foundation models\nduring pre-training process, and prompt tuning can help mitigate this negative\nimpact. To explain this phenomenon, we also introduce a novel perspective to\nunderstand prompt tuning: Prompt tuning is a distribution calibrator. And we\nsupport it by analyzing patch-wise scaling and feature separation operations\ncontained in EPT. Our experiments show that EPT outperforms several\nstate-of-the-art fine-tuning methods by a significant margin on few-shot\nmedical image classification tasks, and completes the fine-tuning process\nwithin highly competitive time, indicating EPT is an effective PEFT method. The\nsource code is available at github.com/zuwenqiang/EPT.\n","authors":["Wenqiang Zu","Shenghao Xie","Qing Zhao","Guoqi Li","Lei Ma"],"pdf_url":"https://arxiv.org/pdf/2407.01003v3.pdf","comment":"16 pages, 7 figures. arXiv admin note: text overlap with\n  arXiv:2306.09579, arXiv:2203.12119 by other authors"},{"id":"http://arxiv.org/abs/2402.10403v3","updated":"2024-10-18T01:44:05Z","published":"2024-02-16T02:01:24Z","title":"Polyhedral Complex Derivation from Piecewise Trilinear Networks","summary":"  Recent advancements in visualizing deep neural networks provide insights into\ntheir structures and mesh extraction from Continuous Piecewise Affine (CPWA)\nfunctions. Meanwhile, developments in neural surface representation learning\nincorporate non-linear positional encoding, addressing issues like spectral\nbias; however, this poses challenges in applying mesh extraction techniques\nbased on CPWA functions. Focusing on trilinear interpolating methods as\npositional encoding, we present theoretical insights and an analytical mesh\nextraction, showing the transformation of hypersurfaces to flat planes within\nthe trilinear region under the eikonal constraint. Moreover, we introduce a\nmethod for approximating intersecting points among three hypersurfaces\ncontributing to broader applications. We empirically validate correctness and\nparsimony through chamfer distance and efficiency, and angular distance, while\nexamining the correlation between the eikonal loss and the planarity of the\nhypersurfaces.\n","authors":["Jin-Hwa Kim"],"pdf_url":"https://arxiv.org/pdf/2402.10403v3.pdf","comment":"Accepted at NeurIPS 2024. Updated with the camera-ready version"},{"id":"http://arxiv.org/abs/2406.14878v2","updated":"2024-10-18T01:40:19Z","published":"2024-06-21T05:58:19Z","title":"MOS: Model Synergy for Test-Time Adaptation on LiDAR-Based 3D Object\n  Detection","summary":"  LiDAR-based 3D object detection is crucial for various applications but often\nexperiences performance degradation in real-world deployments due to domain\nshifts. While most studies focus on cross-dataset shifts, such as changes in\nenvironments and object geometries, practical corruptions from sensor\nvariations and weather conditions remain underexplored. In this work, we\npropose a novel online test-time adaptation framework for 3D detectors that\neffectively tackles these shifts, including a challenging cross-corruption\nscenario where cross-dataset shifts and corruptions co-occur. By leveraging\nlong-term knowledge from previous test batches, our approach mitigates\ncatastrophic forgetting and adapts effectively to diverse shifts. Specifically,\nwe propose a Model Synergy (MOS) strategy that dynamically selects historical\ncheckpoints with diverse knowledge and assembles them to best accommodate the\ncurrent test batch. This assembly is directed by our proposed Synergy Weights\n(SW), which perform a weighted averaging of the selected checkpoints,\nminimizing redundancy in the composite model. The SWs are computed by\nevaluating the similarity of predicted bounding boxes on the test data and the\nindependence of features between checkpoint pairs in the model bank. To\nmaintain an efficient and informative model bank, we discard checkpoints with\nthe lowest average SW scores, replacing them with newly updated models. Our\nmethod was rigorously tested against existing test-time adaptation strategies\nacross three datasets and eight types of corruptions, demonstrating superior\nadaptability to dynamic scenes and conditions. Notably, it achieved a 67.3%\nimprovement in a challenging cross-corruption scenario, offering a more\ncomprehensive benchmark for adaptation. The source code will be made publicly\navailable.\n","authors":["Zhuoxiao Chen","Junjie Meng","Mahsa Baktashmotlagh","Yonggang Zhang","Zi Huang","Yadan Luo"],"pdf_url":"https://arxiv.org/pdf/2406.14878v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.14103v1","updated":"2024-10-18T00:50:56Z","published":"2024-10-18T00:50:56Z","title":"Extreme Precipitation Nowcasting using Multi-Task Latent Diffusion\n  Models","summary":"  Deep learning models have made remarkable strides in precipitation\nprediction, yet they continue to struggle with capturing the spatial details of\nthe features of radar images, particularly over high precipitation intensity\nareas. This shortcoming is evident in the form of low forecast accuracy in the\nspatial positioning of radar echo images across varying precipitation intensity\nregions. To address this challenge, we introduce the multi-task latent\ndiffusion model(MTLDM), a novel approach for precipitation prediction. The\nbasic concept of the MTLDM is based on the understanding that the radar image\nrepresenting precipitation is the result of multiple factors. Therefore, we\nadopt a divide-and-conquer approach, that is, we decompose the radar image\nusing decomposition technology and then predict the decomposed sub-images\nseparately. We conceptualize the precipitation image as a composition of\nvarious components corresponding to different precipitation intensities. The\nMTLDM decomposes the precipitation image into these distinct components and\nemploys a dedicated task to predict each one. This method enables\nspatiotemporally consistent prediction of real-world precipitation areas up to\n5-80 min in advance, outperforming existing state-of-the-art techniques across\nmultiple evaluation metrics.\n","authors":["Li Chaorong","Ling Xudong","Yang Qiang","Qin Fengqing","Huang Yuanyuan"],"pdf_url":"https://arxiv.org/pdf/2410.14103v1.pdf","comment":"12 pages, 6figures"},{"id":"http://arxiv.org/abs/2410.03302v3","updated":"2024-10-18T00:46:30Z","published":"2024-10-04T10:36:22Z","title":"Action Selection Learning for Multi-label Multi-view Action Recognition","summary":"  Multi-label multi-view action recognition aims to recognize multiple\nconcurrent or sequential actions from untrimmed videos captured by multiple\ncameras. Existing work has focused on multi-view action recognition in a narrow\narea with strong labels available, where the onset and offset of each action\nare labeled at the frame-level. This study focuses on real-world scenarios\nwhere cameras are distributed to capture a wide-range area with only weak\nlabels available at the video-level. We propose the method named Multi-view\nAction Selection Learning (MultiASL), which leverages action selection learning\nto enhance view fusion by selecting the most useful information from different\nviewpoints. The proposed method includes a Multi-view Spatial-Temporal\nTransformer video encoder to extract spatial and temporal features from\nmulti-viewpoint videos. Action Selection Learning is employed at the\nframe-level, using pseudo ground-truth obtained from weak labels at the\nvideo-level, to identify the most relevant frames for action recognition.\nExperiments in a real-world office environment using the MM-Office dataset\ndemonstrate the superior performance of the proposed method compared to\nexisting methods. The source code is available at\nhttps://github.com/thanhhff/MultiASL/.\n","authors":["Trung Thanh Nguyen","Yasutomo Kawanishi","Takahiro Komamizu","Ichiro Ide"],"pdf_url":"https://arxiv.org/pdf/2410.03302v3.pdf","comment":"ACM Multimedia Asia 2024"},{"id":"http://arxiv.org/abs/2410.14093v1","updated":"2024-10-18T00:18:27Z","published":"2024-10-18T00:18:27Z","title":"Enhancing In-vehicle Multiple Object Tracking Systems with Embeddable\n  Ising Machines","summary":"  A cognitive function of tracking multiple objects, needed in autonomous\nmobile vehicles, comprises object detection and their temporal association.\nWhile great progress owing to machine learning has been recently seen for\nelaborating the similarity matrix between the objects that have been recognized\nand the objects detected in a current video frame, less for the assignment\nproblem that finally determines the temporal association, which is a\ncombinatorial optimization problem. Here we show an in-vehicle multiple object\ntracking system with a flexible assignment function for tracking through\nmultiple long-term occlusion events. To solve the flexible assignment problem\nformulated as a nondeterministic polynomial time-hard problem, the system\nrelies on an embeddable Ising machine based on a quantum-inspired algorithm\ncalled simulated bifurcation. Using a vehicle-mountable computing platform, we\ndemonstrate a realtime system-wide throughput (23 frames per second on average)\nwith the enhanced functionality.\n","authors":["Kosuke Tatsumura","Yohei Hamakawa","Masaya Yamasaki","Koji Oya","Hiroshi Fujimoto"],"pdf_url":"https://arxiv.org/pdf/2410.14093v1.pdf","comment":"18 pages, 7 figures, 2 tables"}],"Information Retrieval":[{"id":"http://arxiv.org/abs/2410.13428v2","updated":"2024-10-18T09:55:18Z","published":"2024-10-17T10:51:34Z","title":"Generate and Instantiate What You Prefer: Text-Guided Diffusion for\n  Sequential Recommendation","summary":"  Recent advancements in generative recommendation systems, particularly in the\nrealm of sequential recommendation tasks, have shown promise in enhancing\ngeneralization to new items. Among these approaches, diffusion-based generative\nrecommendation has emerged as an effective tool, leveraging its ability to\ncapture data distributions and generate high-quality samples. Despite\neffectiveness, two primary challenges have been identified: 1) the lack of\nconsistent modeling of data distribution for oracle items; and 2) the\ndifficulty in scaling to more informative control signals beyond historical\ninteractions. These issues stem from the uninformative nature of ID embeddings,\nwhich necessitate random initialization and limit the incorporation of\nadditional control signals. To address these limitations, we propose iDreamRec\nto involve more concrete prior knowledge to establish item embeddings,\nparticularly through detailed item text descriptions and advanced Text\nEmbedding Models (TEM). More importantly, by converting item descriptions into\nembeddings aligned with TEM, we enable the integration of intention\ninstructions as control signals to guide the generation of oracle items.\nExperimental results on four datasets demonstrate that iDreamRec not only\noutperforms existing diffusion-based generative recommenders but also\nfacilitates the incorporation of intention instructions for more precise and\neffective recommendation generation.\n","authors":["Guoqing Hu","Zhangyi Yang","Zhibo Cai","An Zhang","Xiang Wang"],"pdf_url":"https://arxiv.org/pdf/2410.13428v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.13230v2","updated":"2024-10-18T08:36:37Z","published":"2024-10-17T05:33:50Z","title":"Starbucks: Improved Training for 2D Matryoshka Embeddings","summary":"  Effective approaches that can scale embedding model depth (i.e. layers) and\nembedding size allow for the creation of models that are highly scalable across\ndifferent computational resources and task requirements. While the recently\nproposed 2D Matryoshka training approach can efficiently produce a single\nembedding model such that its sub-layers and sub-dimensions can measure text\nsimilarity, its effectiveness is significantly worse than if smaller models\nwere trained separately. To address this issue, we propose Starbucks, a new\ntraining strategy for Matryoshka-like embedding models, which encompasses both\nthe fine-tuning and pre-training phases. For the fine-tuning phase, we discover\nthat, rather than sampling a random sub-layer and sub-dimensions for each\ntraining steps, providing a fixed list of layer-dimension pairs, from small\nsize to large sizes, and computing the loss across all pairs significantly\nimproves the effectiveness of 2D Matryoshka embedding models, bringing them on\npar with their separately trained counterparts. To further enhance performance,\nwe introduce a new pre-training strategy, which applies masked autoencoder\nlanguage modelling to sub-layers and sub-dimensions during pre-training,\nresulting in a stronger backbone for subsequent fine-tuning of the embedding\nmodel. Experimental results on both semantic text similarity and retrieval\nbenchmarks demonstrate that the proposed pre-training and fine-tuning\nstrategies significantly improved the effectiveness over 2D Matryoshka models,\nenabling Starbucks models to perform more efficiently and effectively than\nseparately trained models.\n","authors":["Shengyao Zhuang","Shuai Wang","Bevan Koopman","Guido Zuccon"],"pdf_url":"https://arxiv.org/pdf/2410.13230v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.08821v3","updated":"2024-10-18T17:50:57Z","published":"2024-08-16T16:09:59Z","title":"EasyRec: Simple yet Effective Language Models for Recommendation","summary":"  Deep neural networks have become a powerful technique for learning\nrepresentations from user-item interaction data in collaborative filtering (CF)\nfor recommender systems. However, many existing methods heavily rely on unique\nuser and item IDs, which limits their ability to perform well in practical\nzero-shot learning scenarios where sufficient training data may be unavailable.\nInspired by the success of language models (LMs) and their strong\ngeneralization capabilities, a crucial question arises: How can we harness the\npotential of language models to empower recommender systems and elevate its\ngeneralization capabilities to new heights? In this study, we propose EasyRec -\nan effective and easy-to-use approach that seamlessly integrates text-based\nsemantic understanding with collaborative signals. EasyRec employs a\ntext-behavior alignment framework, which combines contrastive learning with\ncollaborative language model tuning, to ensure a strong alignment between the\ntext-enhanced semantic space and the collaborative behavior information.\nExtensive empirical evaluations across diverse real-world datasets demonstrate\nthe superior performance of EasyRec compared to state-of-the-art alternative\nmodels, particularly in the challenging text-based zero-shot recommendation\nscenarios. Furthermore, the study highlights the potential of seamlessly\nintegrating EasyRec as a plug-and-play component into text-enhanced\ncollaborative filtering frameworks, thereby empowering existing recommender\nsystems to elevate their recommendation performance and adapt to the evolving\nuser preferences in dynamic environments. For better result reproducibility of\nour EasyRec framework, the model implementation details, source code, and\ndatasets are available at the link: https://github.com/HKUDS/EasyRec.\n","authors":["Xubin Ren","Chao Huang"],"pdf_url":"https://arxiv.org/pdf/2408.08821v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.14629v1","updated":"2024-10-18T17:30:17Z","published":"2024-10-18T17:30:17Z","title":"SIMformer: Single-Layer Vanilla Transformer Can Learn Free-Space\n  Trajectory Similarity","summary":"  Free-space trajectory similarity calculation, e.g., DTW, Hausdorff, and\nFrechet, often incur quadratic time complexity, thus learning-based methods\nhave been proposed to accelerate the computation. The core idea is to train an\nencoder to transform trajectories into representation vectors and then compute\nvector similarity to approximate the ground truth. However, existing methods\nface dual challenges of effectiveness and efficiency: 1) they all utilize\nEuclidean distance to compute representation similarity, which leads to the\nsevere curse of dimensionality issue -- reducing the distinguishability among\nrepresentations and significantly affecting the accuracy of subsequent\nsimilarity search tasks; 2) most of them are trained in triplets manner and\noften necessitate additional information which downgrades the efficiency; 3)\nprevious studies, while emphasizing the scalability in terms of efficiency,\noverlooked the deterioration of effectiveness when the dataset size grows. To\ncope with these issues, we propose a simple, yet accurate, fast, scalable model\nthat only uses a single-layer vanilla transformer encoder as the feature\nextractor and employs tailored representation similarity functions to\napproximate various ground truth similarity measures. Extensive experiments\ndemonstrate our model significantly mitigates the curse of dimensionality issue\nand outperforms the state-of-the-arts in effectiveness, efficiency, and\nscalability.\n","authors":["Chuang Yang","Renhe Jiang","Xiaohang Xu","Chuan Xiao","Kaoru Sezaki"],"pdf_url":"https://arxiv.org/pdf/2410.14629v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.14625v1","updated":"2024-10-18T17:27:07Z","published":"2024-10-18T17:27:07Z","title":"Enhancing AI Accessibility in Veterinary Medicine: Linking Classifiers\n  and Electronic Health Records","summary":"  In the rapidly evolving landscape of veterinary healthcare, integrating\nmachine learning (ML) clinical decision-making tools with electronic health\nrecords (EHRs) promises to improve diagnostic accuracy and patient care.\nHowever, the seamless integration of ML classifiers into existing EHRs in\nveterinary medicine is frequently hindered by the rigidity of EHR systems or\nthe limited availability of IT resources. To address this shortcoming, we\npresent Anna, a freely-available software solution that provides ML classifier\nresults for EHR laboratory data in real-time.\n","authors":["Chun Yin Kong","Picasso Vasquez","Makan Farhoodimoghadam","Chris Brandt","Titus C. Brown","Krystle L. Reagan","Allison Zwingenberger","Stefan M. Keller"],"pdf_url":"https://arxiv.org/pdf/2410.14625v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.14609v1","updated":"2024-10-18T17:03:17Z","published":"2024-10-18T17:03:17Z","title":"DiSCo Meets LLMs: A Unified Approach for Sparse Retrieval and Contextual\n  Distillation in Conversational Search","summary":"  Conversational Search (CS) is the task of retrieving relevant documents from\na corpus within a conversational context, combining retrieval with\nconversational context modeling. With the explosion of Large Language Models\n(LLMs), the CS field has seen major improvements with LLMs rewriting user\nqueries, accounting for conversational context. However, engaging LLMs at\ninference time harms efficiency. Current methods address this by distilling\nembeddings from human-rewritten queries to learn the context modeling task.\nYet, these approaches predominantly focus on context modeling, and only treat\nthe contrastive component of the retrieval task within a\ndistillation-independent loss term. To address these limitations, we propose a\nnew distillation method, as a relaxation of the previous objective, unifying\nretrieval and context modeling. We relax the existing training objectives by\ndistilling similarity scores between conversations and documents, rather than\nrelying solely on representation learning. Our proposed distillation objective\nallows for more freedom in the representation space and leverages the\ncontrastive nature of document relevance. Through experiments on Learned Sparse\nRetrieval (LSR) across 5 CS datasets, our approach demonstrates substantial\nimprovements in both in-domain and out-of-domain retrieval performance,\noutperforming state-of-the-art with gains of up to 6 points in recall for\nout-of-domain datasets. Additionally, through the relaxation of the objective,\nwe propose a multi-teacher distillation, using multiple LLMs as teachers,\nyielding additional gains, and outperforming the teachers themselves in\nin-domain experiments. Finally, analysis of the sparsity of the models reveals\nthat our distillation allows for better control over the sparsity of the\ntrained models.\n","authors":["Simon Lupart","Mohammad Aliannejadi","Evangelos Kanoulas"],"pdf_url":"https://arxiv.org/pdf/2410.14609v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.14567v1","updated":"2024-10-18T16:11:29Z","published":"2024-10-18T16:11:29Z","title":"RAG-ConfusionQA: A Benchmark for Evaluating LLMs on Confusing Questions","summary":"  Conversational AI agents use Retrieval Augmented Generation (RAG) to provide\nverifiable document-grounded responses to user inquiries. However, many natural\nquestions do not have good answers: about 25\\% contain false\nassumptions~\\cite{Yu2023:CREPE}, and over 50\\% are\nambiguous~\\cite{Min2020:AmbigQA}. RAG agents need high-quality data to improve\ntheir responses to confusing questions. This paper presents a novel synthetic\ndata generation method to efficiently create a diverse set of context-grounded\nconfusing questions from a given document corpus. We conduct an empirical\ncomparative evaluation of several large language models as RAG agents to\nmeasure the accuracy of confusion detection and appropriate response\ngeneration. We contribute a benchmark dataset to the public domain.\n","authors":["Zhiyuan Peng","Jinming Nian","Alexandre Evfimievski","Yi Fang"],"pdf_url":"https://arxiv.org/pdf/2410.14567v1.pdf","comment":"under review"},{"id":"http://arxiv.org/abs/2407.14346v2","updated":"2024-10-18T13:59:54Z","published":"2024-07-19T14:28:53Z","title":"Improving Retrieval in Sponsored Search by Leveraging Query Context\n  Signals","summary":"  Accurately retrieving relevant bid keywords for user queries is critical in\nSponsored Search but remains challenging, particularly for short, ambiguous\nqueries. Existing dense and generative retrieval models often fail to capture\nnuanced user intent in these cases. To address this, we propose an approach to\nenhance query understanding by augmenting queries with rich contextual signals\nderived from web search results and large language models, stored in an online\ncache. Specifically, we use web search titles and snippets to ground queries in\nreal-world information and utilize GPT-4 to generate query rewrites and\nexplanations that clarify user intent. These signals are efficiently integrated\nthrough a Fusion-in-Decoder based Unity architecture, enabling both dense and\ngenerative retrieval with serving costs on par with traditional context-free\nmodels. To address scenarios where context is unavailable in the cache, we\nintroduce context glancing, a curriculum learning strategy that improves model\nrobustness and performance even without contextual signals during inference.\nExtensive offline experiments demonstrate that our context-aware approach\nsubstantially outperforms context-free models. Furthermore, online A/B testing\non a prominent search engine across 160+ countries shows significant\nimprovements in user engagement and revenue.\n","authors":["Akash Kumar Mohankumar","Gururaj K","Gagan Madan","Amit Singh"],"pdf_url":"https://arxiv.org/pdf/2407.14346v2.pdf","comment":"Accepted to EMNLP 2024 Industry Track. 10 pages, 10 tables, 1 figure"},{"id":"http://arxiv.org/abs/2409.14217v2","updated":"2024-10-18T13:25:29Z","published":"2024-09-21T18:39:53Z","title":"Revisiting BPR: A Replicability Study of a Common Recommender System\n  Baseline","summary":"  Bayesian Personalized Ranking (BPR), a collaborative filtering approach based\non matrix factorization, frequently serves as a benchmark for recommender\nsystems research. However, numerous studies often overlook the nuances of BPR\nimplementation, claiming that it performs worse than newly proposed methods\nacross various tasks. In this paper, we thoroughly examine the features of the\nBPR model, indicating their impact on its performance, and investigate\nopen-source BPR implementations. Our analysis reveals inconsistencies between\nthese implementations and the original BPR paper, leading to a significant\ndecrease in performance of up to 50% for specific implementations. Furthermore,\nthrough extensive experiments on real-world datasets under modern evaluation\nsettings, we demonstrate that with proper tuning of its hyperparameters, the\nBPR model can achieve performance levels close to state-of-the-art methods on\nthe top-n recommendation tasks and even outperform them on specific datasets.\nSpecifically, on the Million Song Dataset, the BPR model with hyperparameters\ntuning statistically significantly outperforms Mult-VAE by 10% in NDCG@100 with\nbinary relevance function.\n","authors":["Aleksandr Milogradskii","Oleg Lashinin","Alexander P","Marina Ananyeva","Sergey Kolesnikov"],"pdf_url":"https://arxiv.org/pdf/2409.14217v2.pdf","comment":"This paper is accepted at the Reproducibility track of the ACM RecSys\n  '24 conference"},{"id":"http://arxiv.org/abs/2410.14452v1","updated":"2024-10-18T13:24:18Z","published":"2024-10-18T13:24:18Z","title":"SPFresh: Incremental In-Place Update for Billion-Scale Vector Search","summary":"  Approximate Nearest Neighbor Search (ANNS) is now widely used in various\napplications, ranging from information retrieval, question answering, and\nrecommendation, to search for similar high-dimensional vectors. As the amount\nof vector data grows continuously, it becomes important to support updates to\nvector index, the enabling technique that allows for efficient and accurate\nANNS on vectors. Because of the curse of high dimensionality, it is often\ncostly to identify the right neighbors of a single new vector, a necessary\nprocess for index update. To amortize update costs, existing systems maintain a\nsecondary index to accumulate updates, which are merged by the main index by\nglobal rebuilding the entire index periodically. However, this approach has\nhigh fluctuations of search latency and accuracy, not even to mention that it\nrequires substantial resources and is extremely time-consuming for rebuilds. We\nintroduce SPFresh, a system that supports in-place vector updates. At the heart\nof SPFresh is LIRE, a lightweight incremental rebalancing protocol to split\nvector partitions and reassign vectors in the nearby partitions to adapt to\ndata distribution shift. LIRE achieves low-overhead vector updates by only\nreassigning vectors at the boundary between partitions, where in a high-quality\nvector index the amount of such vectors are deemed small. With LIRE, SPFresh\nprovides superior query latency and accuracy to solutions based on global\nrebuild, with only 1% of DRAM and less than 10% cores needed at the peak\ncompared to the state-of-the-art, in a billion scale vector index with 1% of\ndaily vector update rate.\n","authors":["Yuming Xu","Hengyu Liang","Jin Li","Shuotao Xu","Qi Chen","Qianxi Zhang","Cheng Li","Ziyue Yang","Fan Yang","Yuqing Yang","Peng Cheng","Mao Yang"],"pdf_url":"https://arxiv.org/pdf/2410.14452v1.pdf","comment":"SOSP 23"},{"id":"http://arxiv.org/abs/2410.14331v1","updated":"2024-10-18T09:43:30Z","published":"2024-10-18T09:43:30Z","title":"ChartifyText: Automated Chart Generation from Data-Involved Texts via\n  LLM","summary":"  Text documents with numerical values involved are widely used in various\napplications such as scientific research, economy, public health and\njournalism. However, it is difficult for readers to quickly interpret such\ndata-involved texts and gain deep insights. To fill this research gap, this\nwork aims to automatically generate charts to accurately convey the underlying\ndata and ideas to readers, which is essentially a challenging task. The\nchallenges originate from text ambiguities, intrinsic sparsity and uncertainty\nof data in text documents, and subjective sentiment differences. Specifically,\nwe propose ChartifyText, a novel fully-automated approach that leverages Large\nLanguage Models (LLMs) to convert complex data-involved texts to expressive\ncharts. It consists of two major modules: tabular data inference and expressive\nchart generation. The tabular data inference module employs systematic prompt\nengineering to guide the LLM (e.g., GPT-4) to infer table data, where data\nranges, uncertainties, missing data values and corresponding subjective\nsentiments are explicitly considered. The expressive chart generation module\naugments standard charts with intuitive visual encodings and concise texts to\naccurately convey the underlying data and insights. We extensively evaluate the\neffectiveness of ChartifyText on real-world data-involved text documents\nthrough case studies, in-depth interviews with three visualization experts, and\na carefully-designed user study with 15 participants. The results demonstrate\nthe usefulness and effectiveness of ChartifyText in helping readers efficiently\nand effectively make sense of data-involved texts.\n","authors":["Songheng Zhang","Lei Wang","Toby Jia-Jun Li","Qiaomu Shen","Yixin Cao","Yong Wang"],"pdf_url":"https://arxiv.org/pdf/2410.14331v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2310.14626v2","updated":"2024-10-18T08:56:18Z","published":"2023-10-23T07:00:51Z","title":"Conversational Recommender System and Large Language Model Are Made for\n  Each Other in E-commerce Pre-sales Dialogue","summary":"  E-commerce pre-sales dialogue aims to understand and elicit user needs and\npreferences for the items they are seeking so as to provide appropriate\nrecommendations. Conversational recommender systems (CRSs) learn user\nrepresentation and provide accurate recommendations based on dialogue context,\nbut rely on external knowledge. Large language models (LLMs) generate responses\nthat mimic pre-sales dialogues after fine-tuning, but lack domain-specific\nknowledge for accurate recommendations. Intuitively, the strengths of LLM and\nCRS in E-commerce pre-sales dialogues are complementary, yet no previous work\nhas explored this. This paper investigates the effectiveness of combining LLM\nand CRS in E-commerce pre-sales dialogues, proposing two collaboration methods:\nCRS assisting LLM and LLM assisting CRS. We conduct extensive experiments on a\nreal-world dataset of Ecommerce pre-sales dialogues. We analyze the impact of\ntwo collaborative approaches with two CRSs and two LLMs on four tasks of\nEcommerce pre-sales dialogue. We find that collaborations between CRS and LLM\ncan be very effective in some cases.\n","authors":["Yuanxing Liu","Wei-Nan Zhang","Yifan Chen","Yuchi Zhang","Haopeng Bai","Fan Feng","Hengbin Cui","Yongbin Li","Wanxiang Che"],"pdf_url":"https://arxiv.org/pdf/2310.14626v2.pdf","comment":"EMNLP 2023 Findings"},{"id":"http://arxiv.org/abs/2406.06572v2","updated":"2024-10-18T08:20:38Z","published":"2024-06-03T17:07:46Z","title":"Graph Neural Network Enhanced Retrieval for Question Answering of LLMs","summary":"  Retrieval augmented generation has revolutionized large language model (LLM)\noutputs by providing factual supports. Nevertheless, it struggles to capture\nall the necessary knowledge for complex reasoning questions. Existing retrieval\nmethods typically divide reference documents into passages, treating them in\nisolation. These passages, however, are often interrelated, such as passages\nthat are contiguous or share the same keywords. Therefore, it is crucial to\nrecognize such relatedness for enhancing the retrieval process. In this paper,\nwe propose a novel retrieval method, called GNN-Ret, which leverages graph\nneural networks (GNNs) to enhance retrieval by exploiting the relatedness\nbetween passages. Specifically, we first construct a graph of passages by\nconnecting passages that are structure-related or keyword-related. A graph\nneural network (GNN) is then leveraged to exploit the relationships between\npassages and improve the retrieval of supporting passages. Furthermore, we\nextend our method to handle multi-hop reasoning questions using a recurrent\ngraph neural network (RGNN), named RGNN-Ret. At each step, RGNN-Ret integrates\nthe graphs of passages from previous steps, thereby enhancing the retrieval of\nsupporting passages. Extensive experiments on benchmark datasets demonstrate\nthat GNN-Ret achieves higher accuracy for question answering with a single\nquery of LLMs than strong baselines that require multiple queries, and RGNN-Ret\nfurther improves accuracy and achieves state-of-the-art performance, with up to\n10.4% accuracy improvement on the 2WikiMQA dataset.\n","authors":["Zijian Li","Qingyan Guo","Jiawei Shao","Lei Song","Jiang Bian","Jun Zhang","Rui Wang"],"pdf_url":"https://arxiv.org/pdf/2406.06572v2.pdf","comment":"Under review"},{"id":"http://arxiv.org/abs/2410.14241v1","updated":"2024-10-18T07:44:12Z","published":"2024-10-18T07:44:12Z","title":"Graph Neural Patching for Cold-Start Recommendations","summary":"  The cold start problem in recommender systems remains a critical challenge.\nCurrent solutions often train hybrid models on auxiliary data for both cold and\nwarm users/items, potentially degrading the experience for the latter. This\ndrawback limits their viability in practical scenarios where the satisfaction\nof existing warm users/items is paramount. Although graph neural networks\n(GNNs) excel at warm recommendations by effective collaborative signal\nmodeling, they haven't been effectively leveraged for the cold-start issue\nwithin a user-item graph, which is largely due to the lack of initial\nconnections for cold user/item entities. Addressing this requires a GNN adept\nat cold-start recommendations without sacrificing performance for existing\nones. To this end, we introduce Graph Neural Patching for Cold-Start\nRecommendations (GNP), a customized GNN framework with dual functionalities:\nGWarmer for modeling collaborative signal on existing warm users/items and\nPatching Networks for simulating and enhancing GWarmer's performance on\ncold-start recommendations. Extensive experiments on three benchmark datasets\nconfirm GNP's superiority in recommending both warm and cold users/items.\n","authors":["Hao Chen","Yu Yang","Yuanchen Bei","Zefan Wang","Yue Xu","Feiran Huang"],"pdf_url":"https://arxiv.org/pdf/2410.14241v1.pdf","comment":"13 pages, accepted by Australasian Database Conference 2024. arXiv\n  admin note: substantial text overlap with arXiv:2209.12215"},{"id":"http://arxiv.org/abs/2406.00012v2","updated":"2024-10-18T06:07:06Z","published":"2024-05-20T09:24:45Z","title":"FINED: Feed Instance-Wise Information Need with Essential and\n  Disentangled Parametric Knowledge from the Past","summary":"  Recommender models play a vital role in various industrial scenarios, while\noften faced with the catastrophic forgetting problem caused by the fast\nshifting data distribution. To alleviate this problem, a common approach is to\nreuse knowledge from the historical data. However, preserving the vast and\nfast-accumulating data is hard, which causes dramatic storage overhead.\nMemorizing old data through a parametric knowledge base is then proposed, which\ncompresses the vast amount of raw data into model parameters. Despite the\nflexibility, how to improve the memorization and generalization capabilities of\nthe parametric knowledge base and suit the flexible information need of each\ninstance are challenging. In this paper, we propose FINED to Feed INstance-wise\ninformation need with Essential and Disentangled parametric knowledge from past\ndata for recommendation enhancement. Concretely, we train a knowledge extractor\nthat extracts knowledge patterns of arbitrary order from past data and a\nknowledge encoder that memorizes the arbitrary order patterns, which serves as\nthe retrieval key generator and memory network respectively in the following\nknowledge reusing phase. The whole process is regularized by the proposed two\nconstraints, which improve the capabilities of the parametric knowledge base\nwithout increasing the size of it. The essential principle helps to compress\nthe input into representative vectors that capture the task-relevant\ninformation and filter out the noisy information. The disentanglement principle\nreduces the redundancy of stored information and pushes the knowledge base to\nfocus on capturing the disentangled invariant patterns. These two rules\ntogether promote rational compression of information for robust and generalized\nknowledge representations. Extensive experiments on two datasets justify the\neffectiveness of the proposed method.\n","authors":["Kounianhua Du","Jizheng Chen","Jianghao Lin","Menghui Zhu","Bo Chen","Shuai Li","Yong Yu","Weinan Zhang"],"pdf_url":"https://arxiv.org/pdf/2406.00012v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.14170v1","updated":"2024-10-18T04:20:46Z","published":"2024-10-18T04:20:46Z","title":"Personalized Image Generation with Large Multimodal Models","summary":"  Personalized content filtering, such as recommender systems, has become a\ncritical infrastructure to alleviate information overload. However, these\nsystems merely filter existing content and are constrained by its limited\ndiversity, making it difficult to meet users' varied content needs. To address\nthis limitation, personalized content generation has emerged as a promising\ndirection with broad applications. Nevertheless, most existing research focuses\non personalized text generation, with relatively little attention given to\npersonalized image generation. The limited work in personalized image\ngeneration faces challenges in accurately capturing users' visual preferences\nand needs from noisy user-interacted images and complex multimodal\ninstructions. Worse still, there is a lack of supervised data for training\npersonalized image generation models.\n  To overcome the challenges, we propose a Personalized Image Generation\nFramework named Pigeon, which adopts exceptional large multimodal models with\nthree dedicated modules to capture users' visual preferences and needs from\nnoisy user history and multimodal instructions. To alleviate the data scarcity,\nwe introduce a two-stage preference alignment scheme, comprising masked\npreference reconstruction and pairwise preference alignment, to align Pigeon\nwith the personalized image generation task. We apply Pigeon to personalized\nsticker and movie poster generation, where extensive quantitative results and\nhuman evaluation highlight its superiority over various generative baselines.\n","authors":["Yiyan Xu","Wenjie Wang","Yang Zhang","Tang Biao","Peng Yan","Fuli Feng","Xiangnan He"],"pdf_url":"https://arxiv.org/pdf/2410.14170v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.14167v1","updated":"2024-10-18T04:17:49Z","published":"2024-10-18T04:17:49Z","title":"Optimizing Retrieval-Augmented Generation with Elasticsearch for\n  Enhanced Question-Answering Systems","summary":"  This study aims to improve the accuracy and quality of large-scale language\nmodels (LLMs) in answering questions by integrating Elasticsearch into the\nRetrieval Augmented Generation (RAG) framework. The experiment uses the\nStanford Question Answering Dataset (SQuAD) version 2.0 as the test dataset and\ncompares the performance of different retrieval methods, including traditional\nmethods based on keyword matching or semantic similarity calculation, BM25-RAG\nand TF-IDF- RAG, and the newly proposed ES-RAG scheme. The results show that\nES-RAG not only has obvious advantages in retrieval efficiency but also\nperforms well in key indicators such as accuracy, which is 0.51 percentage\npoints higher than TF-IDF-RAG. In addition, Elasticsearch's powerful search\ncapabilities and rich configuration options enable the entire\nquestion-answering system to better handle complex queries and provide more\nflexible and efficient responses based on the diverse needs of users. Future\nresearch directions can further explore how to optimize the interaction\nmechanism between Elasticsearch and LLM, such as introducing higher-level\nsemantic understanding and context-awareness capabilities, to achieve a more\nintelligent and humanized question-answering experience.\n","authors":["Jiajing Chen","Runyuan Bao","Hongye Zheng","Zhen Qi","Jianjun Wei","Jiacheng Hu"],"pdf_url":"https://arxiv.org/pdf/2410.14167v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.14122v1","updated":"2024-10-18T02:31:36Z","published":"2024-10-18T02:31:36Z","title":"Towards Robust Transcription: Exploring Noise Injection Strategies for\n  Training Data Augmentation","summary":"  Recent advancements in Automatic Piano Transcription (APT) have significantly\nimproved system performance, but the impact of noisy environments on the system\nperformance remains largely unexplored. This study investigates the impact of\nwhite noise at various Signal-to-Noise Ratio (SNR) levels on state-of-the-art\nAPT models and evaluates the performance of the Onsets and Frames model when\ntrained on noise-augmented data. We hope this research provides valuable\ninsights as preliminary work toward developing transcription models that\nmaintain consistent performance across a range of acoustic conditions.\n","authors":["Yonghyun Kim","Alexander Lerch"],"pdf_url":"https://arxiv.org/pdf/2410.14122v1.pdf","comment":"Accepted to the Late-Breaking Demo Session of the 25th International\n  Society for Music Information Retrieval (ISMIR) Conference, 2024"},{"id":"http://arxiv.org/abs/2407.12982v2","updated":"2024-10-18T18:42:25Z","published":"2024-07-17T20:01:21Z","title":"Retrieval-Enhanced Machine Learning: Synthesis and Opportunities","summary":"  In the field of language modeling, models augmented with retrieval components\nhave emerged as a promising solution to address several challenges faced in the\nnatural language processing (NLP) field, including knowledge grounding,\ninterpretability, and scalability. Despite the primary focus on NLP, we posit\nthat the paradigm of retrieval-enhancement can be extended to a broader\nspectrum of machine learning (ML) such as computer vision, time series\nprediction, and computational biology. Therefore, this work introduces a formal\nframework of this paradigm, Retrieval-Enhanced Machine Learning (REML), by\nsynthesizing the literature in various domains in ML with consistent notations\nwhich is missing from the current literature. Also, we found that while a\nnumber of studies employ retrieval components to augment their models, there is\na lack of integration with foundational Information Retrieval (IR) research. We\nbridge this gap between the seminal IR research and contemporary REML studies\nby investigating each component that comprises the REML framework. Ultimately,\nthe goal of this work is to equip researchers across various disciplines with a\ncomprehensive, formally structured framework of retrieval-enhanced models,\nthereby fostering interdisciplinary future research.\n","authors":["To Eun Kim","Alireza Salemi","Andrew Drozdov","Fernando Diaz","Hamed Zamani"],"pdf_url":"https://arxiv.org/pdf/2407.12982v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.14808v1","updated":"2024-10-18T18:30:05Z","published":"2024-10-18T18:30:05Z","title":"The S2 Hierarchical Discrete Global Grid as a Nexus for Data\n  Representation, Integration, and Querying Across Geospatial Knowledge Graphs","summary":"  Geospatial Knowledge Graphs (GeoKGs) have become integral to the growing\nfield of Geospatial Artificial Intelligence. Initiatives like the U.S. National\nScience Foundation's Open Knowledge Network program aim to create an ecosystem\nof nation-scale, cross-disciplinary GeoKGs that provide AI-ready geospatial\ndata aligned with FAIR principles. However, building this infrastructure\npresents key challenges, including 1) managing large volumes of data, 2) the\ncomputational complexity of discovering topological relations via SPARQL, and\n3) conflating multi-scale raster and vector data. Discrete Global Grid Systems\n(DGGS) help tackle these issues by offering efficient data integration and\nrepresentation strategies. The KnowWhereGraph utilizes Google's S2 Geometry --\na DGGS framework -- to enable efficient multi-source data processing,\nqualitative spatial querying, and cross-graph integration. This paper outlines\nthe implementation of S2 within KnowWhereGraph, emphasizing its role in\ntopologically enriching and semantically compressing data. Ultimately, this\nwork demonstrates the potential of DGGS frameworks, particularly S2, for\nbuilding scalable GeoKGs.\n","authors":["Shirly Stephen","Mitchell Faulk","Krzysztof Janowicz","Colby Fisher","Thomas Thelen","Rui Zhu","Pascal Hitzler","Cogan Shimizu","Kitty Currier","Mark Schildhauer","Dean Rehberger","Zhangyu Wang","Antrea Christou"],"pdf_url":"https://arxiv.org/pdf/2410.14808v1.pdf","comment":null}],"Machine Learning":[{"id":"http://arxiv.org/abs/2410.13754v2","updated":"2024-10-18T08:56:52Z","published":"2024-10-17T16:52:28Z","title":"MixEval-X: Any-to-Any Evaluations from Real-World Data Mixtures","summary":"  Perceiving and generating diverse modalities are crucial for AI models to\neffectively learn from and engage with real-world signals, necessitating\nreliable evaluations for their development. We identify two major issues in\ncurrent evaluations: (1) inconsistent standards, shaped by different\ncommunities with varying protocols and maturity levels; and (2) significant\nquery, grading, and generalization biases. To address these, we introduce\nMixEval-X, the first any-to-any, real-world benchmark designed to optimize and\nstandardize evaluations across diverse input and output modalities. We propose\nmulti-modal benchmark mixture and adaptation-rectification pipelines to\nreconstruct real-world task distributions, ensuring evaluations generalize\neffectively to real-world use cases. Extensive meta-evaluations show our\napproach effectively aligns benchmark samples with real-world task\ndistributions. Meanwhile, MixEval-X's model rankings correlate strongly with\nthat of crowd-sourced real-world evaluations (up to 0.98) while being much more\nefficient. We provide comprehensive leaderboards to rerank existing models and\norganizations and offer insights to enhance understanding of multi-modal\nevaluations and inform future research.\n","authors":["Jinjie Ni","Yifan Song","Deepanway Ghosal","Bo Li","David Junhao Zhang","Xiang Yue","Fuzhao Xue","Zian Zheng","Kaichen Zhang","Mahir Shah","Kabir Jain","Yang You","Michael Shieh"],"pdf_url":"https://arxiv.org/pdf/2410.13754v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.13602v2","updated":"2024-10-18T07:04:25Z","published":"2024-10-17T14:36:58Z","title":"Towards Satellite Non-IID Imagery: A Spectral Clustering-Assisted\n  Federated Learning Approach","summary":"  Low Earth orbit (LEO) satellites are capable of gathering abundant Earth\nobservation data (EOD) to enable different Internet of Things (IoT)\napplications. However, to accomplish an effective EOD processing mechanism, it\nis imperative to investigate: 1) the challenge of processing the observed data\nwithout transmitting those large-size data to the ground because the connection\nbetween the satellites and the ground stations is intermittent, and 2) the\nchallenge of processing the non-independent and identically distributed\n(non-IID) satellite data. In this paper, to cope with those challenges, we\npropose an orbit-based spectral clustering-assisted clustered federated\nself-knowledge distillation (OSC-FSKD) approach for each orbit of an LEO\nsatellite constellation, which retains the advantage of FL that the observed\ndata does not need to be sent to the ground. Specifically, we introduce\nnormalized Laplacian-based spectral clustering (NLSC) into federated learning\n(FL) to create clustered FL in each round to address the challenge resulting\nfrom non-IID data. Particularly, NLSC is adopted to dynamically group clients\ninto several clusters based on cosine similarities calculated by model updates.\nIn addition, self-knowledge distillation is utilized to construct each local\nclient, where the most recent updated local model is used to guide current\nlocal model training. Experiments demonstrate that the observation accuracy\nobtained by the proposed method is separately 1.01x, 2.15x, 1.10x, and 1.03x\nhigher than that of pFedSD, FedProx, FedAU, and FedALA approaches using the\nSAT4 dataset. The proposed method also shows superiority when using other\ndatasets.\n","authors":["Luyao Zou","Yu Min Park","Chu Myaet Thwal","Yan Kyaw Tun","Zhu Han","Choong Seon Hong"],"pdf_url":"https://arxiv.org/pdf/2410.13602v2.pdf","comment":"10 pages, 5 figures"},{"id":"http://arxiv.org/abs/2404.16710v4","updated":"2024-10-18T04:02:31Z","published":"2024-04-25T16:20:23Z","title":"LayerSkip: Enabling Early Exit Inference and Self-Speculative Decoding","summary":"  We present LayerSkip, an end-to-end solution to speed-up inference of large\nlanguage models (LLMs). First, during training we apply layer dropout, with low\ndropout rates for earlier layers and higher dropout rates for later layers, and\nan early exit loss where all transformer layers share the same exit. Second,\nduring inference, we show that this training recipe increases the accuracy of\nearly exit at earlier layers, without adding any auxiliary layers or modules to\nthe model. Third, we present a novel self-speculative decoding solution where\nwe exit at early layers and verify and correct with remaining layers of the\nmodel. Our proposed self-speculative decoding approach has less memory\nfootprint than other speculative decoding approaches and benefits from shared\ncompute and activations of the draft and verification stages. We run\nexperiments on different Llama model sizes on different types of training:\npretraining from scratch, continual pretraining, finetuning on specific data\ndomain, and finetuning on specific task. We implement our inference solution\nand show speedups of up to 2.16x on summarization for CNN/DM documents, 1.82x\non coding, and 2.0x on TOPv2 semantic parsing task. We open source our code and\ncheckpoints at https://github.com/facebookresearch/LayerSkip.\n","authors":["Mostafa Elhoushi","Akshat Shrivastava","Diana Liskovich","Basil Hosmer","Bram Wasti","Liangzhen Lai","Anas Mahmoud","Bilge Acun","Saurabh Agarwal","Ahmed Roman","Ahmed A Aly","Beidi Chen","Carole-Jean Wu"],"pdf_url":"https://arxiv.org/pdf/2404.16710v4.pdf","comment":"ACL 2024"},{"id":"http://arxiv.org/abs/2410.13408v2","updated":"2024-10-18T03:05:01Z","published":"2024-10-17T10:14:52Z","title":"MoR: Mixture of Ranks for Low-Rank Adaptation Tuning","summary":"  Low-Rank Adaptation (LoRA) drives research to align its performance with full\nfine-tuning. However, significant challenges remain: (1) Simply increasing the\nrank size of LoRA does not effectively capture high-rank information, which\nleads to a performance bottleneck.(2) MoE-style LoRA methods substantially\nincrease parameters and inference latency, contradicting the goals of efficient\nfine-tuning and ease of application. To address these challenges, we introduce\nMixture of Ranks (MoR), which learns rank-specific information for different\ntasks based on input and efficiently integrates multi-rank information. We\nfirstly propose a new framework that equates the integration of multiple LoRAs\nto expanding the rank of LoRA. Moreover, we hypothesize that low-rank LoRA\nalready captures sufficient intrinsic information, and MoR can derive high-rank\ninformation through mathematical transformations of the low-rank components.\nThus, MoR can reduces the learning difficulty of LoRA and enhances its\nmulti-task capabilities. MoR achieves impressive results, with MoR delivering a\n1.31\\% performance improvement while using only 93.93\\% of the parameters\ncompared to baseline methods.\n","authors":["Chuanyu Tang","Yilong Chen","Zhenyu Zhang","Junyuan Shang","Wenyuan Zhang","Yong Huang","Tingwen Liu"],"pdf_url":"https://arxiv.org/pdf/2410.13408v2.pdf","comment":"11 pages, 7 figures"},{"id":"http://arxiv.org/abs/2410.14673v1","updated":"2024-10-18T17:59:25Z","published":"2024-10-18T17:59:25Z","title":"Self-supervised contrastive learning performs non-linear system\n  identification","summary":"  Self-supervised learning (SSL) approaches have brought tremendous success\nacross many tasks and domains. It has been argued that these successes can be\nattributed to a link between SSL and identifiable representation learning:\nTemporal structure and auxiliary variables ensure that latent representations\nare related to the true underlying generative factors of the data. Here, we\ndeepen this connection and show that SSL can perform system identification in\nlatent space. We propose DynCL, a framework to uncover linear, switching linear\nand non-linear dynamics under a non-linear observation model, give theoretical\nguarantees and validate them empirically.\n","authors":["Rodrigo González Laiz","Tobias Schmidt","Steffen Schneider"],"pdf_url":"https://arxiv.org/pdf/2410.14673v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.14670v1","updated":"2024-10-18T17:58:53Z","published":"2024-10-18T17:58:53Z","title":"Decomposing The Dark Matter of Sparse Autoencoders","summary":"  Sparse autoencoders (SAEs) are a promising technique for decomposing language\nmodel activations into interpretable linear features. However, current SAEs\nfall short of completely explaining model performance, resulting in \"dark\nmatter\": unexplained variance in activations. This work investigates dark\nmatter as an object of study in its own right. Surprisingly, we find that much\nof SAE dark matter--about half of the error vector itself and >90% of its\nnorm--can be linearly predicted from the initial activation vector.\nAdditionally, we find that the scaling behavior of SAE error norms at a per\ntoken level is remarkably predictable: larger SAEs mostly struggle to\nreconstruct the same contexts as smaller SAEs. We build on the linear\nrepresentation hypothesis to propose models of activations that might lead to\nthese observations, including postulating a new type of \"introduced error\";\nthese insights imply that the part of the SAE error vector that cannot be\nlinearly predicted (\"nonlinear\" error) might be fundamentally different from\nthe linearly predictable component. To validate this hypothesis, we empirically\nanalyze nonlinear SAE error and show that 1) it contains fewer not yet learned\nfeatures, 2) SAEs trained on it are quantitatively worse, 3) it helps predict\nSAE per-token scaling behavior, and 4) it is responsible for a proportional\namount of the downstream increase in cross entropy loss when SAE activations\nare inserted into the model. Finally, we examine two methods to reduce\nnonlinear SAE error at a fixed sparsity: inference time gradient pursuit, which\nleads to a very slight decrease in nonlinear error, and linear transformations\nfrom earlier layer SAE outputs, which leads to a larger reduction.\n","authors":["Joshua Engels","Logan Riggs","Max Tegmark"],"pdf_url":"https://arxiv.org/pdf/2410.14670v1.pdf","comment":"Code at https://github.com/JoshEngels/SAE-Dark-Matter"},{"id":"http://arxiv.org/abs/2410.14667v1","updated":"2024-10-18T17:57:01Z","published":"2024-10-18T17:57:01Z","title":"Stochastic Gradient Descent Jittering for Inverse Problems: Alleviating\n  the Accuracy-Robustness Tradeoff","summary":"  Inverse problems aim to reconstruct unseen data from corrupted or perturbed\nmeasurements. While most work focuses on improving reconstruction quality,\ngeneralization accuracy and robustness are equally important, especially for\nsafety-critical applications. Model-based architectures (MBAs), such as loop\nunrolling methods, are considered more interpretable and achieve better\nreconstructions. Empirical evidence suggests that MBAs are more robust to\nperturbations than black-box solvers, but the accuracy-robustness tradeoff in\nMBAs remains underexplored. In this work, we propose a simple yet effective\ntraining scheme for MBAs, called SGD jittering, which injects noise\niteration-wise during reconstruction. We theoretically demonstrate that SGD\njittering not only generalizes better than the standard mean squared error\ntraining but is also more robust to average-case attacks. We validate SGD\njittering using denoising toy examples, seismic deconvolution, and single-coil\nMRI reconstruction. The proposed method achieves cleaner reconstructions for\nout-of-distribution data and demonstrates enhanced robustness to adversarial\nattacks.\n","authors":["Peimeng Guan","Mark A. Davenport"],"pdf_url":"https://arxiv.org/pdf/2410.14667v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.14666v1","updated":"2024-10-18T17:56:11Z","published":"2024-10-18T17:56:11Z","title":"DiscoGraMS: Enhancing Movie Screen-Play Summarization using Movie\n  Character-Aware Discourse Graph","summary":"  Summarizing movie screenplays presents a unique set of challenges compared to\nstandard document summarization. Screenplays are not only lengthy, but also\nfeature a complex interplay of characters, dialogues, and scenes, with numerous\ndirect and subtle relationships and contextual nuances that are difficult for\nmachine learning models to accurately capture and comprehend. Recent attempts\nat screenplay summarization focus on fine-tuning transformer-based pre-trained\nmodels, but these models often fall short in capturing long-term dependencies\nand latent relationships, and frequently encounter the \"lost in the middle\"\nissue. To address these challenges, we introduce DiscoGraMS, a novel resource\nthat represents movie scripts as a movie character-aware discourse graph (CaD\nGraph). This approach is well-suited for various downstream tasks, such as\nsummarization, question-answering, and salience detection. The model aims to\npreserve all salient information, offering a more comprehensive and faithful\nrepresentation of the screenplay's content. We further explore a baseline\nmethod that combines the CaD Graph with the corresponding movie script through\na late fusion of graph and text modalities, and we present very initial\npromising results.\n","authors":["Maitreya Prafulla Chitale","Uday Bindal","Rajakrishnan Rajkumar","Rahul Mishra"],"pdf_url":"https://arxiv.org/pdf/2410.14666v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.14665v1","updated":"2024-10-18T17:55:15Z","published":"2024-10-18T17:55:15Z","title":"Online Reinforcement Learning with Passive Memory","summary":"  This paper considers an online reinforcement learning algorithm that\nleverages pre-collected data (passive memory) from the environment for online\ninteraction. We show that using passive memory improves performance and further\nprovide theoretical guarantees for regret that turns out to be near-minimax\noptimal. Results show that the quality of passive memory determines\nsub-optimality of the incurred regret. The proposed approach and results hold\nin both continuous and discrete state-action spaces.\n","authors":["Anay Pattanaik","Lav R. Varshney"],"pdf_url":"https://arxiv.org/pdf/2410.14665v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.06331v2","updated":"2024-10-18T17:53:46Z","published":"2024-10-08T20:12:11Z","title":"Locate-then-edit for Multi-hop Factual Recall under Knowledge Editing","summary":"  The locate-then-edit paradigm has shown significant promise for knowledge\nediting (KE) in Large Language Models (LLMs). While previous methods perform\nwell on single-hop fact recall tasks, they consistently struggle with multi-hop\nfactual recall tasks involving newly edited knowledge. In this paper,\nleveraging tools in mechanistic interpretability, we first identify that in\nmulti-hop tasks, LLMs tend to retrieve implicit subject knowledge from deeper\nMLP layers, unlike single-hop tasks, which rely on earlier layers. This\ndistinction explains the poor performance of current methods in multi-hop\nqueries, as they primarily focus on editing shallow layers, leaving deeper\nlayers unchanged. To address this, we propose IFMET, a novel locate-then-edit\nKE approach designed to edit both shallow and deep MLP layers. IFMET employs\nmulti-hop editing prompts and supplementary sets to locate and modify knowledge\nacross different reasoning stages. Experimental results demonstrate that IFMET\nsignificantly improves performance on multi-hop factual recall tasks,\neffectively overcoming the limitations of previous locate-then-edit methods.\n","authors":["Zhuoran Zhang","Yongxiang Li","Zijian Kan","Keyuan Cheng","Lijie Hu","Di Wang"],"pdf_url":"https://arxiv.org/pdf/2410.06331v2.pdf","comment":"21 pages"},{"id":"http://arxiv.org/abs/2410.14660v1","updated":"2024-10-18T17:51:51Z","published":"2024-10-18T17:51:51Z","title":"A Large Language Model-Driven Reward Design Framework via Dynamic\n  Feedback for Reinforcement Learning","summary":"  Large Language Models (LLMs) have shown significant potential in designing\nreward functions for Reinforcement Learning (RL) tasks. However, obtaining\nhigh-quality reward code often involves human intervention, numerous LLM\nqueries, or repetitive RL training. To address these issues, we propose CARD, a\nLLM-driven Reward Design framework that iteratively generates and improves\nreward function code. Specifically, CARD includes a Coder that generates and\nverifies the code, while a Evaluator provides dynamic feedback to guide the\nCoder in improving the code, eliminating the need for human feedback. In\naddition to process feedback and trajectory feedback, we introduce Trajectory\nPreference Evaluation (TPE), which evaluates the current reward function based\non trajectory preferences. If the code fails the TPE, the Evaluator provides\npreference feedback, avoiding RL training at every iteration and making the\nreward function better aligned with the task objective. Empirical results on\nMeta-World and ManiSkill2 demonstrate that our method achieves an effective\nbalance between task performance and token efficiency, outperforming or\nmatching the baselines across all tasks. On 10 out of 12 tasks, CARD shows\nbetter or comparable performance to policies trained with expert-designed\nrewards, and our method even surpasses the oracle on 3 tasks.\n","authors":["Shengjie Sun","Runze Liu","Jiafei Lyu","Jing-Wen Yang","Liangpeng Zhang","Xiu Li"],"pdf_url":"https://arxiv.org/pdf/2410.14660v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.14659v1","updated":"2024-10-18T17:51:37Z","published":"2024-10-18T17:51:37Z","title":"Harnessing Causality in Reinforcement Learning With Bagged Decision\n  Times","summary":"  We consider reinforcement learning (RL) for a class of problems with bagged\ndecision times. A bag contains a finite sequence of consecutive decision times.\nThe transition dynamics are non-Markovian and non-stationary within a bag.\nFurther, all actions within a bag jointly impact a single reward, observed at\nthe end of the bag. Our goal is to construct an online RL algorithm to maximize\nthe discounted sum of the bag-specific rewards. To handle non-Markovian\ntransitions within a bag, we utilize an expert-provided causal directed acyclic\ngraph (DAG). Based on the DAG, we construct the states as a dynamical Bayesian\nsufficient statistic of the observed history, which results in Markovian state\ntransitions within and across bags. We then frame this problem as a periodic\nMarkov decision process (MDP) that allows non-stationarity within a period. An\nonline RL algorithm based on Bellman-equations for stationary MDPs is\ngeneralized to handle periodic MDPs. To justify the proposed RL algorithm, we\nshow that our constructed state achieves the maximal optimal value function\namong all state constructions for a periodic MDP. Further we prove the Bellman\noptimality equations for periodic MDPs. We evaluate the proposed method on\ntestbed variants, constructed with real data from a mobile health clinical\ntrial.\n","authors":["Daiqi Gao","Hsin-Yu Lai","Predrag Klasnja","Susan A. Murphy"],"pdf_url":"https://arxiv.org/pdf/2410.14659v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.14655v1","updated":"2024-10-18T17:48:27Z","published":"2024-10-18T17:48:27Z","title":"Bridging the Training-Inference Gap in LLMs by Leveraging Self-Generated\n  Tokens","summary":"  Language models are often trained to maximize the likelihood of the next\ntoken given past tokens in the training dataset. However, during inference\ntime, they are utilized differently, generating text sequentially and\nauto-regressively by using previously generated tokens as input to predict the\nnext one. Marginal differences in predictions at each step can cascade over\nsuccessive steps, resulting in different distributions from what the models\nwere trained for and potentially leading to unpredictable behavior. This paper\nproposes two simple approaches based on model own generation to address this\ndiscrepancy between the training and inference time. Our first approach is\nBatch-Scheduled Sampling, where, during training, we stochastically choose\nbetween the ground-truth token from the dataset and the model's own generated\ntoken as input to predict the next token. This is done in an offline manner,\nmodifying the context window by interleaving ground-truth tokens with those\ngenerated by the model. Our second approach is Reference-Answer-based\nCorrection, where we explicitly incorporate a self-correction capability into\nthe model during training. This enables the model to effectively self-correct\nthe gaps between the generated sequences and the ground truth data without\nrelying on an external oracle model. By incorporating our proposed strategies\nduring training, we have observed an overall improvement in performance\ncompared to baseline methods, as demonstrated by our extensive experiments\nusing summarization, general question-answering, and math question-answering\ntasks.\n","authors":["Zhepeng Cen","Yao Liu","Siliang Zeng","Pratik Chaudhar","Huzefa Rangwala","George Karypis","Rasool Fakoor"],"pdf_url":"https://arxiv.org/pdf/2410.14655v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.14649v1","updated":"2024-10-18T17:46:37Z","published":"2024-10-18T17:46:37Z","title":"EvoPress: Towards Optimal Dynamic Model Compression via Evolutionary\n  Search","summary":"  The high computational costs of large language models (LLMs) have led to a\nflurry of research on LLM compression, via methods such as quantization,\nsparsification, or structured pruning. A new frontier in this area is given by\n\\emph{dynamic, non-uniform} compression methods, which adjust the compression\nlevels (e.g., sparsity) per-block or even per-layer in order to minimize\naccuracy loss, while guaranteeing a global compression threshold. Yet, current\nmethods rely on heuristics for identifying the \"importance\" of a given layer\ntowards the loss, based on assumptions such as \\emph{error monotonicity}, i.e.\nthat the end-to-end model compression error is proportional to the sum of\nlayer-wise errors. In this paper, we revisit this area, and propose a new and\ngeneral approach for dynamic compression that is provably optimal in a given\ninput range. We begin from the motivating observation that, in general,\n\\emph{error monotonicity does not hold for LLMs}: compressed models with lower\nsum of per-layer errors can perform \\emph{worse} than models with higher error\nsums. To address this, we propose a new general evolutionary framework for\ndynamic LLM compression called EvoPress, which has provable convergence, and\nlow sample and evaluation complexity. We show that these theoretical guarantees\nlead to highly competitive practical performance for dynamic compression of\nLlama, Mistral and Phi models. Via EvoPress, we set new state-of-the-art\nresults across all compression approaches: structural pruning (block/layer\ndropping), unstructured sparsity, as well as quantization with dynamic\nbitwidths. Our code is available at https://github.com/IST-DASLab/EvoPress.\n","authors":["Oliver Sieberling","Denis Kuznedelev","Eldar Kurtic","Dan Alistarh"],"pdf_url":"https://arxiv.org/pdf/2410.14649v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.14640v1","updated":"2024-10-18T17:41:19Z","published":"2024-10-18T17:41:19Z","title":"HR-Bandit: Human-AI Collaborated Linear Recourse Bandit","summary":"  Human doctors frequently recommend actionable recourses that allow patients\nto modify their conditions to access more effective treatments. Inspired by\nsuch healthcare scenarios, we propose the Recourse Linear UCB\n($\\textsf{RLinUCB}$) algorithm, which optimizes both action selection and\nfeature modifications by balancing exploration and exploitation. We further\nextend this to the Human-AI Linear Recourse Bandit ($\\textsf{HR-Bandit}$),\nwhich integrates human expertise to enhance performance. $\\textsf{HR-Bandit}$\noffers three key guarantees: (i) a warm-start guarantee for improved initial\nperformance, (ii) a human-effort guarantee to minimize required human\ninteractions, and (iii) a robustness guarantee that ensures sublinear regret\neven when human decisions are suboptimal. Empirical results, including a\nhealthcare case study, validate its superior performance against existing\nbenchmarks.\n","authors":["Junyu Cao","Ruijiang Gao","Esmaeil Keyvanshokooh"],"pdf_url":"https://arxiv.org/pdf/2410.14640v1.pdf","comment":"18 pages"},{"id":"http://arxiv.org/abs/2410.14639v1","updated":"2024-10-18T17:40:58Z","published":"2024-10-18T17:40:58Z","title":"Convergence of Manifold Filter-Combine Networks","summary":"  In order to better understand manifold neural networks (MNNs), we introduce\nManifold Filter-Combine Networks (MFCNs). The filter-combine framework\nparallels the popular aggregate-combine paradigm for graph neural networks\n(GNNs) and naturally suggests many interesting families of MNNs which can be\ninterpreted as the manifold analog of various popular GNNs. We then propose a\nmethod for implementing MFCNs on high-dimensional point clouds that relies on\napproximating the manifold by a sparse graph. We prove that our method is\nconsistent in the sense that it converges to a continuum limit as the number of\ndata points tends to infinity.\n","authors":["David R. Johnson","Joyce Chew","Siddharth Viswanath","Edward De Brouwer","Deanna Needell","Smita Krishnaswamy","Michael Perlmutter"],"pdf_url":"https://arxiv.org/pdf/2410.14639v1.pdf","comment":"Accepted to NeurIPS Workshop on Symmetry and Geometry in Neural\n  Representations (Extended Abstract Track)"},{"id":"http://arxiv.org/abs/2410.14634v1","updated":"2024-10-18T17:35:33Z","published":"2024-10-18T17:35:33Z","title":"Parallel Backpropagation for Inverse of a Convolution with Application\n  to Normalizing Flows","summary":"  Inverse of an invertible convolution is an important operation that comes up\nin Normalizing Flows, Image Deblurring, etc. The naive algorithm for\nbackpropagation of this operation using Gaussian elimination has running time\n$O(n^3)$ where $n$ is the number of pixels in the image. We give a fast\nparallel backpropagation algorithm with running time $O(\\sqrt{n})$ for a square\nimage and provide a GPU implementation of the same. Inverse Convolutions are\nusually used in Normalizing Flows in the sampling pass, making them slow. We\npropose to use Inverse Convolutions in the forward (image to latent vector)\npass of the Normalizing flow. Since the sampling pass is the inverse of the\nforward pass, it will use convolutions only, resulting in efficient sampling\ntimes. We use our parallel backpropagation algorithm for optimizing the inverse\nconvolution layer resulting in fast training times also. We implement this\napproach in various Normalizing Flow backbones, resulting in our Inverse-Flow\nmodels. We benchmark Inverse-Flow on standard datasets and show significantly\nimproved sampling times with similar bits per dimension compared to previous\nmodels.\n","authors":["Sandeep Nagar","Girish Varma"],"pdf_url":"https://arxiv.org/pdf/2410.14634v1.pdf","comment":"Preprint"},{"id":"http://arxiv.org/abs/2109.09889v3","updated":"2024-10-18T17:32:27Z","published":"2021-09-21T00:09:03Z","title":"A Distance-based Anomaly Detection Framework for Deep Reinforcement\n  Learning","summary":"  In deep reinforcement learning (RL) systems, abnormal states pose significant\nrisks by potentially triggering unpredictable behaviors and unsafe actions,\nthus impeding the deployment of RL systems in real-world scenarios. It is\ncrucial for reliable decision-making systems to have the capability to cast an\nalert whenever they encounter unfamiliar observations that they are not\nequipped to handle. In this paper, we propose a novel Mahalanobis\ndistance-based (MD) anomaly detection framework, called \\textit{MDX}, for deep\nRL algorithms. MDX simultaneously addresses random, adversarial, and\nout-of-distribution (OOD) state outliers in both offline and online settings.\nIt utilizes Mahalanobis distance within class-conditional distributions for\neach action and operates within a statistical hypothesis testing framework\nunder the Gaussian assumption. We further extend it to robust and\ndistribution-free versions by incorporating Robust MD and conformal inference\ntechniques. Through extensive experiments on classical control environments,\nAtari games, and autonomous driving scenarios, we demonstrate the effectiveness\nof our MD-based detection framework. MDX offers a simple, unified, and\npractical anomaly detection tool for enhancing the safety and reliability of RL\nsystems in real-world applications.\n","authors":["Hongming Zhang","Ke Sun","Bo Xu","Linglong Kong","Martin Müller"],"pdf_url":"https://arxiv.org/pdf/2109.09889v3.pdf","comment":"19 pages, 21 figures"},{"id":"http://arxiv.org/abs/2410.14630v1","updated":"2024-10-18T17:30:20Z","published":"2024-10-18T17:30:20Z","title":"On the Regularization of Learnable Embeddings for Time Series Processing","summary":"  In processing multiple time series, accounting for the individual features of\neach sequence can be challenging. To address this, modern deep learning methods\nfor time series analysis combine a shared (global) model with local layers,\nspecific to each time series, often implemented as learnable embeddings.\nIdeally, these local embeddings should encode meaningful representations of the\nunique dynamics of each sequence. However, when these are learned end-to-end as\nparameters of a forecasting model, they may end up acting as mere sequence\nidentifiers. Shared processing blocks may then become reliant on such\nidentifiers, limiting their transferability to new contexts. In this paper, we\naddress this issue by investigating methods to regularize the learning of local\nlearnable embeddings for time series processing. Specifically, we perform the\nfirst extensive empirical study on the subject and show how such\nregularizations consistently improve performance in widely adopted\narchitectures. Furthermore, we show that methods preventing the co-adaptation\nof local and global parameters are particularly effective in this context. This\nhypothesis is validated by comparing several methods preventing the downstream\nmodels from relying on sequence identifiers, going as far as completely\nresetting the embeddings during training. The obtained results provide an\nimportant contribution to understanding the interplay between learnable local\nparameters and shared processing layers: a key challenge in modern time series\nprocessing models and a step toward developing effective foundation models for\ntime series.\n","authors":["Luca Butera","Giovanni De Felice","Andrea Cini","Cesare Alippi"],"pdf_url":"https://arxiv.org/pdf/2410.14630v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.14629v1","updated":"2024-10-18T17:30:17Z","published":"2024-10-18T17:30:17Z","title":"SIMformer: Single-Layer Vanilla Transformer Can Learn Free-Space\n  Trajectory Similarity","summary":"  Free-space trajectory similarity calculation, e.g., DTW, Hausdorff, and\nFrechet, often incur quadratic time complexity, thus learning-based methods\nhave been proposed to accelerate the computation. The core idea is to train an\nencoder to transform trajectories into representation vectors and then compute\nvector similarity to approximate the ground truth. However, existing methods\nface dual challenges of effectiveness and efficiency: 1) they all utilize\nEuclidean distance to compute representation similarity, which leads to the\nsevere curse of dimensionality issue -- reducing the distinguishability among\nrepresentations and significantly affecting the accuracy of subsequent\nsimilarity search tasks; 2) most of them are trained in triplets manner and\noften necessitate additional information which downgrades the efficiency; 3)\nprevious studies, while emphasizing the scalability in terms of efficiency,\noverlooked the deterioration of effectiveness when the dataset size grows. To\ncope with these issues, we propose a simple, yet accurate, fast, scalable model\nthat only uses a single-layer vanilla transformer encoder as the feature\nextractor and employs tailored representation similarity functions to\napproximate various ground truth similarity measures. Extensive experiments\ndemonstrate our model significantly mitigates the curse of dimensionality issue\nand outperforms the state-of-the-arts in effectiveness, efficiency, and\nscalability.\n","authors":["Chuang Yang","Renhe Jiang","Xiaohang Xu","Chuan Xiao","Kaoru Sezaki"],"pdf_url":"https://arxiv.org/pdf/2410.14629v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.14625v1","updated":"2024-10-18T17:27:07Z","published":"2024-10-18T17:27:07Z","title":"Enhancing AI Accessibility in Veterinary Medicine: Linking Classifiers\n  and Electronic Health Records","summary":"  In the rapidly evolving landscape of veterinary healthcare, integrating\nmachine learning (ML) clinical decision-making tools with electronic health\nrecords (EHRs) promises to improve diagnostic accuracy and patient care.\nHowever, the seamless integration of ML classifiers into existing EHRs in\nveterinary medicine is frequently hindered by the rigidity of EHR systems or\nthe limited availability of IT resources. To address this shortcoming, we\npresent Anna, a freely-available software solution that provides ML classifier\nresults for EHR laboratory data in real-time.\n","authors":["Chun Yin Kong","Picasso Vasquez","Makan Farhoodimoghadam","Chris Brandt","Titus C. Brown","Krystle L. Reagan","Allison Zwingenberger","Stefan M. Keller"],"pdf_url":"https://arxiv.org/pdf/2410.14625v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.14623v1","updated":"2024-10-18T17:22:38Z","published":"2024-10-18T17:22:38Z","title":"syren-new: Precise formulae for the linear and nonlinear matter power\n  spectra with massive neutrinos and dynamical dark energy","summary":"  Current and future large scale structure surveys aim to constrain the\nneutrino mass and the equation of state of dark energy. We aim to construct\naccurate and interpretable symbolic approximations to the linear and nonlinear\nmatter power spectra as a function of cosmological parameters in extended\n$\\Lambda$CDM models which contain massive neutrinos and non-constant equations\nof state for dark energy. This constitutes an extension of the syren-halofit\nemulators to incorporate these two effects, which we call syren-new\n(SYmbolic-Regression-ENhanced power spectrum emulator with NEutrinos and\n$W_0-w_a$). We also obtain a simple approximation to the derived parameter\n$\\sigma_8$ as a function of the cosmological parameters for these models. Our\nresults for the linear power spectrum are designed to emulate CLASS, whereas\nfor the nonlinear case we aim to match the results of EuclidEmulator2. We\ncompare our results to existing emulators and $N$-body simulations. Our\nanalytic emulators for $\\sigma_8$, the linear and nonlinear power spectra\nachieve root mean squared errors of 0.1%, 0.3% and 1.3%, respectively, across a\nwide range of cosmological parameters, redshifts and wavenumbers. We verify\nthat emulator-related discrepancies are subdominant compared to observational\nerrors and other modelling uncertainties when computing shear power spectra for\nLSST-like surveys. Our expressions have similar accuracy to existing\n(numerical) emulators, but are at least an order of magnitude faster, both on a\nCPU and GPU. Our work greatly improves the accuracy, speed and range of\napplicability of current symbolic approximations to the linear and nonlinear\nmatter power spectra. We provide publicly available code for all symbolic\napproximations found.\n","authors":["Ce Sui","Deaglan J. Bartlett","Shivam Pandey","Harry Desmond","Pedro G. Ferreira","Benjamin D. Wandelt"],"pdf_url":"https://arxiv.org/pdf/2410.14623v1.pdf","comment":"18 pages, 15 figures"},{"id":"http://arxiv.org/abs/2410.14621v1","updated":"2024-10-18T17:21:25Z","published":"2024-10-18T17:21:25Z","title":"JAMUN: Transferable Molecular Conformational Ensemble Generation with\n  Walk-Jump Sampling","summary":"  Conformational ensembles of protein structures are immensely important both\nto understanding protein function, and for drug discovery in novel modalities\nsuch as cryptic pockets. Current techniques for sampling ensembles are\ncomputationally inefficient, or do not transfer to systems outside their\ntraining data. We present walk-Jump Accelerated Molecular ensembles with\nUniversal Noise (JAMUN), a step towards the goal of efficiently sampling the\nBoltzmann distribution of arbitrary proteins. By extending Walk-Jump Sampling\nto point clouds, JAMUN enables ensemble generation at orders of magnitude\nfaster rates than traditional molecular dynamics or state-of-the-art ML\nmethods. Further, JAMUN is able to predict the stable basins of small peptides\nthat were not seen during training.\n","authors":["Ameya Daigavane","Bodhi P. Vani","Saeed Saremi","Joseph Kleinhenz","Joshua Rackers"],"pdf_url":"https://arxiv.org/pdf/2410.14621v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.10989v2","updated":"2024-10-18T17:21:17Z","published":"2024-10-14T18:17:01Z","title":"Liger Kernel: Efficient Triton Kernels for LLM Training","summary":"  Training Large Language Models (LLMs) efficiently at scale presents a\nformidable challenge, driven by their ever-increasing computational demands and\nthe need for enhanced performance. In this work, we introduce Liger-Kernel, an\nopen-sourced set of Triton kernels developed specifically for LLM training.\nWith kernel optimization techniques like kernel operation fusing and input\nchunking, our kernels achieve on average a 20% increase in training throughput\nand a 60% reduction in GPU memory usage for popular LLMs compared to\nHuggingFace implementations. In addition, Liger-Kernel is designed with\nmodularity, accessibility, and adaptability in mind, catering to both casual\nand expert users. Comprehensive benchmarks and integration tests are built in\nto ensure compatibility, performance, correctness, and convergence across\ndiverse computing environments and model architectures.\n  The source code is available under a permissive license at:\ngithub.com/linkedin/Liger-Kernel.\n","authors":["Pin-Lun Hsu","Yun Dai","Vignesh Kothapalli","Qingquan Song","Shao Tang","Siyu Zhu","Steven Shimizu","Shivam Sahni","Haowen Ning","Yanning Chen"],"pdf_url":"https://arxiv.org/pdf/2410.10989v2.pdf","comment":"17 pages, 12 figures"},{"id":"http://arxiv.org/abs/2410.10101v2","updated":"2024-10-18T17:15:09Z","published":"2024-10-14T02:41:01Z","title":"Learning Linear Attention in Polynomial Time","summary":"  Previous research has explored the computational expressivity of Transformer\nmodels in simulating Boolean circuits or Turing machines. However, the\nlearnability of these simulators from observational data has remained an open\nquestion. Our study addresses this gap by providing the first polynomial-time\nlearnability results (specifically strong, agnostic PAC learning) for\nsingle-layer Transformers with linear attention. We show that linear attention\nmay be viewed as a linear predictor in a suitably defined RKHS. As a\nconsequence, the problem of learning any linear transformer may be converted\ninto the problem of learning an ordinary linear predictor in an expanded\nfeature space, and any such predictor may be converted back into a multiheaded\nlinear transformer. Moving to generalization, we show how to efficiently\nidentify training datasets for which every empirical risk minimizer is\nequivalent (up to trivial symmetries) to the linear Transformer that generated\nthe data, thereby guaranteeing the learned model will correctly generalize\nacross all inputs. Finally, we provide examples of computations expressible via\nlinear attention and therefore polynomial-time learnable, including associative\nmemories, finite automata, and a class of Universal Turing Machine (UTMs) with\npolynomially bounded computation histories. We empirically validate our\ntheoretical findings on three tasks: learning random linear attention networks,\nkey--value associations, and learning to execute finite automata. Our findings\nbridge a critical gap between theoretical expressivity and learnability of\nTransformers, and show that flexible and general models of computation are\nefficiently learnable.\n","authors":["Morris Yau","Ekin Akyürek","Jiayuan Mao","Joshua B. Tenenbaum","Stefanie Jegelka","Jacob Andreas"],"pdf_url":"https://arxiv.org/pdf/2410.10101v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.14616v1","updated":"2024-10-18T17:14:28Z","published":"2024-10-18T17:14:28Z","title":"Benchmarking Deep Reinforcement Learning for Navigation in Denied Sensor\n  Environments","summary":"  Deep Reinforcement learning (DRL) is used to enable autonomous navigation in\nunknown environments. Most research assume perfect sensor data, but real-world\nenvironments may contain natural and artificial sensor noise and denial. Here,\nwe present a benchmark of both well-used and emerging DRL algorithms in a\nnavigation task with configurable sensor denial effects. In particular, we are\ninterested in comparing how different DRL methods (e.g. model-free PPO vs.\nmodel-based DreamerV3) are affected by sensor denial. We show that DreamerV3\noutperforms other methods in the visual end-to-end navigation task with a\ndynamic goal - and other methods are not able to learn this. Furthermore,\nDreamerV3 generally outperforms other methods in sensor-denied environments. In\norder to improve robustness, we use adversarial training and demonstrate an\nimproved performance in denied environments, although this generally comes with\na performance cost on the vanilla environments. We anticipate this benchmark of\ndifferent DRL methods and the usage of adversarial training to be a starting\npoint for the development of more elaborate navigation strategies that are\ncapable of dealing with uncertain and denied sensor readings.\n","authors":["Mariusz Wisniewski","Paraskevas Chatzithanos","Weisi Guo","Antonios Tsourdos"],"pdf_url":"https://arxiv.org/pdf/2410.14616v1.pdf","comment":"31 pages, 19 figures. For associated code, see\n  https://github.com/mazqtpopx/cranfield-navigation-gym"},{"id":"http://arxiv.org/abs/2410.14615v1","updated":"2024-10-18T17:13:29Z","published":"2024-10-18T17:13:29Z","title":"Asymptotically Optimal Change Detection for Unnormalized Pre- and\n  Post-Change Distributions","summary":"  This paper addresses the problem of detecting changes when only unnormalized\npre- and post-change distributions are accessible. This situation happens in\nmany scenarios in physics such as in ferromagnetism, crystallography,\nmagneto-hydrodynamics, and thermodynamics, where the energy models are\ndifficult to normalize.\n  Our approach is based on the estimation of the Cumulative Sum (CUSUM)\nstatistics, which is known to produce optimal performance. We first present an\nintuitively appealing approximation method. Unfortunately, this produces a\nbiased estimator of the CUSUM statistics and may cause performance degradation.\nWe then propose the Log-Partition Approximation Cumulative Sum (LPA-CUSUM)\nalgorithm based on thermodynamic integration (TI) in order to estimate the\nlog-ratio of normalizing constants of pre- and post-change distributions. It is\nproved that this approach gives an unbiased estimate of the log-partition\nfunction and the CUSUM statistics, and leads to an asymptotically optimal\nperformance. Moreover, we derive a relationship between the required sample\nsize for thermodynamic integration and the desired detection delay performance,\noffering guidelines for practical parameter selection. Numerical studies are\nprovided demonstrating the efficacy of our approach.\n","authors":["Arman Adibi","Sanjeev Kulkarni","H. Vincent Poor","Taposh Banerjee","Vahid Tarokh"],"pdf_url":"https://arxiv.org/pdf/2410.14615v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.06402v2","updated":"2024-10-18T17:10:05Z","published":"2024-03-11T03:28:13Z","title":"One size doesn't fit all: Predicting the Number of Examples for\n  In-Context Learning","summary":"  In-context learning (ICL) refers to the process of adding a small number of\nlocalized examples (ones that are semantically similar to the input) from a\ntraining set of labelled data to an LLM's prompt with an objective to\neffectively control the generative process seeking to improve the downstream\ntask performance. Existing ICL approaches use an identical number of examples\n(a pre-configured hyper-parameter) for each data instance. Our work alleviates\nthe limitations of this 'one fits all' approach by dynamically predicting the\nnumber of examples for each data instance to be used in few-shot inference with\nLLMs. In particular, we employ a multi-label classifier, the parameters of\nwhich are fitted using a training set, where the label for each instance in the\ntraining set indicates if using a specific value of k (number of most similar\nexamples from 0 up to a maximum value) leads to correct k-shot downstream\npredictions. Our experiments on a number of text classification benchmarks show\nthat AICL substantially outperforms standard ICL by up to 17%.\n","authors":["Manish Chandra","Debasis Ganguly","Iadh Ounis"],"pdf_url":"https://arxiv.org/pdf/2403.06402v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2310.20601v2","updated":"2024-10-18T17:07:01Z","published":"2023-10-31T16:37:01Z","title":"Modular Boundaries in Recurrent Neural Networks","summary":"  Recent theoretical and experimental work in neuroscience has focused on the\nrepresentational and dynamical character of neural manifolds --subspaces in\nneural activity space wherein many neurons coactivate. Importantly, neural\npopulations studied under this \"neural manifold hypothesis\" are continuous and\nnot cleanly divided into separate neural populations. This perspective clashes\nwith the \"modular hypothesis\" of brain organization, wherein neural elements\nmaintain an \"all-or-nothing\" affiliation with modules. In line with this\nmodular hypothesis, recent research on recurrent neural networks suggests that\nmulti-task networks become modular across training, such that different modules\nspecialize for task-general dynamical motifs. If the modular hypothesis is\ntrue, then it would be important to use a dimensionality reduction technique\nthat captures modular structure. Here, we investigate the features of such a\nmethod. We leverage RNNs as a model system to study the character of modular\nneural populations, using a community detection method from network science\nknown as modularity maximization to partition neurons into distinct modules.\nThese partitions allow us to ask the following question: do these modular\nboundaries matter to the system? ...\n","authors":["Jacob Tanner","Sina Mansour L.","Ludovico Coletta","Alessandro Gozzi","Richard F. Betzel"],"pdf_url":"https://arxiv.org/pdf/2310.20601v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.14606v1","updated":"2024-10-18T17:00:29Z","published":"2024-10-18T17:00:29Z","title":"Streaming Deep Reinforcement Learning Finally Works","summary":"  Natural intelligence processes experience as a continuous stream, sensing,\nacting, and learning moment-by-moment in real time. Streaming learning, the\nmodus operandi of classic reinforcement learning (RL) algorithms like\nQ-learning and TD, mimics natural learning by using the most recent sample\nwithout storing it. This approach is also ideal for resource-constrained,\ncommunication-limited, and privacy-sensitive applications. However, in deep RL,\nlearners almost always use batch updates and replay buffers, making them\ncomputationally expensive and incompatible with streaming learning. Although\nthe prevalence of batch deep RL is often attributed to its sample efficiency, a\nmore critical reason for the absence of streaming deep RL is its frequent\ninstability and failure to learn, which we refer to as stream barrier. This\npaper introduces the stream-x algorithms, the first class of deep RL algorithms\nto overcome stream barrier for both prediction and control and match sample\nefficiency of batch RL. Through experiments in Mujoco Gym, DM Control Suite,\nand Atari Games, we demonstrate stream barrier in existing algorithms and\nsuccessful stable learning with our stream-x algorithms: stream Q, stream AC,\nand stream TD, achieving the best model-free performance in DM Control Dog\nenvironments. A set of common techniques underlies the stream-x algorithms,\nenabling their success with a single set of hyperparameters and allowing for\neasy extension to other algorithms, thereby reviving streaming RL.\n","authors":["Mohamed Elsayed","Gautham Vasan","A. Rupam Mahmood"],"pdf_url":"https://arxiv.org/pdf/2410.14606v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.14604v1","updated":"2024-10-18T16:57:27Z","published":"2024-10-18T16:57:27Z","title":"Learning to Control the Smoothness of Graph Convolutional Network\n  Features","summary":"  The pioneering work of Oono and Suzuki [ICLR, 2020] and Cai and Wang\n[arXiv:2006.13318] initializes the analysis of the smoothness of graph\nconvolutional network (GCN) features. Their results reveal an intricate\nempirical correlation between node classification accuracy and the ratio of\nsmooth to non-smooth feature components. However, the optimal ratio that favors\nnode classification is unknown, and the non-smooth features of deep GCN with\nReLU or leaky ReLU activation function diminish. In this paper, we propose a\nnew strategy to let GCN learn node features with a desired smoothness --\nadapting to data and tasks -- to enhance node classification. Our approach has\nthree key steps: (1) We establish a geometric relationship between the input\nand output of ReLU or leaky ReLU. (2) Building on our geometric insights, we\naugment the message-passing process of graph convolutional layers (GCLs) with a\nlearnable term to modulate the smoothness of node features with computational\nefficiency. (3) We investigate the achievable ratio between smooth and\nnon-smooth feature components for GCNs with the augmented message-passing\nscheme. Our extensive numerical results show that the augmented message-passing\nschemes significantly improve node classification for GCN and some related\nmodels.\n","authors":["Shih-Hsin Wang","Justin Baker","Cory Hauck","Bao Wang"],"pdf_url":"https://arxiv.org/pdf/2410.14604v1.pdf","comment":"48 pages"},{"id":"http://arxiv.org/abs/2410.14602v1","updated":"2024-10-18T16:57:05Z","published":"2024-10-18T16:57:05Z","title":"How Does Data Diversity Shape the Weight Landscape of Neural Networks?","summary":"  To enhance the generalization of machine learning models to unseen data,\ntechniques such as dropout, weight decay ($L_2$ regularization), and noise\naugmentation are commonly employed. While regularization methods (i.e., dropout\nand weight decay) are geared toward adjusting model parameters to prevent\noverfitting, data augmentation increases the diversity of the input training\nset, a method purported to improve accuracy and calibration error. In this\npaper, we investigate the impact of each of these techniques on the parameter\nspace of neural networks, with the goal of understanding how they alter the\nweight landscape in transfer learning scenarios. To accomplish this, we employ\nRandom Matrix Theory to analyze the eigenvalue distributions of pre-trained\nmodels, fine-tuned using these techniques but using different levels of data\ndiversity, for the same downstream tasks. We observe that diverse data\ninfluences the weight landscape in a similar fashion as dropout. Additionally,\nwe compare commonly used data augmentation methods with synthetic data created\nby generative models. We conclude that synthetic data can bring more diversity\ninto real input data, resulting in a better performance on out-of-distribution\ntest instances.\n","authors":["Yang Ba","Michelle V. Mancenido","Rong Pan"],"pdf_url":"https://arxiv.org/pdf/2410.14602v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.09639v2","updated":"2024-10-18T16:50:56Z","published":"2024-06-14T00:08:04Z","title":"TGB 2.0: A Benchmark for Learning on Temporal Knowledge Graphs and\n  Heterogeneous Graphs","summary":"  Multi-relational temporal graphs are powerful tools for modeling real-world\ndata, capturing the evolving and interconnected nature of entities over time.\nRecently, many novel models are proposed for ML on such graphs intensifying the\nneed for robust evaluation and standardized benchmark datasets. However, the\navailability of such resources remains scarce and evaluation faces added\ncomplexity due to reproducibility issues in experimental protocols. To address\nthese challenges, we introduce Temporal Graph Benchmark 2.0 (TGB 2.0), a novel\nbenchmarking framework tailored for evaluating methods for predicting future\nlinks on Temporal Knowledge Graphs and Temporal Heterogeneous Graphs with a\nfocus on large-scale datasets, extending the Temporal Graph Benchmark. TGB 2.0\nfacilitates comprehensive evaluations by presenting eight novel datasets\nspanning five domains with up to 53 million edges. TGB 2.0 datasets are\nsignificantly larger than existing datasets in terms of number of nodes, edges,\nor timestamps. In addition, TGB 2.0 provides a reproducible and realistic\nevaluation pipeline for multi-relational temporal graphs. Through extensive\nexperimentation, we observe that 1) leveraging edge-type information is crucial\nto obtain high performance, 2) simple heuristic baselines are often competitive\nwith more complex methods, 3) most methods fail to run on our largest datasets,\nhighlighting the need for research on more scalable methods.\n","authors":["Julia Gastinger","Shenyang Huang","Mikhail Galkin","Erfan Loghmani","Ali Parviz","Farimah Poursafaei","Jacob Danovitch","Emanuele Rossi","Ioannis Koutis","Heiner Stuckenschmidt","Reihaneh Rabbany","Guillaume Rabusseau"],"pdf_url":"https://arxiv.org/pdf/2406.09639v2.pdf","comment":"29 pages, 8 figures, 11 tables, accepted at NeurIPS 2024 Track on\n  Datasets and Benchmarks"},{"id":"http://arxiv.org/abs/2410.14592v1","updated":"2024-10-18T16:43:10Z","published":"2024-10-18T16:43:10Z","title":"Contractivity and linear convergence in bilinear saddle-point problems:\n  An operator-theoretic approach","summary":"  We study the convex-concave bilinear saddle-point problem $\\min_x \\max_y f(x)\n+ y^\\top Ax - g(y)$, where both, only one, or none of the functions $f$ and $g$\nare strongly convex, and suitable rank conditions on the matrix $A$ hold. The\nsolution of this problem is at the core of many machine learning tasks. By\nemploying tools from operator theory, we systematically prove the contractivity\n(in turn, the linear convergence) of several first-order primal-dual\nalgorithms, including the Chambolle-Pock method. Our approach results in\nconcise and elegant proofs, and it yields new convergence guarantees and\ntighter bounds compared to known results.\n","authors":["Colin Dirren","Mattia Bianchi","Panagiotis D. Grontas","John Lygeros","Florian Dörfler"],"pdf_url":"https://arxiv.org/pdf/2410.14592v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.14591v1","updated":"2024-10-18T16:41:37Z","published":"2024-10-18T16:41:37Z","title":"A Lipschitz spaces view of infinitely wide shallow neural networks","summary":"  We revisit the mean field parametrization of shallow neural networks, using\nsigned measures on unbounded parameter spaces and duality pairings that take\ninto account the regularity and growth of activation functions. This setting\ndirectly leads to the use of unbalanced Kantorovich-Rubinstein norms defined by\nduality with Lipschitz functions, and of spaces of measures dual to those of\ncontinuous functions with controlled growth. These allow to make transparent\nthe need for total variation and moment bounds or penalization to obtain\nexistence of minimizers of variational formulations, under which we prove a\ncompactness result in strong Kantorovich-Rubinstein norm, and in the absence of\nwhich we show several examples demonstrating undesirable behavior. Further, the\nKantorovich-Rubinstein setting enables us to combine the advantages of a\ncompletely linear parametrization and ensuing reproducing kernel Banach space\nframework with optimal transport insights. We showcase this synergy with\nrepresenter theorems and uniform large data limits for empirical risk\nminimization, and in proposed formulations for distillation and fusion\napplications.\n","authors":["Francesca Bartolucci","Marcello Carioni","José A. Iglesias","Yury Korolev","Emanuele Naldi","Stefano Vigogna"],"pdf_url":"https://arxiv.org/pdf/2410.14591v1.pdf","comment":"39 pages, 1 table"},{"id":"http://arxiv.org/abs/2410.14588v1","updated":"2024-10-18T16:38:55Z","published":"2024-10-18T16:38:55Z","title":"Learning With Multi-Group Guarantees For Clusterable Subpopulations","summary":"  A canonical desideratum for prediction problems is that performance\nguarantees should hold not just on average over the population, but also for\nmeaningful subpopulations within the overall population. But what constitutes a\nmeaningful subpopulation? In this work, we take the perspective that relevant\nsubpopulations should be defined with respect to the clusters that naturally\nemerge from the distribution of individuals for which predictions are being\nmade. In this view, a population refers to a mixture model whose components\nconstitute the relevant subpopulations. We suggest two formalisms for capturing\nper-subgroup guarantees: first, by attributing each individual to the component\nfrom which they were most likely drawn, given their features; and second, by\nattributing each individual to all components in proportion to their relative\nlikelihood of having been drawn from each component. Using online calibration\nas a case study, we study a \\variational algorithm that provides guarantees for\neach of these formalisms by handling all plausible underlying subpopulation\nstructures simultaneously, and achieve an $O(T^{1/2})$ rate even when the\nsubpopulations are not well-separated. In comparison, the more natural\ncluster-then-predict approach that first recovers the structure of the\nsubpopulations and then makes predictions suffers from a $O(T^{2/3})$ rate and\nrequires the subpopulations to be separable. Along the way, we prove that\nproviding per-subgroup calibration guarantees for underlying clusters can be\neasier than learning the clusters: separation between median subgroup features\nis required for the latter but not the former.\n","authors":["Jessica Dai","Nika Haghtalab","Eric Zhao"],"pdf_url":"https://arxiv.org/pdf/2410.14588v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.14587v1","updated":"2024-10-18T16:37:52Z","published":"2024-10-18T16:37:52Z","title":"Neuro-Symbolic Traders: Assessing the Wisdom of AI Crowds in Markets","summary":"  Deep generative models are becoming increasingly used as tools for financial\nanalysis. However, it is unclear how these models will influence financial\nmarkets, especially when they infer financial value in a semi-autonomous way.\nIn this work, we explore the interplay between deep generative models and\nmarket dynamics. We develop a form of virtual traders that use deep generative\nmodels to make buy/sell decisions, which we term neuro-symbolic traders, and\nexpose them to a virtual market. Under our framework, neuro-symbolic traders\nare agents that use vision-language models to discover a model of the\nfundamental value of an asset. Agents develop this model as a stochastic\ndifferential equation, calibrated to market data using gradient descent. We\ntest our neuro-symbolic traders on both synthetic data and real financial time\nseries, including an equity stock, commodity, and a foreign exchange pair. We\nthen expose several groups of neuro-symbolic traders to a virtual market\nenvironment. This market environment allows for feedback between the traders\nbelief of the underlying value to the observed price dynamics. We find that\nthis leads to price suppression compared to the historical data, highlighting a\nfuture risk to market stability. Our work is a first step towards quantifying\nthe effect of deep generative agents on markets dynamics and sets out some of\nthe potential risks and benefits of this approach in the future.\n","authors":["Namid R. Stillman","Rory Baggott"],"pdf_url":"https://arxiv.org/pdf/2410.14587v1.pdf","comment":"8 pages, 4 figures, ACM format"},{"id":"http://arxiv.org/abs/2410.14586v1","updated":"2024-10-18T16:37:28Z","published":"2024-10-18T16:37:28Z","title":"Neural Combinatorial Clustered Bandits for Recommendation Systems","summary":"  We consider the contextual combinatorial bandit setting where in each round,\nthe learning agent, e.g., a recommender system, selects a subset of \"arms,\"\ne.g., products, and observes rewards for both the individual base arms, which\nare a function of known features (called \"context\"), and the super arm (the\nsubset of arms), which is a function of the base arm rewards. The agent's goal\nis to simultaneously learn the unknown reward functions and choose the\nhighest-reward arms. For example, the \"reward\" may represent a user's\nprobability of clicking on one of the recommended products. Conventional bandit\nmodels, however, employ restrictive reward function models in order to obtain\nperformance guarantees. We make use of deep neural networks to estimate and\nlearn the unknown reward functions and propose Neural UCB Clustering\n(NeUClust), which adopts a clustering approach to select the super arm in every\nround by exploiting underlying structure in the context space. Unlike prior\nneural bandit works, NeUClust uses a neural network to estimate the super arm\nreward and select the super arm, thus eliminating the need for a known\noptimization oracle. We non-trivially extend prior neural combinatorial bandit\nworks to prove that NeUClust achieves\n$\\widetilde{O}\\left(\\widetilde{d}\\sqrt{T}\\right)$ regret, where $\\widetilde{d}$\nis the effective dimension of a neural tangent kernel matrix, $T$ the number of\nrounds. Experiments on real world recommendation datasets show that NeUClust\nachieves better regret and reward than other contextual combinatorial and\nneural bandit algorithms.\n","authors":["Baran Atalar","Carlee Joe-Wong"],"pdf_url":"https://arxiv.org/pdf/2410.14586v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.14581v1","updated":"2024-10-18T16:32:06Z","published":"2024-10-18T16:32:06Z","title":"Optimizing Attention with Mirror Descent: Generalized Max-Margin Token\n  Selection","summary":"  Attention mechanisms have revolutionized several domains of artificial\nintelligence, such as natural language processing and computer vision, by\nenabling models to selectively focus on relevant parts of the input data. While\nrecent work has characterized the optimization dynamics of gradient descent\n(GD) in attention-based models and the structural properties of its preferred\nsolutions, less is known about more general optimization algorithms such as\nmirror descent (MD). In this paper, we investigate the convergence properties\nand implicit biases of a family of MD algorithms tailored for softmax attention\nmechanisms, with the potential function chosen as the $p$-th power of the\n$\\ell_p$-norm. Specifically, we show that these algorithms converge in\ndirection to a generalized hard-margin SVM with an $\\ell_p$-norm objective when\napplied to a classification problem using a softmax attention model. Notably,\nour theoretical results reveal that the convergence rate is comparable to that\nof traditional GD in simpler models, despite the highly nonlinear and nonconvex\nnature of the present problem. Additionally, we delve into the joint\noptimization dynamics of the key-query matrix and the decoder, establishing\nconditions under which this complex joint optimization converges to their\nrespective hard-margin SVM solutions. Lastly, our numerical experiments on real\ndata demonstrate that MD algorithms improve generalization over standard GD and\nexcel in optimal token selection.\n","authors":["Aaron Alvarado Kristanto Julistiono","Davoud Ataee Tarzanagh","Navid Azizan"],"pdf_url":"https://arxiv.org/pdf/2410.14581v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.14579v1","updated":"2024-10-18T16:27:04Z","published":"2024-10-18T16:27:04Z","title":"Towards Unsupervised Validation of Anomaly-Detection Models","summary":"  Unsupervised validation of anomaly-detection models is a highly challenging\ntask. While the common practices for model validation involve a labeled\nvalidation set, such validation sets cannot be constructed when the underlying\ndatasets are unlabeled. The lack of robust and efficient unsupervised\nmodel-validation techniques presents an acute challenge in the implementation\nof automated anomaly-detection pipelines, especially when there exists no prior\nknowledge of the model's performance on similar datasets. This work presents a\nnew paradigm to automated validation of anomaly-detection models, inspired by\nreal-world, collaborative decision-making mechanisms. We focus on two\ncommonly-used, unsupervised model-validation tasks -- model selection and model\nevaluation -- and provide extensive experimental results that demonstrate the\naccuracy and robustness of our approach on both tasks.\n","authors":["Lihi Idan"],"pdf_url":"https://arxiv.org/pdf/2410.14579v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.14578v1","updated":"2024-10-18T16:26:45Z","published":"2024-10-18T16:26:45Z","title":"Large Language Models Are Overparameterized Text Encoders","summary":"  Large language models (LLMs) demonstrate strong performance as text embedding\nmodels when finetuned with supervised contrastive training. However, their\nlarge size balloons inference time and memory requirements. In this paper, we\nshow that by pruning the last $p\\%$ layers of an LLM before supervised training\nfor only 1000 steps, we can achieve a proportional reduction in memory and\ninference time. We evaluate four different state-of-the-art LLMs on text\nembedding tasks and find that our method can prune up to 30\\% of layers with\nnegligible impact on performance and up to 80\\% with only a modest drop. With\nonly three lines of code, our method is easily implemented in any pipeline for\ntransforming LLMs to text encoders. We also propose $\\text{L}^3 \\text{Prune}$,\na novel layer-pruning strategy based on the model's initial loss that provides\ntwo optimal pruning configurations: a large variant with negligible performance\nloss and a small variant for resource-constrained settings. On average, the\nlarge variant prunes 21\\% of the parameters with a $-0.3$ performance drop, and\nthe small variant only suffers from a $-5.1$ decrease while pruning 74\\% of the\nmodel. We consider these results strong evidence that LLMs are\noverparameterized for text embedding tasks, and can be easily pruned.\n","authors":["Thennal D K","Tim Fischer","Chris Biemann"],"pdf_url":"https://arxiv.org/pdf/2410.14578v1.pdf","comment":"8 pages of content + 1 for limitations and ethical considerations, 14\n  pages in total including references and appendix, 5+1 figures"},{"id":"http://arxiv.org/abs/2410.13174v2","updated":"2024-10-18T16:26:30Z","published":"2024-10-17T02:57:35Z","title":"Scalable Drift Monitoring in Medical Imaging AI","summary":"  The integration of artificial intelligence (AI) into medical imaging has\nadvanced clinical diagnostics but poses challenges in managing model drift and\nensuring long-term reliability. To address these challenges, we develop MMC+,\nan enhanced framework for scalable drift monitoring, building upon the\nCheXstray framework that introduced real-time drift detection for medical\nimaging AI models using multi-modal data concordance. This work extends the\noriginal framework's methodologies, providing a more scalable and adaptable\nsolution for real-world healthcare settings and offers a reliable and\ncost-effective alternative to continuous performance monitoring addressing\nlimitations of both continuous and periodic monitoring methods. MMC+ introduces\ncritical improvements to the original framework, including more robust handling\nof diverse data streams, improved scalability with the integration of\nfoundation models like MedImageInsight for high-dimensional image embeddings\nwithout site-specific training, and the introduction of uncertainty bounds to\nbetter capture drift in dynamic clinical environments. Validated with\nreal-world data from Massachusetts General Hospital during the COVID-19\npandemic, MMC+ effectively detects significant data shifts and correlates them\nwith model performance changes. While not directly predicting performance\ndegradation, MMC+ serves as an early warning system, indicating when AI systems\nmay deviate from acceptable performance bounds and enabling timely\ninterventions. By emphasizing the importance of monitoring diverse data streams\nand evaluating data shifts alongside model performance, this work contributes\nto the broader adoption and integration of AI solutions in clinical settings.\n","authors":["Jameson Merkow","Felix J. Dorfner","Xiyu Yang","Alexander Ersoy","Giridhar Dasegowda","Mannudeep Kalra","Matthew P. Lungren","Christopher P. Bridge","Ivan Tarapov"],"pdf_url":"https://arxiv.org/pdf/2410.13174v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.14574v1","updated":"2024-10-18T16:20:22Z","published":"2024-10-18T16:20:22Z","title":"MomentumSMoE: Integrating Momentum into Sparse Mixture of Experts","summary":"  Sparse Mixture of Experts (SMoE) has become the key to unlocking unparalleled\nscalability in deep learning. SMoE has the potential to exponentially increase\nparameter count while maintaining the efficiency of the model by only\nactivating a small subset of these parameters for a given sample. However, it\nhas been observed that SMoE suffers from unstable training and has difficulty\nadapting to new distributions, leading to the model's lack of robustness to\ndata contamination. To overcome these limitations, we first establish a\nconnection between the dynamics of the expert representations in SMoEs and\ngradient descent on a multi-objective optimization problem. Leveraging our\nframework, we then integrate momentum into SMoE and propose a new family of\nSMoEs named MomentumSMoE. We theoretically prove and numerically demonstrate\nthat MomentumSMoE is more stable and robust than SMoE. In particular, we verify\nthe advantages of MomentumSMoE over SMoE on a variety of practical tasks\nincluding ImageNet-1K object recognition and WikiText-103 language modeling. We\ndemonstrate the applicability of MomentumSMoE to many types of SMoE models,\nincluding those in the Sparse MoE model for vision (V-MoE) and the Generalist\nLanguage Model (GLaM). We also show that other advanced momentum-based\noptimization methods, such as Adam, can be easily incorporated into the\nMomentumSMoE framework for designing new SMoE models with even better\nperformance, almost negligible additional computation cost, and simple\nimplementations.\n","authors":["Rachel S. Y. Teo","Tan M. Nguyen"],"pdf_url":"https://arxiv.org/pdf/2410.14574v1.pdf","comment":"10 pages in the main text. Published at NeurIPS 2024. The code is\n  available at https://github.com/rachtsy/MomentumSMoE"},{"id":"http://arxiv.org/abs/2410.14573v1","updated":"2024-10-18T16:20:17Z","published":"2024-10-18T16:20:17Z","title":"Building Trust in Black-box Optimization: A Comprehensive Framework for\n  Explainability","summary":"  Optimizing costly black-box functions within a constrained evaluation budget\npresents significant challenges in many real-world applications. Surrogate\nOptimization (SO) is a common resolution, yet its proprietary nature introduced\nby the complexity of surrogate models and the sampling core (e.g., acquisition\nfunctions) often leads to a lack of explainability and transparency. While\nexisting literature has primarily concentrated on enhancing convergence to\nglobal optima, the practical interpretation of newly proposed strategies\nremains underexplored, especially in batch evaluation settings. In this paper,\nwe propose \\emph{Inclusive} Explainability Metrics for Surrogate Optimization\n(IEMSO), a comprehensive set of model-agnostic metrics designed to enhance the\ntransparency, trustworthiness, and explainability of the SO approaches. Through\nthese metrics, we provide both intermediate and post-hoc explanations to\npractitioners before and after performing expensive evaluations to gain trust.\nWe consider four primary categories of metrics, each targeting a specific\naspect of the SO process: Sampling Core Metrics, Batch Properties Metrics,\nOptimization Process Metrics, and Feature Importance. Our experimental\nevaluations demonstrate the significant potential of the proposed metrics\nacross different benchmarks.\n","authors":["Nazanin Nezami","Hadis Anahideh"],"pdf_url":"https://arxiv.org/pdf/2410.14573v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.14570v1","updated":"2024-10-18T16:16:52Z","published":"2024-10-18T16:16:52Z","title":"Understanding the difficulty of low-precision post-training quantization\n  of large language models","summary":"  Large language models of high parameter counts are computationally expensive,\nyet can be made much more efficient by compressing their weights to very low\nnumerical precision. This can be achieved either through post-training\nquantization by minimizing local, layer-wise quantization errors, or through\nquantization-aware fine-tuning by minimizing the global loss function. In this\nstudy, we discovered that, under the same data constraint, the former approach\nnearly always fared worse than the latter, a phenomenon particularly prominent\nwhen the numerical precision is very low. We further showed that this\ndifficulty of post-training quantization arose from stark misalignment between\noptimization of the local and global objective functions. Our findings explains\nlimited utility in minimization of local quantization error and the importance\nof direct quantization-aware fine-tuning, in the regime of large models at very\nlow precision.\n","authors":["Zifei Xu","Sayeh Sharify","Wanzin Yazar","Tristan Webb","Xin Wang"],"pdf_url":"https://arxiv.org/pdf/2410.14570v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.12616v2","updated":"2024-10-18T16:09:52Z","published":"2024-06-18T13:44:07Z","title":"Learning diffusion at lightspeed","summary":"  Diffusion regulates numerous natural processes and the dynamics of many\nsuccessful generative models. Existing models to learn the diffusion terms from\nobservational data rely on complex bilevel optimization problems and model only\nthe drift of the system. We propose a new simple model, JKOnet*, which bypasses\nthe complexity of existing architectures while presenting significantly\nenhanced representational capabilities: JKOnet* recovers the potential,\ninteraction, and internal energy components of the underlying diffusion\nprocess. JKOnet* minimizes a simple quadratic loss and outperforms other\nbaselines in terms of sample efficiency, computational complexity, and\naccuracy. Additionally, JKOnet* provides a closed-form optimal solution for\nlinearly parametrized functionals, and, when applied to predict the evolution\nof cellular processes from real-world data, it achieves state-of-the-art\naccuracy at a fraction of the computational cost of all existing methods. Our\nmethodology is based on the interpretation of diffusion processes as\nenergy-minimizing trajectories in the probability space via the so-called JKO\nscheme, which we study via its first-order optimality conditions.\n","authors":["Antonio Terpin","Nicolas Lanzetti","Martin Gadea","Florian Dörfler"],"pdf_url":"https://arxiv.org/pdf/2406.12616v2.pdf","comment":"Accepted for presentation at, and publication in the proceedings of,\n  the 38th Conference on Neural Information Processing Systems (NeurIPS 2024,\n  oral)"},{"id":"http://arxiv.org/abs/2410.14556v1","updated":"2024-10-18T15:59:54Z","published":"2024-10-18T15:59:54Z","title":"Measuring Diversity: Axioms and Challenges","summary":"  The concept of diversity is widely used in various applications: from image\nor molecule generation to recommender systems. Thus, being able to properly\nmeasure diversity is important. This paper addresses the problem of quantifying\ndiversity for a set of objects. First, we make a systematic review of existing\ndiversity measures and explore their undesirable behavior in some cases. Based\non this review, we formulate three desirable properties (axioms) of a reliable\ndiversity measure: monotonicity, uniqueness, and continuity. We show that none\nof the existing measures has all three properties and thus these measures are\nnot suitable for quantifying diversity. Then, we construct two examples of\nmeasures that have all the desirable properties, thus proving that the list of\naxioms is not self-contradicting. Unfortunately, the constructed examples are\ntoo computationally complex for practical use, thus we pose an open problem of\nconstructing a diversity measure that has all the listed properties and can be\ncomputed in practice.\n","authors":["Mikhail Mironov","Liudmila Prokhorenkova"],"pdf_url":"https://arxiv.org/pdf/2410.14556v1.pdf","comment":"17 pages, 7 figures"},{"id":"http://arxiv.org/abs/2409.15652v3","updated":"2024-10-18T15:45:39Z","published":"2024-09-24T01:29:24Z","title":"English offensive text detection using CNN based Bi-GRU model","summary":"  Over the years, the number of users of social media has increased\ndrastically. People frequently share their thoughts through social platforms,\nand this leads to an increase in hate content. In this virtual community,\nindividuals share their views, express their feelings, and post photos, videos,\nblogs, and more. Social networking sites like Facebook and Twitter provide\nplatforms to share vast amounts of content with a single click. However, these\nplatforms do not impose restrictions on the uploaded content, which may include\nabusive language and explicit images unsuitable for social media. To resolve\nthis issue, a new idea must be implemented to divide the inappropriate content.\nNumerous studies have been done to automate the process. In this paper, we\npropose a new Bi-GRU-CNN model to classify whether the text is offensive or\nnot. The combination of the Bi-GRU and CNN models outperforms the existing\nmodel.\n","authors":["Tonmoy Roy","Md Robiul Islam","Asif Ahammad Miazee","Anika Antara","Al Amin","Sunjim Hossain"],"pdf_url":"https://arxiv.org/pdf/2409.15652v3.pdf","comment":"5 pages and 6 figures"},{"id":"http://arxiv.org/abs/2410.14548v1","updated":"2024-10-18T15:43:34Z","published":"2024-10-18T15:43:34Z","title":"Boosting K-means for Big Data by Fusing Data Streaming with Global\n  Optimization","summary":"  K-means clustering is a cornerstone of data mining, but its efficiency\ndeteriorates when confronted with massive datasets. To address this limitation,\nwe propose a novel heuristic algorithm that leverages the Variable Neighborhood\nSearch (VNS) metaheuristic to optimize K-means clustering for big data. Our\napproach is based on the sequential optimization of the partial objective\nfunction landscapes obtained by restricting the Minimum Sum-of-Squares\nClustering (MSSC) formulation to random samples from the original big dataset.\nWithin each landscape, systematically expanding neighborhoods of the currently\nbest (incumbent) solution are explored by reinitializing all degenerate and a\nvarying number of additional centroids. Extensive and rigorous experimentation\non a large number of real-world datasets reveals that by transforming the\ntraditional local search into a global one, our algorithm significantly\nenhances the accuracy and efficiency of K-means clustering in big data\nenvironments, becoming the new state of the art in the field.\n","authors":["Ravil Mussabayev","Rustam Mussabayev"],"pdf_url":"https://arxiv.org/pdf/2410.14548v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.11206v2","updated":"2024-10-18T15:43:02Z","published":"2024-06-17T04:53:47Z","title":"Retraining with Predicted Hard Labels Provably Increases Model Accuracy","summary":"  The performance of a model trained with \\textit{noisy labels} is often\nimproved by simply \\textit{retraining} the model with its own predicted\n\\textit{hard} labels (i.e., $1$/$0$ labels). Yet, a detailed theoretical\ncharacterization of this phenomenon is lacking. In this paper, we theoretically\nanalyze retraining in a linearly separable setting with randomly corrupted\nlabels given to us and prove that retraining can improve the population\naccuracy obtained by initially training with the given (noisy) labels. To the\nbest of our knowledge, this is the first such theoretical result. Retraining\nfinds application in improving training with local label differential privacy\n(DP) which involves training with noisy labels. We empirically show that\nretraining selectively on the samples for which the predicted label matches the\ngiven label significantly improves label DP training at \\textit{no extra\nprivacy cost}; we call this \\textit{consensus-based retraining}. As an example,\nwhen training ResNet-18 on CIFAR-100 with $\\epsilon=3$ label DP, we obtain\n$6.4\\%$ improvement in accuracy with consensus-based retraining.\n","authors":["Rudrajit Das","Inderjit S. Dhillon","Alessandro Epasto","Adel Javanmard","Jieming Mao","Vahab Mirrokni","Sujay Sanghavi","Peilin Zhong"],"pdf_url":"https://arxiv.org/pdf/2406.11206v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2404.15379v2","updated":"2024-10-18T15:38:16Z","published":"2024-04-23T07:16:13Z","title":"Clustering of timed sequences -- Application to the analysis of care\n  pathways","summary":"  Improving the future of healthcare starts by better understanding the current\nactual practices in hospital settings. This motivates the objective of\ndiscovering typical care pathways from patient data. Revealing typical care\npathways can be achieved through clustering. The difficulty in clustering care\npathways, represented by sequences of timestamped events, lies in defining a\nsemantically appropriate metric and clustering algorithms. In this article, we\nadapt two methods developed for time series to the clustering of timed\nsequences: the drop-DTW metric and the DBA approach for the construction of\naveraged time sequences. These methods are then applied in clustering\nalgorithms to propose original and sound clustering algorithms for timed\nsequences. This approach is experimented with and evaluated on synthetic and\nreal-world data.\n","authors":["Thomas Guyet","Pierre Pinson","Enoal Gesny"],"pdf_url":"https://arxiv.org/pdf/2404.15379v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.14539v1","updated":"2024-10-18T15:29:04Z","published":"2024-10-18T15:29:04Z","title":"Diffusion-based Semi-supervised Spectral Algorithm for Regression on\n  Manifolds","summary":"  We introduce a novel diffusion-based spectral algorithm to tackle regression\nanalysis on high-dimensional data, particularly data embedded within\nlower-dimensional manifolds. Traditional spectral algorithms often fall short\nin such contexts, primarily due to the reliance on predetermined kernel\nfunctions, which inadequately address the complex structures inherent in\nmanifold-based data. By employing graph Laplacian approximation, our method\nuses the local estimation property of heat kernel, offering an adaptive,\ndata-driven approach to overcome this obstacle. Another distinct advantage of\nour algorithm lies in its semi-supervised learning framework, enabling it to\nfully use the additional unlabeled data. This ability enhances the performance\nby allowing the algorithm to dig the spectrum and curvature of the data\nmanifold, providing a more comprehensive understanding of the dataset.\nMoreover, our algorithm performs in an entirely data-driven manner, operating\ndirectly within the intrinsic manifold structure of the data, without requiring\nany predefined manifold information. We provide a convergence analysis of our\nalgorithm. Our findings reveal that the algorithm achieves a convergence rate\nthat depends solely on the intrinsic dimension of the underlying manifold,\nthereby avoiding the curse of dimensionality associated with the higher ambient\ndimension.\n","authors":["Weichun Xia","Jiaxin Jiang","Lei Shi"],"pdf_url":"https://arxiv.org/pdf/2410.14539v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.12874v2","updated":"2024-10-18T15:26:55Z","published":"2024-10-14T18:11:53Z","title":"On Debiasing Text Embeddings Through Context Injection","summary":"  Current advances in Natural Language Processing (NLP) have made it\nincreasingly feasible to build applications leveraging textual data. Generally,\nthe core of these applications rely on having a good semantic representation of\ntext into vectors, via embedding models. However, it has been shown that these\nembeddings capture and perpetuate biases already present in text. While a few\ntechniques have been proposed to debias embeddings, they do not take advantage\nof the recent advances in context understanding of modern embedding models. In\nthis paper, we fill this gap by conducting a review of 19 embedding models by\nquantifying their biases and how well they respond to context injection as a\nmean of debiasing. We show that higher performing models are more prone to\ncapturing biases, but are also better at incorporating context. Surprisingly,\nwe find that while models can easily embed affirmative semantics, they fail at\nembedding neutral semantics. Finally, in a retrieval task, we show that biases\nin embeddings can lead to non-desirable outcomes. We use our new-found insights\nto design a simple algorithm for top $k$ retrieval, where $k$ is dynamically\nselected. We show that our algorithm is able to retrieve all relevant gendered\nand neutral chunks.\n","authors":["Thomas Uriot"],"pdf_url":"https://arxiv.org/pdf/2410.12874v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.14535v1","updated":"2024-10-18T15:23:29Z","published":"2024-10-18T15:23:29Z","title":"Comparing Differentiable and Dynamic Ray Tracing: Introducing the\n  Multipath Lifetime Map","summary":"  With the increasing presence of dynamic scenarios, such as Vehicle-to-Vehicle\ncommunications, radio propagation modeling tools must adapt to the rapidly\nchanging nature of the radio channel. Recently, both Differentiable and Dynamic\nRay Tracing frameworks have emerged to address these challenges. However, there\nis often confusion about how these approaches differ and which one should be\nused in specific contexts. In this paper, we provide an overview of these two\ntechniques and a comparative analysis against two state-of-the-art tools:\n3DSCAT from UniBo and Sionna from NVIDIA. To provide a more precise\ncharacterization of the scope of these methods, we introduce a novel\nsimulation-based metric, the Multipath Lifetime Map, which enables the\nevaluation of spatial and temporal coherence in radio channels only based on\nthe geometrical description of the environment. Finally, our metrics are\nevaluated on a classic urban street canyon scenario, yielding similar results\nto those obtained from measurement campaigns.\n","authors":["Jérome Eertmans","Enrico Maria Vittuci","Vittorio Degli Esposti","Laurent Jacques","Claude Oestges"],"pdf_url":"https://arxiv.org/pdf/2410.14535v1.pdf","comment":"5 pages, 5 figures, 1 table, submitted to EuCAP 2025"},{"id":"http://arxiv.org/abs/2404.07864v2","updated":"2024-10-18T15:23:26Z","published":"2024-04-11T15:57:12Z","title":"Inferring Change Points in High-Dimensional Regression via Approximate\n  Message Passing","summary":"  We consider the problem of localizing change points in a generalized linear\nmodel (GLM), a model that covers many widely studied problems in statistical\nlearning including linear, logistic, and rectified linear regression. We\npropose a novel and computationally efficient Approximate Message Passing (AMP)\nalgorithm for estimating both the signals and the change point locations, and\nrigorously characterize its performance in the high-dimensional limit where the\nnumber of parameters $p$ is proportional to the number of samples $n$. This\ncharacterization is in terms of a state evolution recursion, which allows us to\nprecisely compute performance measures such as the asymptotic Hausdorff error\nof our change point estimates, and allows us to tailor the algorithm to take\nadvantage of any prior structural information on the signals and change points.\nMoreover, we show how our AMP iterates can be used to efficiently compute a\nBayesian posterior distribution over the change point locations in the\nhigh-dimensional limit. We validate our theory via numerical experiments, and\ndemonstrate the favorable performance of our estimators on both synthetic and\nreal data in the settings of linear, logistic, and rectified linear regression.\n","authors":["Gabriel Arpino","Xiaoqi Liu","Julia Gontarek","Ramji Venkataramanan"],"pdf_url":"https://arxiv.org/pdf/2404.07864v2.pdf","comment":"43 pages, 9 figures. A preliminary version of this paper appeared in\n  ICML 2024"},{"id":"http://arxiv.org/abs/2408.05807v3","updated":"2024-10-18T15:19:04Z","published":"2024-08-11T15:56:44Z","title":"Kernel Density Estimators in Large Dimensions","summary":"  This paper studies Kernel Density Estimation for a high-dimensional\ndistribution $\\rho(x)$. Traditional approaches have focused on the limit of\nlarge number of data points $n$ and fixed dimension $d$. We analyze instead the\nregime where both the number $n$ of data points $y_i$ and their dimensionality\n$d$ grow with a fixed ratio $\\alpha=(\\log n)/d$. Our study reveals three\ndistinct statistical regimes for the kernel-based estimate of the density $\\hat\n\\rho_h^{\\mathcal {D}}(x)=\\frac{1}{n h^d}\\sum_{i=1}^n\nK\\left(\\frac{x-y_i}{h}\\right)$, depending on the bandwidth $h$: a classical\nregime for large bandwidth where the Central Limit Theorem (CLT) holds, which\nis akin to the one found in traditional approaches. Below a certain value of\nthe bandwidth, $h_{CLT}(\\alpha)$, we find that the CLT breaks down. The\nstatistics of $\\hat\\rho_h^{\\mathcal {D}}(x)$ for a fixed $x$ drawn from\n$\\rho(x)$ is given by a heavy-tailed distribution (an alpha-stable\ndistribution). In particular below a value $h_G(\\alpha)$, we find that\n$\\hat\\rho_h^{\\mathcal {D}}(x)$ is governed by extreme value statistics: only a\nfew points in the database matter and give the dominant contribution to the\ndensity estimator. We provide a detailed analysis for high-dimensional\nmultivariate Gaussian data. We show that the optimal bandwidth threshold based\non Kullback-Leibler divergence lies in the new statistical regime identified in\nthis paper. As known by practitioners, when decreasing the bandwidth a\nKernel-estimated estimated changes from a smooth curve to a collections of\npeaks centred on the data points. Our findings reveal that this general\nphenomenon is related to sharp transitions between phases characterized by\ndifferent statistical properties, and offer new insights for Kernel density\nestimation in high-dimensional settings.\n","authors":["Giulio Biroli","Marc Mézard"],"pdf_url":"https://arxiv.org/pdf/2408.05807v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.14533v1","updated":"2024-10-18T15:14:25Z","published":"2024-10-18T15:14:25Z","title":"The Traveling Bandit: A Framework for Bayesian Optimization with\n  Movement Costs","summary":"  This paper introduces a framework for Bayesian Optimization (BO) with metric\nmovement costs, addressing a critical challenge in practical applications where\ninput alterations incur varying costs. Our approach is a convenient plug-in\nthat seamlessly integrates with the existing literature on batched algorithms,\nwhere designs within batches are observed following the solution of a Traveling\nSalesman Problem. The proposed method provides a theoretical guarantee of\nconvergence in terms of movement costs for BO. Empirically, our method\neffectively reduces average movement costs over time while maintaining\ncomparable regret performance to conventional BO methods. This framework also\nshows promise for broader applications in various bandit settings with movement\ncosts.\n","authors":["Qiyuan Chen","Raed Al Kontar"],"pdf_url":"https://arxiv.org/pdf/2410.14533v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.14532v1","updated":"2024-10-18T15:13:07Z","published":"2024-10-18T15:13:07Z","title":"Using Sentiment and Technical Analysis to Predict Bitcoin with Machine\n  Learning","summary":"  Cryptocurrencies have gained significant attention in recent years due to\ntheir decentralized nature and potential for financial innovation. Thus, the\nability to accurately predict its price has become a subject of great interest\nfor investors, traders, and researchers. Some works in the literature show how\nBitcoin's market sentiment correlates with its price fluctuations in the\nmarket. However, papers that consider the sentiment of the market associated\nwith financial Technical Analysis indicators in order to predict Bitcoin's\nprice are still scarce. In this paper, we present a novel approach for\npredicting Bitcoin price movements by combining the Fear & Greedy Index, a\nmeasure of market sentiment, Technical Analysis indicators, and the potential\nof Machine Learning algorithms. This work represents a preliminary study on the\nimportance of sentiment metrics in cryptocurrency forecasting. Our initial\nexperiments demonstrate promising results considering investment returns,\nsurpassing the Buy & Hold baseline, and offering valuable insights about the\ncombination of indicators of sentiment and market in a cryptocurrency\nprediction model.\n","authors":["Arthur Emanuel de Oliveira Carosia"],"pdf_url":"https://arxiv.org/pdf/2410.14532v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.14528v1","updated":"2024-10-18T15:10:55Z","published":"2024-10-18T15:10:55Z","title":"Domain Adaptive Safety Filters via Deep Operator Learning","summary":"  Learning-based approaches for constructing Control Barrier Functions (CBFs)\nare increasingly being explored for safety-critical control systems. However,\nthese methods typically require complete retraining when applied to unseen\nenvironments, limiting their adaptability. To address this, we propose a\nself-supervised deep operator learning framework that learns the mapping from\nenvironmental parameters to the corresponding CBF, rather than learning the CBF\ndirectly. Our approach leverages the residual of a parametric Partial\nDifferential Equation (PDE), where the solution defines a parametric CBF\napproximating the maximal control invariant set. This framework accommodates\ncomplex safety constraints, higher relative degrees, and actuation limits. We\ndemonstrate the effectiveness of the method through numerical experiments on\nnavigation tasks involving dynamic obstacles.\n","authors":["Lakshmideepakreddy Manda","Shaoru Chen","Mahyar Fazlyab"],"pdf_url":"https://arxiv.org/pdf/2410.14528v1.pdf","comment":"63rd IEEE Conference on Decision and Control (CDC)"},{"id":"http://arxiv.org/abs/2410.14522v1","updated":"2024-10-18T15:06:50Z","published":"2024-10-18T15:06:50Z","title":"Rethinking Distance Metrics for Counterfactual Explainability","summary":"  Counterfactual explanations have been a popular method of post-hoc\nexplainability for a variety of settings in Machine Learning. Such methods\nfocus on explaining classifiers by generating new data points that are similar\nto a given reference, while receiving a more desirable prediction. In this\nwork, we investigate a framing for counterfactual generation methods that\nconsiders counterfactuals not as independent draws from a region around the\nreference, but as jointly sampled with the reference from the underlying data\ndistribution. Through this framing, we derive a distance metric, tailored for\ncounterfactual similarity that can be applied to a broad range of settings.\nThrough both quantitative and qualitative analyses of counterfactual generation\nmethods, we show that this framing allows us to express more nuanced\ndependencies among the covariates.\n","authors":["Joshua Nathaniel Williams","Anurag Katakkar","Hoda Heidari","J. Zico Kolter"],"pdf_url":"https://arxiv.org/pdf/2410.14522v1.pdf","comment":"13 pages, 3 figures, 1 table"},{"id":"http://arxiv.org/abs/2410.14515v1","updated":"2024-10-18T14:54:40Z","published":"2024-10-18T14:54:40Z","title":"Efficient Annotator Reliability Assessment and Sample Weighting for\n  Knowledge-Based Misinformation Detection on Social Media","summary":"  Misinformation spreads rapidly on social media, confusing the truth and\ntargetting potentially vulnerable people. To effectively mitigate the negative\nimpact of misinformation, it must first be accurately detected before applying\na mitigation strategy, such as X's community notes, which is currently a manual\nprocess. This study takes a knowledge-based approach to misinformation\ndetection, modelling the problem similarly to one of natural language\ninference. The EffiARA annotation framework is introduced, aiming to utilise\ninter- and intra-annotator agreement to understand the reliability of each\nannotator and influence the training of large language models for\nclassification based on annotator reliability. In assessing the EffiARA\nannotation framework, the Russo-Ukrainian Conflict Knowledge-Based\nMisinformation Classification Dataset (RUC-MCD) was developed and made publicly\navailable. This study finds that sample weighting using annotator reliability\nperforms the best, utilising both inter- and intra-annotator agreement and\nsoft-label training. The highest classification performance achieved using\nLlama-3.2-1B was a macro-F1 of 0.757 and 0.740 using TwHIN-BERT-large.\n","authors":["Owen Cook","Charlie Grimshaw","Ben Wu","Sophie Dillon","Jack Hicks","Luke Jones","Thomas Smith","Matyas Szert","Xingyi Song"],"pdf_url":"https://arxiv.org/pdf/2410.14515v1.pdf","comment":"8 pages, 3 figures, 3 tables. Code available here:\n  https://github.com/MiniEggz/ruc-misinfo"},{"id":"http://arxiv.org/abs/2406.07361v2","updated":"2024-10-18T14:38:03Z","published":"2024-06-11T15:28:48Z","title":"Deep Implicit Optimization for Robust and Flexible Image Registration","summary":"  Deep Learning in Image Registration (DLIR) methods have been tremendously\nsuccessful in image registration due to their speed and ability to incorporate\nweak label supervision at training time. However, DLIR methods forego many of\nthe benefits of classical optimization-based methods. The functional nature of\ndeep networks do not guarantee that the predicted transformation is a local\nminima of the registration objective, the representation of the transformation\n(displacement/velocity field/affine) is fixed, and the networks are not robust\nto domain shift. Our method aims to bridge this gap between classical and\nlearning methods by incorporating optimization as a layer in a deep network. A\ndeep network is trained to predict multi-scale dense feature images that are\nregistered using a black box iterative optimization solver. This optimal warp\nis then used to minimize image and label alignment errors. By implicitly\ndifferentiating end-to-end through an iterative optimization solver, our\nlearned features are registration and label-aware, and the warp functions are\nguaranteed to be local minima of the registration objective in the feature\nspace. Our framework shows excellent performance on in-domain datasets, and is\nagnostic to domain shift such as anisotropy and varying intensity profiles. For\nthe first time, our method allows switching between arbitrary transformation\nrepresentations (free-form to diffeomorphic) at test time with zero retraining.\nEnd-to-end feature learning also facilitates interpretability of features, and\nout-of-the-box promptability using additional label-fidelity terms at\ninference.\n","authors":["Rohit Jena","Pratik Chaudhari","James C. Gee"],"pdf_url":"https://arxiv.org/pdf/2406.07361v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.08979v2","updated":"2024-10-18T14:35:53Z","published":"2024-10-11T16:54:07Z","title":"Overcoming Slow Decision Frequencies in Continuous Control: Model-Based\n  Sequence Reinforcement Learning for Model-Free Control","summary":"  Reinforcement learning (RL) is rapidly reaching and surpassing human-level\ncontrol capabilities. However, state-of-the-art RL algorithms often require\ntimesteps and reaction times significantly faster than human capabilities,\nwhich is impractical in real-world settings and typically necessitates\nspecialized hardware. Such speeds are difficult to achieve in the real world\nand often requires specialized hardware. We introduce Sequence Reinforcement\nLearning (SRL), an RL algorithm designed to produce a sequence of actions for a\ngiven input state, enabling effective control at lower decision frequencies.\nSRL addresses the challenges of learning action sequences by employing both a\nmodel and an actor-critic architecture operating at different temporal scales.\nWe propose a \"temporal recall\" mechanism, where the critic uses the model to\nestimate intermediate states between primitive actions, providing a learning\nsignal for each individual action within the sequence. Once training is\ncomplete, the actor can generate action sequences independently of the model,\nachieving model-free control at a slower frequency. We evaluate SRL on a suite\nof continuous control tasks, demonstrating that it achieves performance\ncomparable to state-of-the-art algorithms while significantly reducing actor\nsample complexity. To better assess performance across varying decision\nfrequencies, we introduce the Frequency-Averaged Score (FAS) metric. Our\nresults show that SRL significantly outperforms traditional RL algorithms in\nterms of FAS, making it particularly suitable for applications requiring\nvariable decision frequencies. Additionally, we compare SRL with model-based\nonline planning, showing that SRL achieves superior FAS while leveraging the\nsame model during training that online planners use for planning.\n","authors":["Devdhar Patel","Hava Siegelmann"],"pdf_url":"https://arxiv.org/pdf/2410.08979v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.13012v2","updated":"2024-10-18T14:32:21Z","published":"2024-10-16T20:14:02Z","title":"Sample Compression Scheme Reductions","summary":"  We present novel reductions from sample compression schemes in multiclass\nclassification, regression, and adversarially robust learning settings to\nbinary sample compression schemes. Assuming we have a compression scheme for\nbinary classes of size $f(d_\\mathrm{VC})$, where $d_\\mathrm{VC}$ is the VC\ndimension, then we have the following results: (1) If the binary compression\nscheme is a majority-vote or a stable compression scheme, then there exists a\nmulticlass compression scheme of size $O(f(d_\\mathrm{G}))$, where\n$d_\\mathrm{G}$ is the graph dimension. Moreover, for general binary compression\nschemes, we obtain a compression of size $O(f(d_\\mathrm{G})\\log|Y|)$, where $Y$\nis the label space. (2) If the binary compression scheme is a majority-vote or\na stable compression scheme, then there exists an $\\epsilon$-approximate\ncompression scheme for regression over $[0,1]$-valued functions of size\n$O(f(d_\\mathrm{P}))$, where $d_\\mathrm{P}$ is the pseudo-dimension. For general\nbinary compression schemes, we obtain a compression of size\n$O(f(d_\\mathrm{P})\\log(1/\\epsilon))$. These results would have significant\nimplications if the sample compression conjecture, which posits that any binary\nconcept class with a finite VC dimension admits a binary compression scheme of\nsize $O(d_\\mathrm{VC})$, is resolved (Littlestone and Warmuth, 1986; Floyd and\nWarmuth, 1995; Warmuth, 2003). Our results would then extend the proof of the\nconjecture immediately to other settings. We establish similar results for\nadversarially robust learning and also provide an example of a concept class\nthat is robustly learnable but has no bounded-size compression scheme,\ndemonstrating that learnability is not equivalent to having a compression\nscheme independent of the sample size, unlike in binary classification, where\ncompression of size $2^{O(d_\\mathrm{VC})}$ is attainable (Moran and Yehudayoff,\n2016).\n","authors":["Idan Attias","Steve Hanneke","Arvind Ramaswami"],"pdf_url":"https://arxiv.org/pdf/2410.13012v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.14489v1","updated":"2024-10-18T14:19:13Z","published":"2024-10-18T14:19:13Z","title":"An Integrated Deep Learning Model for Skin Cancer Detection Using Hybrid\n  Feature Fusion Technique","summary":"  Skin cancer is a serious and potentially fatal disease caused by DNA damage.\nEarly detection significantly increases survival rates, making accurate\ndiagnosis crucial. In this groundbreaking study, we present a hybrid framework\nbased on Deep Learning (DL) that achieves precise classification of benign and\nmalignant skin lesions. Our approach begins with dataset preprocessing to\nenhance classification accuracy, followed by training two separate pre-trained\nDL models, InceptionV3 and DenseNet121. By fusing the results of each model\nusing the weighted sum rule, our system achieves exceptional accuracy rates.\nSpecifically, we achieve a 92.27% detection accuracy rate, 92.33% sensitivity,\n92.22% specificity, 90.81% precision, and 91.57% F1-score, outperforming\nexisting models and demonstrating the robustness and trustworthiness of our\nhybrid approach. Our study represents a significant advance in skin cancer\ndiagnosis and provides a promising foundation for further research in the\nfield. With the potential to save countless lives through earlier detection,\nour hybrid deep-learning approach is a game-changer in the fight against skin\ncancer.\n","authors":["Maksuda Akter","Rabea Khatun","Md. Alamin Talukder","Md. Manowarul Islam","Md. Ashraf Uddin"],"pdf_url":"https://arxiv.org/pdf/2410.14489v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.14488v1","updated":"2024-10-18T14:16:54Z","published":"2024-10-18T14:16:54Z","title":"ANT: Adaptive Noise Schedule for Time Series Diffusion Models","summary":"  Advances in diffusion models for generative artificial intelligence have\nrecently propagated to the time series (TS) domain, demonstrating\nstate-of-the-art performance on various tasks. However, prior works on TS\ndiffusion models often borrow the framework of existing works proposed in other\ndomains without considering the characteristics of TS data, leading to\nsuboptimal performance. In this work, we propose Adaptive Noise schedule for\nTime series diffusion models (ANT), which automatically predetermines proper\nnoise schedules for given TS datasets based on their statistics representing\nnon-stationarity. Our intuition is that an optimal noise schedule should\nsatisfy the following desiderata: 1) It linearly reduces the non-stationarity\nof TS data so that all diffusion steps are equally meaningful, 2) the data is\ncorrupted to the random noise at the final step, and 3) the number of steps is\nsufficiently large. The proposed method is practical for use in that it\neliminates the necessity of finding the optimal noise schedule with a small\nadditional cost to compute the statistics for given datasets, which can be done\noffline before training. We validate the effectiveness of our method across\nvarious tasks, including TS forecasting, refinement, and generation, on\ndatasets from diverse domains. Code is available at this repository:\nhttps://github.com/seunghan96/ANT.\n","authors":["Seunghan Lee","Kibok Lee","Taeyoung Park"],"pdf_url":"https://arxiv.org/pdf/2410.14488v1.pdf","comment":"NeurIPS 2024"},{"id":"http://arxiv.org/abs/2410.14485v1","updated":"2024-10-18T14:10:16Z","published":"2024-10-18T14:10:16Z","title":"CaTs and DAGs: Integrating Directed Acyclic Graphs with Transformers and\n  Fully-Connected Neural Networks for Causally Constrained Predictions","summary":"  Artificial Neural Networks (ANNs), including fully-connected networks and\ntransformers, are highly flexible and powerful function approximators, widely\napplied in fields like computer vision and natural language processing.\nHowever, their inability to inherently respect causal structures can limit\ntheir robustness, making them vulnerable to covariate shift and difficult to\ninterpret/explain. This poses significant challenges for their reliability in\nreal-world applications. In this paper, we introduce Causal Fully-Connected\nNeural Networks (CFCNs) and Causal Transformers (CaTs), two general model\nfamilies designed to operate under predefined causal constraints, as specified\nby a Directed Acyclic Graph (DAG). These models retain the powerful function\napproximation abilities of traditional neural networks while adhering to the\nunderlying structural constraints, improving robustness, reliability, and\ninterpretability at inference time. This approach opens new avenues for\ndeploying neural networks in more demanding, real-world scenarios where\nrobustness and explainability is critical.\n","authors":["Matthew J. Vowels","Mathieu Rochat","Sina Akbari"],"pdf_url":"https://arxiv.org/pdf/2410.14485v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.14484v1","updated":"2024-10-18T14:08:41Z","published":"2024-10-18T14:08:41Z","title":"Transfer Reinforcement Learning in Heterogeneous Action Spaces using\n  Subgoal Mapping","summary":"  In this paper, we consider a transfer reinforcement learning problem\ninvolving agents with different action spaces. Specifically, for any new unseen\ntask, the goal is to use a successful demonstration of this task by an expert\nagent in its action space to enable a learner agent learn an optimal policy in\nits own different action space with fewer samples than those required if the\nlearner was learning on its own. Existing transfer learning methods across\ndifferent action spaces either require handcrafted mappings between those\naction spaces provided by human experts, which can induce bias in the learning\nprocedure, or require the expert agent to share its policy parameters with the\nlearner agent, which does not generalize well to unseen tasks. In this work, we\npropose a method that learns a subgoal mapping between the expert agent policy\nand the learner agent policy. Since the expert agent and the learner agent have\ndifferent action spaces, their optimal policies can have different subgoal\ntrajectories. We learn this subgoal mapping by training a Long Short Term\nMemory (LSTM) network for a distribution of tasks and then use this mapping to\npredict the learner subgoal sequence for unseen tasks, thereby improving the\nspeed of learning by biasing the agent's policy towards the predicted learner\nsubgoal sequence. Through numerical experiments, we demonstrate that the\nproposed learning scheme can effectively find the subgoal mapping underlying\nthe given distribution of tasks. Moreover, letting the learner agent imitate\nthe expert agent's policy with the learnt subgoal mapping can significantly\nimprove the sample efficiency and training time of the learner agent in unseen\nnew tasks.\n","authors":["Kavinayan P. Sivakumar","Yan Zhang","Zachary Bell","Scott Nivison","Michael M. Zavlanos"],"pdf_url":"https://arxiv.org/pdf/2410.14484v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.14483v1","updated":"2024-10-18T14:06:49Z","published":"2024-10-18T14:06:49Z","title":"Spectral Representations for Accurate Causal Uncertainty Quantification\n  with Gaussian Processes","summary":"  Accurate uncertainty quantification for causal effects is essential for\nrobust decision making in complex systems, but remains challenging in\nnon-parametric settings. One promising framework represents conditional\ndistributions in a reproducing kernel Hilbert space and places Gaussian process\npriors on them to infer posteriors on causal effects, but requires restrictive\nnuclear dominant kernels and approximations that lead to unreliable uncertainty\nestimates. In this work, we introduce a method, IMPspec, that addresses these\nlimitations via a spectral representation of the Hilbert space. We show that\nposteriors in this model can be obtained explicitly, by extending a result in\nHilbert space regression theory. We also learn the spectral representation to\noptimise posterior calibration. Our method achieves state-of-the-art\nperformance in uncertainty quantification and causal Bayesian optimisation\nacross simulations and a healthcare application.\n","authors":["Hugh Dance","Peter Orbanz","Arthur Gretton"],"pdf_url":"https://arxiv.org/pdf/2410.14483v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.09804v2","updated":"2024-10-18T14:03:05Z","published":"2024-10-13T11:15:38Z","title":"BlackDAN: A Black-Box Multi-Objective Approach for Effective and\n  Contextual Jailbreaking of Large Language Models","summary":"  While large language models (LLMs) exhibit remarkable capabilities across\nvarious tasks, they encounter potential security risks such as jailbreak\nattacks, which exploit vulnerabilities to bypass security measures and generate\nharmful outputs. Existing jailbreak strategies mainly focus on maximizing\nattack success rate (ASR), frequently neglecting other critical factors,\nincluding the relevance of the jailbreak response to the query and the level of\nstealthiness. This narrow focus on single objectives can result in ineffective\nattacks that either lack contextual relevance or are easily recognizable. In\nthis work, we introduce BlackDAN, an innovative black-box attack framework with\nmulti-objective optimization, aiming to generate high-quality prompts that\neffectively facilitate jailbreaking while maintaining contextual relevance and\nminimizing detectability. BlackDAN leverages Multiobjective Evolutionary\nAlgorithms (MOEAs), specifically the NSGA-II algorithm, to optimize jailbreaks\nacross multiple objectives including ASR, stealthiness, and semantic relevance.\nBy integrating mechanisms like mutation, crossover, and Pareto-dominance,\nBlackDAN provides a transparent and interpretable process for generating\njailbreaks. Furthermore, the framework allows customization based on user\npreferences, enabling the selection of prompts that balance harmfulness,\nrelevance, and other factors. Experimental results demonstrate that BlackDAN\noutperforms traditional single-objective methods, yielding higher success rates\nand improved robustness across various LLMs and multimodal LLMs, while ensuring\njailbreak responses are both relevant and less detectable.\n","authors":["Xinyuan Wang","Victor Shea-Jay Huang","Renmiao Chen","Hao Wang","Chengwei Pan","Lei Sha","Minlie Huang"],"pdf_url":"https://arxiv.org/pdf/2410.09804v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.14479v1","updated":"2024-10-18T14:02:34Z","published":"2024-10-18T14:02:34Z","title":"Backdoored Retrievers for Prompt Injection Attacks on Retrieval\n  Augmented Generation of Large Language Models","summary":"  Large Language Models (LLMs) have demonstrated remarkable capabilities in\ngenerating coherent text but remain limited by the static nature of their\ntraining data. Retrieval Augmented Generation (RAG) addresses this issue by\ncombining LLMs with up-to-date information retrieval, but also expand the\nattack surface of the system. This paper investigates prompt injection attacks\non RAG, focusing on malicious objectives beyond misinformation, such as\ninserting harmful links, promoting unauthorized services, and initiating\ndenial-of-service behaviors. We build upon existing corpus poisoning techniques\nand propose a novel backdoor attack aimed at the fine-tuning process of the\ndense retriever component. Our experiments reveal that corpus poisoning can\nachieve significant attack success rates through the injection of a small\nnumber of compromised documents into the retriever corpus. In contrast,\nbackdoor attacks demonstrate even higher success rates but necessitate a more\ncomplex setup, as the victim must fine-tune the retriever using the attacker\npoisoned dataset.\n","authors":["Cody Clop","Yannick Teglia"],"pdf_url":"https://arxiv.org/pdf/2410.14479v1.pdf","comment":"12 pages, 5 figures"},{"id":"http://arxiv.org/abs/2410.14477v1","updated":"2024-10-18T14:02:06Z","published":"2024-10-18T14:02:06Z","title":"Laplace Transform Based Low-Complexity Learning of Continuous Markov\n  Semigroups","summary":"  Markov processes serve as a universal model for many real-world random\nprocesses. This paper presents a data-driven approach for learning these models\nthrough the spectral decomposition of the infinitesimal generator (IG) of the\nMarkov semigroup. The unbounded nature of IGs complicates traditional methods\nsuch as vector-valued regression and Hilbert-Schmidt operator analysis.\nExisting techniques, including physics-informed kernel regression, are\ncomputationally expensive and limited in scope, with no recovery guarantees for\ntransfer operator methods when the time-lag is small. We propose a novel method\nthat leverages the IG's resolvent, characterized by the Laplace transform of\ntransfer operators. This approach is robust to time-lag variations, ensuring\naccurate eigenvalue learning even for small time-lags. Our statistical analysis\napplies to a broader class of Markov processes than current methods while\nreducing computational complexity from quadratic to linear in the state\ndimension. Finally, we illustrate the behaviour of our method in two\nexperiments.\n","authors":["Vladimir R. Kostic","Karim Lounici","Hélène Halconruy","Timothée Devergne","Pietro Novelli","Massimiliano Pontil"],"pdf_url":"https://arxiv.org/pdf/2410.14477v1.pdf","comment":"35 pages"},{"id":"http://arxiv.org/abs/2410.14475v1","updated":"2024-10-18T14:00:44Z","published":"2024-10-18T14:00:44Z","title":"Enhancing Cryptocurrency Market Forecasting: Advanced Machine Learning\n  Techniques and Industrial Engineering Contributions","summary":"  Cryptocurrencies, as decentralized digital assets, have experienced rapid\ngrowth and adoption, with over 23,000 cryptocurrencies and a market\ncapitalization nearing \\$1.1 trillion (about \\$3,400 per person in the US) as\nof 2023. This dynamic market presents significant opportunities and risks,\nhighlighting the need for accurate price prediction models to manage\nvolatility. This chapter comprehensively reviews machine learning (ML)\ntechniques applied to cryptocurrency price prediction from 2014 to 2024. We\nexplore various ML algorithms, including linear models, tree-based approaches,\nand advanced deep learning architectures such as transformers and large\nlanguage models. Additionally, we examine the role of sentiment analysis in\ncapturing market sentiment from textual data like social media posts and news\narticles to anticipate price fluctuations. With expertise in optimizing complex\nsystems and processes, industrial engineers are pivotal in enhancing these\nmodels. They contribute by applying principles of process optimization,\nefficiency, and risk mitigation to improve computational performance and data\nmanagement. This chapter highlights the evolving landscape of cryptocurrency\nprice prediction, the integration of emerging technologies, and the significant\nrole of industrial engineers in refining predictive models. By addressing\ncurrent limitations and exploring future research directions, this chapter aims\nto advance the development of more accurate and robust prediction systems,\nsupporting better-informed investment decisions and more stable market\nbehavior.\n","authors":["Jannatun Nayeem Pinky","Ramya Akula"],"pdf_url":"https://arxiv.org/pdf/2410.14475v1.pdf","comment":"63 pages, 6 figures"},{"id":"http://arxiv.org/abs/2410.14470v1","updated":"2024-10-18T13:54:46Z","published":"2024-10-18T13:54:46Z","title":"How Do Training Methods Influence the Utilization of Vision Models?","summary":"  Not all learnable parameters (e.g., weights) contribute equally to a neural\nnetwork's decision function. In fact, entire layers' parameters can sometimes\nbe reset to random values with little to no impact on the model's decisions. We\nrevisit earlier studies that examined how architecture and task complexity\ninfluence this phenomenon and ask: is this phenomenon also affected by how we\ntrain the model? We conducted experimental evaluations on a diverse set of\nImageNet-1k classification models to explore this, keeping the architecture and\ntraining data constant but varying the training pipeline. Our findings reveal\nthat the training method strongly influences which layers become critical to\nthe decision function for a given task. For example, improved training regimes\nand self-supervised training increase the importance of early layers while\nsignificantly under-utilizing deeper layers. In contrast, methods such as\nadversarial training display an opposite trend. Our preliminary results extend\nprevious findings, offering a more nuanced understanding of the inner mechanics\nof neural networks.\n  Code: https://github.com/paulgavrikov/layer_criticality\n","authors":["Paul Gavrikov","Shashank Agnihotri","Margret Keuper","Janis Keuper"],"pdf_url":"https://arxiv.org/pdf/2410.14470v1.pdf","comment":"Accepted at the Interpretable AI: Past, Present and Future Workshop\n  at NeurIPS 2024"},{"id":"http://arxiv.org/abs/2410.14466v1","updated":"2024-10-18T13:51:25Z","published":"2024-10-18T13:51:25Z","title":"Flow-based Sampling for Entanglement Entropy and the Machine Learning of\n  Defects","summary":"  We introduce a novel technique to numerically calculate R\\'enyi entanglement\nentropies in lattice quantum field theory using generative models. We describe\nhow flow-based approaches can be combined with the replica trick using a custom\nneural-network architecture around a lattice defect connecting two replicas.\nNumerical tests for the $\\phi^4$ scalar field theory in two and three\ndimensions demonstrate that our technique outperforms state-of-the-art Monte\nCarlo calculations, and exhibit a promising scaling with the defect size.\n","authors":["Andrea Bulgarelli","Elia Cellini","Karl Jansen","Stefan Kühn","Alessandro Nada","Shinichi Nakajima","Kim A. Nicoli","Marco Panero"],"pdf_url":"https://arxiv.org/pdf/2410.14466v1.pdf","comment":"10 pages, 9 figures"},{"id":"http://arxiv.org/abs/2404.18550v4","updated":"2024-10-18T13:50:10Z","published":"2024-04-29T09:45:46Z","title":"IncidentResponseGPT: Generating Traffic Incident Response Plans with\n  Generative Artificial Intelligence","summary":"  The proposed IncidentResponseGPT framework - a novel system that applies\ngenerative artificial intelligence (AI) to potentially enhance the efficiency\nand effectiveness of traffic incident response. This model allows for synthesis\nof region-specific incident response guidelines and generates incident response\nplans adapted to specific area, aiming to expedite decision-making for traffic\nmanagement authorities. This approach aims to accelerate incident resolution\ntimes by suggesting various recommendations (e.g. optimal rerouting strategies,\nestimating resource needs) to minimize the overall impact on the urban traffic\nnetwork. The system suggests specific actions, including dynamic lane closures,\noptimized rerouting and dispatching appropriate emergency resources. We utilize\nthe Technique for Order Preference by Similarity to Ideal Solution (TOPSIS) to\nrank generated response plans based on criteria like impact minimization and\nresource efficiency based on their proximity to an human-proposed solution.\n","authors":["Artur Grigorev","Adriana-Simona Mihaita Khaled Saleh","Yuming Ou"],"pdf_url":"https://arxiv.org/pdf/2404.18550v4.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.14464v1","updated":"2024-10-18T13:48:01Z","published":"2024-10-18T13:48:01Z","title":"Electrocardiogram-Language Model for Few-Shot Question Answering with\n  Meta Learning","summary":"  Electrocardiogram (ECG) interpretation requires specialized expertise, often\ninvolving synthesizing insights from ECG signals with complex clinical queries\nposed in natural language. The scarcity of labeled ECG data coupled with the\ndiverse nature of clinical inquiries presents a significant challenge for\ndeveloping robust and adaptable ECG diagnostic systems. This work introduces a\nnovel multimodal meta-learning method for few-shot ECG question answering,\naddressing the challenge of limited labeled data while leveraging the rich\nknowledge encoded within large language models (LLMs). Our LLM-agnostic\napproach integrates a pre-trained ECG encoder with a frozen LLM (e.g., LLaMA\nand Gemma) via a trainable fusion module, enabling the language model to reason\nabout ECG data and generate clinically meaningful answers. Extensive\nexperiments demonstrate superior generalization to unseen diagnostic tasks\ncompared to supervised baselines, achieving notable performance even with\nlimited ECG leads. For instance, in a 5-way 5-shot setting, our method using\nLLaMA-3.1-8B achieves accuracy of 84.6%, 77.3%, and 69.6% on single verify,\nchoose and query question types, respectively. These results highlight the\npotential of our method to enhance clinical ECG interpretation by combining\nsignal processing with the nuanced language understanding capabilities of LLMs,\nparticularly in data-constrained scenarios.\n","authors":["Jialu Tang","Tong Xia","Yuan Lu","Cecilia Mascolo","Aaqib Saeed"],"pdf_url":"https://arxiv.org/pdf/2410.14464v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.14461v1","updated":"2024-10-18T13:40:44Z","published":"2024-10-18T13:40:44Z","title":"The Propensity for Density in Feed-forward Models","summary":"  Does the process of training a neural network to solve a task tend to use all\nof the available weights even when the task could be solved with fewer weights?\nTo address this question we study the effects of pruning fully connected,\nconvolutional and residual models while varying their widths. We find that the\nproportion of weights that can be pruned without degrading performance is\nlargely invariant to model size. Increasing the width of a model has little\neffect on the density of the pruned model relative to the increase in absolute\nsize of the pruned network. In particular, we find substantial prunability\nacross a large range of model sizes, where our biggest model is 50 times as\nwide as our smallest model. We explore three hypotheses that could explain\nthese findings.\n","authors":["Nandi Schoots","Alex Jackson","Ali Kholmovaia","Peter McBurney","Murray Shanahan"],"pdf_url":"https://arxiv.org/pdf/2410.14461v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.13663v4","updated":"2024-10-18T13:16:57Z","published":"2024-06-19T16:10:26Z","title":"Model Internals-based Answer Attribution for Trustworthy\n  Retrieval-Augmented Generation","summary":"  Ensuring the verifiability of model answers is a fundamental challenge for\nretrieval-augmented generation (RAG) in the question answering (QA) domain.\nRecently, self-citation prompting was proposed to make large language models\n(LLMs) generate citations to supporting documents along with their answers.\nHowever, self-citing LLMs often struggle to match the required format, refer to\nnon-existent sources, and fail to faithfully reflect LLMs' context usage\nthroughout the generation. In this work, we present MIRAGE --Model\nInternals-based RAG Explanations -- a plug-and-play approach using model\ninternals for faithful answer attribution in RAG applications. MIRAGE detects\ncontext-sensitive answer tokens and pairs them with retrieved documents\ncontributing to their prediction via saliency methods. We evaluate our proposed\napproach on a multilingual extractive QA dataset, finding high agreement with\nhuman answer attribution. On open-ended QA, MIRAGE achieves citation quality\nand efficiency comparable to self-citation while also allowing for a\nfiner-grained control of attribution parameters. Our qualitative evaluation\nhighlights the faithfulness of MIRAGE's attributions and underscores the\npromising application of model internals for RAG answer attribution.\n","authors":["Jirui Qi","Gabriele Sarti","Raquel Fernández","Arianna Bisazza"],"pdf_url":"https://arxiv.org/pdf/2406.13663v4.pdf","comment":"Accepted by EMNLP 2024 Main Conference. Code and data released at\n  https://github.com/Betswish/MIRAGE"},{"id":"http://arxiv.org/abs/2410.12804v2","updated":"2024-10-18T13:15:50Z","published":"2024-09-30T12:05:07Z","title":"Hip Fracture Patient Pathways and Agent-based Modelling","summary":"  Increased healthcare demand is significantly straining European services.\nDigital solutions including advanced modelling techniques offer a promising\nsolution to optimising patient flow without impacting day-to-day healthcare\nprovision. In this work we outline an ongoing project that aims to optimise\nhealthcare resources using agent-based simulations.\n","authors":["Alison N. O'Connor","Stephen E. Ryan","Gauri Vaidya","Paul Harford","Meghana Kshirsagar"],"pdf_url":"https://arxiv.org/pdf/2410.12804v2.pdf","comment":"6 pages, 2 figures"},{"id":"http://arxiv.org/abs/2410.11443v2","updated":"2024-10-18T13:09:00Z","published":"2024-10-15T09:47:49Z","title":"Are High-Degree Representations Really Unnecessary in Equivariant Graph\n  Neural Networks?","summary":"  Equivariant Graph Neural Networks (GNNs) that incorporate E(3) symmetry have\nachieved significant success in various scientific applications. As one of the\nmost successful models, EGNN leverages a simple scalarization technique to\nperform equivariant message passing over only Cartesian vectors (i.e.,\n1st-degree steerable vectors), enjoying greater efficiency and efficacy\ncompared to equivariant GNNs using higher-degree steerable vectors. This\nsuccess suggests that higher-degree representations might be unnecessary. In\nthis paper, we disprove this hypothesis by exploring the expressivity of\nequivariant GNNs on symmetric structures, including $k$-fold rotations and\nregular polyhedra. We theoretically demonstrate that equivariant GNNs will\nalways degenerate to a zero function if the degree of the output\nrepresentations is fixed to 1 or other specific values. Based on this\ntheoretical insight, we propose HEGNN, a high-degree version of EGNN to\nincrease the expressivity by incorporating high-degree steerable vectors while\nmaintaining EGNN's efficiency through the scalarization trick. Our extensive\nexperiments demonstrate that HEGNN not only aligns with our theoretical\nanalyses on toy datasets consisting of symmetric structures, but also shows\nsubstantial improvements on more complicated datasets such as $N$-body and\nMD17. Our theoretical findings and empirical results potentially open up new\npossibilities for the research of equivariant GNNs.\n","authors":["Jiacheng Cen","Anyi Li","Ning Lin","Yuxiang Ren","Zihe Wang","Wenbing Huang"],"pdf_url":"https://arxiv.org/pdf/2410.11443v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2405.11877v5","updated":"2024-10-18T13:03:05Z","published":"2024-05-20T08:41:15Z","title":"A Novel Cartography-Based Curriculum Learning Method Applied on RoNLI:\n  The First Romanian Natural Language Inference Corpus","summary":"  Natural language inference (NLI), the task of recognizing the entailment\nrelationship in sentence pairs, is an actively studied topic serving as a proxy\nfor natural language understanding. Despite the relevance of the task in\nbuilding conversational agents and improving text classification, machine\ntranslation and other NLP tasks, to the best of our knowledge, there is no\npublicly available NLI corpus for the Romanian language. To this end, we\nintroduce the first Romanian NLI corpus (RoNLI) comprising 58K training\nsentence pairs, which are obtained via distant supervision, and 6K validation\nand test sentence pairs, which are manually annotated with the correct labels.\nWe conduct experiments with multiple machine learning methods based on distant\nlearning, ranging from shallow models based on word embeddings to\ntransformer-based neural networks, to establish a set of competitive baselines.\nFurthermore, we improve on the best model by employing a new curriculum\nlearning strategy based on data cartography. Our dataset and code to reproduce\nthe baselines are available at https://github.com/Eduard6421/RONLI.\n","authors":["Eduard Poesina","Cornelia Caragea","Radu Tudor Ionescu"],"pdf_url":"https://arxiv.org/pdf/2405.11877v5.pdf","comment":"Accepted at ACL 2024 (Main)"},{"id":"http://arxiv.org/abs/2410.14436v1","updated":"2024-10-18T12:53:23Z","published":"2024-10-18T12:53:23Z","title":"Learning to refine domain knowledge for biological network inference","summary":"  Perturbation experiments allow biologists to discover causal relationships\nbetween variables of interest, but the sparsity and high dimensionality of\nthese data pose significant challenges for causal structure learning\nalgorithms. Biological knowledge graphs can bootstrap the inference of causal\nstructures in these situations, but since they compile vastly diverse\ninformation, they can bias predictions towards well-studied systems.\nAlternatively, amortized causal structure learning algorithms encode inductive\nbiases through data simulation and train supervised models to recapitulate\nthese synthetic graphs. However, realistically simulating biology is arguably\neven harder than understanding a specific system. In this work, we take\ninspiration from both strategies and propose an amortized algorithm for\nrefining domain knowledge, based on data observations. On real and synthetic\ndatasets, we show that our approach outperforms baselines in recovering ground\ntruth causal graphs and identifying errors in the prior knowledge with limited\ninterventional data.\n","authors":["Peiwen Li","Menghua Wu"],"pdf_url":"https://arxiv.org/pdf/2410.14436v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.14433v1","updated":"2024-10-18T12:51:19Z","published":"2024-10-18T12:51:19Z","title":"A Bioinformatic Approach Validated Utilizing Machine Learning Algorithms\n  to Identify Relevant Biomarkers and Crucial Pathways in Gallbladder Cancer","summary":"  Gallbladder cancer (GBC) is the most frequent cause of disease among biliary\ntract neoplasms. Identifying the molecular mechanisms and biomarkers linked to\nGBC progression has been a significant challenge in scientific research. Few\nrecent studies have explored the roles of biomarkers in GBC. Our study aimed to\nidentify biomarkers in GBC using machine learning (ML) and bioinformatics\ntechniques. We compared GBC tumor samples with normal samples to identify\ndifferentially expressed genes (DEGs) from two microarray datasets (GSE100363,\nGSE139682) obtained from the NCBI GEO database. A total of 146 DEGs were found,\nwith 39 up-regulated and 107 down-regulated genes. Functional enrichment\nanalysis of these DEGs was performed using Gene Ontology (GO) terms and\nREACTOME pathways through DAVID. The protein-protein interaction network was\nconstructed using the STRING database. To identify hub genes, we applied three\nranking algorithms: Degree, MNC, and Closeness Centrality. The intersection of\nhub genes from these algorithms yielded 11 hub genes. Simultaneously, two\nfeature selection methods (Pearson correlation and recursive feature\nelimination) were used to identify significant gene subsets. We then developed\nML models using SVM and RF on the GSE100363 dataset, with validation on\nGSE139682, to determine the gene subset that best distinguishes GBC samples.\nThe hub genes outperformed the other gene subsets. Finally, NTRK2, COL14A1,\nSCN4B, ATP1A2, SLC17A7, SLIT3, COL7A1, CLDN4, CLEC3B, ADCYAP1R1, and MFAP4 were\nidentified as crucial genes, with SLIT3, COL7A1, and CLDN4 being strongly\nlinked to GBC development and prediction.\n","authors":["Rabea Khatun","Wahia Tasnim","Maksuda Akter","Md Manowarul Islam","Md. Ashraf Uddin","Md. Zulfiker Mahmud","Saurav Chandra Das"],"pdf_url":"https://arxiv.org/pdf/2410.14433v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.14429v1","updated":"2024-10-18T12:48:22Z","published":"2024-10-18T12:48:22Z","title":"FashionR2R: Texture-preserving Rendered-to-Real Image Translation with\n  Diffusion Models","summary":"  Modeling and producing lifelike clothed human images has attracted\nresearchers' attention from different areas for decades, with the complexity\nfrom highly articulated and structured content. Rendering algorithms decompose\nand simulate the imaging process of a camera, while are limited by the accuracy\nof modeled variables and the efficiency of computation. Generative models can\nproduce impressively vivid human images, however still lacking in\ncontrollability and editability. This paper studies photorealism enhancement of\nrendered images, leveraging generative power from diffusion models on the\ncontrolled basis of rendering. We introduce a novel framework to translate\nrendered images into their realistic counterparts, which consists of two\nstages: Domain Knowledge Injection (DKI) and Realistic Image Generation (RIG).\nIn DKI, we adopt positive (real) domain finetuning and negative (rendered)\ndomain embedding to inject knowledge into a pretrained Text-to-image (T2I)\ndiffusion model. In RIG, we generate the realistic image corresponding to the\ninput rendered image, with a Texture-preserving Attention Control (TAC) to\npreserve fine-grained clothing textures, exploiting the decoupled features\nencoded in the UNet structure. Additionally, we introduce SynFashion dataset,\nfeaturing high-quality digital clothing images with diverse textures. Extensive\nexperimental results demonstrate the superiority and effectiveness of our\nmethod in rendered-to-real image translation.\n","authors":["Rui Hu","Qian He","Gaofeng He","Jiedong Zhuang","Huang Chen","Huafeng Liu","Huamin Wang"],"pdf_url":"https://arxiv.org/pdf/2410.14429v1.pdf","comment":"Accepted by NeurIPS 2024"},{"id":"http://arxiv.org/abs/2410.14426v1","updated":"2024-10-18T12:41:41Z","published":"2024-10-18T12:41:41Z","title":"Predicting time-varying flux and balance in metabolic systems using\n  structured neural-ODE processes","summary":"  We develop a novel data-driven framework as an alternative to dynamic flux\nbalance analysis, bypassing the demand for deep domain knowledge and manual\nefforts to formulate the optimization problem. The proposed framework is\nend-to-end, which trains a structured neural ODE process (SNODEP) model to\nestimate flux and balance samples using gene-expression time-series data.\nSNODEP is designed to circumvent the limitations of the standard neural ODE\nprocess model, including restricting the latent and decoder sampling\ndistributions to be normal and lacking structure between context points for\ncalculating the latent, thus more suitable for modeling the underlying dynamics\nof a metabolic system. Through comprehensive experiments ($156$ in total), we\ndemonstrate that SNODEP not only predicts the unseen time points of real-world\ngene-expression data and the flux and balance estimates well but can even\ngeneralize to more challenging unseen knockout configurations and irregular\ndata sampling scenarios, all essential for metabolic pathway analysis. We hope\nour work can serve as a catalyst for building more scalable and powerful models\nfor genome-scale metabolic analysis. Our code is available at:\n\\url{https://github.com/TrustMLRG/SNODEP}.\n","authors":["Santanu Rathod","Pietro Lio","Xiao Zhang"],"pdf_url":"https://arxiv.org/pdf/2410.14426v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2310.03546v2","updated":"2024-10-18T12:41:23Z","published":"2023-10-05T13:57:53Z","title":"Plug-and-Play Posterior Sampling under Mismatched Measurement and Prior\n  Models","summary":"  Posterior sampling has been shown to be a powerful Bayesian approach for\nsolving imaging inverse problems. The recent plug-and-play unadjusted Langevin\nalgorithm (PnP-ULA) has emerged as a promising method for Monte Carlo sampling\nand minimum mean squared error (MMSE) estimation by combining physical\nmeasurement models with deep-learning priors specified using image denoisers.\nHowever, the intricate relationship between the sampling distribution of\nPnP-ULA and the mismatched data-fidelity and denoiser has not been\ntheoretically analyzed. We address this gap by proposing a posterior-L2\npseudometric and using it to quantify an explicit error bound for PnP-ULA under\nmismatched posterior distribution. We numerically validate our theory on\nseveral inverse problems such as sampling from Gaussian mixture models and\nimage deblurring. Our results suggest that the sensitivity of the sampling\ndistribution of PnP-ULA to a mismatch in the measurement model and the denoiser\ncan be precisely characterized.\n","authors":["Marien Renaud","Jiaming Liu","Valentin de Bortoli","Andrés Almansa","Ulugbek S. Kamilov"],"pdf_url":"https://arxiv.org/pdf/2310.03546v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.14423v1","updated":"2024-10-18T12:37:51Z","published":"2024-10-18T12:37:51Z","title":"Integrating Deep Learning with Fundus and Optical Coherence Tomography\n  for Cardiovascular Disease Prediction","summary":"  Early identification of patients at risk of cardiovascular diseases (CVD) is\ncrucial for effective preventive care, reducing healthcare burden, and\nimproving patients' quality of life. This study demonstrates the potential of\nretinal optical coherence tomography (OCT) imaging combined with fundus\nphotographs for identifying future adverse cardiac events. We used data from\n977 patients who experienced CVD within a 5-year interval post-image\nacquisition, alongside 1,877 control participants without CVD, totaling 2,854\nsubjects. We propose a novel binary classification network based on a\nMulti-channel Variational Autoencoder (MCVAE), which learns a latent embedding\nof patients' fundus and OCT images to classify individuals into two groups:\nthose likely to develop CVD in the future and those who are not. Our model,\ntrained on both imaging modalities, achieved promising results (AUROC 0.78 +/-\n0.02, accuracy 0.68 +/- 0.002, precision 0.74 +/- 0.02, sensitivity 0.73 +/-\n0.02, and specificity 0.68 +/- 0.01), demonstrating its efficacy in identifying\npatients at risk of future CVD events based on their retinal images. This study\nhighlights the potential of retinal OCT imaging and fundus photographs as\ncost-effective, non-invasive alternatives for predicting cardiovascular disease\nrisk. The widespread availability of these imaging techniques in optometry\npractices and hospitals further enhances their potential for large-scale CVD\nrisk screening. Our findings contribute to the development of standardized,\naccessible methods for early CVD risk identification, potentially improving\npreventive care strategies and patient outcomes.\n","authors":["Cynthia Maldonado-Garcia","Arezoo Zakeri","Alejandro F Frangi","Nishant Ravikumar"],"pdf_url":"https://arxiv.org/pdf/2410.14423v1.pdf","comment":"Part of the book series: Lecture Notes in Computer Science\n  ((LNCS,volume 15155))"},{"id":"http://arxiv.org/abs/2410.14420v1","updated":"2024-10-18T12:33:10Z","published":"2024-10-18T12:33:10Z","title":"Asymptotic non-linear shrinkage formulas for weighted sample covariance","summary":"  We compute asymptotic non-linear shrinkage formulas for covariance and\nprecision matrix estimators for weighted sample covariances, in the spirit of\nLedoit and P\\'ech\\'e. We detail explicitly the formulas for\nexponentially-weighted sample covariances. Those new tools pave a way for\napplying non-linear shrinkage methods on weighted sample covariance. We show\nexperimentally the performance of the asymptotic shrinkage formulas. Finally,\nwe test the robustness of the theory to a heavy-tailed distributions.\n","authors":["Benoit Oriol"],"pdf_url":"https://arxiv.org/pdf/2410.14420v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.14416v1","updated":"2024-10-18T12:29:10Z","published":"2024-10-18T12:29:10Z","title":"An explainable machine learning approach for energy forecasting at the\n  household level","summary":"  Electricity forecasting has been a recurring research topic, as it is key to\nfinding the right balance between production and consumption. While most papers\nare focused on the national or regional scale, few are interested in the\nhousehold level. Desegregated forecast is a common topic in Machine Learning\n(ML) literature but lacks explainability that household energy forecasts\nrequire. This paper specifically targets the challenges of forecasting\nelectricity use at the household level. This paper confronts common Machine\nLearning algorithms to electricity household forecasts, weighing the pros and\ncons, including accuracy and explainability with well-known key metrics.\nFurthermore, we also confront them in this paper with the business challenges\nspecific to this sector such as explainability or outliers resistance. We\nintroduce a custom decision tree, aiming at providing a fair estimate of the\nenergy consumption, while being explainable and consistent with human\nintuition. We show that this novel method allows greater explainability without\nsacrificing much accuracy. The custom tree methodology can be used in various\nbusiness use cases but is subject to limitations, such as a lack of resilience\nwith outliers.\n","authors":["Pauline Béraud","Margaux Rioux","Michel Babany","Philippe de La Chevasnerie","Damien Theis","Giacomo Teodori","Chloé Pinguet","Romane Rigaud","François Leclerc"],"pdf_url":"https://arxiv.org/pdf/2410.14416v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.10918v5","updated":"2024-10-18T12:27:07Z","published":"2024-06-16T12:46:40Z","title":"Multi-LLM QA with Embodied Exploration","summary":"  Large language models (LLMs) have grown in popularity due to their natural\nlanguage interface and pre trained knowledge, leading to rapidly increasing\nsuccess in question-answering (QA) tasks. More recently, multi-agent systems\nwith LLM-based agents (Multi-LLM) have been utilized increasingly more for QA.\nIn these scenarios, the models may each answer the question and reach a\nconsensus or each model is specialized to answer different domain questions.\nHowever, most prior work dealing with Multi-LLM QA has focused on scenarios\nwhere the models are asked in a zero-shot manner or are given information\nsources to extract the answer. For question answering of an unknown\nenvironment, embodied exploration of the environment is first needed to answer\nthe question. This skill is necessary for personalizing embodied AI to\nenvironments such as households. There is a lack of insight into whether a\nMulti-LLM system can handle question-answering based on observations from\nembodied exploration. In this work, we address this gap by investigating the\nuse of Multi-Embodied LLM Explorers (MELE) for QA in an unknown environment.\nMultiple LLM-based agents independently explore and then answer queries about a\nhousehold environment. We analyze different aggregation methods to generate a\nsingle, final answer for each query: debating, majority voting, and training a\ncentral answer module (CAM). Using CAM, we observe a $46\\%$ higher accuracy\ncompared against the other non-learning-based aggregation methods. We provide\ncode and the query dataset for further research.\n","authors":["Bhrij Patel","Vishnu Sashank Dorbala","Amrit Singh Bedi","Dinesh Manocha"],"pdf_url":"https://arxiv.org/pdf/2406.10918v5.pdf","comment":"16 pages, 9 Figures, 5 Tables"},{"id":"http://arxiv.org/abs/2410.14413v1","updated":"2024-10-18T12:26:51Z","published":"2024-10-18T12:26:51Z","title":"WeSpeR: Population spectrum retrieval and spectral density estimation of\n  weighted sample covariance","summary":"  The spectrum of the weighted sample covariance shows a asymptotic non random\nbehavior when the dimension grows with the number of samples. In this setting,\nwe prove that the asymptotic spectral distribution $F$ of the weighted sample\ncovariance has a continuous density on $\\mathbb{R}^*$. We address then the\npractical problem of numerically finding this density. We propose a procedure\nto compute it, to determine the support of $F$ and define an efficient grid on\nit. We use this procedure to design the $\\textit{WeSpeR}$ algorithm, which\nestimates the spectral density and retrieves the true spectral covariance\nspectrum. Empirical tests confirm the good properties of the $\\textit{WeSpeR}$\nalgorithm.\n","authors":["Benoit Oriol"],"pdf_url":"https://arxiv.org/pdf/2410.14413v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2407.10547v2","updated":"2024-10-18T12:25:46Z","published":"2024-07-15T08:57:02Z","title":"Learning Social Cost Functions for Human-Aware Path Planning","summary":"  Achieving social acceptance is one of the main goals of Social Robotic\nNavigation. Despite this topic has received increasing interest in recent\nyears, most of the research has focused on driving the robotic agent along\nobstacle-free trajectories, planning around estimates of future human motion to\nrespect personal distances and optimize navigation. However, social\ninteractions in everyday life are also dictated by norms that do not strictly\ndepend on movement, such as when standing at the end of a queue rather than\ncutting it. In this paper, we propose a novel method to recognize common social\nscenarios and modify a traditional planner's cost function to adapt to them.\nThis solution enables the robot to carry out different social navigation\nbehaviors that would not arise otherwise, maintaining the robustness of\ntraditional navigation. Our approach allows the robot to learn different social\nnorms with a single learned model, rather than having different modules for\neach task. As a proof of concept, we consider the tasks of queuing and respect\ninteraction spaces of groups of people talking to one another, but the method\ncan be extended to other human activities that do not involve motion.\n","authors":["Andrea Eirale","Matteo Leonetti","Marcello Chiaberge"],"pdf_url":"https://arxiv.org/pdf/2407.10547v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.14411v1","updated":"2024-10-18T12:24:05Z","published":"2024-10-18T12:24:05Z","title":"SNAC: Multi-Scale Neural Audio Codec","summary":"  Neural audio codecs have recently gained popularity because they can\nrepresent audio signals with high fidelity at very low bitrates, making it\nfeasible to use language modeling approaches for audio generation and\nunderstanding. Residual Vector Quantization (RVQ) has become the standard\ntechnique for neural audio compression using a cascade of VQ codebooks. This\npaper proposes the Multi-Scale Neural Audio Codec, a simple extension of RVQ\nwhere the quantizers can operate at different temporal resolutions. By applying\na hierarchy of quantizers at variable frame rates, the codec adapts to the\naudio structure across multiple timescales. This leads to more efficient\ncompression, as demonstrated by extensive objective and subjective evaluations.\nThe code and model weights are open-sourced at\nhttps://github.com/hubertsiuzdak/snac.\n","authors":["Hubert Siuzdak","Florian Grötschla","Luca A. Lanzendörfer"],"pdf_url":"https://arxiv.org/pdf/2410.14411v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.14437v3","updated":"2024-10-18T12:20:54Z","published":"2022-12-29T19:21:33Z","title":"An algorithm for clustering with confidence-based must-link and\n  cannot-link constraints","summary":"  We study here the semi-supervised $k$-clustering problem where information is\navailable on whether pairs of objects are in the same or in different clusters.\nThis information is either available with certainty or with a limited level of\nconfidence. We introduce the PCCC (Pairwise-Confidence-Constraints-Clustering)\nalgorithm, which iteratively assigns objects to clusters while accounting for\nthe information provided on the pairs of objects. Our algorithm uses integer\nprogramming for the assignment of objects which allows to include relationships\nas hard constraints that are guaranteed to be satisfied or as soft constraints\nthat can be violated subject to a penalty. This flexibility distinguishes our\nalgorithm from the state-of-the-art in which all pairwise constraints are\neither considered hard, or all are considered soft. We developed an enhanced\nmulti-start approach and a model-size reduction technique for the integer\nprogram that contributes to the effectiveness and the efficiency of the\nalgorithm. Unlike existing algorithms, our algorithm scales to large-scale\ninstances with up to 60,000 objects, 100 clusters, and millions of cannot-link\nconstraints (which are the most challenging constraints to incorporate). We\ncompare the PCCC algorithm with state-of-the-art approaches in an extensive\ncomputational study. Even though the PCCC algorithm is more general than the\nstate-of-the-art approaches in its applicability, it outperforms the\nstate-of-the-art approaches on instances with all hard or all soft constraints\nboth in terms of runtime and various metrics of solution quality. The code of\nthe PCCC algorithm is publicly available on GitHub.\n","authors":["Philipp Baumann","Dorit S. Hochbaum"],"pdf_url":"https://arxiv.org/pdf/2212.14437v3.pdf","comment":"To appear in INFORMS Journal on Computing"},{"id":"http://arxiv.org/abs/2405.16504v2","updated":"2024-10-18T12:20:11Z","published":"2024-05-26T09:57:45Z","title":"Explaining Modern Gated-Linear RNNs via a Unified Implicit Attention\n  Formulation","summary":"  Recent advances in efficient sequence modeling have led to attention-free\nlayers, such as Mamba, RWKV, and various gated RNNs, all featuring\nsub-quadratic complexity in sequence length and excellent scaling properties,\nenabling the construction of a new type of foundation models. In this paper, we\npresent a unified view of these models, formulating such layers as implicit\ncausal self-attention layers. The formulation includes most of their\nsub-components and is not limited to a specific part of the architecture. The\nframework compares the underlying mechanisms on similar grounds for different\nlayers and provides a direct means for applying explainability methods. Our\nexperiments show that our attention matrices and attribution method outperform\nan alternative and a more limited formulation that was recently proposed for\nMamba. For the other architectures for which our method is the first to provide\nsuch a view, our method is effective and competitive in the relevant metrics\ncompared to the results obtained by state-of-the-art Transformer explainability\nmethods. Our code is publicly available.\n","authors":["Itamar Zimerman","Ameen Ali","Lior Wolf"],"pdf_url":"https://arxiv.org/pdf/2405.16504v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.12950v2","updated":"2024-10-18T12:19:41Z","published":"2024-06-18T12:54:47Z","title":"MolecularGPT: Open Large Language Model (LLM) for Few-Shot Molecular\n  Property Prediction","summary":"  Molecular property prediction (MPP) is a fundamental and crucial task in drug\ndiscovery. However, prior methods are limited by the requirement for a large\nnumber of labeled molecules and their restricted ability to generalize for\nunseen and new tasks, both of which are essential for real-world applications.\nTo address these challenges, we present MolecularGPT for few-shot MPP. From a\nperspective on instruction tuning, we fine-tune large language models (LLMs)\nbased on curated molecular instructions spanning over 1000 property prediction\ntasks. This enables building a versatile and specialized LLM that can be\nadapted to novel MPP tasks without any fine-tuning through zero- and few-shot\nin-context learning (ICL). MolecularGPT exhibits competitive in-context\nreasoning capabilities across 10 downstream evaluation datasets, setting new\nbenchmarks for few-shot molecular prediction tasks. More importantly, with just\ntwo-shot examples, MolecularGPT can outperform standard supervised graph neural\nnetwork methods on 4 out of 7 datasets. It also excels state-of-the-art LLM\nbaselines by up to 15.7% increase on classification accuracy and decrease of\n17.9 on regression metrics (e.g., RMSE) under zero-shot. This study\ndemonstrates the potential of LLMs as effective few-shot molecular property\npredictors. The code is available at https://github.com/NYUSHCS/MolecularGPT.\n","authors":["Yuyan Liu","Sirui Ding","Sheng Zhou","Wenqi Fan","Qiaoyu Tan"],"pdf_url":"https://arxiv.org/pdf/2406.12950v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.09567v2","updated":"2024-10-18T12:18:01Z","published":"2024-10-12T15:29:18Z","title":"Timeseria: an object-oriented time series processing library","summary":"  Timeseria is an object-oriented time series processing library implemented in\nPython, which aims at making it easier to manipulate time series data and to\nbuild statistical and machine learning models on top of it. Unlike common data\nanalysis frameworks, it builds up from well defined and reusable logical units\n(objects), which can be easily combined together in order to ensure a high\nlevel of consistency. Thanks to this approach, Timeseria can address by design\nseveral non-trivial issues often underestimated, such as handling data losses,\nnon-uniform sampling rates, differences between aggregated data and punctual\nobservations, time zones, daylight saving times, and more. Timeseria comes with\na comprehensive set of base data structures, common data manipulation\noperations, and extensible models for data reconstruction, forecasting and\nanomaly detection. It also integrates a powerful plotting engine capable of\nhandling even millions of data points.\n","authors":["Stefano Alberto Russo","Giuliano Taffoni","Luca Bortolussi"],"pdf_url":"https://arxiv.org/pdf/2410.09567v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.14393v1","updated":"2024-10-18T11:55:34Z","published":"2024-10-18T11:55:34Z","title":"Debug Smarter, Not Harder: AI Agents for Error Resolution in\n  Computational Notebooks","summary":"  Computational notebooks became indispensable tools for research-related\ndevelopment, offering unprecedented interactivity and flexibility in the\ndevelopment process. However, these benefits come at the cost of\nreproducibility and an increased potential for bugs. With the rise of\ncode-fluent Large Language Models empowered with agentic techniques, smart\nbug-fixing tools with a high level of autonomy have emerged. However, those\ntools are tuned for classical script programming and still struggle with\nnon-linear computational notebooks. In this paper, we present an AI agent\ndesigned specifically for error resolution in a computational notebook. We have\ndeveloped an agentic system capable of exploring a notebook environment by\ninteracting with it -- similar to how a user would -- and integrated the system\ninto the JetBrains service for collaborative data science called Datalore. We\nevaluate our approach against the pre-existing single-action solution by\ncomparing costs and conducting a user study. Users rate the error resolution\ncapabilities of the agentic system higher but experience difficulties with UI.\nWe share the results of the study and consider them valuable for further\nimproving user-agent collaboration.\n","authors":["Konstantin Grotov","Artem Borzilov","Maksim Krivobok","Timofey Bryksin","Yaroslav Zharov"],"pdf_url":"https://arxiv.org/pdf/2410.14393v1.pdf","comment":"Accepted to EMNLP 2024 System Demonstrations"},{"id":"http://arxiv.org/abs/2410.14390v1","updated":"2024-10-18T11:50:54Z","published":"2024-10-18T11:50:54Z","title":"Personalizing Low-Rank Bayesian Neural Networks Via Federated Learning","summary":"  To support real-world decision-making, it is crucial for models to be\nwell-calibrated, i.e., to assign reliable confidence estimates to their\npredictions. Uncertainty quantification is particularly important in\npersonalized federated learning (PFL), as participating clients typically have\nsmall local datasets, making it difficult to unambiguously determine optimal\nmodel parameters. Bayesian PFL (BPFL) methods can potentially enhance\ncalibration, but they often come with considerable computational and memory\nrequirements due to the need to track the variances of all the individual model\nparameters. Furthermore, different clients may exhibit heterogeneous\nuncertainty levels owing to varying local dataset sizes and distributions. To\naddress these challenges, we propose LR-BPFL, a novel BPFL method that learns a\nglobal deterministic model along with personalized low-rank Bayesian\ncorrections. To tailor the local model to each client's inherent uncertainty\nlevel, LR-BPFL incorporates an adaptive rank selection mechanism. We evaluate\nLR-BPFL across a variety of datasets, demonstrating its advantages in terms of\ncalibration, accuracy, as well as computational and memory requirements.\n","authors":["Boning Zhang","Dongzhu Liu","Osvaldo Simeone","Guanchu Wang","Dimitrios Pezaros","Guangxu Zhu"],"pdf_url":"https://arxiv.org/pdf/2410.14390v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.14389v1","updated":"2024-10-18T11:49:40Z","published":"2024-10-18T11:49:40Z","title":"SurgeryV2: Bridging the Gap Between Model Merging and Multi-Task\n  Learning with Deep Representation Surgery","summary":"  Model merging-based multitask learning (MTL) offers a promising approach for\nperforming MTL by merging multiple expert models without requiring access to\nraw training data. However, in this paper, we examine the merged model's\nrepresentation distribution and uncover a critical issue of \"representation\nbias\". This bias arises from a significant distribution gap between the\nrepresentations of the merged and expert models, leading to the suboptimal\nperformance of the merged MTL model. To address this challenge, we first\npropose a representation surgery solution called Surgery. Surgery is a\nlightweight, task-specific module that aligns the final layer representations\nof the merged model with those of the expert models, effectively alleviating\nbias and improving the merged model's performance. Despite these improvements,\na performance gap remains compared to the traditional MTL method. Further\nanalysis reveals that representation bias phenomena exist at each layer of the\nmerged model, and aligning representations only in the last layer is\ninsufficient for fully reducing systemic bias because biases introduced at each\nlayer can accumulate and interact in complex ways. To tackle this, we then\npropose a more comprehensive solution, deep representation surgery (also called\nSurgeryV2), which mitigates representation bias across all layers, and thus\nbridges the performance gap between model merging-based MTL and traditional\nMTL. Finally, we design an unsupervised optimization objective to optimize both\nthe Surgery and SurgeryV2 modules. Our experimental results show that\nincorporating these modules into state-of-the-art (SOTA) model merging schemes\nleads to significant performance gains. Notably, our SurgeryV2 scheme reaches\nalmost the same level as individual expert models or the traditional MTL model.\nThe code is available at \\url{https://github.com/EnnengYang/SurgeryV2}.\n","authors":["Enneng Yang","Li Shen","Zhenyi Wang","Guibing Guo","Xingwei Wang","Xiaocun Cao","Jie Zhang","Dacheng Tao"],"pdf_url":"https://arxiv.org/pdf/2410.14389v1.pdf","comment":"This paper is an extended version of our previous work\n  [arXiv:2402.02705] presented at ICML 2024"},{"id":"http://arxiv.org/abs/2410.06927v2","updated":"2024-10-18T11:47:40Z","published":"2024-10-09T14:21:59Z","title":"Spectral and Rhythm Features for Audio Classification with Deep\n  Convolutional Neural Networks","summary":"  Convolutional neural networks (CNNs) are widely used in computer vision. They\ncan be used not only for conventional digital image material to recognize\npatterns, but also for feature extraction from digital imagery representing\nspectral and rhythm features extracted from time-domain digital audio signals\nfor the acoustic classification of sounds. Different spectral and rhythm\nfeature representations like mel-scaled spectrograms, mel-frequency cepstral\ncoefficients (MFCCs), cyclic tempograms, short-time Fourier transform (STFT)\nchromagrams, constant-Q transform (CQT) chromagrams and chroma energy\nnormalized statistics (CENS) chromagrams are investigated in terms of the audio\nclassification performance using a deep convolutional neural network. It can be\nclearly shown that the mel-scaled spectrograms and the mel-frequency cepstral\ncoefficients (MFCCs) perform significantly better than the other spectral and\nrhythm features investigated in this research for audio classification tasks\nusing deep CNNs. The experiments were carried out with the aid of the ESC-50\ndataset with 2,000 labeled environmental audio recordings.\n","authors":["Friedrich Wolf-Monheim"],"pdf_url":"https://arxiv.org/pdf/2410.06927v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.14388v1","updated":"2024-10-18T11:44:29Z","published":"2024-10-18T11:44:29Z","title":"Unscrambling disease progression at scale: fast inference of event\n  permutations with optimal transport","summary":"  Disease progression models infer group-level temporal trajectories of change\nin patients' features as a chronic degenerative condition plays out. They\nprovide unique insight into disease biology and staging systems with\nindividual-level clinical utility. Discrete models consider disease progression\nas a latent permutation of events, where each event corresponds to a feature\nbecoming measurably abnormal. However, permutation inference using traditional\nmaximum likelihood approaches becomes prohibitive due to combinatoric\nexplosion, severely limiting model dimensionality and utility. Here we leverage\nideas from optimal transport to model disease progression as a latent\npermutation matrix of events belonging to the Birkhoff polytope, facilitating\nfast inference via optimisation of the variational lower bound. This enables a\nfactor of 1000 times faster inference than the current state of the art and,\ncorrespondingly, supports models with several orders of magnitude more features\nthan the current state of the art can consider. Experiments demonstrate the\nincrease in speed, accuracy and robustness to noise in simulation. Further\nexperiments with real-world imaging data from two separate datasets, one from\nAlzheimer's disease patients, the other age-related macular degeneration,\nshowcase, for the first time, pixel-level disease progression events in the\nbrain and eye, respectively. Our method is low compute, interpretable and\napplicable to any progressive condition and data modality, giving it broad\npotential clinical utility.\n","authors":["Peter A. Wijeratne","Daniel C. Alexander"],"pdf_url":"https://arxiv.org/pdf/2410.14388v1.pdf","comment":"Pre-print of version accepted to NeurIPS 2024"},{"id":"http://arxiv.org/abs/2407.13625v2","updated":"2024-10-18T11:43:28Z","published":"2024-07-18T15:59:37Z","title":"Distributionally and Adversarially Robust Logistic Regression via\n  Intersecting Wasserstein Balls","summary":"  Adversarially robust optimization (ARO) has become the de facto standard for\ntraining models to defend against adversarial attacks during testing. However,\ndespite their robustness, these models often suffer from severe overfitting. To\nmitigate this issue, several successful approaches have been proposed,\nincluding replacing the empirical distribution in training with: (i) a\nworst-case distribution within an ambiguity set, leading to a distributionally\nrobust (DR) counterpart of ARO; or (ii) a mixture of the empirical distribution\nwith one derived from an auxiliary dataset (e.g., synthetic, external, or\nout-of-domain). Building on the first approach, we explore the Wasserstein DR\ncounterpart of ARO for logistic regression and show it admits a tractable\nconvex optimization reformulation. Adopting the second approach, we enhance the\nDR framework by intersecting its ambiguity set with one constructed from an\nauxiliary dataset, which yields significant improvements when the Wasserstein\ndistance between the data-generating and auxiliary distributions can be\nestimated. We analyze the resulting optimization problem, develop efficient\nsolutions, and show that our method outperforms benchmark approaches on\nstandard datasets.\n","authors":["Aras Selvi","Eleonora Kreacic","Mohsen Ghassemi","Vamsi Potluru","Tucker Balch","Manuela Veloso"],"pdf_url":"https://arxiv.org/pdf/2407.13625v2.pdf","comment":"33 pages, 3 color figures, under review at a conference"},{"id":"http://arxiv.org/abs/2410.14386v1","updated":"2024-10-18T11:38:29Z","published":"2024-10-18T11:38:29Z","title":"Investigating the Capabilities of Deep Learning for Processing and\n  Interpreting One-Shot Multi-offset GPR Data: A Numerical Case Study for Lunar\n  and Martian Environments","summary":"  Ground-penetrating radar (GPR) is a mature geophysical method that has gained\nincreasing popularity in planetary science over the past decade. GPR has been\nutilised both for Lunar and Martian missions providing pivotal information\nregarding the near surface geology of Terrestrial planets. Within that context,\nnumerous processing pipelines have been suggested to address the unique\nchallenges present in planetary setups. These processing pipelines often\nrequire manual tuning resulting to ambiguous outputs open to non-unique\ninterpretations. These pitfalls combined with the large number of planetary GPR\ndata (kilometers in magnitude), highlight the necessity for automatic,\nobjective and advanced processing and interpretation schemes. The current paper\ninvestigates the potential of deep learning for interpreting and processing GPR\ndata. The one-shot multi-offset configuration is investigated via a coherent\nnumerical case study, showcasing the potential of deep learning for A)\nreconstructing the dielectric distribution of the the near surface of\nTerrestrial planets, and B) filling missing or bad-quality traces. Special care\nwas taken for the numerical data to be both realistic and challenging.\nMoreover, the generated synthetic data are properly labelled and made publicly\navailable for training future data-driven pipelines and contributing towards\ndeveloping pre-trained foundation models for GPR.\n","authors":["Iraklis Giannakis","Craig Warren","Antonios Giannopoulos","Georgios Leontidis","Yan Su","Feng Zhou","Javier Martin-Torres","Nectaria Diamanti"],"pdf_url":"https://arxiv.org/pdf/2410.14386v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2310.14659v2","updated":"2024-10-18T11:32:20Z","published":"2023-10-23T07:53:47Z","title":"Predicting Accurate Lagrangian Multipliers for Mixed Integer Linear\n  Programs","summary":"  Lagrangian relaxation stands among the most efficient approaches for solving\na Mixed Integer Linear Programs (MILP) with difficult constraints. Given any\nduals for these constraints, called Lagrangian Multipliers (LMs), it returns a\nbound on the optimal value of the MILP, and Lagrangian methods seek the LMs\ngiving the best such bound. But these methods generally rely on iterative\nalgorithms resembling gradient descent to maximize the concave piecewise linear\ndual function: the computational burden grows quickly with the number of\nrelaxed constraints. We introduce a deep learning approach that bypasses the\ndescent, effectively amortizing the local, per instance, optimization. A\nprobabilistic encoder based on a graph convolutional network computes\nhigh-dimensional representations of relaxed constraints in MILP instances. A\ndecoder then turns these representations into LMs. We train the encoder and\ndecoder jointly by directly optimizing the bound obtained from the predicted\nmultipliers. Numerical experiments show that our approach closes up to 85~\\% of\nthe gap between the continuous relaxation and the best Lagrangian bound, and\nprovides a high quality warm-start for descent based Lagrangian methods.\n","authors":["Francesco Demelas","Joseph Le Roux","Mathieu Lacroix","Axel Parmentier"],"pdf_url":"https://arxiv.org/pdf/2310.14659v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.09388v2","updated":"2024-10-18T11:23:18Z","published":"2024-10-12T06:39:31Z","title":"3-D Magnetotelluric Deep Learning Inversion Guided by Pseudo-Physical\n  Information","summary":"  Magnetotelluric deep learning (DL) inversion methods based on joint\ndata-driven and physics-driven have become a hot topic in recent years. When\nmapping observation data (or forward modeling data) to the resistivity model\nusing neural networks (NNs), incorporating the error (loss) term of the\ninversion resistivity's forward modeling response--which introduces physical\ninformation about electromagnetic field propagation--can significantly enhance\nthe inversion accuracy. To efficiently achieve data-physical dual-driven MT\ndeep learning inversion for large-scale 3-D MT data, we propose using DL\nforward modeling networks to compute this portion of the loss. This approach\nintroduces pseudo-physical information through the forward modeling of NN\nsimulation, further guiding the inversion network fitting. Specifically, we\nfirst pre-train the forward modeling networks as fixed forward modeling\noperators, then transfer and integrate them into the inversion network\ntraining, and finally optimize the inversion network by minimizing the\nmultinomial loss. Theoretical experimental results indicate that despite some\nsimulation errors in DL forward modeling, the introduced pseudo-physical\ninformation still enhances inversion accuracy and significantly mitigates the\noverfitting problem during training. Additionally, we propose a new input mode\nthat involves masking and adding noise to the data, simulating the field data\nenvironment of 3-D MT inversion, thereby making the method more flexible and\neffective for practical applications.\n","authors":["Peifan Jiang","Xuben Wang","Shuang Wang","Fei Deng","Kunpeng Wang","Bin Wang","Yuhan Yang","Islam Fadel"],"pdf_url":"https://arxiv.org/pdf/2410.09388v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.14380v1","updated":"2024-10-18T11:07:26Z","published":"2024-10-18T11:07:26Z","title":"Dual-Label LearningWith Irregularly Present Labels","summary":"  In multi-task learning, we often encounter the case when the presence of\nlabels across samples exhibits irregular patterns: samples can be fully\nlabeled, partially labeled or unlabeled. Taking drug analysis as an example,\nmultiple toxicity properties of a drug molecule may not be concurrently\navailable due to experimental limitations. It triggers a demand for a new\ntraining and inference mechanism that could accommodate irregularly present\nlabels and maximize the utility of any available label information. In this\nwork, we focus on the two-label learning task, and propose a novel training and\ninference framework, Dual-Label Learning (DLL). The DLL framework formulates\nthe problem into a dual-function system, in which the two functions should\nsimultaneously satisfy standard supervision, structural duality and\nprobabilistic duality. DLL features a dual-tower model architecture that\nexplicitly captures the information exchange between labels, aimed at\nmaximizing the utility of partially available labels in understanding label\ncorrelation. During training, label imputation for missing labels is conducted\nas part of the forward propagation process, while during inference, labels are\nregarded as unknowns of a bivariate system of equations and are solved jointly.\nTheoretical analysis guarantees the feasibility of DLL, and extensive\nexperiments are conducted to verify that by explicitly modeling label\ncorrelation and maximizing the utility of available labels, our method makes\nconsistently better predictions than baseline approaches by up to a 10% gain in\nF1-score or MAPE. Remarkably, our method provided with data at a label missing\nrate as high as 60% can achieve similar or even better results than baseline\napproaches at a label missing rate of only 10%.\n","authors":["Mingqian Li","Qiao Han","Yiteng Zhai","Ruifeng Li","Yao Yang","Hongyang Chen"],"pdf_url":"https://arxiv.org/pdf/2410.14380v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.14375v1","updated":"2024-10-18T11:06:23Z","published":"2024-10-18T11:06:23Z","title":"Fine-Tuning Pre-trained Language Models for Robust Causal Representation\n  Learning","summary":"  The fine-tuning of pre-trained language models (PLMs) has been shown to be\neffective across various domains. By using domain-specific supervised data, the\ngeneral-purpose representation derived from PLMs can be transformed into a\ndomain-specific representation. However, these methods often fail to generalize\nto out-of-domain (OOD) data due to their reliance on non-causal\nrepresentations, often described as spurious features. Existing methods either\nmake use of adjustments with strong assumptions about lack of hidden common\ncauses, or mitigate the effect of spurious features using multi-domain data. In\nthis work, we investigate how fine-tuned pre-trained language models aid\ngeneralizability from single-domain scenarios under mild assumptions, targeting\nmore general and practical real-world scenarios. We show that a robust\nrepresentation can be derived through a so-called causal front-door adjustment,\nbased on a decomposition assumption, using fine-tuned representations as a\nsource of data augmentation. Comprehensive experiments in both synthetic and\nreal-world settings demonstrate the superior generalizability of the proposed\nmethod compared to existing approaches. Our work thus sheds light on the domain\ngeneralization problem by introducing links between fine-tuning and causal\nmechanisms into representation learning.\n","authors":["Jialin Yu","Yuxiang Zhou","Yulan He","Nevin L. Zhang","Ricardo Silva"],"pdf_url":"https://arxiv.org/pdf/2410.14375v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.01129v4","updated":"2024-10-18T10:46:43Z","published":"2024-08-02T09:18:41Z","title":"A Survey of Mamba","summary":"  As one of the most representative DL techniques, Transformer architecture has\nempowered numerous advanced models, especially the large language models (LLMs)\nthat comprise billions of parameters, becoming a cornerstone in deep learning.\nDespite the impressive achievements, Transformers still face inherent\nlimitations, particularly the time-consuming inference resulting from the\nquadratic computation complexity of attention calculation. Recently, a novel\narchitecture named Mamba, drawing inspiration from classical state space models\n(SSMs), has emerged as a promising alternative for building foundation models,\ndelivering comparable modeling abilities to Transformers while preserving\nnear-linear scalability concerning sequence length. This has sparked an\nincreasing number of studies actively exploring Mamba's potential to achieve\nimpressive performance across diverse domains. Given such rapid evolution,\nthere is a critical need for a systematic review that consolidates existing\nMamba-empowered models, offering a comprehensive understanding of this emerging\nmodel architecture. In this survey, we therefore conduct an in-depth\ninvestigation of recent Mamba-associated studies, covering three main aspects:\nthe advancements of Mamba-based models, the techniques of adapting Mamba to\ndiverse data, and the applications where Mamba can excel. Specifically, we\nfirst review the foundational knowledge of various representative deep learning\nmodels and the details of Mamba-1&2 as preliminaries. Then, to showcase the\nsignificance of Mamba for AI, we comprehensively review the related studies\nfocusing on Mamba models' architecture design, data adaptability, and\napplications. Finally, we present a discussion of current limitations and\nexplore various promising research directions to provide deeper insights for\nfuture investigations.\n","authors":["Haohao Qu","Liangbo Ning","Rui An","Wenqi Fan","Tyler Derr","Hui Liu","Xin Xu","Qing Li"],"pdf_url":"https://arxiv.org/pdf/2408.01129v4.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.13458v5","updated":"2024-10-18T10:31:27Z","published":"2023-03-23T17:26:12Z","title":"Optimization Dynamics of Equivariant and Augmented Neural Networks","summary":"  We investigate the optimization of neural networks on symmetric data, and\ncompare the strategy of constraining the architecture to be equivariant to that\nof using data augmentation. Our analysis reveals that that the relative\ngeometry of the admissible and the equivariant layers, respectively, plays a\nkey role. Under natural assumptions on the data, network, loss, and group of\nsymmetries, we show that compatibility of the spaces of admissible layers and\nequivariant layers, in the sense that the corresponding orthogonal projections\ncommute, implies that the sets of equivariant stationary points are identical\nfor the two strategies. If the linear layers of the network also are given a\nunitary parametrization, the set of equivariant layers is even invariant under\nthe gradient flow for augmented models. Our analysis however also reveals that\neven in the latter situation, stationary points may be unstable for augmented\ntraining although they are stable for the manifestly equivariant models.\n","authors":["Oskar Nordenfors","Fredrik Ohlsson","Axel Flinth"],"pdf_url":"https://arxiv.org/pdf/2303.13458v5.pdf","comment":"v4: Some discussions added, along with an updated experiment section.\n  v3: Completely revised manuscript: New framework for neural nets, new main\n  result (involving compability condition), new experiments, new author. v2:\n  Revised manuscript. Mostly small edits, apart from new experiments (see\n  Appendix E)"},{"id":"http://arxiv.org/abs/2310.11244v4","updated":"2024-10-18T10:21:31Z","published":"2023-10-17T13:12:32Z","title":"Entity Matching using Large Language Models","summary":"  Entity matching is the task of deciding whether two entity descriptions refer\nto the same real-world entity. Entity matching is a central step in most data\nintegration pipelines. Many state-of-the-art entity matching methods rely on\npre-trained language models (PLMs) such as BERT or RoBERTa. Two major drawbacks\nof these models for entity matching are that (i) the models require significant\namounts of task-specific training data and (ii) the fine-tuned models are not\nrobust concerning out-of-distribution entities. This paper investigates using\ngenerative large language models (LLMs) as a less task-specific training\ndata-dependent and more robust alternative to PLM-based matchers. The study\ncovers hosted and open-source LLMs which can be run locally. We evaluate these\nmodels in a zero-shot scenario and a scenario where task-specific training data\nis available. We compare different prompt designs and the prompt sensitivity of\nthe models. We show that there is no single best prompt but that the prompt\nneeds to be tuned for each model/dataset combination. We further investigate\n(i) the selection of in-context demonstrations, (ii) the generation of matching\nrules, as well as (iii) fine-tuning LLMs using the same pool of training data.\nOur experiments show that the best LLMs require no or only a few training\nexamples to perform comparably to PLMs that were fine-tuned using thousands of\nexamples. LLM-based matchers further exhibit higher robustness to unseen\nentities. We show that GPT4 can generate structured explanations for matching\ndecisions and can automatically identify potential causes of matching errors by\nanalyzing explanations of wrong decisions. We demonstrate that the model can\ngenerate meaningful textual descriptions of the identified error classes, which\ncan help data engineers to improve entity matching pipelines.\n","authors":["Ralph Peeters","Aaron Steiner","Christian Bizer"],"pdf_url":"https://arxiv.org/pdf/2310.11244v4.pdf","comment":"Published in Proceedings of the 28th International Conference on\n  Extending Database Technology (EDBT), 25th March-28th March, 2025, ISBN\n  978-3-89318-098-1 on OpenProceedings.org"},{"id":"http://arxiv.org/abs/2203.08975v2","updated":"2024-10-18T10:14:58Z","published":"2022-03-16T22:39:46Z","title":"A Survey of Multi-Agent Deep Reinforcement Learning with Communication","summary":"  Communication is an effective mechanism for coordinating the behaviors of\nmultiple agents, broadening their views of the environment, and to support\ntheir collaborations. In the field of multi-agent deep reinforcement learning\n(MADRL), agents can improve the overall learning performance and achieve their\nobjectives by communication. Agents can communicate various types of messages,\neither to all agents or to specific agent groups, or conditioned on specific\nconstraints. With the growing body of research work in MADRL with communication\n(Comm-MADRL), there is a lack of a systematic and structural approach to\ndistinguish and classify existing Comm-MADRL approaches. In this paper, we\nsurvey recent works in the Comm-MADRL field and consider various aspects of\ncommunication that can play a role in designing and developing multi-agent\nreinforcement learning systems. With these aspects in mind, we propose 9\ndimensions along which Comm-MADRL approaches can be analyzed, developed, and\ncompared. By projecting existing works into the multi-dimensional space, we\ndiscover interesting trends. We also propose some novel directions for\ndesigning future Comm-MADRL systems through exploring possible combinations of\nthe dimensions.\n","authors":["Changxi Zhu","Mehdi Dastani","Shihan Wang"],"pdf_url":"https://arxiv.org/pdf/2203.08975v2.pdf","comment":"34 pages, 5 figures, 13 tables; published on Autonomous Agents and\n  Multi-Agent Systems"},{"id":"http://arxiv.org/abs/2410.14347v1","updated":"2024-10-18T09:57:59Z","published":"2024-10-18T09:57:59Z","title":"A Scientific Machine Learning Approach for Predicting and Forecasting\n  Battery Degradation in Electric Vehicles","summary":"  Carbon emissions are rising at an alarming rate, posing a significant threat\nto global efforts to mitigate climate change. Electric vehicles have emerged as\na promising solution, but their reliance on lithium-ion batteries introduces\nthe critical challenge of battery degradation. Accurate prediction and\nforecasting of battery degradation over both short and long time spans are\nessential for optimizing performance, extending battery life, and ensuring\neffective long-term energy management. This directly influences the\nreliability, safety, and sustainability of EVs, supporting their widespread\nadoption and aligning with key UN SDGs. In this paper, we present a novel\napproach to the prediction and long-term forecasting of battery degradation\nusing Scientific Machine Learning framework which integrates domain knowledge\nwith neural networks, offering more interpretable and scientifically grounded\nsolutions for both predicting short-term battery health and forecasting\ndegradation over extended periods. This hybrid approach captures both known and\nunknown degradation dynamics, improving predictive accuracy while reducing data\nrequirements. We incorporate ground-truth data to inform our models, ensuring\nthat both the predictions and forecasts reflect practical conditions. The model\nachieved MSE of 9.90 with the UDE and 11.55 with the NeuralODE, in experimental\ndata, a loss of 1.6986 with the UDE, and a MSE of 2.49 in the NeuralODE,\ndemonstrating the enhanced precision of our approach. This integration of\ndata-driven insights with SciML's strengths in interpretability and scalability\nallows for robust battery management. By enhancing battery longevity and\nminimizing waste, our approach contributes to the sustainability of energy\nsystems and accelerates the global transition toward cleaner, more responsible\nenergy solutions, aligning with the UN's SDG agenda.\n","authors":["Sharv Murgai","Hrishikesh Bhagwat","Raj Abhijit Dandekar","Rajat Dandekar","Sreedath Panat"],"pdf_url":"https://arxiv.org/pdf/2410.14347v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.14334v1","updated":"2024-10-18T09:44:35Z","published":"2024-10-18T09:44:35Z","title":"Evaluating the evaluators: Towards human-aligned metrics for missing\n  markers reconstruction","summary":"  Animation data is often obtained through optical motion capture systems,\nwhich utilize a multitude of cameras to establish the position of optical\nmarkers. However, system errors or occlusions can result in missing markers,\nthe manual cleaning of which can be time-consuming. This has sparked interest\nin machine learning-based solutions for missing marker reconstruction in the\nacademic community. Most academic papers utilize a simplistic mean square error\nas the main metric. In this paper, we show that this metric does not correlate\nwith subjective perception of the fill quality. We introduce and evaluate a set\nof better-correlated metrics that can drive progress in the field.\n","authors":["Taras Kucherenko","Derek Peristy","Judith Bütepage"],"pdf_url":"https://arxiv.org/pdf/2410.14334v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.11677v2","updated":"2024-10-18T09:41:53Z","published":"2024-10-15T15:14:22Z","title":"Understanding Likelihood Over-optimisation in Direct Alignment\n  Algorithms","summary":"  Direct Alignment Algorithms (DAAs), such as Direct Preference Optimisation\n(DPO) and Identity Preference Optimisation (IPO), have emerged as alternatives\nto online Reinforcement Learning from Human Feedback (RLHF) algorithms such as\nProximal Policy Optimisation (PPO) for aligning language models to human\npreferences, without the need for explicit reward modelling. These methods\ngenerally aim to increase the likelihood of generating better (preferred)\ncompletions while discouraging worse (non-preferred) ones, while staying close\nto the original model's behaviour. In this work, we explore the relationship\nbetween completion likelihood and model performance in state-of-the-art DAAs,\nand identify a critical issue of likelihood over-optimisation. Contrary to\nexpectations, we find that higher likelihood of better completions and larger\nmargins between better and worse completion likelihoods do not necessarily lead\nto better performance, and may even degrade it. Our analysis reveals that while\nhigher likelihood correlates with better memorisation of factual knowledge\npatterns, a slightly lower completion likelihood tends to improve output\ndiversity, thus leading to better generalisation to unseen scenarios. Moreover,\nwe identify two key indicators that signal when over-optimised output diversity\nbegins to harm performance: Decreasing Entropy over Top-k Tokens and\nDiminishing Top-k Probability Mass. Our experimental results validate that\nthese indicators are reliable signs of declining performance under different\nregularisations, helping prevent over-optimisation and improve alignment with\nhuman preferences.\n","authors":["Zhengyan Shi","Sander Land","Acyr Locatelli","Matthieu Geist","Max Bartolo"],"pdf_url":"https://arxiv.org/pdf/2410.11677v2.pdf","comment":"Preprint Version"},{"id":"http://arxiv.org/abs/2410.14326v1","updated":"2024-10-18T09:37:38Z","published":"2024-10-18T09:37:38Z","title":"Fast proxy centers for Jeffreys centroids: The Jeffreys-Fisher-Rao and\n  the inductive Gauss-Bregman centers","summary":"  The symmetric Kullback-Leibler centroid also called the Jeffreys centroid of\na set of mutually absolutely continuous probability distributions on a measure\nspace provides a notion of centrality which has proven useful in many tasks\nincluding information retrieval, information fusion, and clustering in image,\nvideo and sound processing. However, the Jeffreys centroid is not available in\nclosed-form for sets of categorical or normal distributions, two widely used\nstatistical models, and thus need to be approximated numerically in practice.\nIn this paper, we first propose the new Jeffreys-Fisher-Rao center defined as\nthe Fisher-Rao midpoint of the sided Kullback-Leibler centroids as a plug-in\nreplacement of the Jeffreys centroid. This Jeffreys-Fisher-Rao center admits a\ngeneric formula for uni-parameter exponential family distributions, and\nclosed-form formula for categorical and normal distributions, matches exactly\nthe Jeffreys centroid for same-mean normal distributions, and is experimentally\nobserved in practice to be close to the Jeffreys centroid. Second, we define a\nnew type of inductive centers generalizing the principle of Gauss\narithmetic-geometric double sequence mean for pairs of densities of any given\nexponential family. This center is shown experimentally to approximate very\nwell the Jeffreys centroid and is suggested to use when the Jeffreys-Fisher-Rao\ncenter is not available in closed form. Moreover, this Gauss-Bregman inductive\ncenter always converges and matches the Jeffreys centroid for sets of same-mean\nnormal distributions. We report on our experiments demonstrating the use of the\nJeffreys-Fisher-Rao and Gauss-Bregman centers instead of the Jeffreys centroid.\nFinally, we conclude this work by reinterpreting these fast proxy centers of\nJeffreys centroids under the lens of dually flat spaces in information\ngeometry.\n","authors":["Frank Nielsen"],"pdf_url":"https://arxiv.org/pdf/2410.14326v1.pdf","comment":"35 pages, 10 figures"},{"id":"http://arxiv.org/abs/2410.14325v1","updated":"2024-10-18T09:37:05Z","published":"2024-10-18T09:37:05Z","title":"Debiasing Mini-Batch Quadratics for Applications in Deep Learning","summary":"  Quadratic approximations form a fundamental building block of machine\nlearning methods. E.g., second-order optimizers try to find the Newton step\ninto the minimum of a local quadratic proxy to the objective function; and the\nsecond-order approximation of a network's loss function can be used to quantify\nthe uncertainty of its outputs via the Laplace approximation. When computations\non the entire training set are intractable - typical for deep learning - the\nrelevant quantities are computed on mini-batches. This, however, distorts and\nbiases the shape of the associated stochastic quadratic approximations in an\nintricate way with detrimental effects on applications. In this paper, we (i)\nshow that this bias introduces a systematic error, (ii) provide a theoretical\nexplanation for it, (iii) explain its relevance for second-order optimization\nand uncertainty quantification via the Laplace approximation in deep learning,\nand (iv) develop and evaluate debiasing strategies.\n","authors":["Lukas Tatzel","Bálint Mucsányi","Osane Hackel","Philipp Hennig"],"pdf_url":"https://arxiv.org/pdf/2410.14325v1.pdf","comment":"Main text (including references): 13 pages, 6 figures; Supplements:\n  25 pages, 13 figures"},{"id":"http://arxiv.org/abs/2410.14315v1","updated":"2024-10-18T09:21:10Z","published":"2024-10-18T09:21:10Z","title":"Optimizing importance weighting in the presence of sub-population shifts","summary":"  A distribution shift between the training and test data can severely harm\nperformance of machine learning models. Importance weighting addresses this\nissue by assigning different weights to data points during training. We argue\nthat existing heuristics for determining the weights are suboptimal, as they\nneglect the increase of the variance of the estimated model due to the finite\nsample size of the training data. We interpret the optimal weights in terms of\na bias-variance trade-off, and propose a bi-level optimization procedure in\nwhich the weights and model parameters are optimized simultaneously. We apply\nthis optimization to existing importance weighting techniques for last-layer\nretraining of deep neural networks in the presence of sub-population shifts and\nshow empirically that optimizing weights significantly improves generalization\nperformance.\n","authors":["Floris Holstege","Bram Wouters","Noud van Giersbergen","Cees Diks"],"pdf_url":"https://arxiv.org/pdf/2410.14315v1.pdf","comment":"Preprint. Currently under review"},{"id":"http://arxiv.org/abs/2405.18921v2","updated":"2024-10-18T09:05:18Z","published":"2024-05-29T09:24:25Z","title":"GLANCE: Global Actions in a Nutshell for Counterfactual Explainability","summary":"  The widespread deployment of machine learning systems in critical real-world\ndecision-making applications has highlighted the urgent need for counterfactual\nexplainability methods that operate effectively. Global counterfactual\nexplanations, expressed as actions to offer recourse, aim to provide succinct\nexplanations and insights applicable to large population subgroups.\nEffectiveness is measured by the fraction of the population that is provided\nrecourse, ensuring that the actions benefit as many individuals as possible.\nKeeping the cost of actions low ensures the proposed recourse actions remain\npractical and actionable. Limiting the number of actions that provide global\ncounterfactuals is essential to maximize interpretability. The primary\nchallenge, therefore, is balancing these trade-offs, i.e., maximizing\neffectiveness, minimizing cost, while maintaining a small number of actions. We\nintroduce GLANCE, a versatile and adaptive framework, comprising two\nalgorithms, that allows the careful balancing of the trade-offs among the three\nkey objectives, with the size objective functioning as a tunable parameter to\nkeep the actions few and easy to interpret. C-GLANCE employs a clustering\napproach that considers both the feature space and the space of counterfactual\nactions, thereby accounting for the distribution of points in a way that aligns\nwith the structure of the model. T-GLANCE provides additional features to\nenhance flexibility. It employs a tree-based approach, that allows users to\nspecify split features, to build a decision tree with a single counterfactual\naction at each node that can be used as a subgroup policy. Our extensive\nexperimental evaluation demonstrates that our method consistently shows greater\nrobustness and performance compared to existing methods across various datasets\nand models.\n","authors":["Loukas Kavouras","Eleni Psaroudaki","Konstantinos Tsopelas","Dimitrios Rontogiannis","Nikolaos Theologitis","Dimitris Sacharidis","Giorgos Giannopoulos","Dimitrios Tomaras","Kleopatra Markou","Dimitrios Gunopulos","Dimitris Fotakis","Ioannis Emiris"],"pdf_url":"https://arxiv.org/pdf/2405.18921v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2407.12013v2","updated":"2024-10-18T08:57:30Z","published":"2024-06-26T12:33:34Z","title":"Dating ancient manuscripts using radiocarbon and AI-based writing style\n  analysis","summary":"  Determining the chronology of ancient handwritten manuscripts is essential\nfor reconstructing the evolution of ideas. For the Dead Sea Scrolls, this is\nparticularly important. However, there is an almost complete lack of\ndate-bearing manuscripts evenly distributed across the timeline and written in\nsimilar scripts available for palaeographic comparison. Here, we present Enoch,\na state-of-the-art AI-based date-prediction model, trained on the basis of new\nradiocarbon-dated samples of the scrolls. Enoch uses established\nhandwriting-style descriptors and applies Bayesian ridge regression. The\nchallenge of this study is that the number of radiocarbon-dated manuscripts is\nsmall, while current machine learning requires an abundance of training data.\nWe show that by using combined angular and allographic writing style feature\nvectors and applying Bayesian ridge regression, Enoch could predict the\nradiocarbon-based dates from style, supported by leave-one-out validation, with\nvaried MAEs of 27.9 to 30.7 years relative to the radiocarbon dating. Enoch was\nthen used to estimate the dates of 135 unseen manuscripts, revealing that 79\nper cent of the samples were considered 'realistic' upon palaeographic post-hoc\nevaluation. We present a new chronology of the scrolls. The radiocarbon ranges\nand Enoch's style-based predictions are often older than the traditionally\nassumed palaeographic estimates. In the range of 300-50 BCE, Enoch's date\nprediction provides an improved granularity. The study is in line with current\ndevelopments in multimodal machine-learning techniques, and the methods can be\nused for date prediction in other partially-dated manuscript collections. This\nresearch shows how Enoch's quantitative, probability-based approach can be a\ntool for palaeographers and historians, re-dating ancient Jewish key texts and\ncontributing to current debates on Jewish and Christian origins.\n","authors":["Mladen Popović","Maruf A. Dhali","Lambert Schomaker","Johannes van der Plicht","Kaare Lund Rasmussen","Jacopo La Nasa","Ilaria Degano","Maria Perla Colombini","Eibert Tigchelaar"],"pdf_url":"https://arxiv.org/pdf/2407.12013v2.pdf","comment":"16 pages of main article, 103 pages of supplementary materials; the\n  first version of this article is originally prepared in July 2023 after the\n  completion of all the experiments"},{"id":"http://arxiv.org/abs/2306.05172v3","updated":"2024-10-18T08:44:31Z","published":"2023-06-08T13:11:20Z","title":"FLEdge: Benchmarking Federated Machine Learning Applications in Edge\n  Computing Systems","summary":"  Federated Learning (FL) has become a viable technique for realizing\nprivacy-enhancing distributed deep learning on the network edge. Heterogeneous\nhardware, unreliable client devices, and energy constraints often characterize\nedge computing systems. In this paper, we propose FLEdge, which complements\nexisting FL benchmarks by enabling a systematic evaluation of client\ncapabilities. We focus on computational and communication bottlenecks, client\nbehavior, and data security implications. Our experiments with models varying\nfrom 14K to 80M trainable parameters are carried out on dedicated hardware with\nemulated network characteristics and client behavior. We find that\nstate-of-the-art embedded hardware has significant memory bottlenecks, leading\nto 4x longer processing times than on modern data center GPUs.\n","authors":["Herbert Woisetschläger","Alexander Isenko","Ruben Mayer","Shiqiang Wang","Hans-Arno Jacobsen"],"pdf_url":"https://arxiv.org/pdf/2306.05172v3.pdf","comment":"Paper accepted for publication at the ACM/IFIP Middleware Conference\n  2024. Please cite the published version via\n  https://doi.org/10.1145/3652892.3700751"},{"id":"http://arxiv.org/abs/2410.14281v1","updated":"2024-10-18T08:38:12Z","published":"2024-10-18T08:38:12Z","title":"PTR: A Pre-trained Language Model for Trajectory Recovery","summary":"  Spatiotemporal trajectory data is vital for web-of-things services and is\nextensively collected and analyzed by web-based hardware and platforms.\nHowever, issues such as service interruptions and network instability often\nlead to sparsely recorded trajectories, resulting in a loss of detailed\nmovement data. As a result, recovering these trajectories to restore missing\ninformation becomes essential. Despite progress, several challenges remain\nunresolved. First, the lack of large-scale dense trajectory data hampers the\nperformance of existing deep learning methods, which rely heavily on abundant\ndata for supervised training. Second, current methods struggle to generalize\nacross sparse trajectories with varying sampling intervals, necessitating\nseparate re-training for each interval and increasing computational costs.\nThird, external factors crucial for the recovery of missing points are not\nfully incorporated.\n  To address these challenges, we propose a framework called PTR. This\nframework mitigates the issue of limited dense trajectory data by leveraging\nthe capabilities of pre-trained language models (PLMs). PTR incorporates an\nexplicit trajectory prompt and is trained on datasets with multiple sampling\nintervals, enabling it to generalize effectively across different intervals in\nsparse trajectories. To capture external factors, we introduce an implicit\ntrajectory prompt that models road conditions, providing richer information for\nrecovering missing points. Additionally, we present a trajectory embedder that\nencodes trajectory points and transforms the embeddings of both observed and\nmissing points into a format comprehensible to PLMs. Experimental results on\ntwo public trajectory datasets with three sampling intervals demonstrate the\nefficacy and scalability of PTR.\n","authors":["Tonglong Wei","Yan Lin","Youfang Lin","Shengnan Guo","Jilin Hu","Gao Cong","Huaiyu Wan"],"pdf_url":"https://arxiv.org/pdf/2410.14281v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.13196v2","updated":"2024-10-18T08:33:19Z","published":"2024-10-17T03:56:12Z","title":"Context-Enhanced Multi-View Trajectory Representation Learning: Bridging\n  the Gap through Self-Supervised Models","summary":"  Modeling trajectory data with generic-purpose dense representations has\nbecome a prevalent paradigm for various downstream applications, such as\ntrajectory classification, travel time estimation and similarity computation.\nHowever, existing methods typically rely on trajectories from a single spatial\nview, limiting their ability to capture the rich contextual information that is\ncrucial for gaining deeper insights into movement patterns across different\ngeospatial contexts. To this end, we propose MVTraj, a novel multi-view\nmodeling method for trajectory representation learning. MVTraj integrates\ndiverse contextual knowledge, from GPS to road network and points-of-interest\nto provide a more comprehensive understanding of trajectory data. To align the\nlearning process across multiple views, we utilize GPS trajectories as a bridge\nand employ self-supervised pretext tasks to capture and distinguish movement\npatterns across different spatial views. Following this, we treat trajectories\nfrom different views as distinct modalities and apply a hierarchical\ncross-modal interaction module to fuse the representations, thereby enriching\nthe knowledge derived from multiple sources. Extensive experiments on\nreal-world datasets demonstrate that MVTraj significantly outperforms existing\nbaselines in tasks associated with various spatial views, validating its\neffectiveness and practical utility in spatio-temporal modeling.\n","authors":["Tangwen Qian","Junhe Li","Yile Chen","Gao Cong","Tao Sun","Fei Wang","Yongjun Xu"],"pdf_url":"https://arxiv.org/pdf/2410.13196v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.14270v1","updated":"2024-10-18T08:25:28Z","published":"2024-10-18T08:25:28Z","title":"Stochastic Quasi-Newton Optimization in Large Dimensions Including Deep\n  Network Training","summary":"  Our proposal is on a new stochastic optimizer for non-convex and possibly\nnon-smooth objective functions typically defined over large dimensional design\nspaces. Towards this, we have tried to bridge noise-assisted global search and\nfaster local convergence, the latter being the characteristic feature of a\nNewton-like search. Our specific scheme -- acronymed FINDER (Filtering Informed\nNewton-like and Derivative-free Evolutionary Recursion), exploits the nonlinear\nstochastic filtering equations to arrive at a derivative-free update that has\nresemblance with the Newton search employing the inverse Hessian of the\nobjective function. Following certain simplifications of the update to enable a\nlinear scaling with dimension and a few other enhancements, we apply FINDER to\na range of problems, starting with some IEEE benchmark objective functions to a\ncouple of archetypal data-driven problems in deep networks to certain cases of\nphysics-informed deep networks. The performance of the new method vis-\\'a-vis\nthe well-known Adam and a few others bears evidence to its promise and\npotentialities for large dimensional optimization problems of practical\ninterest.\n","authors":["Uttam Suman","Mariya Mamajiwala","Mukul Saxena","Ankit Tyagi","Debasish Roy"],"pdf_url":"https://arxiv.org/pdf/2410.14270v1.pdf","comment":"19 pages, 12 figures, 3 tables"},{"id":"http://arxiv.org/abs/2410.14269v1","updated":"2024-10-18T08:24:07Z","published":"2024-10-18T08:24:07Z","title":"On time series clustering with k-means","summary":"  There is a long history of research into time series clustering using\ndistance-based partitional clustering. Many of the most popular algorithms\nadapt k-means (also known as Lloyd's algorithm) to exploit time dependencies in\nthe data by specifying a time series distance function. However, these\nalgorithms are often presented with k-means configured in various ways,\naltering key parameters such as the initialisation strategy. This variability\nmakes it difficult to compare studies because k-means is known to be highly\nsensitive to its configuration. To address this, we propose a standard\nLloyd's-based model for TSCL that adopts an end-to-end approach, incorporating\na specialised distance function not only in the assignment step but also in the\ninitialisation and stopping criteria. By doing so, we create a unified\nstructure for comparing seven popular Lloyd's-based TSCL algorithms. This\ncommon framework enables us to more easily attribute differences in clustering\nperformance to the distance function itself, rather than variations in the\nk-means configuration.\n","authors":["Christopher Holder","Anthony Bagnall","Jason Lines"],"pdf_url":"https://arxiv.org/pdf/2410.14269v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.14268v1","updated":"2024-10-18T08:22:07Z","published":"2024-10-18T08:22:07Z","title":"MoDification: Mixture of Depths Made Easy","summary":"  Long-context efficiency has recently become a trending topic in serving large\nlanguage models (LLMs). And mixture of depths (MoD) is proposed as a perfect\nfit to bring down both latency and memory. In this paper, however, we discover\nthat MoD can barely transform existing LLMs without costly training over an\nextensive number of tokens. To enable the transformations from any LLMs to MoD\nones, we showcase top-k operator in MoD should be promoted to threshold-p\noperator, and refinement to architecture and data should also be crafted along.\nAll these designs form our method termed MoDification. Through a comprehensive\nset of experiments covering model scales from 3B to 70B, we exhibit\nMoDification strikes an excellent balance between efficiency and effectiveness.\nMoDification can achieve up to ~1.2x speedup in latency and ~1.8x reduction in\nmemory compared to original LLMs especially in long-context applications.\n","authors":["Chen Zhang","Meizhi Zhong","Qimeng Wang","Xuantao Lu","Zheyu Ye","Chengqiang Lu","Yan Gao","Yao Hu","Kehai Chen","Min Zhang","Dawei Song"],"pdf_url":"https://arxiv.org/pdf/2410.14268v1.pdf","comment":"12 pages, 9 figures, 5 tables, work in progress"},{"id":"http://arxiv.org/abs/2403.13784v6","updated":"2024-10-18T08:20:22Z","published":"2024-03-20T17:47:08Z","title":"The Model Openness Framework: Promoting Completeness and Openness for\n  Reproducibility, Transparency, and Usability in Artificial Intelligence","summary":"  Generative artificial intelligence (AI) offers numerous opportunities for\nresearch and innovation, but its commercialization has raised concerns about\nthe transparency and safety of frontier AI models. Most models lack the\nnecessary components for full understanding, auditing, and reproducibility, and\nsome model producers use restrictive licenses whilst claiming that their models\nare \"open source\". To address these concerns, we introduce the Model Openness\nFramework (MOF), a three-tiered ranked classification system that rates machine\nlearning models based on their completeness and openness, following open\nscience principles. For each MOF class, we specify code, data, and\ndocumentation components of the model development lifecycle that must be\nreleased and under which open licenses. In addition, the Model Openness Tool\n(MOT) provides a user-friendly reference implementation to evaluate the\nopenness and completeness of models against the MOF classification system.\nTogether, the MOF and MOT provide timely practical guidance for (i) model\nproducers to enhance the openness and completeness of their publicly-released\nmodels, and (ii) model consumers to identify open models and their constituent\ncomponents that can be permissively used, studied, modified, and redistributed.\nThrough the MOF, we seek to establish completeness and openness as core tenets\nof responsible AI research and development, and to promote best practices in\nthe burgeoning open AI ecosystem.\n","authors":["Matt White","Ibrahim Haddad","Cailean Osborne","Xiao-Yang Yanglet Liu","Ahmed Abdelmonsef","Sachin Varghese","Arnaud Le Hors"],"pdf_url":"https://arxiv.org/pdf/2403.13784v6.pdf","comment":"28 pages, 4 figures, 2 tables"},{"id":"http://arxiv.org/abs/2406.00125v3","updated":"2024-10-18T08:18:36Z","published":"2024-05-31T18:32:46Z","title":"TotalVibeSegmentator: Full Body MRI Segmentation for the NAKO and UK\n  Biobank","summary":"  Objectives: To present a publicly available torso segmentation network for\nlarge epidemiology datasets on volumetric interpolated breath-hold examination\n(VIBE) images. Materials & Methods: We extracted preliminary segmentations from\nTotalSegmentator, spine, and body composition networks for VIBE images, then\nimproved them iteratively and retrained a nnUNet network. Using subsets of NAKO\n(85 subjects) and UK Biobank (16 subjects), we evaluated with Dice-score on a\nholdout set (12 subjects) and existing organ segmentation approach (1000\nsubjects), generating 71 semantic segmentation types for VIBE images. We\nprovide an additional network for the vertebra segments 22 individual vertebra\ntypes. Results: We achieved an average Dice score of 0.89 +- 0.07 overall 71\nsegmentation labels. We scored > 0.90 Dice-score on the abdominal organs except\nfor the pancreas with a Dice of 0.70. Conclusion: Our work offers a detailed\nand refined publicly available full torso segmentation on VIBE images.\n","authors":["Robert Graf","Paul-Sören Platzek","Evamaria Olga Riedel","Constanze Ramschütz","Sophie Starck","Hendrik Kristian Möller","Matan Atad","Henry Völzke","Robin Bülow","Carsten Oliver Schmidt","Julia Rüdebusch","Matthias Jung","Marco Reisert","Jakob Weiss","Maximilian Löffler","Fabian Bamberg","Bene Wiestler","Johannes C. Paetzold","Daniel Rueckert","Jan Stefan Kirschke"],"pdf_url":"https://arxiv.org/pdf/2406.00125v3.pdf","comment":"https://github.com/robert-graf/TotalVibeSegmentator"},{"id":"http://arxiv.org/abs/2402.16346v3","updated":"2024-10-18T08:09:14Z","published":"2024-02-26T07:00:24Z","title":"Boosting Graph Pooling with Persistent Homology","summary":"  Recently, there has been an emerging trend to integrate persistent homology\n(PH) into graph neural networks (GNNs) to enrich expressive power. However,\nnaively plugging PH features into GNN layers always results in marginal\nimprovement with low interpretability. In this paper, we investigate a novel\nmechanism for injecting global topological invariance into pooling layers using\nPH, motivated by the observation that filtration operation in PH naturally\naligns graph pooling in a cut-off manner. In this fashion, message passing in\nthe coarsened graph acts along persistent pooled topology, leading to improved\nperformance. Experimentally, we apply our mechanism to a collection of graph\npooling methods and observe consistent and substantial performance gain over\nseveral popular datasets, demonstrating its wide applicability and flexibility.\n","authors":["Chaolong Ying","Xinjian Zhao","Tianshu Yu"],"pdf_url":"https://arxiv.org/pdf/2402.16346v3.pdf","comment":"Published at NeurIPS 2024"},{"id":"http://arxiv.org/abs/2410.14257v1","updated":"2024-10-18T08:05:37Z","published":"2024-10-18T08:05:37Z","title":"Revisiting SLO and Goodput Metrics in LLM Serving","summary":"  Large language models (LLMs) have achieved remarkable performance and are\nwidely deployed in various applications, while the serving of LLM inference has\nraised concerns about user experience and serving throughput. Accordingly,\nservice level objectives (SLOs) and goodput-the number of requests that meet\nSLOs per second-are introduced to evaluate the performance of LLM serving.\nHowever, existing metrics fail to capture the nature of user experience. We\nobserve two ridiculous phenomena in existing metrics: 1) delaying token\ndelivery can smooth the tail time between tokens (tail TBT) of a request and 2)\ndropping the request that fails to meet the SLOs midway can improve goodput.\n  In this paper, we revisit SLO and goodput metrics in LLM serving and propose\na unified metric framework smooth goodput including SLOs and goodput to reflect\nthe nature of user experience in LLM serving. The framework can adapt to\nspecific goals of different tasks by setting parameters. We re-evaluate the\nperformance of different LLM serving systems under multiple workloads based on\nthis unified framework and provide possible directions for future optimization\nof existing strategies. We hope that this framework can provide a unified\nstandard for evaluating LLM serving and foster researches in the field of LLM\nserving optimization to move in a cohesive direction.\n","authors":["Zhibin Wang","Shipeng Li","Yuhang Zhou","Xue Li","Rong Gu","Nguyen Cam-Tu","Chen Tian","Sheng Zhong"],"pdf_url":"https://arxiv.org/pdf/2410.14257v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2405.20988v3","updated":"2024-10-18T08:05:18Z","published":"2024-05-31T16:34:11Z","title":"Communication-Efficient Distributed Deep Learning via Federated Dynamic\n  Averaging","summary":"  Driven by the ever-growing volume and decentralized nature of data, coupled\nwith the need to harness this data and generate knowledge from it, has led to\nthe extensive use of distributed deep learning (DDL) techniques for training.\nThese techniques rely on local training that is performed at the distributed\nnodes based on locally collected data, followed by a periodic synchronization\nprocess that combines these models to create a global model. However, frequent\nsynchronization of DL models, encompassing millions to many billions of\nparameters, creates a communication bottleneck, severely hindering scalability.\nWorse yet, DDL algorithms typically waste valuable bandwidth, and make\nthemselves less practical in bandwidth-constrained federated settings, by\nrelying on overly simplistic, periodic, and rigid synchronization schedules.\nThese drawbacks also have a direct impact on the time required for the training\nprocess, necessitating excessive time for data communication. To address these\nshortcomings, we propose Federated Dynamic Averaging (FDA), a\ncommunication-efficient DDL strategy that dynamically triggers synchronization\nbased on the value of the model variance. In essence, the costly\nsynchronization step is triggered only if the local models, which are\ninitialized from a common global model after each synchronization, have\nsignificantly diverged. This decision is facilitated by the communication of a\nsmall local state from each distributed node/worker. Through extensive\nexperiments across a wide range of learning tasks we demonstrate that FDA\nreduces communication cost by orders of magnitude, compared to both traditional\nand cutting-edge communication-efficient algorithms. Additionally, we show that\nFDA maintains robust performance across diverse data heterogeneity settings.\n","authors":["Michail Theologitis","Georgios Frangias","Georgios Anestis","Vasilis Samoladas","Antonios Deligiannakis"],"pdf_url":"https://arxiv.org/pdf/2405.20988v3.pdf","comment":"Accepted as research paper at EDBT 2025"},{"id":"http://arxiv.org/abs/2311.16984v4","updated":"2024-10-18T08:04:36Z","published":"2023-11-28T17:35:38Z","title":"FedECA: A Federated External Control Arm Method for Causal Inference\n  with Time-To-Event Data in Distributed Settings","summary":"  External control arms (ECA) can inform the early clinical development of\nexperimental drugs and provide efficacy evidence for regulatory approval.\nHowever, the main challenge in implementing ECA lies in accessing real-world or\nhistorical clinical trials data. Indeed, regulations protecting patients'\nrights by strictly controlling data processing make pooling data from multiple\nsources in a central server often difficult. To address these limitations, we\ndevelop a new method, 'FedECA' that leverages federated learning (FL) to enable\ninverse probability of treatment weighting (IPTW) for time-to-event outcomes on\nseparate cohorts without needing to pool data. To showcase the potential of\nFedECA, we apply it in different settings of increasing complexity culminating\nwith a real-world use-case in which FedECA provides evidence for a differential\neffect between two drugs that would have otherwise gone unnoticed. By sharing\nour code, we hope FedECA will foster the creation of federated research\nnetworks and thus accelerate drug development.\n","authors":["Jean Ogier du Terrail","Quentin Klopfenstein","Honghao Li","Imke Mayer","Nicolas Loiseau","Mohammad Hallal","Michael Debouver","Thibault Camalon","Thibault Fouqueray","Jorge Arellano Castro","Zahia Yanes","Laetitia Dahan","Julien Taïeb","Pierre Laurent-Puig","Jean-Baptiste Bachet","Shulin Zhao","Remy Nicolle","Jérome Cros","Daniel Gonzalez","Robert Carreras-Torres","Adelaida Garcia Velasco","Kawther Abdilleh","Sudheer Doss","Félix Balazard","Mathieu Andreux"],"pdf_url":"https://arxiv.org/pdf/2311.16984v4.pdf","comment":"code available at: https://github.com/owkin/fedeca, bug in SMD\n  computation present in v1 and v2 has been fixed, many experiments on real\n  data have been added + fix in YODA experiments using imputed data instead of\n  raw data as well as typos and affiliations fix"},{"id":"http://arxiv.org/abs/2410.14254v1","updated":"2024-10-18T08:04:31Z","published":"2024-10-18T08:04:31Z","title":"RAZOR: Refining Accuracy by Zeroing Out Redundancies","summary":"  In many application domains, the proliferation of sensors and devices is\ngenerating vast volumes of data, imposing significant pressure on existing data\nanalysis and data mining techniques. Nevertheless, an increase in data volume\ndoes not inherently imply an increase in informational content, as a\nsubstantial portion may be redundant or represent noise. This challenge is\nparticularly evident in the deep learning domain, where the utility of\nadditional data is contingent on its informativeness. In the absence of such,\nlarger datasets merely exacerbate the computational cost and complexity of the\nlearning process. To address these challenges, we propose RAZOR, a novel\ninstance selection technique designed to extract a significantly smaller yet\nsufficiently informative subset from a larger set of instances without\ncompromising the learning process. RAZOR has been specifically engineered to be\nrobust, efficient, and scalable, making it suitable for large-scale datasets.\nUnlike many techniques in the literature, RAZOR is capable of operating in both\nsupervised and unsupervised settings. Experimental results demonstrate that\nRAZOR outperforms recent state-of-the-art techniques in terms of both\neffectiveness and efficiency.\n","authors":["Daniel Riccio","Genoveffa Tortora","Mara Sangiovanni"],"pdf_url":"https://arxiv.org/pdf/2410.14254v1.pdf","comment":"17 pages, 3 figures"},{"id":"http://arxiv.org/abs/2306.08670v5","updated":"2024-10-18T08:00:31Z","published":"2023-06-14T17:59:15Z","title":"Simple Opinion Dynamics for No-Regret Learning","summary":"  We study a cooperative multi-agent bandit setting in the distributed GOSSIP\nmodel: in every round, each of $n$ agents chooses an action from a common set,\nobserves the action's corresponding reward, and subsequently exchanges\ninformation with a single randomly chosen neighbor, which may inform its choice\nin the next round. We introduce and analyze families of memoryless and\ntime-independent protocols for this setting, inspired by opinion dynamics that\nare well-studied for other algorithmic tasks in the GOSSIP model. For\nstationary reward settings, we prove for the first time that these simple\nprotocols exhibit best-of-both-worlds behavior, simultaneously obtaining\nconstant cumulative regret scaling like $R(T)/T = \\widetilde O(1/T)$, and also\nreaching consensus on the highest-mean action within $\\widetilde O(\\sqrt{n})$\nrounds. We obtain these results by showing a new connection between the global\nevolution of these decentralized protocols and a class of zero-sum\nmultiplicative weights update} processes. Using this connection, we establish a\ngeneral framework for analyzing the population-level regret and other\nproperties of our protocols. Finally, we show our protocols are also\nsurprisingly robust to adversarial rewards, and in this regime we obtain\nsublinear regret scaling like $R(T)/T = \\widetilde O(1/\\sqrt{T})$ as long as\nthe number of rounds does not grow too fast as a function of $n$.\n","authors":["John Lazarsfeld","Dan Alistarh"],"pdf_url":"https://arxiv.org/pdf/2306.08670v5.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.14242v1","updated":"2024-10-18T07:47:59Z","published":"2024-10-18T07:47:59Z","title":"Pseudo-label Refinement for Improving Self-Supervised Learning Systems","summary":"  Self-supervised learning systems have gained significant attention in recent\nyears by leveraging clustering-based pseudo-labels to provide supervision\nwithout the need for human annotations. However, the noise in these\npseudo-labels caused by the clustering methods poses a challenge to the\nlearning process leading to degraded performance. In this work, we propose a\npseudo-label refinement (SLR) algorithm to address this issue. The cluster\nlabels from the previous epoch are projected to the current epoch\ncluster-labels space and a linear combination of the new label and the\nprojected label is computed as a soft refined label containing the information\nfrom the previous epoch clusters as well as from the current epoch. In contrast\nto the common practice of using the maximum value as a cluster/class indicator,\nwe employ hierarchical clustering on these soft pseudo-labels to generate\nrefined hard-labels. This approach better utilizes the information embedded in\nthe soft labels, outperforming the simple maximum value approach for hard label\ngeneration. The effectiveness of the proposed SLR algorithm is evaluated in the\ncontext of person re-identification (Re-ID) using unsupervised domain\nadaptation (UDA). Experimental results demonstrate that the modified Re-ID\nbaseline, incorporating the SLR algorithm, achieves significantly improved mean\nAverage Precision (mAP) performance in various UDA tasks, including\nreal-to-synthetic, synthetic-to-real, and different real-to-real scenarios.\nThese findings highlight the efficacy of the SLR algorithm in enhancing the\nperformance of self-supervised learning systems.\n","authors":[" Zia-ur-Rehman","Arif Mahmood","Wenxiong Kang"],"pdf_url":"https://arxiv.org/pdf/2410.14242v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.14240v1","updated":"2024-10-18T07:44:12Z","published":"2024-10-18T07:44:12Z","title":"Almost-Linear RNNs Yield Highly Interpretable Symbolic Codes in\n  Dynamical Systems Reconstruction","summary":"  Dynamical systems (DS) theory is fundamental for many areas of science and\nengineering. It can provide deep insights into the behavior of systems evolving\nin time, as typically described by differential or recursive equations. A\ncommon approach to facilitate mathematical tractability and interpretability of\nDS models involves decomposing nonlinear DS into multiple linear DS separated\nby switching manifolds, i.e. piecewise linear (PWL) systems. PWL models are\npopular in engineering and a frequent choice in mathematics for analyzing the\ntopological properties of DS. However, hand-crafting such models is tedious and\nonly possible for very low-dimensional scenarios, while inferring them from\ndata usually gives rise to unnecessarily complex representations with very many\nlinear subregions. Here we introduce Almost-Linear Recurrent Neural Networks\n(AL-RNNs) which automatically and robustly produce most parsimonious PWL\nrepresentations of DS from time series data, using as few PWL nonlinearities as\npossible. AL-RNNs can be efficiently trained with any SOTA algorithm for\ndynamical systems reconstruction (DSR), and naturally give rise to a symbolic\nencoding of the underlying DS that provably preserves important topological\nproperties. We show that for the Lorenz and R\\\"ossler systems, AL-RNNs\ndiscover, in a purely data-driven way, the known topologically minimal PWL\nrepresentations of the corresponding chaotic attractors. We further illustrate\non two challenging empirical datasets that interpretable symbolic encodings of\nthe dynamics can be achieved, tremendously facilitating mathematical and\ncomputational analysis of the underlying systems.\n","authors":["Manuel Brenner","Christoph Jürgen Hemmer","Zahra Monfared","Daniel Durstewitz"],"pdf_url":"https://arxiv.org/pdf/2410.14240v1.pdf","comment":"38th Conference on Neural Information Processing Systems (NeurIPS\n  2024)"},{"id":"http://arxiv.org/abs/2410.14237v1","updated":"2024-10-18T07:37:36Z","published":"2024-10-18T07:37:36Z","title":"Unified Convergence Analysis for Score-Based Diffusion Models with\n  Deterministic Samplers","summary":"  Score-based diffusion models have emerged as powerful techniques for\ngenerating samples from high-dimensional data distributions. These models\ninvolve a two-phase process: first, injecting noise to transform the data\ndistribution into a known prior distribution, and second, sampling to recover\nthe original data distribution from noise. Among the various sampling methods,\ndeterministic samplers stand out for their enhanced efficiency. However,\nanalyzing these deterministic samplers presents unique challenges, as they\npreclude the use of established techniques such as Girsanov's theorem, which\nare only applicable to stochastic samplers. Furthermore, existing analysis for\ndeterministic samplers usually focuses on specific examples, lacking a\ngeneralized approach for general forward processes and various deterministic\nsamplers. Our paper addresses these limitations by introducing a unified\nconvergence analysis framework. To demonstrate the power of our framework, we\nanalyze the variance-preserving (VP) forward process with the exponential\nintegrator (EI) scheme, achieving iteration complexity of $\\tilde\nO(d^2/\\epsilon)$. Additionally, we provide a detailed analysis of Denoising\nDiffusion Implicit Models (DDIM)-type samplers, which have been underexplored\nin previous research, achieving polynomial iteration complexity.\n","authors":["Runjia Li","Qiwei Di","Quanquan Gu"],"pdf_url":"https://arxiv.org/pdf/2410.14237v1.pdf","comment":"68 pages"},{"id":"http://arxiv.org/abs/2305.01661v2","updated":"2024-10-18T07:15:51Z","published":"2023-05-02T08:28:55Z","title":"Integrating spoken instructions into flight trajectory prediction to\n  optimize automation in air traffic control","summary":"  The booming air transportation industry inevitably burdens air traffic\ncontrollers' workload, causing unexpected human factor-related incidents.\nCurrent air traffic control systems fail to consider spoken instructions for\ntraffic prediction, bringing significant challenges in detecting human errors\nduring real-time traffic operations. Here, we present an automation paradigm\nintegrating controlling intent into the information processing loop through the\nspoken instruction-aware flight trajectory prediction framework. A 3-stage\nprogressive multi-modal learning paradigm is proposed to address the modality\ngap between the trajectory and spoken instructions, as well as minimize the\ndata requirements. Experiments on a real-world dataset show the proposed\nframework achieves flight trajectory prediction with high predictability and\ntimeliness, obtaining over 20% relative reduction in mean deviation error.\nMoreover, the generalizability of the proposed framework is also confirmed by\nvarious model architectures. The proposed framework can formulate\nfull-automated information processing in real-world air traffic applications,\nsupporting human error detection and enhancing aviation safety.\n","authors":["Dongyue Guo","Zheng Zhang","Bo Yang","Jianwei Zhang","Hongyu Yang","Yi Lin"],"pdf_url":"https://arxiv.org/pdf/2305.01661v2.pdf","comment":"This paper has been accepted in principle by Nature Communications"},{"id":"http://arxiv.org/abs/2410.14223v1","updated":"2024-10-18T07:14:08Z","published":"2024-10-18T07:14:08Z","title":"G-NeuroDAVIS: A Neural Network model for generalized embedding, data\n  visualization and sample generation","summary":"  Visualizing high-dimensional datasets through a generalized embedding has\nbeen a challenge for a long time. Several methods have shown up for the same,\nbut still, they have not been able to generate a generalized embedding, which\nnot only can reveal the hidden patterns present in the data but also generate\nrealistic high-dimensional samples from it. Motivated by this aspect, in this\nstudy, a novel generative model, called G-NeuroDAVIS, has been developed, which\nis capable of visualizing high-dimensional data through a generalized\nembedding, and thereby generating new samples. The model leverages advanced\ngenerative techniques to produce high-quality embedding that captures the\nunderlying structure of the data more effectively than existing methods.\nG-NeuroDAVIS can be trained in both supervised and unsupervised settings. We\nrigorously evaluated our model through a series of experiments, demonstrating\nsuperior performance in classification tasks, which highlights the robustness\nof the learned representations. Furthermore, the conditional sample generation\ncapability of the model has been described through qualitative assessments,\nrevealing a marked improvement in generating realistic and diverse samples.\nG-NeuroDAVIS has outperformed the Variational Autoencoder (VAE) significantly\nin multiple key aspects, including embedding quality, classification\nperformance, and sample generation capability. These results underscore the\npotential of our generative model to serve as a powerful tool in various\napplications requiring high-quality data generation and representation\nlearning.\n","authors":["Chayan Maitra","Rajat K. De"],"pdf_url":"https://arxiv.org/pdf/2410.14223v1.pdf","comment":"15 pages, 8 figures"},{"id":"http://arxiv.org/abs/2409.09785v3","updated":"2024-10-18T07:11:35Z","published":"2024-09-15T16:32:49Z","title":"Large Language Model Based Generative Error Correction: A Challenge and\n  Baselines for Speech Recognition, Speaker Tagging, and Emotion Recognition","summary":"  Given recent advances in generative AI technology, a key question is how\nlarge language models (LLMs) can enhance acoustic modeling tasks using text\ndecoding results from a frozen, pretrained automatic speech recognition (ASR)\nmodel. To explore new capabilities in language modeling for speech processing,\nwe introduce the generative speech transcription error correction (GenSEC)\nchallenge. This challenge comprises three post-ASR language modeling tasks: (i)\npost-ASR transcription correction, (ii) speaker tagging, and (iii) emotion\nrecognition. These tasks aim to emulate future LLM-based agents handling\nvoice-based interfaces while remaining accessible to a broad audience by\nutilizing open pretrained language models or agent-based APIs. We also discuss\ninsights from baseline evaluations, as well as lessons learned for designing\nfuture evaluations.\n","authors":["Chao-Han Huck Yang","Taejin Park","Yuan Gong","Yuanchao Li","Zhehuai Chen","Yen-Ting Lin","Chen Chen","Yuchen Hu","Kunal Dhawan","Piotr Żelasko","Chao Zhang","Yun-Nung Chen","Yu Tsao","Jagadeesh Balam","Boris Ginsburg","Sabato Marco Siniscalchi","Eng Siong Chng","Peter Bell","Catherine Lai","Shinji Watanabe","Andreas Stolcke"],"pdf_url":"https://arxiv.org/pdf/2409.09785v3.pdf","comment":"IEEE SLT 2024. The initial draft version has been done in December\n  2023. Post-ASR Text Processing and Understanding Community and LlaMA-7B\n  pre-training correction model:\n  https://huggingface.co/GenSEC-LLM/SLT-Task1-Llama2-7b-HyPo-baseline"},{"id":"http://arxiv.org/abs/2410.14219v1","updated":"2024-10-18T07:08:31Z","published":"2024-10-18T07:08:31Z","title":"Formal Explanations for Neuro-Symbolic AI","summary":"  Despite the practical success of Artificial Intelligence (AI), current neural\nAI algorithms face two significant issues. First, the decisions made by neural\narchitectures are often prone to bias and brittleness. Second, when a chain of\nreasoning is required, neural systems often perform poorly. Neuro-symbolic\nartificial intelligence is a promising approach that tackles these (and other)\nweaknesses by combining the power of neural perception and symbolic reasoning.\nMeanwhile, the success of AI has made it critical to understand its behaviour,\nleading to the development of explainable artificial intelligence (XAI). While\nneuro-symbolic AI systems have important advantages over purely neural AI, we\nstill need to explain their actions, which are obscured by the interactions of\nthe neural and symbolic components. To address the issue, this paper proposes a\nformal approach to explaining the decisions of neuro-symbolic systems. The\napproach hinges on the use of formal abductive explanations and on solving the\nneuro-symbolic explainability problem hierarchically. Namely, it first computes\na formal explanation for the symbolic component of the system, which serves to\nidentify a subset of the individual parts of neural information that needs to\nbe explained. This is followed by explaining only those individual neural\ninputs, independently of each other, which facilitates succinctness of\nhierarchical formal explanations and helps to increase the overall performance\nof the approach. Experimental results for a few complex reasoning tasks\ndemonstrate practical efficiency of the proposed approach, in comparison to\npurely neural systems, from the perspective of explanation size, explanation\ntime, training time, model sizes, and the quality of explanations reported.\n","authors":["Sushmita Paul","Jinqiang Yu","Jip J. Dekker","Alexey Ignatiev","Peter J. Stuckey"],"pdf_url":"https://arxiv.org/pdf/2410.14219v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.04808v3","updated":"2024-10-18T07:05:57Z","published":"2024-03-06T10:55:30Z","title":"WaterMax: breaking the LLM watermark detectability-robustness-quality\n  trade-off","summary":"  Watermarking is a technical means to dissuade malfeasant usage of Large\nLanguage Models. This paper proposes a novel watermarking scheme, so-called\nWaterMax, that enjoys high detectability while sustaining the quality of the\ngenerated text of the original LLM. Its new design leaves the LLM untouched (no\nmodification of the weights, logits, temperature, or sampling technique).\nWaterMax balances robustness and complexity contrary to the watermarking\ntechniques of the literature inherently provoking a trade-off between quality\nand robustness. Its performance is both theoretically proven and experimentally\nvalidated. It outperforms all the SotA techniques under the most complete\nbenchmark suite. Code available at https://github.com/eva-giboulot/WaterMax.\n","authors":["Eva Giboulot","Teddy Furon"],"pdf_url":"https://arxiv.org/pdf/2403.04808v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.14212v1","updated":"2024-10-18T07:01:56Z","published":"2024-10-18T07:01:56Z","title":"Comparative Evaluation of Clustered Federated Learning Method","summary":"  Over recent years, Federated Learning (FL) has proven to be one of the most\npromising methods of distributed learning which preserves data privacy. As the\nmethod evolved and was confronted to various real-world scenarios, new\nchallenges have emerged. One such challenge is the presence of highly\nheterogeneous (often referred as non-IID) data distributions among participants\nof the FL protocol. A popular solution to this hurdle is Clustered Federated\nLearning (CFL), which aims to partition clients into groups where the\ndistribution are homogeneous. In the literature, state-of-the-art CFL\nalgorithms are often tested using a few cases of data heterogeneities, without\nsystematically justifying the choices. Further, the taxonomy used for\ndifferentiating the different heterogeneity scenarios is not always\nstraightforward. In this paper, we explore the performance of two\nstate-of-theart CFL algorithms with respect to a proposed taxonomy of data\nheterogeneities in federated learning (FL). We work with three image\nclassification datasets and analyze the resulting clusters against the\nheterogeneity classes using extrinsic clustering metrics. Our objective is to\nprovide a clearer understanding of the relationship between CFL performances\nand data heterogeneity scenarios.\n","authors":["Michael Ben Ali","Omar El-Rifai","Imen Megdiche","André Peninou","Olivier Teste"],"pdf_url":"https://arxiv.org/pdf/2410.14212v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2405.16435v2","updated":"2024-10-18T06:56:10Z","published":"2024-05-26T05:22:38Z","title":"Node Identifiers: Compact, Discrete Representations for Efficient Graph\n  Learning","summary":"  We present a novel end-to-end framework that generates highly compact\n(typically 6-15 dimensions), discrete (int4 type), and interpretable node\nrepresentations, termed node identifiers (node IDs), to tackle inference\nchallenges on large-scale graphs. By employing vector quantization, we compress\ncontinuous node embeddings from multiple layers of a Graph Neural Network (GNN)\ninto discrete codes, applicable under both self-supervised and supervised\nlearning paradigms. These node IDs capture high-level abstractions of graph\ndata and offer interpretability that traditional GNN embeddings lack. Extensive\nexperiments on 34 datasets, encompassing node classification, graph\nclassification, link prediction, and attributed graph clustering tasks,\ndemonstrate that the generated node IDs significantly enhance speed and memory\nefficiency while achieving competitive performance compared to current\nstate-of-the-art methods.\n","authors":["Yuankai Luo","Hongkang Li","Qijiong Liu","Lei Shi","Xiao-Ming Wu"],"pdf_url":"https://arxiv.org/pdf/2405.16435v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.14208v1","updated":"2024-10-18T06:50:15Z","published":"2024-10-18T06:50:15Z","title":"Montessori-Instruct: Generate Influential Training Data Tailored for\n  Student Learning","summary":"  Synthetic data has been widely used to train large language models, but their\ngenerative nature inevitably introduces noisy, non-informative, and misleading\nlearning signals. In this paper, we propose Montessori-Instruct, a novel data\nsynthesis framework that tailors the data synthesis ability of the teacher\nlanguage model toward the student language model's learning process.\nSpecifically, we utilize local data influence of synthetic training data points\non students to characterize students' learning preferences. Then, we train the\nteacher model with Direct Preference Optimization (DPO) to generate synthetic\ndata tailored toward student learning preferences. Experiments with\nLlama3-8B-Instruct (teacher) and Llama3-8B (student) on Alpaca Eval and\nMT-Bench demonstrate that Montessori-Instruct significantly outperforms\nstandard synthesis methods by 18.35\\% and 46.24\\% relatively. Our method also\nbeats data synthesized by a stronger teacher model, GPT-4o. Further analysis\nconfirms the benefits of teacher's learning to generate more influential\ntraining data in the student's improved learning, the advantages of local data\ninfluence in accurately measuring student preferences, and the robustness of\nMontessori-Instruct across different student models. Our code and data are\nopen-sourced at https://github.com/cxcscmu/Montessori-Instruct.\n","authors":["Xiaochuan Li","Zichun Yu","Chenyan Xiong"],"pdf_url":"https://arxiv.org/pdf/2410.14208v1.pdf","comment":"Codes and data are open-sourced at\n  https://github.com/cxcscmu/Montessori-Instruct"},{"id":"http://arxiv.org/abs/2410.14207v1","updated":"2024-10-18T06:47:39Z","published":"2024-10-18T06:47:39Z","title":"Flexi-Fuzz least squares SVM for Alzheimer's diagnosis: Tackling noise,\n  outliers, and class imbalance","summary":"  Alzheimer's disease (AD) is a leading neurodegenerative condition and the\nprimary cause of dementia, characterized by progressive cognitive decline and\nmemory loss. Its progression, marked by shrinkage in the cerebral cortex, is\nirreversible. Numerous machine learning algorithms have been proposed for the\nearly diagnosis of AD. However, they often struggle with the issues of noise,\noutliers, and class imbalance. To tackle the aforementioned limitations, in\nthis article, we introduce a novel, robust, and flexible membership scheme\ncalled Flexi-Fuzz. This scheme integrates a novel flexible weighting mechanism,\nclass probability, and imbalance ratio. The proposed flexible weighting\nmechanism assigns the maximum weight to samples within a specific proximity to\nthe center, with a gradual decrease in weight beyond a certain threshold. This\napproach ensures that samples near the class boundary still receive significant\nweight, maintaining their influence in the classification process. Class\nprobability is used to mitigate the impact of noisy samples, while the\nimbalance ratio addresses class imbalance. Leveraging this, we incorporate the\nproposed Flexi-Fuzz membership scheme into the least squares support vector\nmachines (LSSVM) framework, resulting in a robust and flexible model termed\nFlexi-Fuzz-LSSVM. We determine the class-center using two methods: the\nconventional mean approach and an innovative median approach, leading to two\nmodel variants, Flexi-Fuzz-LSSVM-I and Flexi-Fuzz-LSSVM-II. To validate the\neffectiveness of the proposed Flexi-Fuzz-LSSVM models, we evaluated them on\nbenchmark UCI and KEEL datasets, both with and without label noise.\nAdditionally, we tested the models on the Alzheimer's Disease Neuroimaging\nInitiative (ADNI) dataset for AD diagnosis. Experimental results demonstrate\nthe superiority of the Flexi-Fuzz-LSSVM models over baseline models.\n","authors":["Mushir Akhtar","A. Quadir","M. Tanveer","Mohd. Arshad"],"pdf_url":"https://arxiv.org/pdf/2410.14207v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.19619v2","updated":"2024-10-18T06:40:37Z","published":"2024-06-28T03:02:25Z","title":"ScoreFusion: fusing score-based generative models via Kullback-Leibler\n  barycenters","summary":"  We introduce ScoreFusion, a theoretically grounded method for fusing multiple\npre-trained diffusion models that are assumed to generate from auxiliary\npopulations. ScoreFusion is particularly useful for enhancing the generative\nmodeling of a target population with limited observed data. Our starting point\nconsiders the family of KL barycenters of the auxiliary populations, which is\nproven to be an optimal parametric class in the KL sense, but difficult to\nlearn. Nevertheless, by recasting the learning problem as score matching in\ndenoising diffusion, we obtain a tractable way of computing the optimal KL\nbarycenter weights. We prove a dimension-free sample complexity bound in total\nvariation distance, provided that the auxiliary models are well fitted for\ntheir own task and the auxiliary tasks combined capture the target well. We\nalso explain a connection of the practice of checkpoint merging in AI art\ncreation to an approximation of our KL-barycenter-based fusion approach.\nHowever, our fusion method differs in key aspects, allowing generation of new\npopulations, as we illustrate in experiments.\n","authors":["Hao Liu","Junze Tony Ye","Jose Blanchet","Nian Si"],"pdf_url":"https://arxiv.org/pdf/2406.19619v2.pdf","comment":"53 pages, 15 figures"},{"id":"http://arxiv.org/abs/2311.01483v5","updated":"2024-10-18T06:38:11Z","published":"2023-11-02T14:47:06Z","title":"FedSN: A Federated Learning Framework over Heterogeneous LEO Satellite\n  Networks","summary":"  Recently, a large number of Low Earth Orbit (LEO) satellites have been\nlaunched and deployed successfully in space by commercial companies, such as\nSpaceX. Due to multimodal sensors equipped by the LEO satellites, they serve\nnot only for communication but also for various machine learning applications,\nsuch as space modulation recognition, remote sensing image classification, etc.\nHowever, the ground station (GS) may be incapable of downloading such a large\nvolume of raw sensing data for centralized model training due to the limited\ncontact time with LEO satellites (e.g. 5 minutes). Therefore, federated\nlearning (FL) has emerged as the promising solution to address this problem via\non-device training. Unfortunately, to enable FL on LEO satellites, we still\nface three critical challenges that are i) heterogeneous computing and memory\ncapabilities, ii) limited uplink rate, and iii) model staleness. To this end,\nwe propose FedSN as a general FL framework to tackle the above challenges, and\nfully explore data diversity on LEO satellites. Specifically, we first present\na novel sub-structure scheme to enable heterogeneous local model training\nconsidering different computing, memory, and communication constraints on LEO\nsatellites. Additionally, we propose a pseudo-synchronous model aggregation\nstrategy to dynamically schedule model aggregation for compensating model\nstaleness. To further demonstrate the effectiveness of the FedSN, we evaluate\nit using space modulation recognition and remote sensing image classification\ntasks by leveraging the data from real-world satellite networks. Extensive\nexperimental results demonstrate that FedSN framework achieves higher accuracy,\nlower computing, and communication overhead than the state-of-the-art\nbenchmarks and the effectiveness of each components in FedSN.\n","authors":["Zheng Lin","Zhe Chen","Zihan Fang","Xianhao Chen","Xiong Wang","Yue Gao"],"pdf_url":"https://arxiv.org/pdf/2311.01483v5.pdf","comment":"15 pages, 17 figures"},{"id":"http://arxiv.org/abs/2404.02175v2","updated":"2024-10-18T06:33:19Z","published":"2024-04-01T11:23:31Z","title":"Social Dynamics of Consumer Response: A Unified Framework Integrating\n  Statistical Physics and Marketing Dynamics","summary":"  Understanding how consumers react to advertising inputs is essential for\nmarketers aiming to optimize advertising strategies and improve campaign\neffectiveness. This study examines the complex nature of consumer behaviour by\napplying theoretical frameworks derived from physics and social psychology. We\npresent an innovative equation that captures the relation between spending on\nadvertising and consumer response, using concepts such as symmetries, scaling\nlaws, and phase transitions. By validating our equation against well-known\nmodels such as the Michaelis-Menten and Hill equations, we prove its\neffectiveness in accurately representing the complexity of consumer response\ndynamics. The analysis emphasizes the importance of key model parameters, such\nas marketing effectiveness, response sensitivity, and behavioural sensitivity,\nin influencing consumer behaviour. The work explores the practical implications\nfor advertisers and marketers, as well as discussing the limitations and future\nresearch directions. In summary, this study provides a thorough framework for\ncomprehending and forecasting consumer reactions to advertising, which has\nimplications for optimizing advertising strategies and allocating resources.\n","authors":["Javier Marin"],"pdf_url":"https://arxiv.org/pdf/2404.02175v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2405.16922v2","updated":"2024-10-18T06:15:42Z","published":"2024-05-27T08:13:39Z","title":"Theories of synaptic memory consolidation and intelligent plasticity for\n  continual learning","summary":"  Humans and animals learn throughout life. Such continual learning is crucial\nfor intelligence. In this chapter, we examine the pivotal role plasticity\nmechanisms with complex internal synaptic dynamics could play in enabling this\nability in neural networks. By surveying theoretical research, we highlight two\nfundamental enablers for continual learning. First, synaptic plasticity\nmechanisms must maintain and evolve an internal state over several behaviorally\nrelevant timescales. Second, plasticity algorithms must leverage the internal\nstate to intelligently regulate plasticity at individual synapses to facilitate\nthe seamless integration of new memories while avoiding detrimental\ninterference with existing ones. Our chapter covers successful applications of\nthese principles to deep neural networks and underscores the significance of\nsynaptic metaplasticity in sustaining continual learning capabilities. Finally,\nwe outline avenues for further research to understand the brain's superb\ncontinual learning abilities and harness similar mechanisms for artificial\nintelligence systems.\n","authors":["Friedemann Zenke","Axel Laborieux"],"pdf_url":"https://arxiv.org/pdf/2405.16922v2.pdf","comment":"An introductory-level book chapter. 35 pages, 14 figures"},{"id":"http://arxiv.org/abs/2410.14193v1","updated":"2024-10-18T06:07:22Z","published":"2024-10-18T06:07:22Z","title":"xPerT: Extended Persistence Transformer","summary":"  A persistence diagram provides a compact summary of persistent homology,\nwhich captures the topological features of a space at different scales.\nHowever, due to its nature as a set, incorporating it as a feature into a\nmachine learning framework is challenging. Several methods have been proposed\nto use persistence diagrams as input for machine learning models, but they\noften require complex preprocessing steps and extensive hyperparameter tuning.\nIn this paper, we propose a novel transformer architecture called the\n\\textit{Extended Persistence Transformer (xPerT)}, which is highly scalable\nthan the compared to Persformer, an existing transformer for persistence\ndiagrams. xPerT reduces GPU memory usage by over 90\\% and improves accuracy on\nmultiple datasets. Additionally, xPerT does not require complex preprocessing\nsteps or extensive hyperparameter tuning, making it easy to use in practice.\nOur code is available at https://github.com/sehunfromdaegu/ECG_JEPA.\n","authors":["Sehun Kim"],"pdf_url":"https://arxiv.org/pdf/2410.14193v1.pdf","comment":null}]},"2024-10-21T00:00:00Z":{"Computation and Language":[{"id":"http://arxiv.org/abs/2410.14211v2","updated":"2024-10-21T01:22:16Z","published":"2024-10-18T06:57:19Z","title":"Paths-over-Graph: Knowledge Graph Empowered Large Language Model\n  Reasoning","summary":"  Large Language Models (LLMs) have achieved impressive results in various\ntasks but struggle with hallucination problems and lack of relevant knowledge,\nespecially in deep complex reasoning and knowledge-intensive tasks. Knowledge\nGraphs (KGs), which capture vast amounts of facts in a structured format, offer\na reliable source of knowledge for reasoning. However, existing KG-based LLM\nreasoning methods face challenges like handling multi-hop reasoning,\nmulti-entity questions, and effectively utilizing graph structures. To address\nthese issues, we propose Paths-over-Graph (PoG), a novel method that enhances\nLLM reasoning by integrating knowledge reasoning paths from KGs, improving the\ninterpretability and faithfulness of LLM outputs. PoG tackles multi-hop and\nmulti-entity questions through a three-phase dynamic multi-hop path\nexploration, which combines the inherent knowledge of LLMs with factual\nknowledge from KGs. In order to improve the efficiency, PoG prunes irrelevant\ninformation from the graph exploration first and introduces efficient\nthree-step pruning techniques that incorporate graph structures, LLM prompting,\nand a pre-trained language model (e.g., SBERT) to effectively narrow down the\nexplored candidate paths. This ensures all reasoning paths contain highly\nrelevant information captured from KGs, making the reasoning faithful and\ninterpretable in problem-solving. PoG innovatively utilizes graph structure to\nprune the irrelevant noise and represents the first method to implement\nmulti-entity deep path detection on KGs for LLM reasoning tasks. Comprehensive\nexperiments on five benchmark KGQA datasets demonstrate PoG outperforms the\nstate-of-the-art method ToG across GPT-3.5-Turbo and GPT-4, achieving an\naverage accuracy improvement of 18.9%. Notably, PoG with GPT-3.5-Turbo\nsurpasses ToG with GPT-4 by up to 23.9%.\n","authors":["Xingyu Tan","Xiaoyang Wang","Qing Liu","Xiwei Xu","Xin Yuan","Wenjie Zhang"],"pdf_url":"https://arxiv.org/pdf/2410.14211v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.14180v2","updated":"2024-10-21T03:19:40Z","published":"2024-10-18T05:16:39Z","title":"XForecast: Evaluating Natural Language Explanations for Time Series\n  Forecasting","summary":"  Time series forecasting aids decision-making, especially for stakeholders who\nrely on accurate predictions, making it very important to understand and\nexplain these models to ensure informed decisions. Traditional explainable AI\n(XAI) methods, which underline feature or temporal importance, often require\nexpert knowledge. In contrast, natural language explanations (NLEs) are more\naccessible to laypeople. However, evaluating forecast NLEs is difficult due to\nthe complex causal relationships in time series data. To address this, we\nintroduce two new performance metrics based on simulatability, assessing how\nwell a human surrogate can predict model forecasts using the explanations.\nExperiments show these metrics differentiate good from poor explanations and\nalign with human judgments. Utilizing these metrics, we further evaluate the\nability of state-of-the-art large language models (LLMs) to generate\nexplanations for time series data, finding that numerical reasoning, rather\nthan model size, is the main factor influencing explanation quality.\n","authors":["Taha Aksu","Chenghao Liu","Amrita Saha","Sarah Tan","Caiming Xiong","Doyen Sahoo"],"pdf_url":"https://arxiv.org/pdf/2410.14180v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.16267v1","updated":"2024-10-21T17:59:11Z","published":"2024-10-21T17:59:11Z","title":"xGen-MM-Vid (BLIP-3-Video): You Only Need 32 Tokens to Represent a Video\n  Even in VLMs","summary":"  We present xGen-MM-Vid (BLIP-3-Video): a multimodal language model for\nvideos, particularly designed to efficiently capture temporal information over\nmultiple frames. BLIP-3-Video takes advantage of the 'temporal encoder' in\naddition to the conventional visual tokenizer, which maps a sequence of tokens\nover multiple frames into a compact set of visual tokens. This enables\nBLIP3-Video to use much fewer visual tokens than its competing models (e.g., 32\nvs. 4608 tokens). We explore different types of temporal encoders, including\nlearnable spatio-temporal pooling as well as sequential models like Token\nTuring Machines. We experimentally confirm that BLIP-3-Video obtains video\nquestion-answering accuracies comparable to much larger state-of-the-art models\n(e.g., 34B), while being much smaller (i.e., 4B) and more efficient by using\nfewer visual tokens. The project website is at\nhttps://www.salesforceairesearch.com/opensource/xGen-MM-Vid/index.html\n","authors":["Michael S. Ryoo","Honglu Zhou","Shrikant Kendre","Can Qin","Le Xue","Manli Shu","Silvio Savarese","Ran Xu","Caiming Xiong","Juan Carlos Niebles"],"pdf_url":"https://arxiv.org/pdf/2410.16267v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.16256v1","updated":"2024-10-21T17:56:51Z","published":"2024-10-21T17:56:51Z","title":"CompassJudger-1: All-in-one Judge Model Helps Model Evaluation and\n  Evolution","summary":"  Efficient and accurate evaluation is crucial for the continuous improvement\nof large language models (LLMs). Among various assessment methods, subjective\nevaluation has garnered significant attention due to its superior alignment\nwith real-world usage scenarios and human preferences. However, human-based\nevaluations are costly and lack reproducibility, making precise automated\nevaluators (judgers) vital in this process. In this report, we introduce\n\\textbf{CompassJudger-1}, the first open-source \\textbf{all-in-one} judge LLM.\nCompassJudger-1 is a general-purpose LLM that demonstrates remarkable\nversatility. It is capable of: 1. Performing unitary scoring and two-model\ncomparisons as a reward model; 2. Conducting evaluations according to specified\nformats; 3. Generating critiques; 4. Executing diverse tasks like a general\nLLM. To assess the evaluation capabilities of different judge models under a\nunified setting, we have also established \\textbf{JudgerBench}, a new benchmark\nthat encompasses various subjective evaluation tasks and covers a wide range of\ntopics. CompassJudger-1 offers a comprehensive solution for various evaluation\ntasks while maintaining the flexibility to adapt to diverse requirements. Both\nCompassJudger and JudgerBench are released and available to the research\ncommunity athttps://github.com/open-compass/CompassJudger. We believe that by\nopen-sourcing these tools, we can foster collaboration and accelerate progress\nin LLM evaluation methodologies.\n","authors":["Maosong Cao","Alexander Lam","Haodong Duan","Hongwei Liu","Songyang Zhang","Kai Chen"],"pdf_url":"https://arxiv.org/pdf/2410.16256v1.pdf","comment":"Technical Report, Code and Models:\n  https://github.com/open-compass/CompassJudger"},{"id":"http://arxiv.org/abs/2410.16251v1","updated":"2024-10-21T17:55:54Z","published":"2024-10-21T17:55:54Z","title":"Can Knowledge Editing Really Correct Hallucinations?","summary":"  Large Language Models (LLMs) suffer from hallucinations, referring to the\nnon-factual information in generated content, despite their superior capacities\nacross tasks. Meanwhile, knowledge editing has been developed as a new popular\nparadigm to correct the erroneous factual knowledge encoded in LLMs with the\nadvantage of avoiding retraining from scratch. However, one common issue of\nexisting evaluation datasets for knowledge editing is that they do not ensure\nLLMs actually generate hallucinated answers to the evaluation questions before\nediting. When LLMs are evaluated on such datasets after being edited by\ndifferent techniques, it is hard to directly adopt the performance to assess\nthe effectiveness of different knowledge editing methods in correcting\nhallucinations. Thus, the fundamental question remains insufficiently\nvalidated: Can knowledge editing really correct hallucinations in LLMs? We\nproposed HalluEditBench to holistically benchmark knowledge editing methods in\ncorrecting real-world hallucinations. First, we rigorously construct a massive\nhallucination dataset with 9 domains, 26 topics and more than 6,000\nhallucinations. Then, we assess the performance of knowledge editing methods in\na holistic way on five dimensions including Efficacy, Generalization,\nPortability, Locality, and Robustness. Through HalluEditBench, we have provided\nnew insights into the potentials and limitations of different knowledge editing\nmethods in correcting hallucinations, which could inspire future improvements\nand facilitate the progress in the field of knowledge editing.\n","authors":["Baixiang Huang","Canyu Chen","Xiongxiao Xu","Ali Payani","Kai Shu"],"pdf_url":"https://arxiv.org/pdf/2410.16251v1.pdf","comment":"The first two authors contributed equally to this work. The main\n  paper is 10 pages long, with 35 pages total. The code, results, dataset, and\n  additional resources are available on the project website:\n  https://llm-editing.github.io/"},{"id":"http://arxiv.org/abs/2410.16246v1","updated":"2024-10-21T17:51:41Z","published":"2024-10-21T17:51:41Z","title":"Analyzing Context Contributions in LLM-based Machine Translation","summary":"  Large language models (LLMs) have achieved state-of-the-art performance in\nmachine translation (MT) and demonstrated the ability to leverage in-context\nlearning through few-shot examples. However, the mechanisms by which LLMs use\ndifferent parts of the input context remain largely unexplored. In this work,\nwe provide a comprehensive analysis of context utilization in MT, studying how\nLLMs use various context parts, such as few-shot examples and the source text,\nwhen generating translations. We highlight several key findings: (1) the source\npart of few-shot examples appears to contribute more than its corresponding\ntargets, irrespective of translation direction; (2) finetuning LLMs with\nparallel data alters the contribution patterns of different context parts; and\n(3) there is a positional bias where earlier few-shot examples have higher\ncontributions to the translated sequence. Finally, we demonstrate that\ninspecting anomalous context contributions can potentially uncover pathological\ntranslations, such as hallucinations. Our findings shed light on the internal\nworkings of LLM-based MT which go beyond those known for standard\nencoder-decoder MT models.\n","authors":["Emmanouil Zaranis","Nuno M. Guerreiro","André F. T. Martins"],"pdf_url":"https://arxiv.org/pdf/2410.16246v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.16235v1","updated":"2024-10-21T17:41:11Z","published":"2024-10-21T17:41:11Z","title":"ToW: Thoughts of Words Improve Reasoning in Large Language Models","summary":"  We introduce thoughts of words (ToW), a novel training-time data-augmentation\nmethod for next-word prediction. ToW views next-word prediction as a core\nreasoning task and injects fine-grained thoughts explaining what the next word\nshould be and how it is related to the previous contexts in pre-training texts.\nOur formulation addresses two fundamental drawbacks of existing next-word\nprediction learning schemes: they induce factual hallucination and are\ninefficient for models to learn the implicit reasoning processes in raw texts.\nWhile there are many ways to acquire such thoughts of words, we explore the\nfirst step of acquiring ToW annotations through distilling from larger models.\nAfter continual pre-training with only 70K ToW annotations, we effectively\nimprove models' reasoning performances by 7% to 9% on average and reduce model\nhallucination by up to 10%. At the same time, ToW is entirely agnostic to tasks\nand applications, introducing no additional biases on labels or semantics.\n","authors":["Zhikun Xu","Ming Shen","Jacob Dineen","Zhaonan Li","Xiao Ye","Shijie Lu","Aswin RRV","Chitta Baral","Ben Zhou"],"pdf_url":"https://arxiv.org/pdf/2410.16235v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.16232v1","updated":"2024-10-21T17:39:49Z","published":"2024-10-21T17:39:49Z","title":"Sketch2Code: Evaluating Vision-Language Models for Interactive Web\n  Design Prototyping","summary":"  Sketches are a natural and accessible medium for UI designers to\nconceptualize early-stage ideas. However, existing research on UI/UX automation\noften requires high-fidelity inputs like Figma designs or detailed screenshots,\nlimiting accessibility and impeding efficient design iteration. To bridge this\ngap, we introduce Sketch2Code, a benchmark that evaluates state-of-the-art\nVision Language Models (VLMs) on automating the conversion of rudimentary\nsketches into webpage prototypes. Beyond end-to-end benchmarking, Sketch2Code\nsupports interactive agent evaluation that mimics real-world design workflows,\nwhere a VLM-based agent iteratively refines its generations by communicating\nwith a simulated user, either passively receiving feedback instructions or\nproactively asking clarification questions. We comprehensively analyze ten\ncommercial and open-source models, showing that Sketch2Code is challenging for\nexisting VLMs; even the most capable models struggle to accurately interpret\nsketches and formulate effective questions that lead to steady improvement.\nNevertheless, a user study with UI/UX experts reveals a significant preference\nfor proactive question-asking over passive feedback reception, highlighting the\nneed to develop more effective paradigms for multi-turn conversational agents.\n","authors":["Ryan Li","Yanzhe Zhang","Diyi Yang"],"pdf_url":"https://arxiv.org/pdf/2410.16232v1.pdf","comment":"preprint, 9 pages"},{"id":"http://arxiv.org/abs/2407.02273v3","updated":"2024-10-21T17:37:26Z","published":"2024-07-02T14:02:53Z","title":"Language Model Alignment in Multilingual Trolley Problems","summary":"  We evaluate the moral alignment of large language models (LLMs) with human\npreferences in multilingual trolley problems. Building on the Moral Machine\nexperiment, which captures over 40 million human judgments across 200+\ncountries, we develop a cross-lingual corpus of moral dilemma vignettes in over\n100 languages called MultiTP. This dataset enables the assessment of LLMs'\ndecision-making processes in diverse linguistic contexts. Our analysis explores\nthe alignment of 19 different LLMs with human judgments, capturing preferences\nacross six moral dimensions: species, gender, fitness, status, age, and the\nnumber of lives involved. By correlating these preferences with the demographic\ndistribution of language speakers and examining the consistency of LLM\nresponses to various prompt paraphrasings, our findings provide insights into\ncross-lingual and ethical biases of LLMs and their intersection. We discover\nsignificant variance in alignment across languages, challenging the assumption\nof uniform moral reasoning in AI systems and highlighting the importance of\nincorporating diverse perspectives in AI ethics. The results underscore the\nneed for further research on the integration of multilingual dimensions in\nresponsible AI research to ensure fair and equitable AI interactions worldwide.\nOur code and data are at https://github.com/causalNLP/moralmachine\n","authors":["Zhijing Jin","Max Kleiman-Weiner","Giorgio Piatti","Sydney Levine","Jiarui Liu","Fernando Gonzalez","Francesco Ortu","András Strausz","Mrinmaya Sachan","Rada Mihalcea","Yejin Choi","Bernhard Schölkopf"],"pdf_url":"https://arxiv.org/pdf/2407.02273v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.16229v1","updated":"2024-10-21T17:34:39Z","published":"2024-10-21T17:34:39Z","title":"Building A Coding Assistant via the Retrieval-Augmented Language Model","summary":"  Pretrained language models have shown strong effectiveness in code-related\ntasks, such as code retrieval, code generation, code summarization, and code\ncompletion tasks. In this paper, we propose COde assistaNt viA\nretrieval-augmeNted language model (CONAN), which aims to build a code\nassistant by mimicking the knowledge-seeking behaviors of humans during coding.\nSpecifically, it consists of a code structure aware retriever (CONAN-R) and a\ndual-view code representation-based retrieval-augmented generation model\n(CONAN-G). CONAN-R pretrains CodeT5 using Code-Documentation Alignment and\nMasked Entity Prediction tasks to make language models code structure-aware and\nlearn effective representations for code snippets and documentation. Then\nCONAN-G designs a dual-view code representation mechanism for implementing a\nretrieval-augmented code generation model. CONAN-G regards the code\ndocumentation descriptions as prompts, which help language models better\nunderstand the code semantics. Our experiments show that CONAN achieves\nconvincing performance on different code generation tasks and significantly\noutperforms previous retrieval augmented code generation models. Our further\nanalyses show that CONAN learns tailored representations for both code snippets\nand documentation by aligning code-documentation data pairs and capturing\nstructural semantics by masking and predicting entities in the code data.\nAdditionally, the retrieved code snippets and documentation provide necessary\ninformation from both program language and natural language to assist the code\ngeneration process. CONAN can also be used as an assistant for Large Language\nModels (LLMs), providing LLMs with external knowledge in shorter code document\nlengths to improve their effectiveness on various code tasks. It shows the\nability of CONAN to extract necessary information and help filter out the noise\nfrom retrieved code documents.\n","authors":["Xinze Li","Hanbin Wang","Zhenghao Liu","Shi Yu","Shuo Wang","Shuo Wang","Yukun Yan","Yukai Fu","Yu Gu","Ge Yu"],"pdf_url":"https://arxiv.org/pdf/2410.16229v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.16221v1","updated":"2024-10-21T17:25:32Z","published":"2024-10-21T17:25:32Z","title":"On Creating an English-Thai Code-switched Machine Translation in Medical\n  Domain","summary":"  Machine translation (MT) in the medical domain plays a pivotal role in\nenhancing healthcare quality and disseminating medical knowledge. Despite\nadvancements in English-Thai MT technology, common MT approaches often\nunderperform in the medical field due to their inability to precisely translate\nmedical terminologies. Our research prioritizes not merely improving\ntranslation accuracy but also maintaining medical terminology in English within\nthe translated text through code-switched (CS) translation. We developed a\nmethod to produce CS medical translation data, fine-tuned a CS translation\nmodel with this data, and evaluated its performance against strong baselines,\nsuch as Google Neural Machine Translation (NMT) and GPT-3.5/GPT-4. Our model\ndemonstrated competitive performance in automatic metrics and was highly\nfavored in human preference evaluations. Our evaluation result also shows that\nmedical professionals significantly prefer CS translations that maintain\ncritical English terms accurately, even if it slightly compromises fluency. Our\ncode and test set are publicly available\nhttps://github.com/preceptorai-org/NLLB_CS_EM_NLP2024.\n","authors":["Parinthapat Pengpun","Krittamate Tiankanon","Amrest Chinkamol","Jiramet Kinchagawat","Pitchaya Chairuengjitjaras","Pasit Supholkhan","Pubordee Aussavavirojekul","Chiraphat Boonnag","Kanyakorn Veerakanjana","Hirunkul Phimsiri","Boonthicha Sae-jia","Nattawach Sataudom","Piyalitt Ittichaiwong","Peerat Limkonchotiwat"],"pdf_url":"https://arxiv.org/pdf/2410.16221v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.16215v1","updated":"2024-10-21T17:16:13Z","published":"2024-10-21T17:16:13Z","title":"Pre-training Distillation for Large Language Models: A Design Space\n  Exploration","summary":"  Knowledge distillation (KD) aims to transfer knowledge from a large teacher\nmodel to a smaller student model. Previous work applying KD in the field of\nlarge language models (LLMs) typically focused on the post-training phase,\nwhere the student LLM learns directly from instructions and corresponding\nresponses generated by the teacher model. In this paper, we extend KD to the\npre-training phase of LLMs, named pre-training distillation (PD). We first\nconduct a preliminary experiment using GLM-4-9B as the teacher LLM to distill a\n1.9B parameter student LLM, validating the effectiveness of PD. Considering the\nkey impact factors of distillation, we systematically explore the design space\nof pre-training distillation across four aspects: logits processing, loss\nselection, scaling law, and offline or online logits. We conduct extensive\nexperiments to explore the design space of pre-training distillation and find\nbetter configurations and interesting conclusions, such as larger student LLMs\ngenerally benefiting more from pre-training distillation, while a larger\nteacher LLM does not necessarily guarantee better results. We hope our\nexploration of the design space will inform future practices in pre-training\ndistillation.\n","authors":["Hao Peng","Xin Lv","Yushi Bai","Zijun Yao","Jiajie Zhang","Lei Hou","Juanzi Li"],"pdf_url":"https://arxiv.org/pdf/2410.16215v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.16208v1","updated":"2024-10-21T17:11:21Z","published":"2024-10-21T17:11:21Z","title":"Compute-Constrained Data Selection","summary":"  Data selection can reduce the amount of training data needed to finetune\nLLMs; however, the efficacy of data selection scales directly with its compute.\nMotivated by the practical challenge of compute-constrained finetuning, we\nconsider the setting in which both the cost of selecting data and training are\nbudgeted for. We first formalize the problem of data selection with a\ncost-aware utility function, and model the data selection problem as trading\noff initial-selection cost for training gain. We run a comprehensive sweep of\nexperiments across multiple tasks, varying compute budget by scaling finetuning\ntokens, model sizes, and data selection compute. These experiments show the\nvalidity of this model in real-world experiments. Interestingly we find that\nmany powerful data selection methods are almost never compute-optimal, and that\ncheaper data selection alternatives dominate both from a theoretical and\nempirical perspective.\n","authors":["Junjie Oscar Yin","Alexander M. Rush"],"pdf_url":"https://arxiv.org/pdf/2410.16208v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.16207v1","updated":"2024-10-21T17:10:43Z","published":"2024-10-21T17:10:43Z","title":"CoT-TL: Low-Resource Temporal Knowledge Representation of Planning\n  Instructions Using Chain-of-Thought Reasoning","summary":"  Autonomous agents often face the challenge of interpreting uncertain natural\nlanguage instructions for planning tasks. Representing these instructions as\nLinear Temporal Logic (LTL) enables planners to synthesize actionable plans. We\nintroduce CoT-TL, a data-efficient in-context learning framework for\ntranslating natural language specifications into LTL representations. CoT-TL\naddresses the limitations of large language models, which typically rely on\nextensive fine-tuning data, by extending chain-of-thought reasoning and\nsemantic roles to align with the requirements of formal logic creation. This\napproach enhances the transparency and rationale behind LTL generation,\nfostering user trust. CoT-TL achieves state-of-the-art accuracy across three\ndiverse datasets in low-data scenarios, outperforming existing methods without\nfine-tuning or intermediate translations. To improve reliability and minimize\nhallucinations, we incorporate model checking to validate the syntax of the\ngenerated LTL output. We further demonstrate CoT-TL's effectiveness through\nablation studies and evaluations on unseen LTL structures and formulas in a new\ndataset. Finally, we validate CoT-TL's practicality by integrating it into a\nQuadCopter for multi-step drone planning based on natural language\ninstructions.\n","authors":["Kumar Manas","Stefan Zwicklbauer","Adrian Paschke"],"pdf_url":"https://arxiv.org/pdf/2410.16207v1.pdf","comment":"Accepted for publication in Proceedings of the 2024 IEEE/RSJ\n  International Conference on Intelligent Robots and Systems (IROS 2024), Abu\n  Dhabi 14-18 October 2024"},{"id":"http://arxiv.org/abs/2410.16204v1","updated":"2024-10-21T17:05:50Z","published":"2024-10-21T17:05:50Z","title":"Systematic Review: Text Processing Algorithms in Machine Learning and\n  Deep Learning for Mental Health Detection on Social Media","summary":"  The global rise in depression necessitates innovative detection methods for\nearly intervention. Social media provides a unique opportunity to identify\ndepression through user-generated posts. This systematic review evaluates\nmachine learning (ML) models for depression detection on social media, focusing\non biases and methodological challenges throughout the ML lifecycle. A search\nof PubMed, IEEE Xplore, and Google Scholar identified 47 relevant studies\npublished after 2010. The Prediction model Risk Of Bias ASsessment Tool\n(PROBAST) was utilized to assess methodological quality and risk of bias.\nSignificant biases impacting model reliability and generalizability were found.\nThere is a predominant reliance on Twitter (63.8%) and English-language content\n(over 90%), with most studies focusing on users from the United States and\nEurope. Non-probability sampling methods (approximately 80%) limit\nrepresentativeness. Only 23% of studies explicitly addressed linguistic nuances\nlike negations, crucial for accurate sentiment analysis. Inconsistent\nhyperparameter tuning was observed, with only 27.7% properly tuning models.\nAbout 17% did not adequately partition data into training, validation, and test\nsets, risking overfitting. While 74.5% used appropriate evaluation metrics for\nimbalanced data, others relied on accuracy without addressing class imbalance,\npotentially skewing results. Reporting transparency varied, often lacking\ncritical methodological details. These findings highlight the need to diversify\ndata sources, standardize preprocessing protocols, ensure consistent model\ndevelopment practices, address class imbalance, and enhance reporting\ntransparency. By overcoming these challenges, future research can develop more\nrobust and generalizable ML models for depression detection on social media,\ncontributing to improved mental health outcomes globally.\n","authors":["Yuchen Cao","Jianglai Dai","Zhongyan Wang","Yeyubei Zhang","Xiaorui Shen","Yunchong Liu","Yexin Tian"],"pdf_url":"https://arxiv.org/pdf/2410.16204v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2405.19323v2","updated":"2024-10-21T17:05:15Z","published":"2024-05-29T17:54:22Z","title":"Are Large Language Models Chameleons? An Attempt to Simulate Social\n  Surveys","summary":"  Can large language models (LLMs) simulate social surveys? To answer this\nquestion, we conducted millions of simulations in which LLMs were asked to\nanswer subjective questions. A comparison of different LLM responses with the\nEuropean Social Survey (ESS) data suggests that the effect of prompts on bias\nand variability is fundamental, highlighting major cultural, age, and gender\nbiases. We further discussed statistical methods for measuring the difference\nbetween LLM answers and survey data and proposed a novel measure inspired by\nJaccard similarity, as LLM-generated responses are likely to have a smaller\nvariance. Our experiments also reveal that it is important to analyze the\nrobustness and variability of prompts before using LLMs to simulate social\nsurveys, as their imitation abilities are approximate at best.\n","authors":["Mingmeng Geng","Sihong He","Roberto Trotta"],"pdf_url":"https://arxiv.org/pdf/2405.19323v2.pdf","comment":"17 pages"},{"id":"http://arxiv.org/abs/2410.16196v1","updated":"2024-10-21T16:59:25Z","published":"2024-10-21T16:59:25Z","title":"Information for Conversation Generation: Proposals Utilising Knowledge\n  Graphs","summary":"  LLMs are frequently used tools for conversational generation. Without\nadditional information LLMs can generate lower quality responses due to lacking\nrelevant content and hallucinations, as well as the perception of poor\nemotional capability, and an inability to maintain a consistent character.\nKnowledge graphs are commonly used forms of external knowledge and may provide\nsolutions to these challenges. This paper introduces three proposals, utilizing\nknowledge graphs to enhance LLM generation. Firstly, dynamic knowledge graph\nembeddings and recommendation could allow for the integration of new\ninformation and the selection of relevant knowledge for response generation.\nSecondly, storing entities with emotional values as additional features may\nprovide knowledge that is better emotionally aligned with the user input.\nThirdly, integrating character information through narrative bubbles would\nmaintain character consistency, as well as introducing a structure that would\nreadily incorporate new information.\n","authors":["Alex Clay","Ernesto Jiménez-Ruiz"],"pdf_url":"https://arxiv.org/pdf/2410.16196v1.pdf","comment":"7 pages with citations, 1 figure, accepted to the ISWC 2024 Special\n  Session"},{"id":"http://arxiv.org/abs/2406.13791v3","updated":"2024-10-21T16:55:31Z","published":"2024-06-19T19:35:14Z","title":"IoT-Based Preventive Mental Health Using Knowledge Graphs and Standards\n  for Better Well-Being","summary":"  Sustainable Development Goals (SDGs) give the UN a road map for development\nwith Agenda 2030 as a target. SDG3 \"Good Health and Well-Being\" ensures healthy\nlives and promotes well-being for all ages. Digital technologies can support\nSDG3. Burnout and even depression could be reduced by encouraging better\npreventive health. Due to the lack of patient knowledge and focus to take care\nof their health, it is necessary to help patients before it is too late. New\ntrends such as positive psychology and mindfulness are highly encouraged in the\nUSA. Digital Twins (DTs) can help with the continuous monitoring of emotion\nusing physiological signals (e.g., collected via wearables). DTs facilitate\nmonitoring and provide constant health insight to improve quality of life and\nwell-being with better personalization. Healthcare DTs challenges are\nstandardizing data formats, communication protocols, and data exchange\nmechanisms. As an example, ISO has the ISO/IEC JTC 1/SC 41 Internet of Things\n(IoT) and DTs Working Group, with standards such as \"ISO/IEC 21823-3:2021 IoT -\nInteroperability for IoT Systems - Part 3 Semantic interoperability\", \"ISO/IEC\nCD 30178 - IoT - Data format, value and coding\". To achieve those data\nintegration and knowledge challenges, we designed the Mental Health Knowledge\nGraph (ontology and dataset) to boost mental health. As an example, explicit\nknowledge is described such as chocolate contains magnesium which is\nrecommended for depression. The Knowledge Graph (KG) acquires knowledge from\nontology-based mental health projects classified within the LOV4IoT ontology\ncatalog (Emotion, Depression, and Mental Health). Furthermore, the KG is mapped\nto standards when possible. Standards from ETSI SmartM2M can be used such as\nSAREF4EHAW to represent medical devices and sensors, but also ITU/WHO, ISO,\nW3C, NIST, and IEEE standards relevant to mental health can be considered.\n","authors":["Amelie Gyrard","Seyedali Mohammadi","Manas Gaur","Antonio Kung"],"pdf_url":"https://arxiv.org/pdf/2406.13791v3.pdf","comment":"20 pages, Book chapter, Smart Technologies for Achieving Good Health\n  and Well-Being: Towards Sustainable Development Goal, Taylor & Francis"},{"id":"http://arxiv.org/abs/2410.16186v1","updated":"2024-10-21T16:49:35Z","published":"2024-10-21T16:49:35Z","title":"Contamination Report for Multilingual Benchmarks","summary":"  Benchmark contamination refers to the presence of test datasets in Large\nLanguage Model (LLM) pre-training or post-training data. Contamination can lead\nto inflated scores on benchmarks, compromising evaluation results and making it\ndifficult to determine the capabilities of models. In this work, we study the\ncontamination of popular multilingual benchmarks in LLMs that support multiple\nlanguages. We use the Black Box test to determine whether $7$ frequently used\nmultilingual benchmarks are contaminated in $7$ popular open and closed LLMs\nand find that almost all models show signs of being contaminated with almost\nall the benchmarks we test. Our findings can help the community determine the\nbest set of benchmarks to use for multilingual evaluation.\n","authors":["Sanchit Ahuja","Varun Gumma","Sunayana Sitaram"],"pdf_url":"https://arxiv.org/pdf/2410.16186v1.pdf","comment":"11 pages, 2 tables"},{"id":"http://arxiv.org/abs/2410.16184v1","updated":"2024-10-21T16:48:26Z","published":"2024-10-21T16:48:26Z","title":"RM-Bench: Benchmarking Reward Models of Language Models with Subtlety\n  and Style","summary":"  Reward models are critical in techniques like Reinforcement Learning from\nHuman Feedback (RLHF) and Inference Scaling Laws, where they guide language\nmodel alignment and select optimal responses. Despite their importance,\nexisting reward model benchmarks often evaluate models by asking them to\ndistinguish between responses generated by models of varying power. However,\nthis approach fails to assess reward models on subtle but critical content\nchanges and variations in style, resulting in a low correlation with policy\nmodel performance. To this end, we introduce RM-Bench, a novel benchmark\ndesigned to evaluate reward models based on their sensitivity to subtle content\ndifferences and resistance to style biases. Extensive experiments demonstrate\nthat RM-Bench strongly correlates with policy model performance, making it a\nreliable reference for selecting reward models to align language models\neffectively. We evaluate nearly 40 reward models on RM-Bench. Our results\nreveal that even state-of-the-art models achieve an average performance of only\n46.6%, which falls short of random-level accuracy (50%) when faced with style\nbias interference. These findings highlight the significant room for\nimprovement in current reward models. Related code and data are available at\nhttps://github.com/THU-KEG/RM-Bench.\n","authors":["Yantao Liu","Zijun Yao","Rui Min","Yixin Cao","Lei Hou","Juanzi Li"],"pdf_url":"https://arxiv.org/pdf/2410.16184v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.07879v3","updated":"2024-10-21T16:48:18Z","published":"2023-11-14T03:18:28Z","title":"Toxicity Detection is NOT all you Need: Measuring the Gaps to Supporting\n  Volunteer Content Moderators","summary":"  Extensive efforts in automated approaches for content moderation have been\nfocused on developing models to identify toxic, offensive, and hateful content\nwith the aim of lightening the load for moderators. Yet, it remains uncertain\nwhether improvements on those tasks have truly addressed moderators' needs in\naccomplishing their work. In this paper, we surface gaps between past research\nefforts that have aimed to provide automation for aspects of content moderation\nand the needs of volunteer content moderators, regarding identifying violations\nof various moderation rules. To do so, we conduct a model review on Hugging\nFace to reveal the availability of models to cover various moderation rules and\nguidelines from three exemplar forums. We further put state-of-the-art LLMs to\nthe test, evaluating how well these models perform in flagging violations of\nplatform rules from one particular forum. Finally, we conduct a user survey\nstudy with volunteer moderators to gain insight into their perspectives on\nuseful moderation models. Overall, we observe a non-trivial gap, as missing\ndeveloped models and LLMs exhibit moderate to low performance on a significant\nportion of the rules. Moderators' reports provide guides for future work on\ndeveloping moderation assistant models.\n","authors":["Yang Trista Cao","Lovely-Frances Domingo","Sarah Ann Gilbert","Michelle Mazurek","Katie Shilton","Hal Daumé III"],"pdf_url":"https://arxiv.org/pdf/2311.07879v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.16179v1","updated":"2024-10-21T16:44:51Z","published":"2024-10-21T16:44:51Z","title":"MagicPIG: LSH Sampling for Efficient LLM Generation","summary":"  Large language models (LLMs) with long context windows have gained\nsignificant attention. However, the KV cache, stored to avoid re-computation,\nbecomes a bottleneck. Various dynamic sparse or TopK-based attention\napproximation methods have been proposed to leverage the common insight that\nattention is sparse. In this paper, we first show that TopK attention itself\nsuffers from quality degradation in certain downstream tasks because attention\nis not always as sparse as expected. Rather than selecting the keys and values\nwith the highest attention scores, sampling with theoretical guarantees can\nprovide a better estimation for attention output. To make the sampling-based\napproximation practical in LLM generation, we propose MagicPIG, a heterogeneous\nsystem based on Locality Sensitive Hashing (LSH). MagicPIG significantly\nreduces the workload of attention computation while preserving high accuracy\nfor diverse tasks. MagicPIG stores the LSH hash tables and runs the attention\ncomputation on the CPU, which allows it to serve longer contexts and larger\nbatch sizes with high approximation accuracy. MagicPIG can improve decoding\nthroughput by $1.9\\sim3.9\\times$ across various GPU hardware and achieve 110ms\ndecoding latency on a single RTX 4090 for Llama-3.1-8B-Instruct model with a\ncontext of 96k tokens. The code is available at\n\\url{https://github.com/Infini-AI-Lab/MagicPIG}.\n","authors":["Zhuoming Chen","Ranajoy Sadhukhan","Zihao Ye","Yang Zhou","Jianyu Zhang","Niklas Nolte","Yuandong Tian","Matthijs Douze","Leon Bottou","Zhihao Jia","Beidi Chen"],"pdf_url":"https://arxiv.org/pdf/2410.16179v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.07428v2","updated":"2024-10-21T16:37:02Z","published":"2024-10-09T20:48:03Z","title":"The First VoicePrivacy Attacker Challenge Evaluation Plan","summary":"  The First VoicePrivacy Attacker Challenge is a new kind of challenge\norganized as part of the VoicePrivacy initiative and supported by ICASSP 2025\nas the SP Grand Challenge It focuses on developing attacker systems against\nvoice anonymization, which will be evaluated against a set of anonymization\nsystems submitted to the VoicePrivacy 2024 Challenge. Training, development,\nand evaluation datasets are provided along with a baseline attacker system.\nParticipants shall develop their attacker systems in the form of automatic\nspeaker verification systems and submit their scores on the development and\nevaluation data to the organizers. To do so, they can use any additional\ntraining data and models, provided that they are openly available and declared\nbefore the specified deadline. The metric for evaluation is equal error rate\n(EER). Results will be presented at the ICASSP 2025 special session to which 5\nselected top-ranked participants will be invited to submit and present their\nchallenge systems.\n","authors":["Natalia Tomashenko","Xiaoxiao Miao","Emmanuel Vincent","Junichi Yamagishi"],"pdf_url":"https://arxiv.org/pdf/2410.07428v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.16168v1","updated":"2024-10-21T16:33:16Z","published":"2024-10-21T16:33:16Z","title":"Exploring Pretraining via Active Forgetting for Improving Cross Lingual\n  Transfer for Decoder Language Models","summary":"  Large Language Models (LLMs) demonstrate exceptional capabilities in a\nmultitude of NLP tasks. However, the efficacy of such models to languages other\nthan English is often limited. Prior works have shown that encoder-only models\nsuch as BERT or XLM-RoBERTa show impressive cross lingual transfer of their\ncapabilities from English to other languages. In this work, we propose a\npretraining strategy that uses active forgetting to achieve similar cross\nlingual transfer in decoder-only LLMs. We show that LLMs pretrained with active\nforgetting are highly effective when adapting to new and unseen languages.\nThrough extensive experimentation, we find that LLMs pretrained with active\nforgetting are able to learn better multilingual representations which\ntranslates to better performance in many downstream tasks.\n","authors":["Divyanshu Aggarwal","Ashutosh Sathe","Sunayana Sitaram"],"pdf_url":"https://arxiv.org/pdf/2410.16168v1.pdf","comment":"12 pages, 11 tables, 12 figures"},{"id":"http://arxiv.org/abs/2410.16166v1","updated":"2024-10-21T16:32:41Z","published":"2024-10-21T16:32:41Z","title":"Beyond Filtering: Adaptive Image-Text Quality Enhancement for MLLM\n  Pretraining","summary":"  Multimodal large language models (MLLMs) have made significant strides by\nintegrating visual and textual modalities. A critical factor in training MLLMs\nis the quality of image-text pairs within multimodal pretraining datasets.\nHowever, $\\textit {de facto}$ filter-based data quality enhancement paradigms\noften discard a substantial portion of high-quality image data due to\ninadequate semantic alignment between images and texts, leading to\ninefficiencies in data utilization and scalability. In this paper, we propose\nthe Adaptive Image-Text Quality Enhancer (AITQE), a model that dynamically\nassesses and enhances the quality of image-text pairs. AITQE employs a text\nrewriting mechanism for low-quality pairs and incorporates a negative sample\nlearning strategy to improve evaluative capabilities by integrating\ndeliberately selected low-quality samples during training. Unlike prior\napproaches that significantly alter text distributions, our method minimally\nadjusts text to preserve data volume while enhancing quality. Experimental\nresults demonstrate that AITQE surpasses existing methods on various benchmark,\neffectively leveraging raw data and scaling efficiently with increasing data\nvolumes. We hope our work will inspire future works. The code and model are\navailable at: https://github.com/hanhuang22/AITQE.\n","authors":["Han Huang","Yuqi Huo","Zijia Zhao","Haoyu Lu","Shu Wu","Bingning Wang","Qiang Liu","Weipeng Chen","Liang Wang"],"pdf_url":"https://arxiv.org/pdf/2410.16166v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.16165v1","updated":"2024-10-21T16:31:23Z","published":"2024-10-21T16:31:23Z","title":"From Tokens to Materials: Leveraging Language Models for Scientific\n  Discovery","summary":"  Exploring the predictive capabilities of language models in material science\nis an ongoing interest. This study investigates the application of language\nmodel embeddings to enhance material property prediction in materials science.\nBy evaluating various contextual embedding methods and pre-trained models,\nincluding Bidirectional Encoder Representations from Transformers (BERT) and\nGenerative Pre-trained Transformers (GPT), we demonstrate that domain-specific\nmodels, particularly MatBERT significantly outperform general-purpose models in\nextracting implicit knowledge from compound names and material properties. Our\nfindings reveal that information-dense embeddings from the third layer of\nMatBERT, combined with a context-averaging approach, offer the most effective\nmethod for capturing material-property relationships from the scientific\nliterature. We also identify a crucial \"tokenizer effect,\" highlighting the\nimportance of specialized text processing techniques that preserve complete\ncompound names while maintaining consistent token counts. These insights\nunderscore the value of domain-specific training and tokenization in materials\nscience applications and offer a promising pathway for accelerating the\ndiscovery and development of new materials through AI-driven approaches.\n","authors":["Yuwei Wan","Tong Xie","Nan Wu","Wenjie Zhang","Chunyu Kit","Bram Hoex"],"pdf_url":"https://arxiv.org/pdf/2410.16165v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.16162v1","updated":"2024-10-21T16:26:09Z","published":"2024-10-21T16:26:09Z","title":"Sparkle: Mastering Basic Spatial Capabilities in Vision Language Models\n  Elicits Generalization to Composite Spatial Reasoning","summary":"  Vision language models (VLMs) have demonstrated impressive performance across\na wide range of downstream tasks. However, their proficiency in spatial\nreasoning remains limited, despite its crucial role in tasks involving\nnavigation and interaction with physical environments. Specifically, much of\nthe spatial reasoning in these tasks occurs in two-dimensional (2D)\nenvironments, and our evaluation reveals that state-of-the-art VLMs frequently\ngenerate implausible and incorrect responses to composite spatial reasoning\nproblems, including simple pathfinding tasks that humans can solve effortlessly\nat a glance. To address this, we explore an effective approach to enhance 2D\nspatial reasoning within VLMs by training the model on basic spatial\ncapabilities. We begin by disentangling the key components of 2D spatial\nreasoning: direction comprehension, distance estimation, and localization. Our\ncentral hypothesis is that mastering these basic spatial capabilities can\nsignificantly enhance a model's performance on composite spatial tasks\nrequiring advanced spatial understanding and combinatorial problem-solving. To\ninvestigate this hypothesis, we introduce Sparkle, a framework that fine-tunes\nVLMs on these three basic spatial capabilities by synthetic data generation and\ntargeted supervision to form an instruction dataset for each capability. Our\nexperiments demonstrate that VLMs fine-tuned with Sparkle achieve significant\nperformance gains, not only in the basic tasks themselves but also in\ngeneralizing to composite and out-of-distribution spatial reasoning tasks\n(e.g., improving from 13.5% to 40.0% on the shortest path problem). These\nfindings underscore the effectiveness of mastering basic spatial capabilities\nin enhancing composite spatial problem-solving, offering insights for improving\nVLMs' spatial reasoning capabilities.\n","authors":["Yihong Tang","Ao Qu","Zhaokai Wang","Dingyi Zhuang","Zhaofeng Wu","Wei Ma","Shenhao Wang","Yunhan Zheng","Zhan Zhao","Jinhua Zhao"],"pdf_url":"https://arxiv.org/pdf/2410.16162v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2402.13116v4","updated":"2024-10-21T16:22:33Z","published":"2024-02-20T16:17:37Z","title":"A Survey on Knowledge Distillation of Large Language Models","summary":"  In the era of Large Language Models (LLMs), Knowledge Distillation (KD)\nemerges as a pivotal methodology for transferring advanced capabilities from\nleading proprietary LLMs, such as GPT-4, to their open-source counterparts like\nLLaMA and Mistral. Additionally, as open-source LLMs flourish, KD plays a\ncrucial role in both compressing these models, and facilitating their\nself-improvement by employing themselves as teachers. This paper presents a\ncomprehensive survey of KD's role within the realm of LLM, highlighting its\ncritical function in imparting advanced knowledge to smaller models and its\nutility in model compression and self-improvement. Our survey is meticulously\nstructured around three foundational pillars: \\textit{algorithm},\n\\textit{skill}, and \\textit{verticalization} -- providing a comprehensive\nexamination of KD mechanisms, the enhancement of specific cognitive abilities,\nand their practical implications across diverse fields. Crucially, the survey\nnavigates the intricate interplay between data augmentation (DA) and KD,\nillustrating how DA emerges as a powerful paradigm within the KD framework to\nbolster LLMs' performance. By leveraging DA to generate context-rich,\nskill-specific training data, KD transcends traditional boundaries, enabling\nopen-source models to approximate the contextual adeptness, ethical alignment,\nand deep semantic insights characteristic of their proprietary counterparts.\nThis work aims to provide an insightful guide for researchers and\npractitioners, offering a detailed overview of current methodologies in KD and\nproposing future research directions. Importantly, we firmly advocate for\ncompliance with the legal terms that regulate the use of LLMs, ensuring ethical\nand lawful application of KD of LLMs. An associated Github repository is\navailable at https://github.com/Tebmer/Awesome-Knowledge-Distillation-of-LLMs.\n","authors":["Xiaohan Xu","Ming Li","Chongyang Tao","Tao Shen","Reynold Cheng","Jinyang Li","Can Xu","Dacheng Tao","Tianyi Zhou"],"pdf_url":"https://arxiv.org/pdf/2402.13116v4.pdf","comment":"43 pages"},{"id":"http://arxiv.org/abs/2410.16156v1","updated":"2024-10-21T16:21:45Z","published":"2024-10-21T16:21:45Z","title":"Limpeh ga li gong: Challenges in Singlish Annotations","summary":"  Singlish, or Colloquial Singapore English, is a language formed from oral and\nsocial communication within multicultural Singapore. In this work, we work on a\nfundamental Natural Language Processing (NLP) task: Parts-Of-Speech (POS)\ntagging of Singlish sentences. For our analysis, we build a parallel Singlish\ndataset containing direct English translations and POS tags, with translation\nand POS annotation done by native Singlish speakers. Our experiments show that\nautomatic transition- and transformer- based taggers perform with only $\\sim\n80\\%$ accuracy when evaluated against human-annotated POS labels, suggesting\nthat there is indeed room for improvement on computation analysis of the\nlanguage. We provide an exposition of challenges in Singlish annotation: its\ninconsistencies in form and semantics, the highly context-dependent particles\nof the language, its structural unique expressions, and the variation of the\nlanguage on different mediums. Our task definition, resultant labels and\nresults reflects the challenges in analysing colloquial languages formulated\nfrom a variety of dialects, and paves the way for future studies beyond POS\ntagging.\n","authors":["Lynnette Hui Xian Ng","Luo Qi Chan"],"pdf_url":"https://arxiv.org/pdf/2410.16156v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.16155v1","updated":"2024-10-21T16:21:24Z","published":"2024-10-21T16:21:24Z","title":"A Troublemaker with Contagious Jailbreak Makes Chaos in Honest Towns","summary":"  With the development of large language models, they are widely used as agents\nin various fields. A key component of agents is memory, which stores vital\ninformation but is susceptible to jailbreak attacks. Existing research mainly\nfocuses on single-agent attacks and shared memory attacks. However, real-world\nscenarios often involve independent memory. In this paper, we propose the\nTroublemaker Makes Chaos in Honest Town (TMCHT) task, a large-scale,\nmulti-agent, multi-topology text-based attack evaluation framework. TMCHT\ninvolves one attacker agent attempting to mislead an entire society of agents.\nWe identify two major challenges in multi-agent attacks: (1) Non-complete graph\nstructure, (2) Large-scale systems. We attribute these challenges to a\nphenomenon we term toxicity disappearing. To address these issues, we propose\nan Adversarial Replication Contagious Jailbreak (ARCJ) method, which optimizes\nthe retrieval suffix to make poisoned samples more easily retrieved and\noptimizes the replication suffix to make poisoned samples have contagious\nability. We demonstrate the superiority of our approach in TMCHT, with 23.51%,\n18.95%, and 52.93% improvements in line topology, star topology, and 100-agent\nsettings. Encourage community attention to the security of multi-agent systems.\n","authors":["Tianyi Men","Pengfei Cao","Zhuoran Jin","Yubo Chen","Kang Liu","Jun Zhao"],"pdf_url":"https://arxiv.org/pdf/2410.16155v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.16153v1","updated":"2024-10-21T16:19:41Z","published":"2024-10-21T16:19:41Z","title":"Pangea: A Fully Open Multilingual Multimodal LLM for 39 Languages","summary":"  Despite recent advances in multimodal large language models (MLLMs), their\ndevelopment has predominantly focused on English- and western-centric datasets\nand tasks, leaving most of the world's languages and diverse cultural contexts\nunderrepresented. This paper introduces Pangea, a multilingual multimodal LLM\ntrained on PangeaIns, a diverse 6M instruction dataset spanning 39 languages.\nPangeaIns features: 1) high-quality English instructions, 2) carefully\nmachine-translated instructions, and 3) culturally relevant multimodal tasks to\nensure cross-cultural coverage. To rigorously assess models' capabilities, we\nintroduce PangeaBench, a holistic evaluation suite encompassing 14 datasets\ncovering 47 languages. Results show that Pangea significantly outperforms\nexisting open-source models in multilingual settings and diverse cultural\ncontexts. Ablation studies further reveal the importance of English data\nproportions, language popularity, and the number of multimodal training samples\non overall performance. We fully open-source our data, code, and trained\ncheckpoints, to facilitate the development of inclusive and robust multilingual\nMLLMs, promoting equity and accessibility across a broader linguistic and\ncultural spectrum.\n","authors":["Xiang Yue","Yueqi Song","Akari Asai","Seungone Kim","Jean de Dieu Nyandwi","Simran Khanuja","Anjali Kantharuban","Lintang Sutawika","Sathyanarayanan Ramamoorthy","Graham Neubig"],"pdf_url":"https://arxiv.org/pdf/2410.16153v1.pdf","comment":"52 pages, 27 figures"},{"id":"http://arxiv.org/abs/2405.18406v2","updated":"2024-10-21T16:18:37Z","published":"2024-05-28T17:46:36Z","title":"RACCooN: A Versatile Instructional Video Editing Framework with\n  Auto-Generated Narratives","summary":"  Recent video generative models primarily rely on carefully written text\nprompts for specific tasks, like inpainting or style editing. They require\nlabor-intensive textual descriptions for input videos, hindering their\nflexibility to adapt personal/raw videos to user specifications. This paper\nproposes RACCooN, a versatile and user-friendly video-to-paragraph-to-video\ngenerative framework that supports multiple video editing capabilities such as\nremoval, addition, and modification, through a unified pipeline. RACCooN\nconsists of two principal stages: Video-to-Paragraph (V2P) and\nParagraph-to-Video (P2V). In the V2P stage, we automatically describe video\nscenes in well-structured natural language, capturing both the holistic context\nand focused object details. Subsequently, in the P2V stage, users can\noptionally refine these descriptions to guide the video diffusion model,\nenabling various modifications to the input video, such as removing, changing\nsubjects, and/or adding new objects. The proposed approach stands out from\nother methods through several significant contributions: (1) RACCooN suggests a\nmulti-granular spatiotemporal pooling strategy to generate well-structured\nvideo descriptions, capturing both the broad context and object details without\nrequiring complex human annotations, simplifying precise video content editing\nbased on text for users. (2) Our video generative model incorporates\nauto-generated narratives or instructions to enhance the quality and accuracy\nof the generated content. (3) RACCooN also plans to imagine new objects in a\ngiven video, so users simply prompt the model to receive a detailed video\nediting plan for complex video editing. The proposed framework demonstrates\nimpressive versatile capabilities in video-to-paragraph generation, video\ncontent editing, and can be incorporated into other SoTA video generative\nmodels for further enhancement.\n","authors":["Jaehong Yoon","Shoubin Yu","Mohit Bansal"],"pdf_url":"https://arxiv.org/pdf/2405.18406v2.pdf","comment":"The first two authors contribute equally. Project Page:\n  https://raccoon-mllm-gen.github.io/"},{"id":"http://arxiv.org/abs/2410.16144v1","updated":"2024-10-21T16:14:57Z","published":"2024-10-21T16:14:57Z","title":"1-bit AI Infra: Part 1.1, Fast and Lossless BitNet b1.58 Inference on\n  CPUs","summary":"  Recent advances in 1-bit Large Language Models (LLMs), such as BitNet and\nBitNet b1.58, present a promising approach to enhancing the efficiency of LLMs\nin terms of speed and energy consumption. These developments also enable local\nLLM deployment across a broad range of devices. In this work, we introduce\nbitnet.cpp, a tailored software stack designed to unlock the full potential of\n1-bit LLMs. Specifically, we develop a set of kernels to support fast and\nlossless inference of ternary BitNet b1.58 LLMs on CPUs. Extensive experiments\ndemonstrate that bitnet.cpp achieves significant speedups, ranging from 2.37x\nto 6.17x on x86 CPUs and from 1.37x to 5.07x on ARM CPUs, across various model\nsizes. The code is available at https://github.com/microsoft/BitNet.\n","authors":["Jinheng Wang","Hansong Zhou","Ting Song","Shaoguang Mao","Shuming Ma","Hongyu Wang","Yan Xia","Furu Wei"],"pdf_url":"https://arxiv.org/pdf/2410.16144v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.16139v1","updated":"2024-10-21T16:05:58Z","published":"2024-10-21T16:05:58Z","title":"A Psycholinguistic Evaluation of Language Models' Sensitivity to\n  Argument Roles","summary":"  We present a systematic evaluation of large language models' sensitivity to\nargument roles, i.e., who did what to whom, by replicating psycholinguistic\nstudies on human argument role processing. In three experiments, we find that\nlanguage models are able to distinguish verbs that appear in plausible and\nimplausible contexts, where plausibility is determined through the relation\nbetween the verb and its preceding arguments. However, none of the models\ncapture the same selective patterns that human comprehenders exhibit during\nreal-time verb prediction. This indicates that language models' capacity to\ndetect verb plausibility does not arise from the same mechanism that underlies\nhuman real-time sentence processing.\n","authors":["Eun-Kyoung Rosa Lee","Sathvik Nair","Naomi Feldman"],"pdf_url":"https://arxiv.org/pdf/2410.16139v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.14134v2","updated":"2024-10-21T15:59:18Z","published":"2024-08-26T09:29:56Z","title":"Exploring the Potential of Large Language Models for Heterophilic Graphs","summary":"  Large language models (LLMs) have presented significant opportunities to\nenhance various machine learning applications, including graph neural networks\n(GNNs). By leveraging the vast open-world knowledge within LLMs, we can more\neffectively interpret and utilize textual data to better characterize\nheterophilic graphs, where neighboring nodes often have different labels.\nHowever, existing approaches for heterophilic graphs overlook the rich textual\ndata associated with nodes, which could unlock deeper insights into their\nheterophilic contexts. In this work, we explore the potential of LLMs for\nmodeling heterophilic graphs and propose a novel two-stage framework:\nLLM-enhanced edge discriminator and LLM-guided edge reweighting. In the first\nstage, we fine-tune the LLM to better identify homophilic and heterophilic\nedges based on the textual content of their nodes. In the second stage, we\nadaptively manage message propagation in GNNs for different edge types based on\nnode features, structures, and heterophilic or homophilic characteristics. To\ncope with the computational demands when deploying LLMs in practical scenarios,\nwe further explore model distillation techniques to fine-tune smaller, more\nefficient models that maintain competitive performance. Extensive experiments\nvalidate the effectiveness of our framework, demonstrating the feasibility of\nusing LLMs to enhance node classification on heterophilic graphs.\n","authors":["Yuxia Wu","Shujie Li","Yuan Fang","Chuan Shi"],"pdf_url":"https://arxiv.org/pdf/2408.14134v2.pdf","comment":"Under review"},{"id":"http://arxiv.org/abs/2409.13761v2","updated":"2024-10-21T15:59:18Z","published":"2024-09-16T18:46:24Z","title":"Do Large Language Models Need a Content Delivery Network?","summary":"  As the use of large language models (LLMs) expands rapidly, so does the range\nof knowledge needed to supplement various LLM queries. Thus, enabling flexible\nand efficient injection of new knowledge in LLM inference is critical. Three\nhigh-level options exist: (i) embedding the knowledge in LLM's weights (i.e.,\nfine-tuning), (ii) including the knowledge as a part of LLM's text input (i.e.,\nin-context learning), or (iii) injecting the KV caches of the new knowledge to\nLLM during prefill. This paper argues that, although fine-tuning and in-context\nlearning are popular, using KV caches as the medium of knowledge could\nsimultaneously enable more modular management of knowledge injection and more\nefficient LLM serving with low cost and fast response. To realize these\nbenefits, we envision a Knowledge Delivery Network (KDN), a new system\ncomponent in LLM services that dynamically optimizes the storage, transfer, and\ncomposition of KV cache across LLM engines and other compute and storage\nresources. We believe that, just like content delivery networks (CDNs), such as\nAkamai, enabled the success of the Internet ecosystem through their efficient\ndata delivery, KDNs will be critical to the success of LLM applications through\ntheir efficient knowledge delivery. We have open-sourced a KDN prototype at\nhttps://github.com/LMCache/LMCache.\n","authors":["Yihua Cheng","Kuntai Du","Jiayi Yao","Junchen Jiang"],"pdf_url":"https://arxiv.org/pdf/2409.13761v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.13502v2","updated":"2024-10-21T15:58:30Z","published":"2024-10-17T12:48:14Z","title":"MathGAP: Out-of-Distribution Evaluation on Problems with Arbitrarily\n  Complex Proofs","summary":"  Large language models (LLMs) can solve arithmetic word problems with high\naccuracy, but little is known about how well they generalize to problems that\nare more complex than the ones on which they have been trained. Empirical\ninvestigations of such questions are impeded by two major flaws of current\nevaluations: (i) much of the evaluation data is contaminated, in the sense that\nit has already been seen during training, and (ii) benchmark datasets do not\ncapture how problem proofs may be arbitrarily complex in various ways. As a\nstep towards addressing these issues, we present a framework for evaluating\nLLMs on problems with arbitrarily complex arithmetic proofs, called MathGAP.\nMathGAP generates problems that follow fixed proof specifications -- along with\nchain-of-thought reasoning annotations -- enabling systematic studies on\ngeneralization with respect to arithmetic proof complexity. We apply MathGAP to\nanalyze how in-context learning interacts with generalization to problems that\nhave more complex proofs. We find that among the models tested, most show a\nsignificant decrease in performance as proofs get deeper and wider. This effect\nis more pronounced in complex, nonlinear proof structures, which are\nchallenging even for GPT-4o. Surprisingly, providing in-context examples from\nthe same distribution as the test set is not always beneficial for performance.\nIn particular, zero-shot prompting as well as demonstrating a diverse range of\nexamples that are less complex than the test data sometimes yield similar or\nhigher accuracies.\n","authors":["Andreas Opedal","Haruki Shirakami","Bernhard Schölkopf","Abulhair Saparov","Mrinmaya Sachan"],"pdf_url":"https://arxiv.org/pdf/2410.13502v2.pdf","comment":"Preprint"},{"id":"http://arxiv.org/abs/2410.16130v1","updated":"2024-10-21T15:55:27Z","published":"2024-10-21T15:55:27Z","title":"Can Large Audio-Language Models Truly Hear? Tackling Hallucinations with\n  Multi-Task Assessment and Stepwise Audio Reasoning","summary":"  Recent advancements in large audio-language models (LALMs) have shown\nimpressive capabilities in understanding and reasoning about audio and speech\ninformation. However, these models still face challenges, including\nhallucinating non-existent sound events, misidentifying the order of sound\nevents, and incorrectly attributing sound sources, which undermine their\nreliability and real-world application. To systematically evaluate these\nissues, we propose three distinct tasks: object existence, temporal order, and\nobject attribute within audio. These tasks assess the models' comprehension of\ncritical audio information aspects. Our experimental results reveal limitations\nin these fundamental tasks, underscoring the need for better models in\nrecognizing specific sound events, determining event sequences, and identifying\nsound sources. To improve performance in these areas, we introduce a multi-turn\nchain-of-thought approach, which demonstrates significantly improved model\nperformance across the proposed tasks.\n","authors":["Chun-Yi Kuan","Hung-yi Lee"],"pdf_url":"https://arxiv.org/pdf/2410.16130v1.pdf","comment":"5 pages, 1 figure"},{"id":"http://arxiv.org/abs/2410.13073v2","updated":"2024-10-21T15:54:34Z","published":"2024-10-16T22:25:15Z","title":"PromptExp: Multi-granularity Prompt Explanation of Large Language Models","summary":"  Large Language Models excel in tasks like natural language understanding and\ntext generation. Prompt engineering plays a critical role in leveraging LLM\neffectively. However, LLMs black-box nature hinders its interpretability and\neffective prompting engineering. A wide range of model explanation approaches\nhave been developed for deep learning models, However, these local explanations\nare designed for single-output tasks like classification and regression,and\ncannot be directly applied to LLMs, which generate sequences of tokens. Recent\nefforts in LLM explanation focus on natural language explanations, but they are\nprone to hallucinations and inaccuracies. To address this, we introduce\nOurTool, a framework for multi-granularity prompt explanations by aggregating\ntoken-level insights. OurTool introduces two token-level explanation\napproaches: 1.an aggregation-based approach combining local explanation\ntechniques, and 2. a perturbation-based approach with novel techniques to\nevaluate token masking impact. OurTool supports both white-box and black-box\nexplanations and extends explanations to higher granularity levels, enabling\nflexible analysis. We evaluate OurTool in case studies such as sentiment\nanalysis, showing the perturbation-based approach performs best using semantic\nsimilarity to assess perturbation impact. Furthermore, we conducted a user\nstudy to confirm OurTool's accuracy and practical value, and demonstrate its\npotential to enhance LLM interpretability.\n","authors":["Ximing Dong","Shaowei Wang","Dayi Lin","Gopi Krishnan Rajbahadur","Boquan Zhou","Shichao Liu","Ahmed E. Hassan"],"pdf_url":"https://arxiv.org/pdf/2410.13073v2.pdf","comment":"11 pages"},{"id":"http://arxiv.org/abs/2407.15711v2","updated":"2024-10-21T15:45:31Z","published":"2024-07-22T15:18:45Z","title":"AssistantBench: Can Web Agents Solve Realistic and Time-Consuming Tasks?","summary":"  Language agents, built on top of language models (LMs), are systems that can\ninteract with complex environments, such as the open web. In this work, we\nexamine whether such agents can perform realistic and time-consuming tasks on\nthe web, e.g., monitoring real-estate markets or locating relevant nearby\nbusinesses. We introduce AssistantBench, a challenging new benchmark consisting\nof 214 realistic tasks that can be automatically evaluated, covering different\nscenarios and domains. We find that AssistantBench exposes the limitations of\ncurrent systems, including language models and retrieval-augmented language\nmodels, as no model reaches an accuracy of more than 26 points. While\nclosed-book LMs perform well in terms of accuracy, they exhibit low precision\nand tend to hallucinate facts. State-of-the-art web agents reach a score of\nnear zero. Additionally, we introduce SeePlanAct (SPA), a new web agent that\nsignificantly outperforms previous agents, and an ensemble of SPA and\nclosed-book models reaches the best overall performance. Moreover, we analyze\nfailures of current systems and highlight that open web navigation remains a\nmajor challenge.\n","authors":["Ori Yoran","Samuel Joseph Amouyal","Chaitanya Malaviya","Ben Bogin","Ofir Press","Jonathan Berant"],"pdf_url":"https://arxiv.org/pdf/2407.15711v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.16107v1","updated":"2024-10-21T15:35:44Z","published":"2024-10-21T15:35:44Z","title":"Do LLMs write like humans? Variation in grammatical and rhetorical\n  styles","summary":"  Large language models (LLMs) are capable of writing grammatical text that\nfollows instructions, answers questions, and solves problems. As they have\nadvanced, it has become difficult to distinguish their output from\nhuman-written text. While past research has found some differences in surface\nfeatures such as word choice and punctuation, and developed classifiers to\ndetect LLM output, none has studied the rhetorical styles of LLMs.\n  Using several variants of Llama 3 and GPT-4o, we construct two parallel\ncorpora of human- and LLM-written texts from common prompts. Using Douglas\nBiber's set of lexical, grammatical, and rhetorical features, we identify\nsystematic differences between LLMs and humans and between different LLMs.\nThese differences persist when moving from smaller models to larger ones, and\nare larger for instruction-tuned models than base models. This demonstrates\nthat despite their advanced abilities, LLMs struggle to match human styles, and\nhence more advanced linguistic features can detect patterns in their behavior\nnot previously recognized.\n","authors":["Alex Reinhart","David West Brown","Ben Markey","Michael Laudenbach","Kachatad Pantusen","Ronald Yurko","Gordon Weinberg"],"pdf_url":"https://arxiv.org/pdf/2410.16107v1.pdf","comment":"29 pages, 4 figures, 11 tables"},{"id":"http://arxiv.org/abs/2409.08160v3","updated":"2024-10-21T15:22:58Z","published":"2024-09-12T15:52:22Z","title":"On the Role of Context in Reading Time Prediction","summary":"  We present a new perspective on how readers integrate context during\nreal-time language comprehension. Our proposals build on surprisal theory,\nwhich posits that the processing effort of a linguistic unit (e.g., a word) is\nan affine function of its in-context information content. We first observe that\nsurprisal is only one out of many potential ways that a contextual predictor\ncan be derived from a language model. Another one is the pointwise mutual\ninformation (PMI) between a unit and its context, which turns out to yield the\nsame predictive power as surprisal when controlling for unigram frequency.\nMoreover, both PMI and surprisal are correlated with frequency. This means that\nneither PMI nor surprisal contains information about context alone. In response\nto this, we propose a technique where we project surprisal onto the orthogonal\ncomplement of frequency, yielding a new contextual predictor that is\nuncorrelated with frequency. Our experiments show that the proportion of\nvariance in reading times explained by context is a lot smaller when context is\nrepresented by the orthogonalized predictor. From an interpretability\nstandpoint, this indicates that previous studies may have overstated the role\nthat context has in predicting reading times.\n","authors":["Andreas Opedal","Eleanor Chodroff","Ryan Cotterell","Ethan Gotlieb Wilcox"],"pdf_url":"https://arxiv.org/pdf/2409.08160v3.pdf","comment":"EMNLP 2024"},{"id":"http://arxiv.org/abs/2401.05072v2","updated":"2024-10-21T15:19:41Z","published":"2024-01-10T11:03:53Z","title":"Aligning Translation-Specific Understanding to General Understanding in\n  Large Language Models","summary":"  Large Language models (LLMs) have exhibited remarkable abilities in\nunderstanding complex texts, offering a promising path towards human-like\ntranslation performance. However, this study reveals the misalignment between\nthe translation-specific understanding and the general understanding inside\nLLMs. This understanding misalignment leads to LLMs mistakenly or literally\ntranslating some complicated concepts that they accurately comprehend in the\ngeneral scenarios (e.g., QA). To align the translation-specific understanding\nto the general one, we propose a novel translation process, DUAT (Difficult\nwords Understanding Aligned Translation), explicitly incorporating the general\nunderstanding on the complicated content incurring inconsistent understanding\nto guide the translation. Specifically, DUAT performs cross-lingual\ninterpretation for the difficult-to-translate words and enhances the\ntranslation with the generated interpretations. Furthermore, we reframe the\nexternal tools to improve DUAT in detecting difficult words and generating\nhelpful interpretations. We conduct experiments on the self-constructed\nbenchmark Challenge-WMT, consisting of samples that are prone to\nmistranslation. Human evaluation results on high-resource and low-resource\nlanguage pairs indicate that DUAT significantly facilitates the understanding\nalignment, which improves the translation quality (up to +3.85 COMET) and\nreduces the literality of the translation by -25% to -51%.\n","authors":["Yichong Huang","Baohang Li","Xiaocheng Feng","Chengpeng Fu","Wenshuai Huo","Ting Liu","Bing Qin"],"pdf_url":"https://arxiv.org/pdf/2401.05072v2.pdf","comment":"EMNLP2024 (Main)"},{"id":"http://arxiv.org/abs/2410.16090v1","updated":"2024-10-21T15:12:51Z","published":"2024-10-21T15:12:51Z","title":"Analysing the Residual Stream of Language Models Under Knowledge\n  Conflicts","summary":"  Large language models (LLMs) can store a significant amount of factual\nknowledge in their parameters. However, their parametric knowledge may conflict\nwith the information provided in the context. Such conflicts can lead to\nundesirable model behaviour, such as reliance on outdated or incorrect\ninformation. In this work, we investigate whether LLMs can identify knowledge\nconflicts and whether it is possible to know which source of knowledge the\nmodel will rely on by analysing the residual stream of the LLM. Through probing\ntasks, we find that LLMs can internally register the signal of knowledge\nconflict in the residual stream, which can be accurately detected by probing\nthe intermediate model activations. This allows us to detect conflicts within\nthe residual stream before generating the answers without modifying the input\nor model parameters. Moreover, we find that the residual stream shows\nsignificantly different patterns when the model relies on contextual knowledge\nversus parametric knowledge to resolve conflicts. This pattern can be employed\nto estimate the behaviour of LLMs when conflict happens and prevent unexpected\nanswers before producing the answers. Our analysis offers insights into how\nLLMs internally manage knowledge conflicts and provides a foundation for\ndeveloping methods to control the knowledge selection processes.\n","authors":["Yu Zhao","Xiaotang Du","Giwon Hong","Aryo Pradipta Gema","Alessio Devoto","Hongru Wang","Xuanli He","Kam-Fai Wong","Pasquale Minervini"],"pdf_url":"https://arxiv.org/pdf/2410.16090v1.pdf","comment":"Foundation Model Interventions Workshop @ NeurIPS 2024"},{"id":"http://arxiv.org/abs/2410.16088v1","updated":"2024-10-21T15:12:20Z","published":"2024-10-21T15:12:20Z","title":"Fine-Tuning LLMs for Reliable Medical Question-Answering Services","summary":"  We present an advanced approach to medical question-answering (QA) services,\nusing fine-tuned Large Language Models (LLMs) to improve the accuracy and\nreliability of healthcare information. Our study focuses on optimizing models\nlike LLaMA-2 and Mistral, which have shown great promise in delivering precise,\nreliable medical answers. By leveraging comprehensive datasets, we applied\nfine-tuning techniques such as rsDoRA+ and ReRAG. rsDoRA+ enhances model\nperformance through a combination of decomposed model weights, varied learning\nrates for low-rank matrices, and rank stabilization, leading to improved\nefficiency. ReRAG, which integrates retrieval on demand and question rewriting,\nfurther refines the accuracy of the responses. This approach enables healthcare\nproviders to access fast, dependable information, aiding in more efficient\ndecision-making and fostering greater patient trust. Our work highlights the\npotential of fine-tuned LLMs to significantly improve the quality and\naccessibility of medical information services, ultimately contributing to\nbetter healthcare outcomes for all.\n","authors":["Ali Anaissi","Ali Braytee","Junaid Akram"],"pdf_url":"https://arxiv.org/pdf/2410.16088v1.pdf","comment":"8 pages, 10 figures, accepted and to be published in the proceedings\n  of 2024 IEEE International Conference on Data Mining Workshops (ICDMW)"},{"id":"http://arxiv.org/abs/2405.11459v2","updated":"2024-10-21T15:10:20Z","published":"2024-05-19T06:00:36Z","title":"Du-IN: Discrete units-guided mask modeling for decoding speech from\n  Intracranial Neural signals","summary":"  Invasive brain-computer interfaces with Electrocorticography (ECoG) have\nshown promise for high-performance speech decoding in medical applications, but\nless damaging methods like intracranial stereo-electroencephalography (sEEG)\nremain underexplored. With rapid advances in representation learning,\nleveraging abundant recordings to enhance speech decoding is increasingly\nattractive. However, popular methods often pre-train temporal models based on\nbrain-level tokens, overlooking that brain activities in different regions are\nhighly desynchronized during tasks. Alternatively, they pre-train\nspatial-temporal models based on channel-level tokens but fail to evaluate them\non challenging tasks like speech decoding, which requires intricate processing\nin specific language-related areas. To address this issue, we collected a\nwell-annotated Chinese word-reading sEEG dataset targeting language-related\nbrain networks from 12 subjects. Using this benchmark, we developed the Du-IN\nmodel, which extracts contextual embeddings based on region-level tokens\nthrough discrete codex-guided mask modeling. Our model achieves\nstate-of-the-art performance on the 61-word classification task, surpassing all\nbaselines. Model comparisons and ablation studies reveal that our design\nchoices, including (i) temporal modeling based on region-level tokens by\nutilizing 1D depthwise convolution to fuse channels in the lateral sensorimotor\ncortex (vSMC) and superior temporal gyrus (STG) and (ii) self-supervision\nthrough discrete codex-guided mask modeling, significantly contribute to this\nperformance. Overall, our approach -- inspired by neuroscience findings and\ncapitalizing on region-level representations from specific brain regions -- is\nsuitable for invasive brain modeling and represents a promising neuro-inspired\nAI approach in brain-computer interfaces.\n","authors":["Hui Zheng","Hai-Teng Wang","Wei-Bang Jiang","Zhong-Tao Chen","Li He","Pei-Yang Lin","Peng-Hu Wei","Guo-Guang Zhao","Yun-Zhe Liu"],"pdf_url":"https://arxiv.org/pdf/2405.11459v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.16077v1","updated":"2024-10-21T14:55:59Z","published":"2024-10-21T14:55:59Z","title":"CartesianMoE: Boosting Knowledge Sharing among Experts via Cartesian\n  Product Routing in Mixture-of-Experts","summary":"  Large language models (LLM) have been attracting much attention from the\ncommunity recently, due to their remarkable performance in all kinds of\ndownstream tasks. According to the well-known scaling law, scaling up a dense\nLLM enhances its capabilities, but also significantly increases the\ncomputational complexity. Mixture-of-Experts (MoE) models address that by\nallowing the model size to grow without substantially raising training or\ninference costs. Yet MoE models face challenges regarding knowledge sharing\namong experts, making their performance somehow sensitive to routing accuracy.\nTo tackle that, previous works introduced shared experts and combined their\noutputs with those of the top $K$ routed experts in an ``addition'' manner. In\nthis paper, inspired by collective matrix factorization to learn shared\nknowledge among data, we propose CartesianMoE, which implements more effective\nknowledge sharing among experts in more like a ``multiplication'' manner.\nExtensive experimental results indicate that CartesianMoE outperforms previous\nMoE models for building LLMs, in terms of both perplexity and downstream task\nperformance. And we also find that CartesianMoE achieves better expert routing\nrobustness.\n","authors":["Zhenpeng Su","Xing Wu","Zijia Lin","Yizhe Xiong","Minxuan Lv","Guangyuan Ma","Hui Chen","Songlin Hu","Guiguang Ding"],"pdf_url":"https://arxiv.org/pdf/2410.16077v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.16070v1","updated":"2024-10-21T14:48:35Z","published":"2024-10-21T14:48:35Z","title":"On-Device LLMs for SMEs: Challenges and Opportunities","summary":"  This paper presents a systematic review of the infrastructure requirements\nfor deploying Large Language Models (LLMs) on-device within the context of\nsmall and medium-sized enterprises (SMEs), focusing on both hardware and\nsoftware perspectives. From the hardware viewpoint, we discuss the utilization\nof processing units like GPUs and TPUs, efficient memory and storage solutions,\nand strategies for effective deployment, addressing the challenges of limited\ncomputational resources typical in SME settings. From the software perspective,\nwe explore framework compatibility, operating system optimization, and the use\nof specialized libraries tailored for resource-constrained environments. The\nreview is structured to first identify the unique challenges faced by SMEs in\ndeploying LLMs on-device, followed by an exploration of the opportunities that\nboth hardware innovations and software adaptations offer to overcome these\nobstacles. Such a structured review provides practical insights, contributing\nsignificantly to the community by enhancing the technological resilience of\nSMEs in integrating LLMs.\n","authors":["Jeremy Stephen Gabriel Yee Zhi Wen","Pai Chet Ng","Zhengkui Wang","Ian McLoughlin","Aik Beng Ng","Simon See"],"pdf_url":"https://arxiv.org/pdf/2410.16070v1.pdf","comment":"9 pages, 1 figure. The work is supported by the SIT-NVIDIA Joint AI\n  Centre"},{"id":"http://arxiv.org/abs/2410.16069v1","updated":"2024-10-21T14:47:37Z","published":"2024-10-21T14:47:37Z","title":"Rolling the DICE on Idiomaticity: How LLMs Fail to Grasp Context","summary":"  Human processing of idioms relies on understanding the contextual sentences\nin which idioms occur, as well as language-intrinsic features such as frequency\nand speaker-intrinsic factors like familiarity. While LLMs have shown high\nperformance on idiomaticity detection tasks, this success may be attributed to\nreasoning shortcuts in existing datasets. To this end, we construct a novel,\ncontrolled contrastive dataset designed to test whether LLMs can effectively\nuse context to disambiguate idiomatic meaning. Additionally, we explore how\ncollocational frequency and sentence probability influence model performance.\nOur findings reveal that LLMs often fail to resolve idiomaticity when it is\nrequired to attend to the surrounding context, and that models perform better\non sentences that have higher likelihood. The collocational frequency of\nexpressions also impacts performance. We make our code and dataset publicly\navailable.\n","authors":["Maggie Mi","Aline Villavicencio","Nafise Sadat Moosavi"],"pdf_url":"https://arxiv.org/pdf/2410.16069v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.16062v1","updated":"2024-10-21T14:42:37Z","published":"2024-10-21T14:42:37Z","title":"Surprise! Uniform Information Density Isn't the Whole Story: Predicting\n  Surprisal Contours in Long-form Discourse","summary":"  The Uniform Information Density (UID) hypothesis posits that speakers tend to\ndistribute information evenly across linguistic units to achieve efficient\ncommunication. Of course, information rate in texts and discourses is not\nperfectly uniform. While these fluctuations can be viewed as theoretically\nuninteresting noise on top of a uniform target, another explanation is that UID\nis not the only functional pressure regulating information content in a\nlanguage. Speakers may also seek to maintain interest, adhere to writing\nconventions, and build compelling arguments. In this paper, we propose one such\nfunctional pressure; namely that speakers modulate information rate based on\nlocation within a hierarchically-structured model of discourse. We term this\nthe Structured Context Hypothesis and test it by predicting the surprisal\ncontours of naturally occurring discourses extracted from large language models\nusing predictors derived from discourse structure. We find that hierarchical\npredictors are significant predictors of a discourse's information contour and\nthat deeply nested hierarchical predictors are more predictive than shallow\nones. This work takes an initial step beyond UID to propose testable hypotheses\nfor why the information rate fluctuates in predictable ways\n","authors":["Eleftheria Tsipidi","Franz Nowak","Ryan Cotterell","Ethan Wilcox","Mario Giulianelli","Alex Warstadt"],"pdf_url":"https://arxiv.org/pdf/2410.16062v1.pdf","comment":"EMNLP 2024 (main conference)"},{"id":"http://arxiv.org/abs/2404.03881v3","updated":"2024-10-21T14:29:44Z","published":"2024-04-05T04:04:23Z","title":"A Bi-consolidating Model for Joint Relational Triple Extraction","summary":"  Current methods to extract relational triples directly make a prediction\nbased on a possible entity pair in a raw sentence without depending on entity\nrecognition. The task suffers from a serious semantic overlapping problem, in\nwhich several relation triples may share one or two entities in a sentence. In\nthis paper, based on a two-dimensional sentence representation, a\nbi-consolidating model is proposed to address this problem by simultaneously\nreinforcing the local and global semantic features relevant to a relation\ntriple. This model consists of a local consolidation component and a global\nconsolidation component. The first component uses a pixel difference\nconvolution to enhance semantic information of a possible triple representation\nfrom adjacent regions and mitigate noise in neighbouring neighbours. The second\ncomponent strengthens the triple representation based a channel attention and a\nspatial attention, which has the advantage to learn remote semantic\ndependencies in a sentence. They are helpful to improve the performance of both\nentity identification and relation type classification in relation triple\nextraction. After evaluated on several publish datasets, the bi-consolidating\nmodel achieves competitive performance. Analytical experiments demonstrate the\neffectiveness of our model for relational triple extraction and give motivation\nfor other natural language processing tasks.\n","authors":["Xiaocheng Luo","Yanping Chen","Ruixue Tang","Caiwei Yang","Ruizhang Huang","Yongbin Qin"],"pdf_url":"https://arxiv.org/pdf/2404.03881v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2312.04684v2","updated":"2024-10-21T14:21:59Z","published":"2023-12-07T20:36:10Z","title":"Latent Skill Discovery for Chain-of-Thought Reasoning","summary":"  Chain-of-thought (CoT) prompting is a popular in-context learning (ICL)\napproach for large language models (LLMs), especially when tackling complex\nreasoning tasks. Traditional ICL approaches construct prompts using examples\nthat contain questions similar to the input question. However, CoT prompting,\nwhich includes crucial intermediate reasoning steps (rationales) within its\nexamples, necessitates selecting examples based on these rationales rather than\nthe questions themselves. Existing methods require human experts or pre-trained\nLLMs to describe the skill, a high-level abstraction of rationales, to guide\nthe selection. These methods, however, are often costly and difficult to scale.\nInstead, this paper introduces a new approach named Latent Reasoning Skills\n(LaRS) that employs unsupervised learning to create a latent space\nrepresentation of rationales, with a latent variable called a reasoning skill.\nConcurrently, LaRS learns a reasoning policy to determine the required\nreasoning skill for a given question. Then the ICL examples are selected by\naligning the reasoning skills between past examples and the question. This\napproach is theoretically grounded and compute-efficient, eliminating the need\nfor auxiliary LLM inference or manual prompt design. Empirical results\ndemonstrate that LaRS consistently outperforms SOTA skill-based selection\nmethods, processing example banks four times faster, reducing LLM inferences\nduring the selection stage by half, and showing greater robustness to\nsub-optimal example banks.\n","authors":["Zifan Xu","Haozhu Wang","Dmitriy Bespalov","Xuan Wang","Peter Stone","Yanjun Qi"],"pdf_url":"https://arxiv.org/pdf/2312.04684v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.16044v1","updated":"2024-10-21T14:20:25Z","published":"2024-10-21T14:20:25Z","title":"Large Language Models Know What To Say But Not When To Speak","summary":"  Turn-taking is a fundamental mechanism in human communication that ensures\nsmooth and coherent verbal interactions. Recent advances in Large Language\nModels (LLMs) have motivated their use in improving the turn-taking\ncapabilities of Spoken Dialogue Systems (SDS), such as their ability to respond\nat appropriate times. However, existing models often struggle to predict\nopportunities for speaking -- called Transition Relevance Places (TRPs) -- in\nnatural, unscripted conversations, focusing only on turn-final TRPs and not\nwithin-turn TRPs. To address these limitations, we introduce a novel dataset of\nparticipant-labeled within-turn TRPs and use it to evaluate the performance of\nstate-of-the-art LLMs in predicting opportunities for speaking. Our experiments\nreveal the current limitations of LLMs in modeling unscripted spoken\ninteractions, highlighting areas for improvement and paving the way for more\nnaturalistic dialogue systems.\n","authors":["Muhammad Umair","Vasanth Sarathy","JP de Ruiter"],"pdf_url":"https://arxiv.org/pdf/2410.16044v1.pdf","comment":"EMNLP 2024 (Findings)"},{"id":"http://arxiv.org/abs/2410.16027v1","updated":"2024-10-21T14:02:40Z","published":"2024-10-21T14:02:40Z","title":"ComPO: Community Preferences for Language Model Personalization","summary":"  Conventional algorithms for training language models (LMs) with human\nfeedback rely on preferences that are assumed to account for an \"average\" user,\ndisregarding subjectivity and finer-grained variations. Recent studies have\nraised concerns that aggregating such diverse and often contradictory human\nfeedback to finetune models results in generic models that generate outputs not\npreferred by many user groups, as they tend to average out styles and norms. To\naddress this issue, we draw inspiration from recommendation systems and propose\nComPO, a method to personalize preference optimization in LMs by\ncontextualizing the probability distribution of model outputs with the\npreference provider. Focusing on group-level preferences rather than\nindividuals, we collect and release ComPRed, a question answering dataset with\ncommunity-level preferences from Reddit. This dataset facilitates studying\ndiversity in preferences without incurring privacy concerns associated with\nindividual feedback. Our experiments reveal that conditioning language models\non a community identifier (i.e., subreddit name) during preference tuning\nsubstantially enhances model performance. Conversely, replacing this context\nwith random subreddit identifiers significantly diminishes performance,\nhighlighting the effectiveness of our approach in tailoring responses to\ncommunities' preferences.\n","authors":["Sachin Kumar","Chan Young Park","Yulia Tsvetkov","Noah A. Smith","Hannaneh Hajishirzi"],"pdf_url":"https://arxiv.org/pdf/2410.16027v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2402.15518v2","updated":"2024-10-21T14:02:00Z","published":"2024-02-11T13:41:17Z","title":"Beware of Words: Evaluating the Lexical Diversity of Conversational LLMs\n  using ChatGPT as Case Study","summary":"  The performance of conversational Large Language Models (LLMs) in general,\nand of ChatGPT in particular, is currently being evaluated on many different\ntasks, from logical reasoning or maths to answering questions on a myriad of\ntopics. Instead, much less attention is being devoted to the study of the\nlinguistic features of the texts generated by these LLMs. This is surprising\nsince LLMs are models for language, and understanding how they use the language\nis important. Indeed, conversational LLMs are poised to have a significant\nimpact on the evolution of languages as they may eventually dominate the\ncreation of new text. This means that for example, if conversational LLMs do\nnot use a word it may become less and less frequent and eventually stop being\nused altogether. Therefore, evaluating the linguistic features of the text they\nproduce and how those depend on the model parameters is the first step toward\nunderstanding the potential impact of conversational LLMs on the evolution of\nlanguages. In this paper, we consider the evaluation of the lexical richness of\nthe text generated by LLMs and how it depends on the model parameters. A\nmethodology is presented and used to conduct a comprehensive evaluation of\nlexical richness using ChatGPT as a case study. The results show how lexical\nrichness depends on the version of ChatGPT and some of its parameters, such as\nthe presence penalty, or on the role assigned to the model. The dataset and\ntools used in our analysis are released under open licenses with the goal of\ndrawing the much-needed attention to the evaluation of the linguistic features\nof LLM-generated text.\n","authors":["Gonzalo Martínez","José Alberto Hernández","Javier Conde","Pedro Reviriego","Elena Merino"],"pdf_url":"https://arxiv.org/pdf/2402.15518v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.16011v1","updated":"2024-10-21T13:42:19Z","published":"2024-10-21T13:42:19Z","title":"CA*: Addressing Evaluation Pitfalls in Computation-Aware Latency for\n  Simultaneous Speech Translation","summary":"  Simultaneous speech translation (SimulST) systems must balance translation\nquality with response time, making latency measurement crucial for evaluating\ntheir real-world performance. However, there has been a longstanding belief\nthat current metrics yield unrealistically high latency measurements in\nunsegmented streaming settings. In this paper, we investigate this phenomenon,\nrevealing its root cause in a fundamental misconception underlying existing\nlatency evaluation approaches. We demonstrate that this issue affects not only\nstreaming but also segment-level latency evaluation across different metrics.\nFurthermore, we propose a modification to correctly measure computation-aware\nlatency for SimulST systems, addressing the limitations present in existing\nmetrics.\n","authors":["Xi Xu","Wenda Xu","Siqi Ouyang","Lei Li"],"pdf_url":"https://arxiv.org/pdf/2410.16011v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.05770v3","updated":"2024-10-21T13:41:54Z","published":"2024-10-08T07:52:35Z","title":"Efficient Few-shot Learning for Multi-label Classification of Scientific\n  Documents with Many Classes","summary":"  Scientific document classification is a critical task and often involves many\nclasses. However, collecting human-labeled data for many classes is expensive\nand usually leads to label-scarce scenarios. Moreover, recent work has shown\nthat sentence embedding model fine-tuning for few-shot classification is\nefficient, robust, and effective. In this work, we propose FusionSent\n(Fusion-based Sentence Embedding Fine-tuning), an efficient and prompt-free\napproach for few-shot classification of scientific documents with many classes.\nFusionSent uses available training examples and their respective label texts to\ncontrastively fine-tune two different sentence embedding models. Afterward, the\nparameters of both fine-tuned models are fused to combine the complementary\nknowledge from the separate fine-tuning steps into a single model. Finally, the\nresulting sentence embedding model is frozen to embed the training instances,\nwhich are then used as input features to train a classification head. Our\nexperiments show that FusionSent significantly outperforms strong baselines by\nan average of $6.0$ $F_{1}$ points across multiple scientific document\nclassification datasets. In addition, we introduce a new dataset for\nmulti-label classification of scientific documents, which contains 203,961\nscientific articles and 130 classes from the arXiv category taxonomy. Code and\ndata are available at https://github.com/sebischair/FusionSent.\n","authors":["Tim Schopf","Alexander Blatzheim","Nektarios Machner","Florian Matthes"],"pdf_url":"https://arxiv.org/pdf/2410.05770v3.pdf","comment":"Accepted to the 7th International Conference on Natural Language and\n  Speech Processing (ICNLSP 2024)"},{"id":"http://arxiv.org/abs/2406.10576v2","updated":"2024-10-21T13:39:32Z","published":"2024-06-15T09:31:03Z","title":"Bypass Back-propagation: Optimization-based Structural Pruning for Large\n  Language Models via Policy Gradient","summary":"  In contrast to moderate-size neural network pruning, structural weight\npruning on the Large-Language Models (LLMs) imposes a novel challenge on the\nefficiency of the pruning algorithms, due to the heavy computation/memory\ndemands of the LLMs. Recent efficient LLM pruning methods typically operate at\nthe post-training phase without the expensive weight finetuning, however, their\npruning criteria often rely on heuristically hand-crafted metrics, potentially\nleading to suboptimal performance. We instead propose a novel\noptimization-based structural pruning that learns the pruning masks in a\nprobabilistic space directly by optimizing the loss of the pruned model. To\npreserve the efficiency, our method eliminates the back-propagation through the\nLLM per se during the optimization, requiring only the forward pass of the LLM.\nWe achieve this by learning an underlying Bernoulli distribution to sample\nbinary pruning masks, where we decouple the Bernoulli parameters from the LLM\nloss, thus facilitating an efficient optimization via a policy gradient\nestimator without back-propagation. As a result, our method is able to 1)\noperate at structural granularities of channels, heads, and layers, 2) support\nglobal and heterogeneous pruning (i.e., our method automatically determines\ndifferent redundancy for different layers), and 3) optionally initialize with a\nmetric-based method (for our Bernoulli distributions). Extensive experiments on\nLLaMA, LLaMA-2, LLaMA-3, Vicuna, and Mistral using the C4 and WikiText2\ndatasets demonstrate that our method operates for 2.7 hours with around 35GB\nmemory for the 13B models on a single A100 GPU, and our pruned models\noutperform the state-of-the-arts w.r.t. both perplexity and the majority of\nvarious zero-shot tasks. Codes will be released.\n","authors":["Yuan Gao","Zujing Liu","Weizhong Zhang","Bo Du","Gui-Song Xia"],"pdf_url":"https://arxiv.org/pdf/2406.10576v2.pdf","comment":"Initially submitted on June 15, 2024, this version mainly changed the\n  title, and added several experiments: such as 1) experiments on LLaMA-3,\n  Mistral, 2) additional baseline methods (i.e., Bosai -- Everybody Prune Now),\n  and 3) post-pruning finetuned performance (i.e., first prune then finetune)"},{"id":"http://arxiv.org/abs/2410.16006v1","updated":"2024-10-21T13:39:03Z","published":"2024-10-21T13:39:03Z","title":"Exploring Continual Fine-Tuning for Enhancing Language Ability in Large\n  Language Model","summary":"  A common challenge towards the adaptability of Large Language Models (LLMs)\nis their ability to learn new languages over time without hampering the model's\nperformance on languages in which the model is already proficient (usually\nEnglish). Continual fine-tuning (CFT) is the process of sequentially\nfine-tuning an LLM to enable the model to adapt to downstream tasks with\nvarying data distributions and time shifts. This paper focuses on the language\nadaptability of LLMs through CFT. We study a two-phase CFT process in which an\nEnglish-only end-to-end fine-tuned LLM from Phase 1 (predominantly Task\nAbility) is sequentially fine-tuned on a multilingual dataset -- comprising\ntask data in new languages -- in Phase 2 (predominantly Language Ability). We\nobserve that the ``similarity'' of Phase 2 tasks with Phase 1 determines the\nLLM's adaptability. For similar phase-wise datasets, the LLM after Phase 2 does\nnot show deterioration in task ability. In contrast, when the phase-wise\ndatasets are not similar, the LLM's task ability deteriorates. We test our\nhypothesis on the open-source \\mis\\ and \\llm\\ models with multiple phase-wise\ndataset pairs. To address the deterioration, we analyze tailored variants of\ntwo CFT methods: layer freezing and generative replay. Our findings demonstrate\ntheir effectiveness in enhancing the language ability of LLMs while preserving\ntask performance, in comparison to relevant baselines.\n","authors":["Divyanshu Aggarwal","Sankarshan Damle","Navin Goyal","Satya Lokam","Sunayana Sitaram"],"pdf_url":"https://arxiv.org/pdf/2410.16006v1.pdf","comment":"19 pages, 6 tables, 4 figures"},{"id":"http://arxiv.org/abs/2410.15999v1","updated":"2024-10-21T13:30:47Z","published":"2024-10-21T13:30:47Z","title":"Steering Knowledge Selection Behaviours in LLMs via SAE-Based\n  Representation Engineering","summary":"  Large language models (LLMs) can store a significant amount of factual\nknowledge in their parameters. However, their parametric knowledge may conflict\nwith the information provided in the context -- this phenomenon, known as\n\\emph{context-memory knowledge conflicts}, can lead to undesirable model\nbehaviour, such as reliance on outdated or incorrect information. Analysing the\ninternal activations of LLMs, we find that they can internally register the\nsignals of knowledge conflict at mid-layers. Such signals allow us to detect\nwhether a knowledge conflict occurs and use \\emph{inference-time} intervention\nstrategies to resolve it. In this work, we propose \\textsc{SpARE}, a\n\\emph{training-free} representation engineering method that uses pre-trained\nsparse auto-encoders (SAEs) to control the knowledge selection behaviour of\nLLMs. \\textsc{SpARE} identifies the functional features that control the\nknowledge selection behaviours and applies them to edit the internal\nactivations of LLMs at inference time. Our experimental results show that\n\\textsc{SpARE} can effectively control the usage of either knowledge source to\nresolve knowledge conflict in open-domain question-answering tasks, surpassing\nexisting representation engineering methods ($+10\\%$) as well as contrastive\ndecoding methods ($+15\\%$).\n","authors":["Yu Zhao","Alessio Devoto","Giwon Hong","Xiaotang Du","Aryo Pradipta Gema","Hongru Wang","Kam-Fai Wong","Pasquale Minervini"],"pdf_url":"https://arxiv.org/pdf/2410.15999v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.15998v1","updated":"2024-10-21T13:29:08Z","published":"2024-10-21T13:29:08Z","title":"1024m at SMM4H 2024: Tasks 3, 5 & 6 -- Ensembles of Transformers and\n  Large Language Models for Medical Text Classification","summary":"  Social media is a great source of data for users reporting information and\nregarding their health and how various things have had an effect on them. This\npaper presents various approaches using Transformers and Large Language Models\nand their ensembles, their performance along with advantages and drawbacks for\nvarious tasks of SMM4H'24 - Classifying texts on impact of nature and outdoor\nspaces on the author's mental health (Task 3), Binary classification of tweets\nreporting their children's health disorders like Asthma, Autism, ADHD and\nSpeech disorder (task 5), Binary classification of users self-reporting their\nage (task 6).\n","authors":["Ram Mohan Rao Kadiyala","M. V. P. Chandra Sekhara Rao"],"pdf_url":"https://arxiv.org/pdf/2410.15998v1.pdf","comment":"short paper , acl 2024"},{"id":"http://arxiv.org/abs/2410.15990v1","updated":"2024-10-21T13:20:15Z","published":"2024-10-21T13:20:15Z","title":"Augmenting Legal Decision Support Systems with LLM-based NLI for\n  Analyzing Social Media Evidence","summary":"  This paper presents our system description and error analysis of our entry\nfor NLLP 2024 shared task on Legal Natural Language Inference (L-NLI)\n\\citep{hagag2024legallenssharedtask2024}. The task required classifying these\nrelationships as entailed, contradicted, or neutral, indicating any association\nbetween the review and the complaint. Our system emerged as the winning\nsubmission, significantly outperforming other entries with a substantial margin\nand demonstrating the effectiveness of our approach in legal text analysis. We\nprovide a detailed analysis of the strengths and limitations of each model and\napproach tested, along with a thorough error analysis and suggestions for\nfuture improvements. This paper aims to contribute to the growing field of\nlegal NLP by offering insights into advanced techniques for natural language\ninference in legal contexts, making it accessible to both experts and newcomers\nin the field.\n","authors":["Ram Mohan Rao Kadiyala","Siddartha Pullakhandam","Kanwal Mehreen","Subhasya Tippareddy","Ashay Srivastava"],"pdf_url":"https://arxiv.org/pdf/2410.15990v1.pdf","comment":"8 pages , accepted to emnlp 2024"},{"id":"http://arxiv.org/abs/2410.11786v2","updated":"2024-10-21T13:11:44Z","published":"2024-10-15T17:05:25Z","title":"Selection-p: Self-Supervised Task-Agnostic Prompt Compression for\n  Faithfulness and Transferability","summary":"  Large Language Models (LLMs) have demonstrated impressive capabilities in a\nwide range of natural language processing tasks when leveraging in-context\nlearning. To mitigate the additional computational and financial costs\nassociated with in-context learning, several prompt compression methods have\nbeen proposed to compress the in-context learning prompts. Despite their\nsuccess, these methods face challenges with transferability due to\nmodel-specific compression, or rely on external training data, such as GPT-4.\nIn this paper, we investigate the ability of LLMs to develop a unified\ncompression method that discretizes uninformative tokens, utilizing a\nself-supervised pre-training technique. By introducing a small number of\nparameters during the continual pre-training, the proposed Selection-p produces\na probability for each input token, indicating whether to preserve or discard\nit. Experiments show Selection-p achieves state-of-the-art performance across\nnumerous classification tasks, achieving compression rates of up to 10 times\nwhile experiencing only a marginal 0.8% decrease in performance. Moreover, it\nexhibits superior transferability to different models compared to prior work.\nAdditionally, we further analyze how Selection-p helps maintain performance on\nin-context learning with long contexts.\n","authors":["Tsz Ting Chung","Leyang Cui","Lemao Liu","Xinting Huang","Shuming Shi","Dit-Yan Yeung"],"pdf_url":"https://arxiv.org/pdf/2410.11786v2.pdf","comment":"14 pages, 5 figures, 10 tables, EMNLP 2024 Findings"},{"id":"http://arxiv.org/abs/2410.15974v1","updated":"2024-10-21T13:00:09Z","published":"2024-10-21T13:00:09Z","title":"Large Language Models for Cross-lingual Emotion Detection","summary":"  This paper presents a detailed system description of our entry for the WASSA\n2024 Task 2, focused on cross-lingual emotion detection. We utilized a\ncombination of large language models (LLMs) and their ensembles to effectively\nunderstand and categorize emotions across different languages. Our approach not\nonly outperformed other submissions with a large margin, but also demonstrated\nthe strength of integrating multiple models to enhance performance.\nAdditionally, We conducted a thorough comparison of the benefits and\nlimitations of each model used. An error analysis is included along with\nsuggested areas for future improvement. This paper aims to offer a clear and\ncomprehensive understanding of advanced techniques in emotion detection, making\nit accessible even to those new to the field.\n","authors":["Ram Mohan Rao Kadiyala"],"pdf_url":"https://arxiv.org/pdf/2410.15974v1.pdf","comment":"6 pages , accepted to acl 2024"},{"id":"http://arxiv.org/abs/2410.15970v1","updated":"2024-10-21T12:58:03Z","published":"2024-10-21T12:58:03Z","title":"Policy-driven Knowledge Selection and Response Generation for\n  Document-grounded Dialogue","summary":"  Document-grounded dialogue (DGD) uses documents as external knowledge for\ndialogue generation. Correctly understanding the dialogue context is crucial\nfor selecting knowledge from the document and generating proper responses. In\nthis paper, we propose using a dialogue policy to help the dialogue\nunderstanding in DGD. Our dialogue policy consists of two kinds of guiding\nsignals: utterance function and topic transfer intent. The utterance function\nreflects the purpose and style of an utterance, and the topic transfer intent\nreflects the topic and content of an utterance. We propose a novel framework\nexploiting our dialogue policy for two core tasks in DGD, namely knowledge\nselection (KS) and response generation (RG). The framework consists of two\nmodules: the Policy planner leverages policy-aware dialogue representation to\nselect knowledge and predict the policy of the response; the generator uses\npolicy/knowledge-aware dialogue representation for response generation. Our\npolicy-driven model gets state-of-the-art performance on three public\nbenchmarks and we provide a detailed analysis of the experimental results. Our\ncode/data will be released on GitHub.\n","authors":["Longxuan Ma","Jiapeng Li","Mingda Li","Wei-Nan Zhang","Ting Liu"],"pdf_url":"https://arxiv.org/pdf/2410.15970v1.pdf","comment":"29 pages, 9 figures, 14 tables, TOIS 2024"},{"id":"http://arxiv.org/abs/2409.14038v3","updated":"2024-10-21T12:54:33Z","published":"2024-09-21T06:49:34Z","title":"OAEI-LLM: A Benchmark Dataset for Understanding Large Language Model\n  Hallucinations in Ontology Matching","summary":"  Hallucinations of large language models (LLMs) commonly occur in\ndomain-specific downstream tasks, with no exception in ontology matching (OM).\nThe prevalence of using LLMs for OM raises the need for benchmarks to better\nunderstand LLM hallucinations. The OAEI-LLM dataset is an extended version of\nthe Ontology Alignment Evaluation Initiative (OAEI) datasets that evaluate\nLLM-specific hallucinations in OM tasks. We outline the methodology used in\ndataset construction and schema extension, and provide examples of potential\nuse cases.\n","authors":["Zhangcheng Qiang","Kerry Taylor","Weiqing Wang","Jing Jiang"],"pdf_url":"https://arxiv.org/pdf/2409.14038v3.pdf","comment":"5 pages, 1 figure, 1 table"},{"id":"http://arxiv.org/abs/2410.15966v1","updated":"2024-10-21T12:52:03Z","published":"2024-10-21T12:52:03Z","title":"Self-Explained Keywords Empower Large Language Models for Code\n  Generation","summary":"  Large language models (LLMs) have achieved impressive performance in code\ngeneration. However, due to the long-tail distribution of LLMs' training data,\nlow-frequency terms are typically underrepresented in the training process.\nConsequently, LLMs often misunderstand or overlook problem-specific,\nlow-frequency keywords during code generation, compromising the accuracy of the\ngenerated code. To address this, we propose a novel technique named\nSEK(\\textbf{S}elf-\\textbf{E}xplained \\textbf{K}eywords), which empowers an LLM\nfor better code generation by extracting and explaining the key terms in the\nproblem description with the LLM itself and ranking them based on frequency.\nComprehensive experiments across three benchmarks, i.e., HumanEval(+), MBPP(+),\nand APPS, with five representative LLMs, show that SEK can significantly\nimprove LLMs in code generation, yielding substantial and consistent gains. For\ninstance, SEK improves the Pass@1 of DeepSeek-Coder-V2-Instruct from 85.4\\% to\n93.3\\% on the Humaneval benchmark. Further analysis confirms that SEK enables\nthe LLMs to shift their attention from low-frequency keywords to their\ncorresponding high-frequency counterparts.\n","authors":["Lishui Fan","Mouxiang Chen","Zhongxin Liu"],"pdf_url":"https://arxiv.org/pdf/2410.15966v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2409.19381v2","updated":"2024-10-21T12:48:58Z","published":"2024-09-28T15:12:55Z","title":"INC-Math: Integrating Natural Language and Code for Enhanced\n  Mathematical Reasoning in Large Language Models","summary":"  Large Language Models (LLMs) are commonly used to generate solutions for\nmathematical reasoning problems in the following formats: natural language,\ncode, or a combination of both. In this paper, we explore fundamental questions\nrelated to solving mathematical reasoning problems using natural language and\ncode with state-of-the-art LLMs, including GPT-4o-mini and LLama-3.1-8b-Turbo.\nOur findings show that LLMs are better at reasoning in natural language\ncompared to code. Additionally, although natural language and code serve as\ncomplementary forms of reasoning, they can affect each other in a negative way\nin certain scenarios. These insights motivate our development of a new\nprompting method, INC-Math, which leverages an LLM to dynamically select the\nmost appropriate reasoning form, resulting in improved performance over\ncomparable baselines with GPT-4o-mini.\n","authors":["Xuyuan Xiong","Simeng Han","Ziyue Zhou","Arman Cohan"],"pdf_url":"https://arxiv.org/pdf/2409.19381v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.15962v1","updated":"2024-10-21T12:47:57Z","published":"2024-10-21T12:47:57Z","title":"Systematic Exploration of Dialogue Summarization Approaches for\n  Reproducibility, Comparative Assessment, and Methodological Innovations for\n  Advancing Natural Language Processing in Abstractive Summarization","summary":"  Reproducibility in scientific research, particularly within the realm of\nnatural language processing (NLP), is essential for validating and verifying\nthe robustness of experimental findings. This paper delves into the\nreproduction and evaluation of dialogue summarization models, focusing\nspecifically on the discrepancies observed between original studies and our\nreproduction efforts. Dialogue summarization is a critical aspect of NLP,\naiming to condense conversational content into concise and informative\nsummaries, thus aiding in efficient information retrieval and decision-making\nprocesses. Our research involved a thorough examination of several dialogue\nsummarization models using the AMI (Augmented Multi-party Interaction) dataset.\nThe models assessed include Hierarchical Memory Networks (HMNet) and various\nversions of Pointer-Generator Networks (PGN), namely PGN(DKE), PGN(DRD),\nPGN(DTS), and PGN(DALL). The primary objective was to evaluate the\ninformativeness and quality of the summaries generated by these models through\nhuman assessment, a method that introduces subjectivity and variability in the\nevaluation process. The analysis began with Dataset 1, where the sample\nstandard deviation of 0.656 indicated a moderate dispersion of data points\naround the mean.\n","authors":["Yugandhar Reddy Gogireddy","Jithendra Reddy Gogireddy"],"pdf_url":"https://arxiv.org/pdf/2410.15962v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.15956v1","updated":"2024-10-21T12:34:17Z","published":"2024-10-21T12:34:17Z","title":"Do Large Language Models Have an English Accent? Evaluating and\n  Improving the Naturalness of Multilingual LLMs","summary":"  Current Large Language Models (LLMs) are predominantly designed with English\nas the primary language, and even the few that are multilingual tend to exhibit\nstrong English-centric biases. Much like speakers who might produce awkward\nexpressions when learning a second language, LLMs often generate unnatural\noutputs in non-English languages, reflecting English-centric patterns in both\nvocabulary and grammar. Despite the importance of this issue, the naturalness\nof multilingual LLM outputs has received limited attention. In this paper, we\naddress this gap by introducing novel automatic corpus-level metrics to assess\nthe lexical and syntactic naturalness of LLM outputs in a multilingual context.\nUsing our new metrics, we evaluate state-of-the-art LLMs on a curated benchmark\nin French and Chinese, revealing a tendency towards English-influenced\npatterns. To mitigate this issue, we also propose a simple and effective\nalignment method to improve the naturalness of an LLM in a target language and\ndomain, achieving consistent improvements in naturalness without compromising\nthe performance on general-purpose benchmarks. Our work highlights the\nimportance of developing multilingual metrics, resources and methods for the\nnew wave of multilingual LLMs.\n","authors":["Yanzhu Guo","Simone Conia","Zelin Zhou","Min Li","Saloni Potdar","Henry Xiao"],"pdf_url":"https://arxiv.org/pdf/2410.15956v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.15949v1","updated":"2024-10-21T12:30:44Z","published":"2024-10-21T12:30:44Z","title":"Findings of the Third Shared Task on Multilingual Coreference Resolution","summary":"  The paper presents an overview of the third edition of the shared task on\nmultilingual coreference resolution, held as part of the CRAC 2024 workshop.\nSimilarly to the previous two editions, the participants were challenged to\ndevelop systems capable of identifying mentions and clustering them based on\nidentity coreference.\n  This year's edition took another step towards real-world application by not\nproviding participants with gold slots for zero anaphora, increasing the task's\ncomplexity and realism. In addition, the shared task was expanded to include a\nmore diverse set of languages, with a particular focus on historical languages.\nThe training and evaluation data were drawn from version 1.2 of the\nmultilingual collection of harmonized coreference resources CorefUD,\nencompassing 21 datasets across 15 languages. 6 systems competed in this shared\ntask.\n","authors":["Michal Novák","Barbora Dohnalová","Miloslav Konopík","Anna Nedoluzhko","Martin Popel","Ondřej Pražák","Jakub Sido","Milan Straka","Zdeněk Žabokrtský","Daniel Zeman"],"pdf_url":"https://arxiv.org/pdf/2410.15949v1.pdf","comment":"Accepted to CRAC 2024"},{"id":"http://arxiv.org/abs/2410.15939v1","updated":"2024-10-21T12:12:21Z","published":"2024-10-21T12:12:21Z","title":"CausalGraph2LLM: Evaluating LLMs for Causal Queries","summary":"  Causality is essential in scientific research, enabling researchers to\ninterpret true relationships between variables. These causal relationships are\noften represented by causal graphs, which are directed acyclic graphs. With the\nrecent advancements in Large Language Models (LLMs), there is an increasing\ninterest in exploring their capabilities in causal reasoning and their\npotential use to hypothesize causal graphs. These tasks necessitate the LLMs to\nencode the causal graph effectively for subsequent downstream tasks. In this\npaper, we propose a comprehensive benchmark, \\emph{CausalGraph2LLM},\nencompassing a variety of causal graph settings to assess the causal graph\nunderstanding capability of LLMs. We categorize the causal queries into two\ntypes: graph-level and node-level queries. We benchmark both open-sourced and\nclosed models for our study. Our findings reveal that while LLMs show promise\nin this domain, they are highly sensitive to the encoding used. Even capable\nmodels like GPT-4 and Gemini-1.5 exhibit sensitivity to encoding, with\ndeviations of about $60\\%$. We further demonstrate this sensitivity for\ndownstream causal intervention tasks. Moreover, we observe that LLMs can often\ndisplay biases when presented with contextual information about a causal graph,\npotentially stemming from their parametric memory.\n","authors":["Ivaxi Sheth","Bahare Fatemi","Mario Fritz"],"pdf_url":"https://arxiv.org/pdf/2410.15939v1.pdf","comment":"Code - https://github.com/ivaxi0s/CausalGraph2LLM"},{"id":"http://arxiv.org/abs/2410.15929v1","updated":"2024-10-21T11:57:56Z","published":"2024-10-21T11:57:56Z","title":"Yeah, Un, Oh: Continuous and Real-time Backchannel Prediction with\n  Fine-tuning of Voice Activity Projection","summary":"  In human conversations, short backchannel utterances such as \"yeah\" and \"oh\"\nplay a crucial role in facilitating smooth and engaging dialogue. These\nbackchannels signal attentiveness and understanding without interrupting the\nspeaker, making their accurate prediction essential for creating more natural\nconversational agents. This paper proposes a novel method for real-time,\ncontinuous backchannel prediction using a fine-tuned Voice Activity Projection\n(VAP) model. While existing approaches have relied on turn-based or\nartificially balanced datasets, our approach predicts both the timing and type\nof backchannels in a continuous and frame-wise manner on unbalanced, real-world\ndatasets. We first pre-train the VAP model on a general dialogue corpus to\ncapture conversational dynamics and then fine-tune it on a specialized dataset\nfocused on backchannel behavior. Experimental results demonstrate that our\nmodel outperforms baseline methods in both timing and type prediction tasks,\nachieving robust performance in real-time environments. This research offers a\npromising step toward more responsive and human-like dialogue systems, with\nimplications for interactive spoken dialogue applications such as virtual\nassistants and robots.\n","authors":["Koji Inoue","Divesh Lala","Gabriel Skantze","Tatsuya Kawahara"],"pdf_url":"https://arxiv.org/pdf/2410.15929v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.15926v1","updated":"2024-10-21T11:54:53Z","published":"2024-10-21T11:54:53Z","title":"Mitigating Object Hallucination via Concentric Causal Attention","summary":"  Recent Large Vision Language Models (LVLMs) present remarkable zero-shot\nconversational and reasoning capabilities given multimodal queries.\nNevertheless, they suffer from object hallucination, a phenomenon where LVLMs\nare prone to generate textual responses not factually aligned with image\ninputs. Our pilot study reveals that object hallucination is closely tied with\nRotary Position Encoding (RoPE), a widely adopted positional dependency\nmodeling design in existing LVLMs. Due to the long-term decay in RoPE, LVLMs\ntend to hallucinate more when relevant visual cues are distant from instruction\ntokens in the multimodal input sequence. Additionally, we observe a similar\neffect when reversing the sequential order of visual tokens during multimodal\nalignment. Our tests indicate that long-term decay in RoPE poses challenges to\nLVLMs while capturing visual-instruction interactions across long distances. We\npropose Concentric Causal Attention (CCA), a simple yet effective positional\nalignment strategy that mitigates the impact of RoPE long-term decay in LVLMs\nby naturally reducing relative distance between visual and instruction tokens.\nWith CCA, visual tokens can better interact with instruction tokens, thereby\nenhancing model's perception capability and alleviating object hallucination.\nWithout bells and whistles, our positional alignment method surpasses existing\nhallucination mitigation strategies by large margins on multiple object\nhallucination benchmarks.\n","authors":["Yun Xing","Yiheng Li","Ivan Laptev","Shijian Lu"],"pdf_url":"https://arxiv.org/pdf/2410.15926v1.pdf","comment":"To appear at NeurIPS 2024. Code is available at\n  https://github.com/xing0047/cca-llava"},{"id":"http://arxiv.org/abs/2404.12174v2","updated":"2024-10-21T11:33:33Z","published":"2024-04-18T13:31:05Z","title":"Claim Check-Worthiness Detection: How Well do LLMs Grasp Annotation\n  Guidelines?","summary":"  The increasing threat of disinformation calls for automating parts of the\nfact-checking pipeline. Identifying text segments requiring fact-checking is\nknown as claim detection (CD) and claim check-worthiness detection (CW), the\nlatter incorporating complex domain-specific criteria of worthiness and often\nframed as a ranking task. Zero- and few-shot LLM prompting is an attractive\noption for both tasks, as it bypasses the need for labeled datasets and allows\nverbalized claim and worthiness criteria to be directly used for prompting. We\nevaluate the LLMs' predictive and calibration accuracy on five CD/CW datasets\nfrom diverse domains, each utilizing a different worthiness criterion. We\ninvestigate two key aspects: (1) how best to distill factuality and worthiness\ncriteria into a prompt and (2) what amount of context to provide for each\nclaim. To this end, we experiment with varying the level of prompt verbosity\nand the amount of contextual information provided to the model. Our results\nshow that optimal prompt verbosity is domain-dependent, adding context does not\nimprove performance, and confidence scores can be directly used to produce\nreliable check-worthiness rankings.\n","authors":["Laura Majer","Jan Šnajder"],"pdf_url":"https://arxiv.org/pdf/2404.12174v2.pdf","comment":"Accepted to WASSA at EMNLP 2024"},{"id":"http://arxiv.org/abs/2410.15911v1","updated":"2024-10-21T11:33:18Z","published":"2024-10-21T11:33:18Z","title":"DefVerify: Do Hate Speech Models Reflect Their Dataset's Definition?","summary":"  When building a predictive model, it is often difficult to ensure that\ndomain-specific requirements are encoded by the model that will eventually be\ndeployed. Consider researchers working on hate speech detection. They will have\nan idea of what is considered hate speech, but building a model that reflects\ntheir view accurately requires preserving those ideals throughout the workflow\nof data set construction and model training. Complications such as sampling\nbias, annotation bias, and model misspecification almost always arise, possibly\nresulting in a gap between the domain specification and the model's actual\nbehavior upon deployment. To address this issue for hate speech detection, we\npropose DefVerify: a 3-step procedure that (i) encodes a user-specified\ndefinition of hate speech, (ii) quantifies to what extent the model reflects\nthe intended definition, and (iii) tries to identify the point of failure in\nthe workflow. We use DefVerify to find gaps between definition and model\nbehavior when applied to six popular hate speech benchmark datasets.\n","authors":["Urja Khurana","Eric Nalisnick","Antske Fokkens"],"pdf_url":"https://arxiv.org/pdf/2410.15911v1.pdf","comment":"Preprint"},{"id":"http://arxiv.org/abs/2408.04284v2","updated":"2024-10-21T11:26:20Z","published":"2024-08-08T07:43:17Z","title":"LLM-DetectAIve: a Tool for Fine-Grained Machine-Generated Text Detection","summary":"  The ease of access to large language models (LLMs) has enabled a widespread\nof machine-generated texts, and now it is often hard to tell whether a piece of\ntext was human-written or machine-generated. This raises concerns about\npotential misuse, particularly within educational and academic domains. Thus,\nit is important to develop practical systems that can automate the process.\nHere, we present one such system, LLM-DetectAIve, designed for fine-grained\ndetection. Unlike most previous work on machine-generated text detection, which\nfocused on binary classification, LLM-DetectAIve supports four categories: (i)\nhuman-written, (ii) machine-generated, (iii) machine-written, then\nmachine-humanized, and (iv) human-written, then machine-polished. Category\n(iii) aims to detect attempts to obfuscate the fact that a text was\nmachine-generated, while category (iv) looks for cases where the LLM was used\nto polish a human-written text, which is typically acceptable in academic\nwriting, but not in education. Our experiments show that LLM-DetectAIve can\neffectively identify the above four categories, which makes it a potentially\nuseful tool in education, academia, and other domains.\n  LLM-DetectAIve is publicly accessible at\nhttps://github.com/mbzuai-nlp/LLM-DetectAIve. The video describing our system\nis available at https://youtu.be/E8eT_bE7k8c.\n","authors":["Mervat Abassy","Kareem Elozeiri","Alexander Aziz","Minh Ngoc Ta","Raj Vardhan Tomar","Bimarsha Adhikari","Saad El Dine Ahmed","Yuxia Wang","Osama Mohammed Afzal","Zhuohan Xie","Jonibek Mansurov","Ekaterina Artemova","Vladislav Mikhailov","Rui Xing","Jiahui Geng","Hasan Iqbal","Zain Muhammad Mujahid","Tarek Mahmoud","Akim Tsvigun","Alham Fikri Aji","Artem Shelmanov","Nizar Habash","Iryna Gurevych","Preslav Nakov"],"pdf_url":"https://arxiv.org/pdf/2408.04284v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.14859v2","updated":"2024-10-21T11:25:48Z","published":"2024-03-21T22:08:44Z","title":"Log Probabilities Are a Reliable Estimate of Semantic Plausibility in\n  Base and Instruction-Tuned Language Models","summary":"  Semantic plausibility (e.g. knowing that \"the actor won the award\" is more\nlikely than \"the actor won the battle\") serves as an effective proxy for\ngeneral world knowledge. Language models (LMs) capture vast amounts of world\nknowledge by learning distributional patterns in text, accessible via log\nprobabilities (LogProbs) they assign to plausible vs. implausible outputs. The\nnew generation of instruction-tuned LMs can now also provide explicit estimates\nof plausibility via prompting. Here, we evaluate the effectiveness of LogProbs\nand basic prompting to measure semantic plausibility, both in single-sentence\nminimal pairs (Experiment 1) and short context-dependent scenarios (Experiment\n2). We find that (i) in both base and instruction-tuned LMs, LogProbs offers a\nmore reliable measure of semantic plausibility than direct zero-shot prompting,\nwhich yields inconsistent and often poor results; (ii) instruction-tuning\ngenerally does not alter the sensitivity of LogProbs to semantic plausibility\n(although sometimes decreases it); (iii) across models, context mostly\nmodulates LogProbs in expected ways, as measured by three novel metrics of\ncontext-sensitive plausibility and their match to explicit human plausibility\njudgments. We conclude that, even in the era of prompt-based evaluations,\nLogProbs constitute a useful metric of semantic plausibility, both in base and\ninstruction-tuned LMs.\n","authors":["Carina Kauf","Emmanuele Chersoni","Alessandro Lenci","Evelina Fedorenko","Anna A. Ivanova"],"pdf_url":"https://arxiv.org/pdf/2403.14859v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.13296v2","updated":"2024-10-21T11:10:00Z","published":"2024-08-23T14:48:02Z","title":"The Ultimate Guide to Fine-Tuning LLMs from Basics to Breakthroughs: An\n  Exhaustive Review of Technologies, Research, Best Practices, Applied Research\n  Challenges and Opportunities","summary":"  This report examines the fine-tuning of Large Language Models (LLMs),\nintegrating theoretical insights with practical applications. It outlines the\nhistorical evolution of LLMs from traditional Natural Language Processing (NLP)\nmodels to their pivotal role in AI. A comparison of fine-tuning methodologies,\nincluding supervised, unsupervised, and instruction-based approaches,\nhighlights their applicability to different tasks. The report introduces a\nstructured seven-stage pipeline for fine-tuning LLMs, spanning data\npreparation, model initialization, hyperparameter tuning, and model deployment.\nEmphasis is placed on managing imbalanced datasets and optimization techniques.\nParameter-efficient methods like Low-Rank Adaptation (LoRA) and Half\nFine-Tuning are explored for balancing computational efficiency with\nperformance. Advanced techniques such as memory fine-tuning, Mixture of Experts\n(MoE), and Mixture of Agents (MoA) are discussed for leveraging specialized\nnetworks and multi-agent collaboration. The report also examines novel\napproaches like Proximal Policy Optimization (PPO) and Direct Preference\nOptimization (DPO), which align LLMs with human preferences, alongside pruning\nand routing optimizations to improve efficiency. Further sections cover\nvalidation frameworks, post-deployment monitoring, and inference optimization,\nwith attention to deploying LLMs on distributed and cloud-based platforms.\nEmerging areas such as multimodal LLMs, fine-tuning for audio and speech, and\nchallenges related to scalability, privacy, and accountability are also\naddressed. This report offers actionable insights for researchers and\npractitioners navigating LLM fine-tuning in an evolving landscape.\n","authors":["Venkatesh Balavadhani Parthasarathy","Ahtsham Zafar","Aafaq Khan","Arsalan Shahid"],"pdf_url":"https://arxiv.org/pdf/2408.13296v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.10621v3","updated":"2024-10-21T11:06:06Z","published":"2024-06-15T12:48:00Z","title":"StrucText-Eval: Evaluating Large Language Model's Reasoning Ability in\n  Structure-Rich Text","summary":"  The effective utilization of structured data, integral to corporate data\nstrategies, has been challenged by the rise of large language models (LLMs)\ncapable of processing unstructured information. This shift prompts the\nquestion: can LLMs interpret structured data directly in its unstructured form?\nWe propose an automatic evaluation data generation method for assessing LLMs'\nreasoning capabilities on structure-rich text to explore this. Our approach\nsupports 8 structured languages and 29 tasks, generating data with adjustable\ncomplexity through controllable nesting and structural width. We introduce\nStrucText-Eval, a benchmark containing 5,800 pre-generated and annotated\nsamples designed to evaluate how well LLMs understand and reason through\nstructured text. StrucText-Eval is divided into two suites: a regular Test\nsuite (3,712 samples) and a Test-Hard suite (2,088 samples), the latter\nemphasizing the gap between human and model performance on more complex tasks.\nExperimental results show that while open-source LLMs achieve a maximum\naccuracy of 74.9\\% on the standard dataset, their performance drops\nsignificantly to 45.8\\% on the harder dataset. In contrast, human participants\nreach an accuracy of 92.6\\% on StrucText-Eval-Hard, highlighting LLMs' current\nlimitations in handling intricate structural information. The benchmark and\ngeneration codes are open sourced in\n\\url{https://github.com/MikeGu721/StrucText-Eval}\n","authors":["Zhouhong Gu","Haoning Ye","Xingzhou Chen","Zeyang Zhou","Hongwei Feng","Yanghua Xiao"],"pdf_url":"https://arxiv.org/pdf/2406.10621v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.03615v2","updated":"2024-10-21T11:05:27Z","published":"2024-08-07T08:16:32Z","title":"Optimus-1: Hybrid Multimodal Memory Empowered Agents Excel in\n  Long-Horizon Tasks","summary":"  Building a general-purpose agent is a long-standing vision in the field of\nartificial intelligence. Existing agents have made remarkable progress in many\ndomains, yet they still struggle to complete long-horizon tasks in an open\nworld. We attribute this to the lack of necessary world knowledge and\nmultimodal experience that can guide agents through a variety of long-horizon\ntasks. In this paper, we propose a Hybrid Multimodal Memory module to address\nthe above challenges. It 1) transforms knowledge into Hierarchical Directed\nKnowledge Graph that allows agents to explicitly represent and learn world\nknowledge, and 2) summarises historical information into Abstracted Multimodal\nExperience Pool that provide agents with rich references for in-context\nlearning. On top of the Hybrid Multimodal Memory module, a multimodal agent,\nOptimus-1, is constructed with dedicated Knowledge-guided Planner and\nExperience-Driven Reflector, contributing to a better planning and reflection\nin the face of long-horizon tasks in Minecraft. Extensive experimental results\nshow that Optimus-1 significantly outperforms all existing agents on\nchallenging long-horizon task benchmarks, and exhibits near human-level\nperformance on many tasks. In addition, we introduce various Multimodal Large\nLanguage Models (MLLMs) as the backbone of Optimus-1. Experimental results show\nthat Optimus-1 exhibits strong generalization with the help of the Hybrid\nMultimodal Memory module, outperforming the GPT-4V baseline on many tasks.\n","authors":["Zaijing Li","Yuquan Xie","Rui Shao","Gongwei Chen","Dongmei Jiang","Liqiang Nie"],"pdf_url":"https://arxiv.org/pdf/2408.03615v2.pdf","comment":"Accepted by NeurIPS 2024"},{"id":"http://arxiv.org/abs/2410.15884v1","updated":"2024-10-21T11:02:18Z","published":"2024-10-21T11:02:18Z","title":"Using GPT Models for Qualitative and Quantitative News Analytics in the\n  2024 US Presidental Election Process","summary":"  The paper considers an approach of using Google Search API and GPT-4o model\nfor qualitative and quantitative analyses of news through retrieval-augmented\ngeneration (RAG). This approach was applied to analyze news about the 2024 US\npresidential election process. Different news sources for different time\nperiods have been analyzed. Quantitative scores generated by GPT model have\nbeen analyzed using Bayesian regression to derive trend lines. The\ndistributions found for the regression parameters allow for the analysis of\nuncertainty in the election process. The obtained results demonstrate that\nusing the GPT models for news analysis, one can get informative analytics and\nprovide key insights that can be applied in further analyses of election\nprocesses.\n","authors":["Bohdan M. Pavlyshenko"],"pdf_url":"https://arxiv.org/pdf/2410.15884v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2404.07989v3","updated":"2024-10-21T10:54:55Z","published":"2024-04-11T17:59:45Z","title":"Any2Point: Empowering Any-modality Large Models for Efficient 3D\n  Understanding","summary":"  Large foundation models have recently emerged as a prominent focus of\ninterest, attaining superior performance in widespread scenarios. Due to the\nscarcity of 3D data, many efforts have been made to adapt pre-trained\ntransformers from vision to 3D domains. However, such 2D-to-3D approaches are\nstill limited, due to the potential loss of spatial geometries and high\ncomputation cost. More importantly, their frameworks are mainly designed for 2D\nmodels, lacking a general any-to-3D paradigm. In this paper, we introduce\nAny2Point, a parameter-efficient method to empower any-modality large models\n(vision, language, audio) for 3D understanding. Given a frozen transformer from\nany source modality, we propose a 3D-to-any (1D or 2D) virtual projection\nstrategy that correlates the input 3D points to the original 1D or 2D positions\nwithin the source modality. This mechanism enables us to assign each 3D token\nwith a positional encoding paired with the pre-trained model, which avoids 3D\ngeometry loss caused by the true projection and better motivates the\ntransformer for 3D learning with 1D/2D positional priors. Then, within each\ntransformer block, we insert an any-to-3D guided adapter module for\nparameter-efficient fine-tuning. The adapter incorporates prior spatial\nknowledge from the source modality to guide the local feature aggregation of 3D\ntokens, compelling the semantic adaption of any-modality transformers. We\nconduct extensive experiments to showcase the effectiveness and efficiency of\nour method. Code and models are released at\nhttps://github.com/Ivan-Tang-3D/Any2Point.\n","authors":["Yiwen Tang","Ray Zhang","Jiaming Liu","Zoey Guo","Dong Wang","Zhigang Wang","Bin Zhao","Shanghang Zhang","Peng Gao","Hongsheng Li","Xuelong Li"],"pdf_url":"https://arxiv.org/pdf/2404.07989v3.pdf","comment":"Code and models are released at\n  https://github.com/Ivan-Tang-3D/Any2Point"},{"id":"http://arxiv.org/abs/2410.15865v1","updated":"2024-10-21T10:49:54Z","published":"2024-10-21T10:49:54Z","title":"Principles of semantic and functional efficiency in grammatical\n  patterning","summary":"  Grammatical features such as number and gender serve two central functions in\nhuman languages. While they encode salient semantic attributes like numerosity\nand animacy, they also offload sentence processing cost by predictably linking\nwords together via grammatical agreement. Grammars exhibit consistent\norganizational patterns across diverse languages, invariably rooted in a\nsemantic foundation, a widely confirmed but still theoretically unexplained\nphenomenon. To explain the basis of universal grammatical patterns, we unify\ntwo fundamental properties of grammar, semantic encoding and agreement-based\npredictability, into a single information-theoretic objective under cognitive\nconstraints. Our analyses reveal that grammatical organization provably\ninherits from perceptual attributes, but that grammars empirically prioritize\nfunctional goals, promoting efficient language processing over semantic\nencoding.\n","authors":["Emily Cheng","Francesca Franzon"],"pdf_url":"https://arxiv.org/pdf/2410.15865v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.12284v2","updated":"2024-10-21T10:11:11Z","published":"2024-10-16T06:43:02Z","title":"Fool Me Once? Contrasting Textual and Visual Explanations in a Clinical\n  Decision-Support Setting","summary":"  The growing capabilities of AI models are leading to their wider use,\nincluding in safety-critical domains. Explainable AI (XAI) aims to make these\nmodels safer to use by making their inference process more transparent.\nHowever, current explainability methods are seldom evaluated in the way they\nare intended to be used: by real-world end users. To address this, we conducted\na large-scale user study with 85 healthcare practitioners in the context of\nhuman-AI collaborative chest X-ray analysis. We evaluated three types of\nexplanations: visual explanations (saliency maps), natural language\nexplanations, and a combination of both modalities. We specifically examined\nhow different explanation types influence users depending on whether the AI\nadvice and explanations are factually correct. We find that text-based\nexplanations lead to significant over-reliance, which is alleviated by\ncombining them with saliency maps. We also observe that the quality of\nexplanations, that is, how much factually correct information they entail, and\nhow much this aligns with AI correctness, significantly impacts the usefulness\nof the different explanation types.\n","authors":["Maxime Kayser","Bayar Menzat","Cornelius Emde","Bogdan Bercean","Alex Novak","Abdala Espinosa","Bartlomiej W. Papiez","Susanne Gaube","Thomas Lukasiewicz","Oana-Maria Camburu"],"pdf_url":"https://arxiv.org/pdf/2410.12284v2.pdf","comment":"EMNLP 2024"},{"id":"http://arxiv.org/abs/2408.04167v2","updated":"2024-10-21T09:48:08Z","published":"2024-08-08T02:28:32Z","title":"mbrs: A Library for Minimum Bayes Risk Decoding","summary":"  Minimum Bayes risk (MBR) decoding is a decision rule of text generation tasks\nthat outperforms conventional maximum a posterior (MAP) decoding using beam\nsearch by selecting high-quality outputs based on a utility function rather\nthan those with high-probability. Typically, it finds the most suitable\nhypothesis from the set of hypotheses under the sampled pseudo-references. mbrs\nis a library of MBR decoding, which can flexibly combine various metrics,\nalternative expectation estimations, and algorithmic variants. It is designed\nwith a focus on speed measurement and calling count of code blocks,\ntransparency, reproducibility, and extensibility, which are essential for\nresearchers and developers. We published our mbrs as an MIT-licensed\nopen-source project, and the code is available on GitHub.\n  GitHub: https://github.com/naist-nlp/mbrs\n","authors":["Hiroyuki Deguchi","Yusuke Sakai","Hidetaka Kamigaito","Taro Watanabe"],"pdf_url":"https://arxiv.org/pdf/2408.04167v2.pdf","comment":"Accepted at EMNLP2024 System Demonstration track"},{"id":"http://arxiv.org/abs/2402.14296v3","updated":"2024-10-21T09:42:55Z","published":"2024-02-22T05:17:49Z","title":"Mitigating Biases of Large Language Models in Stance Detection with\n  Counterfactual Augmented Calibration","summary":"  Stance detection is critical for understanding the underlying position or\nattitude expressed toward a topic. Large language models (LLMs) have\ndemonstrated significant advancements across various natural language\nprocessing tasks including stance detection, however, their performance in\nstance detection is limited by biases and spurious correlations inherent due to\ntheir data-driven nature. Our statistical experiment reveals that LLMs are\nprone to generate biased stances due to sentiment-stance spurious correlations\nand preference towards certain individuals and topics. Furthermore, the results\ndemonstrate a strong negative correlation between stance bias and stance\ndetection performance, underscoring the importance of mitigating bias to\nenhance the utility of LLMs in stance detection. Therefore, in this paper, we\npropose a Counterfactual Augmented Calibration Network (FACTUAL), which a novel\ncalibration network is devised to calibrate potential bias in the stance\nprediction of LLMs. Further, to address the challenge of effectively learning\nbias representations and the difficulty in the generalizability of debiasing,\nwe construct counterfactual augmented data. This approach enhances the\ncalibration network, facilitating the debiasing and out-of-domain\ngeneralization. Experimental results on in-target and zero-shot stance\ndetection tasks show that the proposed FACTUAL can effectively mitigate biases\nof LLMs, achieving state-of-the-art results.\n","authors":["Ang Li","Jingqian Zhao","Bin Liang","Lin Gui","Hui Wang","Xi Zeng","Xingwei Liang","Kam-Fai Wong","Ruifeng Xu"],"pdf_url":"https://arxiv.org/pdf/2402.14296v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.15825v1","updated":"2024-10-21T09:42:13Z","published":"2024-10-21T09:42:13Z","title":"Did somebody say \"Gest-IT\"? A pilot exploration of multimodal data\n  management","summary":"  The paper presents a pilot exploration of the construction, management and\nanalysis of a multimodal corpus. Through a three-layer annotation that provides\northographic, prosodic, and gestural transcriptions, the Gest-IT resource\nallows to investigate the variation of gesture-making patterns in conversations\nbetween sighted people and people with visual impairment. After discussing the\ntranscription methods and technical procedures employed in our study, we\npropose a unified CoNLL-U corpus and indicate our future steps\n","authors":["Ludovica Pannitto","Lorenzo Albanesi","Laura Marion","Federica Maria Martines","Carmelo Caruso","Claudia S. Bianchini","Francesca Masini","Caterina Mauri"],"pdf_url":"https://arxiv.org/pdf/2410.15825v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.05846v2","updated":"2024-10-21T09:38:03Z","published":"2024-03-09T09:11:49Z","title":"Diffusion Lens: Interpreting Text Encoders in Text-to-Image Pipelines","summary":"  Text-to-image diffusion models (T2I) use a latent representation of a text\nprompt to guide the image generation process. However, the process by which the\nencoder produces the text representation is unknown. We propose the Diffusion\nLens, a method for analyzing the text encoder of T2I models by generating\nimages from its intermediate representations. Using the Diffusion Lens, we\nperform an extensive analysis of two recent T2I models. Exploring compound\nprompts, we find that complex scenes describing multiple objects are composed\nprogressively and more slowly compared to simple scenes; Exploring knowledge\nretrieval, we find that representation of uncommon concepts requires further\ncomputation compared to common concepts, and that knowledge retrieval is\ngradual across layers. Overall, our findings provide valuable insights into the\ntext encoder component in T2I pipelines.\n","authors":["Michael Toker","Hadas Orgad","Mor Ventura","Dana Arad","Yonatan Belinkov"],"pdf_url":"https://arxiv.org/pdf/2403.05846v2.pdf","comment":"Published in: ACL 2024 Project webpage:\n  tokeron.github.io/DiffusionLensWeb"},{"id":"http://arxiv.org/abs/2410.12691v3","updated":"2024-10-21T09:28:12Z","published":"2024-10-16T15:51:18Z","title":"Building Better: Avoiding Pitfalls in Developing Language Resources when\n  Data is Scarce","summary":"  Language is a symbolic capital that affects people's lives in many ways\n(Bourdieu, 1977, 1991). It is a powerful tool that accounts for identities,\ncultures, traditions, and societies in general. Hence, data in a given language\nshould be viewed as more than a collection of tokens. Good data collection and\nlabeling practices are key to building more human-centered and socially aware\ntechnologies. While there has been a rising interest in mid- to low-resource\nlanguages within the NLP community, work in this space has to overcome unique\nchallenges such as data scarcity and access to suitable annotators. In this\npaper, we collect feedback from those directly involved in and impacted by NLP\nartefacts for mid- to low-resource languages. We conduct a quantitative and\nqualitative analysis of the responses and highlight the main issues related to\n(1) data quality such as linguistic and cultural data suitability; and (2) the\nethics of common annotation practices such as the misuse of online community\nservices. Based on these findings, we make several recommendations for the\ncreation of high-quality language artefacts that reflect the cultural milieu of\nits speakers, while simultaneously respecting the dignity and labor of data\nworkers.\n","authors":["Nedjma Ousidhoum","Meriem Beloucif","Saif M. Mohammad"],"pdf_url":"https://arxiv.org/pdf/2410.12691v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.15801v1","updated":"2024-10-21T09:18:30Z","published":"2024-10-21T09:18:30Z","title":"Improve Dense Passage Retrieval with Entailment Tuning","summary":"  Retrieval module can be plugged into many downstream NLP tasks to improve\ntheir performance, such as open-domain question answering and\nretrieval-augmented generation. The key to a retrieval system is to calculate\nrelevance scores to query and passage pairs. However, the definition of\nrelevance is often ambiguous. We observed that a major class of relevance\naligns with the concept of entailment in NLI tasks. Based on this observation,\nwe designed a method called entailment tuning to improve the embedding of dense\nretrievers. Specifically, we unify the form of retrieval data and NLI data\nusing existence claim as a bridge. Then, we train retrievers to predict the\nclaims entailed in a passage with a variant task of masked prediction. Our\nmethod can be efficiently plugged into current dense retrieval methods, and\nexperiments show the effectiveness of our method.\n","authors":["Lu Dai","Hao Liu","Hui Xiong"],"pdf_url":"https://arxiv.org/pdf/2410.15801v1.pdf","comment":"EMNLP 2024 Main"},{"id":"http://arxiv.org/abs/2408.10724v2","updated":"2024-10-21T08:58:39Z","published":"2024-08-20T10:45:36Z","title":"Crafting Tomorrow's Headlines: Neural News Generation and Detection in\n  English, Turkish, Hungarian, and Persian","summary":"  In the era dominated by information overload and its facilitation with Large\nLanguage Models (LLMs), the prevalence of misinformation poses a significant\nthreat to public discourse and societal well-being. A critical concern at\npresent involves the identification of machine-generated news. In this work, we\ntake a significant step by introducing a benchmark dataset designed for neural\nnews detection in four languages: English, Turkish, Hungarian, and Persian. The\ndataset incorporates outputs from multiple multilingual generators (in both,\nzero-shot and fine-tuned setups) such as BloomZ, LLaMa-2, Mistral, Mixtral, and\nGPT-4. Next, we experiment with a variety of classifiers, ranging from those\nbased on linguistic features to advanced Transformer-based models and LLMs\nprompting. We present the detection results aiming to delve into the\ninterpretablity and robustness of machine-generated texts detectors across all\ntarget languages.\n","authors":["Cem Üyük","Danica Rovó","Shaghayegh Kolli","Rabia Varol","Georg Groh","Daryna Dementieva"],"pdf_url":"https://arxiv.org/pdf/2408.10724v2.pdf","comment":"EMNLP 2024 NLP4PI Workshop"},{"id":"http://arxiv.org/abs/2407.12831v2","updated":"2024-10-21T08:55:49Z","published":"2024-07-03T13:01:54Z","title":"Truth is Universal: Robust Detection of Lies in LLMs","summary":"  Large Language Models (LLMs) have revolutionised natural language processing,\nexhibiting impressive human-like capabilities. In particular, LLMs are capable\nof \"lying\", knowingly outputting false statements. Hence, it is of interest and\nimportance to develop methods to detect when LLMs lie. Indeed, several authors\ntrained classifiers to detect LLM lies based on their internal model\nactivations. However, other researchers showed that these classifiers may fail\nto generalise, for example to negated statements. In this work, we aim to\ndevelop a robust method to detect when an LLM is lying. To this end, we make\nthe following key contributions: (i) We demonstrate the existence of a\ntwo-dimensional subspace, along which the activation vectors of true and false\nstatements can be separated. Notably, this finding is universal and holds for\nvarious LLMs, including Gemma-7B, LLaMA2-13B, Mistral-7B and LLaMA3-8B. Our\nanalysis explains the generalisation failures observed in previous studies and\nsets the stage for more robust lie detection; (ii) Building upon (i), we\nconstruct an accurate LLM lie detector. Empirically, our proposed classifier\nachieves state-of-the-art performance, attaining 94% accuracy in both\ndistinguishing true from false factual statements and detecting lies generated\nin real-world scenarios.\n","authors":["Lennart Bürger","Fred A. Hamprecht","Boaz Nadler"],"pdf_url":"https://arxiv.org/pdf/2407.12831v2.pdf","comment":"NeurIPS 2024 poster"},{"id":"http://arxiv.org/abs/2405.20648v2","updated":"2024-10-21T08:52:10Z","published":"2024-05-31T07:30:24Z","title":"Shotluck Holmes: A Family of Efficient Small-Scale Large Language Vision\n  Models For Video Captioning and Summarization","summary":"  Video is an increasingly prominent and information-dense medium, yet it poses\nsubstantial challenges for language models. A typical video consists of a\nsequence of shorter segments, or shots, that collectively form a coherent\nnarrative. Each shot is analogous to a word in a sentence where multiple data\nstreams of information (such as visual and auditory data) must be processed\nsimultaneously. Comprehension of the entire video requires not only\nunderstanding the visual-audio information of each shot but also requires that\nthe model links the ideas between each shot to generate a larger,\nall-encompassing story. Despite significant progress in the field, current\nworks often overlook videos' more granular shot-by-shot semantic information.\nIn this project, we propose a family of efficient large language vision models\n(LLVMs) to boost video summarization and captioning called Shotluck Holmes. By\nleveraging better pretraining and data collection strategies, we extend the\nabilities of existing small LLVMs from being able to understand a picture to\nbeing able to understand a sequence of frames. Specifically, we show that\nShotluck Holmes achieves better performance than state-of-the-art results on\nthe Shot2Story video captioning and summary task with significantly smaller and\nmore computationally efficient models.\n","authors":["Richard Luo","Austin Peng","Adithya Vasudev","Rishabh Jain"],"pdf_url":"https://arxiv.org/pdf/2405.20648v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.08703v2","updated":"2024-10-21T08:49:18Z","published":"2024-10-11T10:47:02Z","title":"On the token distance modeling ability of higher RoPE attention\n  dimension","summary":"  Length extrapolation algorithms based on Rotary position embedding (RoPE)\nhave shown promising results in extending the context length of language\nmodels. However, understanding how position embedding can capture longer-range\ncontextual information remains elusive. Based on the intuition that different\ndimensions correspond to different frequency of changes in RoPE encoding, we\nconducted a dimension-level analysis to investigate the correlation between a\nhidden dimension of an attention head and its contribution to capturing\nlong-distance dependencies. Using our correlation metric, we identified a\nparticular type of attention heads, which we named Positional Heads, from\nvarious length-extrapolated models. These heads exhibit a strong focus on\nlong-range information interaction and play a pivotal role in long input\nprocessing, as evidence by our ablation. We further demonstrate the correlation\nbetween the efficiency of length extrapolation and the extension of the\nhigh-dimensional attention allocation of these heads. The identification of\nPositional Heads provides insights for future research in long-text\ncomprehension.\n","authors":["Xiangyu Hong","Che Jiang","Biqing Qi","Fandong Meng","Mo Yu","Bowen Zhou","Jie Zhou"],"pdf_url":"https://arxiv.org/pdf/2410.08703v2.pdf","comment":"Accepted to EMNLP 2024 Findings"},{"id":"http://arxiv.org/abs/2407.18698v2","updated":"2024-10-21T08:43:41Z","published":"2024-07-26T12:23:54Z","title":"Adaptive Contrastive Search: Uncertainty-Guided Decoding for Open-Ended\n  Text Generation","summary":"  Decoding from the output distributions of large language models to produce\nhigh-quality text is a complex challenge in language modeling. Various\napproaches, such as beam search, sampling with temperature, $k-$sampling,\nnucleus $p-$sampling, typical decoding, contrastive decoding, and contrastive\nsearch, have been proposed to address this problem, aiming to improve\ncoherence, diversity, as well as resemblance to human-generated text. In this\nstudy, we introduce adaptive contrastive search, a novel decoding strategy\nextending contrastive search by incorporating an adaptive degeneration penalty,\nguided by the estimated uncertainty of the model at each generation step. This\nstrategy is designed to enhance both the creativity and diversity of the\nlanguage modeling process while at the same time producing coherent and\nhigh-quality generated text output. Our findings indicate performance\nenhancement in both aspects, across different model architectures and datasets,\nunderscoring the effectiveness of our method in text generation tasks. Our code\nbase, datasets, and models are publicly available.\n","authors":["Esteban Garces Arias","Julian Rodemann","Meimingwei Li","Christian Heumann","Matthias Aßenmacher"],"pdf_url":"https://arxiv.org/pdf/2407.18698v2.pdf","comment":"Accepted to EMNLP 2024 Findings"},{"id":"http://arxiv.org/abs/2410.15761v1","updated":"2024-10-21T08:21:00Z","published":"2024-10-21T08:21:00Z","title":"Learning-to-Defer for Extractive Question Answering","summary":"  Pre-trained language models have profoundly impacted the field of extractive\nquestion-answering, leveraging large-scale textual corpora to enhance\ncontextual language understanding. Despite their success, these models struggle\nin complex scenarios that demand nuanced interpretation or inferential\nreasoning beyond immediate textual cues. Furthermore, their size poses\ndeployment challenges on resource-constrained devices. Addressing these\nlimitations, we introduce an adapted two-stage Learning-to-Defer mechanism that\nenhances decision-making by enabling selective deference to human experts or\nlarger models without retraining language models in the context of\nquestion-answering. This approach not only maintains computational efficiency\nbut also significantly improves model reliability and accuracy in ambiguous\ncontexts. We establish the theoretical soundness of our methodology by proving\nBayes and $(\\mathcal{H}, \\mathcal{R})$--consistency of our surrogate loss\nfunction, guaranteeing the optimality of the final solution. Empirical\nevaluations on the SQuADv2 dataset illustrate performance gains from\nintegrating human expertise and leveraging larger models. Our results further\ndemonstrate that deferring a minimal number of queries allows the smaller model\nto achieve performance comparable to their larger counterparts while preserving\ncomputing efficiency, thus broadening the applicability of pre-trained language\nmodels in diverse operational environments.\n","authors":["Montreuil Yannis","Carlier Axel","Ng Lai Xing","Ooi Wei Tsang"],"pdf_url":"https://arxiv.org/pdf/2410.15761v1.pdf","comment":"25 pages, 17 main paper"},{"id":"http://arxiv.org/abs/2410.10270v3","updated":"2024-10-21T08:13:45Z","published":"2024-10-14T08:21:25Z","title":"QUIS: Question-guided Insights Generation for Automated Exploratory Data\n  Analysis","summary":"  Discovering meaningful insights from a large dataset, known as Exploratory\nData Analysis (EDA), is a challenging task that requires thorough exploration\nand analysis of the data. Automated Data Exploration (ADE) systems use\ngoal-oriented methods with Large Language Models and Reinforcement Learning\ntowards full automation. However, these methods require human involvement to\nanticipate goals that may limit insight extraction, while fully automated\nsystems demand significant computational resources and retraining for new\ndatasets. We introduce QUIS, a fully automated EDA system that operates in two\nstages: insight generation (ISGen) driven by question generation (QUGen). The\nQUGen module generates questions in iterations, refining them from previous\niterations to enhance coverage without human intervention or manually curated\nexamples. The ISGen module analyzes data to produce multiple relevant insights\nin response to each question, requiring no prior training and enabling QUIS to\nadapt to new datasets.\n","authors":["Abhijit Manatkar","Ashlesha Akella","Parthivi Gupta","Krishnasuri Narayanam"],"pdf_url":"https://arxiv.org/pdf/2410.10270v3.pdf","comment":"Accepted for EMNLP 2024 Industry Track"},{"id":"http://arxiv.org/abs/2408.10188v4","updated":"2024-10-21T08:12:42Z","published":"2024-08-19T17:48:08Z","title":"LongVILA: Scaling Long-Context Visual Language Models for Long Videos","summary":"  Long-context capability is critical for multi-modal foundation models,\nespecially for long video understanding. We introduce LongVILA, a full-stack\nsolution for long-context visual-language models \\qinghao{by co-designing the\nalgorithm and system. For model training, we upgrade existing VLMs to support\nlong video understanding by incorporating two additional stages, {\\em i.e.},\nlong context extension and long video supervised fine-tuning. However, training\non long video is computationally and memory intensive. We introduce the\nlong-context Multi-Modal Sequence Parallelism (MM-SP) system that efficiently\nparallelizes long video training and inference, enabling 2M context length\ntraining on 256 GPUs without any gradient checkpointing. LongVILA efficiently\nextends the number of video frames of VILA from 8 to 2048, improving the long\nvideo captioning score from 2.00 to 3.26 (out of 5), achieving 99.8% accuracy\nin 6,000-frame (more than 1 million tokens) video needle-in-a-haystack.\nLongVILA-7B demonstrates strong accuracy on the VideoMME benchmark, i.e., 61.8%\nwith subtitle. Besides, MM-SP is 2.1x - 5.7x faster than ring style sequence\nparallelism and 1.1x - 1.4x faster than Megatron with a hybrid context and\ntensor parallelism. Moreover, it seamlessly integrates with Hugging Face\nTransformers.\n","authors":["Fuzhao Xue","Yukang Chen","Dacheng Li","Qinghao Hu","Ligeng Zhu","Xiuyu Li","Yunhao Fang","Haotian Tang","Shang Yang","Zhijian Liu","Ethan He","Hongxu Yin","Pavlo Molchanov","Jan Kautz","Linxi Fan","Yuke Zhu","Yao Lu","Song Han"],"pdf_url":"https://arxiv.org/pdf/2408.10188v4.pdf","comment":"Code and models are available at\n  https://github.com/NVlabs/VILA/blob/main/LongVILA.md"},{"id":"http://arxiv.org/abs/2410.15753v1","updated":"2024-10-21T08:11:47Z","published":"2024-10-21T08:11:47Z","title":"Natural Language Querying System Through Entity Enrichment","summary":"  This paper focuses on a domain expert querying system over databases. It\npresents a solution designed for a French enterprise interested in offering a\nnatural language interface for its clients. The approach, based on entity\nenrichment, aims at translating natural language queries into database queries.\nIn this paper, the database is treated through a logical paradigm, suggesting\nthe adaptability of our approach to different database models. The good\nprecision of our method is shown through some preliminary experiments.\n","authors":["Joshua Amavi","Mirian Halfeld Ferrari","Nicolas Hiot"],"pdf_url":"https://arxiv.org/pdf/2410.15753v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.15743v1","updated":"2024-10-21T08:01:46Z","published":"2024-10-21T08:01:46Z","title":"Toeing the Party Line: Election Manifestos as a Key to Understand\n  Political Discourse on Twitter","summary":"  Political discourse on Twitter is a moving target: politicians continuously\nmake statements about their positions. It is therefore crucial to track their\ndiscourse on social media to understand their ideological positions and goals.\nHowever, Twitter data is also challenging to work with since it is ambiguous\nand often dependent on social context, and consequently, recent work on\npolitical positioning has tended to focus strongly on manifestos (parties'\nelectoral programs) rather than social media.\n  In this paper, we extend recently proposed methods to predict pairwise\npositional similarities between parties from the manifesto case to the Twitter\ncase, using hashtags as a signal to fine-tune text representations, without the\nneed for manual annotation. We verify the efficacy of fine-tuning and conduct a\nseries of experiments that assess the robustness of our method for low-resource\nscenarios. We find that our method yields stable positioning reflective of\nmanifesto positioning, both in scenarios with all tweets of candidates across\nyears available and when only smaller subsets from shorter time periods are\navailable. This indicates that it is possible to reliably analyze the relative\npositioning of actors forgoing manual annotation, even in the noisier context\nof social media.\n","authors":["Maximilian Maurer","Tanise Ceron","Sebastian Padó","Gabriella Lapesa"],"pdf_url":"https://arxiv.org/pdf/2410.15743v1.pdf","comment":"9 pages, accepted at EMNLP (Findings) 2024"},{"id":"http://arxiv.org/abs/2410.15737v1","updated":"2024-10-21T07:56:45Z","published":"2024-10-21T07:56:45Z","title":"Who's Who: Large Language Models Meet Knowledge Conflicts in Practice","summary":"  Retrieval-augmented generation (RAG) methods are viable solutions for\naddressing the static memory limits of pre-trained language models.\nNevertheless, encountering conflicting sources of information within the\nretrieval context is an inevitable practical challenge. In such situations, the\nlanguage models are recommended to transparently inform users about the\nconflicts rather than autonomously deciding what to present based on their\ninherent biases. To analyze how current large language models (LLMs) align with\nour recommendation, we introduce WhoQA, a public benchmark dataset to examine\nmodel's behavior in knowledge conflict situations. We induce conflicts by\nasking about a common property among entities having the same name, resulting\nin questions with up to 8 distinctive answers. WhoQA evaluation set includes 5K\nquestions across 13 Wikidata property types and 150K Wikipedia entities. Our\nexperiments show that despite the simplicity of WhoQA questions, knowledge\nconflicts significantly degrades LLMs' performance in RAG settings.\n","authors":["Quang Hieu Pham","Hoang Ngo","Anh Tuan Luu","Dat Quoc Nguyen"],"pdf_url":"https://arxiv.org/pdf/2410.15737v1.pdf","comment":"Accepted to EMNLP 2024 Findings"},{"id":"http://arxiv.org/abs/2410.15726v1","updated":"2024-10-21T07:44:01Z","published":"2024-10-21T07:44:01Z","title":"Reducing annotator bias by belief elicitation","summary":"  Crowdsourced annotations of data play a substantial role in the development\nof Artificial Intelligence (AI). It is broadly recognised that annotations of\ntext data can contain annotator bias, where systematic disagreement in\nannotations can be traced back to differences in the annotators' backgrounds.\nBeing unaware of such annotator bias can lead to representational bias against\nminority group perspectives and therefore several methods have been proposed\nfor recognising bias or preserving perspectives. These methods typically\nrequire either a substantial number of annotators or annotations per data\ninstance. In this study, we propose a simple method for handling bias in\nannotations without requirements on the number of annotators or instances.\nInstead, we ask annotators about their beliefs of other annotators' judgements\nof an instance, under the hypothesis that these beliefs may provide more\nrepresentative and less biased labels than judgements. The method was examined\nin two controlled, survey-based experiments involving Democrats and Republicans\n(n=1,590) asked to judge statements as arguments and then report beliefs about\nothers' judgements. The results indicate that bias, defined as systematic\ndifferences between the two groups of annotators, is consistently reduced when\nasking for beliefs instead of judgements. Our proposed method therefore has the\npotential to reduce the risk of annotator bias, thereby improving the\ngeneralisability of AI systems and preventing harm to unrepresented\nsocio-demographic groups, and we highlight the need for further studies of this\npotential in other tasks and downstream applications.\n","authors":["Terne Sasha Thorn Jakobsen","Andreas Bjerre-Nielsen","Robert Böhm"],"pdf_url":"https://arxiv.org/pdf/2410.15726v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.15702v1","updated":"2024-10-21T07:19:19Z","published":"2024-10-21T07:19:19Z","title":"Mitigating Hallucinations of Large Language Models in Medical\n  Information Extraction via Contrastive Decoding","summary":"  The impressive capabilities of large language models (LLMs) have attracted\nextensive interests of applying LLMs to medical field. However, the complex\nnature of clinical environments presents significant hallucination challenges\nfor LLMs, hindering their widespread adoption. In this paper, we address these\nhallucination issues in the context of Medical Information Extraction (MIE)\ntasks by introducing ALternate Contrastive Decoding (ALCD). We begin by\nredefining MIE tasks as an identify-and-classify process. We then separate the\nidentification and classification functions of LLMs by selectively masking the\noptimization of tokens during fine-tuning. During the inference stage, we\nalternately contrast output distributions derived from sub-task models. This\napproach aims to selectively enhance the identification and classification\ncapabilities while minimizing the influence of other inherent abilities in\nLLMs. Additionally, we propose an alternate adaptive constraint strategy to\nmore effectively adjust the scale and scope of contrastive tokens. Through\ncomprehensive experiments on two different backbones and six diverse medical\ninformation extraction tasks, ALCD demonstrates significant improvements in\nresolving hallucination issues compared to conventional decoding methods.\n","authors":["Derong Xu","Ziheng Zhang","Zhihong Zhu","Zhenxi Lin","Qidong Liu","Xian Wu","Tong Xu","Xiangyu Zhao","Yefeng Zheng","Enhong Chen"],"pdf_url":"https://arxiv.org/pdf/2410.15702v1.pdf","comment":"Accepted by EMNLP 2024 Findings"},{"id":"http://arxiv.org/abs/2410.15700v1","updated":"2024-10-21T07:18:23Z","published":"2024-10-21T07:18:23Z","title":"InternLM2.5-StepProver: Advancing Automated Theorem Proving via Expert\n  Iteration on Large-Scale LEAN Problems","summary":"  Large Language Models (LLMs) have emerged as powerful tools in mathematical\ntheorem proving, particularly when utilizing formal languages such as LEAN. The\nmajor learning paradigm is expert iteration, which necessitates a pre-defined\ndataset comprising numerous mathematical problems. In this process, LLMs\nattempt to prove problems within the dataset and iteratively refine their\ncapabilities through self-training on the proofs they discover. We propose to\nuse large scale LEAN problem datasets Lean-workbook for expert iteration with\nmore than 20,000 CPU days. During expert iteration, we found log-linear trends\nbetween solved problem amount with proof length and CPU usage. We train a\ncritic model to select relatively easy problems for policy models to make\ntrials and guide the model to search for deeper proofs. InternLM2.5-StepProver\nachieves open-source state-of-the-art on MiniF2F, Lean-Workbook-Plus, ProofNet,\nand Putnam benchmarks. Specifically, it achieves a pass of 65.9% on the\nMiniF2F-test and proves (or disproves) 17.0% of problems in Lean-Workbook-Plus\nwhich shows a significant improvement compared to only 9.5% of problems proved\nwhen Lean-Workbook-Plus was released. We open-source our models and searched\nproofs at https://github.com/InternLM/InternLM-Math and\nhttps://huggingface.co/datasets/internlm/Lean-Workbook.\n","authors":["Zijian Wu","Suozhi Huang","Zhejian Zhou","Huaiyuan Ying","Jiayu Wang","Dahua Lin","Kai Chen"],"pdf_url":"https://arxiv.org/pdf/2410.15700v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.19170v2","updated":"2024-10-21T07:17:20Z","published":"2024-06-27T13:44:03Z","title":"The Illusion of Competence: Evaluating the Effect of Explanations on\n  Users' Mental Models of Visual Question Answering Systems","summary":"  We examine how users perceive the limitations of an AI system when it\nencounters a task that it cannot perform perfectly and whether providing\nexplanations alongside its answers aids users in constructing an appropriate\nmental model of the system's capabilities and limitations. We employ a visual\nquestion answer and explanation task where we control the AI system's\nlimitations by manipulating the visual inputs: during inference, the system\neither processes full-color or grayscale images. Our goal is to determine\nwhether participants can perceive the limitations of the system. We hypothesize\nthat explanations will make limited AI capabilities more transparent to users.\nHowever, our results show that explanations do not have this effect. Instead of\nallowing users to more accurately assess the limitations of the AI system,\nexplanations generally increase users' perceptions of the system's competence -\nregardless of its actual performance.\n","authors":["Judith Sieker","Simeon Junker","Ronja Utescher","Nazia Attari","Heiko Wersing","Hendrik Buschmeier","Sina Zarrieß"],"pdf_url":"https://arxiv.org/pdf/2406.19170v2.pdf","comment":"17 pages (including Appendix). Accepted at EMNLP 2024 main"},{"id":"http://arxiv.org/abs/2410.13699v2","updated":"2024-10-21T07:12:26Z","published":"2024-10-17T16:04:07Z","title":"Unconstrained Model Merging for Enhanced LLM Reasoning","summary":"  Recent advancements in building domain-specific large language models (LLMs)\nhave shown remarkable success, especially in tasks requiring reasoning\nabilities like logical inference over complex relationships and multi-step\nproblem solving. However, creating a powerful all-in-one LLM remains\nchallenging due to the need for proprietary data and vast computational\nresources. As a resource-friendly alternative, we explore the potential of\nmerging multiple expert models into a single LLM. Existing studies on model\nmerging mainly focus on generalist LLMs instead of domain experts, or the LLMs\nunder the same architecture and size. In this work, we propose an unconstrained\nmodel merging framework that accommodates both homogeneous and heterogeneous\nmodel architectures with a focus on reasoning tasks. A fine-grained layer-wise\nweight merging strategy is designed for homogeneous models merging, while\nheterogeneous model merging is built upon the probabilistic distribution\nknowledge derived from instruction-response fine-tuning data. Across 7\nbenchmarks and 9 reasoning-optimized LLMs, we reveal key findings that\ncombinatorial reasoning emerges from merging which surpasses simple additive\neffects. We propose that unconstrained model merging could serve as a\nfoundation for decentralized LLMs, marking a notable progression from the\nexisting centralized LLM framework. This evolution could enhance wider\nparticipation and stimulate additional advancement in the field of artificial\nintelligence, effectively addressing the constraints posed by centralized\nmodels.\n","authors":["Yiming Zhang","Baoyi He","Shengyu Zhang","Yuhao Fu","Qi Zhou","Zhijie Sang","Zijin Hong","Kejing Yang","Wenjun Wang","Jianbo Yuan","Guanghan Ning","Linyi Li","Chunlin Ji","Fei Wu","Hongxia Yang"],"pdf_url":"https://arxiv.org/pdf/2410.13699v2.pdf","comment":"Under review, correct typos"},{"id":"http://arxiv.org/abs/2410.15696v1","updated":"2024-10-21T07:10:07Z","published":"2024-10-21T07:10:07Z","title":"Tokenization as Finite-State Transduction","summary":"  Tokenization is the first step in modern neural language model pipelines\nwhere an input text is converted to a sequence of subword tokens. We introduce\nfrom first principles a finite-state transduction framework which can\nefficiently encode all possible tokenizations of a regular language. We then\nconstructively show that Byte-Pair Encoding (BPE) and MaxMatch (WordPiece), two\npopular tokenization schemes, fit within this framework. For BPE, this is\nparticularly surprising given its resemblance to context-free grammar and the\nfact that it does not tokenize strings from left to right.\n  An application of this is to guided generation, where the outputs of a\nlanguage model are constrained to match some pattern. Here, patterns are\nencoded at the character level, which creates a mismatch between the\nconstraints and the model's subword vocabulary. While past work has focused\nonly on constraining outputs without regard to the underlying tokenization\nalgorithm, our framework allows for simultaneously constraining the model\noutputs to match a specified pattern while also adhering to the underlying\ntokenizer's canonical tokenization.\n","authors":["Marco Cognetta","Naoaki Okazaki"],"pdf_url":"https://arxiv.org/pdf/2410.15696v1.pdf","comment":"10 pages + 5 pages in appendix"},{"id":"http://arxiv.org/abs/2406.05392v2","updated":"2024-10-21T07:08:11Z","published":"2024-06-08T07:55:01Z","title":"Deconstructing The Ethics of Large Language Models from Long-standing\n  Issues to New-emerging Dilemmas: A Survey","summary":"  Large Language Models (LLMs) have achieved unparalleled success across\ndiverse language modeling tasks in recent years. However, this progress has\nalso intensified ethical concerns, impacting the deployment of LLMs in everyday\ncontexts. This paper provides a comprehensive survey of ethical challenges\nassociated with LLMs, from longstanding issues such as copyright infringement,\nsystematic bias, and data privacy, to emerging problems like truthfulness and\nsocial norms. We critically analyze existing research aimed at understanding,\nexamining, and mitigating these ethical risks. Our survey underscores\nintegrating ethical standards and societal values into the development of LLMs,\nthereby guiding the development of responsible and ethically aligned language\nmodels.\n","authors":["Chengyuan Deng","Yiqun Duan","Xin Jin","Heng Chang","Yijun Tian","Han Liu","Yichen Wang","Kuofeng Gao","Henry Peng Zou","Yiqiao Jin","Yijia Xiao","Shenghao Wu","Zongxing Xie","Weimin Lyu","Sihong He","Lu Cheng","Haohan Wang","Jun Zhuang"],"pdf_url":"https://arxiv.org/pdf/2406.05392v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.15690v1","updated":"2024-10-21T07:01:25Z","published":"2024-10-21T07:01:25Z","title":"Efficient Terminology Integration for LLM-based Translation in\n  Specialized Domains","summary":"  Traditional machine translation methods typically involve training models\ndirectly on large parallel corpora, with limited emphasis on specialized\nterminology. However, In specialized fields such as patent, finance, or\nbiomedical domains, terminology is crucial for translation, with many terms\nthat needs to be translated following agreed-upon conventions. In this paper we\nintroduce a methodology that efficiently trains models with a smaller amount of\ndata while preserving the accuracy of terminology translation. We achieve this\nthrough a systematic process of term extraction and glossary creation using the\nTrie Tree algorithm, followed by data reconstruction to teach the LLM how to\nintegrate these specialized terms. This methodology enhances the model's\nability to handle specialized terminology and ensures high-quality\ntranslations, particularly in fields where term consistency is crucial. Our\napproach has demonstrated exceptional performance, achieving the highest\ntranslation score among participants in the WMT patent task to date, showcasing\nits effectiveness and broad applicability in specialized translation domains\nwhere general methods often fall short.\n","authors":["Sejoon Kim","Mingi Sung","Jeonghwan Lee","Hyunkuk Lim","Jorge Froilan Gimenez Perez"],"pdf_url":"https://arxiv.org/pdf/2410.15690v1.pdf","comment":"Accepted to WMT 2024"},{"id":"http://arxiv.org/abs/2402.06900v4","updated":"2024-10-21T06:56:26Z","published":"2024-02-10T07:55:27Z","title":"Can LLMs Recognize Toxicity? A Structured Investigation Framework and\n  Toxicity Metric","summary":"  In the pursuit of developing Large Language Models (LLMs) that adhere to\nsocietal standards, it is imperative to detect the toxicity in the generated\ntext. The majority of existing toxicity metrics rely on encoder models trained\non specific toxicity datasets, which are susceptible to out-of-distribution\n(OOD) problems and depend on the dataset's definition of toxicity. In this\npaper, we introduce a robust metric grounded on LLMs to flexibly measure\ntoxicity according to the given definition. We first analyze the toxicity\nfactors, followed by an examination of the intrinsic toxic attributes of LLMs\nto ascertain their suitability as evaluators. Finally, we evaluate the\nperformance of our metric with detailed analysis. Our empirical results\ndemonstrate outstanding performance in measuring toxicity within verified\nfactors, improving on conventional metrics by 12 points in the F1 score. Our\nfindings also indicate that upstream toxicity significantly influences\ndownstream metrics, suggesting that LLMs are unsuitable for toxicity\nevaluations within unverified factors.\n","authors":["Hyukhun Koh","Dohyung Kim","Minwoo Lee","Kyomin Jung"],"pdf_url":"https://arxiv.org/pdf/2402.06900v4.pdf","comment":"8 page long"},{"id":"http://arxiv.org/abs/2410.15687v1","updated":"2024-10-21T06:55:35Z","published":"2024-10-21T06:55:35Z","title":"DomainSum: A Hierarchical Benchmark for Fine-Grained Domain Shift in\n  Abstractive Text Summarization","summary":"  Most research on abstractive summarization focuses on single-domain\napplications, often neglecting how domain shifts between documents affect\nperformance and the generalization ability of summarization models. To address\nthis issue, we introduce DomainSum, a hierarchical benchmark designed to\ncapture fine-grained domain shifts in abstractive summarization. We categorize\nthese shifts into three levels: genre, style, and topic, and demonstrate\nthrough comprehensive benchmark analysis that they follow a hierarchical\nstructure. Furthermore, we evaluate the domain generalization capabilities of\ncommonly used pre-trained language models (PLMs) and large language models\n(LLMs) in in-domain and cross-domain settings.\n","authors":["Haohan Yuan","Haopeng Zhang"],"pdf_url":"https://arxiv.org/pdf/2410.15687v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.15678v1","updated":"2024-10-21T06:42:11Z","published":"2024-10-21T06:42:11Z","title":"Revealing and Mitigating the Local Pattern Shortcuts of Mamba","summary":"  Large language models (LLMs) have advanced significantly due to the attention\nmechanism, but their quadratic complexity and linear memory demands limit their\nperformance on long-context tasks. Recently, researchers introduced Mamba, an\nadvanced model built upon State Space Models(SSMs) that offers linear\ncomplexity and constant memory. Although Mamba is reported to match or surpass\nthe performance of attention-based models, our analysis reveals a performance\ngap: Mamba excels in tasks that involve localized key information but faces\nchallenges with tasks that require handling distributed key information. Our\ncontrolled experiments suggest that this inconsistency arises from Mamba's\nreliance on local pattern shortcuts, which enable the model to remember local\nkey information within its limited memory but hinder its ability to retain more\ndispersed information. Therefore, we introduce a global selection module into\nthe Mamba model to address this issue. Experiments on both existing and\nproposed synthetic tasks, as well as real-world tasks, demonstrate the\neffectiveness of our method. Notably, with the introduction of only 4M extra\nparameters, our approach enables the Mamba model(130M) to achieve a significant\nimprovement on tasks with distributed information, increasing its performance\nfrom 0 to 80.54 points.\n","authors":["Wangjie You","Zecheng Tang","Juntao Li","Lili Yao","Min Zhang"],"pdf_url":"https://arxiv.org/pdf/2410.15678v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.02050v3","updated":"2024-10-21T06:33:13Z","published":"2024-06-04T07:31:06Z","title":"Analyzing Social Biases in Japanese Large Language Models","summary":"  With the development of Large Language Models (LLMs), social biases in the\nLLMs have become a crucial issue. While various benchmarks for social biases\nhave been provided across languages, the extent to which Japanese LLMs exhibit\nsocial biases has not been fully investigated. In this study, we construct the\nJapanese Bias Benchmark dataset for Question Answering (JBBQ) based on the\nEnglish bias benchmark BBQ, and analyze social biases in Japanese LLMs. The\nresults show that while current open Japanese LLMs improve their accuracies on\nJBBQ by setting larger parameters, their bias scores become larger. In\naddition, prompts with warnings about social biases and Chain-of-Thought\nprompting reduce the effect of biases in model outputs, but there is room for\nimprovement in the consistency of reasoning.\n","authors":["Hitomi Yanaka","Namgi Han","Ryoma Kumon","Jie Lu","Masashi Takeshita","Ryo Sekizawa","Taisei Kato","Hiromi Arai"],"pdf_url":"https://arxiv.org/pdf/2406.02050v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.16756v2","updated":"2024-10-21T06:30:07Z","published":"2024-08-29T17:54:14Z","title":"How Well Do LLMs Handle Cantonese? Benchmarking Cantonese Capabilities\n  of Large Language Models","summary":"  The rapid evolution of large language models (LLMs) has transformed the\ncompetitive landscape in natural language processing (NLP), particularly for\nEnglish and other data-rich languages. However, underrepresented languages like\nCantonese, spoken by over 85 million people, face significant development gaps,\nwhich is particularly concerning given the economic significance of the\nGuangdong-Hong Kong-Macau Greater Bay Area, and in substantial\nCantonese-speaking populations in places like Singapore and North America.\nDespite its wide use, Cantonese has scant representation in NLP research,\nespecially compared to other languages from similarly developed regions. To\nbridge these gaps, we outline current Cantonese NLP methods and introduce new\nbenchmarks designed to evaluate LLM performance in factual generation,\nmathematical logic, complex reasoning, and general knowledge in Cantonese,\nwhich aim to advance open-source Cantonese LLM technology. We also propose\nfuture research directions and recommended models to enhance Cantonese LLM\ndevelopment.\n","authors":["Jiyue Jiang","Pengan Chen","Liheng Chen","Sheng Wang","Qinghang Bao","Lingpeng Kong","Yu Li","Chuan Wu"],"pdf_url":"https://arxiv.org/pdf/2408.16756v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2409.00608v2","updated":"2024-10-21T06:26:03Z","published":"2024-09-01T04:23:48Z","title":"TinyAgent: Function Calling at the Edge","summary":"  Recent large language models (LLMs) have enabled the development of advanced\nagentic systems that can integrate various tools and APIs to fulfill user\nqueries through function calling. However, the deployment of these LLMs on the\nedge has not been explored since they typically require cloud-based\ninfrastructure due to their substantial model size and computational demands.\nTo this end, we present TinyAgent, an end-to-end framework for training and\ndeploying task-specific small language model agents capable of function calling\nfor driving agentic systems at the edge. We first show how to enable accurate\nfunction calling for open-source models via the LLMCompiler framework. We then\nsystematically curate a high-quality dataset for function calling, which we use\nto fine-tune two small language models, TinyAgent-1.1B and 7B. For efficient\ninference, we introduce a novel tool retrieval method to reduce the input\nprompt length and utilize quantization to further accelerate the inference\nspeed. As a driving application, we demonstrate a local Siri-like system for\nApple's MacBook that can execute user commands through text or voice input. Our\nresults show that our models can achieve, and even surpass, the\nfunction-calling capabilities of larger models like GPT-4-Turbo, while being\nfully deployed at the edge. We open-source our dataset, models, and installable\npackage and provide a demo video for our MacBook assistant agent.\n","authors":["Lutfi Eren Erdogan","Nicholas Lee","Siddharth Jha","Sehoon Kim","Ryan Tabrizi","Suhong Moon","Coleman Hooper","Gopala Anumanchipalli","Kurt Keutzer","Amir Gholami"],"pdf_url":"https://arxiv.org/pdf/2409.00608v2.pdf","comment":"EMNLP 2024 Demo"},{"id":"http://arxiv.org/abs/2410.15669v1","updated":"2024-10-21T06:22:51Z","published":"2024-10-21T06:22:51Z","title":"Learning to Generate and Evaluate Fact-checking Explanations with\n  Transformers","summary":"  In an era increasingly dominated by digital platforms, the spread of\nmisinformation poses a significant challenge, highlighting the need for\nsolutions capable of assessing information veracity. Our research contributes\nto the field of Explainable Artificial Antelligence (XAI) by developing\ntransformer-based fact-checking models that contextualise and justify their\ndecisions by generating human-accessible explanations. Importantly, we also\ndevelop models for automatic evaluation of explanations for fact-checking\nverdicts across different dimensions such as \\texttt{(self)-contradiction},\n\\texttt{hallucination}, \\texttt{convincingness} and \\texttt{overall quality}.\nBy introducing human-centred evaluation methods and developing specialised\ndatasets, we emphasise the need for aligning Artificial Intelligence\n(AI)-generated explanations with human judgements. This approach not only\nadvances theoretical knowledge in XAI but also holds practical implications by\nenhancing the transparency, reliability and users' trust in AI-driven\nfact-checking systems. Furthermore, the development of our metric learning\nmodels is a first step towards potentially increasing efficiency and reducing\nreliance on extensive manual assessment. Based on experimental results, our\nbest performing generative model \\textsc{ROUGE-1} score of 47.77, demonstrating\nsuperior performance in generating fact-checking explanations, particularly\nwhen provided with high-quality evidence. Additionally, the best performing\nmetric learning model showed a moderately strong correlation with human\njudgements on objective dimensions such as \\texttt{(self)-contradiction and\n\\texttt{hallucination}, achieving a Matthews Correlation Coefficient (MCC) of\naround 0.7.}\n","authors":["Darius Feher","Abdullah Khered","Hao Zhang","Riza Batista-Navarro","Viktor Schlegel"],"pdf_url":"https://arxiv.org/pdf/2410.15669v1.pdf","comment":"Forthcoming in Engineering Applications of Artificial Intelligence"},{"id":"http://arxiv.org/abs/2407.11417v2","updated":"2024-10-21T06:17:56Z","published":"2024-07-16T06:18:21Z","title":"SPINACH: SPARQL-Based Information Navigation for Challenging Real-World\n  Questions","summary":"  Large Language Models (LLMs) have led to significant improvements in the\nKnowledge Base Question Answering (KBQA) task. However, datasets used in KBQA\nstudies do not capture the true complexity of KBQA tasks. They either have\nsimple questions, use synthetically generated logical forms, or are based on\nsmall knowledge base (KB) schemas.\n  We introduce the SPINACH dataset, an expert-annotated KBQA dataset collected\nfrom discussions on Wikidata's \"Request a Query\" forum with 320\ndecontextualized question-SPARQL pairs. The complexity of these in-the-wild\nqueries calls for a KBQA system that can dynamically explore large and often\nincomplete schemas and reason about them, as it is infeasible to create a\ncomprehensive training dataset.\n  We also introduce an in-context learning KBQA agent, also called SPINACH,\nthat mimics how a human expert would write SPARQLs to handle challenging\nquestions. SPINACH achieves a new state of the art on the QALD-7, QALD-9 Plus\nand QALD-10 datasets by 31.0%, 27.0%, and 10.0% in $F_1$, respectively, and\ncoming within 1.6% of the fine-tuned LLaMA SOTA model on WikiWebQuestions. On\nour new SPINACH dataset, the SPINACH agent outperforms all baselines, including\nthe best GPT-4-based KBQA agent, by at least 38.1% in $F_1$.\n","authors":["Shicheng Liu","Sina J. Semnani","Harold Triedman","Jialiang Xu","Isaac Dan Zhao","Monica S. Lam"],"pdf_url":"https://arxiv.org/pdf/2407.11417v2.pdf","comment":"Findings of EMNLP 2024"},{"id":"http://arxiv.org/abs/2410.15667v1","updated":"2024-10-21T06:11:38Z","published":"2024-10-21T06:11:38Z","title":"RAC: Efficient LLM Factuality Correction with Retrieval Augmentation","summary":"  Large Language Models (LLMs) exhibit impressive results across a wide range\nof natural language processing (NLP) tasks, yet they can often produce\nfactually incorrect outputs. This paper introduces a simple but effective\nlow-latency post-correction method, \\textbf{Retrieval Augmented Correction\n(RAC)}, aimed at enhancing the factual performance of LLMs without requiring\nadditional fine-tuning. Our method is general and can be used with any\ninstruction-tuned LLM, and has greatly reduced latency compared to prior\napproaches. RAC decomposes the LLM's output into atomic facts and applies a\nfine-grained verification and correction process with retrieved content to\nverify and correct the LLM-generated output. Our extensive experiments show\nthat RAC yields up to 30\\% improvements over state-of-the-art baselines across\ntwo popular factuality evaluation datasets, validating its efficacy and\nrobustness in both with and without the integration of Retrieval-Augmented\nGeneration (RAG) across different LLMs.\\footnote{Our code is at\n\\url{https://github.com/jlab-nlp/Retrieval-Augmented-Correction}}\n","authors":["Changmao Li","Jeffrey Flanigan"],"pdf_url":"https://arxiv.org/pdf/2410.15667v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.15661v1","updated":"2024-10-21T06:03:49Z","published":"2024-10-21T06:03:49Z","title":"Scalable Data Ablation Approximations for Language Models through\n  Modular Training and Merging","summary":"  Training data compositions for Large Language Models (LLMs) can significantly\naffect their downstream performance. However, a thorough data ablation study\nexploring large sets of candidate data mixtures is typically prohibitively\nexpensive since the full effect is seen only after training the models; this\ncan lead practitioners to settle for sub-optimal data mixtures. We propose an\nefficient method for approximating data ablations which trains individual\nmodels on subsets of a training corpus and reuses them across evaluations of\ncombinations of subsets. In continued pre-training experiments, we find that,\ngiven an arbitrary evaluation set, the perplexity score of a single model\ntrained on a candidate set of data is strongly correlated with perplexity\nscores of parameter averages of models trained on distinct partitions of that\ndata. From this finding, we posit that researchers and practitioners can\nconduct inexpensive simulations of data ablations by maintaining a pool of\nmodels that were each trained on partitions of a large training corpus, and\nassessing candidate data mixtures by evaluating parameter averages of\ncombinations of these models. This approach allows for substantial improvements\nin amortized training efficiency -- scaling only linearly with respect to new\ndata -- by enabling reuse of previous training computation, opening new avenues\nfor improving model performance through rigorous, incremental data assessment\nand mixing.\n","authors":["Clara Na","Ian Magnusson","Ananya Harsh Jha","Tom Sherborne","Emma Strubell","Jesse Dodge","Pradeep Dasigi"],"pdf_url":"https://arxiv.org/pdf/2410.15661v1.pdf","comment":"EMNLP 2024. 17 pages"},{"id":"http://arxiv.org/abs/2410.15657v1","updated":"2024-10-21T05:51:51Z","published":"2024-10-21T05:51:51Z","title":"CL-HOI: Cross-Level Human-Object Interaction Distillation from Vision\n  Large Language Models","summary":"  Human-object interaction (HOI) detection has seen advancements with Vision\nLanguage Models (VLMs), but these methods often depend on extensive manual\nannotations. Vision Large Language Models (VLLMs) can inherently recognize and\nreason about interactions at the image level but are computationally heavy and\nnot designed for instance-level HOI detection. To overcome these limitations,\nwe propose a Cross-Level HOI distillation (CL-HOI) framework, which distills\ninstance-level HOIs from VLLMs image-level understanding without the need for\nmanual annotations. Our approach involves two stages: context distillation,\nwhere a Visual Linguistic Translator (VLT) converts visual information into\nlinguistic form, and interaction distillation, where an Interaction Cognition\nNetwork (ICN) reasons about spatial, visual, and context relations. We design\ncontrastive distillation losses to transfer image-level context and interaction\nknowledge from the teacher to the student model, enabling instance-level HOI\ndetection. Evaluations on HICO-DET and V-COCO datasets demonstrate that our\nCL-HOI surpasses existing weakly supervised methods and VLLM supervised\nmethods, showing its efficacy in detecting HOIs without manual labels.\n","authors":["Jianjun Gao","Chen Cai","Ruoyu Wang","Wenyang Liu","Kim-Hui Yap","Kratika Garg","Boon-Siew Han"],"pdf_url":"https://arxiv.org/pdf/2410.15657v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.15642v1","updated":"2024-10-21T05:08:18Z","published":"2024-10-21T05:08:18Z","title":"Resource-Efficient Medical Report Generation using Large Language Models","summary":"  Medical report generation is the task of automatically writing radiology\nreports for chest X-ray images. Manually composing these reports is a\ntime-consuming process that is also prone to human errors. Generating medical\nreports can therefore help reduce the burden on radiologists. In other words,\nwe can promote greater clinical automation in the medical domain. In this work,\nwe propose a new framework leveraging vision-enabled Large Language Models\n(LLM) for the task of medical report generation. We introduce a lightweight\nsolution that achieves better or comparative performance as compared to\nprevious solutions on the task of medical report generation. We conduct\nextensive experiments exploring different model sizes and enhancement\napproaches, such as prefix tuning to improve the text generation abilities of\nthe LLMs. We evaluate our approach on a prominent large-scale radiology report\ndataset - MIMIC-CXR. Our results demonstrate the capability of our\nresource-efficient framework to generate patient-specific reports with strong\nmedical contextual understanding and high precision.\n","authors":[" Abdullah","Ameer Hamza","Seong Tae Kim"],"pdf_url":"https://arxiv.org/pdf/2410.15642v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.15641v1","updated":"2024-10-21T05:01:50Z","published":"2024-10-21T05:01:50Z","title":"SMILES-Prompting: A Novel Approach to LLM Jailbreak Attacks in Chemical\n  Synthesis","summary":"  The increasing integration of large language models (LLMs) across various\nfields has heightened concerns about their potential to propagate dangerous\ninformation. This paper specifically explores the security vulnerabilities of\nLLMs within the field of chemistry, particularly their capacity to provide\ninstructions for synthesizing hazardous substances. We evaluate the\neffectiveness of several prompt injection attack methods, including\nred-teaming, explicit prompting, and implicit prompting. Additionally, we\nintroduce a novel attack technique named SMILES-prompting, which uses the\nSimplified Molecular-Input Line-Entry System (SMILES) to reference chemical\nsubstances. Our findings reveal that SMILES-prompting can effectively bypass\ncurrent safety mechanisms. These findings highlight the urgent need for\nenhanced domain-specific safeguards in LLMs to prevent misuse and improve their\npotential for positive social impact.\n","authors":["Aidan Wong","He Cao","Zijing Liu","Yu Li"],"pdf_url":"https://arxiv.org/pdf/2410.15641v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.15639v1","updated":"2024-10-21T04:57:09Z","published":"2024-10-21T04:57:09Z","title":"Can Large Language Models Invent Algorithms to Improve Themselves?","summary":"  Large Language Models (LLMs) have shown remarkable performance improvements\nand are rapidly gaining adoption in industry. However, the methods for\nimproving LLMs are still designed by humans, which restricts the invention of\nnew model-improving algorithms to human expertise and imagination. To address\nthis, we propose the Self-Developing framework, which enables LLMs to\nautonomously generate and learn model-improvement algorithms. In this\nframework, the seed model generates, applies, and evaluates model-improving\nalgorithms, continuously improving both the seed model and the algorithms\nthemselves. In mathematical reasoning tasks, Self-Developing not only creates\nmodels that surpass the seed model but also consistently outperforms models\ncreated using human-designed algorithms. Additionally, these LLM-discovered\nalgorithms demonstrate strong effectiveness, including transferability to\nout-of-domain models.\n","authors":["Yoichi Ishibashi","Taro Yano","Masafumi Oyamada"],"pdf_url":"https://arxiv.org/pdf/2410.15639v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.02355v2","updated":"2024-10-21T04:32:56Z","published":"2024-10-03T10:06:27Z","title":"AlphaEdit: Null-Space Constrained Knowledge Editing for Language Models","summary":"  Large language models (LLMs) often exhibit hallucinations due to incorrect or\noutdated knowledge. Hence, model editing methods have emerged to enable\ntargeted knowledge updates. To achieve this, a prevailing paradigm is the\nlocating-then-editing approach, which first locates influential parameters and\nthen edits them by introducing a perturbation. While effective, current studies\nhave demonstrated that this perturbation inevitably disrupt the originally\npreserved knowledge within LLMs, especially in sequential editing scenarios. To\naddress this, we introduce AlphaEdit, a novel solution that projects\nperturbation onto the null space of the preserved knowledge before applying it\nto the parameters. We theoretically prove that this projection ensures the\noutput of post-edited LLMs remains unchanged when queried about the preserved\nknowledge, thereby mitigating the issue of disruption. Extensive experiments on\nvarious LLMs, including LLaMA3, GPT2-XL, and GPT-J, show that AlphaEdit boosts\nthe performance of most locating-then-editing methods by an average of 36.4%\nwith a single line of additional code for projection solely. Our code is\navailable at: https://github.com/jianghoucheng/AlphaEdit.\n","authors":["Junfeng Fang","Houcheng Jiang","Kun Wang","Yunshan Ma","Xiang Wang","Xiangnan He","Tat-seng Chua"],"pdf_url":"https://arxiv.org/pdf/2410.02355v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.15633v1","updated":"2024-10-21T04:30:53Z","published":"2024-10-21T04:30:53Z","title":"Selecting Influential Samples for Long Context Alignment via Homologous\n  Models' Guidance and Contextual Awareness Measurement","summary":"  The expansion of large language models to effectively handle instructions\nwith extremely long contexts has yet to be fully investigated. The primary\nobstacle lies in constructing a high-quality long instruction-following dataset\ndevised for long context alignment. Existing studies have attempted to scale up\nthe available data volume by synthesizing long instruction-following samples.\nHowever, indiscriminately increasing the quantity of data without a\nwell-defined strategy for ensuring data quality may introduce low-quality\nsamples and restrict the final performance. To bridge this gap, we aim to\naddress the unique challenge of long-context alignment, i.e., modeling the\nlong-range dependencies for handling instructions and lengthy input contexts.\nWe propose GATEAU, a novel framework designed to identify the influential and\nhigh-quality samples enriched with long-range dependency relations by utilizing\ncrafted Homologous Models' Guidance (HMG) and Contextual Awareness Measurement\n(CAM). Specifically, HMG attempts to measure the difficulty of generating\ncorresponding responses due to the long-range dependencies, using the\nperplexity scores of the response from two homologous models with different\ncontext windows. Also, the role of CAM is to measure the difficulty of\nunderstanding the long input contexts due to long-range dependencies by\nevaluating whether the model's attention is focused on important segments.\nBuilt upon both proposed methods, we select the most challenging samples as the\ninfluential data to effectively frame the long-range dependencies, thereby\nachieving better performance of LLMs. Comprehensive experiments indicate that\nGATEAU effectively identifies samples enriched with long-range dependency\nrelations and the model trained on these selected samples exhibits better\ninstruction-following and long-context understanding capabilities.\n","authors":["Shuzheng Si","Haozhe Zhao","Gang Chen","Yunshui Li","Kangyang Luo","Chuancheng Lv","Kaikai An","Fanchao Qi","Baobao Chang","Maosong Sun"],"pdf_url":"https://arxiv.org/pdf/2410.15633v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.09603v4","updated":"2024-10-21T04:16:09Z","published":"2023-11-16T06:22:17Z","title":"Self-Contradictory Reasoning Evaluation and Detection","summary":"  In a plethora of recent work, large language models (LLMs) demonstrated\nimpressive reasoning ability, but many proposed downstream reasoning tasks only\nfocus on final answers. Two fundamental questions persist: 1) how consistent is\nthe reasoning, and 2) can models detect unreliable reasoning? In this paper, we\ninvestigate self-contradictory (Self-Contra) reasoning, where the model\nreasoning does not support its answers. To answer 1), we define and assess the\nSelf-Contra rate across three datasets and delve into finer-grained categories\nof Self-Contra reasoning. We find that LLMs often contradict themselves in\nreasoning tasks involving contextual information understanding or commonsense.\nThe model may generate correct answers by taking shortcuts in reasoning or\noverlooking contextual evidence, leading to compromised reasoning. For 2), we\ntask the state-of-the-art model GPT-4 with identifying Self-Contra reasoning\nand finer-grained fallacies. We find that finer-grained categories enhanced\ndetection can improve GPT-4's ability to detect Self-Contra. However, it is\nonly able to detect Self-Contra with a 52.2% F1 score, much lower compared to\n66.7% for humans. Our results indicate that current LLMs lack the robustness\nnecessary for reliable reasoning and we emphasize the urgent need for\nestablishing best practices in comprehensive reasoning evaluations beyond pure\nperformance-based metrics.\n","authors":["Ziyi Liu","Soumya Sanyal","Isabelle Lee","Yongkang Du","Rahul Gupta","Yang Liu","Jieyu Zhao"],"pdf_url":"https://arxiv.org/pdf/2311.09603v4.pdf","comment":null},{"id":"http://arxiv.org/abs/2402.03744v2","updated":"2024-10-21T04:10:50Z","published":"2024-02-06T06:23:12Z","title":"INSIDE: LLMs' Internal States Retain the Power of Hallucination\n  Detection","summary":"  Knowledge hallucination have raised widespread concerns for the security and\nreliability of deployed LLMs. Previous efforts in detecting hallucinations have\nbeen employed at logit-level uncertainty estimation or language-level\nself-consistency evaluation, where the semantic information is inevitably lost\nduring the token-decoding procedure. Thus, we propose to explore the dense\nsemantic information retained within LLMs' \\textbf{IN}ternal \\textbf{S}tates\nfor halluc\\textbf{I}nation \\textbf{DE}tection (\\textbf{INSIDE}). In particular,\na simple yet effective \\textbf{EigenScore} metric is proposed to better\nevaluate responses' self-consistency, which exploits the eigenvalues of\nresponses' covariance matrix to measure the semantic consistency/diversity in\nthe dense embedding space. Furthermore, from the perspective of self-consistent\nhallucination detection, a test time feature clipping approach is explored to\ntruncate extreme activations in the internal states, which reduces\noverconfident generations and potentially benefits the detection of\noverconfident hallucinations. Extensive experiments and ablation studies are\nperformed on several popular LLMs and question-answering (QA) benchmarks,\nshowing the effectiveness of our proposal.\n","authors":["Chao Chen","Kai Liu","Ze Chen","Yi Gu","Yue Wu","Mingyuan Tao","Zhihang Fu","Jieping Ye"],"pdf_url":"https://arxiv.org/pdf/2402.03744v2.pdf","comment":"Accepted by ICLR-2024"},{"id":"http://arxiv.org/abs/2406.10786v2","updated":"2024-10-21T04:09:33Z","published":"2024-06-16T02:52:32Z","title":"Exploring the Zero-Shot Capabilities of LLMs Handling Multiple Problems\n  at once","summary":"  Recent studies have proposed placing multiple problems in a single prompt to\nimprove input token utilization for a more efficient LLM inference. We call\nthis MPP, in contrast to conventional SPP that prompts an LLM with a single\nproblem at a time. While MPP has been shown to work comparably well or even\nbetter than SPP under few-shot settings, its zero-shot performance is\nunderexplored, which better reveals the innate multiple problem handling\ncapabilities of LLMs. To address that, we study the zero-shot MPP performance\nof various LLMs on 6 classification and 12 reasoning benchmarks and confirm\nthat LLMs are competent zero-shot multi-problem solvers. We also examine the\nconditions of effectiveness of zero-shot MPP and explore several model-level\nfactors that may enable MPP. We observe that LLMs consistently perform worse\nwith selecting indices of texts of a given class label and with multiple\nmixed-source reasoning problems, indicating a lack of true understanding. We\nalso find that instruction tuning is an important factor than enhances MPP.\n","authors":["Zhengxiang Wang","Jordan Kodner","Owen Rambow"],"pdf_url":"https://arxiv.org/pdf/2406.10786v2.pdf","comment":"26 pages, 11 figures, 16 tables"},{"id":"http://arxiv.org/abs/2410.15625v1","updated":"2024-10-21T04:08:37Z","published":"2024-10-21T04:08:37Z","title":"Improving Parallel Program Performance Through DSL-Driven Code\n  Generation with LLM Optimizers","summary":"  Mapping computations to processors and assigning data to memory are critical\nfor maximizing performance in parallel programming. These mapping decisions are\nmanaged through the development of specialized low-level system code, called\nmappers, crafted by performance engineers. Each mapper is tailored to a\nspecific application and optimized for the underlying machine architecture, a\nprocess that requires days of refinement and tuning from an expert. Despite\nadvances in system research, automating mapper generation remains a challenge\ndue to the complexity of making millions of decisions to find the optimal\nsolution and generate the solution as code. We introduce an approach that\nleverages recent advances in LLM-based optimizers for mapper design. In under\nten minutes, our method automatically discovers mappers that surpass human\nexpert designs in scientific applications by up to 1.34X speedup. For parallel\nmatrix multiplication algorithms, our mapper achieves up to 1.31X of the\nexpert-designed solution. To achieve this, we simplify the complexity of\nlow-level code generation by introducing a domain-specific language (DSL) that\nabstracts the low-level system programming details and defines a structured\nsearch space for LLMs to explore. To maximize the application performance, we\nuse an LLM optimizer to improve an agentic system that generates the mapper\ncode. As a result, this approach significantly reduces the workload for\nperformance engineers while achieving substantial performance gains across\ndiverse applications. Finally, our results demonstrate the effectiveness of\nLLM-based optimization in system design and suggest its potential for\naddressing other complex system challenges.\n","authors":["Anjiang Wei","Allen Nie","Thiago S. F. X. Teixeira","Rohan Yadav","Wonchan Lee","Ke Wang","Alex Aiken"],"pdf_url":"https://arxiv.org/pdf/2410.15625v1.pdf","comment":"26 pages, 8 figures"},{"id":"http://arxiv.org/abs/2410.15623v1","updated":"2024-10-21T04:08:16Z","published":"2024-10-21T04:08:16Z","title":"Guardians of Discourse: Evaluating LLMs on Multilingual Offensive\n  Language Detection","summary":"  Identifying offensive language is essential for maintaining safety and\nsustainability in the social media era. Though large language models (LLMs)\nhave demonstrated encouraging potential in social media analytics, they lack\nthorough evaluation when in offensive language detection, particularly in\nmultilingual environments. We for the first time evaluate multilingual\noffensive language detection of LLMs in three languages: English, Spanish, and\nGerman with three LLMs, GPT-3.5, Flan-T5, and Mistral, in both monolingual and\nmultilingual settings. We further examine the impact of different prompt\nlanguages and augmented translation data for the task in non-English contexts.\nFurthermore, we discuss the impact of the inherent bias in LLMs and the\ndatasets in the mispredictions related to sensitive topics.\n","authors":["Jianfei He","Lilin Wang","Jiaying Wang","Zhenyu Liu","Hongbin Na","Zimu Wang","Wei Wang","Qi Chen"],"pdf_url":"https://arxiv.org/pdf/2410.15623v1.pdf","comment":"Accepted at UIC 2024 proceedings. Accepted version"},{"id":"http://arxiv.org/abs/2409.08098v2","updated":"2024-10-21T04:02:23Z","published":"2024-09-12T14:51:43Z","title":"The CLC-UKET Dataset: Benchmarking Case Outcome Prediction for the UK\n  Employment Tribunal","summary":"  This paper explores the intersection of technological innovation and access\nto justice by developing a benchmark for predicting case outcomes in the UK\nEmployment Tribunal (UKET). To address the challenge of extensive manual\nannotation, the study employs a large language model (LLM) for automatic\nannotation, resulting in the creation of the CLC-UKET dataset. The dataset\nconsists of approximately 19,000 UKET cases and their metadata. Comprehensive\nlegal annotations cover facts, claims, precedent references, statutory\nreferences, case outcomes, reasons and jurisdiction codes. Facilitated by the\nCLC-UKET data, we examine a multi-class case outcome prediction task in the\nUKET. Human predictions are collected to establish a performance reference for\nmodel comparison. Empirical results from baseline models indicate that\nfinetuned transformer models outperform zero-shot and few-shot LLMs on the UKET\nprediction task. The performance of zero-shot LLMs can be enhanced by\nintegrating task-related information into few-shot examples. We hope that the\nCLC-UKET dataset, along with human annotations and empirical findings, can\nserve as a valuable benchmark for employment-related dispute resolution.\n","authors":["Huiyuan Xie","Felix Steffek","Joana Ribeiro de Faria","Christine Carter","Jonathan Rutherford"],"pdf_url":"https://arxiv.org/pdf/2409.08098v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.10678v3","updated":"2024-10-21T03:55:36Z","published":"2022-12-20T22:41:24Z","title":"Causally Testing Gender Bias in LLMs: A Case Study on Occupational Bias","summary":"  Generated texts from large language models (LLMs) have been shown to exhibit\na variety of harmful, human-like biases against various demographics. These\nfindings motivate research efforts aiming to understand and measure such\neffects. This paper introduces a causal formulation for bias measurement in\ngenerative language models. Based on this theoretical foundation, we outline a\nlist of desiderata for designing robust bias benchmarks. We then propose a\nbenchmark called OccuGender, with a bias-measuring procedure to investigate\noccupational gender bias. We test several state-of-the-art open-source LLMs on\nOccuGender, including Llama, Mistral, and their instruction-tuned versions. The\nresults show that these models exhibit substantial occupational gender bias.\nLastly, we discuss prompting strategies for bias mitigation and an extension of\nour causal formulation to illustrate the generalizability of our framework. Our\ncode and data https://github.com/chenyuen0103/gender-bias.\n","authors":["Yuen Chen","Vethavikashini Chithrra Raghuram","Justus Mattern","Rada Mihalcea","Zhijing Jin"],"pdf_url":"https://arxiv.org/pdf/2212.10678v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.15620v1","updated":"2024-10-21T03:48:23Z","published":"2024-10-21T03:48:23Z","title":"Acoustic Model Optimization over Multiple Data Sources: Merging and\n  Valuation","summary":"  Due to the rising awareness of privacy protection and the voluminous scale of\nspeech data, it is becoming infeasible for Automatic Speech Recognition (ASR)\nsystem developers to train the acoustic model with complete data as before. For\nexample, the data may be owned by different curators, and it is not allowed to\nshare with others. In this paper, we propose a novel paradigm to solve salient\nproblems plaguing the ASR field. In the first stage, multiple acoustic models\nare trained based upon different subsets of the complete speech data, while in\nthe second phase, two novel algorithms are utilized to generate a high-quality\nacoustic model based upon those trained on data subsets. We first propose the\nGenetic Merge Algorithm (GMA), which is a highly specialized algorithm for\noptimizing acoustic models but suffers from low efficiency. We further propose\nthe SGD-Based Optimizational Merge Algorithm (SOMA), which effectively\nalleviates the efficiency bottleneck of GMA and maintains superior model\naccuracy. Extensive experiments on public data show that the proposed methods\ncan significantly outperform the state-of-the-art. Furthermore, we introduce\nShapley Value to estimate the contribution score of the trained models, which\nis useful for evaluating the effectiveness of the data and providing fair\nincentives to their curators.\n","authors":["Victor Junqiu Wei","Weicheng Wang","Di Jiang","Conghui Tan","Rongzhong Lian"],"pdf_url":"https://arxiv.org/pdf/2410.15620v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.13185v2","updated":"2024-10-21T03:36:05Z","published":"2024-10-17T03:26:37Z","title":"Chain of Ideas: Revolutionizing Research in Novel Idea Development with\n  LLM Agents","summary":"  Effective research ideation is a critical step for scientific research.\nHowever, the exponential increase in scientific literature makes it challenging\nfor researchers to stay current with recent advances and identify meaningful\nresearch directions. Recent developments in large language models~(LLMs)\nsuggest a promising avenue for automating the generation of novel research\nideas. However, existing methods for idea generation either trivially prompt\nLLMs or directly expose LLMs to extensive literature without indicating useful\ninformation. Inspired by the research process of human researchers, we propose\na Chain-of-Ideas~(CoI) agent, an LLM-based agent that organizes relevant\nliterature in a chain structure to effectively mirror the progressive\ndevelopment in a research domain. This organization facilitates LLMs to capture\nthe current advancements in research, thereby enhancing their ideation\ncapabilities. Furthermore, we propose Idea Arena, an evaluation protocol that\ncan comprehensively evaluate idea generation methods from different\nperspectives, aligning closely with the preferences of human researchers.\nExperimental results indicate that the CoI agent consistently outperforms other\nmethods and shows comparable quality as humans in research idea generation.\nMoreover, our CoI agent is budget-friendly, with a minimum cost of \\$0.50 to\ngenerate a candidate idea and its corresponding experimental design.\n","authors":["Long Li","Weiwen Xu","Jiayan Guo","Ruochen Zhao","Xinxuan Li","Yuqian Yuan","Boqiang Zhang","Yuming Jiang","Yifei Xin","Ronghao Dang","Deli Zhao","Yu Rong","Tian Feng","Lidong Bing"],"pdf_url":"https://arxiv.org/pdf/2410.13185v2.pdf","comment":"10 pages,5 figures, conference"},{"id":"http://arxiv.org/abs/2410.15609v1","updated":"2024-10-21T03:13:22Z","published":"2024-10-21T03:13:22Z","title":"Interventional Speech Noise Injection for ASR Generalizable Spoken\n  Language Understanding","summary":"  Recently, pre-trained language models (PLMs) have been increasingly adopted\nin spoken language understanding (SLU). However, automatic speech recognition\n(ASR) systems frequently produce inaccurate transcriptions, leading to noisy\ninputs for SLU models, which can significantly degrade their performance. To\naddress this, our objective is to train SLU models to withstand ASR errors by\nexposing them to noises commonly observed in ASR systems, referred to as\nASR-plausible noises. Speech noise injection (SNI) methods have pursued this\nobjective by introducing ASR-plausible noises, but we argue that these methods\nare inherently biased towards specific ASR systems, or ASR-specific noises. In\nthis work, we propose a novel and less biased augmentation method of\nintroducing the noises that are plausible to any ASR system, by cutting off the\nnon-causal effect of noises. Experimental results and analyses demonstrate the\neffectiveness of our proposed methods in enhancing the robustness and\ngeneralizability of SLU models against unseen ASR systems by introducing more\ndiverse and plausible ASR noises in advance.\n","authors":["Yeonjoon Jung","Jaeseong Lee","Seungtaek Choi","Dohyeon Lee","Minsoo Kim","Seung-won Hwang"],"pdf_url":"https://arxiv.org/pdf/2410.15609v1.pdf","comment":"9 pages, 3 figures"},{"id":"http://arxiv.org/abs/2410.15608v1","updated":"2024-10-21T03:13:20Z","published":"2024-10-21T03:13:20Z","title":"Moonshine: Speech Recognition for Live Transcription and Voice Commands","summary":"  This paper introduces Moonshine, a family of speech recognition models\noptimized for live transcription and voice command processing. Moonshine is\nbased on an encoder-decoder transformer architecture and employs Rotary\nPosition Embedding (RoPE) instead of traditional absolute position embeddings.\nThe model is trained on speech segments of various lengths, but without using\nzero-padding, leading to greater efficiency for the encoder during inference\ntime. When benchmarked against OpenAI's Whisper tiny.en, Moonshine Tiny\ndemonstrates a 5x reduction in compute requirements for transcribing a\n10-second speech segment while incurring no increase in word error rates across\nstandard evaluation datasets. These results highlight Moonshine's potential for\nreal-time and resource-constrained applications.\n","authors":["Nat Jeffries","Evan King","Manjunath Kudlur","Guy Nicholson","James Wang","Pete Warden"],"pdf_url":"https://arxiv.org/pdf/2410.15608v1.pdf","comment":"7 pages, 6 figures, 3 tables"},{"id":"http://arxiv.org/abs/2410.03421v2","updated":"2024-10-21T02:43:50Z","published":"2024-10-04T13:31:09Z","title":"One2set + Large Language Model: Best Partners for Keyphrase Generation","summary":"  Keyphrase generation (KPG) aims to automatically generate a collection of\nphrases representing the core concepts of a given document. The dominant\nparadigms in KPG include one2seq and one2set. Recently, there has been\nincreasing interest in applying large language models (LLMs) to KPG. Our\npreliminary experiments reveal that it is challenging for a single model to\nexcel in both recall and precision. Further analysis shows that: 1) the one2set\nparadigm owns the advantage of high recall, but suffers from improper\nassignments of supervision signals during training; 2) LLMs are powerful in\nkeyphrase selection, but existing selection methods often make redundant\nselections. Given these observations, we introduce a generate-then-select\nframework decomposing KPG into two steps, where we adopt a one2set-based model\nas generator to produce candidates and then use an LLM as selector to select\nkeyphrases from these candidates. Particularly, we make two important\nimprovements on our generator and selector: 1) we design an Optimal\nTransport-based assignment strategy to address the above improper assignments;\n2) we model the keyphrase selection as a sequence labeling task to alleviate\nredundant selections. Experimental results on multiple benchmark datasets show\nthat our framework significantly surpasses state-of-the-art models, especially\nin absent keyphrase prediction.\n","authors":["Liangying Shao","Liang Zhang","Minlong Peng","Guoqi Ma","Hao Yue","Mingming Sun","Jinsong Su"],"pdf_url":"https://arxiv.org/pdf/2410.03421v2.pdf","comment":"Accepted by EMNLP 2024 Main Conference"},{"id":"http://arxiv.org/abs/2410.05021v3","updated":"2024-10-21T02:41:21Z","published":"2024-10-07T13:24:24Z","title":"DEPT: Decoupled Embeddings for Pre-training Language Models","summary":"  Language model pre-training benefits from diverse data to enhance performance\nacross domains and languages. However, training on such heterogeneous corpora\nrequires extensive and costly efforts. Since these data sources vary lexically,\nsyntactically, and semantically, they cause negative interference or the\n``curse of multilinguality''. We propose a novel pre-training framework to\nalleviate this curse. Our method, DEPT, decouples embeddings from the\ntransformer body while simultaneously training the latter in multiple contexts.\nDEPT enables training without a shared global vocabulary and: (1) can train\nrobustly and effectively under significant data heterogeneity, (2) reduces\ntoken embedding parameters by up to 80% and the communication costs by 675x for\nbillion-scale models, (3) enhances model generalization and plasticity in\nadapting to new languages and domains, and (4) permits training with custom\noptimized vocabularies per data source. We demonstrate DEPT's potential via the\nfirst vocabulary-agnostic federated multilingual pre-training of a 1.3\nbillion-parameter model, limiting its embedding size to 102.4 million instead\nof 512 million.\n","authors":["Alex Iacob","Lorenzo Sani","Meghdad Kurmanji","William F. Shen","Xinchi Qiu","Dongqi Cai","Yan Gao","Nicholas D. Lane"],"pdf_url":"https://arxiv.org/pdf/2410.05021v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.15595v1","updated":"2024-10-21T02:27:24Z","published":"2024-10-21T02:27:24Z","title":"A Comprehensive Survey of Datasets, Theories, Variants, and Applications\n  in Direct Preference Optimization","summary":"  With the rapid advancement of large language models (LLMs), aligning policy\nmodels with human preferences has become increasingly critical. Direct\nPreference Optimization (DPO) has emerged as a promising approach for\nalignment, acting as an RL-free alternative to Reinforcement Learning from\nHuman Feedback (RLHF). Despite DPO's various advancements and inherent\nlimitations, an in-depth review of these aspects is currently lacking in the\nliterature. In this work, we present a comprehensive review of the challenges\nand opportunities in DPO, covering theoretical analyses, variants, relevant\npreference datasets, and applications. Specifically, we categorize recent\nstudies on DPO based on key research questions to provide a thorough\nunderstanding of DPO's current landscape. Additionally, we propose several\nfuture research directions to offer insights on model alignment for the\nresearch community.\n","authors":["Wenyi Xiao","Zechuan Wang","Leilei Gan","Shuai Zhao","Wanggui He","Luu Anh Tuan","Long Chen","Hao Jiang","Zhou Zhao","Fei Wu"],"pdf_url":"https://arxiv.org/pdf/2410.15595v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.15592v1","updated":"2024-10-21T02:21:56Z","published":"2024-10-21T02:21:56Z","title":"CPE-Pro: A Structure-Sensitive Deep Learning Model for Protein\n  Representation and Origin Evaluation","summary":"  Protein structures are important for understanding their functions and\ninteractions. Currently, many protein structure prediction methods are\nenriching the structure database. Discriminating the origin of structures is\ncrucial for distinguishing between experimentally resolved and computationally\npredicted structures, evaluating the reliability of prediction methods, and\nguiding downstream biological studies. Building on works in structure\nprediction, We developed a structure-sensitive supervised deep learning model,\nCrystal vs Predicted Evaluator for Protein Structure (CPE-Pro), to represent\nand discriminate the origin of protein structures. CPE-Pro learns the\nstructural information of proteins and captures inter-structural differences to\nachieve accurate traceability on four data classes, and is expected to be\nextended to more. Simultaneously, we utilized Foldseek to encode protein\nstructures into \"structure-sequence\" and trained a protein Structural Sequence\nLanguage Model, SSLM. Preliminary experiments demonstrated that, compared to\nlarge-scale protein language models pre-trained on vast amounts of amino acid\nsequences, the \"structure-sequences\" enable the language model to learn more\ninformative protein features, enhancing and optimizing structural\nrepresentations. We have provided the code, model weights, and all related\nmaterials on https://github.com/GouWenrui/CPE-Pro-main.git.\n","authors":["Wenrui Gou","Wenhui Ge"," YangTan","Guisheng Fan","Mingchen Li","Huiqun Yu"],"pdf_url":"https://arxiv.org/pdf/2410.15592v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.15591v1","updated":"2024-10-21T02:19:24Z","published":"2024-10-21T02:19:24Z","title":"AMPLE: Emotion-Aware Multimodal Fusion Prompt Learning for Fake News\n  Detection","summary":"  Detecting fake news in large datasets is challenging due to its diversity and\ncomplexity, with traditional approaches often focusing on textual features\nwhile underutilizing semantic and emotional elements. Current methods also rely\nheavily on large annotated datasets, limiting their effectiveness in more\nnuanced analysis. To address these challenges, this paper introduces\nEmotion-\\textbf{A}ware \\textbf{M}ultimodal Fusion \\textbf{P}rompt\n\\textbf{L}\\textbf{E}arning (\\textbf{AMPLE}) framework to address the above\nissue by combining text sentiment analysis with multimodal data and hybrid\nprompt templates. This framework extracts emotional elements from texts by\nleveraging sentiment analysis tools. It then employs Multi-Head Cross-Attention\n(MCA) mechanisms and similarity-aware fusion methods to integrate multimodal\ndata. The proposed AMPLE framework demonstrates strong performance on two\npublic datasets in both few-shot and data-rich settings, with results\nindicating the potential of emotional aspects in fake news detection.\nFurthermore, the study explores the impact of integrating large language models\nwith this method for text sentiment extraction, revealing substantial room for\nfurther improvement. The code can be found at\n:\\url{https://github.com/xxm1215/MMM2025_few-shot/\n","authors":["Xiaoman Xu","Xiangrun Li","Taihang Wang","Ye Jiang"],"pdf_url":"https://arxiv.org/pdf/2410.15591v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.15580v1","updated":"2024-10-21T01:57:16Z","published":"2024-10-21T01:57:16Z","title":"Language Models are Symbolic Learners in Arithmetic","summary":"  Large Language Models (LLMs) are thought to struggle with arithmetic learning\ndue to the inherent differences between language modeling and numerical\ncomputation, but concrete evidence has been lacking. This work responds to this\nclaim through a two-side experiment. We first investigate whether LLMs leverage\npartial products during arithmetic learning. We find that although LLMs can\nidentify some partial products after learning, they fail to leverage them for\narithmetic tasks, conversely. We then explore how LLMs approach arithmetic\nsymbolically by breaking tasks into subgroups, hypothesizing that difficulties\narise from subgroup complexity and selection. Our results show that when\nsubgroup complexity is fixed, LLMs treat a collection of different arithmetic\noperations similarly. By analyzing position-level accuracy across different\ntraining sizes, we further observe that it follows a U-shaped pattern: LLMs\nquickly learn the easiest patterns at the first and last positions, while\nprogressively learning the more difficult patterns in the middle positions.\nThis suggests that LLMs select subgroup following an easy-to-hard paradigm\nduring learning. Our work confirms that LLMs are pure symbolic learners in\narithmetic tasks and underscores the importance of understanding them deeply\nthrough subgroup-level quantification.\n","authors":["Chunyuan Deng","Zhiqi Li","Roy Xie","Ruidi Chang","Hanjie Chen"],"pdf_url":"https://arxiv.org/pdf/2410.15580v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.15578v1","updated":"2024-10-21T01:55:52Z","published":"2024-10-21T01:55:52Z","title":"Generalized Probabilistic Attention Mechanism in Transformers","summary":"  The Transformer architecture has become widely adopted due to its\ndemonstrated success, attributed to the attention mechanism at its core.\nDespite these successes, the attention mechanism of Transformers is associated\nwith two well-known issues: rank-collapse and gradient vanishing. In this\npaper, we present a theoretical analysis that it is inherently difficult to\naddress both issues simultaneously in the conventional attention mechanism. To\nhandle these issues, we introduce a novel class of attention mechanism,\nreferred to as generalized probabilistic attention mechanism (GPAM), and its\ndual-attention implementation within the Transformer architecture. Unlike\nconventional attention mechanisms, GPAM allows for negative attention scores\nwhile preserving a fixed total sum. We provide theoretical evidence that the\nproposed dual-attention GPAM (daGPAM) effectively mitigates both the\nrank-collapse and gradient vanishing issues which are difficult to resolve\nsimultaneously with the conventional attention mechanisms. Furthermore, we\nempirically validate this theoretical evidence, demonstrating the superiority\nof daGPAM compared to other alternative attention mechanisms that were proposed\nto address the same issues. Additionally, we demonstrate the practical benefits\nof GPAM in natural language processing tasks, such as language modeling and\nneural machine translation.\n","authors":["DongNyeong Heo","Heeyoul Choi"],"pdf_url":"https://arxiv.org/pdf/2410.15578v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.15576v1","updated":"2024-10-21T01:54:46Z","published":"2024-10-21T01:54:46Z","title":"A Survey of Conversational Search","summary":"  As a cornerstone of modern information access, search engines have become\nindispensable in everyday life. With the rapid advancements in AI and natural\nlanguage processing (NLP) technologies, particularly large language models\n(LLMs), search engines have evolved to support more intuitive and intelligent\ninteractions between users and systems. Conversational search, an emerging\nparadigm for next-generation search engines, leverages natural language\ndialogue to facilitate complex and precise information retrieval, thus\nattracting significant attention. Unlike traditional keyword-based search\nengines, conversational search systems enhance user experience by supporting\nintricate queries, maintaining context over multi-turn interactions, and\nproviding robust information integration and processing capabilities. Key\ncomponents such as query reformulation, search clarification, conversational\nretrieval, and response generation work in unison to enable these sophisticated\ninteractions. In this survey, we explore the recent advancements and potential\nfuture directions in conversational search, examining the critical modules that\nconstitute a conversational search system. We highlight the integration of LLMs\nin enhancing these systems and discuss the challenges and opportunities that\nlie ahead in this dynamic field. Additionally, we provide insights into\nreal-world applications and robust evaluations of current conversational search\nsystems, aiming to guide future research and development in conversational\nsearch.\n","authors":["Fengran Mo","Kelong Mao","Ziliang Zhao","Hongjin Qian","Haonan Chen","Yiruo Cheng","Xiaoxi Li","Yutao Zhu","Zhicheng Dou","Jian-Yun Nie"],"pdf_url":"https://arxiv.org/pdf/2410.15576v1.pdf","comment":"35 pages, 8 figures, continue to update"},{"id":"http://arxiv.org/abs/2410.15575v1","updated":"2024-10-21T01:50:59Z","published":"2024-10-21T01:50:59Z","title":"Neural Search Space in Gboard Decoder","summary":"  Gboard Decoder produces suggestions by looking for paths that best match\ninput touch points on the context aware search space, which is backed by the\nlanguage Finite State Transducers (FST). The language FST is currently an\nN-gram language model (LM). However, N-gram LMs, limited in context length, are\nknown to have sparsity problem under device model size constraint. In this\npaper, we propose \\textbf{Neural Search Space} which substitutes the N-gram LM\nwith a Neural Network LM (NN-LM) and dynamically constructs the search space\nduring decoding. Specifically, we integrate the long range context awareness of\nNN-LM into the search space by converting its outputs given context, into the\nlanguage FST at runtime. This involves language FST structure redesign, pruning\nstrategy tuning, and data structure optimizations. Online experiments\ndemonstrate improved quality results, reducing Words Modified Ratio by [0.26\\%,\n1.19\\%] on various locales with acceptable latency increases. This work opens\nnew avenues for further improving keyboard decoding quality by enhancing neural\nLM more directly.\n","authors":["Yanxiang Zhang","Yuanbo Zhang","Haicheng Sun","Yun Wang","Billy Dou","Gary Sivek","Shumin Zhai"],"pdf_url":"https://arxiv.org/pdf/2410.15575v1.pdf","comment":"10 pages, 7 figures, 3 tables"},{"id":"http://arxiv.org/abs/2410.15573v1","updated":"2024-10-21T01:36:42Z","published":"2024-10-21T01:36:42Z","title":"OpenMU: Your Swiss Army Knife for Music Understanding","summary":"  We present OpenMU-Bench, a large-scale benchmark suite for addressing the\ndata scarcity issue in training multimodal language models to understand music.\nTo construct OpenMU-Bench, we leveraged existing datasets and bootstrapped new\nannotations. OpenMU-Bench also broadens the scope of music understanding by\nincluding lyrics understanding and music tool usage. Using OpenMU-Bench, we\ntrained our music understanding model, OpenMU, with extensive ablations,\ndemonstrating that OpenMU outperforms baseline models such as MU-Llama. Both\nOpenMU and OpenMU-Bench are open-sourced to facilitate future research in music\nunderstanding and to enhance creative music production efficiency.\n","authors":["Mengjie Zhao","Zhi Zhong","Zhuoyuan Mao","Shiqi Yang","Wei-Hsiang Liao","Shusuke Takahashi","Hiromi Wakaki","Yuki Mitsufuji"],"pdf_url":"https://arxiv.org/pdf/2410.15573v1.pdf","comment":"Resources: https://github.com/mzhaojp22/openmu"},{"id":"http://arxiv.org/abs/2410.15572v1","updated":"2024-10-21T01:36:08Z","published":"2024-10-21T01:36:08Z","title":"Leveraging Retrieval-Augmented Generation for Culturally Inclusive Hakka\n  Chatbots: Design Insights and User Perceptions","summary":"  In an era where cultural preservation is increasingly intertwined with\ntechnological innovation, this study introduces a groundbreaking approach to\npromoting and safeguarding the rich heritage of Taiwanese Hakka culture through\nthe development of a Retrieval-Augmented Generation (RAG)-enhanced chatbot.\nTraditional large language models (LLMs), while powerful, often fall short in\ndelivering accurate and contextually rich responses, particularly in culturally\nspecific domains. By integrating external databases with generative AI models,\nRAG technology bridges this gap, empowering chatbots to not only provide\nprecise answers but also resonate deeply with the cultural nuances that are\ncrucial for authentic interactions. This study delves into the intricate\nprocess of augmenting the chatbot's knowledge base with targeted cultural data,\nspecifically curated to reflect the unique aspects of Hakka traditions,\nlanguage, and practices. Through dynamic information retrieval, the\nRAG-enhanced chatbot becomes a versatile tool capable of handling complex\ninquiries that demand an in-depth understanding of Hakka cultural context. This\nis particularly significant in an age where digital platforms often dilute\ncultural identities, making the role of culturally aware AI systems more\ncritical than ever. System usability studies conducted as part of our research\nreveal a marked improvement in both user satisfaction and engagement,\nhighlighting the chatbot's effectiveness in fostering a deeper connection with\nHakka culture. The feedback underscores the potential of RAG technology to not\nonly enhance user experience but also to serve as a vital instrument in the\nbroader mission of ethnic mainstreaming and cultural celebration.\n","authors":["Chen-Chi Chang","Han-Pi Chang","Hung-Shin Lee"],"pdf_url":"https://arxiv.org/pdf/2410.15572v1.pdf","comment":"Accepted to IEEE RASSE 2024"},{"id":"http://arxiv.org/abs/2410.15570v1","updated":"2024-10-21T01:27:29Z","published":"2024-10-21T01:27:29Z","title":"Stacking Small Language Models for Generalizability","summary":"  Recent advances show that large language models (LLMs) generalize strong\nperformance across different natural language benchmarks. However, the large\nsize of LLMs makes training and inference expensive and impractical to run in\nresource-limited settings. This paper introduces a new approach called\nfine-tuning stacks of language models (FSLM), which involves stacking small\nlanguage models (SLM) as an alternative to LLMs. By fine-tuning each SLM to\nperform a specific task, this approach breaks down high level reasoning into\nmultiple lower-level steps that specific SLMs are responsible for. As a result,\nFSLM allows for lower training and inference costs, and also improves model\ninterpretability as each SLM communicates with the subsequent one through\nnatural language. By evaluating FSLM on common natural language benchmarks,\nthis paper highlights promising early results toward generalizable performance\nusing FSLM as a cost-effective alternative to LLMs.\n","authors":["Laurence Liang"],"pdf_url":"https://arxiv.org/pdf/2410.15570v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.15567v1","updated":"2024-10-21T01:23:34Z","published":"2024-10-21T01:23:34Z","title":"Pruning Foundation Models for High Accuracy without Retraining","summary":"  Despite the superior performance, it is challenging to deploy foundation\nmodels or large language models (LLMs) due to their massive parameters and\ncomputations. While pruning is a promising technique to reduce model size and\naccelerate the inference, the traditional pruning techniques can hardly be\napplied for LLMs as they need to finetune the model on the full dataset with\nmultiple epochs consuming massive data and hardware resources. To deal with\nthis problem, post-training pruning methods are proposed to prune LLMs in\none-shot without retraining. However, their accuracy after pruning may suffer\nfrom certain performance degradation due to the lack of retraining with massive\ndata. To address this issue, in this paper, we first formulate the\npost-training problem for layer-wise LLM compression to simultaneously prune\nmultiple weights in LLMs. Next, we provide an optimal solution for this problem\nand design our post-training pruning algorithm for both unstructured and\nsemi-structured sparsity. Our extensive experiments demonstrate the superior\nperformance of the proposed methods in comparison to SOTA baselines across\nvarious LLM families including transformer-based LLMs and Mamba-based LLMs.\nCode link: https://github.com/piuzha/APT\n","authors":["Pu Zhao","Fei Sun","Xuan Shen","Pinrui Yu","Zhenglun Kong","Yanzhi Wang","Xue Lin"],"pdf_url":"https://arxiv.org/pdf/2410.15567v1.pdf","comment":"Accepted by EMNLP 2024 findings"},{"id":"http://arxiv.org/abs/2410.15553v1","updated":"2024-10-21T00:59:47Z","published":"2024-10-21T00:59:47Z","title":"Multi-IF: Benchmarking LLMs on Multi-Turn and Multilingual Instructions\n  Following","summary":"  Large Language Models (LLMs) have demonstrated impressive capabilities in\nvarious tasks, including instruction following, which is crucial for aligning\nmodel outputs with user expectations. However, evaluating LLMs' ability to\nfollow instructions remains challenging due to the complexity and subjectivity\nof human language. Current benchmarks primarily focus on single-turn,\nmonolingual instructions, which do not adequately reflect the complexities of\nreal-world applications that require handling multi-turn and multilingual\ninteractions. To address this gap, we introduce Multi-IF, a new benchmark\ndesigned to assess LLMs' proficiency in following multi-turn and multilingual\ninstructions. Multi-IF, which utilizes a hybrid framework combining LLM and\nhuman annotators, expands upon the IFEval by incorporating multi-turn sequences\nand translating the English prompts into another 7 languages, resulting in a\ndataset of 4,501 multilingual conversations, where each has three turns. Our\nevaluation of 14 state-of-the-art LLMs on Multi-IF reveals that it presents a\nsignificantly more challenging task than existing benchmarks. All the models\ntested showed a higher rate of failure in executing instructions correctly with\neach additional turn. For example, o1-preview drops from 0.877 at the first\nturn to 0.707 at the third turn in terms of average accuracy over all\nlanguages. Moreover, languages with non-Latin scripts (Hindi, Russian, and\nChinese) generally exhibit higher error rates, suggesting potential limitations\nin the models' multilingual capabilities. We release Multi-IF prompts and the\nevaluation code base to encourage further research in this critical area.\n","authors":["Yun He","Di Jin","Chaoqi Wang","Chloe Bi","Karishma Mandyam","Hejia Zhang","Chen Zhu","Ning Li","Tengyu Xu","Hongjiang Lv","Shruti Bhosale","Chenguang Zhu","Karthik Abinav Sankararaman","Eryk Helenowski","Melanie Kambadur","Aditya Tayade","Hao Ma","Han Fang","Sinong Wang"],"pdf_url":"https://arxiv.org/pdf/2410.15553v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.09662v2","updated":"2024-10-21T23:58:45Z","published":"2024-06-14T02:21:53Z","title":"Learning Language Structures through Grounding","summary":"  Language is highly structured, with syntactic and semantic structures, to\nsome extent, agreed upon by speakers of the same language. With implicit or\nexplicit awareness of such structures, humans can learn and use language\nefficiently and generalize to sentences that contain unseen words. Motivated by\nhuman language learning, in this dissertation, we consider a family of machine\nlearning tasks that aim to learn language structures through grounding. We seek\ndistant supervision from other data sources (i.e., grounds), including but not\nlimited to other modalities (e.g., vision), execution results of programs, and\nother languages.\n  We demonstrate the potential of this task formulation and advocate for its\nadoption through three schemes. In Part I, we consider learning syntactic\nparses through visual grounding. We propose the task of visually grounded\ngrammar induction, present the first models to induce syntactic structures from\nvisually grounded text and speech, and find that the visual grounding signals\ncan help improve the parsing quality over language-only models. As a side\ncontribution, we propose a novel evaluation metric that enables the evaluation\nof speech parsing without text or automatic speech recognition systems\ninvolved. In Part II, we propose two execution-aware methods to map sentences\ninto corresponding semantic structures (i.e., programs), significantly\nimproving compositional generalization and few-shot program synthesis. In Part\nIII, we propose methods that learn language structures from annotations in\nother languages. Specifically, we propose a method that sets a new state of the\nart on cross-lingual word alignment. We then leverage the learned word\nalignments to improve the performance of zero-shot cross-lingual dependency\nparsing, by proposing a novel substructure-based projection method that\npreserves structural knowledge learned from the source language.\n","authors":["Freda Shi"],"pdf_url":"https://arxiv.org/pdf/2406.09662v2.pdf","comment":"Ph.D. Thesis"},{"id":"http://arxiv.org/abs/2410.13804v3","updated":"2024-10-21T23:37:48Z","published":"2024-10-17T17:41:15Z","title":"BenTo: Benchmark Task Reduction with In-Context Transferability","summary":"  Evaluating large language models (LLMs) is costly: it requires the generation\nand examination of LLM outputs on a large-scale benchmark of various tasks.\nThis paper investigates how to efficiently reduce the tasks used to benchmark\nLLMs without affecting the evaluation quality. Our study reveals that task\ntransferability and relevance provide critical information to identify the most\nrepresentative subset of tasks via optimizing a facility location function. We\npropose a practically efficient metric for estimating the transferability\nbetween two tasks via in-context learning (ICL). By analyzing the pairwise\ntransferability, we can reduce tasks in a modern LLM benchmark (e.g., MMLU or\nFLAN) to 5% while inducing only a <4% difference to the evaluation on the\noriginal benchmark. Compared to prior works, our method is training-free,\ngradient-free, and highly efficient requiring ICL only.\n","authors":["Hongyu Zhao","Ming Li","Lichao Sun","Tianyi Zhou"],"pdf_url":"https://arxiv.org/pdf/2410.13804v3.pdf","comment":"https://github.com/tianyi-lab/bento"},{"id":"http://arxiv.org/abs/2405.18400v5","updated":"2024-10-21T22:56:06Z","published":"2024-05-28T17:40:48Z","title":"Superposed Decoding: Multiple Generations from a Single Autoregressive\n  Inference Pass","summary":"  Many applications today provide users with multiple auto-complete drafts as\nthey type, including GitHub's code completion, Gmail's smart compose, and\nApple's messaging auto-suggestions. Under the hood, language models support\nthis by running an autoregressive inference pass to provide a draft.\nConsequently, providing $k$ drafts to the user requires running an expensive\nlanguage model $k$ times. To alleviate the computation cost of running $k$\ninference passes, we propose Superposed Decoding, a new decoding algorithm that\ngenerates $k$ drafts at the computation cost of one autoregressive inference\npass. We achieve this by feeding a superposition of the most recent token\nembeddings from the $k$ drafts as input to the next decoding step of the\nlanguage model. At every inference step we combine the $k$ drafts with the\ntop-$k$ tokens to get $k^2$ new drafts and cache the $k$ most likely options,\nusing an n-gram interpolation with minimal compute overhead to filter out\nincoherent generations. Our experiments show that $k$ drafts from Superposed\nDecoding are at least as coherent and factual as Nucleus Sampling and Greedy\nDecoding respectively, while being at least $2.44\\times$ faster for $k\\ge3$. In\na compute-normalized setting, user evaluations demonstrably favor text\ngenerated by Superposed Decoding over Nucleus Sampling. Superposed Decoding can\nalso be combined with other decoding strategies, resulting in universal\ncoverage gains when scaling inference time compute. Code and more examples\nopen-sourced at https://github.com/RAIVNLab/SuperposedDecoding.\n","authors":["Ethan Shen","Alan Fan","Sarah M. Pratt","Jae Sung Park","Matthew Wallingford","Sham M. Kakade","Ari Holtzman","Ranjay Krishna","Ali Farhadi","Aditya Kusupati"],"pdf_url":"https://arxiv.org/pdf/2405.18400v5.pdf","comment":"23 pages, 16 figures, accepted at NeurIPS 2024"},{"id":"http://arxiv.org/abs/2410.16560v1","updated":"2024-10-21T22:39:52Z","published":"2024-10-21T22:39:52Z","title":"Raising the Stakes: Performance Pressure Improves AI-Assisted Decision\n  Making","summary":"  AI systems are used in many domains to assist with decision making, and\nalthough the potential for AI systems to assist with decision making is much\ndiscussed, human-AI collaboration often underperforms. Investigation into why\nthe performance potential is not realized has revealed many factors, including\n(mis)trust in the AI system and mental models of AI capabilities on subjective\ntasks. Performance pressure is known to influence human decision making\nbehavior, yet how it interacts with human-AI decision making is understudied.\nIn this work, we show the effects of performance pressure on AI advice reliance\nwhen laypeople (Amazon Mechanical Turk crowdworkers) complete a common\nAI-assisted task (fake review detection) and thus have inherently low\nperformance pressure. We manipulate performance pressure by leveraging people's\nloss aversion towards potential monetary gains when completing a task. We find\nthat when the stakes are high, people use AI advice more appropriately than\nwhen stakes are lower, regardless of the presence of an AI explanation.\nFurthermore, when the AI system gives incorrect advice, people correctly\ndiscount the poor advice more often when the stakes are higher than when they\nare lower. We conclude by discussing the implications of how performance\npressure influences AI-assisted decision making and encourage future research\nto incorporate performance pressure analysis.\n","authors":["Nikita Haduong","Noah A. Smith"],"pdf_url":"https://arxiv.org/pdf/2410.16560v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.16540v1","updated":"2024-10-21T22:07:20Z","published":"2024-10-21T22:07:20Z","title":"A Theoretical Understanding of Chain-of-Thought: Coherent Reasoning and\n  Error-Aware Demonstration","summary":"  Few-shot Chain-of-Thought (CoT) prompting has demonstrated strong performance\nin improving the reasoning capabilities of large language models (LLMs). While\ntheoretical investigations have been conducted to understand CoT, the\nunderlying transformer used in these studies isolates the CoT reasoning process\ninto separated in-context learning steps (Stepwise ICL). In this work, we\ntheoretically show that, compared to Stepwise ICL, the transformer gains better\nerror correction ability and more accurate predictions if the reasoning from\nearlier steps (Coherent CoT) is integrated. Given that this coherent reasoning\nchanges the behavior of the transformer, we further investigate the sensitivity\nof the transformer with Coherent CoT when the demonstration examples are\ncorrupted at the inference stage. Our theoretical results indicate that the\ntransformer is more sensitive to errors in intermediate reasoning steps than\nthe final outcome. Building upon this observation, we propose an improvement on\nCoT by incorporating both correct and incorrect reasoning paths in the\ndemonstration. Our experiments validate the effectiveness of the proposed\napproach.\n","authors":["Yingqian Cui","Pengfei He","Xianfeng Tang","Qi He","Chen Luo","Jiliang Tang","Yue Xing"],"pdf_url":"https://arxiv.org/pdf/2410.16540v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.11627v2","updated":"2024-10-21T21:49:33Z","published":"2024-10-15T14:14:19Z","title":"Tokenization and Morphology in Multilingual Language Models: A\n  Comparative Analysis of mT5 and ByT5","summary":"  Morphology is a crucial factor for multilingual language modeling as it poses\ndirect challenges for tokenization. Here, we seek to understand how\ntokenization influences the morphological knowledge encoded in multilingual\nlanguage models. Specifically, we capture the impact of tokenization by\ncontrasting two multilingual language models: mT5 and ByT5. The two models\nshare the same architecture, training objective, and training data and only\ndiffer in their tokenization strategies: subword tokenization vs.\\@\ncharacter-level tokenization. Probing the morphological knowledge encoded in\nthese models on four tasks and 17 languages, our analyses show that the models\nlearn the morphological systems of some languages better than others and that\nmorphological information is encoded in the middle and late layers. Finally, we\nshow that languages with more irregularities benefit more from having a higher\nshare of the pre-training data.\n","authors":["Thao Anh Dang","Limor Raviv","Lukas Galke"],"pdf_url":"https://arxiv.org/pdf/2410.11627v2.pdf","comment":"8 pages"},{"id":"http://arxiv.org/abs/2410.16533v1","updated":"2024-10-21T21:48:24Z","published":"2024-10-21T21:48:24Z","title":"Large Body Language Models","summary":"  As virtual agents become increasingly prevalent in human-computer\ninteraction, generating realistic and contextually appropriate gestures in\nreal-time remains a significant challenge. While neural rendering techniques\nhave made substantial progress with static scripts, their applicability to\nhuman-computer interactions remains limited. To address this, we introduce\nLarge Body Language Models (LBLMs) and present LBLM-AVA, a novel LBLM\narchitecture that combines a Transformer-XL large language model with a\nparallelized diffusion model to generate human-like gestures from multimodal\ninputs (text, audio, and video). LBLM-AVA incorporates several key components\nenhancing its gesture generation capabilities, such as multimodal-to-pose\nembeddings, enhanced sequence-to-sequence mapping with redefined attention\nmechanisms, a temporal smoothing module for gesture sequence coherence, and an\nattention-based refinement module for enhanced realism. The model is trained on\nour large-scale proprietary open-source dataset Allo-AVA. LBLM-AVA achieves\nstate-of-the-art performance in generating lifelike and contextually\nappropriate gestures with a 30% reduction in Fr\\'echet Gesture Distance (FGD),\nand a 25% improvement in Fr\\'echet Inception Distance compared to existing\napproaches.\n","authors":["Saif Punjwani","Larry Heck"],"pdf_url":"https://arxiv.org/pdf/2410.16533v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.16531v1","updated":"2024-10-21T21:45:22Z","published":"2024-10-21T21:45:22Z","title":"Bayesian scaling laws for in-context learning","summary":"  In-context learning (ICL) is a powerful technique for getting language models\nto perform complex tasks with no training updates. Prior work has established\nstrong correlations between the number of in-context examples provided and the\naccuracy of the model's predictions. In this paper, we seek to explain this\ncorrelation by showing that ICL approximates a Bayesian learner. This\nperspective gives rise to a family of novel Bayesian scaling laws for ICL. In\nexperiments with \\mbox{GPT-2} models of different sizes, our scaling laws\nexceed or match existing scaling laws in accuracy while also offering\ninterpretable terms for task priors, learning efficiency, and per-example\nprobabilities. To illustrate the analytic power that such interpretable scaling\nlaws provide, we report on controlled synthetic dataset experiments designed to\ninform real-world studies of safety alignment. In our experimental protocol, we\nuse SFT to suppress an unwanted existing model capability and then use ICL to\ntry to bring that capability back (many-shot jailbreaking). We then experiment\non real-world instruction-tuned LLMs using capabilities benchmarks as well as a\nnew many-shot jailbreaking dataset. In all cases, Bayesian scaling laws\naccurately predict the conditions under which ICL will cause the suppressed\nbehavior to reemerge, which sheds light on the ineffectiveness of post-training\nat increasing LLM safety.\n","authors":["Aryaman Arora","Dan Jurafsky","Christopher Potts","Noah D. Goodman"],"pdf_url":"https://arxiv.org/pdf/2410.16531v1.pdf","comment":"10 pages main text, 26 pages total"},{"id":"http://arxiv.org/abs/2410.14668v2","updated":"2024-10-21T21:42:46Z","published":"2024-10-18T17:57:40Z","title":"MiCEval: Unveiling Multimodal Chain of Thought's Quality via Image\n  Description and Reasoning Steps","summary":"  Multimodal Chain of Thought (MCoT) is a popular prompting strategy for\nimproving the performance of multimodal large language models (MLLMs) across a\nrange of complex reasoning tasks. Despite its popularity, there is a notable\nabsence of automated methods for evaluating the quality of reasoning steps in\nMCoT. To address this gap, we propose Multimodal Chain-of-Thought Evaluation\n(MiCEval), a framework designed to assess the correctness of reasoning chains\nby evaluating the quality of both the description and each reasoning step. The\nevaluation of the description component focuses on the accuracy of the image\ndescriptions, while the reasoning step evaluates the quality of each step as it\nis conditionally generated based on the preceding steps. MiCEval is built upon\na fine-grained dataset with annotations that rate each step according to\ncorrectness, relevance, and informativeness. Extensive experiments on four\nstate-of-the-art MLLMs show that step-wise evaluations using MiCEval align more\nclosely with human judgments compared to existing methods based on cosine\nsimilarity or fine-tuning approaches. MiCEval datasets and code can be found in\nhttps://github.com/alenai97/MiCEval.\n","authors":["Xiongtao Zhou","Jie He","Lanyu Chen","Jingyu Li","Haojing Chen","Victor Gutierrez Basulto","Jeff Z. Pan","Hanjie Chen"],"pdf_url":"https://arxiv.org/pdf/2410.14668v2.pdf","comment":"40 pages"},{"id":"http://arxiv.org/abs/2406.08598v2","updated":"2024-10-21T21:32:51Z","published":"2024-06-12T19:05:43Z","title":"Language Model Council: Democratically Benchmarking Foundation Models on\n  Highly Subjective Tasks","summary":"  As Large Language Models (LLMs) continue to evolve, the search for efficient\nand meaningful evaluation methods is ongoing. Many recent evaluations use LLMs\nas judges to score outputs from other LLMs, often relying on a single large\nmodel like GPT-4o. However, using a single LLM judge is prone to intra-model\nbias, and many tasks - such as those related to emotional intelligence,\ncreative writing, and persuasiveness - may be too subjective for a single model\nto judge fairly. We introduce the Language Model Council (LMC), where a group\nof LLMs collaborate to create tests, respond to them, and evaluate each other's\nresponses to produce a ranking in a democratic fashion. Unlike previous\napproaches that focus on reducing cost or bias by using a panel of smaller\nmodels, our work examines the benefits and nuances of a fully inclusive LLM\nevaluation system. In a detailed case study on emotional intelligence, we\ndeploy a council of 20 recent LLMs to rank each other on open-ended responses\nto interpersonal conflicts. Our results show that the LMC produces rankings\nthat are more separable and more robust, and through a user study, we show that\nthey are more consistent with human evaluations than any individual LLM judge.\nUsing all LLMs for judging can be costly, however, so we use Monte Carlo\nsimulations and hand-curated sub-councils to study hypothetical council\ncompositions and discuss the value of the incremental LLM judge.\n","authors":["Justin Zhao","Flor Miriam Plaza-del-Arco","Benjie Genchel","Amanda Cercas Curry"],"pdf_url":"https://arxiv.org/pdf/2406.08598v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.16520v1","updated":"2024-10-21T21:21:29Z","published":"2024-10-21T21:21:29Z","title":"AUTALIC: A Dataset for Anti-AUTistic Ableist Language In Context","summary":"  As our understanding of autism and ableism continues to increase, so does our\nunderstanding of ableist language towards autistic people. Such language poses\na significant challenge in NLP research due to its subtle and context-dependent\nnature. Yet, detecting anti-autistic ableist language remains underexplored,\nwith existing NLP tools often failing to capture its nuanced expressions. We\npresent AUTALIC, the first benchmark dataset dedicated to the detection of\nanti-autistic ableist language in context, addressing a significant gap in the\nfield. The dataset comprises 2,400 autism-related sentences collected from\nReddit, accompanied by surrounding context, and is annotated by trained experts\nwith backgrounds in neurodiversity. Our comprehensive evaluation reveals that\ncurrent language models, including state-of-the-art LLMs, struggle to reliably\nidentify anti-autistic ableism and align with human judgments, underscoring\ntheir limitations in this domain. We publicly release AUTALIC along with the\nindividual annotations which serve as a valuable resource to researchers\nworking on ableism, neurodiversity, and also studying disagreements in\nannotation tasks. This dataset serves as a crucial step towards developing more\ninclusive and context-aware NLP systems that better reflect diverse\nperspectives.\n","authors":["Naba Rizvi","Harper Strickland","Daniel Gitelman","Tristan Cooper","Alexis Morales-Flores","Michael Golden","Aekta Kallepalli","Akshat Alurkar","Haaset Owens","Saleha Ahmedi","Isha Khirwadkar","Imani Munyaka","Nedjma Ousidhoum"],"pdf_url":"https://arxiv.org/pdf/2410.16520v1.pdf","comment":"9 pages, 5 figures, 7 tables"},{"id":"http://arxiv.org/abs/2405.13274v2","updated":"2024-10-21T21:09:22Z","published":"2024-05-22T01:10:39Z","title":"DiffNorm: Self-Supervised Normalization for Non-autoregressive\n  Speech-to-speech Translation","summary":"  Non-autoregressive Transformers (NATs) are recently applied in direct\nspeech-to-speech translation systems, which convert speech across different\nlanguages without intermediate text data. Although NATs generate high-quality\noutputs and offer faster inference than autoregressive models, they tend to\nproduce incoherent and repetitive results due to complex data distribution\n(e.g., acoustic and linguistic variations in speech). In this work, we\nintroduce DiffNorm, a diffusion-based normalization strategy that simplifies\ndata distributions for training NAT models. After training with a\nself-supervised noise estimation objective, DiffNorm constructs normalized\ntarget data by denoising synthetically corrupted speech features. Additionally,\nwe propose to regularize NATs with classifier-free guidance, improving model\nrobustness and translation quality by randomly dropping out source information\nduring training. Our strategies result in a notable improvement of about +7\nASR-BLEU for English-Spanish (En-Es) and +2 ASR-BLEU for English-French (En-Fr)\ntranslations on the CVSS benchmark, while attaining over 14x speedup for En-Es\nand 5x speedup for En-Fr translations compared to autoregressive baselines.\n","authors":["Weiting Tan","Jingyu Zhang","Lingfeng Shen","Daniel Khashabi","Philipp Koehn"],"pdf_url":"https://arxiv.org/pdf/2405.13274v2.pdf","comment":"Accepted at NeurIPS 2024"},{"id":"http://arxiv.org/abs/2410.16509v1","updated":"2024-10-21T21:00:47Z","published":"2024-10-21T21:00:47Z","title":"Learning from others' mistakes: Finetuning machine translation models\n  with span-level error annotations","summary":"  Despite growing interest in incorporating feedback to improve language\nmodels, most efforts focus only on sequence-level annotations. In this work, we\nexplore the potential of utilizing fine-grained span-level annotations from\noffline datasets to improve model quality. We develop a simple finetuning\nalgorithm, called Training with Annotations (TWA), to directly train machine\ntranslation models on such annotated data. TWA utilizes targeted span-level\nerror information while also flexibly learning what to penalize within a span.\nMoreover, TWA considers the overall trajectory of a sequence when deciding\nwhich non-error spans to utilize as positive signals. Experiments on\nEnglish-German and Chinese-English machine translation show that TWA\noutperforms baselines such as Supervised FineTuning on sequences filtered for\nquality and Direct Preference Optimization on pairs constructed from the same\ndata.\n","authors":["Lily H. Zhang","Hamid Dadkhahi","Mara Finkelstein","Firas Trabelsi","Jiaming Luo","Markus Freitag"],"pdf_url":"https://arxiv.org/pdf/2410.16509v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2402.11414v2","updated":"2024-10-21T20:58:43Z","published":"2024-02-18T01:03:25Z","title":"Fine-grained and Explainable Factuality Evaluation for Multimodal\n  Summarization","summary":"  Multimodal summarization aims to generate a concise summary based on the\ninput text and image. However, the existing methods potentially suffer from\nunfactual output. To evaluate the factuality of multimodal summarization\nmodels, we propose two fine-grained and explainable evaluation frameworks\n(FALLACIOUS) for different application scenarios, i.e. reference-based\nfactuality evaluation framework and reference-free factuality evaluation\nframework. Notably, the reference-free factuality evaluation framework doesn't\nneed ground truth and hence it has a wider application scenario. To evaluate\nthe effectiveness of the proposed frameworks, we compute the correlation\nbetween our frameworks and the other metrics. The experimental results show the\neffectiveness of our proposed method. We will release our code and dataset via\ngithub.\n","authors":["Yue Zhang","Jingxuan Zuo","Liqiang Jing"],"pdf_url":"https://arxiv.org/pdf/2402.11414v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.16503v1","updated":"2024-10-21T20:50:51Z","published":"2024-10-21T20:50:51Z","title":"Allo-AVA: A Large-Scale Multimodal Conversational AI Dataset for\n  Allocentric Avatar Gesture Animation","summary":"  The scarcity of high-quality, multimodal training data severely hinders the\ncreation of lifelike avatar animations for conversational AI in virtual\nenvironments. Existing datasets often lack the intricate synchronization\nbetween speech, facial expressions, and body movements that characterize\nnatural human communication. To address this critical gap, we introduce\nAllo-AVA, a large-scale dataset specifically designed for text and audio-driven\navatar gesture animation in an allocentric (third person point-of-view)\ncontext. Allo-AVA consists of $\\sim$1,250 hours of diverse video content,\ncomplete with audio, transcripts, and extracted keypoints. Allo-AVA uniquely\nmaps these keypoints to precise timestamps, enabling accurate replication of\nhuman movements (body and facial gestures) in synchronization with speech. This\ncomprehensive resource enables the development and evaluation of more natural,\ncontext-aware avatar animation models, potentially transforming applications\nranging from virtual reality to digital assistants.\n","authors":["Saif Punjwani","Larry Heck"],"pdf_url":"https://arxiv.org/pdf/2410.16503v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.16502v1","updated":"2024-10-21T20:48:16Z","published":"2024-10-21T20:48:16Z","title":"Rulebreakers Challenge: Revealing a Blind Spot in Large Language Models'\n  Reasoning with Formal Logic","summary":"  Formal logic has long been applied to natural language reasoning, but this\napproach can sometimes lead to conclusions that, while logically entailed, are\nfactually inconsistent with the premises or are not typically inferred by\nhumans. This study introduces the concept of \"rulebreakers\", which refers to\ninstances where logical entailment diverges from factually acceptable\ninference. We present RULEBREAKERS, a novel dataset for evaluating Large\nLanguage Models' (LLMs) ability to distinguish between rulebreakers and\nnon-rulebreakers. Focusing on modus tollens and disjunctive syllogism, we\nassess six state-of-the-art LLMs using RULEBREAKERS, measuring their\nperformance in terms of token-level exact accuracy and model confidence. Our\nfindings reveal that while most models perform poorly to moderately in\nrecognizing rulebreakers, they demonstrate a latent ability to distinguish\nrulebreakers when assessed by their confidence levels. Further analysis\nsuggests that the failure to recognize rulebreakers is potentially associated\nwith the models' world knowledge and their attention distribution patterns.\nThis research highlights the limitation of LLMs' reasoning capabilities, and\ncontributes to the ongoing discussion on reasoning in LLMs.\n","authors":["Jason Chan","Robert Gaizauskas","Zhixue Zhao"],"pdf_url":"https://arxiv.org/pdf/2410.16502v1.pdf","comment":"Preprint"},{"id":"http://arxiv.org/abs/2410.16498v1","updated":"2024-10-21T20:41:00Z","published":"2024-10-21T20:41:00Z","title":"Natural Language Processing for Human Resources: A Survey","summary":"  The domain of human resources (HR) includes a broad spectrum of tasks related\nto natural language processing (NLP) techniques. Recent breakthroughs in NLP\nhave generated significant interest in its industrial applications in this\ndomain and potentially alleviate challenges such as the difficulty of resource\nacquisition and the complexity of problems. At the same time, the HR domain can\nalso present unique challenges that drive state-of-the-art in NLP research. To\nsupport this, we provide NLP researchers and practitioners with an overview of\nkey HR tasks from an NLP perspective, illustrating how specific sub-tasks\n(e.g., skill extraction) contribute to broader objectives (e.g., job matching).\nThrough this survey, we identify opportunities in NLP for HR and suggest\ndirections for future exploration.\n","authors":["Naoki Otani","Nikita Bhutani","Estevam Hruschka"],"pdf_url":"https://arxiv.org/pdf/2410.16498v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.16491v1","updated":"2024-10-21T20:32:27Z","published":"2024-10-21T20:32:27Z","title":"BIG5-CHAT: Shaping LLM Personalities Through Training on Human-Grounded\n  Data","summary":"  In this work, we tackle the challenge of embedding realistic human\npersonality traits into LLMs. Previous approaches have primarily focused on\nprompt-based methods that describe the behavior associated with the desired\npersonality traits, suffering from realism and validity issues. To address\nthese limitations, we introduce BIG5-CHAT, a large-scale dataset containing\n100,000 dialogues designed to ground models in how humans express their\npersonality in text. Leveraging this dataset, we explore Supervised Fine-Tuning\nand Direct Preference Optimization as training-based methods to align LLMs more\nnaturally with human personality patterns. Our methods outperform prompting on\npersonality assessments such as BFI and IPIP-NEO, with trait correlations more\nclosely matching human data. Furthermore, our experiments reveal that models\ntrained to exhibit higher conscientiousness, higher agreeableness, lower\nextraversion, and lower neuroticism display better performance on reasoning\ntasks, aligning with psychological findings on how these traits impact human\ncognitive performance. To our knowledge, this work is the first comprehensive\nstudy to demonstrate how training-based methods can shape LLM personalities\nthrough learning from real human behaviors.\n","authors":["Wenkai Li","Jiarui Liu","Andy Liu","Xuhui Zhou","Mona Diab","Maarten Sap"],"pdf_url":"https://arxiv.org/pdf/2410.16491v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.16473v1","updated":"2024-10-21T20:01:06Z","published":"2024-10-21T20:01:06Z","title":"Multi-head Sequence Tagging Model for Grammatical Error Correction","summary":"  To solve the Grammatical Error Correction (GEC) problem , a mapping between a\nsource sequence and a target one is needed, where the two differ only on few\nspans. For this reason, the attention has been shifted to the\nnon-autoregressive or sequence tagging models. In which, the GEC has been\nsimplified from Seq2Seq to labeling the input tokens with edit commands chosen\nfrom a large edit space. Due to this large number of classes and the limitation\nof the available datasets, the current sequence tagging approaches still have\nsome issues handling a broad range of grammatical errors just by being\nlaser-focused on one single task. To this end, we simplified the GEC further by\ndividing it into seven related subtasks: Insertion, Deletion, Merge,\nSubstitution, Transformation, Detection, and Correction, with Correction being\nour primary focus. A distinct classification head is dedicated to each of these\nsubtasks. the novel multi-head and multi-task learning model is proposed to\neffectively utilize training data and harness the information from related task\ntraining signals. To mitigate the limited number of available training samples,\na new denoising autoencoder is used to generate a new synthetic dataset to be\nused for pretraining. Additionally, a new character-level transformation is\nproposed to enhance the sequence-to-edit function and improve the model's\nvocabulary coverage. Our single/ensemble model achieves an F0.5 of 74.4/77.0,\nand 68.6/69.1 on BEA-19 (test) and CoNLL-14 (test) respectively. Moreover,\nevaluated on JFLEG test set, the GLEU scores are 61.6 and 61.7 for the single\nand ensemble models, respectively. It mostly outperforms recently published\nstate-of-the-art results by a considerable margin.\n","authors":["Kamal Al-Sabahi","Kang Yang","Wangwang Liu","Guanyu Jiang","Xian Li","Ming Yang"],"pdf_url":"https://arxiv.org/pdf/2410.16473v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.16472v1","updated":"2024-10-21T19:59:04Z","published":"2024-10-21T19:59:04Z","title":"DocEdit-v2: Document Structure Editing Via Multimodal LLM Grounding","summary":"  Document structure editing involves manipulating localized textual, visual,\nand layout components in document images based on the user's requests. Past\nworks have shown that multimodal grounding of user requests in the document\nimage and identifying the accurate structural components and their associated\nattributes remain key challenges for this task. To address these, we introduce\nthe DocEdit-v2, a novel framework that performs end-to-end document editing by\nleveraging Large Multimodal Models (LMMs). It consists of three novel\ncomponents: (1) Doc2Command, which simultaneously localizes edit regions of\ninterest (RoI) and disambiguates user edit requests into edit commands; (2)\nLLM-based Command Reformulation prompting to tailor edit commands originally\nintended for specialized software into edit instructions suitable for\ngeneralist LMMs. (3) Moreover, DocEdit-v2 processes these outputs via Large\nMultimodal Models like GPT-4V and Gemini, to parse the document layout, execute\nedits on grounded Region of Interest (RoI), and generate the edited document\nimage. Extensive experiments on the DocEdit dataset show that DocEdit-v2\nsignificantly outperforms strong baselines on edit command generation (2-33%),\nRoI bounding box detection (12-31%), and overall document editing (1-12\\%)\ntasks.\n","authors":["Manan Suri","Puneet Mathur","Franck Dernoncourt","Rajiv Jain","Vlad I Morariu","Ramit Sawhney","Preslav Nakov","Dinesh Manocha"],"pdf_url":"https://arxiv.org/pdf/2410.16472v1.pdf","comment":"EMNLP 2024 (Main)"},{"id":"http://arxiv.org/abs/2409.01344v2","updated":"2024-10-21T19:49:41Z","published":"2024-09-02T15:58:24Z","title":"Pairing Analogy-Augmented Generation with Procedural Memory for\n  Procedural Q&A","summary":"  Large language models struggle to synthesize disparate pieces of information\ninto a coherent plan when approaching a complex procedural task. In this work,\nwe introduce a novel formalism and structure for such procedural knowledge.\nBased on this formalism, we present a novel procedural knowledge dataset called\nLCStep, which we created from LangChain tutorials. To leverage this procedural\nknowledge to solve new tasks, we propose analogy-augmented generation (AAG),\nwhich draws inspiration from the human ability to assimilate past experiences\nto solve unfamiliar problems. AAG uses a custom procedure memory store to\nretrieve and adapt specialized domain knowledge to answer new procedural tasks.\nWe demonstrate that AAG outperforms few-shot and RAG baselines on LCStep,\nRecipeNLG, and CHAMP datasets under a pairwise LLM-based evaluation,\ncorroborated by human evaluation in the case of RecipeNLG.\n","authors":["K Roth","Rushil Gupta","Simon Halle","Bang Liu"],"pdf_url":"https://arxiv.org/pdf/2409.01344v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.16464v1","updated":"2024-10-21T19:46:06Z","published":"2024-10-21T19:46:06Z","title":"Beyond Browsing: API-Based Web Agents","summary":"  Web browsers are a portal to the internet, where much of human activity is\nundertaken. Thus, there has been significant research work in AI agents that\ninteract with the internet through web browsing. However, there is also another\ninterface designed specifically for machine interaction with online content:\napplication programming interfaces (APIs). In this paper we ask -- what if we\nwere to take tasks traditionally tackled by browsing agents, and give AI agents\naccess to APIs? To do so, we propose two varieties of agents: (1) an\nAPI-calling agent that attempts to perform online tasks through APIs only,\nsimilar to traditional coding agents, and (2) a Hybrid Agent that can interact\nwith online data through both web browsing and APIs. In experiments on\nWebArena, a widely-used and realistic benchmark for web navigation tasks, we\nfind that API-based agents outperform web browsing agents. Hybrid Agents\nout-perform both others nearly uniformly across tasks, resulting in a more than\n20.0% absolute improvement over web browsing alone, achieving a success rate of\n35.8%, achiving the SOTA performance among task-agnostic agents. These results\nstrongly suggest that when APIs are available, they present an attractive\nalternative to relying on web browsing alone.\n","authors":["Yueqi Song","Frank Xu","Shuyan Zhou","Graham Neubig"],"pdf_url":"https://arxiv.org/pdf/2410.16464v1.pdf","comment":"24 pages, 6 figures"},{"id":"http://arxiv.org/abs/2410.16461v1","updated":"2024-10-21T19:40:05Z","published":"2024-10-21T19:40:05Z","title":"Comparative Study of Multilingual Idioms and Similes in Large Language\n  Models","summary":"  This study addresses the gap in the literature concerning the comparative\nperformance of LLMs in interpreting different types of figurative language\nacross multiple languages. By evaluating LLMs using two multilingual datasets\non simile and idiom interpretation, we explore the effectiveness of various\nprompt engineering strategies, including chain-of-thought, few-shot, and\nEnglish translation prompts. We extend the language of these datasets to\nPersian as well by building two new evaluation sets. Our comprehensive\nassessment involves both closed-source (GPT-3.5, GPT-4o mini, Gemini 1.5), and\nopen-source models (Llama 3.1, Qwen2), highlighting significant differences in\nperformance across languages and figurative types. Our findings reveal that\nwhile prompt engineering methods are generally effective, their success varies\nby figurative type, language, and model. We also observe that open-source\nmodels struggle particularly with low-resource languages in similes.\nAdditionally, idiom interpretation is nearing saturation for many languages,\nnecessitating more challenging evaluations.\n","authors":["Paria Khoshtab","Danial Namazifard","Mostafa Masoudi","Ali Akhgary","Samin Mahdizadeh Sani","Yadollah Yaghoobzadeh"],"pdf_url":"https://arxiv.org/pdf/2410.16461v1.pdf","comment":"22 pages, 4 figures"},{"id":"http://arxiv.org/abs/2305.05094v2","updated":"2024-10-21T19:34:27Z","published":"2023-05-08T23:43:15Z","title":"Interactive Concept Learning for Uncovering Latent Themes in Large Text\n  Collections","summary":"  Experts across diverse disciplines are often interested in making sense of\nlarge text collections. Traditionally, this challenge is approached either by\nnoisy unsupervised techniques such as topic models, or by following a manual\ntheme discovery process. In this paper, we expand the definition of a theme to\naccount for more than just a word distribution, and include generalized\nconcepts deemed relevant by domain experts. Then, we propose an interactive\nframework that receives and encodes expert feedback at different levels of\nabstraction. Our framework strikes a balance between automation and manual\ncoding, allowing experts to maintain control of their study while reducing the\nmanual effort required.\n","authors":["Maria Leonor Pacheco","Tunazzina Islam","Lyle Ungar","Ming Yin","Dan Goldwasser"],"pdf_url":"https://arxiv.org/pdf/2305.05094v2.pdf","comment":"Accepted to Findings of ACL: ACL 2023"},{"id":"http://arxiv.org/abs/2410.16456v1","updated":"2024-10-21T19:30:05Z","published":"2024-10-21T19:30:05Z","title":"To the Globe (TTG): Towards Language-Driven Guaranteed Travel Planning","summary":"  Travel planning is a challenging and time-consuming task that aims to find an\nitinerary which satisfies multiple, interdependent constraints regarding\nflights, accommodations, attractions, and other travel arrangements. In this\npaper, we propose To the Globe (TTG), a real-time demo system that takes\nnatural language requests from users, translates it to symbolic form via a\nfine-tuned Large Language Model, and produces optimal travel itineraries with\nMixed Integer Linear Programming solvers. The overall system takes ~5 seconds\nto reply to the user request with guaranteed itineraries. To train TTG, we\ndevelop a synthetic data pipeline that generates user requests, flight and\nhotel information in symbolic form without human annotations, based on the\nstatistics of real-world datasets, and fine-tune an LLM to translate NL user\nrequests to their symbolic form, which is sent to the symbolic solver to\ncompute optimal itineraries. Our NL-symbolic translation achieves ~91% exact\nmatch in a backtranslation metric (i.e., whether the estimated symbolic form of\ngenerated natural language matches the groundtruth), and its returned\nitineraries have a ratio of 0.979 compared to the optimal cost of the ground\ntruth user request. When evaluated by users, TTG achieves consistently high Net\nPromoter Scores (NPS) of 35-40% on generated itinerary.\n","authors":["Da JU","Song Jiang","Andrew Cohen","Aaron Foss","Sasha Mitts","Arman Zharmagambetov","Brandon Amos","Xian Li","Justine T Kao","Maryam Fazel-Zarandi","Yuandong Tian"],"pdf_url":"https://arxiv.org/pdf/2410.16456v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.16454v1","updated":"2024-10-21T19:28:37Z","published":"2024-10-21T19:28:37Z","title":"Does your LLM truly unlearn? An embarrassingly simple approach to\n  recover unlearned knowledge","summary":"  Large language models (LLMs) have shown remarkable proficiency in generating\ntext, benefiting from extensive training on vast textual corpora. However, LLMs\nmay also acquire unwanted behaviors from the diverse and sensitive nature of\ntheir training data, which can include copyrighted and private content. Machine\nunlearning has been introduced as a viable solution to remove the influence of\nsuch problematic content without the need for costly and time-consuming\nretraining. This process aims to erase specific knowledge from LLMs while\npreserving as much model utility as possible. Despite the effectiveness of\ncurrent unlearning methods, little attention has been given to whether existing\nunlearning methods for LLMs truly achieve forgetting or merely hide the\nknowledge, which current unlearning benchmarks fail to detect. This paper\nreveals that applying quantization to models that have undergone unlearning can\nrestore the \"forgotten\" information. To thoroughly evaluate this phenomenon, we\nconduct comprehensive experiments using various quantization techniques across\nmultiple precision levels. We find that for unlearning methods with utility\nconstraints, the unlearned model retains an average of 21\\% of the intended\nforgotten knowledge in full precision, which significantly increases to 83\\%\nafter 4-bit quantization. Based on our empirical findings, we provide a\ntheoretical explanation for the observed phenomenon and propose a\nquantization-robust unlearning strategy to mitigate this intricate issue...\n","authors":["Zhiwei Zhang","Fali Wang","Xiaomin Li","Zongyu Wu","Xianfeng Tang","Hui Liu","Qi He","Wenpeng Yin","Suhang Wang"],"pdf_url":"https://arxiv.org/pdf/2410.16454v1.pdf","comment":"21 pages, 2 figures"},{"id":"http://arxiv.org/abs/2410.16451v1","updated":"2024-10-21T19:25:31Z","published":"2024-10-21T19:25:31Z","title":"Susu Box or Piggy Bank: Assessing Cultural Commonsense Knowledge between\n  Ghana and the U.S","summary":"  Recent work has highlighted the culturally-contingent nature of commonsense\nknowledge. We introduce AMAMMER${\\epsilon}$, a test set of 525 multiple-choice\nquestions designed to evaluate the commonsense knowledge of English LLMs,\nrelative to the cultural contexts of Ghana and the United States. To create\nAMAMMER${\\epsilon}$, we select a set of multiple-choice questions (MCQs) from\nexisting commonsense datasets and rewrite them in a multi-stage process\ninvolving surveys of Ghanaian and U.S. participants. In three rounds of\nsurveys, participants from both pools are solicited to (1) write correct and\nincorrect answer choices, (2) rate individual answer choices on a 5-point\nLikert scale, and (3) select the best answer choice from the newly-constructed\nMCQ items, in a final validation step. By engaging participants at multiple\nstages, our procedure ensures that participant perspectives are incorporated\nboth in the creation and validation of test items, resulting in high levels of\nagreement within each pool. We evaluate several off-the-shelf English LLMs on\nAMAMMER${\\epsilon}$. Uniformly, models prefer answers choices that align with\nthe preferences of U.S. annotators over Ghanaian annotators. Additionally, when\ntest items specify a cultural context (Ghana or the U.S.), models exhibit some\nability to adapt, but performance is consistently better in U.S. contexts than\nGhanaian. As large resources are devoted to the advancement of English LLMs,\nour findings underscore the need for culturally adaptable models and\nevaluations to meet the needs of diverse English-speaking populations around\nthe world.\n","authors":["Christabel Acquaye","Haozhe An","Rachel Rudinger"],"pdf_url":"https://arxiv.org/pdf/2410.16451v1.pdf","comment":"Accepted to EMNLP 2024"},{"id":"http://arxiv.org/abs/2410.16443v1","updated":"2024-10-21T19:12:33Z","published":"2024-10-21T19:12:33Z","title":"Improving Neuron-level Interpretability with White-box Language Models","summary":"  Neurons in auto-regressive language models like GPT-2 can be interpreted by\nanalyzing their activation patterns. Recent studies have shown that techniques\nsuch as dictionary learning, a form of post-hoc sparse coding, enhance this\nneuron-level interpretability. In our research, we are driven by the goal to\nfundamentally improve neural network interpretability by embedding sparse\ncoding directly within the model architecture, rather than applying it as an\nafterthought. In our study, we introduce a white-box transformer-like\narchitecture named Coding RAte TransformEr (CRATE), explicitly engineered to\ncapture sparse, low-dimensional structures within data distributions. Our\ncomprehensive experiments showcase significant improvements (up to 103%\nrelative improvement) in neuron-level interpretability across a variety of\nevaluation metrics. Detailed investigations confirm that this enhanced\ninterpretability is steady across different layers irrespective of the model\nsize, underlining CRATE's robust performance in enhancing neural network\ninterpretability. Further analysis shows that CRATE's increased\ninterpretability comes from its enhanced ability to consistently and\ndistinctively activate on relevant tokens. These findings point towards a\npromising direction for creating white-box foundation models that excel in\nneuron-level interpretation.\n","authors":["Hao Bai","Yi Ma"],"pdf_url":"https://arxiv.org/pdf/2410.16443v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.16407v1","updated":"2024-10-21T18:19:09Z","published":"2024-10-21T18:19:09Z","title":"Enhancing Multimodal Affective Analysis with Learned Live Comment\n  Features","summary":"  Live comments, also known as Danmaku, are user-generated messages that are\nsynchronized with video content. These comments overlay directly onto streaming\nvideos, capturing viewer emotions and reactions in real-time. While prior work\nhas leveraged live comments in affective analysis, its use has been limited due\nto the relative rarity of live comments across different video platforms. To\naddress this, we first construct the Live Comment for Affective Analysis\n(LCAffect) dataset which contains live comments for English and Chinese videos\nspanning diverse genres that elicit a wide spectrum of emotions. Then, using\nthis dataset, we use contrastive learning to train a video encoder to produce\nsynthetic live comment features for enhanced multimodal affective content\nanalysis. Through comprehensive experimentation on a wide range of affective\nanalysis tasks (sentiment, emotion recognition, and sarcasm detection) in both\nEnglish and Chinese, we demonstrate that these synthetic live comment features\nsignificantly improve performance over state-of-the-art methods.\n","authors":["Zhaoyuan Deng","Amith Ananthram","Kathleen McKeown"],"pdf_url":"https://arxiv.org/pdf/2410.16407v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2405.19261v2","updated":"2024-10-21T18:12:44Z","published":"2024-05-29T16:55:08Z","title":"Faster Cascades via Speculative Decoding","summary":"  Cascades and speculative decoding are two common approaches to improving\nlanguage models' inference efficiency. Both approaches involve interleaving\nmodels of different sizes, but via fundamentally distinct mechanisms: cascades\nemploy a deferral rule that invokes the larger model only for \"hard\" inputs,\nwhile speculative decoding uses speculative execution to primarily invoke the\nlarger model in parallel verification mode. These mechanisms offer different\nbenefits: empirically, cascades offer better cost-quality trade-offs, often\neven outperforming the large model, while theoretically, speculative decoding\noffers a guarantee of quality-neutrality. In this paper, we leverage the best\nof both these approaches by designing new speculative cascading techniques that\nimplement their deferral rule through speculative execution. We characterize\nthe optimal deferral rule for our speculative cascades, and employ a plug-in\napproximation to the optimal rule. Experiments with Gemma and T5 models on a\nrange of language benchmarks show that our approach yields better cost quality\ntrade-offs than cascading and speculative decoding baselines.\n","authors":["Harikrishna Narasimhan","Wittawat Jitkrittum","Ankit Singh Rawat","Seungyeon Kim","Neha Gupta","Aditya Krishna Menon","Sanjiv Kumar"],"pdf_url":"https://arxiv.org/pdf/2405.19261v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.16400v1","updated":"2024-10-21T18:10:26Z","published":"2024-10-21T18:10:26Z","title":"VipAct: Visual-Perception Enhancement via Specialized VLM Agent\n  Collaboration and Tool-use","summary":"  While vision-language models (VLMs) have demonstrated remarkable performance\nacross various tasks combining textual and visual information, they continue to\nstruggle with fine-grained visual perception tasks that require detailed\npixel-level analysis. Effectively eliciting comprehensive reasoning from VLMs\non such intricate visual elements remains an open challenge. In this paper, we\npresent VipAct, an agent framework that enhances VLMs by integrating\nmulti-agent collaboration and vision expert models, enabling more precise\nvisual understanding and comprehensive reasoning. VipAct consists of an\norchestrator agent, which manages task requirement analysis, planning, and\ncoordination, along with specialized agents that handle specific tasks such as\nimage captioning and vision expert models that provide high-precision\nperceptual information. This multi-agent approach allows VLMs to better perform\nfine-grained visual perception tasks by synergizing planning, reasoning, and\ntool use. We evaluate VipAct on benchmarks featuring a diverse set of visual\nperception tasks, with experimental results demonstrating significant\nperformance improvements over state-of-the-art baselines across all tasks.\nFurthermore, comprehensive ablation studies reveal the critical role of\nmulti-agent collaboration in eliciting more detailed System-2 reasoning and\nhighlight the importance of image input for task planning. Additionally, our\nerror analysis identifies patterns of VLMs' inherent limitations in visual\nperception, providing insights into potential future improvements. VipAct\noffers a flexible and extensible framework, paving the way for more advanced\nvisual perception systems across various real-world applications.\n","authors":["Zhehao Zhang","Ryan Rossi","Tong Yu","Franck Dernoncourt","Ruiyi Zhang","Jiuxiang Gu","Sungchul Kim","Xiang Chen","Zichao Wang","Nedim Lipka"],"pdf_url":"https://arxiv.org/pdf/2410.16400v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.16392v1","updated":"2024-10-21T18:06:25Z","published":"2024-10-21T18:06:25Z","title":"LLM-based Optimization of Compound AI Systems: A Survey","summary":"  In a compound AI system, components such as an LLM call, a retriever, a code\ninterpreter, or tools are interconnected. The system's behavior is primarily\ndriven by parameters such as instructions or tool definitions. Recent\nadvancements enable end-to-end optimization of these parameters using an LLM.\nNotably, leveraging an LLM as an optimizer is particularly efficient because it\navoids gradient computation and can generate complex code and instructions.\nThis paper presents a survey of the principles and emerging trends in LLM-based\noptimization of compound AI systems. It covers archetypes of compound AI\nsystems, approaches to LLM-based end-to-end optimization, and insights into\nfuture directions and broader impacts. Importantly, this survey uses concepts\nfrom program analysis to provide a unified view of how an LLM optimizer is\nprompted to optimize a compound AI system. The exhaustive list of paper is\nprovided at\nhttps://github.com/linyuhongg/LLM-based-Optimization-of-Compound-AI-Systems.\n","authors":["Matthieu Lin","Jenny Sheng","Andrew Zhao","Shenzhi Wang","Yang Yue","Yiran Wu","Huan Liu","Jun Liu","Gao Huang","Yong-Jin Liu"],"pdf_url":"https://arxiv.org/pdf/2410.16392v1.pdf","comment":null}],"Computer Vision and Pattern Recognition":[{"id":"http://arxiv.org/abs/2410.14445v2","updated":"2024-10-21T01:45:47Z","published":"2024-10-18T13:04:35Z","title":"Toward Generalizing Visual Brain Decoding to Unseen Subjects","summary":"  Visual brain decoding aims to decode visual information from human brain\nactivities. Despite the great progress, one critical limitation of current\nbrain decoding research lies in the lack of generalization capability to unseen\nsubjects. Prior works typically focus on decoding brain activity of individuals\nbased on the observation that different subjects exhibit different brain\nactivities, while it remains unclear whether brain decoding can be generalized\nto unseen subjects. This study aims to answer this question. We first\nconsolidate an image-fMRI dataset consisting of stimulus-image and\nfMRI-response pairs, involving 177 subjects in the movie-viewing task of the\nHuman Connectome Project (HCP). This dataset allows us to investigate the brain\ndecoding performance with the increase of participants. We then present a\nlearning paradigm that applies uniform processing across all subjects, instead\nof employing different network heads or tokenizers for individuals as in\nprevious methods, which can accommodate a large number of subjects to explore\nthe generalization capability across different subjects. A series of\nexperiments are conducted and we have the following findings. First, the\nnetwork exhibits clear generalization capabilities with the increase of\ntraining subjects. Second, the generalization capability is common to popular\nnetwork architectures (MLP, CNN and Transformer). Third, the generalization\nperformance is affected by the similarity between subjects. Our findings reveal\nthe inherent similarities in brain activities across individuals. With the\nemerging of larger and more comprehensive datasets, it is possible to train a\nbrain decoding foundation model in the future. Codes and models can be found at\nhttps://github.com/Xiangtaokong/TGBD.\n","authors":["Xiangtao Kong","Kexin Huang","Ping Li","Lei Zhang"],"pdf_url":"https://arxiv.org/pdf/2410.14445v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.16271v1","updated":"2024-10-21T17:59:53Z","published":"2024-10-21T17:59:53Z","title":"FrugalNeRF: Fast Convergence for Few-shot Novel View Synthesis without\n  Learned Priors","summary":"  Neural Radiance Fields (NeRF) face significant challenges in few-shot\nscenarios, primarily due to overfitting and long training times for\nhigh-fidelity rendering. Existing methods, such as FreeNeRF and SparseNeRF, use\nfrequency regularization or pre-trained priors but struggle with complex\nscheduling and bias. We introduce FrugalNeRF, a novel few-shot NeRF framework\nthat leverages weight-sharing voxels across multiple scales to efficiently\nrepresent scene details. Our key contribution is a cross-scale geometric\nadaptation scheme that selects pseudo ground truth depth based on reprojection\nerrors across scales. This guides training without relying on externally\nlearned priors, enabling full utilization of the training data. It can also\nintegrate pre-trained priors, enhancing quality without slowing convergence.\nExperiments on LLFF, DTU, and RealEstate-10K show that FrugalNeRF outperforms\nother few-shot NeRF methods while significantly reducing training time, making\nit a practical solution for efficient and accurate 3D scene reconstruction.\n","authors":["Chin-Yang Lin","Chung-Ho Wu","Chang-Han Yeh","Shih-Han Yen","Cheng Sun","Yu-Lun Liu"],"pdf_url":"https://arxiv.org/pdf/2410.16271v1.pdf","comment":"Project page: https://linjohnss.github.io/frugalnerf/"},{"id":"http://arxiv.org/abs/2410.16272v1","updated":"2024-10-21T17:59:53Z","published":"2024-10-21T17:59:53Z","title":"MvDrag3D: Drag-based Creative 3D Editing via Multi-view\n  Generation-Reconstruction Priors","summary":"  Drag-based editing has become popular in 2D content creation, driven by the\ncapabilities of image generative models. However, extending this technique to\n3D remains a challenge. Existing 3D drag-based editing methods, whether\nemploying explicit spatial transformations or relying on implicit latent\noptimization within limited-capacity 3D generative models, fall short in\nhandling significant topology changes or generating new textures across diverse\nobject categories. To overcome these limitations, we introduce MVDrag3D, a\nnovel framework for more flexible and creative drag-based 3D editing that\nleverages multi-view generation and reconstruction priors. At the core of our\napproach is the usage of a multi-view diffusion model as a strong generative\nprior to perform consistent drag editing over multiple rendered views, which is\nfollowed by a reconstruction model that reconstructs 3D Gaussians of the edited\nobject. While the initial 3D Gaussians may suffer from misalignment between\ndifferent views, we address this via view-specific deformation networks that\nadjust the position of Gaussians to be well aligned. In addition, we propose a\nmulti-view score function that distills generative priors from multiple views\nto further enhance the view consistency and visual quality. Extensive\nexperiments demonstrate that MVDrag3D provides a precise, generative, and\nflexible solution for 3D drag-based editing, supporting more versatile editing\neffects across various object categories and 3D representations.\n","authors":["Honghua Chen","Yushi Lan","Yongwei Chen","Yifan Zhou","Xingang Pan"],"pdf_url":"https://arxiv.org/pdf/2410.16272v1.pdf","comment":"16 pages, 10 figures, conference"},{"id":"http://arxiv.org/abs/2410.16268v1","updated":"2024-10-21T17:59:19Z","published":"2024-10-21T17:59:19Z","title":"SAM2Long: Enhancing SAM 2 for Long Video Segmentation with a\n  Training-Free Memory Tree","summary":"  The Segment Anything Model 2 (SAM 2) has emerged as a powerful foundation\nmodel for object segmentation in both images and videos, paving the way for\nvarious downstream video applications. The crucial design of SAM 2 for video\nsegmentation is its memory module, which prompts object-aware memories from\nprevious frames for current frame prediction. However, its greedy-selection\nmemory design suffers from the \"error accumulation\" problem, where an errored\nor missed mask will cascade and influence the segmentation of the subsequent\nframes, which limits the performance of SAM 2 toward complex long-term videos.\nTo this end, we introduce SAM2Long, an improved training-free video object\nsegmentation strategy, which considers the segmentation uncertainty within each\nframe and chooses the video-level optimal results from multiple segmentation\npathways in a constrained tree search manner. In practice, we maintain a fixed\nnumber of segmentation pathways throughout the video. For each frame, multiple\nmasks are proposed based on the existing pathways, creating various candidate\nbranches. We then select the same fixed number of branches with higher\ncumulative scores as the new pathways for the next frame. After processing the\nfinal frame, the pathway with the highest cumulative score is chosen as the\nfinal segmentation result. Benefiting from its heuristic search design,\nSAM2Long is robust toward occlusions and object reappearances, and can\neffectively segment and track objects for complex long-term videos. Notably,\nSAM2Long achieves an average improvement of 3.0 points across all 24\nhead-to-head comparisons, with gains of up to 5.3 points in J&F on long-term\nvideo object segmentation benchmarks such as SA-V and LVOS. The code is\nreleased at https://github.com/Mark12Ding/SAM2Long.\n","authors":["Shuangrui Ding","Rui Qian","Xiaoyi Dong","Pan Zhang","Yuhang Zang","Yuhang Cao","Yuwei Guo","Dahua Lin","Jiaqi Wang"],"pdf_url":"https://arxiv.org/pdf/2410.16268v1.pdf","comment":"Project page: https://mark12ding.github.io/project/SAM2Long/"},{"id":"http://arxiv.org/abs/2410.16267v1","updated":"2024-10-21T17:59:11Z","published":"2024-10-21T17:59:11Z","title":"xGen-MM-Vid (BLIP-3-Video): You Only Need 32 Tokens to Represent a Video\n  Even in VLMs","summary":"  We present xGen-MM-Vid (BLIP-3-Video): a multimodal language model for\nvideos, particularly designed to efficiently capture temporal information over\nmultiple frames. BLIP-3-Video takes advantage of the 'temporal encoder' in\naddition to the conventional visual tokenizer, which maps a sequence of tokens\nover multiple frames into a compact set of visual tokens. This enables\nBLIP3-Video to use much fewer visual tokens than its competing models (e.g., 32\nvs. 4608 tokens). We explore different types of temporal encoders, including\nlearnable spatio-temporal pooling as well as sequential models like Token\nTuring Machines. We experimentally confirm that BLIP-3-Video obtains video\nquestion-answering accuracies comparable to much larger state-of-the-art models\n(e.g., 34B), while being much smaller (i.e., 4B) and more efficient by using\nfewer visual tokens. The project website is at\nhttps://www.salesforceairesearch.com/opensource/xGen-MM-Vid/index.html\n","authors":["Michael S. Ryoo","Honglu Zhou","Shrikant Kendre","Can Qin","Le Xue","Manli Shu","Silvio Savarese","Ran Xu","Caiming Xiong","Juan Carlos Niebles"],"pdf_url":"https://arxiv.org/pdf/2410.16267v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.16266v1","updated":"2024-10-21T17:59:09Z","published":"2024-10-21T17:59:09Z","title":"3DGS-Enhancer: Enhancing Unbounded 3D Gaussian Splatting with\n  View-consistent 2D Diffusion Priors","summary":"  Novel-view synthesis aims to generate novel views of a scene from multiple\ninput images or videos, and recent advancements like 3D Gaussian splatting\n(3DGS) have achieved notable success in producing photorealistic renderings\nwith efficient pipelines. However, generating high-quality novel views under\nchallenging settings, such as sparse input views, remains difficult due to\ninsufficient information in under-sampled areas, often resulting in noticeable\nartifacts. This paper presents 3DGS-Enhancer, a novel pipeline for enhancing\nthe representation quality of 3DGS representations. We leverage 2D video\ndiffusion priors to address the challenging 3D view consistency problem,\nreformulating it as achieving temporal consistency within a video generation\nprocess. 3DGS-Enhancer restores view-consistent latent features of rendered\nnovel views and integrates them with the input views through a spatial-temporal\ndecoder. The enhanced views are then used to fine-tune the initial 3DGS model,\nsignificantly improving its rendering performance. Extensive experiments on\nlarge-scale datasets of unbounded scenes demonstrate that 3DGS-Enhancer yields\nsuperior reconstruction performance and high-fidelity rendering results\ncompared to state-of-the-art methods. The project webpage is\nhttps://xiliu8006.github.io/3DGS-Enhancer-project .\n","authors":["Xi Liu","Chaoyi Zhou","Siyu Huang"],"pdf_url":"https://arxiv.org/pdf/2410.16266v1.pdf","comment":"Accepted by NeurIPS 2024 Spotlight"},{"id":"http://arxiv.org/abs/2410.16261v1","updated":"2024-10-21T17:58:20Z","published":"2024-10-21T17:58:20Z","title":"Mini-InternVL: A Flexible-Transfer Pocket Multimodal Model with 5%\n  Parameters and 90% Performance","summary":"  Multimodal large language models (MLLMs) have demonstrated impressive\nperformance in vision-language tasks across a broad spectrum of domains.\nHowever, the large model scale and associated high computational costs pose\nsignificant challenges for training and deploying MLLMs on consumer-grade GPUs\nor edge devices, thereby hindering their widespread application. In this work,\nwe introduce Mini-InternVL, a series of MLLMs with parameters ranging from 1B\nto 4B, which achieves 90% of the performance with only 5% of the parameters.\nThis significant improvement in efficiency and effectiveness makes our models\nmore accessible and applicable in various real-world scenarios. To further\npromote the adoption of our models, we develop a unified adaptation framework\nfor Mini-InternVL, which enables our models to transfer and outperform\nspecialized models in downstream tasks, including autonomous driving, medical\nimages, and remote sensing. We believe that our study can provide valuable\ninsights and resources to advance the development of efficient and effective\nMLLMs. Code is available at https://github.com/OpenGVLab/InternVL.\n","authors":["Zhangwei Gao","Zhe Chen","Erfei Cui","Yiming Ren","Weiyun Wang","Jinguo Zhu","Hao Tian","Shenglong Ye","Junjun He","Xizhou Zhu","Lewei Lu","Tong Lu","Yu Qiao","Jifeng Dai","Wenhai Wang"],"pdf_url":"https://arxiv.org/pdf/2410.16261v1.pdf","comment":"Technical report"},{"id":"http://arxiv.org/abs/2410.16259v1","updated":"2024-10-21T17:57:50Z","published":"2024-10-21T17:57:50Z","title":"Agent-to-Sim: Learning Interactive Behavior Models from Casual\n  Longitudinal Videos","summary":"  We present Agent-to-Sim (ATS), a framework for learning interactive behavior\nmodels of 3D agents from casual longitudinal video collections. Different from\nprior works that rely on marker-based tracking and multiview cameras, ATS\nlearns natural behaviors of animal and human agents non-invasively through\nvideo observations recorded over a long time-span (e.g., a month) in a single\nenvironment. Modeling 3D behavior of an agent requires persistent 3D tracking\n(e.g., knowing which point corresponds to which) over a long time period. To\nobtain such data, we develop a coarse-to-fine registration method that tracks\nthe agent and the camera over time through a canonical 3D space, resulting in a\ncomplete and persistent spacetime 4D representation. We then train a generative\nmodel of agent behaviors using paired data of perception and motion of an agent\nqueried from the 4D reconstruction. ATS enables real-to-sim transfer from video\nrecordings of an agent to an interactive behavior simulator. We demonstrate\nresults on pets (e.g., cat, dog, bunny) and human given monocular RGBD videos\ncaptured by a smartphone.\n","authors":["Gengshan Yang","Andrea Bajcsy","Shunsuke Saito","Angjoo Kanazawa"],"pdf_url":"https://arxiv.org/pdf/2410.16259v1.pdf","comment":"Project page: https://gengshan-y.github.io/agent2sim-www/"},{"id":"http://arxiv.org/abs/2410.16257v1","updated":"2024-10-21T17:57:04Z","published":"2024-10-21T17:57:04Z","title":"Elucidating the design space of language models for image generation","summary":"  The success of autoregressive (AR) language models in text generation has\ninspired the computer vision community to adopt Large Language Models (LLMs)\nfor image generation. However, considering the essential differences between\ntext and image modalities, the design space of language models for image\ngeneration remains underexplored. We observe that image tokens exhibit greater\nrandomness compared to text tokens, which presents challenges when training\nwith token prediction. Nevertheless, AR models demonstrate their potential by\neffectively learning patterns even from a seemingly suboptimal optimization\nproblem. Our analysis also reveals that while all models successfully grasp the\nimportance of local information in image generation, smaller models struggle to\ncapture the global context. In contrast, larger models showcase improved\ncapabilities in this area, helping to explain the performance gains achieved\nwhen scaling up model size. We further elucidate the design space of language\nmodels for vision generation, including tokenizer choice, model choice, model\nscalability, vocabulary design, and sampling strategy through extensive\ncomparative experiments. Our work is the first to analyze the optimization\nbehavior of language models in vision generation, and we believe it can inspire\nmore effective designs when applying LMs to other domains. Finally, our\nelucidated language model for image generation, termed as ELM, achieves\nstate-of-the-art performance on the ImageNet 256*256 benchmark. The code is\navailable at https://github.com/Pepperlll/LMforImageGeneration.git.\n","authors":["Xuantong Liu","Shaozhe Hao","Xianbiao Qi","Tianyang Hu","Jun Wang","Rong Xiao","Yuan Yao"],"pdf_url":"https://arxiv.org/pdf/2410.16257v1.pdf","comment":"Project page: https://pepper-lll.github.io/LMforImageGeneration/"},{"id":"http://arxiv.org/abs/2410.16255v1","updated":"2024-10-21T17:56:47Z","published":"2024-10-21T17:56:47Z","title":"Revisiting Deep Feature Reconstruction for Logical and Structural\n  Industrial Anomaly Detection","summary":"  Industrial anomaly detection is crucial for quality control and predictive\nmaintenance, but it presents challenges due to limited training data, diverse\nanomaly types, and external factors that alter object appearances. Existing\nmethods commonly detect structural anomalies, such as dents and scratches, by\nleveraging multi-scale features from image patches extracted through deep\npre-trained networks. However, significant memory and computational demands\noften limit their practical application. Additionally, detecting logical\nanomalies-such as images with missing or excess elements-requires an\nunderstanding of spatial relationships that traditional patch-based methods\nfail to capture. In this work, we address these limitations by focusing on Deep\nFeature Reconstruction (DFR), a memory- and compute-efficient approach for\ndetecting structural anomalies. We further enhance DFR into a unified\nframework, called ULSAD, which is capable of detecting both structural and\nlogical anomalies. Specifically, we refine the DFR training objective to\nimprove performance in structural anomaly detection, while introducing an\nattention-based loss mechanism using a global autoencoder-like network to\nhandle logical anomaly detection. Our empirical evaluation across five\nbenchmark datasets demonstrates the performance of ULSAD in detecting and\nlocalizing both structural and logical anomalies, outperforming eight\nstate-of-the-art methods. An extensive ablation study further highlights the\ncontribution of each component to the overall performance improvement. Our code\nis available at https://github.com/sukanyapatra1997/ULSAD-2024.git\n","authors":["Sukanya Patra","Souhaib Ben Taieb"],"pdf_url":"https://arxiv.org/pdf/2410.16255v1.pdf","comment":"Accepted in Transactions on Machine Learning Research (TMLR). Link to\n  OpenReview: https://openreview.net/forum?id=kdTC4ktHPD"},{"id":"http://arxiv.org/abs/2410.16239v1","updated":"2024-10-21T17:42:41Z","published":"2024-10-21T17:42:41Z","title":"MoRE: Multi-Modal Contrastive Pre-training with Transformers on X-Rays,\n  ECGs, and Diagnostic Report","summary":"  In this paper, we introduce a novel Multi-Modal Contrastive Pre-training\nFramework that synergistically combines X-rays, electrocardiograms (ECGs), and\nradiology/cardiology reports. Our approach leverages transformers to encode\nthese diverse modalities into a unified representation space, aiming to enhance\ndiagnostic accuracy and facilitate comprehensive patient assessments. We\nutilize LoRA-Peft to significantly reduce trainable parameters in the LLM and\nincorporate recent linear attention dropping strategy in the Vision\nTransformer(ViT) for smoother attention. Furthermore, we provide novel\nmultimodal attention explanations and retrieval for our model. To the best of\nour knowledge, we are the first to propose an integrated model that combines\nX-ray, ECG, and Radiology/Cardiology Report with this approach. By utilizing\ncontrastive loss, MoRE effectively aligns modality-specific features into a\ncoherent embedding, which supports various downstream tasks such as zero-shot\nclassification and multimodal retrieval. Employing our proposed methodology, we\nachieve state-of-the-art (SOTA) on the Mimic-IV, CheXpert, Edema Severity, and\nPtbXl downstream datasets, surpassing existing multimodal approaches. Our\nproposed framework shows significant improvements in capturing intricate\ninter-modal relationships and its robustness in medical diagnosis that\nestablishes a framework for future research in multimodal learning in the\nhealthcare sector.\n","authors":["Samrajya Thapa","Koushik Howlader","Subhankar Bhattacharjee","Wei le"],"pdf_url":"https://arxiv.org/pdf/2410.16239v1.pdf","comment":"10 pages, 5 figures, 9 tables. Supplementary detail in Appendix. Code\n  made available in Github for reproducibility"},{"id":"http://arxiv.org/abs/2410.16238v1","updated":"2024-10-21T17:41:58Z","published":"2024-10-21T17:41:58Z","title":"Deep Radiomics Detection of Clinically Significant Prostate Cancer on\n  Multicenter MRI: Initial Comparison to PI-RADS Assessment","summary":"  Objective: To develop and evaluate a deep radiomics model for clinically\nsignificant prostate cancer (csPCa, grade group >= 2) detection and compare its\nperformance to Prostate Imaging Reporting and Data System (PI-RADS) assessment\nin a multicenter cohort. Materials and Methods: This retrospective study\nanalyzed biparametric (T2W and DW) prostate MRI sequences of 615 patients (mean\nage, 63.1 +/- 7 years) from four datasets acquired between 2010 and 2020:\nPROSTATEx challenge, Prostate158 challenge, PCaMAP trial, and an in-house\n(NTNU/St. Olavs Hospital) dataset. With expert annotations as ground truth, a\ndeep radiomics model was trained, including nnU-Net segmentation of the\nprostate gland, voxel-wise radiomic feature extraction, extreme gradient boost\nclassification, and post-processing of tumor probability maps into csPCa\ndetection maps. Training involved 5-fold cross-validation using the PROSTATEx\n(n=199), Prostate158 (n=138), and PCaMAP (n=78) datasets, and testing on the\nin-house (n=200) dataset. Patient- and lesion-level performance were compared\nto PI-RADS using area under ROC curve (AUROC [95% CI]), sensitivity, and\nspecificity analysis. Results: On the test data, the radiologist achieved a\npatient-level AUROC of 0.94 [0.91-0.98] with 94% (75/80) sensitivity and 77%\n(92/120) specificity at PI-RADS >= 3. The deep radiomics model at a tumor\nprobability cut-off >= 0.76 achieved 0.91 [0.86-0.95] AUROC with 90% (72/80)\nsensitivity and 73% (87/120) specificity, not significantly different (p =\n0.068) from PI-RADS. On the lesion level, PI-RADS cut-off >= 3 had 84% (91/108)\nsensitivity at 0.2 (40/200) false positives per patient, while deep radiomics\nattained 68% (73/108) sensitivity at the same false positive rate. Conclusion:\nDeep radiomics machine learning model achieved comparable performance to\nPI-RADS assessment in csPCa detection at the patient-level but not at the\nlesion-level.\n","authors":["G. A. Nketiah","M. R. Sunoqrot","E. Sandsmark","S. Langørgen","K. M. Selnæs","H. Bertilsson","M. Elschot","T. F. Bathen"],"pdf_url":"https://arxiv.org/pdf/2410.16238v1.pdf","comment":"20 pages, 4 figures, 4 tables"},{"id":"http://arxiv.org/abs/2410.16236v1","updated":"2024-10-21T17:41:28Z","published":"2024-10-21T17:41:28Z","title":"LLaVA-KD: A Framework of Distilling Multimodal Large Language Models","summary":"  The success of Large Language Models (LLM) has led researchers to explore\nMultimodal Large Language Models (MLLM) for unified visual and linguistic\nunderstanding. However, the increasing model size and computational complexity\nof MLLM limit their use in resource-constrained environments. Small-scale MLLM\n(s-MLLM) aims to retain the capabilities of the large-scale model (l-MLLM)\nwhile reducing computational demands, but resulting in a significant decline in\nperformance. To address the aforementioned issues, we propose a novel LLaVA-KD\nframework to transfer knowledge from l-MLLM to s-MLLM. Specifically, we\nintroduce Multimodal Distillation (MDist) to minimize the divergence between\nthe visual-textual output distributions of l-MLLM and s-MLLM, and Relation\nDistillation (RDist) to transfer l-MLLM's ability to model correlations between\nvisual features. Additionally, we propose a three-stage training scheme to\nfully exploit the potential of s-MLLM: 1) Distilled Pre-Training to align\nvisual-textual representations, 2) Supervised Fine-Tuning to equip the model\nwith multimodal understanding, and 3) Distilled Fine-Tuning to further transfer\nl-MLLM capabilities. Our approach significantly improves performance without\naltering the small model's architecture. Extensive experiments and ablation\nstudies validate the effectiveness of each proposed component. Code will be\navailable at https://github.com/caiyuxuan1120/LLaVA-KD.\n","authors":["Yuxuan Cai","Jiangning Zhang","Haoyang He","Xinwei He","Ao Tong","Zhenye Gan","Chengjie Wang","Xiang Bai"],"pdf_url":"https://arxiv.org/pdf/2410.16236v1.pdf","comment":"Under review"},{"id":"http://arxiv.org/abs/2410.16227v1","updated":"2024-10-21T17:32:36Z","published":"2024-10-21T17:32:36Z","title":"Managing Bandwidth: The Key to Cloud-Assisted Autonomous Driving","summary":"  Prevailing wisdom asserts that one cannot rely on the cloud for critical\nreal-time control systems like self-driving cars. We argue that we can, and\nmust. Following the trends of increasing model sizes, improvements in hardware,\nand evolving mobile networks, we identify an opportunity to offload parts of\ntime-sensitive and latency-critical compute to the cloud. Doing so requires\ncarefully allocating bandwidth to meet strict latency SLOs, while maximizing\nbenefit to the car.\n","authors":["Alexander Krentsel","Peter Schafhalter","Joseph E. Gonzalez","Sylvia Ratnasamy","Scott Shenker","Ion Stoica"],"pdf_url":"https://arxiv.org/pdf/2410.16227v1.pdf","comment":"6 pages"},{"id":"http://arxiv.org/abs/2406.01583v2","updated":"2024-10-21T17:25:44Z","published":"2024-06-03T17:58:43Z","title":"Decomposing and Interpreting Image Representations via Text in ViTs\n  Beyond CLIP","summary":"  Recent work has explored how individual components of the CLIP-ViT model\ncontribute to the final representation by leveraging the shared image-text\nrepresentation space of CLIP. These components, such as attention heads and\nMLPs, have been shown to capture distinct image features like shape, color or\ntexture. However, understanding the role of these components in arbitrary\nvision transformers (ViTs) is challenging. To this end, we introduce a general\nframework which can identify the roles of various components in ViTs beyond\nCLIP. Specifically, we (a) automate the decomposition of the final\nrepresentation into contributions from different model components, and (b)\nlinearly map these contributions to CLIP space to interpret them via text.\nAdditionally, we introduce a novel scoring function to rank components by their\nimportance with respect to specific features. Applying our framework to various\nViT variants (e.g. DeiT, DINO, DINOv2, Swin, MaxViT), we gain insights into the\nroles of different components concerning particular image features. These\ninsights facilitate applications such as image retrieval using text\ndescriptions or reference images, visualizing token importance heatmaps, and\nmitigating spurious correlations. We release our code to reproduce the\nexperiments at https://github.com/SriramB-98/vit-decompose\n","authors":["Sriram Balasubramanian","Samyadeep Basu","Soheil Feizi"],"pdf_url":"https://arxiv.org/pdf/2406.01583v2.pdf","comment":"NeurIPS 2024, 31 pages, 15 figures"},{"id":"http://arxiv.org/abs/2410.16198v1","updated":"2024-10-21T17:00:06Z","published":"2024-10-21T17:00:06Z","title":"Improve Vision Language Model Chain-of-thought Reasoning","summary":"  Chain-of-thought (CoT) reasoning in vision language models (VLMs) is crucial\nfor improving interpretability and trustworthiness. However, current training\nrecipes lack robust CoT reasoning data, relying on datasets dominated by short\nannotations with minimal rationales. In this work, we show that training VLM on\nshort answers does not generalize well to reasoning tasks that require more\ndetailed responses. To address this, we propose a two-fold approach. First, we\ndistill rationales from GPT-4o model to enrich the training data and fine-tune\nVLMs, boosting their CoT performance. Second, we apply reinforcement learning\nto further calibrate reasoning quality. Specifically, we construct positive\n(correct) and negative (incorrect) pairs of model-generated reasoning chains,\nby comparing their predictions with annotated short answers. Using this\npairwise data, we apply the Direct Preference Optimization algorithm to refine\nthe model's reasoning abilities. Our experiments demonstrate significant\nimprovements in CoT reasoning on benchmark datasets and better generalization\nto direct answer prediction as well. This work emphasizes the importance of\nincorporating detailed rationales in training and leveraging reinforcement\nlearning to strengthen the reasoning capabilities of VLMs.\n","authors":["Ruohong Zhang","Bowen Zhang","Yanghao Li","Haotian Zhang","Zhiqing Sun","Zhe Gan","Yinfei Yang","Ruoming Pang","Yiming Yang"],"pdf_url":"https://arxiv.org/pdf/2410.16198v1.pdf","comment":"10 pages + appendix"},{"id":"http://arxiv.org/abs/2410.16190v1","updated":"2024-10-21T16:52:44Z","published":"2024-10-21T16:52:44Z","title":"Training Better Deep Learning Models Using Human Saliency","summary":"  This work explores how human judgement about salient regions of an image can\nbe introduced into deep convolutional neural network (DCNN) training.\nTraditionally, training of DCNNs is purely data-driven. This often results in\nlearning features of the data that are only coincidentally correlated with\nclass labels. Human saliency can guide network training using our proposed new\ncomponent of the loss function that ConveYs Brain Oversight to Raise\nGeneralization (CYBORG) and penalizes the model for using non-salient regions.\nThis mechanism produces DCNNs achieving higher accuracy and generalization\ncompared to using the same training data without human salience. Experimental\nresults demonstrate that CYBORG applies across multiple network architectures\nand problem domains (detection of synthetic faces, iris presentation attacks\nand anomalies in chest X-rays), while requiring significantly less data than\ntraining without human saliency guidance. Visualizations show that\nCYBORG-trained models' saliency is more consistent across independent training\nruns than traditionally-trained models, and also in better agreement with\nhumans. To lower the cost of collecting human annotations, we also explore\nusing deep learning to provide automated annotations. CYBORG training of CNNs\naddresses important issues such as reducing the appetite for large training\nsets, increasing interpretability, and reducing fragility by generalizing\nbetter to new types of data.\n","authors":["Aidan Boyd","Patrick Tinsley","Kevin W. Bowyer","Adam Czajka"],"pdf_url":"https://arxiv.org/pdf/2410.16190v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.16177v1","updated":"2024-10-21T16:43:16Z","published":"2024-10-21T16:43:16Z","title":"A Framework for Evaluating Predictive Models Using Synthetic Image\n  Covariates and Longitudinal Data","summary":"  We present a novel framework for synthesizing patient data with complex\ncovariates (e.g., eye scans) paired with longitudinal observations (e.g.,\nvisual acuity over time), addressing privacy concerns in healthcare research.\nOur approach introduces controlled association in latent spaces generating each\ndata modality, enabling the creation of complex covariate-longitudinal\nobservation pairs. This framework facilitates the development of predictive\nmodels and provides openly available benchmarking datasets for healthcare\nresearch. We demonstrate our framework using optical coherence tomography (OCT)\nscans, though it is applicable across domains. Using 109,309 2D OCT scan\nslices, we trained an image generative model combining a variational\nautoencoder and a diffusion model. Longitudinal observations were simulated\nusing a nonlinear mixed effect (NLME) model from a low-dimensional space of\nrandom effects. We generated 1.1M OCT scan slices paired with five sets of\nlongitudinal observations at controlled association levels (100%, 50%, 10%,\n5.26%, and 2% of between-subject variability). To assess the framework, we\nmodeled synthetic longitudinal observations with another NLME model, computed\nempirical Bayes estimates of random effects, and trained a ResNet to predict\nthese estimates from synthetic OCT scans. We then incorporated ResNet\npredictions into the NLME model for patient-individualized predictions.\nPrediction accuracy on withheld data declined as intended with reduced\nassociation between images and longitudinal measurements. Notably, in all but\nthe 2% case, we achieved within 50% of the theoretical best possible prediction\non withheld data, demonstrating our ability to detect even weak signals. This\nconfirms the effectiveness of our framework in generating synthetic data with\ncontrolled levels of association, providing a valuable tool for healthcare\nresearch.\n","authors":["Simon Deltadahl","Andreu Vall","Vijay Ivaturi","Niklas Korsbo"],"pdf_url":"https://arxiv.org/pdf/2410.16177v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.16166v1","updated":"2024-10-21T16:32:41Z","published":"2024-10-21T16:32:41Z","title":"Beyond Filtering: Adaptive Image-Text Quality Enhancement for MLLM\n  Pretraining","summary":"  Multimodal large language models (MLLMs) have made significant strides by\nintegrating visual and textual modalities. A critical factor in training MLLMs\nis the quality of image-text pairs within multimodal pretraining datasets.\nHowever, $\\textit {de facto}$ filter-based data quality enhancement paradigms\noften discard a substantial portion of high-quality image data due to\ninadequate semantic alignment between images and texts, leading to\ninefficiencies in data utilization and scalability. In this paper, we propose\nthe Adaptive Image-Text Quality Enhancer (AITQE), a model that dynamically\nassesses and enhances the quality of image-text pairs. AITQE employs a text\nrewriting mechanism for low-quality pairs and incorporates a negative sample\nlearning strategy to improve evaluative capabilities by integrating\ndeliberately selected low-quality samples during training. Unlike prior\napproaches that significantly alter text distributions, our method minimally\nadjusts text to preserve data volume while enhancing quality. Experimental\nresults demonstrate that AITQE surpasses existing methods on various benchmark,\neffectively leveraging raw data and scaling efficiently with increasing data\nvolumes. We hope our work will inspire future works. The code and model are\navailable at: https://github.com/hanhuang22/AITQE.\n","authors":["Han Huang","Yuqi Huo","Zijia Zhao","Haoyu Lu","Shu Wu","Bingning Wang","Qiang Liu","Weipeng Chen","Liang Wang"],"pdf_url":"https://arxiv.org/pdf/2410.16166v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.16163v1","updated":"2024-10-21T16:30:29Z","published":"2024-10-21T16:30:29Z","title":"Griffon-G: Bridging Vision-Language and Vision-Centric Tasks via Large\n  Multimodal Models","summary":"  Large Multimodal Models (LMMs) have achieved significant breakthroughs in\nvarious vision-language and vision-centric tasks based on auto-regressive\nmodeling. However, these models typically focus on either vision-centric tasks,\nsuch as visual grounding and region description, or vision-language tasks, like\nimage caption and multi-scenario VQAs. None of the LMMs have yet\ncomprehensively unified both types of tasks within a single model, as seen in\nLarge Language Models in the natural language processing field. Furthermore,\neven with abundant multi-task instruction-following data, directly stacking\nthese data for universal capabilities extension remains challenging. To address\nthese issues, we introduce a novel multi-dimension curated and consolidated\nmultimodal dataset, named CCMD-8M, which overcomes the data barriers of\nunifying vision-centric and vision-language tasks through multi-level data\ncuration and multi-task consolidation. More importantly, we present Griffon-G,\na general large multimodal model that addresses both vision-centric and\nvision-language tasks within a single end-to-end paradigm. Griffon-G resolves\nthe training collapse issue encountered during the joint optimization of these\ntasks, achieving better training efficiency. Evaluations across multimodal\nbenchmarks, general Visual Question Answering (VQA) tasks, scene text-centric\nVQA tasks, document-related VQA tasks, Referring Expression Comprehension, and\nobject detection demonstrate that Griffon-G surpasses the advanced LMMs and\nachieves expert-level performance in complicated vision-centric tasks.\n","authors":["Yufei Zhan","Hongyin Zhao","Yousong Zhu","Fan Yang","Ming Tang","Jinqiao Wang"],"pdf_url":"https://arxiv.org/pdf/2410.16163v1.pdf","comment":"This work has been submitted to the IEEE for possible publication.\n  Codes and data will be later released at\n  https://github.com/jefferyZhan/Griffon"},{"id":"http://arxiv.org/abs/2410.16162v1","updated":"2024-10-21T16:26:09Z","published":"2024-10-21T16:26:09Z","title":"Sparkle: Mastering Basic Spatial Capabilities in Vision Language Models\n  Elicits Generalization to Composite Spatial Reasoning","summary":"  Vision language models (VLMs) have demonstrated impressive performance across\na wide range of downstream tasks. However, their proficiency in spatial\nreasoning remains limited, despite its crucial role in tasks involving\nnavigation and interaction with physical environments. Specifically, much of\nthe spatial reasoning in these tasks occurs in two-dimensional (2D)\nenvironments, and our evaluation reveals that state-of-the-art VLMs frequently\ngenerate implausible and incorrect responses to composite spatial reasoning\nproblems, including simple pathfinding tasks that humans can solve effortlessly\nat a glance. To address this, we explore an effective approach to enhance 2D\nspatial reasoning within VLMs by training the model on basic spatial\ncapabilities. We begin by disentangling the key components of 2D spatial\nreasoning: direction comprehension, distance estimation, and localization. Our\ncentral hypothesis is that mastering these basic spatial capabilities can\nsignificantly enhance a model's performance on composite spatial tasks\nrequiring advanced spatial understanding and combinatorial problem-solving. To\ninvestigate this hypothesis, we introduce Sparkle, a framework that fine-tunes\nVLMs on these three basic spatial capabilities by synthetic data generation and\ntargeted supervision to form an instruction dataset for each capability. Our\nexperiments demonstrate that VLMs fine-tuned with Sparkle achieve significant\nperformance gains, not only in the basic tasks themselves but also in\ngeneralizing to composite and out-of-distribution spatial reasoning tasks\n(e.g., improving from 13.5% to 40.0% on the shortest path problem). These\nfindings underscore the effectiveness of mastering basic spatial capabilities\nin enhancing composite spatial problem-solving, offering insights for improving\nVLMs' spatial reasoning capabilities.\n","authors":["Yihong Tang","Ao Qu","Zhaokai Wang","Dingyi Zhuang","Zhaofeng Wu","Wei Ma","Shenhao Wang","Yunhan Zheng","Zhan Zhao","Jinhua Zhao"],"pdf_url":"https://arxiv.org/pdf/2410.16162v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.16159v1","updated":"2024-10-21T16:22:19Z","published":"2024-10-21T16:22:19Z","title":"Metric as Transform: Exploring beyond Affine Transform for Interpretable\n  Neural Network","summary":"  Artificial Neural Networks of varying architectures are generally paired with\naffine transformation at the core. However, we find dot product neurons with\nglobal influence less interpretable as compared to local influence of euclidean\ndistance (as used in Radial Basis Function Network). In this work, we explore\nthe generalization of dot product neurons to $l^p$-norm, metrics, and beyond.\nWe find that metrics as transform performs similarly to affine transform when\nused in MultiLayer Perceptron or Convolutional Neural Network. Moreover, we\nexplore various properties of Metrics, compare it with Affine, and present\nmultiple cases where metrics seem to provide better interpretability. We\ndevelop an interpretable local dictionary based Neural Networks and use it to\nunderstand and reject adversarial examples.\n","authors":["Suman Sapkota"],"pdf_url":"https://arxiv.org/pdf/2410.16159v1.pdf","comment":"22 pages, 20 figures, 3 tables"},{"id":"http://arxiv.org/abs/2410.16153v1","updated":"2024-10-21T16:19:41Z","published":"2024-10-21T16:19:41Z","title":"Pangea: A Fully Open Multilingual Multimodal LLM for 39 Languages","summary":"  Despite recent advances in multimodal large language models (MLLMs), their\ndevelopment has predominantly focused on English- and western-centric datasets\nand tasks, leaving most of the world's languages and diverse cultural contexts\nunderrepresented. This paper introduces Pangea, a multilingual multimodal LLM\ntrained on PangeaIns, a diverse 6M instruction dataset spanning 39 languages.\nPangeaIns features: 1) high-quality English instructions, 2) carefully\nmachine-translated instructions, and 3) culturally relevant multimodal tasks to\nensure cross-cultural coverage. To rigorously assess models' capabilities, we\nintroduce PangeaBench, a holistic evaluation suite encompassing 14 datasets\ncovering 47 languages. Results show that Pangea significantly outperforms\nexisting open-source models in multilingual settings and diverse cultural\ncontexts. Ablation studies further reveal the importance of English data\nproportions, language popularity, and the number of multimodal training samples\non overall performance. We fully open-source our data, code, and trained\ncheckpoints, to facilitate the development of inclusive and robust multilingual\nMLLMs, promoting equity and accessibility across a broader linguistic and\ncultural spectrum.\n","authors":["Xiang Yue","Yueqi Song","Akari Asai","Seungone Kim","Jean de Dieu Nyandwi","Simran Khanuja","Anjali Kantharuban","Lintang Sutawika","Sathyanarayanan Ramamoorthy","Graham Neubig"],"pdf_url":"https://arxiv.org/pdf/2410.16153v1.pdf","comment":"52 pages, 27 figures"},{"id":"http://arxiv.org/abs/2410.16152v1","updated":"2024-10-21T16:19:34Z","published":"2024-10-21T16:19:34Z","title":"Warped Diffusion: Solving Video Inverse Problems with Image Diffusion\n  Models","summary":"  Using image models naively for solving inverse video problems often suffers\nfrom flickering, texture-sticking, and temporal inconsistency in generated\nvideos. To tackle these problems, in this paper, we view frames as continuous\nfunctions in the 2D space, and videos as a sequence of continuous warping\ntransformations between different frames. This perspective allows us to train\nfunction space diffusion models only on images and utilize them to solve\ntemporally correlated inverse problems. The function space diffusion models\nneed to be equivariant with respect to the underlying spatial transformations.\nTo ensure temporal consistency, we introduce a simple post-hoc test-time\nguidance towards (self)-equivariant solutions. Our method allows us to deploy\nstate-of-the-art latent diffusion models such as Stable Diffusion XL to solve\nvideo inverse problems. We demonstrate the effectiveness of our method for\nvideo inpainting and $8\\times$ video super-resolution, outperforming existing\ntechniques based on noise transformations. We provide generated video results:\nhttps://giannisdaras.github.io/warped\\_diffusion.github.io/.\n","authors":["Giannis Daras","Weili Nie","Karsten Kreis","Alex Dimakis","Morteza Mardani","Nikola Borislavov Kovachki","Arash Vahdat"],"pdf_url":"https://arxiv.org/pdf/2410.16152v1.pdf","comment":"Accepted in NeurIPS 2024"},{"id":"http://arxiv.org/abs/2405.18406v2","updated":"2024-10-21T16:18:37Z","published":"2024-05-28T17:46:36Z","title":"RACCooN: A Versatile Instructional Video Editing Framework with\n  Auto-Generated Narratives","summary":"  Recent video generative models primarily rely on carefully written text\nprompts for specific tasks, like inpainting or style editing. They require\nlabor-intensive textual descriptions for input videos, hindering their\nflexibility to adapt personal/raw videos to user specifications. This paper\nproposes RACCooN, a versatile and user-friendly video-to-paragraph-to-video\ngenerative framework that supports multiple video editing capabilities such as\nremoval, addition, and modification, through a unified pipeline. RACCooN\nconsists of two principal stages: Video-to-Paragraph (V2P) and\nParagraph-to-Video (P2V). In the V2P stage, we automatically describe video\nscenes in well-structured natural language, capturing both the holistic context\nand focused object details. Subsequently, in the P2V stage, users can\noptionally refine these descriptions to guide the video diffusion model,\nenabling various modifications to the input video, such as removing, changing\nsubjects, and/or adding new objects. The proposed approach stands out from\nother methods through several significant contributions: (1) RACCooN suggests a\nmulti-granular spatiotemporal pooling strategy to generate well-structured\nvideo descriptions, capturing both the broad context and object details without\nrequiring complex human annotations, simplifying precise video content editing\nbased on text for users. (2) Our video generative model incorporates\nauto-generated narratives or instructions to enhance the quality and accuracy\nof the generated content. (3) RACCooN also plans to imagine new objects in a\ngiven video, so users simply prompt the model to receive a detailed video\nediting plan for complex video editing. The proposed framework demonstrates\nimpressive versatile capabilities in video-to-paragraph generation, video\ncontent editing, and can be incorporated into other SoTA video generative\nmodels for further enhancement.\n","authors":["Jaehong Yoon","Shoubin Yu","Mohit Bansal"],"pdf_url":"https://arxiv.org/pdf/2405.18406v2.pdf","comment":"The first two authors contribute equally. Project Page:\n  https://raccoon-mllm-gen.github.io/"},{"id":"http://arxiv.org/abs/2410.16146v1","updated":"2024-10-21T16:17:01Z","published":"2024-10-21T16:17:01Z","title":"Towards Combating Frequency Simplicity-biased Learning for Domain\n  Generalization","summary":"  Domain generalization methods aim to learn transferable knowledge from source\ndomains that can generalize well to unseen target domains. Recent studies show\nthat neural networks frequently suffer from a simplicity-biased learning\nbehavior which leads to over-reliance on specific frequency sets, namely as\nfrequency shortcuts, instead of semantic information, resulting in poor\ngeneralization performance. Despite previous data augmentation techniques\nsuccessfully enhancing generalization performances, they intend to apply more\nfrequency shortcuts, thereby causing hallucinations of generalization\nimprovement. In this paper, we aim to prevent such learning behavior of\napplying frequency shortcuts from a data-driven perspective. Given the\ntheoretical justification of models' biased learning behavior on different\nspatial frequency components, which is based on the dataset frequency\nproperties, we argue that the learning behavior on various frequency components\ncould be manipulated by changing the dataset statistical structure in the\nFourier domain. Intuitively, as frequency shortcuts are hidden in the dominant\nand highly dependent frequencies of dataset structure, dynamically perturbating\nthe over-reliance frequency components could prevent the application of\nfrequency shortcuts. To this end, we propose two effective data augmentation\nmodules designed to collaboratively and adaptively adjust the frequency\ncharacteristic of the dataset, aiming to dynamically influence the learning\nbehavior of the model and ultimately serving as a strategy to mitigate shortcut\nlearning. Code is available at AdvFrequency\n(https://github.com/C0notSilly/AdvFrequency).\n","authors":["Xilin He","Jingyu Hu","Qinliang Lin","Cheng Luo","Weicheng Xie","Siyang Song","Muhammad Haris Khan","Linlin Shen"],"pdf_url":"https://arxiv.org/pdf/2410.16146v1.pdf","comment":"Accepted by NeurIPS 2024"},{"id":"http://arxiv.org/abs/2410.16143v1","updated":"2024-10-21T16:14:50Z","published":"2024-10-21T16:14:50Z","title":"An Explainable Contrastive-based Dilated Convolutional Network with\n  Transformer for Pediatric Pneumonia Detection","summary":"  Pediatric pneumonia remains a significant global threat, posing a larger\nmortality risk than any other communicable disease. According to UNICEF, it is\na leading cause of mortality in children under five and requires prompt\ndiagnosis. Early diagnosis using chest radiographs is the prevalent standard,\nbut limitations include low radiation levels in unprocessed images and data\nimbalance issues. This necessitates the development of efficient,\ncomputer-aided diagnosis techniques. To this end, we propose a novel\nEXplainable Contrastive-based Dilated Convolutional Network with Transformer\n(XCCNet) for pediatric pneumonia detection. XCCNet harnesses the spatial power\nof dilated convolutions and the global insights from contrastive-based\ntransformers for effective feature refinement. A robust chest X-ray processing\nmodule tackles low-intensity radiographs, while adversarial-based data\naugmentation mitigates the skewed distribution of chest X-rays in the dataset.\nFurthermore, we actively integrate an explainability approach through feature\nvisualization, directly aligning it with the attention region that pinpoints\nthe presence of pneumonia or normality in radiographs. The efficacy of XCCNet\nis comprehensively assessed on four publicly available datasets. Extensive\nperformance evaluation demonstrates the superiority of XCCNet compared to\nstate-of-the-art methods.\n","authors":["Chandravardhan Singh Raghaw","Parth Shirish Bhore","Mohammad Zia Ur Rehman","Nagendra Kumar"],"pdf_url":"https://arxiv.org/pdf/2410.16143v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2407.00299v4","updated":"2024-10-21T15:56:23Z","published":"2024-06-29T03:37:29Z","title":"Human-Agent Joint Learning for Efficient Robot Manipulation Skill\n  Acquisition","summary":"  Employing a teleoperation system for gathering demonstrations offers the\npotential for more efficient learning of robot manipulation. However,\nteleoperating a robot arm equipped with a dexterous hand or gripper, via a\nteleoperation system presents inherent challenges due to the task's high\ndimensionality, complexity of motion, and differences between physiological\nstructures. In this study, we introduce a novel system for joint learning\nbetween human operators and robots, that enables human operators to share\ncontrol of a robot end-effector with a learned assistive agent, simplifies the\ndata collection process, and facilitates simultaneous human demonstration\ncollection and robot manipulation training. As data accumulates, the assistive\nagent gradually learns. Consequently, less human effort and attention are\nrequired, enhancing the efficiency of the data collection process. It also\nallows the human operator to adjust the control ratio to achieve a trade-off\nbetween manual and automated control. We conducted experiments in both\nsimulated environments and physical real-world settings. Through user studies\nand quantitative evaluations, it is evident that the proposed system could\nenhance data collection efficiency and reduce the need for human adaptation\nwhile ensuring the collected data is of sufficient quality for downstream\ntasks. \\textit{For more details, please refer to our webpage\nhttps://norweig1an.github.io/HAJL.github.io/.\n","authors":["Shengcheng Luo","Quanquan Peng","Jun Lv","Kaiwen Hong","Katherine Rose Driggs-Campbell","Cewu Lu","Yong-Lu Li"],"pdf_url":"https://arxiv.org/pdf/2407.00299v4.pdf","comment":"8 pages, 6 figures"},{"id":"http://arxiv.org/abs/2410.08797v2","updated":"2024-10-21T15:45:23Z","published":"2024-10-11T13:31:28Z","title":"CoTCoNet: An Optimized Coupled Transformer-Convolutional Network with an\n  Adaptive Graph Reconstruction for Leukemia Detection","summary":"  Swift and accurate blood smear analysis is an effective diagnostic method for\nleukemia and other hematological malignancies. However, manual leukocyte count\nand morphological evaluation using a microscope is time-consuming and prone to\nerrors. Conventional image processing methods also exhibit limitations in\ndifferentiating cells due to the visual similarity between malignant and benign\ncell morphology. This limitation is further compounded by the skewed training\ndata that hinders the extraction of reliable and pertinent features. In\nresponse to these challenges, we propose an optimized Coupled Transformer\nConvolutional Network (CoTCoNet) framework for the classification of leukemia,\nwhich employs a well-designed transformer integrated with a deep convolutional\nnetwork to effectively capture comprehensive global features and scalable\nspatial patterns, enabling the identification of complex and large-scale\nhematological features. Further, the framework incorporates a graph-based\nfeature reconstruction module to reveal the hidden or unobserved hard-to-see\nbiological features of leukocyte cells and employs a Population-based\nMeta-Heuristic Algorithm for feature selection and optimization. To mitigate\ndata imbalance issues, we employ a synthetic leukocyte generator. In the\nevaluation phase, we initially assess CoTCoNet on a dataset containing 16,982\nannotated cells, and it achieves remarkable accuracy and F1-Score rates of\n0.9894 and 0.9893, respectively. To broaden the generalizability of our model,\nwe evaluate it across four publicly available diverse datasets, which include\nthe aforementioned dataset. This evaluation demonstrates that our method\noutperforms current state-of-the-art approaches. We also incorporate an\nexplainability approach in the form of feature visualization closely aligned\nwith cell annotations to provide a deeper understanding of the framework.\n","authors":["Chandravardhan Singh Raghaw","Arnav Sharma","Shubhi Bansal","Mohammad Zia Ur Rehman","Nagendra Kumar"],"pdf_url":"https://arxiv.org/pdf/2410.08797v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.16116v1","updated":"2024-10-21T15:42:47Z","published":"2024-10-21T15:42:47Z","title":"Multimodal Flare Forecasting with Deep Learning","summary":"  Solar flare forecasting mainly relies on photospheric magnetograms and\nassociated physical features to predict forthcoming flares. However, it is\nbelieved that flare initiation mechanisms often originate in the chromosphere\nand the lower corona. In this study, we employ deep learning as a purely\ndata-driven approach to compare the predictive capabilities of chromospheric\nand coronal UV and EUV emissions across different wavelengths with those of\nphotospheric line-of-sight magnetograms. Our findings indicate that individual\nEUV wavelengths can provide discriminatory power comparable or better to that\nof line-of-sight magnetograms. Moreover, we identify simple multimodal neural\nnetwork architectures that consistently outperform single-input models, showing\ncomplementarity between the flare precursors that can be extracted from the\ndistinct layers of the solar atmosphere. To mitigate potential biases from\nknown misattributions in Active Region flare catalogs, our models are trained\nand evaluated using full-disk images and a comprehensive flare event catalog at\nthe full-disk level. We introduce a deep-learning architecture suited for\nextracting temporal features from full-disk videos.\n","authors":["Grégoire Francisco","Sabrina Guastavino","Teresa Barata","João Fernandes","Dario Del Moro"],"pdf_url":"https://arxiv.org/pdf/2410.16116v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.13861v2","updated":"2024-10-21T15:42:46Z","published":"2024-10-17T17:59:57Z","title":"PUMA: Empowering Unified MLLM with Multi-granular Visual Generation","summary":"  Recent advancements in multimodal foundation models have yielded significant\nprogress in vision-language understanding. Initial attempts have also explored\nthe potential of multimodal large language models (MLLMs) for visual content\ngeneration. However, existing works have insufficiently addressed the varying\ngranularity demands of different image generation tasks within a unified MLLM\nparadigm - from the diversity required in text-to-image generation to the\nprecise controllability needed in image manipulation. In this work, we propose\nPUMA, emPowering Unified MLLM with Multi-grAnular visual generation. PUMA\nunifies multi-granular visual features as both inputs and outputs of MLLMs,\nelegantly addressing the different granularity requirements of various image\ngeneration tasks within a unified MLLM framework. Following multimodal\npretraining and task-specific instruction tuning, PUMA demonstrates proficiency\nin a wide range of multimodal tasks. This work represents a significant step\ntowards a truly unified MLLM capable of adapting to the granularity demands of\nvarious visual tasks. The code and model will be released in\nhttps://github.com/rongyaofang/PUMA.\n","authors":["Rongyao Fang","Chengqi Duan","Kun Wang","Hao Li","Hao Tian","Xingyu Zeng","Rui Zhao","Jifeng Dai","Hongsheng Li","Xihui Liu"],"pdf_url":"https://arxiv.org/pdf/2410.13861v2.pdf","comment":"Project page: https://rongyaofang.github.io/puma/"},{"id":"http://arxiv.org/abs/2410.16115v1","updated":"2024-10-21T15:42:27Z","published":"2024-10-21T15:42:27Z","title":"Increasing Interpretability of Neural Networks By Approximating Human\n  Visual Saliency","summary":"  Understanding specifically where a model focuses on within an image is\ncritical for human interpretability of the decision-making process. Deep\nlearning-based solutions are prone to learning coincidental correlations in\ntraining datasets, causing over-fitting and reducing the explainability. Recent\nadvances have shown that guiding models to human-defined regions of saliency\nwithin individual images significantly increases performance and\ninterpretability. Human-guided models also exhibit greater generalization\ncapabilities, as coincidental dataset features are avoided. Results show that\nmodels trained with saliency incorporation display an increase in\ninterpretability of up to 30% over models trained without saliency information.\nThe collection of this saliency information, however, can be costly, laborious\nand in some cases infeasible. To address this limitation, we propose a\ncombination strategy of saliency incorporation and active learning to reduce\nthe human annotation data required by 80% while maintaining the\ninterpretability and performance increase from human saliency. Extensive\nexperimentation outlines the effectiveness of the proposed approach across five\npublic datasets and six active learning criteria.\n","authors":["Aidan Boyd","Mohamed Trabelsi","Huseyin Uzunalioglu","Dan Kushnir"],"pdf_url":"https://arxiv.org/pdf/2410.16115v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.16095v1","updated":"2024-10-21T15:20:02Z","published":"2024-10-21T15:20:02Z","title":"LMHaze: Intensity-aware Image Dehazing with a Large-scale\n  Multi-intensity Real Haze Dataset","summary":"  Image dehazing has drawn a significant attention in recent years.\nLearning-based methods usually require paired hazy and corresponding ground\ntruth (haze-free) images for training. However, it is difficult to collect\nreal-world image pairs, which prevents developments of existing methods.\nAlthough several works partially alleviate this issue by using synthetic\ndatasets or small-scale real datasets. The haze intensity distribution bias and\nscene homogeneity in existing datasets limit the generalization ability of\nthese methods, particularly when encountering images with previously unseen\nhaze intensities. In this work, we present LMHaze, a large-scale, high-quality\nreal-world dataset. LMHaze comprises paired hazy and haze-free images captured\nin diverse indoor and outdoor environments, spanning multiple scenarios and\nhaze intensities. It contains over 5K high-resolution image pairs, surpassing\nthe size of the biggest existing real-world dehazing dataset by over 25 times.\nMeanwhile, to better handle images with different haze intensities, we propose\na mixture-of-experts model based on Mamba (MoE-Mamba) for dehazing, which\ndynamically adjusts the model parameters according to the haze intensity.\nMoreover, with our proposed dataset, we conduct a new large multimodal model\n(LMM)-based benchmark study to simulate human perception for evaluating dehazed\nimages. Experiments demonstrate that LMHaze dataset improves the dehazing\nperformance in real scenarios and our dehazing method provides better results\ncompared to state-of-the-art methods.\n","authors":["Ruikun Zhang","Hao Yang","Yan Yang","Ying Fu","Liyuan Pan"],"pdf_url":"https://arxiv.org/pdf/2410.16095v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.08381v4","updated":"2024-10-21T15:18:39Z","published":"2024-08-15T18:54:31Z","title":"Pre-processing and Compression: Understanding Hidden Representation\n  Refinement Across Imaging Domains via Intrinsic Dimension","summary":"  In recent years, there has been interest in how geometric properties such as\nintrinsic dimension (ID) of a neural network's hidden representations change\nthrough its layers, and how such properties are predictive of important model\nbehavior such as generalization ability. However, evidence has begun to emerge\nthat such behavior can change significantly depending on the domain of the\nnetwork's training data, such as natural versus medical images. Here, we\nfurther this inquiry by exploring how the ID of a network's learned\nrepresentations changes through its layers, in essence, characterizing how the\nnetwork successively refines the information content of input data to be used\nfor predictions. Analyzing eleven natural and medical image datasets across six\nnetwork architectures, we find that how ID changes through the network differs\nnoticeably between natural and medical image models. Specifically, medical\nimage models peak in representation ID earlier in the network, implying a\ndifference in the image features and their abstractness that are typically used\nfor downstream tasks in these domains. Additionally, we discover a strong\ncorrelation of this peak representation ID with the ID of the data in its input\nspace, implying that the intrinsic information content of a model's learned\nrepresentations is guided by that of the data it was trained on. Overall, our\nfindings emphasize notable discrepancies in network behavior between natural\nand non-natural imaging domains regarding hidden representation information\ncontent, and provide further insights into how a network's learned features are\nshaped by its training data.\n","authors":["Nicholas Konz","Maciej A. Mazurowski"],"pdf_url":"https://arxiv.org/pdf/2408.08381v4.pdf","comment":"Published in NeurIPS 2024 Workshop on Scientific Methods for\n  Understanding Deep Learning (SciForDL)"},{"id":"http://arxiv.org/abs/2410.16093v1","updated":"2024-10-21T15:16:00Z","published":"2024-10-21T15:16:00Z","title":"Final Report for CHESS: Cloud, High-Performance Computing, and Edge for\n  Science and Security","summary":"  Automating the theory-experiment cycle requires effective distributed\nworkflows that utilize a computing continuum spanning lab instruments, edge\nsensors, computing resources at multiple facilities, data sets distributed\nacross multiple information sources, and potentially cloud. Unfortunately, the\nobvious methods for constructing continuum platforms, orchestrating workflow\ntasks, and curating datasets over time fail to achieve scientific requirements\nfor performance, energy, security, and reliability. Furthermore, achieving the\nbest use of continuum resources depends upon the efficient composition and\nexecution of workflow tasks, i.e., combinations of numerical solvers, data\nanalytics, and machine learning. Pacific Northwest National Laboratory's LDRD\n\"Cloud, High-Performance Computing (HPC), and Edge for Science and Security\"\n(CHESS) has developed a set of interrelated capabilities for enabling\ndistributed scientific workflows and curating datasets. This report describes\nthe results and successes of CHESS from the perspective of open science.\n","authors":["Nathan Tallent","Jan Strube","Luanzheng Guo","Hyungro Lee","Jesun Firoz","Sayan Ghosh","Bo Fang","Oceane Bel","Steven Spurgeon","Sarah Akers","Christina Doty","Erol Cromwell"],"pdf_url":"https://arxiv.org/pdf/2410.16093v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.16063v1","updated":"2024-10-21T14:44:08Z","published":"2024-10-21T14:44:08Z","title":"Integrated Image-Text Based on Semi-supervised Learning for Small Sample\n  Instance Segmentation","summary":"  Small sample instance segmentation is a very challenging task, and many\nexisting methods follow the training strategy of meta-learning which pre-train\nmodels on support set and fine-tune on query set. The pre-training phase, which\nis highly task related, requires a significant amount of additional training\ntime and the selection of datasets with close proximity to ensure\neffectiveness. The article proposes a novel small sample instance segmentation\nsolution from the perspective of maximizing the utilization of existing\ninformation without increasing annotation burden and training costs. The\nproposed method designs two modules to address the problems encountered in\nsmall sample instance segmentation. First, it helps the model fully utilize\nunlabeled data by learning to generate pseudo labels, increasing the number of\navailable samples. Second, by integrating the features of text and image, more\naccurate classification results can be obtained. These two modules are suitable\nfor box-free and box-dependent frameworks. In the way, the proposed method not\nonly improves the performance of small sample instance segmentation, but also\ngreatly reduce reliance on pre-training. We have conducted experiments in three\ndatasets from different scenes: on land, underwater and under microscope. As\nevidenced by our experiments, integrated image-text corrects the confidence of\nclassification, and pseudo labels help the model obtain preciser masks. All the\nresults demonstrate the effectiveness and superiority of our method.\n","authors":["Ruting Chi","Zhiyi Huang","Yuexing Han"],"pdf_url":"https://arxiv.org/pdf/2410.16063v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.11792v2","updated":"2024-10-21T14:42:16Z","published":"2024-03-18T13:50:35Z","title":"SETA: Semantic-Aware Token Augmentation for Domain Generalization","summary":"  Domain generalization (DG) aims to enhance the model robustness against\ndomain shifts without accessing target domains. A prevalent category of methods\nfor DG is data augmentation, which focuses on generating virtual samples to\nsimulate domain shifts. However, existing augmentation techniques in DG are\nmainly tailored for convolutional neural networks (CNNs), with limited\nexploration in token-based architectures, i.e., vision transformer (ViT) and\nmulti-layer perceptrons (MLP) models. In this paper, we study the impact of\nprior CNN-based augmentation methods on token-based models, revealing their\nperformance is suboptimal due to the lack of incentivizing the model to learn\nholistic shape information. To tackle the issue, we propose the SEmantic-aware\nToken Augmentation (SETA) method. SETA transforms token features by perturbing\nlocal edge cues while preserving global shape features, thereby enhancing the\nmodel learning of shape information. To further enhance the generalization\nability of the model, we introduce two stylized variants of our method combined\nwith two state-of-the-art style augmentation methods in DG. We provide a\ntheoretical insight into our method, demonstrating its effectiveness in\nreducing the generalization risk bound. Comprehensive experiments on five\nbenchmarks prove that our method achieves SOTA performances across various ViT\nand MLP architectures. Our code is available at\nhttps://github.com/lingeringlight/SETA.\n","authors":["Jintao Guo","Lei Qi","Yinghuan Shi","Yang Gao"],"pdf_url":"https://arxiv.org/pdf/2403.11792v2.pdf","comment":"Accepted by IEEE TIP 2024. The code is available at\n  https://github.com/lingeringlight/SETA"},{"id":"http://arxiv.org/abs/2410.16057v1","updated":"2024-10-21T14:36:36Z","published":"2024-10-21T14:36:36Z","title":"Label Filling via Mixed Supervision for Medical Image Segmentation from\n  Noisy Annotations","summary":"  The success of medical image segmentation usually requires a large number of\nhigh-quality labels. But since the labeling process is usually affected by the\nraters' varying skill levels and characteristics, the estimated masks provided\nby different raters usually suffer from high inter-rater variability. In this\npaper, we propose a simple yet effective Label Filling framework, termed as\nLF-Net, predicting the groundtruth segmentation label given only noisy\nannotations during training. The fundamental idea of label filling is to\nsupervise the segmentation model by a subset of pixels with trustworthy labels,\nmeanwhile filling labels of other pixels by mixed supervision. More concretely,\nwe propose a qualified majority voting strategy, i.e., a threshold voting\nscheme is designed to model agreement among raters and the majority-voted\nlabels of the selected subset of pixels are regarded as supervision. To fill\nlabels of other pixels, two types of mixed auxiliary supervision are proposed:\na soft label learned from intrinsic structures of noisy annotations, and\nraters' characteristics labels which propagate individual rater's\ncharacteristics information. LF-Net has two main advantages. 1) Training with\ntrustworthy pixels incorporates training with confident supervision, guiding\nthe direction of groundtruth label learning. 2) Two types of mixed supervision\nprevent over-fitting issues when the network is supervised by a subset of\npixels, and guarantee high fidelity with the true label. Results on five\ndatasets of diverse imaging modalities show that our LF-Net boosts segmentation\naccuracy in all datasets compared with state-of-the-art methods, with even a 7%\nimprovement in DSC for MS lesion segmentation.\n","authors":["Ming Li","Wei Shen","Qingli Li","Yan Wang"],"pdf_url":"https://arxiv.org/pdf/2410.16057v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.06446v2","updated":"2024-10-21T14:28:18Z","published":"2024-10-09T01:12:07Z","title":"Machine Unlearning in Forgettability Sequence","summary":"  Machine unlearning (MU) is becoming a promising paradigm to achieve the\n\"right to be forgotten\", where the training trace of any chosen data points\ncould be eliminated, while maintaining the model utility on general testing\nsamples after unlearning. With the advancement of forgetting research, many\nfundamental open questions remain unanswered: do different samples exhibit\nvarying levels of difficulty in being forgotten? Further, does the sequence in\nwhich samples are forgotten, determined by their respective difficulty levels,\ninfluence the performance of forgetting algorithms? In this paper, we identify\nkey factor affecting unlearning difficulty and the performance of unlearning\nalgorithms. We find that samples with higher privacy risks are more likely to\nbe unlearning, indicating that the unlearning difficulty varies among different\nsamples which motives a more precise unlearning mode. Built upon this insight,\nwe propose a general unlearning framework, dubbed RSU, which consists of\nRanking module and SeqUnlearn module.\n","authors":["Junjie Chen","Qian Chen","Jian Lou","Xiaoyu Zhang","Kai Wu","Zilong Wang"],"pdf_url":"https://arxiv.org/pdf/2410.06446v2.pdf","comment":"The senior authors of the draft are not fully convinced that the\n  novelty is significant enough for this submission compared to the latest\n  research progress in this area. Additionally, the senior authors have\n  identified writing issues. Based on these two reasons, we have decided to\n  withdraw the draft from arXiv"},{"id":"http://arxiv.org/abs/2409.09478v2","updated":"2024-10-21T14:15:30Z","published":"2024-09-14T16:39:17Z","title":"From FDG to PSMA: A Hitchhiker's Guide to Multitracer, Multicenter\n  Lesion Segmentation in PET/CT Imaging","summary":"  Automated lesion segmentation in PET/CT scans is crucial for improving\nclinical workflows and advancing cancer diagnostics. However, the task is\nchallenging due to physiological variability, different tracers used in PET\nimaging, and diverse imaging protocols across medical centers. To address this,\nthe autoPET series was created to challenge researchers to develop algorithms\nthat generalize across diverse PET/CT environments. This paper presents our\nsolution for the autoPET III challenge, targeting multitracer, multicenter\ngeneralization using the nnU-Net framework with the ResEncL architecture. Key\ntechniques include misalignment data augmentation and multi-modal pretraining\nacross CT, MR, and PET datasets to provide an initial anatomical understanding.\nWe incorporate organ supervision as a multitask approach, enabling the model to\ndistinguish between physiological uptake and tracer-specific patterns, which is\nparticularly beneficial in cases where no lesions are present. Compared to the\ndefault nnU-Net, which achieved a Dice score of 57.61, or the larger ResEncL\n(65.31) our model significantly improved performance with a Dice score of\n68.40, alongside a reduction in false positive (FPvol: 7.82) and false negative\n(FNvol: 10.35) volumes. These results underscore the effectiveness of combining\nadvanced network design, augmentation, pretraining, and multitask learning for\nPET/CT lesion segmentation. After evaluation on the test set, our approach was\nawarded the first place in the model-centric category (Team LesionTracer). Code\nis publicly available at https://github.com/MIC-DKFZ/autopet-3-submission.\n","authors":["Maximilian Rokuss","Balint Kovacs","Yannick Kirchhoff","Shuhan Xiao","Constantin Ulrich","Klaus H. Maier-Hein","Fabian Isensee"],"pdf_url":"https://arxiv.org/pdf/2409.09478v2.pdf","comment":"Winning method of the autoPET III challenge (model-centric) - Team\n  LesionTracer"},{"id":"http://arxiv.org/abs/2410.06558v4","updated":"2024-10-21T14:11:54Z","published":"2024-10-09T05:28:43Z","title":"Deep Correlated Prompting for Visual Recognition with Missing Modalities","summary":"  Large-scale multimodal models have shown excellent performance over a series\nof tasks powered by the large corpus of paired multimodal training data.\nGenerally, they are always assumed to receive modality-complete inputs.\nHowever, this simple assumption may not always hold in the real world due to\nprivacy constraints or collection difficulty, where models pretrained on\nmodality-complete data easily demonstrate degraded performance on\nmissing-modality cases. To handle this issue, we refer to prompt learning to\nadapt large pretrained multimodal models to handle missing-modality scenarios\nby regarding different missing cases as different types of input. Instead of\nonly prepending independent prompts to the intermediate layers, we present to\nleverage the correlations between prompts and input features and excavate the\nrelationships between different layers of prompts to carefully design the\ninstructions. We also incorporate the complementary semantics of different\nmodalities to guide the prompting design for each modality. Extensive\nexperiments on three commonly-used datasets consistently demonstrate the\nsuperiority of our method compared to the previous approaches upon different\nmissing scenarios. Plentiful ablations are further given to show the\ngeneralizability and reliability of our method upon different modality-missing\nratios and types.\n","authors":["Lianyu Hu","Tongkai Shi","Wei Feng","Fanhua Shang","Liang Wan"],"pdf_url":"https://arxiv.org/pdf/2410.06558v4.pdf","comment":"NeurIPS 2024, add some results"},{"id":"http://arxiv.org/abs/2410.16038v1","updated":"2024-10-21T14:10:18Z","published":"2024-10-21T14:10:18Z","title":"Benchmarking Pathology Foundation Models: Adaptation Strategies and\n  Scenarios","summary":"  In computational pathology, several foundation models have recently emerged\nand demonstrated enhanced learning capability for analyzing pathology images.\nHowever, adapting these models to various downstream tasks remains challenging,\nparticularly when faced with datasets from different sources and acquisition\nconditions, as well as limited data availability. In this study, we benchmark\nfour pathology-specific foundation models across 14 datasets and two\nscenarios-consistency assessment and flexibility assessment-addressing diverse\nadaptation scenarios and downstream tasks. In the consistency assessment\nscenario, involving five fine-tuning methods, we found that the\nparameter-efficient fine-tuning approach was both efficient and effective for\nadapting pathology-specific foundation models to diverse datasets within the\nsame downstream task. In the flexibility assessment scenario under data-limited\nenvironments, utilizing five few-shot learning methods, we observed that the\nfoundation models benefited more from the few-shot learning methods that\ninvolve modification during the testing phase only. These findings provide\ninsights that could guide the deployment of pathology-specific foundation\nmodels in real clinical settings, potentially improving the accuracy and\nreliability of pathology image analysis. The code for this study is available\nat: https://github.com/QuIIL/BenchmarkingPathologyFoundationModels.\n","authors":["Jeaung Lee","Jeewoo Lim","Keunho Byeon","Jin Tae Kwak"],"pdf_url":"https://arxiv.org/pdf/2410.16038v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.16037v1","updated":"2024-10-21T14:10:14Z","published":"2024-10-21T14:10:14Z","title":"Improving the Multi-label Atomic Activity Recognition by Robust Visual\n  Feature and Advanced Attention @ ROAD++ Atomic Activity Recognition 2024","summary":"  Road++ Track3 proposes a multi-label atomic activity recognition task in\ntraffic scenarios, which can be standardized as a 64-class multi-label video\naction recognition task. In the multi-label atomic activity recognition task,\nthe robustness of visual feature extraction remains a key challenge, which\ndirectly affects the model performance and generalization ability. To cope with\nthese issues, our team optimized three aspects: data processing, model and\npost-processing. Firstly, the appropriate resolution and video sampling\nstrategy are selected, and a fixed sampling strategy is set on the validation\nand test sets. Secondly, in terms of model training, the team selects a variety\nof visual backbone networks for feature extraction, and then introduces the\naction-slot model, which is trained on the training and validation sets, and\nreasoned on the test set. Finally, for post-processing, the team combined the\nstrengths and weaknesses of different models for weighted fusion, and the final\nmAP on the test set was 58%, which is 4% higher than the challenge baseline.\n","authors":["Jiamin Cao","Lingqi Wang","Kexin Zhang","Yuting Yang","Licheng Jiao","Yuwei Guo"],"pdf_url":"https://arxiv.org/pdf/2410.16037v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.11545v3","updated":"2024-10-21T14:04:16Z","published":"2024-08-21T11:53:53Z","title":"UNetMamba: An Efficient UNet-Like Mamba for Semantic Segmentation of\n  High-Resolution Remote Sensing Images","summary":"  Semantic segmentation of high-resolution remote sensing images is vital in\ndownstream applications such as land-cover mapping, urban planning and disaster\nassessment.Existing Transformer-based methods suffer from the constraint\nbetween accuracy and efficiency, while the recently proposed Mamba is renowned\nfor being efficient. Therefore, to overcome the dilemma, we propose UNetMamba,\na UNet-like semantic segmentation model based on Mamba. It incorporates a mamba\nsegmentation decoder (MSD) that can efficiently decode the complex information\nwithin high-resolution images, and a local supervision module (LSM), which is\ntrain-only but can significantly enhance the perception of local contents.\nExtensive experiments demonstrate that UNetMamba outperforms the\nstate-of-the-art methods with mIoU increased by 0.87% on LoveDA and 0.39% on\nISPRS Vaihingen, while achieving high efficiency through the lightweight\ndesign, less memory footprint and reduced computational cost. The source code\nis available at https://github.com/EnzeZhu2001/UNetMamba.\n","authors":["Enze Zhu","Zhan Chen","Dingkai Wang","Hanru Shi","Xiaoxuan Liu","Lei Wang"],"pdf_url":"https://arxiv.org/pdf/2408.11545v3.pdf","comment":"5 pages, 3 figures"},{"id":"http://arxiv.org/abs/2410.16028v1","updated":"2024-10-21T14:03:15Z","published":"2024-10-21T14:03:15Z","title":"Few-shot target-driven instance detection based on open-vocabulary\n  object detection models","summary":"  Current large open vision models could be useful for one and few-shot object\nrecognition. Nevertheless, gradient-based re-training solutions are costly. On\nthe other hand, open-vocabulary object detection models bring closer visual and\ntextual concepts in the same latent space, allowing zero-shot detection via\nprompting at small computational cost. We propose a lightweight method to turn\nthe latter into a one-shot or few-shot object recognition models without\nrequiring textual descriptions. Our experiments on the TEgO dataset using the\nYOLO-World model as a base show that performance increases with the model size,\nthe number of examples and the use of image augmentation.\n","authors":["Ben Crulis","Barthelemy Serres","Cyril De Runz","Gilles Venturini"],"pdf_url":"https://arxiv.org/pdf/2410.16028v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.16020v1","updated":"2024-10-21T13:50:32Z","published":"2024-10-21T13:50:32Z","title":"START: A Generalized State Space Model with Saliency-Driven Token-Aware\n  Transformation","summary":"  Domain Generalization (DG) aims to enable models to generalize to unseen\ntarget domains by learning from multiple source domains. Existing DG methods\nprimarily rely on convolutional neural networks (CNNs), which inherently learn\ntexture biases due to their limited receptive fields, making them prone to\noverfitting source domains. While some works have introduced transformer-based\nmethods (ViTs) for DG to leverage the global receptive field, these methods\nincur high computational costs due to the quadratic complexity of\nself-attention. Recently, advanced state space models (SSMs), represented by\nMamba, have shown promising results in supervised learning tasks by achieving\nlinear complexity in sequence length during training and fast RNN-like\ncomputation during inference. Inspired by this, we investigate the\ngeneralization ability of the Mamba model under domain shifts and find that\ninput-dependent matrices within SSMs could accumulate and amplify\ndomain-specific features, thus hindering model generalization. To address this\nissue, we propose a novel SSM-based architecture with saliency-based\ntoken-aware transformation (namely START), which achieves state-of-the-art\n(SOTA) performances and offers a competitive alternative to CNNs and ViTs. Our\nSTART can selectively perturb and suppress domain-specific features in salient\ntokens within the input-dependent matrices of SSMs, thus effectively reducing\nthe discrepancy between different domains. Extensive experiments on five\nbenchmarks demonstrate that START outperforms existing SOTA DG methods with\nefficient linear complexity. Our code is available at\nhttps://github.com/lingeringlight/START.\n","authors":["Jintao Guo","Lei Qi","Yinghuan Shi","Yang Gao"],"pdf_url":"https://arxiv.org/pdf/2410.16020v1.pdf","comment":"Accepted by NeurIPS2024. The code is available at\n  https://github.com/lingeringlight/START"},{"id":"http://arxiv.org/abs/2410.16019v1","updated":"2024-10-21T13:49:54Z","published":"2024-10-21T13:49:54Z","title":"Multispectral Texture Synthesis using RGB Convolutional Neural Networks","summary":"  State-of-the-art RGB texture synthesis algorithms rely on style distances\nthat are computed through statistics of deep features. These deep features are\nextracted by classification neural networks that have been trained on large\ndatasets of RGB images. Extending such synthesis methods to multispectral\nimages is not straightforward, since the pre-trained networks are designed for\nand have been trained on RGB images. In this work, we propose two solutions to\nextend these methods to multispectral imaging. Neither of them require\nadditional training of the neural network from which the second order neural\nstatistics are extracted. The first one consists in optimizing over batches of\nrandom triplets of spectral bands throughout training. The second one projects\nmultispectral pixels onto a 3 dimensional space. We further explore the benefit\nof a color transfer operation upstream of the projection to avoid the\npotentially abnormal color distributions induced by the projection. Our\nexperiments compare the performances of the various methods through different\nmetrics. We demonstrate that they can be used to perform exemplar-based texture\nsynthesis, achieve good visual quality and comes close to state-of-the art\nmethods on RGB bands.\n","authors":["Sélim Ollivier","Yann Gousseau","Sidonie Lefebvre"],"pdf_url":"https://arxiv.org/pdf/2410.16019v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2401.09283v2","updated":"2024-10-21T13:45:54Z","published":"2024-01-17T15:37:00Z","title":"A gradient-based approach to fast and accurate head motion compensation\n  in cone-beam CT","summary":"  Cone-beam computed tomography (CBCT) systems, with their flexibility, present\na promising avenue for direct point-of-care medical imaging, particularly in\ncritical scenarios such as acute stroke assessment. However, the integration of\nCBCT into clinical workflows faces challenges, primarily linked to long scan\nduration resulting in patient motion during scanning and leading to image\nquality degradation in the reconstructed volumes. This paper introduces a novel\napproach to CBCT motion estimation using a gradient-based optimization\nalgorithm, which leverages generalized derivatives of the backprojection\noperator for cone-beam CT geometries. Building on that, a fully differentiable\ntarget function is formulated which grades the quality of the current motion\nestimate in reconstruction space. We drastically accelerate motion estimation\nyielding a 19-fold speed-up compared to existing methods. Additionally, we\ninvestigate the architecture of networks used for quality metric regression and\npropose predicting voxel-wise quality maps, favoring autoencoder-like\narchitectures over contracting ones. This modification improves gradient flow,\nleading to more accurate motion estimation. The presented method is evaluated\nthrough realistic experiments on head anatomy. It achieves a reduction in\nreprojection error from an initial average of 3mm to 0.61mm after motion\ncompensation and consistently demonstrates superior performance compared to\nexisting approaches. The analytic Jacobian for the backprojection operation,\nwhich is at the core of the proposed method, is made publicly available. In\nsummary, this paper contributes to the advancement of CBCT integration into\nclinical workflows by proposing a robust motion estimation approach that\nenhances efficiency and accuracy, addressing critical challenges in\ntime-sensitive scenarios.\n","authors":["Mareike Thies","Fabian Wagner","Noah Maul","Haijun Yu","Manuela Goldmann","Linda-Sophie Schneider","Mingxuan Gu","Siyuan Mei","Lukas Folle","Alexander Preuhs","Michael Manhart","Andreas Maier"],"pdf_url":"https://arxiv.org/pdf/2401.09283v2.pdf","comment":"\\copyright 2024 IEEE. Personal use of this material is permitted.\n  Permission from IEEE must be obtained for all other uses, in any current or\n  future media, including reprinting/republishing this material for advertising\n  or promotional purposes, creating new collective works, for resale or\n  redistribution to servers or lists, or reuse of any copyrighted component of\n  this work in other works"},{"id":"http://arxiv.org/abs/2410.16012v1","updated":"2024-10-21T13:43:02Z","published":"2024-10-21T13:43:02Z","title":"Massimo: Public Queue Monitoring and Management using Mass-Spring Model","summary":"  An efficient system of a queue control and regulation in public spaces is\nvery important in order to avoid the traffic jams and to improve the customer\nsatisfaction. This article offers a detailed road map based on a merger of\nintelligent systems and creating an efficient systems of queues in public\nplaces. Through the utilization of different technologies i.e. computer vision,\nmachine learning algorithms, deep learning our system provide accurate\ninformation about the place is crowded or not and the necessary efforts to be\ntaken.\n","authors":["Abhijeet Kumar","Unnati Singh","Rajdeep Chatterjee","Tathagata Bandyopadhyay"],"pdf_url":"https://arxiv.org/pdf/2410.16012v1.pdf","comment":"8 pages, 6 figures, 3 algorithms, 3 tables"},{"id":"http://arxiv.org/abs/2410.16009v1","updated":"2024-10-21T13:42:06Z","published":"2024-10-21T13:42:06Z","title":"3D-GANTex: 3D Face Reconstruction with StyleGAN3-based Multi-View Images\n  and 3DDFA based Mesh Generation","summary":"  Geometry and texture estimation from a single face image is an ill-posed\nproblem since there is very little information to work with. The problem\nfurther escalates when the face is rotated at a different angle. This paper\ntries to tackle this problem by introducing a novel method for texture\nestimation from a single image by first using StyleGAN and 3D Morphable Models.\nThe method begins by generating multi-view faces using the latent space of GAN.\nThen 3DDFA trained on 3DMM estimates a 3D face mesh as well as a\nhigh-resolution texture map that is consistent with the estimated face shape.\nThe result shows that the generated mesh is of high quality with near to\naccurate texture representation.\n","authors":["Rohit Das","Tzung-Han Lin","Ko-Chih Wang"],"pdf_url":"https://arxiv.org/pdf/2410.16009v1.pdf","comment":"7 pages, 4 figures, 2 tables, pre-print version"},{"id":"http://arxiv.org/abs/2211.11571v3","updated":"2024-10-21T13:12:25Z","published":"2022-11-21T15:29:38Z","title":"SLLEN: Semantic-aware Low-light Image Enhancement Network","summary":"  How to effectively explore semantic feature is vital for low-light image\nenhancement (LLE). Existing methods usually utilize the semantic feature that\nis only drawn from the output produced by high-level semantic segmentation (SS)\nnetwork. However, if the output is not accurately estimated, it would affect\nthe high-level semantic feature (HSF) extraction, which accordingly interferes\nwith LLE. To this end, we develop a simple and effective semantic-aware LLE\nnetwork (SSLEN) composed of a LLE main-network (LLEmN) and a SS\nauxiliary-network (SSaN). In SLLEN, LLEmN integrates the random intermediate\nembedding feature (IEF), i.e., the information extracted from the intermediate\nlayer of SSaN, together with the HSF into a unified framework for better LLE.\nSSaN is designed to act as a SS role to provide HSF and IEF. Moreover, thanks\nto a shared encoder between LLEmN and SSaN, we further propose an alternating\ntraining mechanism to facilitate the collaboration between them. Unlike\ncurrently available approaches, the proposed SLLEN is able to fully lever the\nsemantic information, e.g., IEF, HSF, and SS dataset, to assist LLE, thereby\nleading to a more promising enhancement performance. Comparisons between the\nproposed SLLEN and other state-of-the-art techniques demonstrate the\nsuperiority of SLLEN with respect to LLE quality over all the comparable\nalternatives.\n","authors":["Mingye Ju","Chuheng Chen","Charles A. Guo","Jinshan Pan","Jinhui Tang","Dacheng Tao"],"pdf_url":"https://arxiv.org/pdf/2211.11571v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2211.16005v2","updated":"2024-10-21T13:07:42Z","published":"2022-11-29T07:59:15Z","title":"Convex Relaxations for Isometric and Equiareal NRSfM","summary":"  Extensible objects form a challenging case for NRSfM, owing to the lack of a\nsufficiently constrained extensible model of the point-cloud. We tackle the\nchallenge by proposing 1) convex relaxations of the isometric model up to\nquasi-isometry, and 2) convex relaxations involving the equiareal deformation\nmodel, which preserves local area and has not been used in NRSfM. The equiareal\nmodel is appealing because it is physically plausible and widely applicable.\nHowever, it has two main difficulties: first, when used on its own, it is\nambiguous, and second, it involves quartic, hence highly nonconvex,\nconstraints. Our approach handles the first difficulty by mixing the equiareal\nwith the isometric model and the second difficulty by new convex relaxations.\nWe validate our methods on multiple real and synthetic data, including\nwell-known benchmarks.\n","authors":["Agniva Sengupta","Adrien Bartoli"],"pdf_url":"https://arxiv.org/pdf/2211.16005v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.15981v1","updated":"2024-10-21T13:06:38Z","published":"2024-10-21T13:06:38Z","title":"Visual Representation Learning Guided By Multi-modal Prior Knowledge","summary":"  Despite the remarkable success of deep neural networks (DNNs) in computer\nvision, they fail to remain high-performing when facing distribution shifts\nbetween training and testing data. In this paper, we propose Knowledge-Guided\nVisual representation learning (KGV), a distribution-based learning approach\nleveraging multi-modal prior knowledge, to improve generalization under\ndistribution shift. We use prior knowledge from two distinct modalities: 1) a\nknowledge graph (KG) with hierarchical and association relationships; and 2)\ngenerated synthetic images of visual elements semantically represented in the\nKG. The respective embeddings are generated from the given modalities in a\ncommon latent space, i.e., visual embeddings from original and synthetic images\nas well as knowledge graph embeddings (KGEs). These embeddings are aligned via\na novel variant of translation-based KGE methods, where the node and relation\nembeddings of the KG are modeled as Gaussian distributions and translations\nrespectively. We claim that incorporating multi-model prior knowledge enables\nmore regularized learning of image representations. Thus, the models are able\nto better generalize across different data distributions. We evaluate KGV on\ndifferent image classification tasks with major or minor distribution shifts,\nnamely road sign classification across datasets from Germany, China, and\nRussia, image classification with the mini-ImageNet dataset and its variants,\nas well as the DVM-CAR dataset. The results demonstrate that KGV consistently\nexhibits higher accuracy and data efficiency than the baselines across all\nexperiments.\n","authors":["Hongkuan Zhou","Lavdim Halilaj","Sebastian Monka","Stefan Schmid","Yuqicheng Zhu","Bo Xiong","Steffen Staab"],"pdf_url":"https://arxiv.org/pdf/2410.15981v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.15980v1","updated":"2024-10-21T13:06:21Z","published":"2024-10-21T13:06:21Z","title":"Granularity Matters in Long-Tail Learning","summary":"  Balancing training on long-tail data distributions remains a long-standing\nchallenge in deep learning. While methods such as re-weighting and re-sampling\nhelp alleviate the imbalance issue, limited sample diversity continues to\nhinder models from learning robust and generalizable feature representations,\nparticularly for tail classes. In contrast to existing methods, we offer a\nnovel perspective on long-tail learning, inspired by an observation: datasets\nwith finer granularity tend to be less affected by data imbalance. In this\npaper, we investigate this phenomenon through both quantitative and qualitative\nstudies, showing that increased granularity enhances the generalization of\nlearned features in tail categories. Motivated by these findings, we propose a\nmethod to increase dataset granularity through category extrapolation.\nSpecifically, we introduce open-set auxiliary classes that are visually similar\nto existing ones, aiming to enhance representation learning for both head and\ntail classes. This forms the core contribution and insight of our approach. To\nautomate the curation of auxiliary data, we leverage large language models\n(LLMs) as knowledge bases to search for auxiliary categories and retrieve\nrelevant images through web crawling. To prevent the overwhelming presence of\nauxiliary classes from disrupting training, we introduce a neighbor-silencing\nloss that encourages the model to focus on class discrimination within the\ntarget dataset. During inference, the classifier weights for auxiliary\ncategories are masked out, leaving only the target class weights for use.\nExtensive experiments and ablation studies on three standard long-tail\nbenchmarks demonstrate the effectiveness of our approach, notably outperforming\nstrong baseline methods that use the same amount of data. The code will be made\npublicly available.\n","authors":["Shizhen Zhao","Xin Wen","Jiahui Liu","Chuofan Ma","Chunfeng Yuan","Xiaojuan Qi"],"pdf_url":"https://arxiv.org/pdf/2410.15980v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.15971v1","updated":"2024-10-21T12:58:19Z","published":"2024-10-21T12:58:19Z","title":"Zero-Shot Scene Reconstruction from Single Images with Deep Prior\n  Assembly","summary":"  Large language and vision models have been leading a revolution in visual\ncomputing. By greatly scaling up sizes of data and model parameters, the large\nmodels learn deep priors which lead to remarkable performance in various tasks.\nIn this work, we present deep prior assembly, a novel framework that assembles\ndiverse deep priors from large models for scene reconstruction from single\nimages in a zero-shot manner. We show that this challenging task can be done\nwithout extra knowledge but just simply generalizing one deep prior in one\nsub-task. To this end, we introduce novel methods related to poses, scales, and\nocclusion parsing which are keys to enable deep priors to work together in a\nrobust way. Deep prior assembly does not require any 3D or 2D data-driven\ntraining in the task and demonstrates superior performance in generalizing\npriors to open-world scenes. We conduct evaluations on various datasets, and\nreport analysis, numerical and visual comparisons with the latest methods to\nshow our superiority. Project page:\nhttps://junshengzhou.github.io/DeepPriorAssembly.\n","authors":["Junsheng Zhou","Yu-Shen Liu","Zhizhong Han"],"pdf_url":"https://arxiv.org/pdf/2410.15971v1.pdf","comment":"To appear at NeurIPS 2024. Project page:\n  https://junshengzhou.github.io/DeepPriorAssembly"},{"id":"http://arxiv.org/abs/2405.17991v2","updated":"2024-10-21T12:53:21Z","published":"2024-05-28T09:23:14Z","title":"VeLoRA: Memory Efficient Training using Rank-1 Sub-Token Projections","summary":"  Large language models (LLMs) have recently emerged as powerful tools for\ntackling many language-processing tasks. Despite their success, training and\nfine-tuning these models is still far too computationally and memory intensive.\nIn this paper, we identify and characterise the important components needed for\neffective model convergence using gradient descent. In doing so we find that\nthe intermediate activations used to implement backpropagation can be\nexcessively compressed without incurring any degradation in performance. This\nresult leads us to a cheap and memory-efficient algorithm for both fine-tuning\nand pre-training LLMs. The proposed algorithm simply divides the tokens up into\nsmaller sub-tokens before projecting them onto a fixed 1-dimensional subspace\nduring the forward pass. These features are then coarsely reconstructed during\nthe backward pass to implement the update rules. We confirm the effectiveness\nof our algorithm as being complimentary to many state-of-the-art PEFT methods\non the VTAB-1k fine-tuning benchmark. Furthermore, we outperform QLoRA for\nfine-tuning LLaMA and show competitive performance against other\nmemory-efficient pre-training methods on the large-scale C4 dataset.\n","authors":["Roy Miles","Pradyumna Reddy","Ismail Elezi","Jiankang Deng"],"pdf_url":"https://arxiv.org/pdf/2405.17991v2.pdf","comment":"NeurIPS 2024. Code available at https://github.com/roymiles/VeLoRA"},{"id":"http://arxiv.org/abs/2410.15961v1","updated":"2024-10-21T12:47:36Z","published":"2024-10-21T12:47:36Z","title":"A Paradigm Shift in Mouza Map Vectorization: A Human-Machine\n  Collaboration Approach","summary":"  Efficient vectorization of hand-drawn cadastral maps, such as Mouza maps in\nBangladesh, poses a significant challenge due to their complex structures.\nCurrent manual digitization methods are time-consuming and labor-intensive. Our\nstudy proposes a semi-automated approach to streamline the digitization\nprocess, saving both time and human resources. Our methodology focuses on\nseparating the plot boundaries and plot identifiers and applying our\ndigitization methodology to convert both of them into vectorized format. To\naccomplish full vectorization, Convolutional Neural Network (CNN) models are\nutilized for pre-processing and plot number detection along with our smoothing\nalgorithms based on the diversity of vector maps. The CNN models are trained\nwith our own labeled dataset, generated from the maps, and smoothing algorithms\nare introduced from the various observations of the map's vector formats.\nFurther human intervention remains essential for precision. We have evaluated\nour methods on several maps and provided both quantitative and qualitative\nresults with user study. The result demonstrates that our methodology\noutperforms the existing map digitization processes significantly.\n","authors":["Mahir Shahriar Dhrubo","Samira Akter","Anwarul Bashir Shuaib","Md Toki Tahmid","Zahid Hasan","A. B. M. Alim Al Islam"],"pdf_url":"https://arxiv.org/pdf/2410.15961v1.pdf","comment":"13 pages including reference, 14 figures, 4 tables"},{"id":"http://arxiv.org/abs/2410.15959v1","updated":"2024-10-21T12:43:54Z","published":"2024-10-21T12:43:54Z","title":"Diffusion Transformer Policy","summary":"  Recent large visual-language action models pretrained on diverse robot\ndatasets have demonstrated the potential for generalizing to new environments\nwith a few in-domain data. However, those approaches usually predict\ndiscretized or continuous actions by a small action head, which limits the\nability in handling diverse action spaces. In contrast, we model the continuous\naction with a large multi-modal diffusion transformer, dubbed as Diffusion\nTransformer Policy, in which we directly denoise action chunks by a large\ntransformer model rather than a small action head. By leveraging the scaling\ncapability of transformers, the proposed approach can effectively model\ncontinuous end-effector actions across large diverse robot datasets, and\nachieve better generalization performance. Extensive experiments demonstrate\nDiffusion Transformer Policy pretrained on diverse robot data can generalize to\ndifferent embodiments, including simulation environments like Maniskill2 and\nCalvin, as well as the real-world Franka arm. Specifically, without bells and\nwhistles, the proposed approach achieves state-of-the-art performance with only\na single third-view camera stream in the Calvin novel task setting (ABC->D),\nimproving the average number of tasks completed in a row of 5 to 3.6, and the\npretraining stage significantly facilitates the success sequence length on the\nCalvin by over 1.2. The code will be publicly available.\n","authors":["Zhi Hou","Tianyi Zhang","Yuwen Xiong","Hengjun Pu","Chengyang Zhao","Ronglei Tong","Yu Qiao","Jifeng Dai","Yuntao Chen"],"pdf_url":"https://arxiv.org/pdf/2410.15959v1.pdf","comment":"Preprint"},{"id":"http://arxiv.org/abs/2410.15957v1","updated":"2024-10-21T12:36:27Z","published":"2024-10-21T12:36:27Z","title":"CamI2V: Camera-Controlled Image-to-Video Diffusion Model","summary":"  Recently, camera pose, as a user-friendly and physics-related condition, has\nbeen introduced into text-to-video diffusion model for camera control. However,\nexisting methods simply inject camera conditions through a side input. These\napproaches neglect the inherent physical knowledge of camera pose, resulting in\nimprecise camera control, inconsistencies, and also poor interpretability. In\nthis paper, we emphasize the necessity of integrating explicit physical\nconstraints into model design. Epipolar attention is proposed for modeling all\ncross-frame relationships from a novel perspective of noised condition. This\nensures that features are aggregated from corresponding epipolar lines in all\nnoised frames, overcoming the limitations of current attention mechanisms in\ntracking displaced features across frames, especially when features move\nsignificantly with the camera and become obscured by noise. Additionally, we\nintroduce register tokens to handle cases without intersections between frames,\ncommonly caused by rapid camera movements, dynamic objects, or occlusions. To\nsupport image-to-video, we propose the multiple guidance scale to allow for\nprecise control for image, text, and camera, respectively. Furthermore, we\nestablish a more robust and reproducible evaluation pipeline to solve the\ninaccuracy and instability of existing camera control measurement. We achieve a\n25.5\\% improvement in camera controllability on RealEstate10K while maintaining\nstrong generalization to out-of-domain images. Only 24GB and 12GB are required\nfor training and inference, respectively. We plan to release checkpoints, along\nwith training and evaluation codes. Dynamic videos are best viewed at\n\\url{https://zgctroy.github.io/CamI2V}.\n","authors":["Guangcong Zheng","Teng Li","Rui Jiang","Yehao Lu","Tao Wu","Xi Li"],"pdf_url":"https://arxiv.org/pdf/2410.15957v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.15947v1","updated":"2024-10-21T12:26:53Z","published":"2024-10-21T12:26:53Z","title":"AI-Driven Approaches for Glaucoma Detection -- A Comprehensive Review","summary":"  The diagnosis of glaucoma plays a critical role in the management and\ntreatment of this vision-threatening disease. Glaucoma is a group of eye\ndiseases that cause blindness by damaging the optic nerve at the back of the\neye. Often called \"silent thief of sight\", it exhibits no symptoms during the\nearly stages. Therefore, early detection is crucial to prevent vision loss.\nWith the rise of Artificial Intelligence (AI), particularly Deep Learning (DL)\ntechniques, Computer-Aided Diagnosis (CADx) systems have emerged as promising\ntools to assist clinicians in accurately diagnosing glaucoma early. This paper\naims to provide a comprehensive overview of AI techniques utilized in CADx\nsystems for glaucoma diagnosis. Through a detailed analysis of current\nliterature, we identify key gaps and challenges in these systems, emphasizing\nthe need for improved safety, reliability, interpretability, and\nexplainability. By identifying research gaps, we aim to advance the field of\nCADx systems especially for the early diagnosis of glaucoma, in order to\nprevent any potential loss of vision.\n","authors":["Yuki Hagiwara","Octavia-Andreaa Ciora","Maureen Monnet","Gino Lancho","Jeanette Miriam Lorenz"],"pdf_url":"https://arxiv.org/pdf/2410.15947v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.15941v1","updated":"2024-10-21T12:13:43Z","published":"2024-10-21T12:13:43Z","title":"MBPU: A Plug-and-Play State Space Model for Point Cloud Upsamping with\n  Fast Point Rendering","summary":"  The task of point cloud upsampling (PCU) is to generate dense and uniform\npoint clouds from sparse input captured by 3D sensors like LiDAR, holding\npotential applications in real yet is still a challenging task. Existing deep\nlearning-based methods have shown significant achievements in this field.\nHowever, they still face limitations in effectively handling long sequences and\naddressing the issue of shrinkage artifacts around the surface of the point\ncloud. Inspired by the newly proposed Mamba, in this paper, we introduce a\nnetwork named MBPU built on top of the Mamba architecture, which performs well\nin long sequence modeling, especially for large-scale point cloud upsampling,\nand achieves fast convergence speed. Moreover, MBPU is an arbitrary-scale\nupsampling framework as the predictor of point distance in the point refinement\nphase. At the same time, we simultaneously predict the 3D position shift and 1D\npoint-to-point distance as regression quantities to constrain the global\nfeatures while ensuring the accuracy of local details. We also introduce a fast\ndifferentiable renderer to further enhance the fidelity of the upsampled point\ncloud and reduce artifacts. It is noted that, by the merits of our fast point\nrendering, MBPU yields high-quality upsampled point clouds by effectively\neliminating surface noise. Extensive experiments have demonstrated that our\nMBPU outperforms other off-the-shelf methods in terms of point cloud\nupsampling, especially for large-scale point clouds.\n","authors":["Jiayi Song","Weidong Yang","Zhijun Li","Wen-Ming Chen","Ben Fei"],"pdf_url":"https://arxiv.org/pdf/2410.15941v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.15932v1","updated":"2024-10-21T12:00:52Z","published":"2024-10-21T12:00:52Z","title":"Focus on BEV: Self-calibrated Cycle View Transformation for Monocular\n  Birds-Eye-View Segmentation","summary":"  Birds-Eye-View (BEV) segmentation aims to establish a spatial mapping from\nthe perspective view to the top view and estimate the semantic maps from\nmonocular images. Recent studies have encountered difficulties in view\ntransformation due to the disruption of BEV-agnostic features in image space.\nTo tackle this issue, we propose a novel FocusBEV framework consisting of $(i)$\na self-calibrated cross view transformation module to suppress the BEV-agnostic\nimage areas and focus on the BEV-relevant areas in the view transformation\nstage, $(ii)$ a plug-and-play ego-motion-based temporal fusion module to\nexploit the spatiotemporal structure consistency in BEV space with a memory\nbank, and $(iii)$ an occupancy-agnostic IoU loss to mitigate both semantic and\npositional uncertainties. Experimental evidence demonstrates that our approach\nachieves new state-of-the-art on two popular benchmarks,\\ie, 29.2\\% mIoU on\nnuScenes and 35.2\\% mIoU on Argoverse.\n","authors":["Jiawei Zhao","Qixing Jiang","Xuede Li","Junfeng Luo"],"pdf_url":"https://arxiv.org/pdf/2410.15932v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.07255v3","updated":"2024-10-21T11:57:29Z","published":"2024-06-11T13:34:57Z","title":"Towards Realistic Data Generation for Real-World Super-Resolution","summary":"  Existing image super-resolution (SR) techniques often fail to generalize\neffectively in complex real-world settings due to the significant divergence\nbetween training data and practical scenarios. To address this challenge,\nprevious efforts have either manually simulated intricate physical-based\ndegradations or utilized learning-based techniques, yet these approaches remain\ninadequate for producing large-scale, realistic, and diverse data\nsimultaneously. In this paper, we introduce a novel Realistic Decoupled Data\nGenerator (RealDGen), an unsupervised learning data generation framework\ndesigned for real-world super-resolution. We meticulously develop content and\ndegradation extraction strategies, which are integrated into a novel\ncontent-degradation decoupled diffusion model to create realistic\nlow-resolution images from unpaired real LR and HR images. Extensive\nexperiments demonstrate that RealDGen excels in generating large-scale,\nhigh-quality paired data that mirrors real-world degradations, significantly\nadvancing the performance of popular SR models on various real-world\nbenchmarks.\n","authors":["Long Peng","Wenbo Li","Renjing Pei","Jingjing Ren","Yang Wang","Yang Cao","Zheng-Jun Zha"],"pdf_url":"https://arxiv.org/pdf/2406.07255v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.15927v1","updated":"2024-10-21T11:55:06Z","published":"2024-10-21T11:55:06Z","title":"GReFEL: Geometry-Aware Reliable Facial Expression Learning under Bias\n  and Imbalanced Data Distribution","summary":"  Reliable facial expression learning (FEL) involves the effective learning of\ndistinctive facial expression characteristics for more reliable, unbiased and\naccurate predictions in real-life settings. However, current systems struggle\nwith FEL tasks because of the variance in people's facial expressions due to\ntheir unique facial structures, movements, tones, and demographics. Biased and\nimbalanced datasets compound this challenge, leading to wrong and biased\nprediction labels. To tackle these, we introduce GReFEL, leveraging Vision\nTransformers and a facial geometry-aware anchor-based reliability balancing\nmodule to combat imbalanced data distributions, bias, and uncertainty in facial\nexpression learning. Integrating local and global data with anchors that learn\ndifferent facial data points and structural features, our approach adjusts\nbiased and mislabeled emotions caused by intra-class disparity, inter-class\nsimilarity, and scale sensitivity, resulting in comprehensive, accurate, and\nreliable facial expression predictions. Our model outperforms current\nstate-of-the-art methodologies, as demonstrated by extensive experiments on\nvarious datasets.\n","authors":["Azmine Toushik Wasi","Taki Hasan Rafi","Raima Islam","Karlo Serbetar","Dong Kyu Chae"],"pdf_url":"https://arxiv.org/pdf/2410.15927v1.pdf","comment":"ACCV 2024. Extended version of ARBEx (arXiv:2305.01486)"},{"id":"http://arxiv.org/abs/2410.15926v1","updated":"2024-10-21T11:54:53Z","published":"2024-10-21T11:54:53Z","title":"Mitigating Object Hallucination via Concentric Causal Attention","summary":"  Recent Large Vision Language Models (LVLMs) present remarkable zero-shot\nconversational and reasoning capabilities given multimodal queries.\nNevertheless, they suffer from object hallucination, a phenomenon where LVLMs\nare prone to generate textual responses not factually aligned with image\ninputs. Our pilot study reveals that object hallucination is closely tied with\nRotary Position Encoding (RoPE), a widely adopted positional dependency\nmodeling design in existing LVLMs. Due to the long-term decay in RoPE, LVLMs\ntend to hallucinate more when relevant visual cues are distant from instruction\ntokens in the multimodal input sequence. Additionally, we observe a similar\neffect when reversing the sequential order of visual tokens during multimodal\nalignment. Our tests indicate that long-term decay in RoPE poses challenges to\nLVLMs while capturing visual-instruction interactions across long distances. We\npropose Concentric Causal Attention (CCA), a simple yet effective positional\nalignment strategy that mitigates the impact of RoPE long-term decay in LVLMs\nby naturally reducing relative distance between visual and instruction tokens.\nWith CCA, visual tokens can better interact with instruction tokens, thereby\nenhancing model's perception capability and alleviating object hallucination.\nWithout bells and whistles, our positional alignment method surpasses existing\nhallucination mitigation strategies by large margins on multiple object\nhallucination benchmarks.\n","authors":["Yun Xing","Yiheng Li","Ivan Laptev","Shijian Lu"],"pdf_url":"https://arxiv.org/pdf/2410.15926v1.pdf","comment":"To appear at NeurIPS 2024. Code is available at\n  https://github.com/xing0047/cca-llava"},{"id":"http://arxiv.org/abs/2408.11958v2","updated":"2024-10-21T11:49:56Z","published":"2024-08-21T19:25:03Z","title":"CARLA Drone: Monocular 3D Object Detection from a Different Perspective","summary":"  Existing techniques for monocular 3D detection have a serious restriction.\nThey tend to perform well only on a limited set of benchmarks, faring well\neither on ego-centric car views or on traffic camera views, but rarely on both.\nTo encourage progress, this work advocates for an extended evaluation of 3D\ndetection frameworks across different camera perspectives. We make two key\ncontributions. First, we introduce the CARLA Drone dataset, CDrone. Simulating\ndrone views, it substantially expands the diversity of camera perspectives in\nexisting benchmarks. Despite its synthetic nature, CDrone represents a\nreal-world challenge. To show this, we confirm that previous techniques\nstruggle to perform well both on CDrone and a real-world 3D drone dataset.\nSecond, we develop an effective data augmentation pipeline called GroundMix.\nIts distinguishing element is the use of the ground for creating 3D-consistent\naugmentation of a training image. GroundMix significantly boosts the detection\naccuracy of a lightweight one-stage detector. In our expanded evaluation, we\nachieve the average precision on par with or substantially higher than the\nprevious state of the art across all tested datasets.\n","authors":["Johannes Meier","Luca Scalerandi","Oussema Dhaouadi","Jacques Kaiser","Nikita Araslanov","Daniel Cremers"],"pdf_url":"https://arxiv.org/pdf/2408.11958v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.15919v1","updated":"2024-10-21T11:49:10Z","published":"2024-10-21T11:49:10Z","title":"Are Large-scale Soft Labels Necessary for Large-scale Dataset\n  Distillation?","summary":"  In ImageNet-condensation, the storage for auxiliary soft labels exceeds that\nof the condensed dataset by over 30 times. However, are large-scale soft labels\nnecessary for large-scale dataset distillation? In this paper, we first\ndiscover that the high within-class similarity in condensed datasets\nnecessitates the use of large-scale soft labels. This high within-class\nsimilarity can be attributed to the fact that previous methods use samples from\ndifferent classes to construct a single batch for batch normalization (BN)\nmatching. To reduce the within-class similarity, we introduce class-wise\nsupervision during the image synthesizing process by batching the samples\nwithin classes, instead of across classes. As a result, we can increase\nwithin-class diversity and reduce the size of required soft labels. A key\nbenefit of improved image diversity is that soft label compression can be\nachieved through simple random pruning, eliminating the need for complex\nrule-based strategies. Experiments validate our discoveries. For example, when\ncondensing ImageNet-1K to 200 images per class, our approach compresses the\nrequired soft labels from 113 GB to 2.8 GB (40x compression) with a 2.6%\nperformance gain. Code is available at:\nhttps://github.com/he-y/soft-label-pruning-for-dataset-distillation\n","authors":["Lingao Xiao","Yang He"],"pdf_url":"https://arxiv.org/pdf/2410.15919v1.pdf","comment":"Accepted by Neurips 2024"},{"id":"http://arxiv.org/abs/2410.15916v1","updated":"2024-10-21T11:46:28Z","published":"2024-10-21T11:46:28Z","title":"Leveraging CORAL-Correlation Consistency Network for Semi-Supervised\n  Left Atrium MRI Segmentation","summary":"  Semi-supervised learning (SSL) has been widely used to learn from both a few\nlabeled images and many unlabeled images to overcome the scarcity of labeled\nsamples in medical image segmentation. Most current SSL-based segmentation\nmethods use pixel values directly to identify similar features in labeled and\nunlabeled data. They usually fail to accurately capture the intricate\nattachment structures in the left atrium, such as the areas of inconsistent\ndensity or exhibit outward curvatures, adding to the complexity of the task. In\nthis paper, we delve into this issue and introduce an effective solution,\nCORAL(Correlation-Aligned)-Correlation Consistency Network (CORN), to capture\nthe global structure shape and local details of Left Atrium. Diverging from\nprevious methods focused on each local pixel value, the CORAL-Correlation\nConsistency Module (CCM) in the CORN leverages second-order statistical\ninformation to capture global structural features by minimizing the\ndistribution discrepancy between labeled and unlabeled samples in feature\nspace. Yet, direct construction of features from unlabeled data frequently\nresults in ``Sample Selection Bias'', leading to flawed supervision. We thus\nfurther propose the Dynamic Feature Pool (DFP) for the CCM, which utilizes a\nconfidence-based filtering strategy to remove incorrectly selected features and\nregularize both teacher and student models by constraining the similarity\nmatrix to be consistent. Extensive experiments on the Left Atrium dataset have\nshown that the proposed CORN outperforms previous state-of-the-art\nsemi-supervised learning methods.\n","authors":["Xinze Li","Runlin Huang","Zhenghao Wu","Bohan Yang","Wentao Fan","Chengzhang Zhu","Weifeng Su"],"pdf_url":"https://arxiv.org/pdf/2410.15916v1.pdf","comment":"5 pages, 3 figures, Accepted by 2024 IEEE International Conference on\n  Bioinformatics and Biomedicine (BIBM 2024)"},{"id":"http://arxiv.org/abs/2403.17633v4","updated":"2024-10-21T11:34:27Z","published":"2024-03-26T12:08:14Z","title":"UADA3D: Unsupervised Adversarial Domain Adaptation for 3D Object\n  Detection with Sparse LiDAR and Large Domain Gaps","summary":"  In this study, we address a gap in existing unsupervised domain adaptation\napproaches on LiDAR-based 3D object detection, which have predominantly\nconcentrated on adapting between established, high-density autonomous driving\ndatasets. We focus on sparser point clouds, capturing scenarios from different\nperspectives: not just from vehicles on the road but also from mobile robots on\nsidewalks, which encounter significantly different environmental conditions and\nsensor configurations. We introduce Unsupervised Adversarial Domain Adaptation\nfor 3D Object Detection (UADA3D). UADA3D does not depend on pre-trained source\nmodels or teacher-student architectures. Instead, it uses an adversarial\napproach to directly learn domain-invariant features. We demonstrate its\nefficacy in various adaptation scenarios, showing significant improvements in\nboth self-driving car and mobile robot domains. Our code is open-source and\nwill be available soon.\n","authors":["Maciej K Wozniak","Mattias Hansson","Marko Thiel","Patric Jensfelt"],"pdf_url":"https://arxiv.org/pdf/2403.17633v4.pdf","comment":"Accepted for IEEE RA-L 2024"},{"id":"http://arxiv.org/abs/2410.15909v1","updated":"2024-10-21T11:32:46Z","published":"2024-10-21T11:32:46Z","title":"Hybrid Architecture for Real-Time Video Anomaly Detection: Integrating\n  Spatial and Temporal Analysis","summary":"  We propose a new architecture for real-time anomaly detection in video data,\ninspired by human behavior by combining spatial and temporal analyses. This\napproach uses two distinct models: for temporal analysis, a recurrent\nconvolutional network (CNN + RNN) is employed, associating VGG19 and a GRU to\nprocess video sequences. Regarding spatial analysis, it is performed using\nYOLOv7 to analyze individual images. These two analyses can be carried out\neither in parallel, with a final prediction that combines the results of both\nanalyses, or in series, where the spatial analysis enriches the data before the\ntemporal analysis. In this article, we will compare these two architectural\nconfigurations with each other, to evaluate the effectiveness of our hybrid\napproach in video anomaly detection.\n","authors":["Fabien Poirier"],"pdf_url":"https://arxiv.org/pdf/2410.15909v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.15907v1","updated":"2024-10-21T11:29:35Z","published":"2024-10-21T11:29:35Z","title":"Seismic Phase Picking","summary":"  Seismic phase picking, which aims to determine the arrival time of P- and\nS-waves according to seismic waveforms, is fundamental to earthquake\nmonitoring. Generally, manual phase picking is trustworthy, but with the\nincreasing number of worldwide stations and seismic monitors, it becomes more\nchallenging for human to complete the task comprehensively. In this work, we\nexplore multiple ways to do automatic phase picking, including traditional and\nlearning-based methods.\n","authors":["Yuchen Wang","Ruihuan Wang"],"pdf_url":"https://arxiv.org/pdf/2410.15907v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.07758v2","updated":"2024-10-21T11:12:38Z","published":"2024-10-10T09:37:33Z","title":"HeightFormer: A Semantic Alignment Monocular 3D Object Detection Method\n  from Roadside Perspective","summary":"  The on-board 3D object detection technology has received extensive attention\nas a critical technology for autonomous driving, while few studies have focused\non applying roadside sensors in 3D traffic object detection. Existing studies\nachieve the projection of 2D image features to 3D features through height\nestimation based on the frustum. However, they did not consider the height\nalignment and the extraction efficiency of bird's-eye-view features. We propose\na novel 3D object detection framework integrating Spatial Former and Voxel\nPooling Former to enhance 2D-to-3D projection based on height estimation.\nExtensive experiments were conducted using the Rope3D and DAIR-V2X-I dataset,\nand the results demonstrated the outperformance of the proposed algorithm in\nthe detection of both vehicles and cyclists. These results indicate that the\nalgorithm is robust and generalized under various detection scenarios.\nImproving the accuracy of 3D object detection on the roadside is conducive to\nbuilding a safe and trustworthy intelligent transportation system of\nvehicle-road coordination and promoting the large-scale application of\nautonomous driving. The code and pre-trained models will be released on\nhttps://anonymous.4open.science/r/HeightFormer.\n","authors":["Pei Liu","Zihao Zhang","Haipeng Liu","Nanfang Zheng","Meixin Zhu","Ziyuan Pu"],"pdf_url":"https://arxiv.org/pdf/2410.07758v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.15891v1","updated":"2024-10-21T11:10:07Z","published":"2024-10-21T11:10:07Z","title":"TexPro: Text-guided PBR Texturing with Procedural Material Modeling","summary":"  In this paper, we present TexPro, a novel method for high-fidelity material\ngeneration for input 3D meshes given text prompts. Unlike existing\ntext-conditioned texture generation methods that typically generate RGB\ntextures with baked lighting, TexPro is able to produce diverse texture maps\nvia procedural material modeling, which enables physical-based rendering,\nrelighting, and additional benefits inherent to procedural materials.\nSpecifically, we first generate multi-view reference images given the input\ntextual prompt by employing the latest text-to-image model. We then derive\ntexture maps through a rendering-based optimization with recent differentiable\nprocedural materials. To this end, we design several techniques to handle the\nmisalignment between the generated multi-view images and 3D meshes, and\nintroduce a novel material agent that enhances material classification and\nmatching by exploring both part-level understanding and object-aware material\nreasoning. Experiments demonstrate the superiority of the proposed method over\nexisting SOTAs and its capability of relighting.\n","authors":["Ziqiang Dang","Wenqi Dong","Zesong Yang","Bangbang Yang","Liang Li","Yuewen Ma","Zhaopeng Cui"],"pdf_url":"https://arxiv.org/pdf/2410.15891v1.pdf","comment":"In submission. Supplementary material is included at the end of the\n  main paper (5 pages, 2 figures)"},{"id":"http://arxiv.org/abs/2410.15886v1","updated":"2024-10-21T11:04:58Z","published":"2024-10-21T11:04:58Z","title":"Foundation Models for Slide-level Cancer Subtyping in Digital Pathology","summary":"  Since the emergence of the ImageNet dataset, the pretraining and fine-tuning\napproach has become widely adopted in computer vision due to the ability of\nImageNet-pretrained models to learn a wide variety of visual features. However,\na significant challenge arises when adapting these models to domain-specific\nfields, such as digital pathology, due to substantial gaps between domains. To\naddress this limitation, foundation models (FM) have been trained on\nlarge-scale in-domain datasets to learn the intricate features of\nhistopathology images. In cancer diagnosis, whole-slide image (WSI) prediction\nis essential for patient prognosis, and multiple instance learning (MIL) has\nbeen implemented to handle the giga-pixel size of WSI. As MIL frameworks rely\non patch-level feature aggregation, this work aims to compare the performance\nof various feature extractors developed under different pretraining strategies\nfor cancer subtyping on WSI under a MIL framework. Results demonstrate the\nability of foundation models to surpass ImageNet-pretrained models for the\nprediction of six skin cancer subtypes\n","authors":["Pablo Meseguer","Rocío del Amor","Adrian Colomer","Valery Naranjo"],"pdf_url":"https://arxiv.org/pdf/2410.15886v1.pdf","comment":"Manuscript accepted for oral presentation at Decision Science\n  Allieance -INternational Summer Conference (DSA-ISC) 2024 held on Valencia,\n  Spain"},{"id":"http://arxiv.org/abs/2408.17433v2","updated":"2024-10-21T11:01:46Z","published":"2024-08-30T17:35:06Z","title":"DARES: Depth Anything in Robotic Endoscopic Surgery with Self-supervised\n  Vector-LoRA of the Foundation Model","summary":"  Robotic-assisted surgery (RAS) relies on accurate depth estimation for 3D\nreconstruction and visualization. While foundation models like Depth Anything\nModels (DAM) show promise, directly applying them to surgery often yields\nsuboptimal results. Fully fine-tuning on limited surgical data can cause\noverfitting and catastrophic forgetting, compromising model robustness and\ngeneralization. Although Low-Rank Adaptation (LoRA) addresses some adaptation\nissues, its uniform parameter distribution neglects the inherent feature\nhierarchy, where earlier layers, learning more general features, require more\nparameters than later ones. To tackle this issue, we introduce Depth Anything\nin Robotic Endoscopic Surgery (DARES), a novel approach that employs a new\nadaptation technique, Vector Low-Rank Adaptation (Vector-LoRA) on the DAM V2 to\nperform self-supervised monocular depth estimation in RAS scenes. To enhance\nlearning efficiency, we introduce Vector-LoRA by integrating more parameters in\nearlier layers and gradually decreasing parameters in later layers. We also\ndesign a reprojection loss based on the multi-scale SSIM error to enhance depth\nperception by better tailoring the foundation model to the specific\nrequirements of the surgical environment. The proposed method is validated on\nthe SCARED dataset and demonstrates superior performance over recent\nstate-of-the-art self-supervised monocular depth estimation techniques,\nachieving an improvement of 13.3% in the absolute relative error metric. The\ncode and pre-trained weights are available at\nhttps://github.com/mobarakol/DARES.\n","authors":["Mona Sheikh Zeinoddin","Chiara Lena","Jiongqi Qu","Luca Carlini","Mattia Magro","Seunghoi Kim","Elena De Momi","Sophia Bano","Matthew Grech-Sollars","Evangelos Mazomenos","Daniel C. Alexander","Danail Stoyanov","Matthew J. Clarkson","Mobarakol Islam"],"pdf_url":"https://arxiv.org/pdf/2408.17433v2.pdf","comment":"11 pages"},{"id":"http://arxiv.org/abs/2410.15882v1","updated":"2024-10-21T11:01:44Z","published":"2024-10-21T11:01:44Z","title":"Distributed Learning for UAV Swarms","summary":"  Unmanned Aerial Vehicle (UAV) swarms are increasingly deployed in dynamic,\ndata-rich environments for applications such as environmental monitoring and\nsurveillance. These scenarios demand efficient data processing while\nmaintaining privacy and security, making Federated Learning (FL) a promising\nsolution. FL allows UAVs to collaboratively train global models without sharing\nraw data, but challenges arise due to the non-Independent and Identically\nDistributed (non-IID) nature of the data collected by UAVs. In this study, we\nshow an integration of the state-of-the-art FL methods to UAV Swarm application\nand invetigate the performance of multiple aggregation methods (namely FedAvg,\nFedProx, FedOpt, and MOON) with a particular focus on tackling non-IID on a\nvariety of datasets, specifically MNIST for baseline performance, CIFAR10 for\nnatural object classification, EuroSAT for environment monitoring, and CelebA\nfor surveillance. These algorithms were selected to cover improved techniques\non both client-side updates and global aggregation. Results show that while all\nalgorithms perform comparably on IID data, their performance deteriorates\nsignificantly under non-IID conditions. FedProx demonstrated the most stable\noverall performance, emphasising the importance of regularising local updates\nin non-IID environments to mitigate drastic deviations in local models.\n","authors":["Chen Hu","Hanchi Ren","Jingjing Deng","Xianghua Xie"],"pdf_url":"https://arxiv.org/pdf/2410.15882v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.15881v1","updated":"2024-10-21T11:01:20Z","published":"2024-10-21T11:01:20Z","title":"MI-VisionShot: Few-shot adaptation of vision-language models for\n  slide-level classification of histopathological images","summary":"  Vision-language supervision has made remarkable strides in learning visual\nrepresentations from textual guidance. In digital pathology, vision-language\nmodels (VLM), pre-trained on curated datasets of histological image-captions,\nhave been adapted to downstream tasks, such as region of interest\nclassification. Zero-shot transfer for slide-level prediction has been\nformulated by MI-Zero, but it exhibits high variability depending on the\ntextual prompts. Inspired by prototypical learning, we propose MI-VisionShot, a\ntraining-free adaptation method on top of VLMs to predict slide-level labels in\nfew-shot learning scenarios. Our framework takes advantage of the excellent\nrepresentation learning of VLM to create prototype-based classifiers under a\nmultiple-instance setting by retrieving the most discriminative patches within\neach slide. Experimentation through different settings shows the ability of\nMI-VisionShot to surpass zero-shot transfer with lower variability, even in\nlow-shot scenarios. Code coming soon at\nthttps://github.com/cvblab/MIVisionShot.\n","authors":["Pablo Meseguer","Rocío del Amor","Valery Naranjo"],"pdf_url":"https://arxiv.org/pdf/2410.15881v1.pdf","comment":"Manuscript accepted for oral presentation at KES-InnovationInMedicine\n  2024 held on Madeira, Portugal"},{"id":"http://arxiv.org/abs/2404.07989v3","updated":"2024-10-21T10:54:55Z","published":"2024-04-11T17:59:45Z","title":"Any2Point: Empowering Any-modality Large Models for Efficient 3D\n  Understanding","summary":"  Large foundation models have recently emerged as a prominent focus of\ninterest, attaining superior performance in widespread scenarios. Due to the\nscarcity of 3D data, many efforts have been made to adapt pre-trained\ntransformers from vision to 3D domains. However, such 2D-to-3D approaches are\nstill limited, due to the potential loss of spatial geometries and high\ncomputation cost. More importantly, their frameworks are mainly designed for 2D\nmodels, lacking a general any-to-3D paradigm. In this paper, we introduce\nAny2Point, a parameter-efficient method to empower any-modality large models\n(vision, language, audio) for 3D understanding. Given a frozen transformer from\nany source modality, we propose a 3D-to-any (1D or 2D) virtual projection\nstrategy that correlates the input 3D points to the original 1D or 2D positions\nwithin the source modality. This mechanism enables us to assign each 3D token\nwith a positional encoding paired with the pre-trained model, which avoids 3D\ngeometry loss caused by the true projection and better motivates the\ntransformer for 3D learning with 1D/2D positional priors. Then, within each\ntransformer block, we insert an any-to-3D guided adapter module for\nparameter-efficient fine-tuning. The adapter incorporates prior spatial\nknowledge from the source modality to guide the local feature aggregation of 3D\ntokens, compelling the semantic adaption of any-modality transformers. We\nconduct extensive experiments to showcase the effectiveness and efficiency of\nour method. Code and models are released at\nhttps://github.com/Ivan-Tang-3D/Any2Point.\n","authors":["Yiwen Tang","Ray Zhang","Jiaming Liu","Zoey Guo","Dong Wang","Zhigang Wang","Bin Zhao","Shanghang Zhang","Peng Gao","Hongsheng Li","Xuelong Li"],"pdf_url":"https://arxiv.org/pdf/2404.07989v3.pdf","comment":"Code and models are released at\n  https://github.com/Ivan-Tang-3D/Any2Point"},{"id":"http://arxiv.org/abs/2410.15866v1","updated":"2024-10-21T10:50:00Z","published":"2024-10-21T10:50:00Z","title":"Visual Motif Identification: Elaboration of a Curated Comparative\n  Dataset and Classification Methods","summary":"  In cinema, visual motifs are recurrent iconographic compositions that carry\nartistic or aesthetic significance. Their use throughout the history of visual\narts and media is interesting to researchers and filmmakers alike. Our goal in\nthis work is to recognise and classify these motifs by proposing a new machine\nlearning model that uses a custom dataset to that end. We show how features\nextracted from a CLIP model can be leveraged by using a shallow network and an\nappropriate loss to classify images into 20 different motifs, with surprisingly\ngood results: an $F_1$-score of 0.91 on our test set. We also present several\nablation studies justifying the input features, architecture and\nhyperparameters used.\n","authors":["Adam Phillips","Daniel Grandes Rodriguez","Miriam Sánchez-Manzano","Alan Salvadó","Manuel Garin","Gloria Haro","Coloma Ballester"],"pdf_url":"https://arxiv.org/pdf/2410.15866v1.pdf","comment":"17 pages, 11 figures, one table, to be published in the conference\n  proceedings of ECCV 2024"},{"id":"http://arxiv.org/abs/2310.03059v8","updated":"2024-10-21T10:49:59Z","published":"2023-10-04T16:49:36Z","title":"Point-PEFT: Parameter-Efficient Fine-Tuning for 3D Pre-trained Models","summary":"  The popularity of pre-trained large models has revolutionized downstream\ntasks across diverse fields, such as language, vision, and multi-modality. To\nminimize the adaption cost for downstream tasks, many Parameter-Efficient\nFine-Tuning (PEFT) techniques are proposed for language and 2D image\npre-trained models. However, the specialized PEFT method for 3D pre-trained\nmodels is still under-explored. To this end, we introduce Point-PEFT, a novel\nframework for adapting point cloud pre-trained models with minimal learnable\nparameters. Specifically, for a pre-trained 3D model, we freeze most of its\nparameters, and only tune the newly added PEFT modules on downstream tasks,\nwhich consist of a Point-prior Prompt and a Geometry-aware Adapter. The\nPoint-prior Prompt adopts a set of learnable prompt tokens, for which we\npropose to construct a memory bank with domain-specific knowledge, and utilize\na parameter-free attention to enhance the prompt tokens. The Geometry-aware\nAdapter aims to aggregate point cloud features within spatial neighborhoods to\ncapture fine-grained geometric information through local interactions.\nExtensive experiments indicate that our Point-PEFT can achieve better\nperformance than the full fine-tuning on various downstream tasks, while using\nonly 5% of the trainable parameters, demonstrating the efficiency and\neffectiveness of our approach. Code is released at\nhttps://github.com/Ivan-Tang-3D/Point-PEFT.\n","authors":["Yiwen Tang","Ray Zhang","Zoey Guo","Dong Wang","Zhigang Wang","Bin Zhao","Xuelong Li"],"pdf_url":"https://arxiv.org/pdf/2310.03059v8.pdf","comment":"The specialized PEFT framework for 3D pre-trained models, which\n  achieves competitive performance to full fine-tuning, and significantly\n  reduces the computational resources. Project page:\n  https://github.com/Ivan-Tang-3D/Point-PEFT"},{"id":"http://arxiv.org/abs/2410.15851v1","updated":"2024-10-21T10:27:57Z","published":"2024-10-21T10:27:57Z","title":"R2I-rPPG: A Robust Region of Interest Selection Method for Remote\n  Photoplethysmography to Extract Heart Rate","summary":"  The COVID-19 pandemic has underscored the need for low-cost, scalable\napproaches to measuring contactless vital signs, either during initial triage\nat a healthcare facility or virtual telemedicine visits. Remote\nphotoplethysmography (rPPG) can accurately estimate heart rate (HR) when\napplied to close-up videos of healthy volunteers in well-lit laboratory\nsettings. However, results from such highly optimized laboratory studies may\nnot be readily translated to healthcare settings. One significant barrier to\nthe practical application of rPPG in health care is the accurate localization\nof the region of interest (ROI). Clinical or telemedicine visits may involve\nsub-optimal lighting, movement artifacts, variable camera angle, and subject\ndistance. This paper presents an rPPG ROI selection method based on 3D facial\nlandmarks and patient head yaw angle. We then demonstrate the robustness of\nthis ROI selection method when coupled to the Plane-Orthogonal-to-Skin (POS)\nrPPG method when applied to videos of patients presenting to an Emergency\nDepartment for respiratory complaints. Our results demonstrate the\neffectiveness of our proposed approach in improving the accuracy and robustness\nof rPPG in a challenging clinical environment.\n","authors":["Sandeep Nagar","Mark Hasegawa-Johnson","David G. Beiser","Narendra Ahuja"],"pdf_url":"https://arxiv.org/pdf/2410.15851v1.pdf","comment":"preprint"},{"id":"http://arxiv.org/abs/2410.15847v1","updated":"2024-10-21T10:19:45Z","published":"2024-10-21T10:19:45Z","title":"Random Token Fusion for Multi-View Medical Diagnosis","summary":"  In multi-view medical diagnosis, deep learning-based models often fuse\ninformation from different imaging perspectives to improve diagnostic\nperformance. However, existing approaches are prone to overfitting and rely\nheavily on view-specific features, which can lead to trivial solutions. In this\nwork, we introduce Random Token Fusion (RTF), a novel technique designed to\nenhance multi-view medical image analysis using vision transformers. By\nintegrating randomness into the feature fusion process during training, RTF\naddresses the issue of overfitting and enhances the robustness and accuracy of\ndiagnostic models without incurring any additional cost at inference. We\nvalidate our approach on standard mammography and chest X-ray benchmark\ndatasets. Through extensive experiments, we demonstrate that RTF consistently\nimproves the performance of existing fusion methods, paving the way for a new\ngeneration of multi-view medical foundation models.\n","authors":["Jingyu Guo","Christos Matsoukas","Fredrik Strand","Kevin Smith"],"pdf_url":"https://arxiv.org/pdf/2410.15847v1.pdf","comment":"Originally published at the NeurIPS 2024 Workshop on Advancements In\n  Medical Foundation Models: Explainability, Robustness, Security, and Beyond\n  (AIM-FM)"},{"id":"http://arxiv.org/abs/2410.12284v2","updated":"2024-10-21T10:11:11Z","published":"2024-10-16T06:43:02Z","title":"Fool Me Once? Contrasting Textual and Visual Explanations in a Clinical\n  Decision-Support Setting","summary":"  The growing capabilities of AI models are leading to their wider use,\nincluding in safety-critical domains. Explainable AI (XAI) aims to make these\nmodels safer to use by making their inference process more transparent.\nHowever, current explainability methods are seldom evaluated in the way they\nare intended to be used: by real-world end users. To address this, we conducted\na large-scale user study with 85 healthcare practitioners in the context of\nhuman-AI collaborative chest X-ray analysis. We evaluated three types of\nexplanations: visual explanations (saliency maps), natural language\nexplanations, and a combination of both modalities. We specifically examined\nhow different explanation types influence users depending on whether the AI\nadvice and explanations are factually correct. We find that text-based\nexplanations lead to significant over-reliance, which is alleviated by\ncombining them with saliency maps. We also observe that the quality of\nexplanations, that is, how much factually correct information they entail, and\nhow much this aligns with AI correctness, significantly impacts the usefulness\nof the different explanation types.\n","authors":["Maxime Kayser","Bayar Menzat","Cornelius Emde","Bogdan Bercean","Alex Novak","Abdala Espinosa","Bartlomiej W. Papiez","Susanne Gaube","Thomas Lukasiewicz","Oana-Maria Camburu"],"pdf_url":"https://arxiv.org/pdf/2410.12284v2.pdf","comment":"EMNLP 2024"},{"id":"http://arxiv.org/abs/2410.15833v1","updated":"2024-10-21T09:50:17Z","published":"2024-10-21T09:50:17Z","title":"LiOn-XA: Unsupervised Domain Adaptation via LiDAR-Only Cross-Modal\n  Adversarial Training","summary":"  In this paper, we propose LiOn-XA, an unsupervised domain adaptation (UDA)\napproach that combines LiDAR-Only Cross-Modal (X) learning with Adversarial\ntraining for 3D LiDAR point cloud semantic segmentation to bridge the domain\ngap arising from environmental and sensor setup changes. Unlike existing works\nthat exploit multiple data modalities like point clouds and RGB image data, we\naddress UDA in scenarios where RGB images might not be available and show that\ntwo distinct LiDAR data representations can learn from each other for UDA. More\nspecifically, we leverage 3D voxelized point clouds to preserve important\ngeometric structure in combination with 2D projection-based range images that\nprovide information such as object orientations or surfaces. To further align\nthe feature space between both domains, we apply adversarial training using\nboth features and predictions of both 2D and 3D neural networks. Our\nexperiments on 3 real-to-real adaptation scenarios demonstrate the\neffectiveness of our approach, achieving new state-of-the-art performance when\ncompared to previous uni- and multi-model UDA methods. Our source code is\npublicly available at https://github.com/JensLe97/lion-xa.\n","authors":["Thomas Kreutz","Jens Lemke","Max Mühlhäuser","Alejandro Sanchez Guinea"],"pdf_url":"https://arxiv.org/pdf/2410.15833v1.pdf","comment":"Preprint, Paper has been accepted at IROS2024"},{"id":"http://arxiv.org/abs/2403.05846v2","updated":"2024-10-21T09:38:03Z","published":"2024-03-09T09:11:49Z","title":"Diffusion Lens: Interpreting Text Encoders in Text-to-Image Pipelines","summary":"  Text-to-image diffusion models (T2I) use a latent representation of a text\nprompt to guide the image generation process. However, the process by which the\nencoder produces the text representation is unknown. We propose the Diffusion\nLens, a method for analyzing the text encoder of T2I models by generating\nimages from its intermediate representations. Using the Diffusion Lens, we\nperform an extensive analysis of two recent T2I models. Exploring compound\nprompts, we find that complex scenes describing multiple objects are composed\nprogressively and more slowly compared to simple scenes; Exploring knowledge\nretrieval, we find that representation of uncommon concepts requires further\ncomputation compared to common concepts, and that knowledge retrieval is\ngradual across layers. Overall, our findings provide valuable insights into the\ntext encoder component in T2I pipelines.\n","authors":["Michael Toker","Hadas Orgad","Mor Ventura","Dana Arad","Yonatan Belinkov"],"pdf_url":"https://arxiv.org/pdf/2403.05846v2.pdf","comment":"Published in: ACL 2024 Project webpage:\n  tokeron.github.io/DiffusionLensWeb"},{"id":"http://arxiv.org/abs/2410.15819v1","updated":"2024-10-21T09:35:57Z","published":"2024-10-21T09:35:57Z","title":"LiMTR: Time Series Motion Prediction for Diverse Road Users through\n  Multimodal Feature Integration","summary":"  Predicting the behavior of road users accurately is crucial to enable the\nsafe operation of autonomous vehicles in urban or densely populated areas.\nTherefore, there has been a growing interest in time series motion prediction\nresearch, leading to significant advancements in state-of-the-art techniques in\nrecent years. However, the potential of using LiDAR data to capture more\ndetailed local features, such as a person's gaze or posture, remains largely\nunexplored. To address this, we develop a novel multimodal approach for motion\nprediction based on the PointNet foundation model architecture, incorporating\nlocal LiDAR features. Evaluation on the Waymo Open Dataset shows a performance\nimprovement of 6.20% and 1.58% in minADE and mAP respectively, when integrated\nand compared with the previous state-of-the-art MTR. We open-source the code of\nour LiMTR model.\n","authors":["Camiel Oerlemans","Bram Grooten","Michiel Braat","Alaa Alassi","Emilia Silvas","Decebal Constantin Mocanu"],"pdf_url":"https://arxiv.org/pdf/2410.15819v1.pdf","comment":"Accepted at the NeurIPS 2024 workshop Time Series in the Age of Large\n  Models. Code available at https://github.com/Cing2/LiMTR"},{"id":"http://arxiv.org/abs/2410.15814v1","updated":"2024-10-21T09:28:42Z","published":"2024-10-21T09:28:42Z","title":"Kaninfradet3D:A Road-side Camera-LiDAR Fusion 3D Perception Model based\n  on Nonlinear Feature Extraction and Intrinsic Correlation","summary":"  With the development of AI-assisted driving, numerous methods have emerged\nfor ego-vehicle 3D perception tasks, but there has been limited research on\nroadside perception. With its ability to provide a global view and a broader\nsensing range, the roadside perspective is worth developing. LiDAR provides\nprecise three-dimensional spatial information, while cameras offer semantic\ninformation. These two modalities are complementary in 3D detection. However,\nadding camera data does not increase accuracy in some studies since the\ninformation extraction and fusion procedure is not sufficiently reliable.\nRecently, Kolmogorov-Arnold Networks (KANs) have been proposed as replacements\nfor MLPs, which are better suited for high-dimensional, complex data. Both the\ncamera and the LiDAR provide high-dimensional information, and employing KANs\nshould enhance the extraction of valuable features to produce better fusion\noutcomes. This paper proposes Kaninfradet3D, which optimizes the feature\nextraction and fusion modules. To extract features from complex\nhigh-dimensional data, the model's encoder and fuser modules were improved\nusing KAN Layers. Cross-attention was applied to enhance feature fusion, and\nvisual comparisons verified that camera features were more evenly integrated.\nThis addressed the issue of camera features being abnormally concentrated,\nnegatively impacting fusion. Compared to the benchmark, our approach shows\nimprovements of +9.87 mAP and +10.64 mAP in the two viewpoints of the TUMTraf\nIntersection Dataset and an improvement of +1.40 mAP in the roadside end of the\nTUMTraf V2X Cooperative Perception Dataset. The results indicate that\nKaninfradet3D can effectively fuse features, demonstrating the potential of\napplying KANs in roadside perception tasks.\n","authors":["Pei Liu","Nanfang Zheng","Yiqun Li","Junlan Chen","Ziyuan Pu"],"pdf_url":"https://arxiv.org/pdf/2410.15814v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.15812v1","updated":"2024-10-21T09:27:51Z","published":"2024-10-21T09:27:51Z","title":"FusionLungNet: Multi-scale Fusion Convolution with Refinement Network\n  for Lung CT Image Segmentation","summary":"  Early detection of lung cancer is crucial as it increases the chances of\nsuccessful treatment. Automatic lung image segmentation assists doctors in\nidentifying diseases such as lung cancer, COVID-19, and respiratory disorders.\nHowever, lung segmentation is challenging due to overlapping features like\nvascular and bronchial structures, along with pixel-level fusion of brightness,\ncolor, and texture. New lung segmentation methods face difficulties in\nidentifying long-range relationships between image components, reliance on\nconvolution operations that may not capture all critical features, and the\ncomplex structures of the lungs. Furthermore, semantic gaps between feature\nmaps can hinder the integration of relevant information, reducing model\naccuracy. Skip connections can also limit the decoder's access to complete\ninformation, resulting in partial information loss during encoding. To overcome\nthese challenges, we propose a hybrid approach using the FusionLungNet network,\nwhich has a multi-level structure with key components, including the ResNet-50\nencoder, Channel-wise Aggregation Attention (CAA) module, Multi-scale Feature\nFusion (MFF) block, self refinement (SR) module, and multiple decoders. The\nrefinement sub-network uses convolutional neural networks for image\npost-processing to improve quality. Our method employs a combination of loss\nfunctions, including SSIM, IOU, and focal loss, to optimize image\nreconstruction quality. We created and publicly released a new dataset for lung\nsegmentation called LungSegDB, including 1800 CT images from the LIDC-IDRI\ndataset (dataset version 1) and 700 images from the Chest CT Cancer Images from\nKaggle dataset (dataset version 2). Our method achieved an IOU score of 98.04,\noutperforming existing methods and demonstrating significant improvements in\nsegmentation accuracy. https://github.com/sadjadrz/FusionLungNet\n","authors":["Sadjad Rezvani","Mansoor Fateh","Yeganeh Jalali","Amirreza Fateh"],"pdf_url":"https://arxiv.org/pdf/2410.15812v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.15811v1","updated":"2024-10-21T09:25:49Z","published":"2024-10-21T09:25:49Z","title":"Data-Efficient CLIP-Powered Dual-Branch Networks for Source-Free\n  Unsupervised Domain Adaptation","summary":"  Source-Free Unsupervised Domain Adaptation (SF-UDA) aims to transfer a\nmodel's performance from a labeled source domain to an unlabeled target domain\nwithout direct access to source samples, addressing data privacy issues.\nHowever, most existing SF-UDA approaches assume the availability of abundant\nsource domain samples, which is often impractical due to the high cost of data\nannotation. In this paper, we explore a more challenging scenario where direct\naccess to source domain samples is restricted, and the source domain contains\nonly a few samples. To tackle the dual challenges of limited source data and\nprivacy concerns, we introduce a data-efficient, CLIP-powered dual-branch\nnetwork (CDBN in short). We design a cross-modal dual-branch network that\nintegrates source domain class semantics into the unsupervised fine-tuning of\nthe target domain. It preserves the class information from the source domain\nwhile enhancing the model's generalization to the target domain. Additionally,\nwe propose an unsupervised optimization strategy driven by accurate\nclassification and diversity, which aims to retain the classification\ncapability learned from the source domain while producing more confident and\ndiverse predictions in the target domain. Extensive experiments across 31\ntransfer tasks on 7 public datasets demonstrate that our approach achieves\nstate-of-the-art performance compared to existing methods.\n","authors":["Yongguang Li","Yueqi Cao","Jindong Li","Qi Wang","Shengsheng Wang"],"pdf_url":"https://arxiv.org/pdf/2410.15811v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.15802v1","updated":"2024-10-21T09:20:33Z","published":"2024-10-21T09:20:33Z","title":"Assisted Physical Interaction: Autonomous Aerial Robots with Neural\n  Network Detection, Navigation, and Safety Layers","summary":"  The paper introduces a novel framework for safe and autonomous aerial\nphysical interaction in industrial settings. It comprises two main components:\na neural network-based target detection system enhanced with edge computing for\nreduced onboard computational load, and a control barrier function (CBF)-based\ncontroller for safe and precise maneuvering. The target detection system is\ntrained on a dataset under challenging visual conditions and evaluated for\naccuracy across various unseen data with changing lighting conditions. Depth\nfeatures are utilized for target pose estimation, with the entire detection\nframework offloaded into low-latency edge computing. The CBF-based controller\nenables the UAV to converge safely to the target for precise contact. Simulated\nevaluations of both the controller and target detection are presented,\nalongside an analysis of real-world detection performance.\n","authors":["Andrea Berra","Viswa Narayanan Sankaranarayanan","Achilleas Santi Seisa","Julien Mellet","Udayanga G. W. K. N. Gamage","Sumeet Gajanan Satpute","Fabio Ruggiero","Vincenzo Lippiello","Silvia Tolu","Matteo Fumagalli","George Nikolakopoulos","Miguel Ángel Trujillo Soto","Guillermo Heredia"],"pdf_url":"https://arxiv.org/pdf/2410.15802v1.pdf","comment":"8 pages,14 figures, ICUAS 2024"},{"id":"http://arxiv.org/abs/2410.13571v2","updated":"2024-10-21T09:15:37Z","published":"2024-10-17T14:07:46Z","title":"DriveDreamer4D: World Models Are Effective Data Machines for 4D Driving\n  Scene Representation","summary":"  Closed-loop simulation is essential for advancing end-to-end autonomous\ndriving systems. Contemporary sensor simulation methods, such as NeRF and 3DGS,\nrely predominantly on conditions closely aligned with training data\ndistributions, which are largely confined to forward-driving scenarios.\nConsequently, these methods face limitations when rendering complex maneuvers\n(e.g., lane change, acceleration, deceleration). Recent advancements in\nautonomous-driving world models have demonstrated the potential to generate\ndiverse driving videos. However, these approaches remain constrained to 2D\nvideo generation, inherently lacking the spatiotemporal coherence required to\ncapture intricacies of dynamic driving environments. In this paper, we\nintroduce DriveDreamer4D, which enhances 4D driving scene representation\nleveraging world model priors. Specifically, we utilize the world model as a\ndata machine to synthesize novel trajectory videos based on real-world driving\ndata. Notably, we explicitly leverage structured conditions to control the\nspatial-temporal consistency of foreground and background elements, thus the\ngenerated data adheres closely to traffic constraints. To our knowledge,\nDriveDreamer4D is the first to utilize video generation models for improving 4D\nreconstruction in driving scenarios. Experimental results reveal that\nDriveDreamer4D significantly enhances generation quality under novel trajectory\nviews, achieving a relative improvement in FID by 24.5%, 39.0%, and 10.5%\ncompared to PVG, S3Gaussian, and Deformable-GS. Moreover, DriveDreamer4D\nmarkedly enhances the spatiotemporal coherence of driving agents, which is\nverified by a comprehensive user study and the relative increases of 20.3%,\n42.0%, and 13.7% in the NTA-IoU metric.\n","authors":["Guosheng Zhao","Chaojun Ni","Xiaofeng Wang","Zheng Zhu","Xueyang Zhang","Yida Wang","Guan Huang","Xinze Chen","Boyuan Wang","Youyi Zhang","Wenjun Mei","Xingang Wang"],"pdf_url":"https://arxiv.org/pdf/2410.13571v2.pdf","comment":"Project Page: https://drivedreamer4d.github.io"},{"id":"http://arxiv.org/abs/2409.07825v3","updated":"2024-10-21T09:14:47Z","published":"2024-09-12T08:15:39Z","title":"Deep Multimodal Learning with Missing Modality: A Survey","summary":"  During multimodal model training and testing, certain data modalities may be\nabsent due to sensor limitations, cost constraints, privacy concerns, or data\nloss, negatively affecting performance. Multimodal learning techniques designed\nto handle missing modalities can mitigate this by ensuring model robustness\neven when some modalities are unavailable. This survey reviews recent progress\nin Multimodal Learning with Missing Modality (MLMM), focusing on deep learning\nmethods. It provides the first comprehensive survey that covers the motivation\nand distinctions between MLMM and standard multimodal learning setups, followed\nby a detailed analysis of current methods, applications, and datasets,\nconcluding with challenges and future directions.\n","authors":["Renjie Wu","Hu Wang","Hsiang-Ting Chen","Gustavo Carneiro"],"pdf_url":"https://arxiv.org/pdf/2409.07825v3.pdf","comment":"Submitted to ACM Computing Surveys"},{"id":"http://arxiv.org/abs/2410.15794v1","updated":"2024-10-21T09:06:13Z","published":"2024-10-21T09:06:13Z","title":"Habaek: High-performance water segmentation through dataset expansion\n  and inductive bias optimization","summary":"  Water segmentation is critical to disaster response and water resource\nmanagement. Authorities may employ high-resolution photography to monitor\nrivers, lakes, and reservoirs, allowing for more proactive management in\nagriculture, industry, and conservation. Deep learning has improved flood\nmonitoring by allowing models like CNNs, U-Nets, and transformers to handle\nlarge volumes of satellite and aerial data. However, these models usually have\nsignificant processing requirements, limiting their usage in real-time\napplications. This research proposes upgrading the SegFormer model for water\nsegmentation by data augmentation with datasets such as ADE20K and RIWA to\nboost generalization. We examine how inductive bias affects attention-based\nmodels and discover that SegFormer performs better on bigger datasets. To\nfurther demonstrate the function of data augmentation, Low-Rank Adaptation\n(LoRA) is used to lower processing complexity while preserving accuracy. We\nshow that the suggested Habaek model outperforms current models in\nsegmentation, with an Intersection over Union (IoU) ranging from 0.91986 to\n0.94397. In terms of F1-score, recall, accuracy, and precision, Habaek performs\nbetter than rival models, indicating its potential for real-world applications.\nThis study highlights the need to enhance structures and include datasets for\neffective water segmentation.\n","authors":["Hanseon Joo","Eunji Lee","Minjong Cheon"],"pdf_url":"https://arxiv.org/pdf/2410.15794v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.15792v1","updated":"2024-10-21T09:02:40Z","published":"2024-10-21T09:02:40Z","title":"WildOcc: A Benchmark for Off-Road 3D Semantic Occupancy Prediction","summary":"  3D semantic occupancy prediction is an essential part of autonomous driving,\nfocusing on capturing the geometric details of scenes. Off-road environments\nare rich in geometric information, therefore it is suitable for 3D semantic\noccupancy prediction tasks to reconstruct such scenes. However, most of\nresearches concentrate on on-road environments, and few methods are designed\nfor off-road 3D semantic occupancy prediction due to the lack of relevant\ndatasets and benchmarks. In response to this gap, we introduce WildOcc, to our\nknowledge, the first benchmark to provide dense occupancy annotations for\noff-road 3D semantic occupancy prediction tasks. A ground truth generation\npipeline is proposed in this paper, which employs a coarse-to-fine\nreconstruction to achieve a more realistic result. Moreover, we introduce a\nmulti-modal 3D semantic occupancy prediction framework, which fuses\nspatio-temporal information from multi-frame images and point clouds at voxel\nlevel. In addition, a cross-modality distillation function is introduced, which\ntransfers geometric knowledge from point clouds to image features.\n","authors":["Heng Zhai","Jilin Mei","Chen Min","Liang Chen","Fangzhou Zhao","Yu Hu"],"pdf_url":"https://arxiv.org/pdf/2410.15792v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2405.20648v2","updated":"2024-10-21T08:52:10Z","published":"2024-05-31T07:30:24Z","title":"Shotluck Holmes: A Family of Efficient Small-Scale Large Language Vision\n  Models For Video Captioning and Summarization","summary":"  Video is an increasingly prominent and information-dense medium, yet it poses\nsubstantial challenges for language models. A typical video consists of a\nsequence of shorter segments, or shots, that collectively form a coherent\nnarrative. Each shot is analogous to a word in a sentence where multiple data\nstreams of information (such as visual and auditory data) must be processed\nsimultaneously. Comprehension of the entire video requires not only\nunderstanding the visual-audio information of each shot but also requires that\nthe model links the ideas between each shot to generate a larger,\nall-encompassing story. Despite significant progress in the field, current\nworks often overlook videos' more granular shot-by-shot semantic information.\nIn this project, we propose a family of efficient large language vision models\n(LLVMs) to boost video summarization and captioning called Shotluck Holmes. By\nleveraging better pretraining and data collection strategies, we extend the\nabilities of existing small LLVMs from being able to understand a picture to\nbeing able to understand a sequence of frames. Specifically, we show that\nShotluck Holmes achieves better performance than state-of-the-art results on\nthe Shot2Story video captioning and summary task with significantly smaller and\nmore computationally efficient models.\n","authors":["Richard Luo","Austin Peng","Adithya Vasudev","Rishabh Jain"],"pdf_url":"https://arxiv.org/pdf/2405.20648v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.15780v1","updated":"2024-10-21T08:45:26Z","published":"2024-10-21T08:45:26Z","title":"An Efficient System for Automatic Map Storytelling -- A Case Study on\n  Historical Maps","summary":"  Historical maps provide valuable information and knowledge about the past.\nHowever, as they often feature non-standard projections, hand-drawn styles, and\nartistic elements, it is challenging for non-experts to identify and interpret\nthem. While existing image captioning methods have achieved remarkable success\non natural images, their performance on maps is suboptimal as maps are\nunderrepresented in their pre-training process. Despite the recent advance of\nGPT-4 in text recognition and map captioning, it still has a limited\nunderstanding of maps, as its performance wanes when texts (e.g., titles and\nlegends) in maps are missing or inaccurate. Besides, it is inefficient or even\nimpractical to fine-tune the model with users' own datasets. To address these\nproblems, we propose a novel and lightweight map-captioning counterpart.\nSpecifically, we fine-tune the state-of-the-art vision-language model CLIP to\ngenerate captions relevant to historical maps and enrich the captions with\nGPT-3.5 to tell a brief story regarding where, what, when and why of a given\nmap. We propose a novel decision tree architecture to only generate captions\nrelevant to the specified map type. Our system shows invariance to text\nalterations in maps. The system can be easily adapted and extended to other map\ntypes and scaled to a larger map captioning system. The code is open-sourced at\nhttps://github.com/claudaff/automatic-map-storytelling.\n","authors":["Ziyi Liu","Claudio Affolter","Sidi Wu","Yizi Chen","Lorenz Hurni"],"pdf_url":"https://arxiv.org/pdf/2410.15780v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.15778v1","updated":"2024-10-21T08:42:30Z","published":"2024-10-21T08:42:30Z","title":"Reducing Hallucinations in Vision-Language Models via Latent Space\n  Steering","summary":"  Hallucination poses a challenge to the deployment of large vision-language\nmodels (LVLMs) in applications. Unlike in large language models (LLMs),\nhallucination in LVLMs often arises from misalignments between visual inputs\nand textual outputs. This paper investigates the underlying mechanisms of\nhallucination, focusing on the unique structure of LVLMs that distinguishes\nthem from large language models (LLMs). We identify that hallucinations often\narise from the sensitivity of text decoders to vision inputs, a natural\nphenomenon when image encoders and text decoders are pre-trained separately.\nInspired by this, we introduce Visual and Textual Intervention (VTI), a novel\ntechnique designed to reduce hallucinations by steering latent space\nrepresentations during inference to enhance the stability of vision features.\nAs a task-agnostic test-time intervention, VTI can be easily applied to any\nproblem without additional cost. Extensive experiments demonstrate that it can\neffectively reduce hallucinations and outperform baseline methods across\nmultiple metrics, highlighting the critical role of vision feature stability in\nLVLMs.\n","authors":["Sheng Liu","Haotian Ye","James Zou"],"pdf_url":"https://arxiv.org/pdf/2410.15778v1.pdf","comment":"21 pages"},{"id":"http://arxiv.org/abs/2410.15774v1","updated":"2024-10-21T08:36:25Z","published":"2024-10-21T08:36:25Z","title":"Generalizing Motion Planners with Mixture of Experts for Autonomous\n  Driving","summary":"  Large real-world driving datasets have sparked significant research into\nvarious aspects of data-driven motion planners for autonomous driving. These\ninclude data augmentation, model architecture, reward design, training\nstrategies, and planner pipelines. These planners promise better\ngeneralizations on complicated and few-shot cases than previous methods.\nHowever, experiment results show that many of these approaches produce limited\ngeneralization abilities in planning performance due to overly complex designs\nor training paradigms. In this paper, we review and benchmark previous methods\nfocusing on generalizations. The experimental results indicate that as models\nare appropriately scaled, many design elements become redundant. We introduce\nStateTransformer-2 (STR2), a scalable, decoder-only motion planner that uses a\nVision Transformer (ViT) encoder and a mixture-of-experts (MoE) causal\nTransformer architecture. The MoE backbone addresses modality collapse and\nreward balancing by expert routing during training. Extensive experiments on\nthe NuPlan dataset show that our method generalizes better than previous\napproaches across different test sets and closed-loop simulations. Furthermore,\nwe assess its scalability on billions of real-world urban driving scenarios,\ndemonstrating consistent accuracy improvements as both data and model size\ngrow.\n","authors":["Qiao Sun","Huimin Wang","Jiahao Zhan","Fan Nie","Xin Wen","Leimeng Xu","Kun Zhan","Peng Jia","Xianpeng Lang","Hang Zhao"],"pdf_url":"https://arxiv.org/pdf/2410.15774v1.pdf","comment":"7 pages, 3 figures"},{"id":"http://arxiv.org/abs/2410.15768v1","updated":"2024-10-21T08:28:11Z","published":"2024-10-21T08:28:11Z","title":"Learning to Synthesize Graphics Programs for Geometric Artworks","summary":"  Creating and understanding art has long been a hallmark of human ability.\nWhen presented with finished digital artwork, professional graphic artists can\nintuitively deconstruct and replicate it using various drawing tools, such as\nthe line tool, paint bucket, and layer features, including opacity and blending\nmodes. While most recent research in this field has focused on art generation,\nproposing a range of methods, these often rely on the concept of artwork being\nrepresented as a final image. To bridge the gap between pixel-level results and\nthe actual drawing process, we present an approach that treats a set of drawing\ntools as executable programs. This method predicts a sequence of steps to\nachieve the final image, allowing for understandable and resolution-independent\nreproductions under the usage of a set of drawing commands. Our experiments\ndemonstrate that our program synthesizer, Art2Prog, can comprehensively\nunderstand complex input images and reproduce them using high-quality\nexecutable programs. The experimental results evidence the potential of\nmachines to grasp higher-level information from images and generate compact\nprogram-level descriptions.\n","authors":["Qi Bing","Chaoyi Zhang","Weidong Cai"],"pdf_url":"https://arxiv.org/pdf/2410.15768v1.pdf","comment":"ICPR 2024"},{"id":"http://arxiv.org/abs/2410.15767v1","updated":"2024-10-21T08:27:13Z","published":"2024-10-21T08:27:13Z","title":"Improving Instance Optimization in Deformable Image Registration with\n  Gradient Projection","summary":"  Deformable image registration is inherently a multi-objective optimization\n(MOO) problem, requiring a delicate balance between image similarity and\ndeformation regularity. These conflicting objectives often lead to poor\noptimization outcomes, such as being trapped in unsatisfactory local minima or\nexperiencing slow convergence. Deep learning methods have recently gained\npopularity in this domain due to their efficiency in processing large datasets\nand achieving high accuracy. However, they often underperform during test time\ncompared to traditional optimization techniques, which further explore\niterative, instance-specific gradient-based optimization. This performance gap\nis more pronounced when a distribution shift between training and test data\nexists. To address this issue, we focus on the instance optimization (IO)\nparadigm, which involves additional optimization for test-time instances based\non a pre-trained model. IO effectively combines the generalization capabilities\nof deep learning with the fine-tuning advantages of instance-specific\noptimization. Within this framework, we emphasize the use of gradient\nprojection to mitigate conflicting updates in MOO. This technique projects\nconflicting gradients into a common space, better aligning the dual objectives\nand enhancing optimization stability. We validate our method using a\nstate-of-the-art foundation model on the 3D Brain inter-subject registration\ntask (LUMIR) from the Learn2Reg 2024 Challenge. Our results show significant\nimprovements over standard gradient descent, leading to more accurate and\nreliable registration results.\n","authors":["Yi Zhang","Yidong Zhao","Qian Tao"],"pdf_url":"https://arxiv.org/pdf/2410.15767v1.pdf","comment":"L2R 2024 Challenge Paper"},{"id":"http://arxiv.org/abs/2410.15766v1","updated":"2024-10-21T08:24:46Z","published":"2024-10-21T08:24:46Z","title":"How Important are Data Augmentations to Close the Domain Gap for Object\n  Detection in Orbit?","summary":"  We investigate the efficacy of data augmentations to close the domain gap in\nspaceborne computer vision, crucial for autonomous operations like on-orbit\nservicing. As the use of computer vision in space increases, challenges such as\nhostile illumination and low signal-to-noise ratios significantly hinder\nperformance. While learning-based algorithms show promising results, their\nadoption is limited by the need for extensive annotated training data and the\ndomain gap that arises from differences between synthesized and real-world\nimagery. This study explores domain generalization in terms of data\naugmentations -- classical color and geometric transformations, corruptions,\nand noise -- to enhance model performance across the domain gap. To this end,\nwe conduct an large scale experiment using a hyperparameter optimization\npipeline that samples hundreds of different configurations and searches for the\nbest set to bridge the domain gap. As a reference task, we use 2D object\ndetection and evaluate on the SPEED+ dataset that contains real\nhardware-in-the-loop satellite images in its test set. Moreover, we evaluate\nfour popular object detectors, including Mask R-CNN, Faster R-CNN, YOLO-v7, and\nthe open set detector GroundingDINO, and highlight their trade-offs between\nperformance, inference speed, and training time. Our results underscore the\nvital role of data augmentations in bridging the domain gap, improving model\nperformance, robustness, and reliability for critical space applications. As a\nresult, we propose two novel data augmentations specifically developed to\nemulate the visual effects observed in orbital imagery. We conclude by\nrecommending the most effective augmentations for advancing computer vision in\nchallenging orbital environments. Code for training detectors and\nhyperparameter search will be made publicly available.\n","authors":["Maximilian Ulmer","Leonard Klüpfel","Maximilian Durner","Rudolph Triebel"],"pdf_url":"https://arxiv.org/pdf/2410.15766v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.15760v1","updated":"2024-10-21T08:20:19Z","published":"2024-10-21T08:20:19Z","title":"DeepIcon: A Hierarchical Network for Layer-wise Icon Vectorization","summary":"  In contrast to the well-established technique of rasterization, vectorization\nof images poses a significant challenge in the field of computer graphics.\nRecent learning-based methods for converting raster images to vector formats\nfrequently suffer from incomplete shapes, redundant path prediction, and a lack\nof accuracy in preserving the semantics of the original content. These\nshortcomings severely hinder the utility of these methods for further editing\nand manipulation of images. To address these challenges, we present DeepIcon, a\nnovel hierarchical image vectorization network specifically tailored for\ngenerating variable-length icon vector graphics based on the raster image\ninput. Our experimental results indicate that DeepIcon can efficiently produce\nScalable Vector Graphics (SVGs) directly from raster images, bypassing the need\nfor a differentiable rasterizer while also demonstrating a profound\nunderstanding of the image contents.\n","authors":["Qi Bing","Chaoyi Zhang","Weidong Cai"],"pdf_url":"https://arxiv.org/pdf/2410.15760v1.pdf","comment":"Accepted as Oral Presentation at DICTA 2024"},{"id":"http://arxiv.org/abs/2408.10188v4","updated":"2024-10-21T08:12:42Z","published":"2024-08-19T17:48:08Z","title":"LongVILA: Scaling Long-Context Visual Language Models for Long Videos","summary":"  Long-context capability is critical for multi-modal foundation models,\nespecially for long video understanding. We introduce LongVILA, a full-stack\nsolution for long-context visual-language models \\qinghao{by co-designing the\nalgorithm and system. For model training, we upgrade existing VLMs to support\nlong video understanding by incorporating two additional stages, {\\em i.e.},\nlong context extension and long video supervised fine-tuning. However, training\non long video is computationally and memory intensive. We introduce the\nlong-context Multi-Modal Sequence Parallelism (MM-SP) system that efficiently\nparallelizes long video training and inference, enabling 2M context length\ntraining on 256 GPUs without any gradient checkpointing. LongVILA efficiently\nextends the number of video frames of VILA from 8 to 2048, improving the long\nvideo captioning score from 2.00 to 3.26 (out of 5), achieving 99.8% accuracy\nin 6,000-frame (more than 1 million tokens) video needle-in-a-haystack.\nLongVILA-7B demonstrates strong accuracy on the VideoMME benchmark, i.e., 61.8%\nwith subtitle. Besides, MM-SP is 2.1x - 5.7x faster than ring style sequence\nparallelism and 1.1x - 1.4x faster than Megatron with a hybrid context and\ntensor parallelism. Moreover, it seamlessly integrates with Hugging Face\nTransformers.\n","authors":["Fuzhao Xue","Yukang Chen","Dacheng Li","Qinghao Hu","Ligeng Zhu","Xiuyu Li","Yunhao Fang","Haotian Tang","Shang Yang","Zhijian Liu","Ethan He","Hongxu Yin","Pavlo Molchanov","Jan Kautz","Linxi Fan","Yuke Zhu","Yao Lu","Song Han"],"pdf_url":"https://arxiv.org/pdf/2408.10188v4.pdf","comment":"Code and models are available at\n  https://github.com/NVlabs/VILA/blob/main/LongVILA.md"},{"id":"http://arxiv.org/abs/2410.15744v1","updated":"2024-10-21T08:01:58Z","published":"2024-10-21T08:01:58Z","title":"Unleashing the Potential of Vision-Language Pre-Training for 3D\n  Zero-Shot Lesion Segmentation via Mask-Attribute Alignment","summary":"  Recent advancements in medical vision-language pre-training models have\ndriven significant progress in zero-shot disease recognition. However,\ntransferring image-level knowledge to pixel-level tasks, such as lesion\nsegmentation in 3D CT scans, remains a critical challenge. Due to the\ncomplexity and variability of pathological visual characteristics, existing\nmethods struggle to align fine-grained lesion features not encountered during\ntraining with disease-related textual representations. In this paper, we\npresent Malenia, a novel multi-scale lesion-level mask-attribute alignment\nframework, specifically designed for 3D zero-shot lesion segmentation. Malenia\nimproves the compatibility between mask representations and their associated\nelemental attributes, explicitly linking the visual features of unseen lesions\nwith the extensible knowledge learned from previously seen ones. Furthermore,\nwe design a Cross-Modal Knowledge Injection module to enhance both visual and\ntextual features with mutually beneficial information, effectively guiding the\ngeneration of segmentation results. Comprehensive experiments across three\ndatasets and 12 lesion categories validate the superior performance of Malenia.\nCodes will be publicly available.\n","authors":["Yankai Jiang","Wenhui Lei","Xiaofan Zhang","Shaoting Zhang"],"pdf_url":"https://arxiv.org/pdf/2410.15744v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2407.15169v2","updated":"2024-10-21T07:57:56Z","published":"2024-07-21T13:58:43Z","title":"Back-in-Time Diffusion: Unsupervised Detection of Medical Deepfakes","summary":"  Recent progress in generative models has made it easier for a wide audience\nto edit and create image content, raising concerns about the proliferation of\ndeepfakes, especially in healthcare. Despite the availability of numerous\ntechniques for detecting manipulated images captured by conventional cameras,\ntheir applicability to medical images is limited. This limitation stems from\nthe distinctive forensic characteristics of medical images, a result of their\nimaging process.\n  In this work we propose a novel anomaly detector for medical imagery based on\ndiffusion models. Normally, diffusion models are used to generate images.\nHowever, we show how a similar process can be used to detect synthetic content\nby making a model reverse the diffusion on a suspected image. We evaluate our\nmethod on the task of detecting fake tumors injected and removed from CT and\nMRI scans. Our method significantly outperforms other state of the art\nunsupervised detectors with an increased AUC of 0.9 from 0.79 for injection and\nof 0.96 from 0.91 for removal on average. We also explore our hypothesis using\nAI explainability tools and publish our code and new medical deepfake datasets\nto encourage further research into this domain.\n","authors":["Fred Grabovski","Lior Yasur","Guy Amit","Yisroel Mirsky"],"pdf_url":"https://arxiv.org/pdf/2407.15169v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.15732v1","updated":"2024-10-21T07:51:17Z","published":"2024-10-21T07:51:17Z","title":"ViMoE: An Empirical Study of Designing Vision Mixture-of-Experts","summary":"  Mixture-of-Experts (MoE) models embody the divide-and-conquer concept and are\na promising approach for increasing model capacity, demonstrating excellent\nscalability across multiple domains. In this paper, we integrate the MoE\nstructure into the classic Vision Transformer (ViT), naming it ViMoE, and\nexplore the potential of applying MoE to vision through a comprehensive study\non image classification. However, we observe that the performance is sensitive\nto the configuration of MoE layers, making it challenging to obtain optimal\nresults without careful design. The underlying cause is that inappropriate MoE\nlayers lead to unreliable routing and hinder experts from effectively acquiring\nhelpful knowledge. To address this, we introduce a shared expert to learn and\ncapture common information, serving as an effective way to construct stable\nViMoE. Furthermore, we demonstrate how to analyze expert routing behavior,\nrevealing which MoE layers are capable of specializing in handling specific\ninformation and which are not. This provides guidance for retaining the\ncritical layers while removing redundancies, thereby advancing ViMoE to be more\nefficient without sacrificing accuracy. We aspire for this work to offer new\ninsights into the design of vision MoE models and provide valuable empirical\nguidance for future research.\n","authors":["Xumeng Han","Longhui Wei","Zhiyang Dou","Zipeng Wang","Chenhui Qiang","Xin He","Yingfei Sun","Zhenjun Han","Qi Tian"],"pdf_url":"https://arxiv.org/pdf/2410.15732v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.15728v1","updated":"2024-10-21T07:44:44Z","published":"2024-10-21T07:44:44Z","title":"Object-Centric Temporal Consistency via Conditional Autoregressive\n  Inductive Biases","summary":"  Unsupervised object-centric learning from videos is a promising approach\ntowards learning compositional representations that can be applied to various\ndownstream tasks, such as prediction and reasoning. Recently, it was shown that\npretrained Vision Transformers (ViTs) can be useful to learn object-centric\nrepresentations on real-world video datasets. However, while these approaches\nsucceed at extracting objects from the scenes, the slot-based representations\nfail to maintain temporal consistency across consecutive frames in a video,\ni.e. the mapping of objects to slots changes across the video. To address this,\nwe introduce Conditional Autoregressive Slot Attention (CA-SA), a framework\nthat enhances the temporal consistency of extracted object-centric\nrepresentations in video-centric vision tasks. Leveraging an autoregressive\nprior network to condition representations on previous timesteps and a novel\nconsistency loss function, CA-SA predicts future slot representations and\nimposes consistency across frames. We present qualitative and quantitative\nresults showing that our proposed method outperforms the considered baselines\non downstream tasks, such as video prediction and visual question-answering\ntasks.\n","authors":["Cristian Meo","Akihiro Nakano","Mircea Lică","Aniket Didolkar","Masahiro Suzuki","Anirudh Goyal","Mengmi Zhang","Justin Dauwels","Yutaka Matsuo","Yoshua Bengio"],"pdf_url":"https://arxiv.org/pdf/2410.15728v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2405.15209v2","updated":"2024-10-21T07:34:04Z","published":"2024-05-24T04:36:13Z","title":"Motion Segmentation for Neuromorphic Aerial Surveillance","summary":"  Aerial surveillance demands rapid and precise detection of moving objects in\ndynamic environments. Event cameras, which draw inspiration from biological\nvision systems, present a promising alternative to frame-based sensors due to\ntheir exceptional temporal resolution, superior dynamic range, and minimal\npower requirements. Unlike traditional frame-based sensors that capture\nredundant information at fixed intervals, event cameras asynchronously record\npixel-level brightness changes, providing a continuous and efficient data\nstream ideal for fast motion segmentation. While these sensors are ideal for\nfast motion segmentation, existing event-based motion segmentation methods\noften suffer from limitations such as the need for per-scene parameter tuning\nor reliance on manual labelling, hindering their scalability and practical\ndeployment. In this paper, we address these challenges by introducing a novel\nmotion segmentation method that leverages self-supervised vision transformers\non both event data and optical flow information. Our approach eliminates the\nneed for human annotations and reduces dependency on scene-specific parameters.\nIn this paper, we used the EVK4-HD Prophesee event camera onboard a highly\ndynamic aerial platform in urban settings. We conduct extensive evaluations of\nour framework across multiple datasets, demonstrating state-of-the-art\nperformance compared to existing benchmarks. Our method can effectively handle\nvarious types of motion and an arbitrary number of moving objects. Code and\ndataset are available at: \\url{https://samiarja.github.io/evairborne/}\n","authors":["Sami Arja","Alexandre Marcireau","Saeed Afshar","Bharath Ramesh","Gregory Cohen"],"pdf_url":"https://arxiv.org/pdf/2405.15209v2.pdf","comment":"17 pages, 11 figures, 8 tables"},{"id":"http://arxiv.org/abs/2403.12931v5","updated":"2024-10-21T07:32:04Z","published":"2024-03-19T17:34:27Z","title":"You Only Sample Once: Taming One-Step Text-to-Image Synthesis by\n  Self-Cooperative Diffusion GANs","summary":"  Recently, some works have tried to combine diffusion and Generative\nAdversarial Networks (GANs) to alleviate the computational cost of the\niterative denoising inference in Diffusion Models (DMs). However, existing\nworks in this line suffer from either training instability and mode collapse or\nsubpar one-step generation learning efficiency. To address these issues, we\nintroduce YOSO, a novel generative model designed for rapid, scalable, and\nhigh-fidelity one-step image synthesis with high training stability and mode\ncoverage. Specifically, we smooth the adversarial divergence by the denoising\ngenerator itself, performing self-cooperative learning. We show that our method\ncan serve as a one-step generation model training from scratch with competitive\nperformance. Moreover, we extend our YOSO to one-step text-to-image generation\nbased on pre-trained models by several effective training techniques (i.e.,\nlatent perceptual loss and latent discriminator for efficient training along\nwith the latent DMs; the informative prior initialization (IPI), and the quick\nadaption stage for fixing the flawed noise scheduler). Experimental results\nshow that YOSO achieves the state-of-the-art one-step generation performance\neven with Low-Rank Adaptation (LoRA) fine-tuning. In particular, we show that\nthe YOSO-PixArt-$\\alpha$ can generate images in one step trained on 512\nresolution, with the capability of adapting to 1024 resolution without extra\nexplicit training, requiring only ~10 A800 days for fine-tuning. Our code is\nprovided at https://github.com/Luo-Yihong/YOSO.\n","authors":["Yihong Luo","Xiaolong Chen","Xinghua Qu","Tianyang Hu","Jing Tang"],"pdf_url":"https://arxiv.org/pdf/2403.12931v5.pdf","comment":"Revision"},{"id":"http://arxiv.org/abs/2410.13621v3","updated":"2024-10-21T07:29:23Z","published":"2024-10-17T14:55:09Z","title":"Enhanced Prompt-leveraged Weakly Supervised Cancer Segmentation based on\n  Segment Anything","summary":"  This work proposes a novel approach beyond supervised learning for effective\npathological image analysis, addressing the challenge of limited robust labeled\ndata. Pathological diagnosis of diseases like cancer has conventionally relied\non the evaluation of morphological features by physicians and pathologists.\nHowever, recent advancements in compute-aided diagnosis (CAD) systems are\ngaining significant attention as diagnostic support tools. Although the\nadvancement of deep learning has improved CAD significantly, segmentation\nmodels typically require large pixel-level annotated dataset, and such labeling\nis expensive. Existing studies not based on supervised approaches still\nstruggle with limited generalization, and no practical approach has emerged\nyet. To address this issue, we present a weakly supervised semantic\nsegmentation (WSSS) model by combining class activation map and Segment\nAnything Model (SAM)-based pseudo-labeling. For effective pretraining, we adopt\nthe SAM-a foundation model that is pretrained on large datasets and operates in\nzero-shot configurations using only coarse prompts. The proposed approach\ntransfer enhanced Attention Dropout Layer's knowledge to SAM, thereby\ngenerating pseudo-labels. To demonstrate the superiority of the proposed\nmethod, experimental studies are conducted on histopathological breast cancer\ndatasets. The proposed method outperformed other WSSS methods across three\ndatasets, demonstrating its efficiency by achieving this with only 12GB of GPU\nmemory during training. Our code is available at :\nhttps://github.com/QI-NemoSong/EPLC-SAM\n","authors":["Joonhyeon Song","Seohwan Yun","Seongho Yoon","Joohyeok Kim","Sangmin Lee"],"pdf_url":"https://arxiv.org/pdf/2410.13621v3.pdf","comment":"10 pages, 7 figures"},{"id":"http://arxiv.org/abs/2404.12020v3","updated":"2024-10-21T07:23:37Z","published":"2024-04-18T09:16:02Z","title":"Look, Listen, and Answer: Overcoming Biases for Audio-Visual Question\n  Answering","summary":"  Audio-Visual Question Answering (AVQA) is a complex multi-modal reasoning\ntask, demanding intelligent systems to accurately respond to natural language\nqueries based on audio-video input pairs. Nevertheless, prevalent AVQA\napproaches are prone to overlearning dataset biases, resulting in poor\nrobustness. Furthermore, current datasets may not provide a precise diagnostic\nfor these methods. To tackle these challenges, firstly, we propose a novel\ndataset, MUSIC-AVQA-R, crafted in two steps: rephrasing questions within the\ntest split of a public dataset (MUSIC-AVQA) and subsequently introducing\ndistribution shifts to split questions. The former leads to a large, diverse\ntest space, while the latter results in a comprehensive robustness evaluation\non rare, frequent, and overall questions. Secondly, we propose a robust\narchitecture that utilizes a multifaceted cycle collaborative debiasing\nstrategy to overcome bias learning. Experimental results show that this\narchitecture achieves state-of-the-art performance on MUSIC-AVQA-R, notably\nobtaining a significant improvement of 9.32%. Extensive ablation experiments\nare conducted on the two datasets mentioned to analyze the component\neffectiveness within the debiasing strategy. Additionally, we highlight the\nlimited robustness of existing multi-modal QA methods through the evaluation on\nour dataset. We also conduct experiments combining various baselines with our\nproposed strategy on two datasets to verify its plug-and-play capability. Our\ndataset and code are available at https://github.com/reml-group/MUSIC-AVQA-R.\n","authors":["Jie Ma","Min Hu","Pinghui Wang","Wangchun Sun","Lingyun Song","Hongbin Pei","Jun Liu","Youtian Du"],"pdf_url":"https://arxiv.org/pdf/2404.12020v3.pdf","comment":"Accepted by NeurIPS 2024"},{"id":"http://arxiv.org/abs/2410.15701v1","updated":"2024-10-21T07:18:24Z","published":"2024-10-21T07:18:24Z","title":"Students Rather Than Experts: A New AI For Education Pipeline To Model\n  More Human-Like And Personalised Early Adolescences","summary":"  The capabilities of large language models (LLMs) have been applied in expert\nsystems across various domains, providing new opportunities for AI in\nEducation. Educational interactions involve a cyclical exchange between\nteachers and students. Current research predominantly focuses on using LLMs to\nsimulate teachers, leveraging their expertise to enhance student learning\noutcomes. However, the simulation of students, which could improve teachers'\ninstructional skills, has received insufficient attention due to the challenges\nof modeling and evaluating virtual students. This research asks: Can LLMs be\nutilized to develop virtual student agents that mimic human-like behavior and\nindividual variability? Unlike expert systems focusing on knowledge delivery,\nvirtual students must replicate learning difficulties, emotional responses, and\nlinguistic uncertainties. These traits present significant challenges in both\nmodeling and evaluation. To address these issues, this study focuses on\nlanguage learning as a context for modeling virtual student agents. We propose\na novel AI4Education framework, called SOE (Scene-Object-Evaluation), to\nsystematically construct LVSA (LLM-based Virtual Student Agents). By curating a\ndataset of personalized teacher-student interactions with various personality\ntraits, question types, and learning stages, and fine-tuning LLMs using LoRA,\nwe conduct multi-dimensional evaluation experiments. Specifically, we: (1)\ndevelop a theoretical framework for generating LVSA; (2) integrate human\nsubjective evaluation metrics into GPT-4 assessments, demonstrating a strong\ncorrelation between human evaluators and GPT-4 in judging LVSA authenticity;\nand (3) validate that LLMs can generate human-like, personalized virtual\nstudent agents in educational contexts, laying a foundation for future\napplications in pre-service teacher training and multi-agent simulation\nenvironments.\n","authors":["Yiping Ma","Shiyu Hu","Xuchen Li","Yipei Wang","Shiqing Liu","Kang Hao Cheong"],"pdf_url":"https://arxiv.org/pdf/2410.15701v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.15694v1","updated":"2024-10-21T07:05:07Z","published":"2024-10-21T07:05:07Z","title":"PALMS: Plane-based Accessible Indoor Localization Using Mobile\n  Smartphones","summary":"  In this paper, we present PALMS, an innovative indoor global localization and\nrelocalization system for mobile smartphones that utilizes publicly available\nfloor plans. Unlike most vision-based methods that require constant visual\ninput, our system adopts a dynamic form of localization that considers a single\ninstantaneous observation and odometry data. The core contribution of this work\nis the introduction of a particle filter initialization method that leverages\nthe Certainly Empty Space (CES) constraint along with principal orientation\nmatching. This approach creates a spatial probability distribution of the\ndevice's location, significantly improving localization accuracy and reducing\nparticle filter convergence time. Our experimental evaluations demonstrate that\nPALMS outperforms traditional methods with uniformly initialized particle\nfilters, providing a more efficient and accessible approach to indoor\nwayfinding. By eliminating the need for prior environmental fingerprinting,\nPALMS provides a scalable and practical approach to indoor navigation.\n","authors":["Yunqian Cheng","Roberto Manduchi"],"pdf_url":"https://arxiv.org/pdf/2410.15694v1.pdf","comment":"7 pages, 3 figures, accepted to the 14th International Conference on\n  Indoor Positioning and Indoor Navigation (IPIN) 2024, Best Presentation Award"},{"id":"http://arxiv.org/abs/2410.15689v1","updated":"2024-10-21T06:59:04Z","published":"2024-10-21T06:59:04Z","title":"Enhancing SNN-based Spatio-Temporal Learning: A Benchmark Dataset and\n  Cross-Modality Attention Model","summary":"  Spiking Neural Networks (SNNs), renowned for their low power consumption,\nbrain-inspired architecture, and spatio-temporal representation capabilities,\nhave garnered considerable attention in recent years. Similar to Artificial\nNeural Networks (ANNs), high-quality benchmark datasets are of great importance\nto the advances of SNNs. However, our analysis indicates that many prevalent\nneuromorphic datasets lack strong temporal correlation, preventing SNNs from\nfully exploiting their spatio-temporal representation capabilities. Meanwhile,\nthe integration of event and frame modalities offers more comprehensive visual\nspatio-temporal information. Yet, the SNN-based cross-modality fusion remains\nunderexplored.\n  In this work, we present a neuromorphic dataset called DVS-SLR that can\nbetter exploit the inherent spatio-temporal properties of SNNs. Compared to\nexisting datasets, it offers advantages in terms of higher temporal\ncorrelation, larger scale, and more varied scenarios. In addition, our\nneuromorphic dataset contains corresponding frame data, which can be used for\ndeveloping SNN-based fusion methods. By virtue of the dual-modal feature of the\ndataset, we propose a Cross-Modality Attention (CMA) based fusion method. The\nCMA model efficiently utilizes the unique advantages of each modality, allowing\nfor SNNs to learn both temporal and spatial attention scores from the\nspatio-temporal features of event and frame modalities, subsequently allocating\nthese scores across modalities to enhance their synergy. Experimental results\ndemonstrate that our method not only improves recognition accuracy but also\nensures robustness across diverse scenarios.\n","authors":["Shibo Zhou","Bo Yang","Mengwen Yuan","Runhao Jiang","Rui Yan","Gang Pan","Huajin Tang"],"pdf_url":"https://arxiv.org/pdf/2410.15689v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.10532v2","updated":"2024-10-21T06:50:51Z","published":"2024-08-20T04:18:53Z","title":"NutrifyAI: An AI-Powered System for Real-Time Food Detection,\n  Nutritional Analysis, and Personalized Meal Recommendations","summary":"  With diet and nutrition apps reaching 1.4 billion users in 2022 [1], it's not\nsurprise that popular health apps, MyFitnessPal, Noom, and Calorie Counter, are\nsurging in popularity. However, one major setback [2] of nearly all nutrition\napplications is that users must enter food data manually, which is\ntime-consuming and tedious. Thus, there has been an increasing demand for\napplications that can accurately identify food items, analyze their nutritional\ncontent, and offer dietary recommendations in real-time. This paper introduces\na comprehensive system that combines advanced computer vision techniques with\nnutritional analysis, implemented in a versatile mobile and web application.\nThe system is divided into three key concepts: 1) food detection using the\nYOLOv8 model, 2) nutrient analysis via the Edamam Nutrition Analysis API, and\n3) personalized meal recommendations using the Edamam Meal Planning and Recipe\nSearch APIs. Preliminary results showcase the system's effectiveness by\nproviding immediate, accurate dietary insights, with a demonstrated food\nrecognition accuracy of nearly 80%, making it a valuable tool for users to make\ninformed dietary decisions.\n","authors":["Michelle Han","Junyao Chen","Zhengyuan Zhou"],"pdf_url":"https://arxiv.org/pdf/2408.10532v2.pdf","comment":"4 pages, 8 figures"},{"id":"http://arxiv.org/abs/2410.05273v2","updated":"2024-10-21T06:50:05Z","published":"2024-09-12T09:18:09Z","title":"HiRT: Enhancing Robotic Control with Hierarchical Robot Transformers","summary":"  Large Vision-Language-Action (VLA) models, leveraging powerful pre trained\nVision-Language Models (VLMs) backends, have shown promise in robotic control\ndue to their impressive generalization ability. However, the success comes at a\ncost. Their reliance on VLM backends with billions of parameters leads to high\ncomputational costs and inference latency, limiting the testing scenarios to\nmainly quasi-static tasks and hindering performance in dynamic tasks requiring\nrapid interactions. To address these limitations, this paper proposes HiRT, a\nHierarchical Robot Transformer framework that enables flexible frequency and\nperformance trade-off. HiRT keeps VLMs running at low frequencies to capture\ntemporarily invariant features while enabling real-time interaction through a\nhigh-frequency vision-based policy guided by the slowly updated features.\nExperiment results in both simulation and real-world settings demonstrate\nsignificant improvements over baseline methods. Empirically, in static tasks,\nwe double the control frequency and achieve comparable success rates.\nAdditionally, on novel real-world dynamic ma nipulation tasks which are\nchallenging for previous VLA models, HiRT improves the success rate from 48% to\n75%.\n","authors":["Jianke Zhang","Yanjiang Guo","Xiaoyu Chen","Yen-Jen Wang","Yucheng Hu","Chengming Shi","Jianyu Chen"],"pdf_url":"https://arxiv.org/pdf/2410.05273v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.15682v1","updated":"2024-10-21T06:46:49Z","published":"2024-10-21T06:46:49Z","title":"RANSAC Back to SOTA: A Two-stage Consensus Filtering for Real-time 3D\n  Registration","summary":"  Correspondence-based point cloud registration (PCR) plays a key role in\nrobotics and computer vision. However, challenges like sensor noises, object\nocclusions, and descriptor limitations inevitably result in numerous outliers.\nRANSAC family is the most popular outlier removal solution. However, the\nrequisite iterations escalate exponentially with the outlier ratio, rendering\nit far inferior to existing methods (SC2PCR [1], MAC [2], etc.) in terms of\naccuracy or speed. Thus, we propose a two-stage consensus filtering (TCF) that\nelevates RANSAC to state-of-the-art (SOTA) speed and accuracy. Firstly,\none-point RANSAC obtains a consensus set based on length consistency.\nSubsequently, two-point RANSAC refines the set via angle consistency. Then,\nthree-point RANSAC computes a coarse pose and removes outliers based on\ntransformed correspondence's distances. Drawing on optimizations from one-point\nand two-point RANSAC, three-point RANSAC requires only a few iterations.\nEventually, an iterative reweighted least squares (IRLS) is applied to yield\nthe optimal pose. Experiments on the large-scale KITTI and ETH datasets\ndemonstrate our method achieves up to three-orders-of-magnitude speedup\ncompared to MAC while maintaining registration accuracy and recall. Our code is\navailable at https://github.com/ShiPC-AI/TCF.\n","authors":["Pengcheng Shi","Shaocheng Yan","Yilin Xiao","Xinyi Liu","Yongjun Zhang","Jiayuan Li"],"pdf_url":"https://arxiv.org/pdf/2410.15682v1.pdf","comment":"8 pages, 8 figures"},{"id":"http://arxiv.org/abs/2403.06403v4","updated":"2024-10-21T06:44:01Z","published":"2024-03-11T03:28:20Z","title":"PointSeg: A Training-Free Paradigm for 3D Scene Segmentation via\n  Foundation Models","summary":"  Recent success of vision foundation models have shown promising performance\nfor the 2D perception tasks. However, it is difficult to train a 3D foundation\nnetwork directly due to the limited dataset and it remains under explored\nwhether existing foundation models can be lifted to 3D space seamlessly. In\nthis paper, we present PointSeg, a novel training-free paradigm that leverages\noff-the-shelf vision foundation models to address 3D scene perception tasks.\nPointSeg can segment anything in 3D scene by acquiring accurate 3D prompts to\nalign their corresponding pixels across frames. Concretely, we design a\ntwo-branch prompts learning structure to construct the 3D point-box prompts\npairs, combining with the bidirectional matching strategy for accurate point\nand proposal prompts generation. Then, we perform the iterative post-refinement\nadaptively when cooperated with different vision foundation models. Moreover,\nwe design a affinity-aware merging algorithm to improve the final ensemble\nmasks. PointSeg demonstrates impressive segmentation performance across various\ndatasets, all without training. Specifically, our approach significantly\nsurpasses the state-of-the-art specialist training-free model by 14.1$\\%$,\n12.3$\\%$, and 12.6$\\%$ mAP on ScanNet, ScanNet++, and KITTI-360 datasets,\nrespectively. On top of that, PointSeg can incorporate with various foundation\nmodels and even surpasses the specialist training-based methods by\n3.4$\\%$-5.4$\\%$ mAP across various datasets, serving as an effective generalist\nmodel.\n","authors":["Qingdong He","Jinlong Peng","Zhengkai Jiang","Xiaobin Hu","Jiangning Zhang","Qiang Nie","Yabiao Wang","Chengjie Wang"],"pdf_url":"https://arxiv.org/pdf/2403.06403v4.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.15674v1","updated":"2024-10-21T06:37:13Z","published":"2024-10-21T06:37:13Z","title":"TALoS: Enhancing Semantic Scene Completion via Test-time Adaptation on\n  the Line of Sight","summary":"  Semantic Scene Completion (SSC) aims to perform geometric completion and\nsemantic segmentation simultaneously. Despite the promising results achieved by\nexisting studies, the inherently ill-posed nature of the task presents\nsignificant challenges in diverse driving scenarios. This paper introduces\nTALoS, a novel test-time adaptation approach for SSC that excavates the\ninformation available in driving environments. Specifically, we focus on that\nobservations made at a certain moment can serve as Ground Truth (GT) for scene\ncompletion at another moment. Given the characteristics of the LiDAR sensor, an\nobservation of an object at a certain location confirms both 1) the occupation\nof that location and 2) the absence of obstacles along the line of sight from\nthe LiDAR to that point. TALoS utilizes these observations to obtain\nself-supervision about occupancy and emptiness, guiding the model to adapt to\nthe scene in test time. In a similar manner, we aggregate reliable SSC\npredictions among multiple moments and leverage them as semantic pseudo-GT for\nadaptation. Further, to leverage future observations that are not accessible at\nthe current time, we present a dual optimization scheme using the model in\nwhich the update is delayed until the future observation is available.\nEvaluations on the SemanticKITTI validation and test sets demonstrate that\nTALoS significantly improves the performance of the pre-trained SSC model. Our\ncode is available at https://github.com/blue-531/TALoS.\n","authors":["Hyun-Kurl Jang","Jihun Kim","Hyeokjun Kweon","Kuk-Jin Yoon"],"pdf_url":"https://arxiv.org/pdf/2410.15674v1.pdf","comment":"Accepted at NeurIPS 2024. Code is available at\n  https://github.com/blue-531/TALoS"},{"id":"http://arxiv.org/abs/2410.04419v2","updated":"2024-10-21T06:35:08Z","published":"2024-10-06T09:26:07Z","title":"LiteVLoc: Map-Lite Visual Localization for Image Goal Navigation","summary":"  This paper presents LiteVLoc, a hierarchical visual localization framework\nthat uses a lightweight topo-metric map to represent the environment. The\nmethod consists of three sequential modules that estimate camera poses in a\ncoarse-to-fine manner. Unlike mainstream approaches relying on detailed 3D\nrepresentations, LiteVLoc reduces storage overhead by leveraging learning-based\nfeature matching and geometric solvers for metric pose estimation. A novel\ndataset for the map-free relocalization task is also introduced. Extensive\nexperiments including localization and navigation in both simulated and\nreal-world scenarios have validate the system's performance and demonstrated\nits precision and efficiency for large-scale deployment. Code and data will be\nmade publicly available.\n","authors":["Jianhao Jiao","Jinhao He","Changkun Liu","Sebastian Aegidius","Xiangcheng Hu","Tristan Braud","Dimitrios Kanoulas"],"pdf_url":"https://arxiv.org/pdf/2410.04419v2.pdf","comment":"9 pages, 4 figures"},{"id":"http://arxiv.org/abs/2406.13165v2","updated":"2024-10-21T06:25:57Z","published":"2024-06-19T02:42:29Z","title":"Cardiac Copilot: Automatic Probe Guidance for Echocardiography with\n  World Model","summary":"  Echocardiography is the only technique capable of real-time imaging of the\nheart and is vital for diagnosing the majority of cardiac diseases. However,\nthere is a severe shortage of experienced cardiac sonographers, due to the\nheart's complex structure and significant operational challenges. To mitigate\nthis situation, we present a Cardiac Copilot system capable of providing\nreal-time probe movement guidance to assist less experienced sonographers in\nconducting freehand echocardiography. This system can enable non-experts,\nespecially in primary departments and medically underserved areas, to perform\ncardiac ultrasound examinations, potentially improving global healthcare\ndelivery. The core innovation lies in proposing a data-driven world model,\nnamed Cardiac Dreamer, for representing cardiac spatial structures. This world\nmodel can provide structure features of any cardiac planes around the current\nprobe position in the latent space, serving as an precise navigation map for\nautonomous plane localization. We train our model with real-world ultrasound\ndata and corresponding probe motion from 110 routine clinical scans with 151K\nsample pairs by three certified sonographers. Evaluations on three standard\nplanes with 37K sample pairs demonstrate that the world model can reduce\nnavigation errors by up to 33\\% and exhibit more stable performance.\n","authors":["Haojun Jiang","Zhenguo Sun","Ning Jia","Meng Li","Yu Sun","Shaqi Luo","Shiji Song","Gao Huang"],"pdf_url":"https://arxiv.org/pdf/2406.13165v2.pdf","comment":"Accepted by MICCAI2024"},{"id":"http://arxiv.org/abs/2410.15670v1","updated":"2024-10-21T06:23:13Z","published":"2024-10-21T06:23:13Z","title":"Transforming Blood Cell Detection and Classification with Advanced Deep\n  Learning Models: A Comparative Study","summary":"  Efficient detection and classification of blood cells are vital for accurate\ndiagnosis and effective treatment of blood disorders. This study utilizes a\nYOLOv10 model trained on Roboflow data with images resized to 640x640 pixels\nacross varying epochs. The results show that increased training epochs\nsignificantly enhance accuracy, precision, and recall, particularly in\nreal-time blood cell detection & classification. The YOLOv10 model outperforms\nMobileNetV2, ShuffleNetV2, and DarkNet in real-time performance, though\nMobileNetV2 and ShuffleNetV2 are more computationally efficient, and DarkNet\nexcels in feature extraction for blood cell classification. This research\nhighlights the potential of integrating deep learning models like YOLOv10,\nMobileNetV2, ShuffleNetV2, and DarkNet into clinical workflows, promising\nimprovements in diagnostic accuracy and efficiency. Additionally, a new,\nwell-annotated blood cell dataset was created and will be open-sourced to\nsupport further advancements in automatic blood cell detection and\nclassification. The findings demonstrate the transformative impact of these\nmodels in revolutionizing medical diagnostics and enhancing blood disorder\nmanagement\n","authors":["Shilpa Choudhary","Sandeep Kumar","Pammi Sri Siddhaarth","Guntu Charitasri"],"pdf_url":"https://arxiv.org/pdf/2410.15670v1.pdf","comment":"26 pages, 4884 Words, 17 Figures, 10 Tables"},{"id":"http://arxiv.org/abs/2305.18512v2","updated":"2024-10-21T05:59:50Z","published":"2023-05-29T17:09:26Z","title":"A Rainbow in Deep Network Black Boxes","summary":"  A central question in deep learning is to understand the functions learned by\ndeep networks. What is their approximation class? Do the learned weights and\nrepresentations depend on initialization? Previous empirical work has evidenced\nthat kernels defined by network activations are similar across initializations.\nFor shallow networks, this has been theoretically studied with random feature\nmodels, but an extension to deep networks has remained elusive. Here, we\nprovide a deep extension of such random feature models, which we call the\nrainbow model. We prove that rainbow networks define deterministic\n(hierarchical) kernels in the infinite-width limit. The resulting functions\nthus belong to a data-dependent RKHS which does not depend on the weight\nrandomness. We also verify numerically our modeling assumptions on deep CNNs\ntrained on image classification tasks, and show that the trained networks\napproximately satisfy the rainbow hypothesis. In particular, rainbow networks\nsampled from the corresponding random feature model achieve similar performance\nas the trained networks. Our results highlight the central role played by the\ncovariances of network weights at each layer, which are observed to be low-rank\nas a result of feature learning.\n","authors":["Florentin Guth","Brice Ménard","Gaspar Rochette","Stéphane Mallat"],"pdf_url":"https://arxiv.org/pdf/2305.18512v2.pdf","comment":"59 pages, 10 figures. To appear at JMLR"},{"id":"http://arxiv.org/abs/2410.15658v1","updated":"2024-10-21T05:56:31Z","published":"2024-10-21T05:56:31Z","title":"Calibration of ordinal regression networks","summary":"  Recent studies have shown that deep neural networks are not well-calibrated\nand produce over-confident predictions. The miscalibration issue primarily\nstems from the minimization of cross-entropy, which aims to align predicted\nsoftmax probabilities with one-hot labels. In ordinal regression tasks, this\nproblem is compounded by an additional challenge: the expectation that softmax\nprobabilities should exhibit unimodal distribution is not met with\ncross-entropy. Rather, the ordinal regression literature has focused on\nunimodality and overlooked calibration. To address these issues, we propose a\nnovel loss function that introduces order-aware calibration, ensuring that\nprediction confidence adheres to ordinal relationships between classes. It\nincorporates soft ordinal encoding and label-smoothing-based regularization to\nenforce both calibration and unimodality. Extensive experiments across three\npopular ordinal regression benchmarks demonstrate that our approach achieves\nstate-of-the-art calibration without compromising accuracy.\n","authors":["Daehwan Kim","Haejun Chung","Ikbeom Jang"],"pdf_url":"https://arxiv.org/pdf/2410.15658v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.15657v1","updated":"2024-10-21T05:51:51Z","published":"2024-10-21T05:51:51Z","title":"CL-HOI: Cross-Level Human-Object Interaction Distillation from Vision\n  Large Language Models","summary":"  Human-object interaction (HOI) detection has seen advancements with Vision\nLanguage Models (VLMs), but these methods often depend on extensive manual\nannotations. Vision Large Language Models (VLLMs) can inherently recognize and\nreason about interactions at the image level but are computationally heavy and\nnot designed for instance-level HOI detection. To overcome these limitations,\nwe propose a Cross-Level HOI distillation (CL-HOI) framework, which distills\ninstance-level HOIs from VLLMs image-level understanding without the need for\nmanual annotations. Our approach involves two stages: context distillation,\nwhere a Visual Linguistic Translator (VLT) converts visual information into\nlinguistic form, and interaction distillation, where an Interaction Cognition\nNetwork (ICN) reasons about spatial, visual, and context relations. We design\ncontrastive distillation losses to transfer image-level context and interaction\nknowledge from the teacher to the student model, enabling instance-level HOI\ndetection. Evaluations on HICO-DET and V-COCO datasets demonstrate that our\nCL-HOI surpasses existing weakly supervised methods and VLLM supervised\nmethods, showing its efficacy in detecting HOIs without manual labels.\n","authors":["Jianjun Gao","Chen Cai","Ruoyu Wang","Wenyang Liu","Kim-Hui Yap","Kratika Garg","Boon-Siew Han"],"pdf_url":"https://arxiv.org/pdf/2410.15657v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.15642v1","updated":"2024-10-21T05:08:18Z","published":"2024-10-21T05:08:18Z","title":"Resource-Efficient Medical Report Generation using Large Language Models","summary":"  Medical report generation is the task of automatically writing radiology\nreports for chest X-ray images. Manually composing these reports is a\ntime-consuming process that is also prone to human errors. Generating medical\nreports can therefore help reduce the burden on radiologists. In other words,\nwe can promote greater clinical automation in the medical domain. In this work,\nwe propose a new framework leveraging vision-enabled Large Language Models\n(LLM) for the task of medical report generation. We introduce a lightweight\nsolution that achieves better or comparative performance as compared to\nprevious solutions on the task of medical report generation. We conduct\nextensive experiments exploring different model sizes and enhancement\napproaches, such as prefix tuning to improve the text generation abilities of\nthe LLMs. We evaluate our approach on a prominent large-scale radiology report\ndataset - MIMIC-CXR. Our results demonstrate the capability of our\nresource-efficient framework to generate patient-specific reports with strong\nmedical contextual understanding and high precision.\n","authors":[" Abdullah","Ameer Hamza","Seong Tae Kim"],"pdf_url":"https://arxiv.org/pdf/2410.15642v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2402.18292v5","updated":"2024-10-21T05:06:15Z","published":"2024-02-28T12:37:30Z","title":"FSL-Rectifier: Rectify Outliers in Few-Shot Learning via Test-Time\n  Augmentation","summary":"  Few-shot-learning (FSL) commonly requires a model to identify images\n(queries) that belong to classes unseen during training, based on a few labeled\nsamples of the new classes (support set) as reference. So far, plenty of\nalgorithms involve training data augmentation to improve the generalization\ncapability of FSL models, but outlier queries or support images during\ninference can still pose great generalization challenges. In this work, to\nreduce the bias caused by the outlier samples, we generate additional\ntest-class samples by combining original samples with suitable train-class\nsamples via a generative image combiner. Then, we obtain averaged features via\nan augmentor, which leads to more typical representations through the\naveraging. We experimentally and theoretically demonstrate the effectiveness of\nour method, e.g., obtaining a test accuracy improvement proportion of around\n10% (e.g., from 46.86% to 53.28%) for trained FSL models. Importantly, given\npretrained image combiner, our method is training-free for off-the-shelf FSL\nmodels, whose performance can be improved without extra datasets nor further\ntraining of the models themselves.\n","authors":["Yunwei Bai","Ying Kiat Tan","Shiming Chen","Yao Shu","Tsuhan Chen"],"pdf_url":"https://arxiv.org/pdf/2402.18292v5.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.15636v1","updated":"2024-10-21T04:47:01Z","published":"2024-10-21T04:47:01Z","title":"LucidFusion: Generating 3D Gaussians with Arbitrary Unposed Images","summary":"  Recent large reconstruction models have made notable progress in generating\nhigh-quality 3D objects from single images. However, these methods often\nstruggle with controllability, as they lack information from multiple views,\nleading to incomplete or inconsistent 3D reconstructions. To address this\nlimitation, we introduce LucidFusion, a flexible end-to-end feed-forward\nframework that leverages the Relative Coordinate Map (RCM). Unlike traditional\nmethods linking images to 3D world thorough pose, LucidFusion utilizes RCM to\nalign geometric features coherently across different views, making it highly\nadaptable for 3D generation from arbitrary, unposed images. Furthermore,\nLucidFusion seamlessly integrates with the original single-image-to-3D\npipeline, producing detailed 3D Gaussians at a resolution of $512 \\times 512$,\nmaking it well-suited for a wide range of applications.\n","authors":["Hao He","Yixun Liang","Luozhou Wang","Yuanhao Cai","Xinli Xu","Hao-Xiang Guo","Xiang Wen","Yingcong Chen"],"pdf_url":"https://arxiv.org/pdf/2410.15636v1.pdf","comment":"17 pages, 12 figures, project page: coming soon"},{"id":"http://arxiv.org/abs/2408.03361v7","updated":"2024-10-21T04:26:41Z","published":"2024-08-06T17:59:21Z","title":"GMAI-MMBench: A Comprehensive Multimodal Evaluation Benchmark Towards\n  General Medical AI","summary":"  Large Vision-Language Models (LVLMs) are capable of handling diverse data\ntypes such as imaging, text, and physiological signals, and can be applied in\nvarious fields. In the medical field, LVLMs have a high potential to offer\nsubstantial assistance for diagnosis and treatment. Before that, it is crucial\nto develop benchmarks to evaluate LVLMs' effectiveness in various medical\napplications. Current benchmarks are often built upon specific academic\nliterature, mainly focusing on a single domain, and lacking varying perceptual\ngranularities. Thus, they face specific challenges, including limited clinical\nrelevance, incomplete evaluations, and insufficient guidance for interactive\nLVLMs. To address these limitations, we developed the GMAI-MMBench, the most\ncomprehensive general medical AI benchmark with well-categorized data structure\nand multi-perceptual granularity to date. It is constructed from 284 datasets\nacross 38 medical image modalities, 18 clinical-related tasks, 18 departments,\nand 4 perceptual granularities in a Visual Question Answering (VQA) format.\nAdditionally, we implemented a lexical tree structure that allows users to\ncustomize evaluation tasks, accommodating various assessment needs and\nsubstantially supporting medical AI research and applications. We evaluated 50\nLVLMs, and the results show that even the advanced GPT-4o only achieves an\naccuracy of 53.96%, indicating significant room for improvement. Moreover, we\nidentified five key insufficiencies in current cutting-edge LVLMs that need to\nbe addressed to advance the development of better medical applications. We\nbelieve that GMAI-MMBench will stimulate the community to build the next\ngeneration of LVLMs toward GMAI.\n","authors":["Pengcheng Chen","Jin Ye","Guoan Wang","Yanjun Li","Zhongying Deng","Wei Li","Tianbin Li","Haodong Duan","Ziyan Huang","Yanzhou Su","Benyou Wang","Shaoting Zhang","Bin Fu","Jianfei Cai","Bohan Zhuang","Eric J Seibel","Junjun He","Yu Qiao"],"pdf_url":"https://arxiv.org/pdf/2408.03361v7.pdf","comment":"GitHub: https://github.com/uni-medical/GMAI-MMBench Hugging face:\n  https://huggingface.co/datasets/OpenGVLab/GMAI-MMBench"},{"id":"http://arxiv.org/abs/2410.15629v1","updated":"2024-10-21T04:25:43Z","published":"2024-10-21T04:25:43Z","title":"Fully Explicit Dynamic Gaussian Splatting","summary":"  3D Gaussian Splatting has shown fast and high-quality rendering results in\nstatic scenes by leveraging dense 3D prior and explicit representations.\nUnfortunately, the benefits of the prior and representation do not involve\nnovel view synthesis for dynamic motions. Ironically, this is because the main\nbarrier is the reliance on them, which requires increasing training and\nrendering times to account for dynamic motions. In this paper, we design a\nExplicit 4D Gaussian Splatting(Ex4DGS). Our key idea is to firstly separate\nstatic and dynamic Gaussians during training, and to explicitly sample\npositions and rotations of the dynamic Gaussians at sparse timestamps. The\nsampled positions and rotations are then interpolated to represent both\nspatially and temporally continuous motions of objects in dynamic scenes as\nwell as reducing computational cost. Additionally, we introduce a progressive\ntraining scheme and a point-backtracking technique that improves Ex4DGS's\nconvergence. We initially train Ex4DGS using short timestamps and progressively\nextend timestamps, which makes it work well with a few point clouds. The\npoint-backtracking is used to quantify the cumulative error of each Gaussian\nover time, enabling the detection and removal of erroneous Gaussians in dynamic\nscenes. Comprehensive experiments on various scenes demonstrate the\nstate-of-the-art rendering quality from our method, achieving fast rendering of\n62 fps on a single 2080Ti GPU.\n","authors":["Junoh Lee","Chang-Yeon Won","Hyunjun Jung","Inhwan Bae","Hae-Gon Jeon"],"pdf_url":"https://arxiv.org/pdf/2410.15629v1.pdf","comment":"Accepted at NeurIPS 2024"},{"id":"http://arxiv.org/abs/2410.15628v1","updated":"2024-10-21T04:24:10Z","published":"2024-10-21T04:24:10Z","title":"Towards Kriging-informed Conditional Diffusion for Regional Sea-Level\n  Data Downscaling","summary":"  Given coarser-resolution projections from global climate models or satellite\ndata, the downscaling problem aims to estimate finer-resolution regional\nclimate data, capturing fine-scale spatial patterns and variability.\nDownscaling is any method to derive high-resolution data from low-resolution\nvariables, often to provide more detailed and local predictions and analyses.\nThis problem is societally crucial for effective adaptation, mitigation, and\nresilience against significant risks from climate change. The challenge arises\nfrom spatial heterogeneity and the need to recover finer-scale features while\nensuring model generalization. Most downscaling methods \\cite{Li2020} fail to\ncapture the spatial dependencies at finer scales and underperform on real-world\nclimate datasets, such as sea-level rise. We propose a novel Kriging-informed\nConditional Diffusion Probabilistic Model (Ki-CDPM) to capture spatial\nvariability while preserving fine-scale features. Experimental results on\nclimate data show that our proposed method is more accurate than\nstate-of-the-art downscaling techniques.\n","authors":["Subhankar Ghosh","Arun Sharma","Jayant Gupta","Aneesh Subramanian","Shashi Shekhar"],"pdf_url":"https://arxiv.org/pdf/2410.15628v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2304.10038v2","updated":"2024-10-21T04:05:25Z","published":"2023-04-20T01:32:32Z","title":"Open-World Continual Learning: Unifying Novelty Detection and Continual\n  Learning","summary":"  As AI agents are increasingly used in the real open world with unknowns or\nnovelties, they need the ability to (1) recognize objects that (a) they have\nlearned before and (b) detect items that they have never seen or learned, and\n(2) learn the new items incrementally to become more and more knowledgeable and\npowerful. (1) is called novelty detection or out-of-distribution (OOD)\ndetection and (2) is called class incremental learning (CIL), which is a\nsetting of continual learning (CL). In existing research, OOD detection and CIL\nare regarded as two completely different problems. This paper first provides a\ntheoretical proof that good OOD detection for each task within the set of\nlearned tasks (called closed-world OOD detection) is necessary for successful\nCIL. We show this by decomposing CIL into two sub-problems: within-task\nprediction (WP) and task-id prediction (TP), and proving that TP is correlated\nwith closed-world OOD detection. The key theoretical result is that regardless\nof whether WP and OOD detection (or TP) are defined explicitly or implicitly by\na CIL algorithm, good WP and good closed-world OOD detection are necessary and\nsufficient conditions for good CIL, which unifies novelty or OOD detection and\ncontinual learning (CIL, in particular). We call this traditional CIL the\nclosed-world CIL as it does not detect future OOD data in the open world. The\npaper then proves that the theory can be generalized or extended to open-world\nCIL, which is the proposed open-world continual learning, that can perform CIL\nin the open world and detect future or open-world OOD data. Based on the\ntheoretical results, new CIL methods are also designed, which outperform strong\nbaselines in CIL accuracy and in continual OOD detection by a large margin.\n","authors":["Gyuhak Kim","Changnan Xiao","Tatsuya Konishi","Zixuan Ke","Bing Liu"],"pdf_url":"https://arxiv.org/pdf/2304.10038v2.pdf","comment":"To appear in Artificial Intelligence Journal. arXiv admin note:\n  substantial text overlap with arXiv:2211.02633"},{"id":"http://arxiv.org/abs/2405.10160v2","updated":"2024-10-21T03:49:58Z","published":"2024-05-16T14:53:45Z","title":"PIR: Remote Sensing Image-Text Retrieval with Prior Instruction\n  Representation Learning","summary":"  Remote sensing image-text retrieval constitutes a foundational aspect of\nremote sensing interpretation tasks, facilitating the alignment of vision and\nlanguage representations. This paper introduces a prior instruction\nrepresentation (PIR) learning paradigm that draws on prior knowledge to\ninstruct adaptive learning of vision and text representations. Based on PIR, a\ndomain-adapted remote sensing image-text retrieval framework PIR-ITR is\ndesigned to address semantic noise issues in vision-language understanding\ntasks. However, with massive additional data for pre-training the\nvision-language foundation model, remote sensing image-text retrieval is\nfurther developed into an open-domain retrieval task. Continuing with the\nabove, we propose PIR-CLIP, a domain-specific CLIP-based framework for remote\nsensing image-text retrieval, to address semantic noise in remote sensing\nvision-language representations and further improve open-domain retrieval\nperformance. In vision representation, we utilize the prior-guided knowledge of\nthe remote sensing scene recognition by building a belief matrix to select key\nfeatures for reducing the impact of semantic noise. In text representation, we\nuse the previous time step to cyclically activate the current time step to\nenhance text representation capability. A cluster-wise Affiliation Loss (AL) is\nproposed to constrain the inter-classes and to reduce the semantic confusion\nzones in the common subspace. Comprehensive experiments demonstrate that PIR\ncould enhance vision and text representations and outperform the\nstate-of-the-art methods of closed-domain and open-domain retrieval on two\nbenchmark datasets, RSICD and RSITMD.\n","authors":["Jiancheng Pan","Muyuan Ma","Qing Ma","Cong Bai","Shengyong Chen"],"pdf_url":"https://arxiv.org/pdf/2405.10160v2.pdf","comment":"13 pages, 8 figures"},{"id":"http://arxiv.org/abs/2410.15618v1","updated":"2024-10-21T03:40:29Z","published":"2024-10-21T03:40:29Z","title":"Erasing Undesirable Concepts in Diffusion Models with Adversarial\n  Preservation","summary":"  Diffusion models excel at generating visually striking content from text but\ncan inadvertently produce undesirable or harmful content when trained on\nunfiltered internet data. A practical solution is to selectively removing\ntarget concepts from the model, but this may impact the remaining concepts.\nPrior approaches have tried to balance this by introducing a loss term to\npreserve neutral content or a regularization term to minimize changes in the\nmodel parameters, yet resolving this trade-off remains challenging. In this\nwork, we propose to identify and preserving concepts most affected by parameter\nchanges, termed as \\textit{adversarial concepts}. This approach ensures stable\nerasure with minimal impact on the other concepts. We demonstrate the\neffectiveness of our method using the Stable Diffusion model, showing that it\noutperforms state-of-the-art erasure methods in eliminating unwanted content\nwhile maintaining the integrity of other unrelated elements. Our code is\navailable at\n\\url{https://github.com/tuananhbui89/Erasing-Adversarial-Preservation}.\n","authors":["Anh Bui","Long Vuong","Khanh Doan","Trung Le","Paul Montague","Tamas Abraham","Dinh Phung"],"pdf_url":"https://arxiv.org/pdf/2410.15618v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.15615v1","updated":"2024-10-21T03:33:13Z","published":"2024-10-21T03:33:13Z","title":"Joint Top-Down and Bottom-Up Frameworks for 3D Visual Grounding","summary":"  This paper tackles the challenging task of 3D visual grounding-locating a\nspecific object in a 3D point cloud scene based on text descriptions. Existing\nmethods fall into two categories: top-down and bottom-up methods. Top-down\nmethods rely on a pre-trained 3D detector to generate and select the best\nbounding box, resulting in time-consuming processes. Bottom-up methods directly\nregress object bounding boxes with coarse-grained features, producing worse\nresults. To combine their strengths while addressing their limitations, we\npropose a joint top-down and bottom-up framework, aiming to enhance the\nperformance while improving the efficiency. Specifically, in the first stage,\nwe propose a bottom-up based proposal generation module, which utilizes\nlightweight neural layers to efficiently regress and cluster several coarse\nobject proposals instead of using a complex 3D detector. Then, in the second\nstage, we introduce a top-down based proposal consolidation module, which\nutilizes graph design to effectively aggregate and propagate the query-related\nobject contexts among the generated proposals for further refinement. By\njointly training these two modules, we can avoid the inherent drawbacks of the\ncomplex proposals in the top-down framework and the coarse proposals in the\nbottom-up framework. Experimental results on the ScanRefer benchmark show that\nour framework is able to achieve the state-of-the-art performance.\n","authors":["Yang Liu","Daizong Liu","Wei Hu"],"pdf_url":"https://arxiv.org/pdf/2410.15615v1.pdf","comment":"Accepted by ICPR2024"},{"id":"http://arxiv.org/abs/2410.15614v1","updated":"2024-10-21T03:33:09Z","published":"2024-10-21T03:33:09Z","title":"Topology-Aware Exploration of Circle of Willis for CTA and MRA:\n  Segmentation, Detection, and Classification","summary":"  The Circle of Willis (CoW) vessels is critical to connecting major\ncirculations of the brain. The topology of the vascular structure is clinical\nsignificance to evaluate the risk, severity of the neuro-vascular diseases. The\nCoW has two representative angiographic imaging modalities, computed tomography\nangiography (CTA) and magnetic resonance angiography (MRA). TopCow24 provided\n125 paired CTA-MRA dataset for the analysis of CoW. To explore both CTA and MRA\nimages in a unified framework to learn the inherent topology of Cow, we\nconstruct the universal dataset via independent intensity preprocess, followed\nby joint resampling and normarlization. Then, we utilize the topology-aware\nloss to enhance the topology completeness of the CoW and the discrimination\nbetween different classes. A complementary topology-aware refinement is further\nconducted to enhance the connectivity within the same class. Our method was\nevaluated on all the three tasks and two modalities, achieving competitive\nresults. In the final test phase of TopCow24 Challenge, we achieved the second\nplace in the CTA-Seg-Task, the third palce in the CTA-Box-Task, the first place\nin the CTA-Edg-Task, the second place in the MRA-Seg-Task, the third palce in\nthe MRA-Box-Task, the second place in the MRA-Edg-Task.\n","authors":["Minghui Zhang","Xin You","Hanxiao Zhang","Yun Gu"],"pdf_url":"https://arxiv.org/pdf/2410.15614v1.pdf","comment":"Participation technical report for TopCoW24 challenge @ MICCAI 2024"},{"id":"http://arxiv.org/abs/2410.15613v1","updated":"2024-10-21T03:17:25Z","published":"2024-10-21T03:17:25Z","title":"Exploring Stronger Transformer Representation Learning for Occluded\n  Person Re-Identificatio","summary":"  Due to some complex factors (e.g., occlusion, pose variation and diverse\ncamera perspectives), extracting stronger feature representation in person\nre-identification remains a challenging task. In this paper, we proposed a\nnovel self-supervision and supervision combining transformer-based person\nre-identification framework, namely SSSC-TransReID. Different from the general\ntransformer-based person re-identification models, we designed a\nself-supervised contrastive learning branch, which can enhance the feature\nrepresentation for person re-identification without negative samples or\nadditional pre-training. In order to train the contrastive learning branch, we\nalso proposed a novel random rectangle mask strategy to simulate the occlusion\nin real scenes, so as to enhance the feature representation for occlusion.\nFinally, we utilized the joint-training loss function to integrate the\nadvantages of supervised learning with ID tags and self-supervised contrastive\nlearning without negative samples, which can reinforce the ability of our model\nto excavate stronger discriminative features, especially for occlusion.\nExtensive experimental results on several benchmark datasets show our proposed\nmodel obtains superior Re-ID performance consistently and outperforms the\nstate-of-the-art ReID methods by large margins on the mean average accuracy\n(mAP) and Rank-1 accuracy.\n","authors":["Zhangjian Ji","Donglin Cheng","Kai Feng"],"pdf_url":"https://arxiv.org/pdf/2410.15613v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2402.11507v2","updated":"2024-10-21T03:13:20Z","published":"2024-02-18T08:34:15Z","title":"MAL: Motion-Aware Loss with Temporal and Distillation Hints for\n  Self-Supervised Depth Estimation","summary":"  Depth perception is crucial for a wide range of robotic applications.\nMulti-frame self-supervised depth estimation methods have gained research\ninterest due to their ability to leverage large-scale, unlabeled real-world\ndata. However, the self-supervised methods often rely on the assumption of a\nstatic scene and their performance tends to degrade in dynamic environments. To\naddress this issue, we present Motion-Aware Loss, which leverages the temporal\nrelation among consecutive input frames and a novel distillation scheme between\nthe teacher and student networks in the multi-frame self-supervised depth\nestimation methods. Specifically, we associate the spatial locations of moving\nobjects with the temporal order of input frames to eliminate errors induced by\nobject motion. Meanwhile, we enhance the original distillation scheme in\nmulti-frame methods to better exploit the knowledge from a teacher network. MAL\nis a novel, plug-and-play module designed for seamless integration into\nmulti-frame self-supervised monocular depth estimation methods. Adding MAL into\nprevious state-of-the-art methods leads to a reduction in depth estimation\nerrors by up to 4.2% and 10.8% on KITTI and CityScapes benchmarks,\nrespectively.\n","authors":["Yue-Jiang Dong","Fang-Lue Zhang","Song-Hai Zhang"],"pdf_url":"https://arxiv.org/pdf/2402.11507v2.pdf","comment":"Accepted by ICRA 2024; Project homepage:\n  https://yuejiangdong.github.io/MotionAwareLoss/"},{"id":"http://arxiv.org/abs/2406.01597v2","updated":"2024-10-21T03:11:29Z","published":"2024-04-09T14:37:54Z","title":"End-to-End Rate-Distortion Optimized 3D Gaussian Representation","summary":"  3D Gaussian Splatting (3DGS) has become an emerging technique with remarkable\npotential in 3D representation and image rendering. However, the substantial\nstorage overhead of 3DGS significantly impedes its practical applications. In\nthis work, we formulate the compact 3D Gaussian learning as an end-to-end\nRate-Distortion Optimization (RDO) problem and propose RDO-Gaussian that can\nachieve flexible and continuous rate control. RDO-Gaussian addresses two main\nissues that exist in current schemes: 1) Different from prior endeavors that\nminimize the rate under the fixed distortion, we introduce dynamic pruning and\nentropy-constrained vector quantization (ECVQ) that optimize the rate and\ndistortion at the same time. 2) Previous works treat the colors of each\nGaussian equally, while we model the colors of different regions and materials\nwith learnable numbers of parameters. We verify our method on both real and\nsynthetic scenes, showcasing that RDO-Gaussian greatly reduces the size of 3D\nGaussian over 40x, and surpasses existing methods in rate-distortion\nperformance.\n","authors":["Henan Wang","Hanxin Zhu","Tianyu He","Runsen Feng","Jiajun Deng","Jiang Bian","Zhibo Chen"],"pdf_url":"https://arxiv.org/pdf/2406.01597v2.pdf","comment":"ECCV 2024"},{"id":"http://arxiv.org/abs/2405.08813v3","updated":"2024-10-21T03:08:08Z","published":"2024-05-14T17:59:02Z","title":"CinePile: A Long Video Question Answering Dataset and Benchmark","summary":"  Current datasets for long-form video understanding often fall short of\nproviding genuine long-form comprehension challenges, as many tasks derived\nfrom these datasets can be successfully tackled by analyzing just one or a few\nrandom frames from a video. To address this issue, we present a novel dataset\nand benchmark, CinePile, specifically designed for authentic long-form video\nunderstanding. This paper details our innovative approach for creating a\nquestion-answer dataset, utilizing advanced LLMs with human-in-the-loop and\nbuilding upon human-generated raw data. Our comprehensive dataset comprises\n305,000 multiple-choice questions (MCQs), covering various visual and\nmultimodal aspects, including temporal comprehension, understanding\nhuman-object interactions, and reasoning about events or actions within a\nscene. Additionally, we fine-tuned open-source Video-LLMs on the training split\nand evaluated both open-source and proprietary video-centric LLMs on the test\nsplit of our dataset. The findings indicate that although current models\nunderperform compared to humans, fine-tuning these models can lead to\nsignificant improvements in their performance.\n","authors":["Ruchit Rawal","Khalid Saifullah","Miquel Farré","Ronen Basri","David Jacobs","Gowthami Somepalli","Tom Goldstein"],"pdf_url":"https://arxiv.org/pdf/2405.08813v3.pdf","comment":"Project page with all the artifacts -\n  https://ruchitrawal.github.io/cinepile/. Updated version with adversarial\n  refinement pipeline and more model evaluations"},{"id":"http://arxiv.org/abs/2410.15605v1","updated":"2024-10-21T03:04:09Z","published":"2024-10-21T03:04:09Z","title":"Deep Active Learning with Manifold-preserving Trajectory Sampling","summary":"  Active learning (AL) is for optimizing the selection of unlabeled data for\nannotation (labeling), aiming to enhance model performance while minimizing\nlabeling effort. The key question in AL is which unlabeled data should be\nselected for annotation. Existing deep AL methods arguably suffer from bias\nincurred by clabeled data, which takes a much lower percentage than unlabeled\ndata in AL context. We observe that such an issue is severe in different types\nof data, such as vision and non-vision data. To address this issue, we propose\na novel method, namely Manifold-Preserving Trajectory Sampling (MPTS), aiming\nto enforce the feature space learned from labeled data to represent a more\naccurate manifold. By doing so, we expect to effectively correct the bias\nincurred by labeled data, which can cause a biased selection of unlabeled data.\nDespite its focus on manifold, the proposed method can be conveniently\nimplemented by performing distribution mapping with MMD (Maximum Mean\nDiscrepancies). Extensive experiments on various vision and non-vision\nbenchmark datasets demonstrate the superiority of our method. Our source code\ncan be found here.\n","authors":["Yingrui Ji","Vijaya Sindhoori Kaza","Nishanth Artham","Tianyang Wang"],"pdf_url":"https://arxiv.org/pdf/2410.15605v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.15602v1","updated":"2024-10-21T02:56:44Z","published":"2024-10-21T02:56:44Z","title":"P-YOLOv8: Efficient and Accurate Real-Time Detection of Distracted\n  Driving","summary":"  Distracted driving is a critical safety issue that leads to numerous\nfatalities and injuries worldwide. This study addresses the urgent need for\nefficient and real-time machine learning models to detect distracted driving\nbehaviors. Leveraging the Pretrained YOLOv8 (P-YOLOv8) model, a real-time\nobject detection system is introduced, optimized for both speed and accuracy.\nThis approach addresses the computational constraints and latency limitations\ncommonly associated with conventional detection models. The study demonstrates\nP-YOLOv8 versatility in both object detection and image classification tasks\nusing the Distracted Driver Detection dataset from State Farm, which includes\n22,424 images across ten behavior categories. Our research explores the\napplication of P-YOLOv8 for image classification, evaluating its performance\ncompared to deep learning models such as VGG16, VGG19, and ResNet. Some\ntraditional models often struggle with low accuracy, while others achieve high\naccuracy but come with high computational costs and slow detection speeds,\nmaking them unsuitable for real-time applications. P-YOLOv8 addresses these\nissues by achieving competitive accuracy with significant computational cost\nand efficiency advantages. In particular, P-YOLOv8 generates a lightweight\nmodel with a size of only 2.84 MB and a lower number of parameters, totaling\n1,451,098, due to its innovative architecture. It achieves a high accuracy of\n99.46 percent with this small model size, opening new directions for deployment\non inexpensive and small embedded devices using Tiny Machine Learning (TinyML).\nThe experimental results show robust performance, making P-YOLOv8 a\ncost-effective solution for real-time deployment. This study provides a\ndetailed analysis of P-YOLOv8's architecture, training, and performance\nbenchmarks, highlighting its potential for real-time use in detecting\ndistracted driving.\n","authors":["Mohamed R. Elshamy","Heba M. Emara","Mohamed R. Shoaib","Abdel-Hameed A. Badawy"],"pdf_url":"https://arxiv.org/pdf/2410.15602v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.15584v1","updated":"2024-10-21T02:10:49Z","published":"2024-10-21T02:10:49Z","title":"Deep Learning and Machine Learning -- Object Detection and Semantic\n  Segmentation: From Theory to Applications","summary":"  This book offers an in-depth exploration of object detection and semantic\nsegmentation, combining theoretical foundations with practical applications. It\ncovers state-of-the-art advancements in machine learning and deep learning,\nwith a focus on convolutional neural networks (CNNs), YOLO architectures, and\ntransformer-based approaches like DETR. The book also delves into the\nintegration of artificial intelligence (AI) techniques and large language\nmodels for enhanced object detection in complex environments. A thorough\ndiscussion of big data analysis is presented, highlighting the importance of\ndata processing, model optimization, and performance evaluation metrics. By\nbridging the gap between traditional methods and modern deep learning\nframeworks, this book serves as a comprehensive guide for researchers, data\nscientists, and engineers aiming to leverage AI-driven methodologies in\nlarge-scale object detection tasks.\n","authors":["Jintao Ren","Ziqian Bi","Qian Niu","Junyu Liu","Benji Peng","Sen Zhang","Xuanhe Pan","Jinlang Wang","Keyu Chen","Caitlyn Heqi Yin","Pohsun Feng","Yizhu Wen","Tianyang Wang","Silin Chen","Ming Li","Jiawei Xu","Ming Liu"],"pdf_url":"https://arxiv.org/pdf/2410.15584v1.pdf","comment":"167 pages"},{"id":"http://arxiv.org/abs/2410.15582v1","updated":"2024-10-21T02:06:43Z","published":"2024-10-21T02:06:43Z","title":"ARTS: Semi-Analytical Regressor using Disentangled Skeletal\n  Representations for Human Mesh Recovery from Videos","summary":"  Although existing video-based 3D human mesh recovery methods have made\nsignificant progress, simultaneously estimating human pose and shape from\nlow-resolution image features limits their performance. These image features\nlack sufficient spatial information about the human body and contain various\nnoises (e.g., background, lighting, and clothing), which often results in\ninaccurate pose and inconsistent motion. Inspired by the rapid advance in human\npose estimation, we discover that compared to image features, skeletons\ninherently contain accurate human pose and motion. Therefore, we propose a\nnovel semiAnalytical Regressor using disenTangled Skeletal representations for\nhuman mesh recovery from videos, called ARTS. Specifically, a skeleton\nestimation and disentanglement module is proposed to estimate the 3D skeletons\nfrom a video and decouple them into disentangled skeletal representations\n(i.e., joint position, bone length, and human motion). Then, to fully utilize\nthese representations, we introduce a semi-analytical regressor to estimate the\nparameters of the human mesh model. The regressor consists of three modules:\nTemporal Inverse Kinematics (TIK), Bone-guided Shape Fitting (BSF), and\nMotion-Centric Refinement (MCR). TIK utilizes joint position to estimate\ninitial pose parameters and BSF leverages bone length to regress bone-aligned\nshape parameters. Finally, MCR combines human motion representation with image\nfeatures to refine the initial human model parameters. Extensive experiments\ndemonstrate that our ARTS surpasses existing state-of-the-art video-based\nmethods in both per-frame accuracy and temporal consistency on popular\nbenchmarks: 3DPW, MPI-INF-3DHP, and Human3.6M. Code is available at\nhttps://github.com/TangTao-PKU/ARTS.\n","authors":["Tao Tang","Hong Liu","Yingxuan You","Ti Wang","Wenhao Li"],"pdf_url":"https://arxiv.org/pdf/2410.15582v1.pdf","comment":"Accepted by ACM MM 2024. Project page:\n  https://github.com/TangTao-PKU/ARTS"},{"id":"http://arxiv.org/abs/2410.15581v1","updated":"2024-10-21T01:58:26Z","published":"2024-10-21T01:58:26Z","title":"Multimodal Learning for Embryo Viability Prediction in Clinical IVF","summary":"  In clinical In-Vitro Fertilization (IVF), identifying the most viable embryo\nfor transfer is important to increasing the likelihood of a successful\npregnancy. Traditionally, this process involves embryologists manually\nassessing embryos' static morphological features at specific intervals using\nlight microscopy. This manual evaluation is not only time-intensive and costly,\ndue to the need for expert analysis, but also inherently subjective, leading to\nvariability in the selection process. To address these challenges, we develop a\nmultimodal model that leverages both time-lapse video data and Electronic\nHealth Records (EHRs) to predict embryo viability. One of the primary\nchallenges of our research is to effectively combine time-lapse video and EHR\ndata, owing to their inherent differences in modality. We comprehensively\nanalyze our multimodal model with various modality inputs and integration\napproaches. Our approach will enable fast and automated embryo viability\npredictions in scale for clinical IVF.\n","authors":["Junsik Kim","Zhiyi Shi","Davin Jeong","Johannes Knittel","Helen Y. Yang","Yonghyun Song","Wanhua Li","Yicong Li","Dalit Ben-Yosef","Daniel Needleman","Hanspeter Pfister"],"pdf_url":"https://arxiv.org/pdf/2410.15581v1.pdf","comment":"Accepted to MICCAI 2024"},{"id":"http://arxiv.org/abs/2410.15569v1","updated":"2024-10-21T01:23:42Z","published":"2024-10-21T01:23:42Z","title":"Online Pseudo-Label Unified Object Detection for Multiple Datasets\n  Training","summary":"  The Unified Object Detection (UOD) task aims to achieve object detection of\nall merged categories through training on multiple datasets, and is of great\nsignificance in comprehensive object detection scenarios. In this paper, we\nconduct a thorough analysis of the cross datasets missing annotations issue,\nand propose an Online Pseudo-Label Unified Object Detection scheme. Our method\nuses a periodically updated teacher model to generate pseudo-labels for the\nunlabelled objects in each sub-dataset. This periodical update strategy could\nbetter ensure that the accuracy of the teacher model reaches the local maxima\nand maximized the quality of pseudo-labels. In addition, we survey the\ninfluence of overlapped region proposals on the accuracy of box regression. We\npropose a category specific box regression and a pseudo-label RPN head to\nimprove the recall rate of the Region Proposal Network (PRN). Our experimental\nresults on common used benchmarks (\\eg COCO, Object365 and OpenImages)\nindicates that our online pseudo-label UOD method achieves higher accuracy than\nexisting SOTA methods.\n","authors":["XiaoJun Tang","Jingru Wang","Zeyu Shangguan","Darun Tang","Yuyu Liu"],"pdf_url":"https://arxiv.org/pdf/2410.15569v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.13147v2","updated":"2024-10-21T00:38:07Z","published":"2024-10-17T02:04:57Z","title":"Utilizing Large Language Models in An Iterative Paradigm with Domain\n  Feedback for Molecule Optimization","summary":"  Molecule optimization is a critical task in drug discovery to optimize\ndesired properties of a given molecule through chemical modification. Despite\nLarge Language Models (LLMs) holding the potential to efficiently simulate this\ntask by using natural language to direct the optimization, straightforwardly\nutilizing shows limited performance. In this work, we facilitate utilizing LLMs\nin an iterative paradigm by proposing a simple yet highly effective domain\nfeedback provider, namely $\\text{Re}^2$DF. In detail, $\\text{Re}^2$DF harnesses\nan external toolkit, RDKit, to handle the molecule hallucination, if the\nmodified molecule is chemically invalid. Otherwise, its desired properties are\ncomputed and compared to the original one, establishing reliable domain\nfeedback with correct direction and distance towards the objective, followed by\na retrieved example, to explicitly guide the LLM to refine the modified\nmolecule. We conduct experiments across both single- and multi-property\nobjectives with 2 thresholds, where $\\text{Re}^2$DF shows significant\nimprovements. Particularly, for 20 single-property objectives, $\\text{Re}^2$DF\nenhances Hit ratio by 16.95% and 20.76% under loose and strict thresholds,\nrespectively. For 32 multi-property objectives, $\\text{Re}^2$DF enhances Hit\nratio by 6.04% and 5.25%.\n","authors":["Khiem Le","Nitesh V. Chawla"],"pdf_url":"https://arxiv.org/pdf/2410.13147v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.15549v1","updated":"2024-10-21T00:36:02Z","published":"2024-10-21T00:36:02Z","title":"A Dual Process VLA: Efficient Robotic Manipulation Leveraging VLM","summary":"  Vision-Language-Action (VLA) models are receiving increasing attention for\ntheir ability to enable robots to perform complex tasks by integrating visual\ncontext with linguistic commands. However, achieving efficient real-time\nperformance remains challenging due to the high computational demands of\nexisting models. To overcome this, we propose Dual Process VLA (DP-VLA), a\nhierarchical framework inspired by dual-process theory. DP-VLA utilizes a Large\nSystem 2 Model (L-Sys2) for complex reasoning and decision-making, while a\nSmall System 1 Model (S-Sys1) handles real-time motor control and sensory\nprocessing. By leveraging Vision-Language Models (VLMs), the L-Sys2 operates at\nlow frequencies, reducing computational overhead, while the S-Sys1 ensures fast\nand accurate task execution. Experimental results on the RoboCasa dataset\ndemonstrate that DP-VLA achieves faster inference and higher task success\nrates, providing a scalable solution for advanced robotic applications.\n","authors":["ByungOk Han","Jaehong Kim","Jinhyeok Jang"],"pdf_url":"https://arxiv.org/pdf/2410.15549v1.pdf","comment":"10 page"},{"id":"http://arxiv.org/abs/2408.12528v6","updated":"2024-10-21T00:33:23Z","published":"2024-08-22T16:32:32Z","title":"Show-o: One Single Transformer to Unify Multimodal Understanding and\n  Generation","summary":"  We present a unified transformer, i.e., Show-o, that unifies multimodal\nunderstanding and generation. Unlike fully autoregressive models, Show-o\nunifies autoregressive and (discrete) diffusion modeling to adaptively handle\ninputs and outputs of various and mixed modalities. The unified model flexibly\nsupports a wide range of vision-language tasks including visual\nquestion-answering, text-to-image generation, text-guided\ninpainting/extrapolation, and mixed-modality generation. Across various\nbenchmarks, it demonstrates comparable or superior performance to existing\nindividual models with an equivalent or larger number of parameters tailored\nfor understanding or generation. This significantly highlights its potential as\na next-generation foundation model. Code and models are released at\nhttps://github.com/showlab/Show-o.\n","authors":["Jinheng Xie","Weijia Mao","Zechen Bai","David Junhao Zhang","Weihao Wang","Kevin Qinghong Lin","Yuchao Gu","Zhijie Chen","Zhenheng Yang","Mike Zheng Shou"],"pdf_url":"https://arxiv.org/pdf/2408.12528v6.pdf","comment":"Technical Report"},{"id":"http://arxiv.org/abs/2406.09662v2","updated":"2024-10-21T23:58:45Z","published":"2024-06-14T02:21:53Z","title":"Learning Language Structures through Grounding","summary":"  Language is highly structured, with syntactic and semantic structures, to\nsome extent, agreed upon by speakers of the same language. With implicit or\nexplicit awareness of such structures, humans can learn and use language\nefficiently and generalize to sentences that contain unseen words. Motivated by\nhuman language learning, in this dissertation, we consider a family of machine\nlearning tasks that aim to learn language structures through grounding. We seek\ndistant supervision from other data sources (i.e., grounds), including but not\nlimited to other modalities (e.g., vision), execution results of programs, and\nother languages.\n  We demonstrate the potential of this task formulation and advocate for its\nadoption through three schemes. In Part I, we consider learning syntactic\nparses through visual grounding. We propose the task of visually grounded\ngrammar induction, present the first models to induce syntactic structures from\nvisually grounded text and speech, and find that the visual grounding signals\ncan help improve the parsing quality over language-only models. As a side\ncontribution, we propose a novel evaluation metric that enables the evaluation\nof speech parsing without text or automatic speech recognition systems\ninvolved. In Part II, we propose two execution-aware methods to map sentences\ninto corresponding semantic structures (i.e., programs), significantly\nimproving compositional generalization and few-shot program synthesis. In Part\nIII, we propose methods that learn language structures from annotations in\nother languages. Specifically, we propose a method that sets a new state of the\nart on cross-lingual word alignment. We then leverage the learned word\nalignments to improve the performance of zero-shot cross-lingual dependency\nparsing, by proposing a novel substructure-based projection method that\npreserves structural knowledge learned from the source language.\n","authors":["Freda Shi"],"pdf_url":"https://arxiv.org/pdf/2406.09662v2.pdf","comment":"Ph.D. Thesis"},{"id":"http://arxiv.org/abs/2409.03901v2","updated":"2024-10-21T23:15:51Z","published":"2024-09-05T20:21:49Z","title":"Onboard Satellite Image Classification for Earth Observation: A\n  Comparative Study of ViT Models","summary":"  This study focuses on identifying the most effective pre-trained model for\nland use classification in onboard satellite processing, emphasizing achieving\nhigh accuracy, computational efficiency, and robustness against noisy data\nconditions commonly encountered during satellite-based inference. Through\nextensive experimentation, we compare the performance of traditional CNN-based,\nResNet-based, and various pre-trained vision Transformer models. Our findings\ndemonstrate that pre-trained Vision Transformer (ViT) models, particularly\nMobileViTV2 and EfficientViT-M2, outperform models trained from scratch in\nterms of accuracy and efficiency. These models achieve high performance with\nreduced computational requirements and exhibit greater resilience during\ninference under noisy conditions. While MobileViTV2 has excelled on clean\nvalidation data, EfficientViT-M2 has proved more robust when handling noise,\nmaking it the most suitable model for onboard satellite EO tasks. Our\nexperimental results demonstrate that EfficientViT-M2 is the optimal choice for\nreliable and efficient RS-IC in satellite operations, achieving 98.76 % of\naccuracy, precision, and recall. Precisely, EfficientViT-M2 delivers the\nhighest performance across all metrics, excels in training efficiency (1,000s)\nand inference time (10s), and demonstrates greater robustness (overall\nrobustness score of 0.79). Consequently, EfficientViT-M2 consumes 63.93 % less\npower than MobileViTV2 (79.23 W) and 73.26 % less power than SwinTransformer\n(108.90 W). This highlights its significant advantage in energy efficiency.\n","authors":["Thanh-Dung Le","Vu Nguyen Ha","Ti Ti Nguyen","Geoffrey Eappen","Prabhu Thiruvasagam","Luis M. Garces-Socarras","Hong-fu Chou","Jorge L. Gonzalez-Rios","Juan Carlos Merlano-Duncan","Symeon Chatzinotas"],"pdf_url":"https://arxiv.org/pdf/2409.03901v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.16545v1","updated":"2024-10-21T22:16:37Z","published":"2024-10-21T22:16:37Z","title":"PlaneSAM: Multimodal Plane Instance Segmentation Using the Segment\n  Anything Model","summary":"  Plane instance segmentation from RGB-D data is a crucial research topic for\nmany downstream tasks. However, most existing deep-learning-based methods\nutilize only information within the RGB bands, neglecting the important role of\nthe depth band in plane instance segmentation. Based on EfficientSAM, a fast\nversion of SAM, we propose a plane instance segmentation network called\nPlaneSAM, which can fully integrate the information of the RGB bands (spectral\nbands) and the D band (geometric band), thereby improving the effectiveness of\nplane instance segmentation in a multimodal manner. Specifically, we use a\ndual-complexity backbone, with primarily the simpler branch learning D-band\nfeatures and primarily the more complex branch learning RGB-band features.\nConsequently, the backbone can effectively learn D-band feature representations\neven when D-band training data is limited in scale, retain the powerful\nRGB-band feature representations of EfficientSAM, and allow the original\nbackbone branch to be fine-tuned for the current task. To enhance the\nadaptability of our PlaneSAM to the RGB-D domain, we pretrain our\ndual-complexity backbone using the segment anything task on large-scale RGB-D\ndata through a self-supervised pretraining strategy based on imperfect\npseudo-labels. To support the segmentation of large planes, we optimize the\nloss function combination ratio of EfficientSAM. In addition, Faster R-CNN is\nused as a plane detector, and its predicted bounding boxes are fed into our\ndual-complexity network as prompts, thereby enabling fully automatic plane\ninstance segmentation. Experimental results show that the proposed PlaneSAM\nsets a new SOTA performance on the ScanNet dataset, and outperforms previous\nSOTA approaches in zero-shot transfer on the 2D-3D-S, Matterport3D, and\nICL-NUIM RGB-D datasets, while only incurring a 10% increase in computational\noverhead compared to EfficientSAM.\n","authors":["Zhongchen Deng","Zhechen Yang","Chi Chen","Cheng Zeng","Yan Meng","Bisheng Yang"],"pdf_url":"https://arxiv.org/pdf/2410.16545v1.pdf","comment":"submitted to Information Fusion"},{"id":"http://arxiv.org/abs/2310.17042v3","updated":"2024-10-21T21:54:46Z","published":"2023-10-25T22:45:31Z","title":"StochGradAdam: Accelerating Neural Networks Training with Stochastic\n  Gradient Sampling","summary":"  In this paper, we introduce StochGradAdam, a novel optimizer designed as an\nextension of the Adam algorithm, incorporating stochastic gradient sampling\ntechniques to improve computational efficiency while maintaining robust\nperformance. StochGradAdam optimizes by selectively sampling a subset of\ngradients during training, reducing the computational cost while preserving the\nadvantages of adaptive learning rates and bias corrections found in Adam. Our\nexperimental results, applied to image classification and segmentation tasks,\ndemonstrate that StochGradAdam can achieve comparable or superior performance\nto Adam, even when using fewer gradient updates per iteration. By focusing on\nkey gradient updates, StochGradAdam offers stable convergence and enhanced\nexploration of the loss landscape, while mitigating the impact of noisy\ngradients. The results suggest that this approach is particularly effective for\nlarge-scale models and datasets, providing a promising alternative to\ntraditional optimization techniques for deep learning applications.\n","authors":["Juyoung Yun"],"pdf_url":"https://arxiv.org/pdf/2310.17042v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.16533v1","updated":"2024-10-21T21:48:24Z","published":"2024-10-21T21:48:24Z","title":"Large Body Language Models","summary":"  As virtual agents become increasingly prevalent in human-computer\ninteraction, generating realistic and contextually appropriate gestures in\nreal-time remains a significant challenge. While neural rendering techniques\nhave made substantial progress with static scripts, their applicability to\nhuman-computer interactions remains limited. To address this, we introduce\nLarge Body Language Models (LBLMs) and present LBLM-AVA, a novel LBLM\narchitecture that combines a Transformer-XL large language model with a\nparallelized diffusion model to generate human-like gestures from multimodal\ninputs (text, audio, and video). LBLM-AVA incorporates several key components\nenhancing its gesture generation capabilities, such as multimodal-to-pose\nembeddings, enhanced sequence-to-sequence mapping with redefined attention\nmechanisms, a temporal smoothing module for gesture sequence coherence, and an\nattention-based refinement module for enhanced realism. The model is trained on\nour large-scale proprietary open-source dataset Allo-AVA. LBLM-AVA achieves\nstate-of-the-art performance in generating lifelike and contextually\nappropriate gestures with a 30% reduction in Fr\\'echet Gesture Distance (FGD),\nand a 25% improvement in Fr\\'echet Inception Distance compared to existing\napproaches.\n","authors":["Saif Punjwani","Larry Heck"],"pdf_url":"https://arxiv.org/pdf/2410.16533v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.16524v1","updated":"2024-10-21T21:32:17Z","published":"2024-10-21T21:32:17Z","title":"Gradient-Free Supervised Learning using Spike-Timing-Dependent\n  Plasticity for Image Recognition","summary":"  An approach to supervised learning in spiking neural networks is presented\nusing a gradient-free method combined with spike-timing-dependent plasticity\nfor image recognition. The proposed network architecture is scalable to\nmultiple layers, enabling the development of more complex and deeper SNN\nmodels. The effectiveness of this method is demonstrated by its application to\nthe MNIST dataset, showing good learning accuracy. The proposed method provides\na robust and efficient alternative to the backpropagation-based method in\nsupervised learning.\n","authors":["Wei Xie"],"pdf_url":"https://arxiv.org/pdf/2410.16524v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.16523v1","updated":"2024-10-21T21:31:12Z","published":"2024-10-21T21:31:12Z","title":"Efficient Neural Network Training via Subset Pretraining","summary":"  In training neural networks, it is common practice to use partial gradients\ncomputed over batches, mostly very small subsets of the training set. This\napproach is motivated by the argument that such a partial gradient is close to\nthe true one, with precision growing only with the square root of the batch\nsize. A theoretical justification is with the help of stochastic approximation\ntheory. However, the conditions for the validity of this theory are not\nsatisfied in the usual learning rate schedules. Batch processing is also\ndifficult to combine with efficient second-order optimization methods. This\nproposal is based on another hypothesis: the loss minimum of the training set\ncan be expected to be well-approximated by the minima of its subsets. Such\nsubset minima can be computed in a fraction of the time necessary for\noptimizing over the whole training set. This hypothesis has been tested with\nthe help of the MNIST, CIFAR-10, and CIFAR-100 image classification benchmarks,\noptionally extended by training data augmentation. The experiments have\nconfirmed that results equivalent to conventional training can be reached. In\nsummary, even small subsets are representative if the overdetermination ratio\nfor the given model parameter set sufficiently exceeds unity. The computing\nexpense can be reduced to a tenth or less.\n","authors":["Jan Spörer","Bernhard Bermeitinger","Tomas Hrycej","Niklas Limacher","Siegfried Handschuh"],"pdf_url":"https://arxiv.org/pdf/2410.16523v1.pdf","comment":"To appear in KDIR 2024"},{"id":"http://arxiv.org/abs/2410.16512v1","updated":"2024-10-21T21:05:04Z","published":"2024-10-21T21:05:04Z","title":"TIPS: Text-Image Pretraining with Spatial Awareness","summary":"  While image-text representation learning has become very popular in recent\nyears, existing models tend to lack spatial awareness and have limited direct\napplicability for dense understanding tasks. For this reason, self-supervised\nimage-only pretraining is still the go-to method for many dense vision\napplications (e.g. depth estimation, semantic segmentation), despite the lack\nof explicit supervisory signals. In this paper, we close this gap between\nimage-text and self-supervised learning, by proposing a novel general-purpose\nimage-text model, which can be effectively used off-the-shelf for dense and\nglobal vision tasks. Our method, which we refer to as Text-Image Pretraining\nwith Spatial awareness (TIPS), leverages two simple and effective insights.\nFirst, on textual supervision: we reveal that replacing noisy web image\ncaptions by synthetically generated textual descriptions boosts dense\nunderstanding performance significantly, due to a much richer signal for\nlearning spatially aware representations. We propose an adapted training method\nthat combines noisy and synthetic captions, resulting in improvements across\nboth dense and global understanding tasks. Second, on the learning technique:\nwe propose to combine contrastive image-text learning with self-supervised\nmasked image modeling, to encourage spatial coherence, unlocking substantial\nenhancements for downstream applications. Building on these two ideas, we scale\nour model using the transformer architecture, trained on a curated set of\npublic images. Our experiments are conducted on 8 tasks involving 16 datasets\nin total, demonstrating strong off-the-shelf performance on both dense and\nglobal understanding, for several image-only and image-text tasks.\n","authors":["Kevis-Kokitsi Maninis","Kaifeng Chen","Soham Ghosh","Arjun Karpur","Koert Chen","Ye Xia","Bingyi Cao","Daniel Salz","Guangxing Han","Jan Dlabal","Dan Gnanapragasam","Mojtaba Seyedhosseini","Howard Zhou","Andre Araujo"],"pdf_url":"https://arxiv.org/pdf/2410.16512v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.03783v2","updated":"2024-10-21T20:54:04Z","published":"2024-10-03T16:42:23Z","title":"Improving Neural Optimal Transport via Displacement Interpolation","summary":"  Optimal Transport (OT) theory investigates the cost-minimizing transport map\nthat moves a source distribution to a target distribution. Recently, several\napproaches have emerged for learning the optimal transport map for a given cost\nfunction using neural networks. We refer to these approaches as the OT Map. OT\nMap provides a powerful tool for diverse machine learning tasks, such as\ngenerative modeling and unpaired image-to-image translation. However, existing\nmethods that utilize max-min optimization often experience training instability\nand sensitivity to hyperparameters. In this paper, we propose a novel method to\nimprove stability and achieve a better approximation of the OT Map by\nexploiting displacement interpolation, dubbed Displacement Interpolation\nOptimal Transport Model (DIOTM). We derive the dual formulation of displacement\ninterpolation at specific time $t$ and prove how these dual problems are\nrelated across time. This result allows us to utilize the entire trajectory of\ndisplacement interpolation in learning the OT Map. Our method improves the\ntraining stability and achieves superior results in estimating optimal\ntransport maps. We demonstrate that DIOTM outperforms existing OT-based models\non image-to-image translation tasks.\n","authors":["Jaemoo Choi","Yongxin Chen","Jaewoong Choi"],"pdf_url":"https://arxiv.org/pdf/2410.03783v2.pdf","comment":"20 pages"},{"id":"http://arxiv.org/abs/2410.16503v1","updated":"2024-10-21T20:50:51Z","published":"2024-10-21T20:50:51Z","title":"Allo-AVA: A Large-Scale Multimodal Conversational AI Dataset for\n  Allocentric Avatar Gesture Animation","summary":"  The scarcity of high-quality, multimodal training data severely hinders the\ncreation of lifelike avatar animations for conversational AI in virtual\nenvironments. Existing datasets often lack the intricate synchronization\nbetween speech, facial expressions, and body movements that characterize\nnatural human communication. To address this critical gap, we introduce\nAllo-AVA, a large-scale dataset specifically designed for text and audio-driven\navatar gesture animation in an allocentric (third person point-of-view)\ncontext. Allo-AVA consists of $\\sim$1,250 hours of diverse video content,\ncomplete with audio, transcripts, and extracted keypoints. Allo-AVA uniquely\nmaps these keypoints to precise timestamps, enabling accurate replication of\nhuman movements (body and facial gestures) in synchronization with speech. This\ncomprehensive resource enables the development and evaluation of more natural,\ncontext-aware avatar animation models, potentially transforming applications\nranging from virtual reality to digital assistants.\n","authors":["Saif Punjwani","Larry Heck"],"pdf_url":"https://arxiv.org/pdf/2410.16503v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.16499v1","updated":"2024-10-21T20:41:32Z","published":"2024-10-21T20:41:32Z","title":"SINGAPO: Single Image Controlled Generation of Articulated Parts in\n  Object","summary":"  We address the challenge of creating 3D assets for household articulated\nobjects from a single image. Prior work on articulated object creation either\nrequires multi-view multi-state input, or only allows coarse control over the\ngeneration process. These limitations hinder the scalability and practicality\nfor articulated object modeling. In this work, we propose a method to generate\narticulated objects from a single image. Observing the object in resting state\nfrom an arbitrary view, our method generates an articulated object that is\nvisually consistent with the input image. To capture the ambiguity in part\nshape and motion posed by a single view of the object, we design a diffusion\nmodel that learns the plausible variations of objects in terms of geometry and\nkinematics. To tackle the complexity of generating structured data with\nattributes in multiple domains, we design a pipeline that produces articulated\nobjects from high-level structure to geometric details in a coarse-to-fine\nmanner, where we use a part connectivity graph and part abstraction as proxies.\nOur experiments show that our method outperforms the state-of-the-art in\narticulated object creation by a large margin in terms of the generated object\nrealism, resemblance to the input image, and reconstruction quality.\n","authors":["Jiayi Liu","Denys Iliash","Angel X. Chang","Manolis Savva","Ali Mahdavi-Amiri"],"pdf_url":"https://arxiv.org/pdf/2410.16499v1.pdf","comment":"Project page: https://3dlg-hcvc.github.io/singapo"},{"id":"http://arxiv.org/abs/2410.16485v1","updated":"2024-10-21T20:21:09Z","published":"2024-10-21T20:21:09Z","title":"GenGMM: Generalized Gaussian-Mixture-based Domain Adaptation Model for\n  Semantic Segmentation","summary":"  Domain adaptive semantic segmentation is the task of generating precise and\ndense predictions for an unlabeled target domain using a model trained on a\nlabeled source domain. While significant efforts have been devoted to improving\nunsupervised domain adaptation for this task, it is crucial to note that many\nmodels rely on a strong assumption that the source data is entirely and\naccurately labeled, while the target data is unlabeled. In real-world\nscenarios, however, we often encounter partially or noisy labeled data in\nsource and target domains, referred to as Generalized Domain Adaptation (GDA).\nIn such cases, we suggest leveraging weak or unlabeled data from both domains\nto narrow the gap between them, resulting in effective adaptation. We introduce\nthe Generalized Gaussian-mixture-based (GenGMM) domain adaptation model, which\nharnesses the underlying data distribution in both domains to refine noisy weak\nand pseudo labels. The experiments demonstrate the effectiveness of our\napproach.\n","authors":["Nazanin Moradinasab","Hassan Jafarzadeh","Donald E. Brown"],"pdf_url":"https://arxiv.org/pdf/2410.16485v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2409.10695v2","updated":"2024-10-21T20:01:13Z","published":"2024-09-16T19:52:24Z","title":"Playground v3: Improving Text-to-Image Alignment with Deep-Fusion Large\n  Language Models","summary":"  We introduce Playground v3 (PGv3), our latest text-to-image model that\nachieves state-of-the-art (SoTA) performance across multiple testing\nbenchmarks, excels in graphic design abilities and introduces new capabilities.\nUnlike traditional text-to-image generative models that rely on pre-trained\nlanguage models like T5 or CLIP text encoders, our approach fully integrates\nLarge Language Models (LLMs) with a novel structure that leverages text\nconditions exclusively from a decoder-only LLM. Additionally, to enhance image\ncaptioning quality-we developed an in-house captioner, capable of generating\ncaptions with varying levels of detail, enriching the diversity of text\nstructures. We also introduce a new benchmark CapsBench to evaluate detailed\nimage captioning performance. Experimental results demonstrate that PGv3 excels\nin text prompt adherence, complex reasoning, and accurate text rendering. User\npreference studies indicate the super-human graphic design ability of our model\nfor common design applications, such as stickers, posters, and logo designs.\nFurthermore, PGv3 introduces new capabilities, including precise RGB color\ncontrol and robust multilingual understanding.\n","authors":["Bingchen Liu","Ehsan Akhgari","Alexander Visheratin","Aleks Kamko","Linmiao Xu","Shivam Shrirao","Chase Lambert","Joao Souza","Suhail Doshi","Daiqing Li"],"pdf_url":"https://arxiv.org/pdf/2409.10695v2.pdf","comment":"Project page: https://playground.com/pg-v3"},{"id":"http://arxiv.org/abs/2410.16438v1","updated":"2024-10-21T19:02:13Z","published":"2024-10-21T19:02:13Z","title":"AlignVSR: Audio-Visual Cross-Modal Alignment for Visual Speech\n  Recognition","summary":"  Visual Speech Recognition (VSR) aims to recognize corresponding text by\nanalyzing visual information from lip movements. Due to the high variability\nand weak information of lip movements, VSR tasks require effectively utilizing\nany information from any source and at any level. In this paper, we propose a\nVSR method based on audio-visual cross-modal alignment, named AlignVSR. The\nmethod leverages the audio modality as an auxiliary information source and\nutilizes the global and local correspondence between the audio and visual\nmodalities to improve visual-to-text inference. Specifically, the method first\ncaptures global alignment between video and audio through a cross-modal\nattention mechanism from video frames to a bank of audio units. Then, based on\nthe temporal correspondence between audio and video, a frame-level local\nalignment loss is introduced to refine the global alignment, improving the\nutility of the audio information. Experimental results on the LRS2 and\nCNVSRC.Single datasets consistently show that AlignVSR outperforms several\nmainstream VSR methods, demonstrating its superior and robust performance.\n","authors":["Zehua Liu","Xiaolou Li","Chen Chen","Li Guo","Lantian Li","Dong Wang"],"pdf_url":"https://arxiv.org/pdf/2410.16438v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2409.15512v2","updated":"2024-10-21T18:57:08Z","published":"2024-09-03T06:02:02Z","title":"PixelBytes: Catching Unified Embedding for Multimodal Generation","summary":"  This report introduces PixelBytes Embedding, a novel approach for unified\nmultimodal representation learning. Our method captures diverse inputs in a\nsingle, cohesive representation, enabling emergent properties for multimodal\nsequence generation, particularly for text and pixelated images. Inspired by\nstate-of-the-art sequence models such as Image Transformers, PixelCNN, and\nMamba-Bytes, PixelBytes aims to address the challenges of integrating different\ndata types. We explore various model architectures, including Recurrent Neural\nNetworks (RNNs), State Space Models (SSMs), and Attention-based models,\nfocusing on bidirectional processing and our innovative PxBy embedding\ntechnique. Our experiments, conducted on a specialized PixelBytes Pok{\\'e}mon\ndataset, demonstrate that bidirectional sequence models with PxBy embedding and\nconvolutional layers can generate coherent multimodal sequences. This work\ncontributes to the advancement of integrated AI models capable of understanding\nand generating multimodal data in a unified manner.\n","authors":["Fabien Furfaro"],"pdf_url":"https://arxiv.org/pdf/2409.15512v2.pdf","comment":"This article is an earlier version of my work arXiv:2410.01820\n  \"PixelBytes: Catching Unified Representation for Multimodal Generation.\""},{"id":"http://arxiv.org/abs/2410.16430v1","updated":"2024-10-21T18:50:16Z","published":"2024-10-21T18:50:16Z","title":"HaHeAE: Learning Generalisable Joint Representations of Human Hand and\n  Head Movements in Extended Reality","summary":"  Human hand and head movements are the most pervasive input modalities in\nextended reality (XR) and are significant for a wide range of applications.\nHowever, prior works on hand and head modelling in XR only explored a single\nmodality or focused on specific applications. We present HaHeAE - a novel\nself-supervised method for learning generalisable joint representations of hand\nand head movements in XR. At the core of our method is an autoencoder (AE) that\nuses a graph convolutional network-based semantic encoder and a diffusion-based\nstochastic encoder to learn the joint semantic and stochastic representations\nof hand-head movements. It also features a diffusion-based decoder to\nreconstruct the original signals. Through extensive evaluations on three public\nXR datasets, we show that our method 1) significantly outperforms commonly used\nself-supervised methods by up to 74.0% in terms of reconstruction quality and\nis generalisable across users, activities, and XR environments, 2) enables new\napplications, including interpretable hand-head cluster identification and\nvariable hand-head movement generation, and 3) can serve as an effective\nfeature extractor for downstream tasks. Together, these results demonstrate the\neffectiveness of our method and underline the potential of self-supervised\nmethods for jointly modelling hand-head behaviours in extended reality.\n","authors":["Zhiming Hu","Guanhua Zhang","Zheming Yin","Daniel Haeufle","Syn Schmitt","Andreas Bulling"],"pdf_url":"https://arxiv.org/pdf/2410.16430v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2312.12090v2","updated":"2024-10-21T18:45:37Z","published":"2023-12-19T12:10:12Z","title":"GazeMoDiff: Gaze-guided Diffusion Model for Stochastic Human Motion\n  Prediction","summary":"  Human motion prediction is important for many virtual and augmented reality\n(VR/AR) applications such as collision avoidance and realistic avatar\ngeneration. Existing methods have synthesised body motion only from observed\npast motion, despite the fact that human eye gaze is known to correlate\nstrongly with body movements and is readily available in recent VR/AR headsets.\nWe present GazeMoDiff - a novel gaze-guided denoising diffusion model to\ngenerate stochastic human motions. Our method first uses a gaze encoder and a\nmotion encoder to extract the gaze and motion features respectively, then\nemploys a graph attention network to fuse these features, and finally injects\nthe gaze-motion features into a noise prediction network via a cross-attention\nmechanism to progressively generate multiple reasonable human motions in the\nfuture. Extensive experiments on the MoGaze and GIMO datasets demonstrate that\nour method outperforms the state-of-the-art methods by a large margin in terms\nof multi-modal final displacement error (17.3% on MoGaze and 13.3% on GIMO). We\nfurther conducted a human study (N=21) and validated that the motions generated\nby our method were perceived as both more precise and more realistic than those\nof prior methods. Taken together, these results reveal the significant\ninformation content available in eye gaze for stochastic human motion\nprediction as well as the effectiveness of our method in exploiting this\ninformation.\n","authors":["Haodong Yan","Zhiming Hu","Syn Schmitt","Andreas Bulling"],"pdf_url":"https://arxiv.org/pdf/2312.12090v2.pdf","comment":"Accepted at PG 2024. Link:\n  https://zhiminghu.net/yan24_gazemodiff.html"},{"id":"http://arxiv.org/abs/2410.16418v1","updated":"2024-10-21T18:36:45Z","published":"2024-10-21T18:36:45Z","title":"AttentionPainter: An Efficient and Adaptive Stroke Predictor for Scene\n  Painting","summary":"  Stroke-based Rendering (SBR) aims to decompose an input image into a sequence\nof parameterized strokes, which can be rendered into a painting that resembles\nthe input image. Recently, Neural Painting methods that utilize deep learning\nand reinforcement learning models to predict the stroke sequences have been\ndeveloped, but suffer from longer inference time or unstable training. To\naddress these issues, we propose AttentionPainter, an efficient and adaptive\nmodel for single-step neural painting. First, we propose a novel scalable\nstroke predictor, which predicts a large number of stroke parameters within a\nsingle forward process, instead of the iterative prediction of previous\nReinforcement Learning or auto-regressive methods, which makes AttentionPainter\nfaster than previous neural painting methods. To further increase the training\nefficiency, we propose a Fast Stroke Stacking algorithm, which brings 13 times\nacceleration for training. Moreover, we propose Stroke-density Loss, which\nencourages the model to use small strokes for detailed information, to help\nimprove the reconstruction quality. Finally, we propose a new stroke diffusion\nmodel for both conditional and unconditional stroke-based generation, which\ndenoises in the stroke parameter space and facilitates stroke-based inpainting\nand editing applications helpful for human artists design. Extensive\nexperiments show that AttentionPainter outperforms the state-of-the-art neural\npainting methods.\n","authors":["Yizhe Tang","Yue Wang","Teng Hu","Ran Yi","Xin Tan","Lizhuang Ma","Yu-Kun Lai","Paul L. Rosin"],"pdf_url":"https://arxiv.org/pdf/2410.16418v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2409.06111v2","updated":"2024-10-21T18:16:09Z","published":"2024-09-09T23:34:24Z","title":"Competency-Aware Planning for Probabilistically Safe Navigation Under\n  Perception Uncertainty","summary":"  Perception-based navigation systems are useful for unmanned ground vehicle\n(UGV) navigation in complex terrains, where traditional depth-based navigation\nschemes are insufficient. However, these data-driven methods are highly\ndependent on their training data and can fail in surprising and dramatic ways\nwith little warning. To ensure the safety of the vehicle and the surrounding\nenvironment, it is imperative that the navigation system is able to recognize\nthe predictive uncertainty of the perception model and respond safely and\neffectively in the face of uncertainty. In an effort to enable safe navigation\nunder perception uncertainty, we develop a probabilistic and\nreconstruction-based competency estimation (PaRCE) method to estimate the\nmodel's level of familiarity with an input image as a whole and with specific\nregions in the image. We find that the overall competency score can correctly\npredict correctly classified, misclassified, and out-of-distribution (OOD)\nsamples. We also confirm that the regional competency maps can accurately\ndistinguish between familiar and unfamiliar regions across images. We then use\nthis competency information to develop a planning and control scheme that\nenables effective navigation while maintaining a low probability of error. We\nfind that the competency-aware scheme greatly reduces the number of collisions\nwith unfamiliar obstacles, compared to a baseline controller with no competency\nawareness. Furthermore, the regional competency information is very valuable in\nenabling efficient navigation.\n","authors":["Sara Pohland","Claire Tomlin"],"pdf_url":"https://arxiv.org/pdf/2409.06111v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.16395v1","updated":"2024-10-21T18:07:33Z","published":"2024-10-21T18:07:33Z","title":"Joker: Conditional 3D Head Synthesis with Extreme Facial Expressions","summary":"  We introduce Joker, a new method for the conditional synthesis of 3D human\nheads with extreme expressions. Given a single reference image of a person, we\nsynthesize a volumetric human head with the reference identity and a new\nexpression. We offer control over the expression via a 3D morphable model\n(3DMM) and textual inputs. This multi-modal conditioning signal is essential\nsince 3DMMs alone fail to define subtle emotional changes and extreme\nexpressions, including those involving the mouth cavity and tongue\narticulation. Our method is built upon a 2D diffusion-based prior that\ngeneralizes well to out-of-domain samples, such as sculptures, heavy makeup,\nand paintings while achieving high levels of expressiveness. To improve view\nconsistency, we propose a new 3D distillation technique that converts\npredictions of our 2D prior into a neural radiance field (NeRF). Both the 2D\nprior and our distillation technique produce state-of-the-art results, which\nare confirmed by our extensive evaluations. Also, to the best of our knowledge,\nour method is the first to achieve view-consistent extreme tongue articulation.\n","authors":["Malte Prinzler","Egor Zakharov","Vanessa Sklyarova","Berna Kabadayi","Justus Thies"],"pdf_url":"https://arxiv.org/pdf/2410.16395v1.pdf","comment":"Project Page: https://malteprinzler.github.io/projects/joker/"}],"Machine Learning":[{"id":"http://arxiv.org/abs/2410.14380v2","updated":"2024-10-21T01:28:32Z","published":"2024-10-18T11:07:26Z","title":"Dual-Label Learning With Irregularly Present Labels","summary":"  In multi-task learning, we often encounter the case when the presence of\nlabels across samples exhibits irregular patterns: samples can be fully\nlabeled, partially labeled or unlabeled. Taking drug analysis as an example,\nmultiple toxicity properties of a drug molecule may not be concurrently\navailable due to experimental limitations. It triggers a demand for a new\ntraining and inference mechanism that could accommodate irregularly present\nlabels and maximize the utility of any available label information. In this\nwork, we focus on the two-label learning task, and propose a novel training and\ninference framework, Dual-Label Learning (DLL). The DLL framework formulates\nthe problem into a dual-function system, in which the two functions should\nsimultaneously satisfy standard supervision, structural duality and\nprobabilistic duality. DLL features a dual-tower model architecture that\nexplicitly captures the information exchange between labels, aimed at\nmaximizing the utility of partially available labels in understanding label\ncorrelation. During training, label imputation for missing labels is conducted\nas part of the forward propagation process, while during inference, labels are\nregarded as unknowns of a bivariate system of equations and are solved jointly.\nTheoretical analysis guarantees the feasibility of DLL, and extensive\nexperiments are conducted to verify that by explicitly modeling label\ncorrelation and maximizing the utility of available labels, our method makes\nconsistently better predictions than baseline approaches by up to a 10% gain in\nF1-score or MAPE. Remarkably, our method provided with data at a label missing\nrate as high as 60% can achieve similar or even better results than baseline\napproaches at a label missing rate of only 10%.\n","authors":["Mingqian Li","Qiao Han","Yiteng Zhai","Ruifeng Li","Yao Yang","Hongyang Chen"],"pdf_url":"https://arxiv.org/pdf/2410.14380v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.08472v2","updated":"2024-10-21T17:59:13Z","published":"2024-06-12T17:56:31Z","title":"RILe: Reinforced Imitation Learning","summary":"  Reinforcement Learning has achieved significant success in generating complex\nbehavior but often requires extensive reward function engineering. Adversarial\nvariants of Imitation Learning and Inverse Reinforcement Learning offer an\nalternative by learning policies from expert demonstrations via a\ndiscriminator. However, these methods struggle in complex tasks where randomly\nsampling expert-like behaviors is challenging. This limitation stems from their\nreliance on policy-agnostic discriminators, which provide insufficient guidance\nfor agent improvement, especially as task complexity increases and expert\nbehavior becomes more distinct. We introduce RILe (Reinforced Imitation\nLearning environment), a novel trainer-student system that learns a dynamic\nreward function based on the student's performance and alignment with expert\ndemonstrations. In RILe, the student learns an action policy while the trainer,\nusing reinforcement learning, continuously updates itself via the\ndiscriminator's feedback to optimize the alignment between the student and the\nexpert. The trainer optimizes for long-term cumulative rewards from the\ndiscriminator, enabling it to provide nuanced feedback that accounts for the\ncomplexity of the task and the student's current capabilities. This approach\nallows for greater exploration of agent actions by providing graduated feedback\nrather than binary expert/non-expert classifications. By reducing dependence on\npolicy-agnostic discriminators, RILe enables better performance in complex\nsettings where traditional methods falter, outperforming existing methods by 2x\nin complex simulated robot-locomotion tasks.\n","authors":["Mert Albaba","Sammy Christen","Thomas Langarek","Christoph Gebhardt","Otmar Hilliges","Michael J. Black"],"pdf_url":"https://arxiv.org/pdf/2406.08472v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.16267v1","updated":"2024-10-21T17:59:11Z","published":"2024-10-21T17:59:11Z","title":"xGen-MM-Vid (BLIP-3-Video): You Only Need 32 Tokens to Represent a Video\n  Even in VLMs","summary":"  We present xGen-MM-Vid (BLIP-3-Video): a multimodal language model for\nvideos, particularly designed to efficiently capture temporal information over\nmultiple frames. BLIP-3-Video takes advantage of the 'temporal encoder' in\naddition to the conventional visual tokenizer, which maps a sequence of tokens\nover multiple frames into a compact set of visual tokens. This enables\nBLIP3-Video to use much fewer visual tokens than its competing models (e.g., 32\nvs. 4608 tokens). We explore different types of temporal encoders, including\nlearnable spatio-temporal pooling as well as sequential models like Token\nTuring Machines. We experimentally confirm that BLIP-3-Video obtains video\nquestion-answering accuracies comparable to much larger state-of-the-art models\n(e.g., 34B), while being much smaller (i.e., 4B) and more efficient by using\nfewer visual tokens. The project website is at\nhttps://www.salesforceairesearch.com/opensource/xGen-MM-Vid/index.html\n","authors":["Michael S. Ryoo","Honglu Zhou","Shrikant Kendre","Can Qin","Le Xue","Manli Shu","Silvio Savarese","Ran Xu","Caiming Xiong","Juan Carlos Niebles"],"pdf_url":"https://arxiv.org/pdf/2410.16267v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.16255v1","updated":"2024-10-21T17:56:47Z","published":"2024-10-21T17:56:47Z","title":"Revisiting Deep Feature Reconstruction for Logical and Structural\n  Industrial Anomaly Detection","summary":"  Industrial anomaly detection is crucial for quality control and predictive\nmaintenance, but it presents challenges due to limited training data, diverse\nanomaly types, and external factors that alter object appearances. Existing\nmethods commonly detect structural anomalies, such as dents and scratches, by\nleveraging multi-scale features from image patches extracted through deep\npre-trained networks. However, significant memory and computational demands\noften limit their practical application. Additionally, detecting logical\nanomalies-such as images with missing or excess elements-requires an\nunderstanding of spatial relationships that traditional patch-based methods\nfail to capture. In this work, we address these limitations by focusing on Deep\nFeature Reconstruction (DFR), a memory- and compute-efficient approach for\ndetecting structural anomalies. We further enhance DFR into a unified\nframework, called ULSAD, which is capable of detecting both structural and\nlogical anomalies. Specifically, we refine the DFR training objective to\nimprove performance in structural anomaly detection, while introducing an\nattention-based loss mechanism using a global autoencoder-like network to\nhandle logical anomaly detection. Our empirical evaluation across five\nbenchmark datasets demonstrates the performance of ULSAD in detecting and\nlocalizing both structural and logical anomalies, outperforming eight\nstate-of-the-art methods. An extensive ablation study further highlights the\ncontribution of each component to the overall performance improvement. Our code\nis available at https://github.com/sukanyapatra1997/ULSAD-2024.git\n","authors":["Sukanya Patra","Souhaib Ben Taieb"],"pdf_url":"https://arxiv.org/pdf/2410.16255v1.pdf","comment":"Accepted in Transactions on Machine Learning Research (TMLR). Link to\n  OpenReview: https://openreview.net/forum?id=kdTC4ktHPD"},{"id":"http://arxiv.org/abs/2410.16253v1","updated":"2024-10-21T17:56:09Z","published":"2024-10-21T17:56:09Z","title":"Distribution Learning with Valid Outputs Beyond the Worst-Case","summary":"  Generative models at times produce \"invalid\" outputs, such as images with\ngeneration artifacts and unnatural sounds. Validity-constrained distribution\nlearning attempts to address this problem by requiring that the learned\ndistribution have a provably small fraction of its mass in invalid parts of\nspace -- something which standard loss minimization does not always ensure. To\nthis end, a learner in this model can guide the learning via \"validity\nqueries\", which allow it to ascertain the validity of individual examples.\nPrior work on this problem takes a worst-case stance, showing that proper\nlearning requires an exponential number of validity queries, and demonstrating\nan improper algorithm which -- while generating guarantees in a wide-range of\nsettings -- makes an atypical polynomial number of validity queries. In this\nwork, we take a first step towards characterizing regimes where guaranteeing\nvalidity is easier than in the worst-case. We show that when the data\ndistribution lies in the model class and the log-loss is minimized, the number\nof samples required to ensure validity has a weak dependence on the validity\nrequirement. Additionally, we show that when the validity region belongs to a\nVC-class, a limited number of validity queries are often sufficient.\n","authors":["Nick Rittler","Kamalika Chaudhuri"],"pdf_url":"https://arxiv.org/pdf/2410.16253v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.16247v1","updated":"2024-10-21T17:52:01Z","published":"2024-10-21T17:52:01Z","title":"Implicit Regularization for Tubal Tensor Factorizations via Gradient\n  Descent","summary":"  We provide a rigorous analysis of implicit regularization in an\noverparametrized tensor factorization problem beyond the lazy training regime.\nFor matrix factorization problems, this phenomenon has been studied in a number\nof works. A particular challenge has been to design universal initialization\nstrategies which provably lead to implicit regularization in gradient-descent\nmethods. At the same time, it has been argued by Cohen et. al. 2016 that more\ngeneral classes of neural networks can be captured by considering tensor\nfactorizations. However, in the tensor case, implicit regularization has only\nbeen rigorously established for gradient flow or in the lazy training regime.\nIn this paper, we prove the first tensor result of its kind for gradient\ndescent rather than gradient flow. We focus on the tubal tensor product and the\nassociated notion of low tubal rank, encouraged by the relevance of this model\nfor image data. We establish that gradient descent in an overparametrized\ntensor factorization model with a small random initialization exhibits an\nimplicit bias towards solutions of low tubal rank. Our theoretical findings are\nillustrated in an extensive set of numerical simulations show-casing the\ndynamics predicted by our theory as well as the crucial role of using a small\nrandom initialization.\n","authors":["Santhosh Karnik","Anna Veselovska","Mark Iwen","Felix Krahmer"],"pdf_url":"https://arxiv.org/pdf/2410.16247v1.pdf","comment":"58 pages, 4 figures"},{"id":"http://arxiv.org/abs/2405.21042v2","updated":"2024-10-21T17:50:10Z","published":"2024-05-31T17:33:07Z","title":"Comparing the information content of probabilistic representation spaces","summary":"  Probabilistic representation spaces convey information about a dataset, and\nto understand the effects of factors such as training loss and network\narchitecture, we seek to compare the information content of such spaces.\nHowever, most existing methods to compare representation spaces assume\nrepresentations are points, and neglect the distributional nature of\nprobabilistic representations. Here, instead of building upon point-based\nmeasures of comparison, we build upon classic methods from literature on hard\nclustering. We generalize two information-theoretic methods of comparing hard\nclustering assignments to be applicable to general probabilistic representation\nspaces. We then propose a practical method of estimation that is based on\nfingerprinting a representation space with a sample of the dataset and is\napplicable when the communicated information is only a handful of bits. With\nunsupervised disentanglement as a motivating problem, we find information\nfragments that are repeatedly contained in individual latent dimensions in VAE\nand InfoGAN ensembles. Then, by comparing the full latent spaces of models, we\nfind highly consistent information content across datasets, methods, and\nhyperparameters, even though there is often a point during training with\nsubstantial variety across repeat runs. Finally, we leverage the\ndifferentiability of the proposed method and perform model fusion by\nsynthesizing the information content of multiple weak learners, each incapable\nof representing the global structure of a dataset. Across the case studies, the\ndirect comparison of information content provides a natural basis for\nunderstanding the processing of information.\n","authors":["Kieran A. Murphy","Sam Dillavou","Dani S. Bassett"],"pdf_url":"https://arxiv.org/pdf/2405.21042v2.pdf","comment":"Code:\n  https://github.com/murphyka/representation-space-info-comparison"},{"id":"http://arxiv.org/abs/2410.16239v1","updated":"2024-10-21T17:42:41Z","published":"2024-10-21T17:42:41Z","title":"MoRE: Multi-Modal Contrastive Pre-training with Transformers on X-Rays,\n  ECGs, and Diagnostic Report","summary":"  In this paper, we introduce a novel Multi-Modal Contrastive Pre-training\nFramework that synergistically combines X-rays, electrocardiograms (ECGs), and\nradiology/cardiology reports. Our approach leverages transformers to encode\nthese diverse modalities into a unified representation space, aiming to enhance\ndiagnostic accuracy and facilitate comprehensive patient assessments. We\nutilize LoRA-Peft to significantly reduce trainable parameters in the LLM and\nincorporate recent linear attention dropping strategy in the Vision\nTransformer(ViT) for smoother attention. Furthermore, we provide novel\nmultimodal attention explanations and retrieval for our model. To the best of\nour knowledge, we are the first to propose an integrated model that combines\nX-ray, ECG, and Radiology/Cardiology Report with this approach. By utilizing\ncontrastive loss, MoRE effectively aligns modality-specific features into a\ncoherent embedding, which supports various downstream tasks such as zero-shot\nclassification and multimodal retrieval. Employing our proposed methodology, we\nachieve state-of-the-art (SOTA) on the Mimic-IV, CheXpert, Edema Severity, and\nPtbXl downstream datasets, surpassing existing multimodal approaches. Our\nproposed framework shows significant improvements in capturing intricate\ninter-modal relationships and its robustness in medical diagnosis that\nestablishes a framework for future research in multimodal learning in the\nhealthcare sector.\n","authors":["Samrajya Thapa","Koushik Howlader","Subhankar Bhattacharjee","Wei le"],"pdf_url":"https://arxiv.org/pdf/2410.16239v1.pdf","comment":"10 pages, 5 figures, 9 tables. Supplementary detail in Appendix. Code\n  made available in Github for reproducibility"},{"id":"http://arxiv.org/abs/2405.12235v6","updated":"2024-10-21T17:34:08Z","published":"2024-05-14T23:50:01Z","title":"Hypergraph: A Unified and Uniform Definition with Application to\n  Chemical Hypergraph and More","summary":"  The conventional definition of hypergraph has two major issues: (1) there is\nnot a standard definition of directed hypergraph and (2) there is not a formal\ndefinition of nested hypergraph. To resolve these issues, we propose a new\ndefinition of hypergraph that unifies the concepts of undirected, directed and\nnested hypergraphs, and that is uniform in using hyperedge as a single\nconstruct for representing high-order correlations among things, i.e., nodes\nand hyperedges. Specifically, we define a hyperedge to be a simple hyperedge, a\nnesting hyperedge, or a directed hyperedge. With this new definition, a\nhypergraph is nested if it has nesting hyperedge(s), and is directed if it has\ndirected hyperedge(s). Otherwise, a hypergraph is a simple hypergraph. The\nuniformity and power of this new definition, with visualization, should\nfacilitate the use of hypergraph for representing (hierarchical) high-order\ncorrelations in general and chemical systems in particular. Graph has been\nwidely used as a mathematical structure for machine learning on molecular\nstructures and 3D molecular geometries. However, graph has a major limitation:\nit can represent only pairwise correlations between nodes. Hypergraph extends\ngraph with high-order correlations among nodes. This extension is significant\nor essential for machine learning on chemical systems. For molecules, this is\nsignificant as it allows the direct, explicit representation of multicenter\nbonds and molecular substructures. For chemical reactions, this is essential\nsince most chemical reactions involve multiple participants. We propose the use\nof chemical hypergraph, a multilevel hypergraph with simple, nesting and\ndirected hyperedges, as a single mathematical structure for representing\nchemical systems. We apply the new definition of hypergraph to chemical\nhypergraph and, as simplified versions, molecular hypergraph and chemical\nreaction hypergraph.\n","authors":["Daniel T. Chang"],"pdf_url":"https://arxiv.org/pdf/2405.12235v6.pdf","comment":"arXiv admin note: text overlap with arXiv:2310.03623 by other authors"},{"id":"http://arxiv.org/abs/2410.16222v1","updated":"2024-10-21T17:27:01Z","published":"2024-10-21T17:27:01Z","title":"A Realistic Threat Model for Large Language Model Jailbreaks","summary":"  A plethora of jailbreaking attacks have been proposed to obtain harmful\nresponses from safety-tuned LLMs. In their original settings, these methods all\nlargely succeed in coercing the target output, but their attacks vary\nsubstantially in fluency and computational effort. In this work, we propose a\nunified threat model for the principled comparison of these methods. Our threat\nmodel combines constraints in perplexity, measuring how far a jailbreak\ndeviates from natural text, and computational budget, in total FLOPs. For the\nformer, we build an N-gram model on 1T tokens, which, in contrast to\nmodel-based perplexity, allows for an LLM-agnostic and inherently interpretable\nevaluation. We adapt popular attacks to this new, realistic threat model, with\nwhich we, for the first time, benchmark these attacks on equal footing. After a\nrigorous comparison, we not only find attack success rates against safety-tuned\nmodern models to be lower than previously presented but also find that attacks\nbased on discrete optimization significantly outperform recent LLM-based\nattacks. Being inherently interpretable, our threat model allows for a\ncomprehensive analysis and comparison of jailbreak attacks. We find that\neffective attacks exploit and abuse infrequent N-grams, either selecting\nN-grams absent from real-world text or rare ones, e.g. specific to code\ndatasets.\n","authors":["Valentyn Boreiko","Alexander Panfilov","Vaclav Voracek","Matthias Hein","Jonas Geiping"],"pdf_url":"https://arxiv.org/pdf/2410.16222v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.17355v2","updated":"2024-10-21T17:27:00Z","published":"2024-08-30T15:39:34Z","title":"Bidirectional Decoding: Improving Action Chunking via Closed-Loop\n  Resampling","summary":"  Predicting and executing a sequence of actions without intermediate\nreplanning, known as action chunking, is increasingly used in robot learning\nfrom human demonstrations. Yet, its reported effects on the learned policy are\ninconsistent: some studies find it crucial for achieving strong results, while\nothers observe decreased performance. In this paper, we first dissect how\naction chunking impacts the divergence between a learner and a demonstrator. We\nfind that action chunking allows the learner to better capture the temporal\ndependencies in demonstrations but at the cost of reduced reactivity in\nstochastic environments. To address this tradeoff, we propose Bidirectional\nDecoding (BID), a test-time inference algorithm that bridges action chunking\nwith closed-loop operations. BID samples multiple predictions at each time step\nand searches for the optimal one based on two criteria: (i) backward coherence,\nwhich favors samples that align with previous decisions; (ii) forward contrast,\nwhich seeks samples of high likelihood for future plans. By coupling decisions\nwithin and across action chunks, BID promotes consistency over time while\nmaintaining reactivity to unexpected changes. Experimental results show that\nBID boosts the performance of two state-of-the-art generative policies across\nseven simulation benchmarks and two real-world tasks. Code and videos are\navailable at https://bid-robot.github.io.\n","authors":["Yuejiang Liu","Jubayer Ibn Hamid","Annie Xie","Yoonho Lee","Maximilian Du","Chelsea Finn"],"pdf_url":"https://arxiv.org/pdf/2408.17355v2.pdf","comment":"Project website: https://bid-robot.github.io/"},{"id":"http://arxiv.org/abs/2406.01583v2","updated":"2024-10-21T17:25:44Z","published":"2024-06-03T17:58:43Z","title":"Decomposing and Interpreting Image Representations via Text in ViTs\n  Beyond CLIP","summary":"  Recent work has explored how individual components of the CLIP-ViT model\ncontribute to the final representation by leveraging the shared image-text\nrepresentation space of CLIP. These components, such as attention heads and\nMLPs, have been shown to capture distinct image features like shape, color or\ntexture. However, understanding the role of these components in arbitrary\nvision transformers (ViTs) is challenging. To this end, we introduce a general\nframework which can identify the roles of various components in ViTs beyond\nCLIP. Specifically, we (a) automate the decomposition of the final\nrepresentation into contributions from different model components, and (b)\nlinearly map these contributions to CLIP space to interpret them via text.\nAdditionally, we introduce a novel scoring function to rank components by their\nimportance with respect to specific features. Applying our framework to various\nViT variants (e.g. DeiT, DINO, DINOv2, Swin, MaxViT), we gain insights into the\nroles of different components concerning particular image features. These\ninsights facilitate applications such as image retrieval using text\ndescriptions or reference images, visualizing token importance heatmaps, and\nmitigating spurious correlations. We release our code to reproduce the\nexperiments at https://github.com/SriramB-98/vit-decompose\n","authors":["Sriram Balasubramanian","Samyadeep Basu","Soheil Feizi"],"pdf_url":"https://arxiv.org/pdf/2406.01583v2.pdf","comment":"NeurIPS 2024, 31 pages, 15 figures"},{"id":"http://arxiv.org/abs/2410.13714v2","updated":"2024-10-21T17:21:16Z","published":"2024-10-17T16:14:49Z","title":"Generation through the lens of learning theory","summary":"  We study generation through the lens of statistical learning theory. First,\nwe abstract and formalize the results of Gold [1967], Angluin [1979, 1980], and\nKleinberg and Mullainathan [2024] for language identification/generation in the\nlimit in terms of a binary hypothesis class defined over an abstract instance\nspace. Then, we formalize a different paradigm of generation studied by\nKleinberg and Mullainathan [2024], which we call ``uniform generation,\" and\nprovide a characterization of which hypothesis classes are uniformly\ngeneratable. As is standard in statistical learning theory, our\ncharacterization is in terms of the finiteness of a new combinatorial dimension\nwe call the Closure dimension. By doing so, we are able to compare\ngeneratability with predictability (captured via PAC and online learnability)\nand show that these two properties of hypothesis classes are\n\\emph{incompatible} - there are classes that are generatable but not\npredictable and vice versa.\n","authors":["Vinod Raman","Ambuj Tewari"],"pdf_url":"https://arxiv.org/pdf/2410.13714v2.pdf","comment":"Minor edits"},{"id":"http://arxiv.org/abs/2402.06674v3","updated":"2024-10-21T17:19:12Z","published":"2024-02-07T14:23:01Z","title":"Impact of Dataset Properties on Membership Inference Vulnerability of\n  Deep Transfer Learning","summary":"  We analyse the relationship between privacy vulnerability and dataset\nproperties, such as examples per class and number of classes, when applying two\nstate-of-the-art membership inference attacks (MIAs) to fine-tuned neural\nnetworks. We derive per-example MIA vulnerability in terms of score\ndistributions and statistics computed from shadow models. We introduce a\nsimplified model of membership inference and prove that in this model, the\nlogarithm of the difference of true and false positive rates depends linearly\non the logarithm of the number of examples per class. We complement the\ntheoretical analysis with empirical analysis by systematically testing the\npractical privacy vulnerability of fine-tuning large image classification\nmodels and obtain the previously derived power law dependence between the\nnumber of examples per class in the data and the MIA vulnerability, as measured\nby true positive rate of the attack at a low false positive rate. Finally, we\nfit a parametric model of the previously derived form to predict true positive\nrate based on dataset properties and observe good fit for MIA vulnerability on\nunseen fine-tuning scenarios.\n","authors":["Marlon Tobaben","Hibiki Ito","Joonas Jälkö","Gauri Pradhan","Yuan He","Antti Honkela"],"pdf_url":"https://arxiv.org/pdf/2402.06674v3.pdf","comment":"39 pages, 12 figures"},{"id":"http://arxiv.org/abs/2410.16212v1","updated":"2024-10-21T17:12:06Z","published":"2024-10-21T17:12:06Z","title":"Comprehensive benchmarking of large language models for RNA secondary\n  structure prediction","summary":"  Inspired by the success of large language models (LLM) for DNA and proteins,\nseveral LLM for RNA have been developed recently. RNA-LLM uses large datasets\nof RNA sequences to learn, in a self-supervised way, how to represent each RNA\nbase with a semantically rich numerical vector. This is done under the\nhypothesis that obtaining high-quality RNA representations can enhance\ndata-costly downstream tasks. Among them, predicting the secondary structure is\na fundamental task for uncovering RNA functional mechanisms. In this work we\npresent a comprehensive experimental analysis of several pre-trained RNA-LLM,\ncomparing them for the RNA secondary structure prediction task in an unified\ndeep learning framework. The RNA-LLM were assessed with increasing\ngeneralization difficulty on benchmark datasets. Results showed that two LLM\nclearly outperform the other models, and revealed significant challenges for\ngeneralization in low-homology scenarios.\n","authors":["L. I. Zablocki","L. A. Bugnon","M. Gerard","L. Di Persia","G. Stegmayer","D. H. Milone"],"pdf_url":"https://arxiv.org/pdf/2410.16212v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.16208v1","updated":"2024-10-21T17:11:21Z","published":"2024-10-21T17:11:21Z","title":"Compute-Constrained Data Selection","summary":"  Data selection can reduce the amount of training data needed to finetune\nLLMs; however, the efficacy of data selection scales directly with its compute.\nMotivated by the practical challenge of compute-constrained finetuning, we\nconsider the setting in which both the cost of selecting data and training are\nbudgeted for. We first formalize the problem of data selection with a\ncost-aware utility function, and model the data selection problem as trading\noff initial-selection cost for training gain. We run a comprehensive sweep of\nexperiments across multiple tasks, varying compute budget by scaling finetuning\ntokens, model sizes, and data selection compute. These experiments show the\nvalidity of this model in real-world experiments. Interestingly we find that\nmany powerful data selection methods are almost never compute-optimal, and that\ncheaper data selection alternatives dominate both from a theoretical and\nempirical perspective.\n","authors":["Junjie Oscar Yin","Alexander M. Rush"],"pdf_url":"https://arxiv.org/pdf/2410.16208v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.16207v1","updated":"2024-10-21T17:10:43Z","published":"2024-10-21T17:10:43Z","title":"CoT-TL: Low-Resource Temporal Knowledge Representation of Planning\n  Instructions Using Chain-of-Thought Reasoning","summary":"  Autonomous agents often face the challenge of interpreting uncertain natural\nlanguage instructions for planning tasks. Representing these instructions as\nLinear Temporal Logic (LTL) enables planners to synthesize actionable plans. We\nintroduce CoT-TL, a data-efficient in-context learning framework for\ntranslating natural language specifications into LTL representations. CoT-TL\naddresses the limitations of large language models, which typically rely on\nextensive fine-tuning data, by extending chain-of-thought reasoning and\nsemantic roles to align with the requirements of formal logic creation. This\napproach enhances the transparency and rationale behind LTL generation,\nfostering user trust. CoT-TL achieves state-of-the-art accuracy across three\ndiverse datasets in low-data scenarios, outperforming existing methods without\nfine-tuning or intermediate translations. To improve reliability and minimize\nhallucinations, we incorporate model checking to validate the syntax of the\ngenerated LTL output. We further demonstrate CoT-TL's effectiveness through\nablation studies and evaluations on unseen LTL structures and formulas in a new\ndataset. Finally, we validate CoT-TL's practicality by integrating it into a\nQuadCopter for multi-step drone planning based on natural language\ninstructions.\n","authors":["Kumar Manas","Stefan Zwicklbauer","Adrian Paschke"],"pdf_url":"https://arxiv.org/pdf/2410.16207v1.pdf","comment":"Accepted for publication in Proceedings of the 2024 IEEE/RSJ\n  International Conference on Intelligent Robots and Systems (IROS 2024), Abu\n  Dhabi 14-18 October 2024"},{"id":"http://arxiv.org/abs/2410.16204v1","updated":"2024-10-21T17:05:50Z","published":"2024-10-21T17:05:50Z","title":"Systematic Review: Text Processing Algorithms in Machine Learning and\n  Deep Learning for Mental Health Detection on Social Media","summary":"  The global rise in depression necessitates innovative detection methods for\nearly intervention. Social media provides a unique opportunity to identify\ndepression through user-generated posts. This systematic review evaluates\nmachine learning (ML) models for depression detection on social media, focusing\non biases and methodological challenges throughout the ML lifecycle. A search\nof PubMed, IEEE Xplore, and Google Scholar identified 47 relevant studies\npublished after 2010. The Prediction model Risk Of Bias ASsessment Tool\n(PROBAST) was utilized to assess methodological quality and risk of bias.\nSignificant biases impacting model reliability and generalizability were found.\nThere is a predominant reliance on Twitter (63.8%) and English-language content\n(over 90%), with most studies focusing on users from the United States and\nEurope. Non-probability sampling methods (approximately 80%) limit\nrepresentativeness. Only 23% of studies explicitly addressed linguistic nuances\nlike negations, crucial for accurate sentiment analysis. Inconsistent\nhyperparameter tuning was observed, with only 27.7% properly tuning models.\nAbout 17% did not adequately partition data into training, validation, and test\nsets, risking overfitting. While 74.5% used appropriate evaluation metrics for\nimbalanced data, others relied on accuracy without addressing class imbalance,\npotentially skewing results. Reporting transparency varied, often lacking\ncritical methodological details. These findings highlight the need to diversify\ndata sources, standardize preprocessing protocols, ensure consistent model\ndevelopment practices, address class imbalance, and enhance reporting\ntransparency. By overcoming these challenges, future research can develop more\nrobust and generalizable ML models for depression detection on social media,\ncontributing to improved mental health outcomes globally.\n","authors":["Yuchen Cao","Jianglai Dai","Zhongyan Wang","Yeyubei Zhang","Xiaorui Shen","Yunchong Liu","Yexin Tian"],"pdf_url":"https://arxiv.org/pdf/2410.16204v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2405.19323v2","updated":"2024-10-21T17:05:15Z","published":"2024-05-29T17:54:22Z","title":"Are Large Language Models Chameleons? An Attempt to Simulate Social\n  Surveys","summary":"  Can large language models (LLMs) simulate social surveys? To answer this\nquestion, we conducted millions of simulations in which LLMs were asked to\nanswer subjective questions. A comparison of different LLM responses with the\nEuropean Social Survey (ESS) data suggests that the effect of prompts on bias\nand variability is fundamental, highlighting major cultural, age, and gender\nbiases. We further discussed statistical methods for measuring the difference\nbetween LLM answers and survey data and proposed a novel measure inspired by\nJaccard similarity, as LLM-generated responses are likely to have a smaller\nvariance. Our experiments also reveal that it is important to analyze the\nrobustness and variability of prompts before using LLMs to simulate social\nsurveys, as their imitation abilities are approximate at best.\n","authors":["Mingmeng Geng","Sihong He","Roberto Trotta"],"pdf_url":"https://arxiv.org/pdf/2405.19323v2.pdf","comment":"17 pages"},{"id":"http://arxiv.org/abs/2410.16201v1","updated":"2024-10-21T17:03:20Z","published":"2024-10-21T17:03:20Z","title":"Theoretical Limitations of Ensembles in the Age of Overparameterization","summary":"  Classic tree-based ensembles generalize better than any single decision tree.\nIn contrast, recent empirical studies find that modern ensembles of\n(overparameterized) neural networks may not provide any inherent generalization\nadvantage over single but larger neural networks. This paper clarifies how\nmodern overparameterized ensembles differ from their classic underparameterized\ncounterparts, using ensembles of random feature (RF) regressors as a basis for\ndeveloping theory. In contrast to the underparameterized regime, where\nensembling typically induces regularization and increases generalization, we\nprove that infinite ensembles of overparameterized RF regressors become\npointwise equivalent to (single) infinite-width RF regressors. This\nequivalence, which is exact for ridgeless models and approximate for small\nridge penalties, implies that overparameterized ensembles and single large\nmodels exhibit nearly identical generalization. As a consequence, we can\ncharacterize the predictive variance amongst ensemble members, and demonstrate\nthat it quantifies the expected effects of increasing capacity rather than\ncapturing any conventional notion of uncertainty. Our results challenge common\nassumptions about the advantages of ensembles in overparameterized settings,\nprompting a reconsideration of how well intuitions from underparameterized\nensembles transfer to deep ensembles and the overparameterized regime.\n","authors":["Niclas Dern","John P. Cunningham","Geoff Pleiss"],"pdf_url":"https://arxiv.org/pdf/2410.16201v1.pdf","comment":"26 pages, 12 figures"},{"id":"http://arxiv.org/abs/2410.16195v1","updated":"2024-10-21T16:59:01Z","published":"2024-10-21T16:59:01Z","title":"A Trust-Region Method for Graphical Stein Variational Inference","summary":"  Stein variational inference (SVI) is a sample-based approximate Bayesian\ninference technique that generates a sample set by jointly optimizing the\nsamples' locations to minimize an information-theoretic measure of discrepancy\nwith the target probability distribution. SVI thus provides a fast and\nsignificantly more sample-efficient approach to Bayesian inference than\ntraditional (random-sampling-based) alternatives. However, the optimization\ntechniques employed in existing SVI methods struggle to address problems in\nwhich the target distribution is high-dimensional, poorly-conditioned, or\nnon-convex, which severely limits the range of their practical applicability.\nIn this paper, we propose a novel trust-region optimization approach for SVI\nthat successfully addresses each of these challenges. Our method builds upon\nprior work in SVI by leveraging conditional independences in the target\ndistribution (to achieve high-dimensional scaling) and second-order information\n(to address poor conditioning), while additionally providing an effective\nadaptive step control procedure, which is essential for ensuring convergence on\nchallenging non-convex optimization problems. Experimental results show our\nmethod achieves superior numerical performance, both in convergence rate and\nsample accuracy, and scales better in high-dimensional distributions, than\nprevious SVI techniques.\n","authors":["Liam Pavlovic","David M. Rosen"],"pdf_url":"https://arxiv.org/pdf/2410.16195v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.13791v3","updated":"2024-10-21T16:55:31Z","published":"2024-06-19T19:35:14Z","title":"IoT-Based Preventive Mental Health Using Knowledge Graphs and Standards\n  for Better Well-Being","summary":"  Sustainable Development Goals (SDGs) give the UN a road map for development\nwith Agenda 2030 as a target. SDG3 \"Good Health and Well-Being\" ensures healthy\nlives and promotes well-being for all ages. Digital technologies can support\nSDG3. Burnout and even depression could be reduced by encouraging better\npreventive health. Due to the lack of patient knowledge and focus to take care\nof their health, it is necessary to help patients before it is too late. New\ntrends such as positive psychology and mindfulness are highly encouraged in the\nUSA. Digital Twins (DTs) can help with the continuous monitoring of emotion\nusing physiological signals (e.g., collected via wearables). DTs facilitate\nmonitoring and provide constant health insight to improve quality of life and\nwell-being with better personalization. Healthcare DTs challenges are\nstandardizing data formats, communication protocols, and data exchange\nmechanisms. As an example, ISO has the ISO/IEC JTC 1/SC 41 Internet of Things\n(IoT) and DTs Working Group, with standards such as \"ISO/IEC 21823-3:2021 IoT -\nInteroperability for IoT Systems - Part 3 Semantic interoperability\", \"ISO/IEC\nCD 30178 - IoT - Data format, value and coding\". To achieve those data\nintegration and knowledge challenges, we designed the Mental Health Knowledge\nGraph (ontology and dataset) to boost mental health. As an example, explicit\nknowledge is described such as chocolate contains magnesium which is\nrecommended for depression. The Knowledge Graph (KG) acquires knowledge from\nontology-based mental health projects classified within the LOV4IoT ontology\ncatalog (Emotion, Depression, and Mental Health). Furthermore, the KG is mapped\nto standards when possible. Standards from ETSI SmartM2M can be used such as\nSAREF4EHAW to represent medical devices and sensors, but also ITU/WHO, ISO,\nW3C, NIST, and IEEE standards relevant to mental health can be considered.\n","authors":["Amelie Gyrard","Seyedali Mohammadi","Manas Gaur","Antonio Kung"],"pdf_url":"https://arxiv.org/pdf/2406.13791v3.pdf","comment":"20 pages, Book chapter, Smart Technologies for Achieving Good Health\n  and Well-Being: Towards Sustainable Development Goal, Taylor & Francis"},{"id":"http://arxiv.org/abs/2409.18169v3","updated":"2024-10-21T16:51:22Z","published":"2024-09-26T17:55:22Z","title":"Harmful Fine-tuning Attacks and Defenses for Large Language Models: A\n  Survey","summary":"  Recent research demonstrates that the nascent fine-tuning-as-a-service\nbusiness model exposes serious safety concerns -- fine-tuning over a few\nharmful data uploaded by the users can compromise the safety alignment of the\nmodel. The attack, known as harmful fine-tuning, has raised a broad research\ninterest among the community. However, as the attack is still new, \\textbf{we\nobserve from our miserable submission experience that there are general\nmisunderstandings within the research community.} We in this paper aim to clear\nsome common concerns for the attack setting, and formally establish the\nresearch problem. Specifically, we first present the threat model of the\nproblem, and introduce the harmful fine-tuning attack and its variants. Then we\nsystematically survey the existing literature on attacks/defenses/mechanical\nanalysis of the problem. Finally, we outline future research directions that\nmight contribute to the development of the field. Additionally, we present a\nlist of questions of interest, which might be useful to refer to when reviewers\nin the peer review process question the realism of the\nexperiment/attack/defense setting. A curated list of relevant papers is\nmaintained and made accessible at:\n\\url{https://github.com/git-disl/awesome_LLM-harmful-fine-tuning-papers}.\n","authors":["Tiansheng Huang","Sihao Hu","Fatih Ilhan","Selim Furkan Tekin","Ling Liu"],"pdf_url":"https://arxiv.org/pdf/2409.18169v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2402.11137v3","updated":"2024-10-21T16:48:06Z","published":"2024-02-17T00:02:23Z","title":"TuneTables: Context Optimization for Scalable Prior-Data Fitted Networks","summary":"  While tabular classification has traditionally relied on from-scratch\ntraining, a recent breakthrough called prior-data fitted networks (PFNs)\nchallenges this approach. Similar to large language models, PFNs make use of\npretraining and in-context learning to achieve strong performance on new tasks\nin a single forward pass. However, current PFNs have limitations that prohibit\ntheir widespread adoption. Notably, TabPFN achieves very strong performance on\nsmall tabular datasets but is not designed to make predictions for datasets of\nsize larger than 1000. In this work, we overcome these limitations and\nsubstantially improve the performance of PFNs via context optimization. We\nintroduce TuneTables, a parameter-efficient fine-tuning strategy for PFNs that\ncompresses large datasets into a smaller learned context. We conduct extensive\nexperiments on 19 algorithms over 98 datasets and find that TuneTables achieves\nthe best performance on average, outperforming boosted trees such as CatBoost,\nwhile optimizing fewer than 5% of TabPFN's parameters. Furthermore, we show\nthat TuneTables can be used as an interpretability tool and can even be used to\nmitigate biases by optimizing a fairness objective. We open-source our code and\nraw results at https://github.com/penfever/TuneTables.\n","authors":["Benjamin Feuer","Robin Tibor Schirrmeister","Valeriia Cherepanova","Chinmay Hegde","Frank Hutter","Micah Goldblum","Niv Cohen","Colin White"],"pdf_url":"https://arxiv.org/pdf/2402.11137v3.pdf","comment":"NeurIPS 2024 Poster"},{"id":"http://arxiv.org/abs/2405.20539v2","updated":"2024-10-21T16:44:58Z","published":"2024-05-30T23:31:25Z","title":"SleeperNets: Universal Backdoor Poisoning Attacks Against Reinforcement\n  Learning Agents","summary":"  Reinforcement learning (RL) is an actively growing field that is seeing\nincreased usage in real-world, safety-critical applications -- making it\nparamount to ensure the robustness of RL algorithms against adversarial\nattacks. In this work we explore a particularly stealthy form of training-time\nattacks against RL -- backdoor poisoning. Here the adversary intercepts the\ntraining of an RL agent with the goal of reliably inducing a particular action\nwhen the agent observes a pre-determined trigger at inference time. We uncover\ntheoretical limitations of prior work by proving their inability to generalize\nacross domains and MDPs. Motivated by this, we formulate a novel poisoning\nattack framework which interlinks the adversary's objectives with those of\nfinding an optimal policy -- guaranteeing attack success in the limit. Using\ninsights from our theoretical analysis we develop ``SleeperNets'' as a\nuniversal backdoor attack which exploits a newly proposed threat model and\nleverages dynamic reward poisoning techniques. We evaluate our attack in 6\nenvironments spanning multiple domains and demonstrate significant improvements\nin attack success over existing methods, while preserving benign episodic\nreturn.\n","authors":["Ethan Rathbun","Christopher Amato","Alina Oprea"],"pdf_url":"https://arxiv.org/pdf/2405.20539v2.pdf","comment":"23 pages, 14 figures, NeurIPS"},{"id":"http://arxiv.org/abs/2410.16179v1","updated":"2024-10-21T16:44:51Z","published":"2024-10-21T16:44:51Z","title":"MagicPIG: LSH Sampling for Efficient LLM Generation","summary":"  Large language models (LLMs) with long context windows have gained\nsignificant attention. However, the KV cache, stored to avoid re-computation,\nbecomes a bottleneck. Various dynamic sparse or TopK-based attention\napproximation methods have been proposed to leverage the common insight that\nattention is sparse. In this paper, we first show that TopK attention itself\nsuffers from quality degradation in certain downstream tasks because attention\nis not always as sparse as expected. Rather than selecting the keys and values\nwith the highest attention scores, sampling with theoretical guarantees can\nprovide a better estimation for attention output. To make the sampling-based\napproximation practical in LLM generation, we propose MagicPIG, a heterogeneous\nsystem based on Locality Sensitive Hashing (LSH). MagicPIG significantly\nreduces the workload of attention computation while preserving high accuracy\nfor diverse tasks. MagicPIG stores the LSH hash tables and runs the attention\ncomputation on the CPU, which allows it to serve longer contexts and larger\nbatch sizes with high approximation accuracy. MagicPIG can improve decoding\nthroughput by $1.9\\sim3.9\\times$ across various GPU hardware and achieve 110ms\ndecoding latency on a single RTX 4090 for Llama-3.1-8B-Instruct model with a\ncontext of 96k tokens. The code is available at\n\\url{https://github.com/Infini-AI-Lab/MagicPIG}.\n","authors":["Zhuoming Chen","Ranajoy Sadhukhan","Zihao Ye","Yang Zhou","Jianyu Zhang","Niklas Nolte","Yuandong Tian","Matthijs Douze","Leon Bottou","Zhihao Jia","Beidi Chen"],"pdf_url":"https://arxiv.org/pdf/2410.16179v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2405.14540v2","updated":"2024-10-21T16:40:09Z","published":"2024-05-23T13:22:59Z","title":"This Too Shall Pass: Removing Stale Observations in Dynamic Bayesian\n  Optimization","summary":"  Bayesian Optimization (BO) has proven to be very successful at optimizing a\nstatic, noisy, costly-to-evaluate black-box function $f : \\mathcal{S} \\to\n\\mathbb{R}$. However, optimizing a black-box which is also a function of time\n(i.e., a dynamic function) $f : \\mathcal{S} \\times \\mathcal{T} \\to \\mathbb{R}$\nremains a challenge, since a dynamic Bayesian Optimization (DBO) algorithm has\nto keep track of the optimum over time. This changes the nature of the\noptimization problem in at least three aspects: (i) querying an arbitrary point\nin $\\mathcal{S} \\times \\mathcal{T}$ is impossible, (ii) past observations\nbecome less and less relevant for keeping track of the optimum as time goes by\nand (iii) the DBO algorithm must have a high sampling frequency so it can\ncollect enough relevant observations to keep track of the optimum through time.\nIn this paper, we design a Wasserstein distance-based criterion able to\nquantify the relevancy of an observation with respect to future predictions.\nThen, we leverage this criterion to build W-DBO, a DBO algorithm able to remove\nirrelevant observations from its dataset on the fly, thus maintaining\nsimultaneously a good predictive performance and a high sampling frequency,\neven in continuous-time optimization tasks with unknown horizon. Numerical\nexperiments establish the superiority of W-DBO, which outperforms\nstate-of-the-art methods by a comfortable margin.\n","authors":["Anthony Bardou","Patrick Thiran","Giovanni Ranieri"],"pdf_url":"https://arxiv.org/pdf/2405.14540v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2407.07059v2","updated":"2024-10-21T16:34:48Z","published":"2024-07-09T17:31:47Z","title":"Differentiable Optimization of Similarity Scores Between Models and\n  Brains","summary":"  How do we know if two systems - biological or artificial - process\ninformation in a similar way? Similarity measures such as linear regression,\nCentered Kernel Alignment (CKA), Normalized Bures Similarity (NBS), and angular\nProcrustes distance, are often used to quantify this similarity. However, it is\ncurrently unclear what drives high similarity scores and even what constitutes\na \"good\" score. Here, we introduce a novel tool to investigate these questions\nby differentiating through similarity measures to directly maximize the score.\nSurprisingly, we find that high similarity scores do not guarantee encoding\ntask-relevant information in a manner consistent with neural data; and this is\nparticularly acute for CKA and even some variations of cross-validated and\nregularized linear regression. We find no consistent threshold for a good\nsimilarity score - it depends on both the measure and the dataset. In addition,\nsynthetic datasets optimized to maximize similarity scores initially learn the\nhighest variance principal component of the target dataset, but some methods\nlike angular Procrustes capture lower variance dimensions much earlier than\nmethods like CKA. To shed light on this, we mathematically derive the\nsensitivity of CKA, angular Procrustes, and NBS to the variance of principal\ncomponent dimensions, and explain the emphasis CKA places on high variance\ncomponents. Finally, by jointly optimizing multiple similarity measures, we\ncharacterize their allowable ranges and reveal that some similarity measures\nare more constraining than others. While current measures offer a seemingly\nstraightforward way to quantify the similarity between neural systems, our work\nunderscores the need for careful interpretation. We hope the tools we developed\nwill be used by practitioners to better understand current and future\nsimilarity measures.\n","authors":["Nathan Cloos","Moufan Li","Markus Siegel","Scott L. Brincat","Earl K. Miller","Guangyu Robert Yang","Christopher J. Cueva"],"pdf_url":"https://arxiv.org/pdf/2407.07059v2.pdf","comment":"19 pages, 9 figures"},{"id":"http://arxiv.org/abs/2405.16195v2","updated":"2024-10-21T16:32:24Z","published":"2024-05-25T11:57:43Z","title":"Adaptive $Q$-Network: On-the-fly Target Selection for Deep Reinforcement\n  Learning","summary":"  Deep Reinforcement Learning (RL) is well known for being highly sensitive to\nhyperparameters, requiring practitioners substantial efforts to optimize them\nfor the problem at hand. This also limits the applicability of RL in real-world\nscenarios. In recent years, the field of automated Reinforcement Learning\n(AutoRL) has grown in popularity by trying to address this issue. However,\nthese approaches typically hinge on additional samples to select\nwell-performing hyperparameters, hindering sample-efficiency and practicality.\nFurthermore, most AutoRL methods are heavily based on already existing AutoML\nmethods, which were originally developed neglecting the additional challenges\ninherent to RL due to its non-stationarities. In this work, we propose a new\napproach for AutoRL, called Adaptive $Q$-Network (AdaQN), that is tailored to\nRL to take into account the non-stationarity of the optimization procedure\nwithout requiring additional samples. AdaQN learns several $Q$-functions, each\none trained with different hyperparameters, which are updated online using the\n$Q$-function with the smallest approximation error as a shared target. Our\nselection scheme simultaneously handles different hyperparameters while coping\nwith the non-stationarity induced by the RL optimization procedure and being\northogonal to any critic-based RL algorithm. We demonstrate that AdaQN is\ntheoretically sound and empirically validate it in MuJoCo control problems and\nAtari $2600$ games, showing benefits in sample-efficiency, overall performance,\nrobustness to stochasticity and training stability.\n","authors":["Théo Vincent","Fabian Wahren","Jan Peters","Boris Belousov","Carlo D'Eramo"],"pdf_url":"https://arxiv.org/pdf/2405.16195v2.pdf","comment":"Preprint"},{"id":"http://arxiv.org/abs/2311.05017v2","updated":"2024-10-21T16:30:03Z","published":"2023-11-08T21:03:43Z","title":"Joint Sensing and Semantic Communications with Multi-Task Deep Learning","summary":"  This paper explores the integration of deep learning techniques for joint\nsensing and communications, with an extension to semantic communications. The\nintegrated system comprises a transmitter and receiver operating over a\nwireless channel, subject to noise and fading. The transmitter employs a deep\nneural network (DNN), namely an encoder, for joint operations of source coding,\nchannel coding, and modulation, while the receiver utilizes another DNN, namely\na decoder, for joint operations of demodulation, channel decoding, and source\ndecoding to reconstruct the data samples. The transmitted signal serves a dual\npurpose, supporting communication with the receiver and enabling sensing. When\na target is present, the reflected signal is received, and another DNN decoder\nis utilized for sensing. This decoder is responsible for detecting the target's\npresence and determining its range. All these DNNs, including one encoder and\ntwo decoders, undergo joint training through multi-task learning, considering\ndata and channel characteristics. This paper extends to incorporate semantic\ncommunications by introducing an additional DNN, another decoder at the\nreceiver, operating as a task classifier. This decoder evaluates the fidelity\nof label classification for received signals, enhancing the integration of\nsemantics within the communication process. The study presents results based on\nusing the CIFAR-10 as the input data and accounting for channel effects like\nAdditive White Gaussian Noise (AWGN) and Rayleigh fading. The results\nunderscore the effectiveness of multi-task deep learning in achieving\nhigh-fidelity joint sensing and semantic communications.\n","authors":["Yalin E. Sagduyu","Tugba Erpek","Aylin Yener","Sennur Ulukus"],"pdf_url":"https://arxiv.org/pdf/2311.05017v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.13995v2","updated":"2024-10-21T16:27:48Z","published":"2024-10-17T19:50:28Z","title":"Adversarial Inception for Bounded Backdoor Poisoning in Deep\n  Reinforcement Learning","summary":"  Recent works have demonstrated the vulnerability of Deep Reinforcement\nLearning (DRL) algorithms against training-time, backdoor poisoning attacks.\nThese attacks induce pre-determined, adversarial behavior in the agent upon\nobserving a fixed trigger during deployment while allowing the agent to solve\nits intended task during training. Prior attacks rely on arbitrarily large\nperturbations to the agent's rewards to achieve both of these objectives -\nleaving them open to detection. Thus, in this work, we propose a new class of\nbackdoor attacks against DRL which achieve state of the art performance while\nminimally altering the agent's rewards. These \"inception\" attacks train the\nagent to associate the targeted adversarial behavior with high returns by\ninducing a disjunction between the agent's chosen action and the true action\nexecuted in the environment during training. We formally define these attacks\nand prove they can achieve both adversarial objectives. We then devise an\nonline inception attack which significantly out-performs prior attacks under\nbounded reward constraints.\n","authors":["Ethan Rathbun","Christopher Amato","Alina Oprea"],"pdf_url":"https://arxiv.org/pdf/2410.13995v2.pdf","comment":"10 pages, 5 figures, ICLR 2025"},{"id":"http://arxiv.org/abs/2410.16161v1","updated":"2024-10-21T16:25:14Z","published":"2024-10-21T16:25:14Z","title":"DMM: Distributed Matrix Mechanism for Differentially-Private Federated\n  Learning using Packed Secret Sharing","summary":"  Federated Learning (FL) has gained lots of traction recently, both in\nindustry and academia. In FL, a machine learning model is trained using data\nfrom various end-users arranged in committees across several rounds. Since such\ndata can often be sensitive, a primary challenge in FL is providing privacy\nwhile still retaining utility of the model. Differential Privacy (DP) has\nbecome the main measure of privacy in the FL setting. DP comes in two flavors:\ncentral and local. In the former, a centralized server is trusted to receive\nthe users' raw gradients from a training step, and then perturb their\naggregation with some noise before releasing the next version of the model. In\nthe latter (more private) setting, noise is applied on users' local devices,\nand only the aggregation of users' noisy gradients is revealed even to the\nserver. Great strides have been made in increasing the privacy-utility\ntrade-off in the central DP setting, by utilizing the so-called matrix\nmechanism. However, progress has been mostly stalled in the local DP setting.\nIn this work, we introduce the distributed matrix mechanism to achieve the\nbest-of-both-worlds; local DP and also better privacy-utility trade-off from\nthe matrix mechanism. We accomplish this by proposing a cryptographic protocol\nthat securely transfers sensitive values across rounds, which makes use of\npacked secret sharing. This protocol accommodates the dynamic participation of\nusers per training round required by FL, including those that may drop out from\nthe computation. We provide experiments which show that our mechanism indeed\nsignificantly improves the privacy-utility trade-off of FL models compared to\nprevious local DP mechanisms, with little added overhead.\n","authors":["Alexander Bienstock","Ujjwal Kumar","Antigoni Polychroniadou"],"pdf_url":"https://arxiv.org/pdf/2410.16161v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.16159v1","updated":"2024-10-21T16:22:19Z","published":"2024-10-21T16:22:19Z","title":"Metric as Transform: Exploring beyond Affine Transform for Interpretable\n  Neural Network","summary":"  Artificial Neural Networks of varying architectures are generally paired with\naffine transformation at the core. However, we find dot product neurons with\nglobal influence less interpretable as compared to local influence of euclidean\ndistance (as used in Radial Basis Function Network). In this work, we explore\nthe generalization of dot product neurons to $l^p$-norm, metrics, and beyond.\nWe find that metrics as transform performs similarly to affine transform when\nused in MultiLayer Perceptron or Convolutional Neural Network. Moreover, we\nexplore various properties of Metrics, compare it with Affine, and present\nmultiple cases where metrics seem to provide better interpretability. We\ndevelop an interpretable local dictionary based Neural Networks and use it to\nunderstand and reject adversarial examples.\n","authors":["Suman Sapkota"],"pdf_url":"https://arxiv.org/pdf/2410.16159v1.pdf","comment":"22 pages, 20 figures, 3 tables"},{"id":"http://arxiv.org/abs/2410.16154v1","updated":"2024-10-21T16:21:09Z","published":"2024-10-21T16:21:09Z","title":"Unsupervised Replay Strategies for Continual Learning with Limited Data","summary":"  Artificial neural networks (ANNs) show limited performance with scarce or\nimbalanced training data and face challenges with continuous learning, such as\nforgetting previously learned data after new tasks training. In contrast, the\nhuman brain can learn continuously and from just a few examples. This research\nexplores the impact of 'sleep', an unsupervised phase incorporating stochastic\nactivation with local Hebbian learning rules, on ANNs trained incrementally\nwith limited and imbalanced datasets, specifically MNIST and Fashion MNIST. We\ndiscovered that introducing a sleep phase significantly enhanced accuracy in\nmodels trained with limited data. When a few tasks were trained sequentially,\nsleep replay not only rescued previously learned information that had been\ncatastrophically forgetting following new task training but often enhanced\nperformance in prior tasks, especially those trained with limited data. This\nstudy highlights the multifaceted role of sleep replay in augmenting learning\nefficiency and facilitating continual learning in ANNs.\n","authors":["Anthony Bazhenov","Pahan Dewasurendra","Giri P. Krishnan","Jean Erik Delanois"],"pdf_url":"https://arxiv.org/pdf/2410.16154v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.16152v1","updated":"2024-10-21T16:19:34Z","published":"2024-10-21T16:19:34Z","title":"Warped Diffusion: Solving Video Inverse Problems with Image Diffusion\n  Models","summary":"  Using image models naively for solving inverse video problems often suffers\nfrom flickering, texture-sticking, and temporal inconsistency in generated\nvideos. To tackle these problems, in this paper, we view frames as continuous\nfunctions in the 2D space, and videos as a sequence of continuous warping\ntransformations between different frames. This perspective allows us to train\nfunction space diffusion models only on images and utilize them to solve\ntemporally correlated inverse problems. The function space diffusion models\nneed to be equivariant with respect to the underlying spatial transformations.\nTo ensure temporal consistency, we introduce a simple post-hoc test-time\nguidance towards (self)-equivariant solutions. Our method allows us to deploy\nstate-of-the-art latent diffusion models such as Stable Diffusion XL to solve\nvideo inverse problems. We demonstrate the effectiveness of our method for\nvideo inpainting and $8\\times$ video super-resolution, outperforming existing\ntechniques based on noise transformations. We provide generated video results:\nhttps://giannisdaras.github.io/warped\\_diffusion.github.io/.\n","authors":["Giannis Daras","Weili Nie","Karsten Kreis","Alex Dimakis","Morteza Mardani","Nikola Borislavov Kovachki","Arash Vahdat"],"pdf_url":"https://arxiv.org/pdf/2410.16152v1.pdf","comment":"Accepted in NeurIPS 2024"},{"id":"http://arxiv.org/abs/2410.16151v1","updated":"2024-10-21T16:18:31Z","published":"2024-10-21T16:18:31Z","title":"Small Contributions, Small Networks: Efficient Neural Network Pruning\n  Based on Relative Importance","summary":"  Recent advancements have scaled neural networks to unprecedented sizes,\nachieving remarkable performance across a wide range of tasks. However,\ndeploying these large-scale models on resource-constrained devices poses\nsignificant challenges due to substantial storage and computational\nrequirements. Neural network pruning has emerged as an effective technique to\nmitigate these limitations by reducing model size and complexity. In this\npaper, we introduce an intuitive and interpretable pruning method based on\nactivation statistics, rooted in information theory and statistical analysis.\nOur approach leverages the statistical properties of neuron activations to\nidentify and remove weights with minimal contributions to neuron outputs.\nSpecifically, we build a distribution of weight contributions across the\ndataset and utilize its parameters to guide the pruning process. Furthermore,\nwe propose a Pruning-aware Training strategy that incorporates an additional\nregularization term to enhance the effectiveness of our pruning method.\nExtensive experiments on multiple datasets and network architectures\ndemonstrate that our method consistently outperforms several baseline and\nstate-of-the-art pruning techniques.\n","authors":["Mostafa Hussien","Mahmoud Afifi","Kim Khoa Nguyen","Mohamed Cheriet"],"pdf_url":"https://arxiv.org/pdf/2410.16151v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.16150v1","updated":"2024-10-21T16:18:19Z","published":"2024-10-21T16:18:19Z","title":"Modelling Structured Data Learning with Restricted Boltzmann Machines in\n  the Teacher-Student Setting","summary":"  Restricted Boltzmann machines (RBM) are generative models capable to learn\ndata with a rich underlying structure. We study the teacher-student setting\nwhere a student RBM learns structured data generated by a teacher RBM. The\namount of structure in the data is controlled by adjusting the number of hidden\nunits of the teacher and the correlations in the rows of the weights, a.k.a.\npatterns. In the absence of correlations, we validate the conjecture that the\nperformance is independent of the number of teacher patters and hidden units of\nthe student RBMs, and we argue that the teacher-student setting can be used as\na toy model for studying the lottery ticket hypothesis. Beyond this regime, we\nfind that the critical amount of data required to learn the teacher patterns\ndecreases with both their number and correlations. In both regimes, we find\nthat, even with an relatively large dataset, it becomes impossible to learn the\nteacher patterns if the inference temperature used for regularization is kept\ntoo low. In our framework, the student can learn teacher patterns one-to-one or\nmany-to-one, generalizing previous findings about the teacher-student setting\nwith two hidden units to any arbitrary finite number of hidden units.\n","authors":["Robin Thériault","Francesco Tosello","Daniele Tantari"],"pdf_url":"https://arxiv.org/pdf/2410.16150v1.pdf","comment":"51 pages, 21 figures"},{"id":"http://arxiv.org/abs/2410.16146v1","updated":"2024-10-21T16:17:01Z","published":"2024-10-21T16:17:01Z","title":"Towards Combating Frequency Simplicity-biased Learning for Domain\n  Generalization","summary":"  Domain generalization methods aim to learn transferable knowledge from source\ndomains that can generalize well to unseen target domains. Recent studies show\nthat neural networks frequently suffer from a simplicity-biased learning\nbehavior which leads to over-reliance on specific frequency sets, namely as\nfrequency shortcuts, instead of semantic information, resulting in poor\ngeneralization performance. Despite previous data augmentation techniques\nsuccessfully enhancing generalization performances, they intend to apply more\nfrequency shortcuts, thereby causing hallucinations of generalization\nimprovement. In this paper, we aim to prevent such learning behavior of\napplying frequency shortcuts from a data-driven perspective. Given the\ntheoretical justification of models' biased learning behavior on different\nspatial frequency components, which is based on the dataset frequency\nproperties, we argue that the learning behavior on various frequency components\ncould be manipulated by changing the dataset statistical structure in the\nFourier domain. Intuitively, as frequency shortcuts are hidden in the dominant\nand highly dependent frequencies of dataset structure, dynamically perturbating\nthe over-reliance frequency components could prevent the application of\nfrequency shortcuts. To this end, we propose two effective data augmentation\nmodules designed to collaboratively and adaptively adjust the frequency\ncharacteristic of the dataset, aiming to dynamically influence the learning\nbehavior of the model and ultimately serving as a strategy to mitigate shortcut\nlearning. Code is available at AdvFrequency\n(https://github.com/C0notSilly/AdvFrequency).\n","authors":["Xilin He","Jingyu Hu","Qinliang Lin","Cheng Luo","Weicheng Xie","Siyang Song","Muhammad Haris Khan","Linlin Shen"],"pdf_url":"https://arxiv.org/pdf/2410.16146v1.pdf","comment":"Accepted by NeurIPS 2024"},{"id":"http://arxiv.org/abs/2410.16138v1","updated":"2024-10-21T16:04:50Z","published":"2024-10-21T16:04:50Z","title":"Theoretical Insights into Line Graph Transformation on Graph Learning","summary":"  Line graph transformation has been widely studied in graph theory, where each\nnode in a line graph corresponds to an edge in the original graph. This has\ninspired a series of graph neural networks (GNNs) applied to transformed line\ngraphs, which have proven effective in various graph representation learning\ntasks. However, there is limited theoretical study on how line graph\ntransformation affects the expressivity of GNN models. In this study, we focus\non two types of graphs known to be challenging to the Weisfeiler-Leman (WL)\ntests: Cai-F\\\"urer-Immerman (CFI) graphs and strongly regular graphs, and show\nthat applying line graph transformation helps exclude these challenging graph\nproperties, thus potentially assist WL tests in distinguishing these graphs. We\nempirically validate our findings by conducting a series of experiments that\ncompare the accuracy and efficiency of graph isomorphism tests and GNNs on both\nline-transformed and original graphs across these graph structure types.\n","authors":["Fan Yang","Xingyue Huang"],"pdf_url":"https://arxiv.org/pdf/2410.16138v1.pdf","comment":"21 pages, code available at\n  https://github.com/lukeyf/graphs-and-lines"},{"id":"http://arxiv.org/abs/2410.16135v1","updated":"2024-10-21T16:00:04Z","published":"2024-10-21T16:00:04Z","title":"Beyond 2:4: exploring V:N:M sparsity for efficient transformer inference\n  on GPUs","summary":"  To date, 2:4 sparsity has stood as the only sparse pattern that can be\naccelerated using sparse tensor cores on GPUs. In practice, 2:4 sparsity often\npossesses low actual speedups ($\\leq 1.3$) and requires fixed sparse ratios,\nmeaning that other ratios, such as 4:8, 8:16, or those exceeding 50% sparsity,\ndo not incur any speedups on GPUs. Recent studies suggest that V:N:M sparsity\nis promising in addressing these limitations of 2:4 sparsity. However,\nregarding accuracy, the effects of V:N:M sparsity on broader Transformer\nmodels, such as vision Transformers and large language models (LLMs), are\nlargely unexamined. Moreover, Some specific issues related to V:N:M sparsity,\nsuch as how to select appropriate V and M values, remain unresolved. In this\nstudy, we thoroughly investigate the application of V:N:M sparsity in vision\nmodels and LLMs across multiple tasks, from pertaining to downstream tasks. We\npropose three key approaches to enhance the applicability and accuracy of\nV:N:M-sparse Transformers, including heuristic V and M selection,\nV:N:M-specific channel permutation, and three-staged LoRA training techniques.\nExperimental results show that, with our methods, the DeiT-small achieves\nlossless accuracy at 64:2:5 sparsity, while the DeiT-base maintains accuracy\neven at 64:2:8 sparsity. In addition, the fine-tuned LLama2-7B at 64:2:5\nsparsity performs comparably or better than training-free 2:4 sparse\nalternatives on downstream tasks. More importantly, V:N:M-sparse Transformers\noffer a wider range of speedup-accuracy trade-offs compared to 2:4 sparsity.\nOverall, our exploration largely facilitates the V:N:M sparsity to act as a\ntruly effective acceleration solution for Transformers in cost-sensitive\ninference scenarios.\n","authors":["Kang Zhao","Tao Yuan","Han Bao","Zhenfeng Su","Chang Gao","Zhaofeng Sun","Zichen Liang","Liping Jing","Jianfei Chen"],"pdf_url":"https://arxiv.org/pdf/2410.16135v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.14134v2","updated":"2024-10-21T15:59:18Z","published":"2024-08-26T09:29:56Z","title":"Exploring the Potential of Large Language Models for Heterophilic Graphs","summary":"  Large language models (LLMs) have presented significant opportunities to\nenhance various machine learning applications, including graph neural networks\n(GNNs). By leveraging the vast open-world knowledge within LLMs, we can more\neffectively interpret and utilize textual data to better characterize\nheterophilic graphs, where neighboring nodes often have different labels.\nHowever, existing approaches for heterophilic graphs overlook the rich textual\ndata associated with nodes, which could unlock deeper insights into their\nheterophilic contexts. In this work, we explore the potential of LLMs for\nmodeling heterophilic graphs and propose a novel two-stage framework:\nLLM-enhanced edge discriminator and LLM-guided edge reweighting. In the first\nstage, we fine-tune the LLM to better identify homophilic and heterophilic\nedges based on the textual content of their nodes. In the second stage, we\nadaptively manage message propagation in GNNs for different edge types based on\nnode features, structures, and heterophilic or homophilic characteristics. To\ncope with the computational demands when deploying LLMs in practical scenarios,\nwe further explore model distillation techniques to fine-tune smaller, more\nefficient models that maintain competitive performance. Extensive experiments\nvalidate the effectiveness of our framework, demonstrating the feasibility of\nusing LLMs to enhance node classification on heterophilic graphs.\n","authors":["Yuxia Wu","Shujie Li","Yuan Fang","Chuan Shi"],"pdf_url":"https://arxiv.org/pdf/2408.14134v2.pdf","comment":"Under review"},{"id":"http://arxiv.org/abs/2410.13502v2","updated":"2024-10-21T15:58:30Z","published":"2024-10-17T12:48:14Z","title":"MathGAP: Out-of-Distribution Evaluation on Problems with Arbitrarily\n  Complex Proofs","summary":"  Large language models (LLMs) can solve arithmetic word problems with high\naccuracy, but little is known about how well they generalize to problems that\nare more complex than the ones on which they have been trained. Empirical\ninvestigations of such questions are impeded by two major flaws of current\nevaluations: (i) much of the evaluation data is contaminated, in the sense that\nit has already been seen during training, and (ii) benchmark datasets do not\ncapture how problem proofs may be arbitrarily complex in various ways. As a\nstep towards addressing these issues, we present a framework for evaluating\nLLMs on problems with arbitrarily complex arithmetic proofs, called MathGAP.\nMathGAP generates problems that follow fixed proof specifications -- along with\nchain-of-thought reasoning annotations -- enabling systematic studies on\ngeneralization with respect to arithmetic proof complexity. We apply MathGAP to\nanalyze how in-context learning interacts with generalization to problems that\nhave more complex proofs. We find that among the models tested, most show a\nsignificant decrease in performance as proofs get deeper and wider. This effect\nis more pronounced in complex, nonlinear proof structures, which are\nchallenging even for GPT-4o. Surprisingly, providing in-context examples from\nthe same distribution as the test set is not always beneficial for performance.\nIn particular, zero-shot prompting as well as demonstrating a diverse range of\nexamples that are less complex than the test data sometimes yield similar or\nhigher accuracies.\n","authors":["Andreas Opedal","Haruki Shirakami","Bernhard Schölkopf","Abulhair Saparov","Mrinmaya Sachan"],"pdf_url":"https://arxiv.org/pdf/2410.13502v2.pdf","comment":"Preprint"},{"id":"http://arxiv.org/abs/2407.00299v4","updated":"2024-10-21T15:56:23Z","published":"2024-06-29T03:37:29Z","title":"Human-Agent Joint Learning for Efficient Robot Manipulation Skill\n  Acquisition","summary":"  Employing a teleoperation system for gathering demonstrations offers the\npotential for more efficient learning of robot manipulation. However,\nteleoperating a robot arm equipped with a dexterous hand or gripper, via a\nteleoperation system presents inherent challenges due to the task's high\ndimensionality, complexity of motion, and differences between physiological\nstructures. In this study, we introduce a novel system for joint learning\nbetween human operators and robots, that enables human operators to share\ncontrol of a robot end-effector with a learned assistive agent, simplifies the\ndata collection process, and facilitates simultaneous human demonstration\ncollection and robot manipulation training. As data accumulates, the assistive\nagent gradually learns. Consequently, less human effort and attention are\nrequired, enhancing the efficiency of the data collection process. It also\nallows the human operator to adjust the control ratio to achieve a trade-off\nbetween manual and automated control. We conducted experiments in both\nsimulated environments and physical real-world settings. Through user studies\nand quantitative evaluations, it is evident that the proposed system could\nenhance data collection efficiency and reduce the need for human adaptation\nwhile ensuring the collected data is of sufficient quality for downstream\ntasks. \\textit{For more details, please refer to our webpage\nhttps://norweig1an.github.io/HAJL.github.io/.\n","authors":["Shengcheng Luo","Quanquan Peng","Jun Lv","Kaiwen Hong","Katherine Rose Driggs-Campbell","Cewu Lu","Yong-Lu Li"],"pdf_url":"https://arxiv.org/pdf/2407.00299v4.pdf","comment":"8 pages, 6 figures"},{"id":"http://arxiv.org/abs/2410.16128v1","updated":"2024-10-21T15:55:04Z","published":"2024-10-21T15:55:04Z","title":"SMART: Self-learning Meta-strategy Agent for Reasoning Tasks","summary":"  Tasks requiring deductive reasoning, especially those involving multiple\nsteps, often demand adaptive strategies such as intermediate generation of\nrationales or programs, as no single approach is universally optimal. While\nLanguage Models (LMs) can enhance their outputs through iterative\nself-refinement and strategy adjustments, they frequently fail to apply the\nmost effective strategy in their first attempt. This inefficiency raises the\nquestion: Can LMs learn to select the optimal strategy in the first attempt,\nwithout a need for refinement? To address this challenge, we introduce SMART\n(Self-learning Meta-strategy Agent for Reasoning Tasks), a novel framework that\nenables LMs to autonomously learn and select the most effective strategies for\nvarious reasoning tasks. We model the strategy selection process as a Markov\nDecision Process and leverage reinforcement learning-driven continuous\nself-improvement to allow the model to find the suitable strategy to solve a\ngiven task. Unlike traditional self-refinement methods that rely on multiple\ninference passes or external feedback, SMART allows an LM to internalize the\noutcomes of its own reasoning processes and adjust its strategy accordingly,\naiming for correct solutions on the first attempt. Our experiments across\nvarious reasoning datasets and with different model architectures demonstrate\nthat SMART significantly enhances the ability of models to choose optimal\nstrategies without external guidance (+15 points on the GSM8K dataset). By\nachieving higher accuracy with a single inference pass, SMART not only improves\nperformance but also reduces computational costs for refinement-based\nstrategies, paving the way for more efficient and intelligent reasoning in LMs.\n","authors":["Rongxing Liu","Kumar Shridhar","Manish Prajapat","Patrick Xia","Mrinmaya Sachan"],"pdf_url":"https://arxiv.org/pdf/2410.16128v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.16124v1","updated":"2024-10-21T15:51:30Z","published":"2024-10-21T15:51:30Z","title":"MNIST-Nd: a set of naturalistic datasets to benchmark clustering across\n  dimensions","summary":"  Driven by advances in recording technology, large-scale high-dimensional\ndatasets have emerged across many scientific disciplines. Especially in\nbiology, clustering is often used to gain insights into the structure of such\ndatasets, for instance to understand the organization of different cell types.\nHowever, clustering is known to scale poorly to high dimensions, even though\nthe exact impact of dimensionality is unclear as current benchmark datasets are\nmostly two-dimensional. Here we propose MNIST-Nd, a set of synthetic datasets\nthat share a key property of real-world datasets, namely that individual\nsamples are noisy and clusters do not perfectly separate. MNIST-Nd is obtained\nby training mixture variational autoencoders with 2 to 64 latent dimensions on\nMNIST, resulting in six datasets with comparable structure but varying\ndimensionality. It thus offers the chance to disentangle the impact of\ndimensionality on clustering. Preliminary common clustering algorithm\nbenchmarks on MNIST-Nd suggest that Leiden is the most robust for growing\ndimensions.\n","authors":["Polina Turishcheva","Laura Hansel","Martin Ritzert","Marissa A. Weis","Alexander S. Ecker"],"pdf_url":"https://arxiv.org/pdf/2410.16124v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.16122v1","updated":"2024-10-21T15:50:04Z","published":"2024-10-21T15:50:04Z","title":"Integer linear programming for unsupervised training set selection in\n  molecular machine learning","summary":"  Integer linear programming (ILP) is an elegant approach to solve linear\noptimization problems, naturally described using integer decision variables.\nWithin the context of physics-inspired machine learning applied to chemistry,\nwe demonstrate the relevance of an ILP formulation to select molecular training\nsets for predictions of size-extensive properties. We show that our algorithm\noutperforms existing unsupervised training set selection approaches, especially\nwhen predicting properties of molecules larger than those present in the\ntraining set. We argue that the reason for the improved performance is due to\nthe selection that is based on the notion of local similarity (i.e., per-atom)\nand a unique ILP approach that finds optimal solutions efficiently. Altogether,\nthis work provides a practical algorithm to improve the performance of\nphysics-inspired machine learning models and offers insights into the\nconceptual differences with existing training set selection approaches.\n","authors":["Matthieu Haeberle","Puck van Gerwen","Ruben Laplaza","Ksenia R. Briling","Jan Weinreich","Friedrich Eisenbrand","Clemence Corminboeuf"],"pdf_url":"https://arxiv.org/pdf/2410.16122v1.pdf","comment":"31 pages + SI (15 pages)"},{"id":"http://arxiv.org/abs/2410.16121v1","updated":"2024-10-21T15:48:34Z","published":"2024-10-21T15:48:34Z","title":"Extracting Spatiotemporal Data from Gradients with Large Language Models","summary":"  Recent works show that sensitive user data can be reconstructed from gradient\nupdates, breaking the key privacy promise of federated learning. While success\nwas demonstrated primarily on image data, these methods do not directly\ntransfer to other domains, such as spatiotemporal data. To understand privacy\nrisks in spatiotemporal federated learning, we first propose Spatiotemporal\nGradient Inversion Attack (ST-GIA), a gradient attack algorithm tailored to\nspatiotemporal data that successfully reconstructs the original location from\ngradients. Furthermore, the absence of priors in attacks on spatiotemporal data\nhas hindered the accurate reconstruction of real client data. To address this\nlimitation, we propose ST-GIA+, which utilizes an auxiliary language model to\nguide the search for potential locations, thereby successfully reconstructing\nthe original data from gradients. In addition, we design an adaptive defense\nstrategy to mitigate gradient inversion attacks in spatiotemporal federated\nlearning. By dynamically adjusting the perturbation levels, we can offer\ntailored protection for varying rounds of training data, thereby achieving a\nbetter trade-off between privacy and utility than current state-of-the-art\nmethods. Through intensive experimental analysis on three real-world datasets,\nwe reveal that the proposed defense strategy can well preserve the utility of\nspatiotemporal federated learning with effective security protection.\n","authors":["Lele Zheng","Yang Cao","Renhe Jiang","Kenjiro Taura","Yulong Shen","Sheng Li","Masatoshi Yoshikawa"],"pdf_url":"https://arxiv.org/pdf/2410.16121v1.pdf","comment":"arXiv admin note: substantial text overlap with arXiv:2407.08529"},{"id":"http://arxiv.org/abs/2410.16119v1","updated":"2024-10-21T15:47:03Z","published":"2024-10-21T15:47:03Z","title":"SeaDAG: Semi-autoregressive Diffusion for Conditional Directed Acyclic\n  Graph Generation","summary":"  We introduce SeaDAG, a semi-autoregressive diffusion model for conditional\ngeneration of Directed Acyclic Graphs (DAGs). Considering their inherent\nlayer-wise structure, we simulate layer-wise autoregressive generation by\ndesigning different denoising speed for different layers. Unlike conventional\nautoregressive generation that lacks a global graph structure view, our method\nmaintains a complete graph structure at each diffusion step, enabling\noperations such as property control that require the full graph structure.\nLeveraging this capability, we evaluate the DAG properties during training by\nemploying a graph property decoder. We explicitly train the model to learn\ngraph conditioning with a condition loss, which enhances the diffusion model's\ncapacity to generate graphs that are both realistic and aligned with specified\nproperties. We evaluate our method on two representative conditional DAG\ngeneration tasks: (1) circuit generation from truth tables, where precise DAG\nstructures are crucial for realizing circuit functionality, and (2) molecule\ngeneration based on quantum properties. Our approach demonstrates promising\nresults, generating high-quality and realistic DAGs that closely align with\ngiven conditions.\n","authors":["Xinyi Zhou","Xing Li","Yingzhao Lian","Yiwen Wang","Lei Chen","Mingxuan Yuan","Jianye Hao","Guangyong Chen","Pheng Ann Heng"],"pdf_url":"https://arxiv.org/pdf/2410.16119v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.02176v3","updated":"2024-10-21T15:37:16Z","published":"2024-06-04T10:12:09Z","title":"AROMA: Preserving Spatial Structure for Latent PDE Modeling with Local\n  Neural Fields","summary":"  We present AROMA (Attentive Reduced Order Model with Attention), a framework\ndesigned to enhance the modeling of partial differential equations (PDEs) using\nlocal neural fields. Our flexible encoder-decoder architecture can obtain\nsmooth latent representations of spatial physical fields from a variety of data\ntypes, including irregular-grid inputs and point clouds. This versatility\neliminates the need for patching and allows efficient processing of diverse\ngeometries. The sequential nature of our latent representation can be\ninterpreted spatially and permits the use of a conditional transformer for\nmodeling the temporal dynamics of PDEs. By employing a diffusion-based\nformulation, we achieve greater stability and enable longer rollouts compared\nto conventional MSE training. AROMA's superior performance in simulating 1D and\n2D equations underscores the efficacy of our approach in capturing complex\ndynamical behaviors.\n","authors":["Louis Serrano","Thomas X Wang","Etienne Le Naour","Jean-Noël Vittaut","Patrick Gallinari"],"pdf_url":"https://arxiv.org/pdf/2406.02176v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.16106v1","updated":"2024-10-21T15:34:44Z","published":"2024-10-21T15:34:44Z","title":"Statistical Inference for Temporal Difference Learning with Linear\n  Function Approximation","summary":"  Statistical inference with finite-sample validity for the value function of a\ngiven policy in Markov decision processes (MDPs) is crucial for ensuring the\nreliability of reinforcement learning. Temporal Difference (TD) learning,\narguably the most widely used algorithm for policy evaluation, serves as a\nnatural framework for this purpose.In this paper, we study the consistency\nproperties of TD learning with Polyak-Ruppert averaging and linear function\napproximation, and obtain three significant improvements over existing results.\nFirst, we derive a novel sharp high-dimensional probability convergence\nguarantee that depends explicitly on the asymptotic variance and holds under\nweak conditions. We further establish refined high-dimensional Berry-Esseen\nbounds over the class of convex sets that guarantee faster rates than those in\nthe literature. Finally, we propose a plug-in estimator for the asymptotic\ncovariance matrix, designed for efficient online computation. These results\nenable the construction of confidence regions and simultaneous confidence\nintervals for the linear parameters of the value function, with guaranteed\nfinite-sample coverage. We demonstrate the applicability of our theoretical\nfindings through numerical experiments.\n","authors":["Weichen Wu","Gen Li","Yuting Wei","Alessandro Rinaldo"],"pdf_url":"https://arxiv.org/pdf/2410.16106v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.16105v1","updated":"2024-10-21T15:34:33Z","published":"2024-10-21T15:34:33Z","title":"Addressing Spectral Bias of Deep Neural Networks by Multi-Grade Deep\n  Learning","summary":"  Deep neural networks (DNNs) suffer from the spectral bias, wherein DNNs\ntypically exhibit a tendency to prioritize the learning of lower-frequency\ncomponents of a function, struggling to capture its high-frequency features.\nThis paper is to address this issue. Notice that a function having only low\nfrequency components may be well-represented by a shallow neural network (SNN),\na network having only a few layers. By observing that composition of low\nfrequency functions can effectively approximate a high-frequency function, we\npropose to learn a function containing high-frequency components by composing\nseveral SNNs, each of which learns certain low-frequency information from the\ngiven data. We implement the proposed idea by exploiting the multi-grade deep\nlearning (MGDL) model, a recently introduced model that trains a DNN\nincrementally, grade by grade, a current grade learning from the residue of the\nprevious grade only an SNN composed with the SNNs trained in the preceding\ngrades as features. We apply MGDL to synthetic, manifold, colored images, and\nMNIST datasets, all characterized by presence of high-frequency features. Our\nstudy reveals that MGDL excels at representing functions containing\nhigh-frequency information. Specifically, the neural networks learned in each\ngrade adeptly capture some low-frequency information, allowing their\ncompositions with SNNs learned in the previous grades effectively representing\nthe high-frequency features. Our experimental results underscore the efficacy\nof MGDL in addressing the spectral bias inherent in DNNs. By leveraging MGDL,\nwe offer insights into overcoming spectral bias limitation of DNNs, thereby\nenhancing the performance and applicability of deep learning models in tasks\nrequiring the representation of high-frequency information. This study confirms\nthat the proposed method offers a promising solution to address the spectral\nbias of DNNs.\n","authors":["Ronglong Fang","Yuesheng Xu"],"pdf_url":"https://arxiv.org/pdf/2410.16105v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.16103v1","updated":"2024-10-21T15:31:06Z","published":"2024-10-21T15:31:06Z","title":"LDAdam: Adaptive Optimization from Low-Dimensional Gradient Statistics","summary":"  We introduce LDAdam, a memory-efficient optimizer for training large models,\nthat performs adaptive optimization steps within lower dimensional subspaces,\nwhile consistently exploring the full parameter space during training. This\nstrategy keeps the optimizer's memory footprint to a fraction of the model\nsize. LDAdam relies on a new projection-aware update rule for the optimizer\nstates that allows for transitioning between subspaces, i.e., estimation of the\nstatistics of the projected gradients. To mitigate the errors due to low-rank\nprojection, LDAdam integrates a new generalized error feedback mechanism, which\nexplicitly accounts for both gradient and optimizer state compression. We prove\nthe convergence of LDAdam under standard assumptions, and show that LDAdam\nallows for accurate and efficient fine-tuning and pre-training of language\nmodels.\n","authors":["Thomas Robert","Mher Safaryan","Ionut-Vlad Modoranu","Dan Alistarh"],"pdf_url":"https://arxiv.org/pdf/2410.16103v1.pdf","comment":"36 pages"},{"id":"http://arxiv.org/abs/2410.16100v1","updated":"2024-10-21T15:27:18Z","published":"2024-10-21T15:27:18Z","title":"ExDBN: Exact learning of Dynamic Bayesian Networks","summary":"  Causal learning from data has received much attention in recent years. One\nway of capturing causal relationships is by utilizing Bayesian networks. There,\none recovers a weighted directed acyclic graph, in which random variables are\nrepresented by vertices, and the weights associated with each edge represent\nthe strengths of the causal relationships between them. This concept is\nextended to capture dynamic effects by introducing a dependency on past data,\nwhich may be captured by the structural equation model, which is utilized in\nthe present contribution to formulate a score-based learning approach. A\nmixed-integer quadratic program is formulated and an algorithmic solution\nproposed, in which the pre-generation of exponentially many acyclicity\nconstraints is avoided by utilizing the so-called branch-and-cut (\"lazy\nconstraint\") method. Comparing the novel approach to the state of the art, we\nshow that the proposed approach turns out to produce excellent results when\napplied to small and medium-sized synthetic instances of up to 25 time-series.\nLastly, two interesting applications in bio-science and finance, to which the\nmethod is directly applied, further stress the opportunities in developing\nhighly accurate, globally convergent solvers that can handle modest instances.\n","authors":["Pavel Rytíř","Aleš Wodecki","Georgios Korpas","Jakub Mareček"],"pdf_url":"https://arxiv.org/pdf/2410.16100v1.pdf","comment":"12 pages"},{"id":"http://arxiv.org/abs/2402.06955v3","updated":"2024-10-21T15:26:26Z","published":"2024-02-10T13:51:09Z","title":"Feature Mapping in Physics-Informed Neural Networks (PINNs)","summary":"  In this paper, the training dynamics of PINNs with a feature mapping layer\nvia the limiting Conjugate Kernel and Neural Tangent Kernel is investigated,\nshedding light on the convergence of PINNs; Although the commonly used\nFourier-based feature mapping has achieved great success, we show its\ninadequacy in some physics scenarios. Via these two scopes, we propose\nconditionally positive definite Radial Basis Function as a better alternative.\nLastly, we explore the feature mapping numerically in wide neural networks. Our\nempirical results reveal the efficacy of our method in diverse forward and\ninverse problem sets. Composing feature functions is found to be a practical\nway to address the expressivity and generalisability trade-off, viz., tuning\nthe bandwidth of the kernels and the surjectivity of the feature mapping\nfunction. This simple technique can be implemented for coordinate inputs and\nbenefits the broader PINNs research.\n","authors":["Chengxi Zeng","Tilo Burghardt","Alberto M Gambaruto"],"pdf_url":"https://arxiv.org/pdf/2402.06955v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2409.08160v3","updated":"2024-10-21T15:22:58Z","published":"2024-09-12T15:52:22Z","title":"On the Role of Context in Reading Time Prediction","summary":"  We present a new perspective on how readers integrate context during\nreal-time language comprehension. Our proposals build on surprisal theory,\nwhich posits that the processing effort of a linguistic unit (e.g., a word) is\nan affine function of its in-context information content. We first observe that\nsurprisal is only one out of many potential ways that a contextual predictor\ncan be derived from a language model. Another one is the pointwise mutual\ninformation (PMI) between a unit and its context, which turns out to yield the\nsame predictive power as surprisal when controlling for unigram frequency.\nMoreover, both PMI and surprisal are correlated with frequency. This means that\nneither PMI nor surprisal contains information about context alone. In response\nto this, we propose a technique where we project surprisal onto the orthogonal\ncomplement of frequency, yielding a new contextual predictor that is\nuncorrelated with frequency. Our experiments show that the proportion of\nvariance in reading times explained by context is a lot smaller when context is\nrepresented by the orthogonalized predictor. From an interpretability\nstandpoint, this indicates that previous studies may have overstated the role\nthat context has in predicting reading times.\n","authors":["Andreas Opedal","Eleanor Chodroff","Ryan Cotterell","Ethan Gotlieb Wilcox"],"pdf_url":"https://arxiv.org/pdf/2409.08160v3.pdf","comment":"EMNLP 2024"},{"id":"http://arxiv.org/abs/2310.03946v5","updated":"2024-10-21T15:22:54Z","published":"2023-10-05T23:46:45Z","title":"Improved prediction of ligand-protein binding affinities by\n  meta-modeling","summary":"  The accurate screening of candidate drug ligands against target proteins\nthrough computational approaches is of prime interest to drug development\nefforts. Such virtual screening depends in part on methods to predict the\nbinding affinity between ligands and proteins. Many computational models for\nbinding affinity prediction have been developed, but with varying results\nacross targets. Given that ensembling or meta-modeling approaches have shown\ngreat promise in reducing model-specific biases, we develop a framework to\nintegrate published force-field-based empirical docking and sequence-based deep\nlearning models. In building this framework, we evaluate many combinations of\nindividual base models, training databases, and several meta-modeling\napproaches. We show that many of our meta-models significantly improve affinity\npredictions over base models. Our best meta-models achieve comparable\nperformance to state-of-the-art deep learning tools exclusively based on 3D\nstructures, while allowing for improved database scalability and flexibility\nthrough the explicit inclusion of features such as physicochemical properties\nor molecular descriptors. We further demonstrate improved generalization\ncapability by our models using a large-scale benchmark of affinity prediction\nas well as a virtual screening application benchmark. Overall, we demonstrate\nthat diverse modeling approaches can be ensembled together to gain meaningful\nimprovement in binding affinity prediction.\n","authors":["Ho-Joon Lee","Prashant S. Emani","Mark B. Gerstein"],"pdf_url":"https://arxiv.org/pdf/2310.03946v5.pdf","comment":"54 pages, 6 main tables, 6 main figures, 8 supplementary figures, and\n  supporting information. For 11 supplementary tables and code, see\n  https://github.com/Lee1701/Lee2023a"},{"id":"http://arxiv.org/abs/2410.13203v2","updated":"2024-10-21T15:21:56Z","published":"2024-10-17T04:10:36Z","title":"TabSeq: A Framework for Deep Learning on Tabular Data via Sequential\n  Ordering","summary":"  Effective analysis of tabular data still poses a significant problem in deep\nlearning, mainly because features in tabular datasets are often heterogeneous\nand have different levels of relevance. This work introduces TabSeq, a novel\nframework for the sequential ordering of features, addressing the vital\nnecessity to optimize the learning process. Features are not always equally\ninformative, and for certain deep learning models, their random arrangement can\nhinder the model's learning capacity. Finding the optimum sequence order for\nsuch features could improve the deep learning models' learning process. The\nnovel feature ordering technique we provide in this work is based on clustering\nand incorporates both local ordering and global ordering. It is designed to be\nused with a multi-head attention mechanism in a denoising autoencoder network.\nOur framework uses clustering to align comparable features and improve data\norganization. Multi-head attention focuses on essential characteristics,\nwhereas the denoising autoencoder highlights important aspects by rebuilding\nfrom distorted inputs. This method improves the capability to learn from\ntabular data while lowering redundancy. Our research, demonstrating improved\nperformance through appropriate feature sequence rearrangement using raw\nantibody microarray and two other real-world biomedical datasets, validates the\nimpact of feature ordering. These results demonstrate that feature ordering can\nbe a viable approach to improved deep learning of tabular data.\n","authors":["Al Zadid Sultan Bin Habib","Kesheng Wang","Mary-Anne Hartley","Gianfranco Doretto","Donald A. Adjeroh"],"pdf_url":"https://arxiv.org/pdf/2410.13203v2.pdf","comment":"This paper has been accepted for presentation at the 27th\n  International Conference on Pattern Recognition (ICPR 2024) in Kolkata, India"},{"id":"http://arxiv.org/abs/2408.08381v4","updated":"2024-10-21T15:18:39Z","published":"2024-08-15T18:54:31Z","title":"Pre-processing and Compression: Understanding Hidden Representation\n  Refinement Across Imaging Domains via Intrinsic Dimension","summary":"  In recent years, there has been interest in how geometric properties such as\nintrinsic dimension (ID) of a neural network's hidden representations change\nthrough its layers, and how such properties are predictive of important model\nbehavior such as generalization ability. However, evidence has begun to emerge\nthat such behavior can change significantly depending on the domain of the\nnetwork's training data, such as natural versus medical images. Here, we\nfurther this inquiry by exploring how the ID of a network's learned\nrepresentations changes through its layers, in essence, characterizing how the\nnetwork successively refines the information content of input data to be used\nfor predictions. Analyzing eleven natural and medical image datasets across six\nnetwork architectures, we find that how ID changes through the network differs\nnoticeably between natural and medical image models. Specifically, medical\nimage models peak in representation ID earlier in the network, implying a\ndifference in the image features and their abstractness that are typically used\nfor downstream tasks in these domains. Additionally, we discover a strong\ncorrelation of this peak representation ID with the ID of the data in its input\nspace, implying that the intrinsic information content of a model's learned\nrepresentations is guided by that of the data it was trained on. Overall, our\nfindings emphasize notable discrepancies in network behavior between natural\nand non-natural imaging domains regarding hidden representation information\ncontent, and provide further insights into how a network's learned features are\nshaped by its training data.\n","authors":["Nicholas Konz","Maciej A. Mazurowski"],"pdf_url":"https://arxiv.org/pdf/2408.08381v4.pdf","comment":"Published in NeurIPS 2024 Workshop on Scientific Methods for\n  Understanding Deep Learning (SciForDL)"},{"id":"http://arxiv.org/abs/2406.15819v2","updated":"2024-10-21T15:07:13Z","published":"2024-06-22T11:17:50Z","title":"Automatic AI Model Selection for Wireless Systems: Online Learning via\n  Digital Twinning","summary":"  In modern wireless network architectures, such as O-RAN, artificial\nintelligence (AI)-based applications are deployed at intelligent controllers to\ncarry out functionalities like scheduling or power control. The AI \"apps\" are\nselected on the basis of contextual information such as network conditions,\ntopology, traffic statistics, and design goals. The mapping between context and\nAI model parameters is ideally done in a zero-shot fashion via an automatic\nmodel selection (AMS) mapping that leverages only contextual information\nwithout requiring any current data. This paper introduces a general methodology\nfor the online optimization of AMS mappings. Optimizing an AMS mapping is\nchallenging, as it requires exposure to data collected from many different\ncontexts. Therefore, if carried out online, this initial optimization phase\nwould be extremely time consuming. A possible solution is to leverage a digital\ntwin of the physical system to generate synthetic data from multiple simulated\ncontexts. However, given that the simulator at the digital twin is imperfect, a\ndirect use of simulated data for the optimization of the AMS mapping would\nyield poor performance when tested in the real system. This paper proposes a\nnovel method for the online optimization of AMS mapping that corrects for the\nbias of the simulator by means of limited real data collected from the physical\nsystem. Experimental results for a graph neural network-based power control app\ndemonstrate the significant advantages of the proposed approach.\n","authors":["Qiushuo Hou","Matteo Zecchin","Sangwoo Park","Yunlong Cai","Guanding Yu","Kaushik Chowdhury","Osvaldo Simeone"],"pdf_url":"https://arxiv.org/pdf/2406.15819v2.pdf","comment":"submitted for a journal publication"},{"id":"http://arxiv.org/abs/2410.16077v1","updated":"2024-10-21T14:55:59Z","published":"2024-10-21T14:55:59Z","title":"CartesianMoE: Boosting Knowledge Sharing among Experts via Cartesian\n  Product Routing in Mixture-of-Experts","summary":"  Large language models (LLM) have been attracting much attention from the\ncommunity recently, due to their remarkable performance in all kinds of\ndownstream tasks. According to the well-known scaling law, scaling up a dense\nLLM enhances its capabilities, but also significantly increases the\ncomputational complexity. Mixture-of-Experts (MoE) models address that by\nallowing the model size to grow without substantially raising training or\ninference costs. Yet MoE models face challenges regarding knowledge sharing\namong experts, making their performance somehow sensitive to routing accuracy.\nTo tackle that, previous works introduced shared experts and combined their\noutputs with those of the top $K$ routed experts in an ``addition'' manner. In\nthis paper, inspired by collective matrix factorization to learn shared\nknowledge among data, we propose CartesianMoE, which implements more effective\nknowledge sharing among experts in more like a ``multiplication'' manner.\nExtensive experimental results indicate that CartesianMoE outperforms previous\nMoE models for building LLMs, in terms of both perplexity and downstream task\nperformance. And we also find that CartesianMoE achieves better expert routing\nrobustness.\n","authors":["Zhenpeng Su","Xing Wu","Zijia Lin","Yizhe Xiong","Minxuan Lv","Guangyuan Ma","Hui Chen","Songlin Hu","Guiguang Ding"],"pdf_url":"https://arxiv.org/pdf/2410.16077v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.16073v1","updated":"2024-10-21T14:53:12Z","published":"2024-10-21T14:53:12Z","title":"On the Geometry of Regularization in Adversarial Training:\n  High-Dimensional Asymptotics and Generalization Bounds","summary":"  Regularization, whether explicit in terms of a penalty in the loss or\nimplicit in the choice of algorithm, is a cornerstone of modern machine\nlearning. Indeed, controlling the complexity of the model class is particularly\nimportant when data is scarce, noisy or contaminated, as it translates a\nstatistical belief on the underlying structure of the data. This work\ninvestigates the question of how to choose the regularization norm $\\lVert\n\\cdot \\rVert$ in the context of high-dimensional adversarial training for\nbinary classification. To this end, we first derive an exact asymptotic\ndescription of the robust, regularized empirical risk minimizer for various\ntypes of adversarial attacks and regularization norms (including non-$\\ell_p$\nnorms). We complement this analysis with a uniform convergence analysis,\nderiving bounds on the Rademacher Complexity for this class of problems.\nLeveraging our theoretical results, we quantitatively characterize the\nrelationship between perturbation size and the optimal choice of $\\lVert \\cdot\n\\rVert$, confirming the intuition that, in the data scarce regime, the type of\nregularization becomes increasingly important for adversarial training as\nperturbations grow in size.\n","authors":["Matteo Vilucchio","Nikolaos Tsilivis","Bruno Loureiro","Julia Kempe"],"pdf_url":"https://arxiv.org/pdf/2410.16073v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.07012v2","updated":"2024-10-21T14:53:11Z","published":"2024-03-09T10:01:49Z","title":"A PID-Controlled Non-Negative Tensor Factorization Model for Analyzing\n  Missing Data in NILM","summary":"  With the growing demand for energy and increased environmental awareness,\nNon-Intrusive Load Monitoring (NILM) has become an essential tool in smart grid\nand energy management. By analyzing total power load data, NILM infers the\nenergy usage of individual appliances without the need for separate sensors,\nenabling real-time monitoring from a few locations. This approach helps users\nunderstand consumption patterns, enhance energy efficiency, and detect\nanomalies for effective energy management. However, NILM datasets often suffer\nfrom issues such as sensor failures and data loss, compromising data integrity,\nthereby impacting subsequent analysis and applications. Traditional imputation\nmethods, such as linear interpolation and matrix factorization, struggle with\nnonlinear relationships and are sensitive to sparse data, resulting in\ninformation loss. To address these challenges, this paper proposes a\nProportional-Integral-Derivative (PID) Controlled Non-Negative Latent\nFactorization of Tensor (PNLF) model, which dynamically adjusts parameter\ngradients to improve convergence, stability, and accuracy. Experimental results\nshow that the PNLF model significantly outperforms state-of-the-art tensor\ncompletion models in both accuracy and efficiency. By addressing data loss\nissues, this study enhances load disaggregation precision and optimizes energy\nmanagement, providing reliable data support for smart grid applications and\npolicy formulation.\n","authors":["DengYu Shi"],"pdf_url":"https://arxiv.org/pdf/2403.07012v2.pdf","comment":"13papegs 8figures"},{"id":"http://arxiv.org/abs/2410.09940v2","updated":"2024-10-21T14:36:35Z","published":"2024-10-13T17:51:21Z","title":"Generalized Group Data Attribution","summary":"  Data Attribution (DA) methods quantify the influence of individual training\ndata points on model outputs and have broad applications such as\nexplainability, data selection, and noisy label identification. However,\nexisting DA methods are often computationally intensive, limiting their\napplicability to large-scale machine learning models. To address this\nchallenge, we introduce the Generalized Group Data Attribution (GGDA)\nframework, which computationally simplifies DA by attributing to groups of\ntraining points instead of individual ones. GGDA is a general framework that\nsubsumes existing attribution methods and can be applied to new DA techniques\nas they emerge. It allows users to optimize the trade-off between efficiency\nand fidelity based on their needs. Our empirical results demonstrate that GGDA\napplied to popular DA methods such as Influence Functions, TracIn, and TRAK\nresults in upto 10x-50x speedups over standard DA methods while gracefully\ntrading off attribution fidelity. For downstream applications such as dataset\npruning and noisy label identification, we demonstrate that GGDA significantly\nimproves computational efficiency and maintains effectiveness, enabling\npractical applications in large-scale machine learning scenarios that were\npreviously infeasible.\n","authors":["Dan Ley","Suraj Srinivas","Shichang Zhang","Gili Rusak","Himabindu Lakkaraju"],"pdf_url":"https://arxiv.org/pdf/2410.09940v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2310.16705v4","updated":"2024-10-21T14:33:15Z","published":"2023-10-25T15:20:53Z","title":"Wasserstein Gradient Flow over Variational Parameter Space for\n  Variational Inference","summary":"  Variational inference (VI) can be cast as an optimization problem in which\nthe variational parameters are tuned to closely align a variational\ndistribution with the true posterior. The optimization task can be approached\nthrough vanilla gradient descent in black-box VI or natural-gradient descent in\nnatural-gradient VI. In this work, we reframe VI as the optimization of an\nobjective that concerns probability distributions defined over a\n\\textit{variational parameter space}. Subsequently, we propose Wasserstein\ngradient descent for tackling this optimization problem. Notably, the\noptimization techniques, namely black-box VI and natural-gradient VI, can be\nreinterpreted as specific instances of the proposed Wasserstein gradient\ndescent. To enhance the efficiency of optimization, we develop practical\nmethods for numerically solving the discrete gradient flows. We validate the\neffectiveness of the proposed methods through empirical experiments on a\nsynthetic dataset, supplemented by theoretical analyses.\n","authors":["Dai Hai Nguyen","Tetsuya Sakurai","Hiroshi Mamitsuka"],"pdf_url":"https://arxiv.org/pdf/2310.16705v4.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.16052v1","updated":"2024-10-21T14:28:26Z","published":"2024-10-21T14:28:26Z","title":"Near-Optimal Algorithm for Non-Stationary Kernelized Bandits","summary":"  This paper studies a non-stationary kernelized bandit (KB) problem, also\ncalled time-varying Bayesian optimization, where one seeks to minimize the\nregret under an unknown reward function that varies over time. In particular,\nwe focus on a near-optimal algorithm whose regret upper bound matches the\nregret lower bound. For this goal, we show the first algorithm-independent\nregret lower bound for non-stationary KB with squared exponential and Mat\\'ern\nkernels, which reveals that an existing optimization-based KB algorithm with\nslight modification is near-optimal. However, this existing algorithm suffers\nfrom feasibility issues due to its huge computational cost. Therefore, we\npropose a novel near-optimal algorithm called restarting phased elimination\nwith random permutation (R-PERP), which bypasses the huge computational cost. A\ntechnical key point is the simple permutation procedures of query candidates,\nwhich enable us to derive a novel tighter confidence bound tailored to the\nnon-stationary problems.\n","authors":["Shogo Iwazaki","Shion Takeno"],"pdf_url":"https://arxiv.org/pdf/2410.16052v1.pdf","comment":"24 pages, 2 figures"},{"id":"http://arxiv.org/abs/2410.06446v2","updated":"2024-10-21T14:28:18Z","published":"2024-10-09T01:12:07Z","title":"Machine Unlearning in Forgettability Sequence","summary":"  Machine unlearning (MU) is becoming a promising paradigm to achieve the\n\"right to be forgotten\", where the training trace of any chosen data points\ncould be eliminated, while maintaining the model utility on general testing\nsamples after unlearning. With the advancement of forgetting research, many\nfundamental open questions remain unanswered: do different samples exhibit\nvarying levels of difficulty in being forgotten? Further, does the sequence in\nwhich samples are forgotten, determined by their respective difficulty levels,\ninfluence the performance of forgetting algorithms? In this paper, we identify\nkey factor affecting unlearning difficulty and the performance of unlearning\nalgorithms. We find that samples with higher privacy risks are more likely to\nbe unlearning, indicating that the unlearning difficulty varies among different\nsamples which motives a more precise unlearning mode. Built upon this insight,\nwe propose a general unlearning framework, dubbed RSU, which consists of\nRanking module and SeqUnlearn module.\n","authors":["Junjie Chen","Qian Chen","Jian Lou","Xiaoyu Zhang","Kai Wu","Zilong Wang"],"pdf_url":"https://arxiv.org/pdf/2410.06446v2.pdf","comment":"The senior authors of the draft are not fully convinced that the\n  novelty is significant enough for this submission compared to the latest\n  research progress in this area. Additionally, the senior authors have\n  identified writing issues. Based on these two reasons, we have decided to\n  withdraw the draft from arXiv"},{"id":"http://arxiv.org/abs/2410.16041v1","updated":"2024-10-21T14:14:29Z","published":"2024-10-21T14:14:29Z","title":"GFlowNets for Hamiltonian decomposition in groups of compatible\n  operators","summary":"  Quantum computing presents a promising alternative for the direct simulation\nof quantum systems with the potential to explore chemical problems beyond the\ncapabilities of classical methods. However, current quantum algorithms are\nconstrained by hardware limitations and the increased number of measurements\nrequired to achieve chemical accuracy. To address the measurement challenge,\ntechniques for grouping commuting and anti-commuting terms, driven by\nheuristics, have been developed to reduce the number of measurements needed in\nquantum algorithms on near-term quantum devices. In this work, we propose a\nprobabilistic framework using GFlowNets to group fully (FC) or qubit-wise\ncommuting (QWC) terms within a given Hamiltonian. The significance of this\napproach is demonstrated by the reduced number of measurements for the found\ngroupings; 51% and 67% reduction factors respectively for FC and QWC\npartitionings with respect to greedy coloring algorithms, highlighting the\npotential of GFlowNets for future applications in the measurement problem.\nFurthermore, the flexibility of our algorithm extends its applicability to\nother resource optimization problems in Hamiltonian simulation, such as circuit\ndesign.\n","authors":["Isaac L. Huidobro-Meezs","Jun Dai","Guillaume Rabusseau","Rodrigo A. Vargas-Hernández"],"pdf_url":"https://arxiv.org/pdf/2410.16041v1.pdf","comment":"8 pages, 2 figures. Accepted for Machine Learning and the Physical\n  Sciences Workshop, NeurIPS 2024. Submission Number: 167"},{"id":"http://arxiv.org/abs/2410.16032v1","updated":"2024-10-21T14:06:53Z","published":"2024-10-21T14:06:53Z","title":"TimeMixer++: A General Time Series Pattern Machine for Universal\n  Predictive Analysis","summary":"  Time series analysis plays a critical role in numerous applications,\nsupporting tasks such as forecasting, classification, anomaly detection, and\nimputation. In this work, we present the time series pattern machine (TSPM), a\nmodel designed to excel in a broad range of time series tasks through powerful\nrepresentation and pattern extraction capabilities. Traditional time series\nmodels often struggle to capture universal patterns, limiting their\neffectiveness across diverse tasks. To address this, we define multiple scales\nin the time domain and various resolutions in the frequency domain, employing\nvarious mixing strategies to extract intricate, task-adaptive time series\npatterns. Specifically, we introduce a general-purpose TSPM that processes\nmulti-scale time series using (1) multi-resolution time imaging (MRTI), (2)\ntime image decomposition (TID), (3) multi-scale mixing (MCM), and (4)\nmulti-resolution mixing (MRM) to extract comprehensive temporal patterns. MRTI\ntransforms multi-scale time series into multi-resolution time images, capturing\npatterns across both temporal and frequency domains. TID leverages dual-axis\nattention to extract seasonal and trend patterns, while MCM hierarchically\naggregates these patterns across scales. MRM adaptively integrates all\nrepresentations across resolutions. This method achieves state-of-the-art\nperformance across 8 time series analytical tasks, consistently surpassing both\ngeneral-purpose and task-specific models. Our work marks a promising step\ntoward the next generation of TSPMs, paving the way for further advancements in\ntime series analysis.\n","authors":["Shiyu Wang","Jiawei Li","Xiaoming Shi","Zhou Ye","Baichuan Mo","Wenze Lin","Shengtong Ju","Zhixuan Chu","Ming Jin"],"pdf_url":"https://arxiv.org/pdf/2410.16032v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.16029v1","updated":"2024-10-21T14:05:06Z","published":"2024-10-21T14:05:06Z","title":"Natural GaLore: Accelerating GaLore for memory-efficient LLM Training\n  and Fine-tuning","summary":"  Training LLMs presents significant memory challenges due to growing size of\ndata, weights, and optimizer states. Techniques such as data and model\nparallelism, gradient checkpointing, and offloading strategies address this\nissue but are often infeasible due to hardware constraints. To mitigate memory\nusage, alternative methods like Parameter-Efficient-Fine-Tuning (PEFT) and\nGaLore approximate weights or optimizer states. PEFT methods, such as LoRA,\nhave gained popularity for fine-tuning LLMs, though they require a full-rank\nwarm start. In contrast, GaLore allows full-parameter learning while being more\nmemory-efficient. This work introduces Natural GaLore, a simple drop in\nreplacement for AdamW, which efficiently applies the inverse Empirical Fisher\nInformation Matrix to low-rank gradients using Woodbury's Identity. We\ndemonstrate that incorporating second-order information speeds up optimization\nsignificantly, especially when the iteration budget is limited. Empirical\npretraining on 60M, 130M, 350M, and 1.1B parameter Llama models on C4 data\ndemonstrate significantly lower perplexity over GaLore without additional\nmemory overhead. By fine-tuning RoBERTa on the GLUE benchmark using Natural\nGaLore, we demonstrate significant reduction in gap 86.05% vs 86.28% for\nfull-finetuning. Furthermore, fine-tuning the TinyLlama 1.1B model for function\ncalling using the TinyAgent framework shows that Natural GaLore achieving\n83.09% accuracy on the TinyAgent dataset, significantly outperforms 16-bit LoRA\nat 80.06% and even surpasses GPT4-Turbo by 4%, all while using 30% less memory.\n  All code to reproduce the results are available at:\nhttps://github.com/selfsupervised-ai/Natural-GaLore.git\n","authors":["Arijit Das"],"pdf_url":"https://arxiv.org/pdf/2410.16029v1.pdf","comment":"10 pages, 3 tables, 3 figures"},{"id":"http://arxiv.org/abs/2403.04202v6","updated":"2024-10-21T13:47:44Z","published":"2024-03-07T04:12:24Z","title":"Dynamics of Moral Behavior in Heterogeneous Populations of Learning\n  Agents","summary":"  Growing concerns about safety and alignment of AI systems highlight the\nimportance of embedding moral capabilities in artificial agents: a promising\nsolution is the use of learning from experience, i.e., Reinforcement Learning.\nIn multi-agent (social) environments, complex population-level phenomena may\nemerge from interactions between individual learning agents. Many of the\nexisting studies rely on simulated social dilemma environments to study the\ninteractions of independent learning agents; however, they tend to ignore the\nmoral heterogeneity that is likely to be present in societies of agents in\npractice. For example, at different points in time a single learning agent may\nface opponents who are consequentialist (i.e., focused on maximizing outcomes\nover time), norm-based (i.e., conforming to specific norms), or virtue-based\n(i.e., considering a combination of different virtues). The extent to which\nagents' co-development may be impacted by such moral heterogeneity in\npopulations is not well understood. In this paper, we present a study of the\nlearning dynamics of morally heterogeneous populations interacting in a social\ndilemma setting. Using an Iterated Prisoner's Dilemma environment with a\npartner selection mechanism, we investigate the extent to which the prevalence\nof diverse moral agents in populations affects individual agents' learning\nbehaviors and emergent population-level outcomes. We observe several types of\nnon-trivial interactions between pro-social and anti-social agents, and find\nthat certain types of moral agents are able to steer selfish agents towards\nmore cooperative behavior.\n","authors":["Elizaveta Tennant","Stephen Hailes","Mirco Musolesi"],"pdf_url":"https://arxiv.org/pdf/2403.04202v6.pdf","comment":"Presented at AIES 2024 (7th AAAI/ACM Conference on AI, Ethics, and\n  Society - San Jose, CA, USA)\n  https://ojs.aaai.org/index.php/AIES/article/view/31736"},{"id":"http://arxiv.org/abs/2410.16013v1","updated":"2024-10-21T13:45:02Z","published":"2024-10-21T13:45:02Z","title":"Information-Theoretic Minimax Regret Bounds for Reinforcement Learning\n  based on Duality","summary":"  We study agents acting in an unknown environment where the agent's goal is to\nfind a robust policy. We consider robust policies as policies that achieve high\ncumulative rewards for all possible environments. To this end, we consider\nagents minimizing the maximum regret over different environment parameters,\nleading to the study of minimax regret. This research focuses on deriving\ninformation-theoretic bounds for minimax regret in Markov Decision Processes\n(MDPs) with a finite time horizon. Building on concepts from supervised\nlearning, such as minimum excess risk (MER) and minimax excess risk, we use\nrecent bounds on the Bayesian regret to derive minimax regret bounds.\nSpecifically, we establish minimax theorems and use bounds on the Bayesian\nregret to perform minimax regret analysis using these minimax theorems. Our\ncontributions include defining a suitable minimax regret in the context of\nMDPs, finding information-theoretic bounds for it, and applying these bounds in\nvarious scenarios.\n","authors":["Raghav Bongole","Amaury Gouverneur","Borja Rodríguez-Gálvez","Tobias J. Oechtering","Mikael Skoglund"],"pdf_url":"https://arxiv.org/pdf/2410.16013v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.16012v1","updated":"2024-10-21T13:43:02Z","published":"2024-10-21T13:43:02Z","title":"Massimo: Public Queue Monitoring and Management using Mass-Spring Model","summary":"  An efficient system of a queue control and regulation in public spaces is\nvery important in order to avoid the traffic jams and to improve the customer\nsatisfaction. This article offers a detailed road map based on a merger of\nintelligent systems and creating an efficient systems of queues in public\nplaces. Through the utilization of different technologies i.e. computer vision,\nmachine learning algorithms, deep learning our system provide accurate\ninformation about the place is crowded or not and the necessary efforts to be\ntaken.\n","authors":["Abhijeet Kumar","Unnati Singh","Rajdeep Chatterjee","Tathagata Bandyopadhyay"],"pdf_url":"https://arxiv.org/pdf/2410.16012v1.pdf","comment":"8 pages, 6 figures, 3 algorithms, 3 tables"},{"id":"http://arxiv.org/abs/2410.16008v1","updated":"2024-10-21T13:41:27Z","published":"2024-10-21T13:41:27Z","title":"Resilient Temporal GCN for Smart Grid State Estimation Under Topology\n  Inaccuracies","summary":"  State Estimation is a crucial task in power systems. Graph Neural Networks\nhave demonstrated significant potential in state estimation for power systems\nby effectively analyzing measurement data and capturing the complex\ninteractions and interrelations among the measurements through the system's\ngraph structure. However, the information about the system's graph structure\nmay be inaccurate due to noise, attack or lack of accurate information about\nthe topology of the system. This paper studies these scenarios under topology\nuncertainties and evaluates the impact of the topology uncertainties on the\nperformance of a Temporal Graph Convolutional Network (TGCN) for state\nestimation in power systems. In order to make the model resilient to topology\nuncertainties, modifications in the TGCN model are proposed to incorporate a\nknowledge graph, generated based on the measurement data. This knowledge graph\nsupports the assumed uncertain system graph. Two variations of the TGCN\narchitecture are introduced to integrate the knowledge graph, and their\nperformances are evaluated and compared to demonstrate improved resilience\nagainst topology uncertainties. The evaluation results indicate that while the\ntwo proposed architecture show different performance, they both improve the\nperformance of the TGCN state estimation under topology uncertainties.\n","authors":["Seyed Hamed Haghshenas","Mia Naeini"],"pdf_url":"https://arxiv.org/pdf/2410.16008v1.pdf","comment":"9 pages, 5 figures"},{"id":"http://arxiv.org/abs/2406.10576v2","updated":"2024-10-21T13:39:32Z","published":"2024-06-15T09:31:03Z","title":"Bypass Back-propagation: Optimization-based Structural Pruning for Large\n  Language Models via Policy Gradient","summary":"  In contrast to moderate-size neural network pruning, structural weight\npruning on the Large-Language Models (LLMs) imposes a novel challenge on the\nefficiency of the pruning algorithms, due to the heavy computation/memory\ndemands of the LLMs. Recent efficient LLM pruning methods typically operate at\nthe post-training phase without the expensive weight finetuning, however, their\npruning criteria often rely on heuristically hand-crafted metrics, potentially\nleading to suboptimal performance. We instead propose a novel\noptimization-based structural pruning that learns the pruning masks in a\nprobabilistic space directly by optimizing the loss of the pruned model. To\npreserve the efficiency, our method eliminates the back-propagation through the\nLLM per se during the optimization, requiring only the forward pass of the LLM.\nWe achieve this by learning an underlying Bernoulli distribution to sample\nbinary pruning masks, where we decouple the Bernoulli parameters from the LLM\nloss, thus facilitating an efficient optimization via a policy gradient\nestimator without back-propagation. As a result, our method is able to 1)\noperate at structural granularities of channels, heads, and layers, 2) support\nglobal and heterogeneous pruning (i.e., our method automatically determines\ndifferent redundancy for different layers), and 3) optionally initialize with a\nmetric-based method (for our Bernoulli distributions). Extensive experiments on\nLLaMA, LLaMA-2, LLaMA-3, Vicuna, and Mistral using the C4 and WikiText2\ndatasets demonstrate that our method operates for 2.7 hours with around 35GB\nmemory for the 13B models on a single A100 GPU, and our pruned models\noutperform the state-of-the-arts w.r.t. both perplexity and the majority of\nvarious zero-shot tasks. Codes will be released.\n","authors":["Yuan Gao","Zujing Liu","Weizhong Zhang","Bo Du","Gui-Song Xia"],"pdf_url":"https://arxiv.org/pdf/2406.10576v2.pdf","comment":"Initially submitted on June 15, 2024, this version mainly changed the\n  title, and added several experiments: such as 1) experiments on LLaMA-3,\n  Mistral, 2) additional baseline methods (i.e., Bosai -- Everybody Prune Now),\n  and 3) post-pruning finetuned performance (i.e., first prune then finetune)"},{"id":"http://arxiv.org/abs/2404.14212v4","updated":"2024-10-21T13:34:22Z","published":"2024-04-22T14:21:37Z","title":"Toward Routing River Water in Land Surface Models with Recurrent Neural\n  Networks","summary":"  Machine learning is playing an increasing role in hydrology, supplementing or\nreplacing physics-based models. One notable example is the use of recurrent\nneural networks (RNNs) for forecasting streamflow given observed precipitation\nand geographic characteristics. Training of such a model over the continental\nUnited States (CONUS) demonstrated that a single set of model parameters can be\nused across independent catchments, and that RNNs can outperform physics-based\nmodels. In this work, we take a next step and study the performance of RNNs for\nriver routing in land surface models (LSMs). Instead of observed precipitation,\nthe LSM-RNN uses instantaneous runoff calculated from physics-based models as\nan input. We train the model with data from river basins spanning the globe and\ntest using historical streamflow measurements. The model demonstrates skill at\ngeneralization across basins (predicting streamflow in catchments not used in\ntraining) and across time (predicting streamflow during years not used in\ntraining). We compare the predictions from the LSM-RNN to an existing\nphysics-based model calibrated with a similar dataset and find that the LSM-RNN\noutperforms the physics-based model. Our results show that RNNs are effective\nfor global streamflow prediction from runoff inputs and motivate the\ndevelopment of complete routing models that can capture nested sub-basis\nconnections.\n","authors":["Mauricio Lima","Katherine Deck","Oliver R. A. Dunbar","Tapio Schneider"],"pdf_url":"https://arxiv.org/pdf/2404.14212v4.pdf","comment":"32 pages, 11 figures; submitted in HESS (EGU) with CCBY license"},{"id":"http://arxiv.org/abs/2410.15998v1","updated":"2024-10-21T13:29:08Z","published":"2024-10-21T13:29:08Z","title":"1024m at SMM4H 2024: Tasks 3, 5 & 6 -- Ensembles of Transformers and\n  Large Language Models for Medical Text Classification","summary":"  Social media is a great source of data for users reporting information and\nregarding their health and how various things have had an effect on them. This\npaper presents various approaches using Transformers and Large Language Models\nand their ensembles, their performance along with advantages and drawbacks for\nvarious tasks of SMM4H'24 - Classifying texts on impact of nature and outdoor\nspaces on the author's mental health (Task 3), Binary classification of tweets\nreporting their children's health disorders like Asthma, Autism, ADHD and\nSpeech disorder (task 5), Binary classification of users self-reporting their\nage (task 6).\n","authors":["Ram Mohan Rao Kadiyala","M. V. P. Chandra Sekhara Rao"],"pdf_url":"https://arxiv.org/pdf/2410.15998v1.pdf","comment":"short paper , acl 2024"},{"id":"http://arxiv.org/abs/2410.15997v1","updated":"2024-10-21T13:28:28Z","published":"2024-10-21T13:28:28Z","title":"MultiRC: Joint Learning for Time Series Anomaly Prediction and Detection\n  with Multi-scale Reconstructive Contrast","summary":"  Many methods have been proposed for unsupervised time series anomaly\ndetection. Despite some progress, research on predicting future anomalies is\nstill relatively scarce. Predicting anomalies is particularly challenging due\nto the diverse reaction time and the lack of labeled data. To address these\nchallenges, we propose MultiRC to integrate reconstructive and contrastive\nlearning for joint learning of anomaly prediction and detection, with\nmulti-scale structure and adaptive dominant period mask to deal with the\ndiverse reaction time. MultiRC also generates negative samples to provide\nessential training momentum for the anomaly prediction tasks and prevent model\ndegradation. We evaluate seven benchmark datasets from different fields. For\nboth anomaly prediction and detection tasks, MultiRC outperforms existing\nstate-of-the-art methods.\n","authors":["Shiyan Hu","Kai Zhao","Xiangfei Qiu","Yang Shu","Jilin Hu","Bin Yang","Chenjuan Guo"],"pdf_url":"https://arxiv.org/pdf/2410.15997v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.15990v1","updated":"2024-10-21T13:20:15Z","published":"2024-10-21T13:20:15Z","title":"Augmenting Legal Decision Support Systems with LLM-based NLI for\n  Analyzing Social Media Evidence","summary":"  This paper presents our system description and error analysis of our entry\nfor NLLP 2024 shared task on Legal Natural Language Inference (L-NLI)\n\\citep{hagag2024legallenssharedtask2024}. The task required classifying these\nrelationships as entailed, contradicted, or neutral, indicating any association\nbetween the review and the complaint. Our system emerged as the winning\nsubmission, significantly outperforming other entries with a substantial margin\nand demonstrating the effectiveness of our approach in legal text analysis. We\nprovide a detailed analysis of the strengths and limitations of each model and\napproach tested, along with a thorough error analysis and suggestions for\nfuture improvements. This paper aims to contribute to the growing field of\nlegal NLP by offering insights into advanced techniques for natural language\ninference in legal contexts, making it accessible to both experts and newcomers\nin the field.\n","authors":["Ram Mohan Rao Kadiyala","Siddartha Pullakhandam","Kanwal Mehreen","Subhasya Tippareddy","Ashay Srivastava"],"pdf_url":"https://arxiv.org/pdf/2410.15990v1.pdf","comment":"8 pages , accepted to emnlp 2024"},{"id":"http://arxiv.org/abs/2410.15987v1","updated":"2024-10-21T13:16:58Z","published":"2024-10-21T13:16:58Z","title":"Analyzing Closed-loop Training Techniques for Realistic Traffic Agent\n  Models in Autonomous Highway Driving Simulations","summary":"  Simulation plays a crucial role in the rapid development and safe deployment\nof autonomous vehicles. Realistic traffic agent models are indispensable for\nbridging the gap between simulation and the real world. Many existing\napproaches for imitating human behavior are based on learning from\ndemonstration. However, these approaches are often constrained by focusing on\nindividual training strategies. Therefore, to foster a broader understanding of\nrealistic traffic agent modeling, in this paper, we provide an extensive\ncomparative analysis of different training principles, with a focus on\nclosed-loop methods for highway driving simulation. We experimentally compare\n(i) open-loop vs. closed-loop multi-agent training, (ii) adversarial vs.\ndeterministic supervised training, (iii) the impact of reinforcement losses,\nand (iv) the impact of training alongside log-replayed agents to identify\nsuitable training techniques for realistic agent modeling. Furthermore, we\nidentify promising combinations of different closed-loop training methods.\n","authors":["Matthias Bitzer","Reinis Cimurs","Benjamin Coors","Johannes Goth","Sebastian Ziesche","Philipp Geiger","Maximilian Naumann"],"pdf_url":"https://arxiv.org/pdf/2410.15987v1.pdf","comment":"15 pages, 6 figures, 4 tables"},{"id":"http://arxiv.org/abs/2410.15986v1","updated":"2024-10-21T13:16:29Z","published":"2024-10-21T13:16:29Z","title":"A quantitative Robbins-Siegmund theorem","summary":"  The Robbins-Siegmund theorem is one of the most important results in\nstochastic optimization, where it is widely used to prove the convergence of\nstochastic algorithms. We provide a quantitative version of the theorem,\nestablishing a bound on how far one needs to look in order to locate a region\nof metastability in the sense of Tao. Our proof involves a metastable analogue\nof Doob's theorem for $L_1$-supermartingales along with a series of technical\nlemmas that make precise how quantitative information propagates through sums\nand products of stochastic processes. In this way, our paper establishes a\ngeneral methodology for finding metastable bounds for stochastic processes that\ncan be reduced to supermartingales, and therefore for obtaining quantitative\nconvergence information across a broad class of stochastic algorithms whose\nconvergence proof relies on some variation of the Robbins-Siegmund theorem. We\nconclude by discussing how our general quantitative result might be used in\npractice.\n","authors":["Morenikeji Neri","Thomas Powell"],"pdf_url":"https://arxiv.org/pdf/2410.15986v1.pdf","comment":"30 pages"},{"id":"http://arxiv.org/abs/2410.06003v3","updated":"2024-10-21T13:12:35Z","published":"2024-10-08T13:04:02Z","title":"Is the MMI Criterion Necessary for Interpretability? Degenerating\n  Non-causal Features to Plain Noise for Self-Rationalization","summary":"  An important line of research in the field of explainability is to extract a\nsmall subset of crucial rationales from the full input. The most widely used\ncriterion for rationale extraction is the maximum mutual information (MMI)\ncriterion. However, in certain datasets, there are spurious features\nnon-causally correlated with the label and also get high mutual information,\ncomplicating the loss landscape of MMI. Although some penalty-based methods\nhave been developed to penalize the spurious features (e.g., invariance\npenalty, intervention penalty, etc) to help MMI work better, these are merely\nremedial measures. In the optimization objectives of these methods, spurious\nfeatures are still distinguished from plain noise, which hinders the discovery\nof causal rationales. This paper aims to develop a new criterion that treats\nspurious features as plain noise, allowing the model to work on datasets rich\nin spurious features as if it were working on clean datasets, thereby making\nrationale extraction easier. We theoretically observe that removing either\nplain noise or spurious features from the input does not alter the conditional\ndistribution of the remaining components relative to the task label. However,\nsignificant changes in the conditional distribution occur only when causal\nfeatures are eliminated. Based on this discovery, the paper proposes a\ncriterion for \\textbf{M}aximizing the \\textbf{R}emaining \\textbf{D}iscrepancy\n(MRD). Experiments on six widely used datasets show that our MRD criterion\nimproves rationale quality (measured by the overlap with human-annotated\nrationales) by up to $10.4\\%$ as compared to several recent competitive MMI\nvariants. Code: \\url{https://github.com/jugechengzi/Rationalization-MRD}.\n","authors":["Wei Liu","Zhiying Deng","Zhongyu Niu","Jun Wang","Haozhao Wang","YuanKai Zhang","Ruixuan Li"],"pdf_url":"https://arxiv.org/pdf/2410.06003v3.pdf","comment":"Accepted at NeurIPS 2024. arXiv admin note: text overlap with\n  arXiv:2309.13391"},{"id":"http://arxiv.org/abs/2410.15982v1","updated":"2024-10-21T13:12:22Z","published":"2024-10-21T13:12:22Z","title":"State Estimation Using Sparse DEIM and Recurrent Neural Networks","summary":"  Discrete Empirical Interpolation Method (DEIM) estimates a function from its\npointwise incomplete observations. In particular, this method can be used to\nestimate the state of a dynamical system from observational data gathered by\nsensors. However, when the number of observations are limited, DEIM returns\nlarge estimation errors. Sparse DEIM (S-DEIM) was recently developed to address\nthis problem by introducing a kernel vector which previous DEIM-based methods\nhad ignored. Unfortunately, estimating the optimal kernel vector in S-DEIM is a\ndifficult task. Here, we introduce a data-driven method to estimate this kernel\nvector from sparse observational time series using recurrent neural networks.\nUsing numerical examples, we demonstrate that this machine learning approach\ntogether with S-DEIM leads to nearly optimal state estimations.\n","authors":["Mohammad Farazmand"],"pdf_url":"https://arxiv.org/pdf/2410.15982v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.11786v2","updated":"2024-10-21T13:11:44Z","published":"2024-10-15T17:05:25Z","title":"Selection-p: Self-Supervised Task-Agnostic Prompt Compression for\n  Faithfulness and Transferability","summary":"  Large Language Models (LLMs) have demonstrated impressive capabilities in a\nwide range of natural language processing tasks when leveraging in-context\nlearning. To mitigate the additional computational and financial costs\nassociated with in-context learning, several prompt compression methods have\nbeen proposed to compress the in-context learning prompts. Despite their\nsuccess, these methods face challenges with transferability due to\nmodel-specific compression, or rely on external training data, such as GPT-4.\nIn this paper, we investigate the ability of LLMs to develop a unified\ncompression method that discretizes uninformative tokens, utilizing a\nself-supervised pre-training technique. By introducing a small number of\nparameters during the continual pre-training, the proposed Selection-p produces\na probability for each input token, indicating whether to preserve or discard\nit. Experiments show Selection-p achieves state-of-the-art performance across\nnumerous classification tasks, achieving compression rates of up to 10 times\nwhile experiencing only a marginal 0.8% decrease in performance. Moreover, it\nexhibits superior transferability to different models compared to prior work.\nAdditionally, we further analyze how Selection-p helps maintain performance on\nin-context learning with long contexts.\n","authors":["Tsz Ting Chung","Leyang Cui","Lemao Liu","Xinting Huang","Shuming Shi","Dit-Yan Yeung"],"pdf_url":"https://arxiv.org/pdf/2410.11786v2.pdf","comment":"14 pages, 5 figures, 10 tables, EMNLP 2024 Findings"},{"id":"http://arxiv.org/abs/2410.15981v1","updated":"2024-10-21T13:06:38Z","published":"2024-10-21T13:06:38Z","title":"Visual Representation Learning Guided By Multi-modal Prior Knowledge","summary":"  Despite the remarkable success of deep neural networks (DNNs) in computer\nvision, they fail to remain high-performing when facing distribution shifts\nbetween training and testing data. In this paper, we propose Knowledge-Guided\nVisual representation learning (KGV), a distribution-based learning approach\nleveraging multi-modal prior knowledge, to improve generalization under\ndistribution shift. We use prior knowledge from two distinct modalities: 1) a\nknowledge graph (KG) with hierarchical and association relationships; and 2)\ngenerated synthetic images of visual elements semantically represented in the\nKG. The respective embeddings are generated from the given modalities in a\ncommon latent space, i.e., visual embeddings from original and synthetic images\nas well as knowledge graph embeddings (KGEs). These embeddings are aligned via\na novel variant of translation-based KGE methods, where the node and relation\nembeddings of the KG are modeled as Gaussian distributions and translations\nrespectively. We claim that incorporating multi-model prior knowledge enables\nmore regularized learning of image representations. Thus, the models are able\nto better generalize across different data distributions. We evaluate KGV on\ndifferent image classification tasks with major or minor distribution shifts,\nnamely road sign classification across datasets from Germany, China, and\nRussia, image classification with the mini-ImageNet dataset and its variants,\nas well as the DVM-CAR dataset. The results demonstrate that KGV consistently\nexhibits higher accuracy and data efficiency than the baselines across all\nexperiments.\n","authors":["Hongkuan Zhou","Lavdim Halilaj","Sebastian Monka","Stefan Schmid","Yuqicheng Zhu","Bo Xiong","Steffen Staab"],"pdf_url":"https://arxiv.org/pdf/2410.15981v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.15974v1","updated":"2024-10-21T13:00:09Z","published":"2024-10-21T13:00:09Z","title":"Large Language Models for Cross-lingual Emotion Detection","summary":"  This paper presents a detailed system description of our entry for the WASSA\n2024 Task 2, focused on cross-lingual emotion detection. We utilized a\ncombination of large language models (LLMs) and their ensembles to effectively\nunderstand and categorize emotions across different languages. Our approach not\nonly outperformed other submissions with a large margin, but also demonstrated\nthe strength of integrating multiple models to enhance performance.\nAdditionally, We conducted a thorough comparison of the benefits and\nlimitations of each model used. An error analysis is included along with\nsuggested areas for future improvement. This paper aims to offer a clear and\ncomprehensive understanding of advanced techniques in emotion detection, making\nit accessible even to those new to the field.\n","authors":["Ram Mohan Rao Kadiyala"],"pdf_url":"https://arxiv.org/pdf/2410.15974v1.pdf","comment":"6 pages , accepted to acl 2024"},{"id":"http://arxiv.org/abs/2410.15973v1","updated":"2024-10-21T12:59:58Z","published":"2024-10-21T12:59:58Z","title":"Karush-Kuhn-Tucker Condition-Trained Neural Networks (KKT Nets)","summary":"  This paper presents a novel approach to solving convex optimization problems\nby leveraging the fact that, under certain regularity conditions, any set of\nprimal or dual variables satisfying the Karush-Kuhn-Tucker (KKT) conditions is\nnecessary and sufficient for optimality. Similar to Theory-Trained Neural\nNetworks (TTNNs), the parameters of the convex optimization problem are input\nto the neural network, and the expected outputs are the optimal primal and dual\nvariables. A choice for the loss function in this case is a loss, which we\nrefer to as the KKT Loss, that measures how well the network's outputs satisfy\nthe KKT conditions. We demonstrate the effectiveness of this approach using a\nlinear program as an example. For this problem, we observe that minimizing the\nKKT Loss alone outperforms training the network with a weighted sum of the KKT\nLoss and a Data Loss (the mean-squared error between the ground truth optimal\nsolutions and the network's output). Moreover, minimizing only the Data Loss\nyields inferior results compared to those obtained by minimizing the KKT Loss.\nWhile the approach is promising, the obtained primal and dual solutions are not\nsufficiently close to the ground truth optimal solutions. In the future, we aim\nto develop improved models to obtain solutions closer to the ground truth and\nextend the approach to other problem classes.\n","authors":["Shreya Arvind","Rishabh Pomaje","Rajshekhar V Bhat"],"pdf_url":"https://arxiv.org/pdf/2410.15973v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.15954v1","updated":"2024-10-21T12:34:02Z","published":"2024-10-21T12:34:02Z","title":"TS-ACL: A Time Series Analytic Continual Learning Framework for\n  Privacy-Preserving and Class-Incremental Pattern Recognition","summary":"  Class-incremental Learning (CIL) in Time Series Classification (TSC) aims to\nincrementally train models using the streaming time series data that arrives\ncontinuously. The main problem in this scenario is catastrophic forgetting,\ni.e., training models with new samples inevitably leads to the forgetting of\npreviously learned knowledge. Among existing methods, the replay-based methods\nachieve satisfactory performance but compromise privacy, while exemplar-free\nmethods protect privacy but suffer from low accuracy. However, more critically,\nowing to their reliance on gradient-based update techniques, these existing\nmethods fundamentally cannot solve the catastrophic forgetting problem. In TSC\nscenarios with continuously arriving data and temporally shifting\ndistributions, these methods become even less practical. In this paper, we\npropose a Time Series Analytic Continual Learning framework, called TS-ACL.\nInspired by analytical learning, TS-ACL transforms neural network updates into\ngradient-free linear regression problems, thereby fundamentally mitigating\ncatastrophic forgetting. Specifically, employing a pre-trained and frozen\nfeature extraction encoder, TS-ACL only needs to update its analytic classifier\nrecursively in a lightweight manner that is highly suitable for real-time\napplications and large-scale data processing. Additionally, we theoretically\ndemonstrate that the model obtained recursively through the TS-ACL is exactly\nequivalent to a model trained on the complete dataset in a centralized manner,\nthereby establishing the property of absolute knowledge memory. Extensive\nexperiments validate the superior performance of our TS-ACL.\n","authors":["Kejia Fan","Jiaxu Li","Songning Lai","Linpu Lv","Anfeng Liu","Jianheng Tang","Houbing Herbert Song","Huiping Zhuang"],"pdf_url":"https://arxiv.org/pdf/2410.15954v1.pdf","comment":"11 pages, 3 figures, 2 tables"},{"id":"http://arxiv.org/abs/2410.15952v1","updated":"2024-10-21T12:32:39Z","published":"2024-10-21T12:32:39Z","title":"User-centric evaluation of explainability of AI with and for humans: a\n  comprehensive empirical study","summary":"  This study is located in the Human-Centered Artificial Intelligence (HCAI)\nand focuses on the results of a user-centered assessment of commonly used\neXplainable Artificial Intelligence (XAI) algorithms, specifically\ninvestigating how humans understand and interact with the explanations provided\nby these algorithms. To achieve this, we employed a multi-disciplinary approach\nthat included state-of-the-art research methods from social sciences to measure\nthe comprehensibility of explanations generated by a state-of-the-art lachine\nlearning model, specifically the Gradient Boosting Classifier (XGBClassifier).\nWe conducted an extensive empirical user study involving interviews with 39\nparticipants from three different groups, each with varying expertise in data\nscience, data visualization, and domain-specific knowledge related to the\ndataset used for training the machine learning model. Participants were asked a\nseries of questions to assess their understanding of the model's explanations.\nTo ensure replicability, we built the model using a publicly available dataset\nfrom the UC Irvine Machine Learning Repository, focusing on edible and\nnon-edible mushrooms. Our findings reveal limitations in existing XAI methods\nand confirm the need for new design principles and evaluation techniques that\naddress the specific information needs and user perspectives of different\nclasses of AI stakeholders. We believe that the results of our research and the\ncross-disciplinary methodology we developed can be successfully adapted to\nvarious data types and user profiles, thus promoting dialogue and address\nopportunities in HCAI research. To support this, we are making the data\nresulting from our study publicly available.\n","authors":["Szymon Bobek","Paloma Korycińska","Monika Krakowska","Maciej Mozolewski","Dorota Rak","Magdalena Zych","Magdalena Wójcik","Grzegorz J. Nalepa"],"pdf_url":"https://arxiv.org/pdf/2410.15952v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.15927v1","updated":"2024-10-21T11:55:06Z","published":"2024-10-21T11:55:06Z","title":"GReFEL: Geometry-Aware Reliable Facial Expression Learning under Bias\n  and Imbalanced Data Distribution","summary":"  Reliable facial expression learning (FEL) involves the effective learning of\ndistinctive facial expression characteristics for more reliable, unbiased and\naccurate predictions in real-life settings. However, current systems struggle\nwith FEL tasks because of the variance in people's facial expressions due to\ntheir unique facial structures, movements, tones, and demographics. Biased and\nimbalanced datasets compound this challenge, leading to wrong and biased\nprediction labels. To tackle these, we introduce GReFEL, leveraging Vision\nTransformers and a facial geometry-aware anchor-based reliability balancing\nmodule to combat imbalanced data distributions, bias, and uncertainty in facial\nexpression learning. Integrating local and global data with anchors that learn\ndifferent facial data points and structural features, our approach adjusts\nbiased and mislabeled emotions caused by intra-class disparity, inter-class\nsimilarity, and scale sensitivity, resulting in comprehensive, accurate, and\nreliable facial expression predictions. Our model outperforms current\nstate-of-the-art methodologies, as demonstrated by extensive experiments on\nvarious datasets.\n","authors":["Azmine Toushik Wasi","Taki Hasan Rafi","Raima Islam","Karlo Serbetar","Dong Kyu Chae"],"pdf_url":"https://arxiv.org/pdf/2410.15927v1.pdf","comment":"ACCV 2024. Extended version of ARBEx (arXiv:2305.01486)"},{"id":"http://arxiv.org/abs/2405.14468v2","updated":"2024-10-21T11:54:16Z","published":"2024-05-23T11:55:49Z","title":"Neural Collapse versus Low-rank Bias: Is Deep Neural Collapse Really\n  Optimal?","summary":"  Deep neural networks (DNNs) exhibit a surprising structure in their final\nlayer known as neural collapse (NC), and a growing body of works has currently\ninvestigated the propagation of neural collapse to earlier layers of DNNs -- a\nphenomenon called deep neural collapse (DNC). However, existing theoretical\nresults are restricted to special cases: linear models, only two layers or\nbinary classification. In contrast, we focus on non-linear models of arbitrary\ndepth in multi-class classification and reveal a surprising qualitative shift.\nAs soon as we go beyond two layers or two classes, DNC stops being optimal for\nthe deep unconstrained features model (DUFM) -- the standard theoretical\nframework for the analysis of collapse. The main culprit is a low-rank bias of\nmulti-layer regularization schemes: this bias leads to optimal solutions of\neven lower rank than the neural collapse. We support our theoretical findings\nwith experiments on both DUFM and real data, which show the emergence of the\nlow-rank structure in the solution found by gradient descent.\n","authors":["Peter Súkeník","Marco Mondelli","Christoph Lampert"],"pdf_url":"https://arxiv.org/pdf/2405.14468v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.15923v1","updated":"2024-10-21T11:53:49Z","published":"2024-10-21T11:53:49Z","title":"Automatic Differentiation of Optimization Algorithms with Time-Varying\n  Updates","summary":"  Numerous Optimization Algorithms have a time-varying update rule thanks to,\nfor instance, a changing step size, momentum parameter or, Hessian\napproximation. In this paper, we apply unrolled or automatic differentiation to\na time-varying iterative process and provide convergence (rate) guarantees for\nthe resulting derivative iterates. We adapt these convergence results and apply\nthem to proximal gradient descent with variable step size and FISTA when\nsolving partly smooth problems. We confirm our findings numerically by solving\n$\\ell_1$ and $\\ell_2$-regularized linear and logisitc regression respectively.\nOur theoretical and numerical results show that the convergence rate of the\nalgorithm is reflected in its derivative iterates.\n","authors":["Sheheryar Mehmood","Peter Ochs"],"pdf_url":"https://arxiv.org/pdf/2410.15923v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2402.08958v2","updated":"2024-10-21T11:49:53Z","published":"2024-02-14T05:58:43Z","title":"Towards Next-Level Post-Training Quantization of Hyper-Scale\n  Transformers","summary":"  With the increasing complexity of generative AI models, post-training\nquantization (PTQ) has emerged as a promising solution for deploying\nhyper-scale models on edge devices such as mobile and TVs. Existing PTQ\nschemes, however, consume considerable time and resources, which could be a\nbottleneck in real situations where frequent model updates and multiple\nhyperparameter tunings are required. As a cost-effective alternative,\nlearning-free PTQ schemes have been proposed. However, the performance is\nsomewhat limited because they cannot consider the inter-layer dependency within\nthe attention module, which is a significant feature of Transformers. In this\npaper, we thus propose a novel PTQ algorithm that balances accuracy and\nefficiency. The key idea of the proposed algorithm called aespa is to perform\nquantization layer-wise for efficiency while targeting attention-wise\nreconstruction to consider the cross-layer dependency. Through extensive\nexperiments on various language models and complexity analysis, we demonstrate\nthat aespa is accurate and efficient in quantizing Transformer models.\n","authors":["Junhan Kim","Chungman Lee","Eulrang Cho","Kyungphil Park","Ho-young Kim","Joonyoung Kim","Yongkweon Jeon"],"pdf_url":"https://arxiv.org/pdf/2402.08958v2.pdf","comment":"Accepted to NeurIPS 2024"},{"id":"http://arxiv.org/abs/2310.07446v5","updated":"2024-10-21T11:45:04Z","published":"2023-10-11T12:48:45Z","title":"ProbTS: Benchmarking Point and Distributional Forecasting across Diverse\n  Prediction Horizons","summary":"  Delivering precise point and distributional forecasts across a spectrum of\nprediction horizons represents a significant and enduring challenge in the\napplication of time-series forecasting within various industries. Prior\nresearch on developing deep learning models for time-series forecasting has\noften concentrated on isolated aspects, such as long-term point forecasting or\nshort-term probabilistic estimations. This narrow focus may result in skewed\nmethodological choices and hinder the adaptability of these models to uncharted\nscenarios. While there is a rising trend in developing universal forecasting\nmodels, a thorough understanding of their advantages and drawbacks, especially\nregarding essential forecasting needs like point and distributional forecasts\nacross short and long horizons, is still lacking. In this paper, we present\nProbTS, a benchmark tool designed as a unified platform to evaluate these\nfundamental forecasting needs and to conduct a rigorous comparative analysis of\nnumerous cutting-edge studies from recent years. We dissect the distinctive\ndata characteristics arising from disparate forecasting requirements and\nelucidate how these characteristics can skew methodological preferences in\ntypical research trajectories, which often fail to fully accommodate essential\nforecasting needs. Building on this, we examine the latest models for universal\ntime-series forecasting and discover that our analyses of methodological\nstrengths and weaknesses are also applicable to these universal models.\nFinally, we outline the limitations inherent in current research and underscore\nseveral avenues for future exploration.\n","authors":["Jiawen Zhang","Xumeng Wen","Zhenwei Zhang","Shun Zheng","Jia Li","Jiang Bian"],"pdf_url":"https://arxiv.org/pdf/2310.07446v5.pdf","comment":"NeurIPS 2024 Datasets and Benchmarks Track"},{"id":"http://arxiv.org/abs/2410.15910v1","updated":"2024-10-21T11:33:14Z","published":"2024-10-21T11:33:14Z","title":"Diverse Policies Recovering via Pointwise Mutual Information Weighted\n  Imitation Learning","summary":"  Recovering a spectrum of diverse policies from a set of expert trajectories\nis an important research topic in imitation learning. After determining a\nlatent style for a trajectory, previous diverse policies recovering methods\nusually employ a vanilla behavioral cloning learning objective conditioned on\nthe latent style, treating each state-action pair in the trajectory with equal\nimportance. Based on an observation that in many scenarios, behavioral styles\nare often highly relevant with only a subset of state-action pairs, this paper\npresents a new principled method in diverse polices recovery. In particular,\nafter inferring or assigning a latent style for a trajectory, we enhance the\nvanilla behavioral cloning by incorporating a weighting mechanism based on\npointwise mutual information. This additional weighting reflects the\nsignificance of each state-action pair's contribution to learning the style,\nthus allowing our method to focus on state-action pairs most representative of\nthat style. We provide theoretical justifications for our new objective, and\nextensive empirical evaluations confirm the effectiveness of our method in\nrecovering diverse policies from expert data.\n","authors":["Hanlin Yang","Jian Yao","Weiming Liu","Qing Wang","Hanmin Qin","Hansheng Kong","Kirk Tang","Jiechao Xiong","Chao Yu","Kai Li","Junliang Xing","Hongwu Chen","Juchao Zhuo","Qiang Fu","Yang Wei","Haobo Fu"],"pdf_url":"https://arxiv.org/pdf/2410.15910v1.pdf","comment":"18 pages, 6 figures"},{"id":"http://arxiv.org/abs/2208.03107v2","updated":"2024-10-21T11:28:18Z","published":"2022-08-05T11:27:55Z","title":"Fixed-Point Automatic Differentiation of Forward--Backward Splitting\n  Algorithms for Partly Smooth Functions","summary":"  A large class of non-smooth practical optimization problems can be written as\nminimization of a sum of smooth and partly smooth functions. We examine such\nstructured problems which also depend on a parameter vector and study the\nproblem of differentiating its solution mapping with respect to the parameter\nwhich has far reaching applications in sensitivity analysis and parameter\nlearning problems. Under partial smoothness and other mild assumptions, we\napply Implicit (ID) and Automatic Differentiation (AD) to the fixed-point\niterations of proximal splitting algorithms. We show that AD of the sequence\ngenerated by these algorithms converges (linearly under further assumptions) to\nthe derivative of the solution mapping. For a variant of automatic\ndifferentiation, which we call Fixed-Point Automatic Differentiation (FPAD), we\nremedy the memory overhead problem of the Reverse Mode AD and moreover provide\nfaster convergence theoretically. We numerically illustrate the convergence and\nconvergence rates of AD and FPAD on Lasso and Group Lasso problems and\ndemonstrate the working of FPAD on prototypical image denoising problems by\nlearning the regularization term.\n","authors":["Sheheryar Mehmood","Peter Ochs"],"pdf_url":"https://arxiv.org/pdf/2208.03107v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2405.02063v5","updated":"2024-10-21T11:26:32Z","published":"2024-05-03T12:48:21Z","title":"Few-sample Variational Inference of Bayesian Neural Networks with\n  Arbitrary Nonlinearities","summary":"  Bayesian Neural Networks (BNNs) extend traditional neural networks to provide\nuncertainties associated with their outputs. On the forward pass through a BNN,\npredictions (and their uncertainties) are made either by Monte Carlo sampling\nnetwork weights from the learned posterior or by analytically propagating\nstatistical moments through the network. Though flexible, Monte Carlo sampling\nis computationally expensive and can be infeasible or impractical under\nresource constraints or for large networks. While moment propagation can\nameliorate the computational costs of BNN inference, it can be difficult or\nimpossible for networks with arbitrary nonlinearities, thereby restricting the\npossible set of network layers permitted with such a scheme. In this work, we\ndemonstrate a simple yet effective approach for propagating statistical moments\nthrough arbitrary nonlinearities with only 3 deterministic samples, enabling\nfew-sample variational inference of BNNs without restricting the set of network\nlayers used. Furthermore, we leverage this approach to demonstrate a novel\nnonlinear activation function that we use to inject physics-informed prior\ninformation into output nodes of a BNN.\n","authors":["David J. Schodt"],"pdf_url":"https://arxiv.org/pdf/2405.02063v5.pdf","comment":"Comment 1: Fixed plot markers in figure 6 to match legend and to\n  improve grayscale appearance Comment 2: Fixed mistyped value for optimizer\n  learning rate"},{"id":"http://arxiv.org/abs/2410.15899v1","updated":"2024-10-21T11:23:23Z","published":"2024-10-21T11:23:23Z","title":"On the Design and Performance of Machine Learning Based Error Correcting\n  Decoders","summary":"  This paper analyzes the design and competitiveness of four neural network\n(NN) architectures recently proposed as decoders for forward error correction\n(FEC) codes. We first consider the so-called single-label neural network (SLNN)\nand the multi-label neural network (MLNN) decoders which have been reported to\nachieve near maximum likelihood (ML) performance. Here, we show analytically\nthat SLNN and MLNN decoders can always achieve ML performance, regardless of\nthe code dimensions -- although at the cost of computational complexity -- and\nno training is in fact required. We then turn our attention to two\ntransformer-based decoders: the error correction code transformer (ECCT) and\nthe cross-attention message passing transformer (CrossMPT). We compare their\nperformance against traditional decoders, and show that ordered statistics\ndecoding outperforms these transformer-based decoders. The results in this\npaper cast serious doubts on the application of NN-based FEC decoders in the\nshort and medium block length regime.\n","authors":["Yuncheng Yuan","Péter Scheepers","Lydia Tasiou","Yunus Can Gültekin","Federico Corradi","Alex Alvarado"],"pdf_url":"https://arxiv.org/pdf/2410.15899v1.pdf","comment":"6 pages, 4 figures, submitted for possible presentation in a\n  conference"},{"id":"http://arxiv.org/abs/2310.04539v3","updated":"2024-10-21T11:12:02Z","published":"2023-10-06T19:06:13Z","title":"Generating Less Certain Adversarial Examples Improves Robust\n  Generalization","summary":"  This paper revisits the robust overfitting phenomenon of adversarial\ntraining. Observing that models with better robust generalization performance\nare less certain in predicting adversarially generated training inputs, we\nargue that overconfidence in predicting adversarial examples is a potential\ncause. Therefore, we hypothesize that generating less certain adversarial\nexamples improves robust generalization, and propose a formal definition of\nadversarial certainty that captures the variance of the model's predicted\nlogits on adversarial examples. Our theoretical analysis of synthetic\ndistributions characterizes the connection between adversarial certainty and\nrobust generalization. Accordingly, built upon the notion of adversarial\ncertainty, we develop a general method to search for models that can generate\ntraining-time adversarial inputs with reduced certainty, while maintaining the\nmodel's capability in distinguishing adversarial examples. Extensive\nexperiments on image benchmarks demonstrate that our method effectively learns\nmodels with consistently improved robustness and mitigates robust overfitting,\nconfirming the importance of generating less certain adversarial examples for\nrobust generalization.\n","authors":["Minxing Zhang","Michael Backes","Xiao Zhang"],"pdf_url":"https://arxiv.org/pdf/2310.04539v3.pdf","comment":"Published in Transactions of Machine Learning Research (TMLR)"},{"id":"http://arxiv.org/abs/2408.13296v2","updated":"2024-10-21T11:10:00Z","published":"2024-08-23T14:48:02Z","title":"The Ultimate Guide to Fine-Tuning LLMs from Basics to Breakthroughs: An\n  Exhaustive Review of Technologies, Research, Best Practices, Applied Research\n  Challenges and Opportunities","summary":"  This report examines the fine-tuning of Large Language Models (LLMs),\nintegrating theoretical insights with practical applications. It outlines the\nhistorical evolution of LLMs from traditional Natural Language Processing (NLP)\nmodels to their pivotal role in AI. A comparison of fine-tuning methodologies,\nincluding supervised, unsupervised, and instruction-based approaches,\nhighlights their applicability to different tasks. The report introduces a\nstructured seven-stage pipeline for fine-tuning LLMs, spanning data\npreparation, model initialization, hyperparameter tuning, and model deployment.\nEmphasis is placed on managing imbalanced datasets and optimization techniques.\nParameter-efficient methods like Low-Rank Adaptation (LoRA) and Half\nFine-Tuning are explored for balancing computational efficiency with\nperformance. Advanced techniques such as memory fine-tuning, Mixture of Experts\n(MoE), and Mixture of Agents (MoA) are discussed for leveraging specialized\nnetworks and multi-agent collaboration. The report also examines novel\napproaches like Proximal Policy Optimization (PPO) and Direct Preference\nOptimization (DPO), which align LLMs with human preferences, alongside pruning\nand routing optimizations to improve efficiency. Further sections cover\nvalidation frameworks, post-deployment monitoring, and inference optimization,\nwith attention to deploying LLMs on distributed and cloud-based platforms.\nEmerging areas such as multimodal LLMs, fine-tuning for audio and speech, and\nchallenges related to scalability, privacy, and accountability are also\naddressed. This report offers actionable insights for researchers and\npractitioners navigating LLM fine-tuning in an evolving landscape.\n","authors":["Venkatesh Balavadhani Parthasarathy","Ahtsham Zafar","Aafaq Khan","Arsalan Shahid"],"pdf_url":"https://arxiv.org/pdf/2408.13296v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.15889v1","updated":"2024-10-21T11:06:56Z","published":"2024-10-21T11:06:56Z","title":"Model Mimic Attack: Knowledge Distillation for Provably Transferable\n  Adversarial Examples","summary":"  The vulnerability of artificial neural networks to adversarial perturbations\nin the black-box setting is widely studied in the literature. The majority of\nattack methods to construct these perturbations suffer from an impractically\nlarge number of queries required to find an adversarial example. In this work,\nwe focus on knowledge distillation as an approach to conduct transfer-based\nblack-box adversarial attacks and propose an iterative training of the\nsurrogate model on an expanding dataset. This work is the first, to our\nknowledge, to provide provable guarantees on the success of knowledge\ndistillation-based attack on classification neural networks: we prove that if\nthe student model has enough learning capabilities, the attack on the teacher\nmodel is guaranteed to be found within the finite number of distillation\niterations.\n","authors":["Kirill Lukyanov","Andrew Perminov","Denis Turdakov","Mikhail Pautov"],"pdf_url":"https://arxiv.org/pdf/2410.15889v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.15884v1","updated":"2024-10-21T11:02:18Z","published":"2024-10-21T11:02:18Z","title":"Using GPT Models for Qualitative and Quantitative News Analytics in the\n  2024 US Presidental Election Process","summary":"  The paper considers an approach of using Google Search API and GPT-4o model\nfor qualitative and quantitative analyses of news through retrieval-augmented\ngeneration (RAG). This approach was applied to analyze news about the 2024 US\npresidential election process. Different news sources for different time\nperiods have been analyzed. Quantitative scores generated by GPT model have\nbeen analyzed using Bayesian regression to derive trend lines. The\ndistributions found for the regression parameters allow for the analysis of\nuncertainty in the election process. The obtained results demonstrate that\nusing the GPT models for news analysis, one can get informative analytics and\nprovide key insights that can be applied in further analyses of election\nprocesses.\n","authors":["Bohdan M. Pavlyshenko"],"pdf_url":"https://arxiv.org/pdf/2410.15884v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.15882v1","updated":"2024-10-21T11:01:44Z","published":"2024-10-21T11:01:44Z","title":"Distributed Learning for UAV Swarms","summary":"  Unmanned Aerial Vehicle (UAV) swarms are increasingly deployed in dynamic,\ndata-rich environments for applications such as environmental monitoring and\nsurveillance. These scenarios demand efficient data processing while\nmaintaining privacy and security, making Federated Learning (FL) a promising\nsolution. FL allows UAVs to collaboratively train global models without sharing\nraw data, but challenges arise due to the non-Independent and Identically\nDistributed (non-IID) nature of the data collected by UAVs. In this study, we\nshow an integration of the state-of-the-art FL methods to UAV Swarm application\nand invetigate the performance of multiple aggregation methods (namely FedAvg,\nFedProx, FedOpt, and MOON) with a particular focus on tackling non-IID on a\nvariety of datasets, specifically MNIST for baseline performance, CIFAR10 for\nnatural object classification, EuroSAT for environment monitoring, and CelebA\nfor surveillance. These algorithms were selected to cover improved techniques\non both client-side updates and global aggregation. Results show that while all\nalgorithms perform comparably on IID data, their performance deteriorates\nsignificantly under non-IID conditions. FedProx demonstrated the most stable\noverall performance, emphasising the importance of regularising local updates\nin non-IID environments to mitigate drastic deviations in local models.\n","authors":["Chen Hu","Hanchi Ren","Jingjing Deng","Xianghua Xie"],"pdf_url":"https://arxiv.org/pdf/2410.15882v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.15876v1","updated":"2024-10-21T10:57:45Z","published":"2024-10-21T10:57:45Z","title":"FlickerFusion: Intra-trajectory Domain Generalizing Multi-Agent RL","summary":"  Multi-agent reinforcement learning has demonstrated significant potential in\naddressing complex cooperative tasks across various real-world applications.\nHowever, existing MARL approaches often rely on the restrictive assumption that\nthe number of entities (e.g., agents, obstacles) remains constant between\ntraining and inference. This overlooks scenarios where entities are dynamically\nremoved or added during the inference trajectory -- a common occurrence in\nreal-world environments like search and rescue missions and dynamic combat\nsituations. In this paper, we tackle the challenge of intra-trajectory dynamic\nentity composition under zero-shot out-of-domain (OOD) generalization, where\nsuch dynamic changes cannot be anticipated beforehand. Our empirical studies\nreveal that existing MARL methods suffer significant performance degradation\nand increased uncertainty in these scenarios. In response, we propose\nFlickerFusion, a novel OOD generalization method that acts as a universally\napplicable augmentation technique for MARL backbone methods. Our results show\nthat FlickerFusion not only achieves superior inference rewards but also\nuniquely reduces uncertainty vis-\\`a-vis the backbone, compared to existing\nmethods. For standardized evaluation, we introduce MPEv2, an enhanced version\nof Multi Particle Environments (MPE), consisting of 12 benchmarks. Benchmarks,\nimplementations, and trained models are organized and open-sourced at\nflickerfusion305.github.io, accompanied by ample demo video renderings.\n","authors":["Woosung Koh","Wonbeen Oh","Siyeol Kim","Suhin Shin","Hyeongjin Kim","Jaein Jang","Junghyun Lee","Se-Young Yun"],"pdf_url":"https://arxiv.org/pdf/2410.15876v1.pdf","comment":"NeurIPS '24 Open-World Agents Workshop"},{"id":"http://arxiv.org/abs/2410.15875v1","updated":"2024-10-21T10:57:25Z","published":"2024-10-21T10:57:25Z","title":"Enabling Asymmetric Knowledge Transfer in Multi-Task Learning with\n  Self-Auxiliaries","summary":"  Knowledge transfer in multi-task learning is typically viewed as a dichotomy;\npositive transfer, which improves the performance of all tasks, or negative\ntransfer, which hinders the performance of all tasks. In this paper, we\ninvestigate the understudied problem of asymmetric task relationships, where\nknowledge transfer aids the learning of certain tasks while hindering the\nlearning of others. We propose an optimisation strategy that includes\nadditional cloned tasks named self-auxiliaries into the learning process to\nflexibly transfer knowledge between tasks asymmetrically. Our method can\nexploit asymmetric task relationships, benefiting from the positive transfer\ncomponent while avoiding the negative transfer component. We demonstrate that\nasymmetric knowledge transfer provides substantial improvements in performance\ncompared to existing multi-task optimisation strategies on benchmark computer\nvision problems.\n","authors":["Olivier Graffeuille","Yun Sing Koh","Joerg Wicker","Moritz Lehmann"],"pdf_url":"https://arxiv.org/pdf/2410.15875v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.04133v2","updated":"2024-10-21T10:56:37Z","published":"2024-10-05T12:12:02Z","title":"An Electrocardiogram Foundation Model Built on over 10 Million\n  Recordings with External Evaluation across Multiple Domains","summary":"  Artificial intelligence (AI) has demonstrated significant potential in ECG\nanalysis and cardiovascular disease assessment. Recently, foundation models\nhave played a remarkable role in advancing medical AI. The development of an\nECG foundation model holds the promise of elevating AI-ECG research to new\nheights. However, building such a model faces several challenges, including\ninsufficient database sample sizes and inadequate generalization across\nmultiple domains. Additionally, there is a notable performance gap between\nsingle-lead and multi-lead ECG analyses. We introduced an ECG Foundation Model\n(ECGFounder), a general-purpose model that leverages real-world ECG annotations\nfrom cardiology experts to broaden the diagnostic capabilities of ECG analysis.\nECGFounder was trained on over 10 million ECGs with 150 label categories from\nthe Harvard-Emory ECG Database, enabling comprehensive cardiovascular disease\ndiagnosis through ECG analysis. The model is designed to be both an effective\nout-of-the-box solution, and a to be fine-tunable for downstream tasks,\nmaximizing usability. Importantly, we extended its application to lower rank\nECGs, and arbitrary single-lead ECGs in particular. ECGFounder is applicable to\nsupporting various downstream tasks in mobile monitoring scenarios.\nExperimental results demonstrate that ECGFounder achieves expert-level\nperformance on internal validation sets, with AUROC exceeding 0.95 for eighty\ndiagnoses. It also shows strong classification performance and generalization\nacross various diagnoses on external validation sets. When fine-tuned,\nECGFounder outperforms baseline models in demographic analysis, clinical event\ndetection, and cross-modality cardiac rhythm diagnosis. The trained model and\ndata will be publicly released upon publication through the bdsp.io. Our code\nis available at https://github.com/bdsp-core/ECGFounder\n","authors":["Jun Li","Aaron Aguirre","Junior Moura","Che Liu","Lanhai Zhong","Chenxi Sun","Gari Clifford","Brandon Westover","Shenda Hong"],"pdf_url":"https://arxiv.org/pdf/2410.04133v2.pdf","comment":"working in progress"},{"id":"http://arxiv.org/abs/2404.07989v3","updated":"2024-10-21T10:54:55Z","published":"2024-04-11T17:59:45Z","title":"Any2Point: Empowering Any-modality Large Models for Efficient 3D\n  Understanding","summary":"  Large foundation models have recently emerged as a prominent focus of\ninterest, attaining superior performance in widespread scenarios. Due to the\nscarcity of 3D data, many efforts have been made to adapt pre-trained\ntransformers from vision to 3D domains. However, such 2D-to-3D approaches are\nstill limited, due to the potential loss of spatial geometries and high\ncomputation cost. More importantly, their frameworks are mainly designed for 2D\nmodels, lacking a general any-to-3D paradigm. In this paper, we introduce\nAny2Point, a parameter-efficient method to empower any-modality large models\n(vision, language, audio) for 3D understanding. Given a frozen transformer from\nany source modality, we propose a 3D-to-any (1D or 2D) virtual projection\nstrategy that correlates the input 3D points to the original 1D or 2D positions\nwithin the source modality. This mechanism enables us to assign each 3D token\nwith a positional encoding paired with the pre-trained model, which avoids 3D\ngeometry loss caused by the true projection and better motivates the\ntransformer for 3D learning with 1D/2D positional priors. Then, within each\ntransformer block, we insert an any-to-3D guided adapter module for\nparameter-efficient fine-tuning. The adapter incorporates prior spatial\nknowledge from the source modality to guide the local feature aggregation of 3D\ntokens, compelling the semantic adaption of any-modality transformers. We\nconduct extensive experiments to showcase the effectiveness and efficiency of\nour method. Code and models are released at\nhttps://github.com/Ivan-Tang-3D/Any2Point.\n","authors":["Yiwen Tang","Ray Zhang","Jiaming Liu","Zoey Guo","Dong Wang","Zhigang Wang","Bin Zhao","Shanghang Zhang","Peng Gao","Hongsheng Li","Xuelong Li"],"pdf_url":"https://arxiv.org/pdf/2404.07989v3.pdf","comment":"Code and models are released at\n  https://github.com/Ivan-Tang-3D/Any2Point"},{"id":"http://arxiv.org/abs/2310.03059v8","updated":"2024-10-21T10:49:59Z","published":"2023-10-04T16:49:36Z","title":"Point-PEFT: Parameter-Efficient Fine-Tuning for 3D Pre-trained Models","summary":"  The popularity of pre-trained large models has revolutionized downstream\ntasks across diverse fields, such as language, vision, and multi-modality. To\nminimize the adaption cost for downstream tasks, many Parameter-Efficient\nFine-Tuning (PEFT) techniques are proposed for language and 2D image\npre-trained models. However, the specialized PEFT method for 3D pre-trained\nmodels is still under-explored. To this end, we introduce Point-PEFT, a novel\nframework for adapting point cloud pre-trained models with minimal learnable\nparameters. Specifically, for a pre-trained 3D model, we freeze most of its\nparameters, and only tune the newly added PEFT modules on downstream tasks,\nwhich consist of a Point-prior Prompt and a Geometry-aware Adapter. The\nPoint-prior Prompt adopts a set of learnable prompt tokens, for which we\npropose to construct a memory bank with domain-specific knowledge, and utilize\na parameter-free attention to enhance the prompt tokens. The Geometry-aware\nAdapter aims to aggregate point cloud features within spatial neighborhoods to\ncapture fine-grained geometric information through local interactions.\nExtensive experiments indicate that our Point-PEFT can achieve better\nperformance than the full fine-tuning on various downstream tasks, while using\nonly 5% of the trainable parameters, demonstrating the efficiency and\neffectiveness of our approach. Code is released at\nhttps://github.com/Ivan-Tang-3D/Point-PEFT.\n","authors":["Yiwen Tang","Ray Zhang","Zoey Guo","Dong Wang","Zhigang Wang","Bin Zhao","Xuelong Li"],"pdf_url":"https://arxiv.org/pdf/2310.03059v8.pdf","comment":"The specialized PEFT framework for 3D pre-trained models, which\n  achieves competitive performance to full fine-tuning, and significantly\n  reduces the computational resources. Project page:\n  https://github.com/Ivan-Tang-3D/Point-PEFT"},{"id":"http://arxiv.org/abs/2410.15859v1","updated":"2024-10-21T10:39:05Z","published":"2024-10-21T10:39:05Z","title":"Mesa-Extrapolation: A Weave Position Encoding Method for Enhanced\n  Extrapolation in LLMs","summary":"  Large language models (LLMs), although having revolutionized many fields,\nstill suffer from the challenging extrapolation problem, where the inference\nability of LLMs sharply declines beyond their max training lengths. In this\nwork, we conduct a theoretical analysis to better understand why No Position\nEncoding (NoPE) fails outside its effective range, as well as examining the\npower of Position Encoding (PE) in this context. Our findings reveal that with\nmeticulous weave position, PE can indeed be extended beyond effective range.\nOur theorems establish that LLMs equipped with weave PE can achieve improved\nextrapolation performance without additional cost. Furthermore, we introduce a\nnovel weave PE method, Mesa-Extrapolation, which utilizes a chunk-based\ntriangular attention matrix and applies Stair PE to manage the final chunk.\nThis method not only retains competitive performance but also offers\nsubstantial benefits such as significantly reduced memory demand and faster\ninference speed. Extensive experiments validate the effectiveness of\nMesa-Extrapolation, demonstrating its potential as a scalable solution to\nenhancing LLMs applicative reach.\n","authors":["Xin Ma","Yang Liu","Jingjing Liu","Xiaoxu Ma"],"pdf_url":"https://arxiv.org/pdf/2410.15859v1.pdf","comment":"accepted by NeurIPS 2024. arXiv admin note: text overlap with\n  arXiv:2305.19466 by other authors"},{"id":"http://arxiv.org/abs/2410.15858v1","updated":"2024-10-21T10:37:17Z","published":"2024-10-21T10:37:17Z","title":"Towards Optimal Adapter Placement for Efficient Transfer Learning","summary":"  Parameter-efficient transfer learning (PETL) aims to adapt pre-trained models\nto new downstream tasks while minimizing the number of fine-tuned parameters.\nAdapters, a popular approach in PETL, inject additional capacity into existing\nnetworks by incorporating low-rank projections, achieving performance\ncomparable to full fine-tuning with significantly fewer parameters. This paper\ninvestigates the relationship between the placement of an adapter and its\nperformance. We observe that adapter location within a network significantly\nimpacts its effectiveness, and that the optimal placement is task-dependent. To\nexploit this observation, we introduce an extended search space of adapter\nconnections, including long-range and recurrent adapters. We demonstrate that\neven randomly selected adapter placements from this expanded space yield\nimproved results, and that high-performing placements often correlate with high\ngradient rank. Our findings reveal that a small number of strategically placed\nadapters can match or exceed the performance of the common baseline of adding\nadapters in every block, opening a new avenue for research into optimal adapter\nplacement strategies.\n","authors":["Aleksandra I. Nowak","Otniel-Bogdan Mercea","Anurag Arnab","Jonas Pfeiffer","Yann Dauphin","Utku Evci"],"pdf_url":"https://arxiv.org/pdf/2410.15858v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.15854v1","updated":"2024-10-21T10:30:24Z","published":"2024-10-21T10:30:24Z","title":"TEXEL: A neuromorphic processor with on-chip learning for beyond-CMOS\n  device integration","summary":"  Recent advances in memory technologies, devices and materials have shown\ngreat potential for integration into neuromorphic electronic systems. However,\na significant gap remains between the development of these materials and the\nrealization of large-scale, fully functional systems. One key challenge is\ndetermining which devices and materials are best suited for specific functions\nand how they can be paired with CMOS circuitry. To address this, we introduce\nTEXEL, a mixed-signal neuromorphic architecture designed to explore the\nintegration of on-chip learning circuits and novel two- and three-terminal\ndevices. TEXEL serves as an accessible platform to bridge the gap between\nCMOS-based neuromorphic computation and the latest advancements in emerging\ndevices. In this paper, we demonstrate the readiness of TEXEL for device\nintegration through comprehensive chip measurements and simulations. TEXEL\nprovides a practical system for testing bio-inspired learning algorithms\nalongside emerging devices, establishing a tangible link between brain-inspired\ncomputation and cutting-edge device research.\n","authors":["Hugh Greatorex","Ole Richter","Michele Mastella","Madison Cotteret","Philipp Klein","Maxime Fabre","Arianna Rubino","Willian Soares Girão","Junren Chen","Martin Ziegler","Laura Bégon-Lours","Giacomo Indiveri","Elisabetta Chicca"],"pdf_url":"https://arxiv.org/pdf/2410.15854v1.pdf","comment":"17 pages, 7 figures. Supplementary material: 8 pages, 4 figures"},{"id":"http://arxiv.org/abs/2304.03552v2","updated":"2024-10-21T10:29:32Z","published":"2023-04-07T09:22:28Z","title":"A physics-informed neural network framework for modeling\n  obstacle-related equations","summary":"  Deep learning has been highly successful in some applications. Nevertheless,\nits use for solving partial differential equations (PDEs) has only been of\nrecent interest with current state-of-the-art machine learning libraries, e.g.,\nTensorFlow or PyTorch. Physics-informed neural networks (PINNs) are an\nattractive tool for solving partial differential equations based on sparse and\nnoisy data. Here extend PINNs to solve obstacle-related PDEs which present a\ngreat computational challenge because they necessitate numerical methods that\ncan yield an accurate approximation of the solution that lies above a given\nobstacle. The performance of the proposed PINNs is demonstrated in multiple\nscenarios for linear and nonlinear PDEs subject to regular and irregular\nobstacles.\n","authors":["Hamid El Bahja","Jan Christian Hauffen","Peter Jung","Bubacarr Bah","Issa Karambal"],"pdf_url":"https://arxiv.org/pdf/2304.03552v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.15851v1","updated":"2024-10-21T10:27:57Z","published":"2024-10-21T10:27:57Z","title":"R2I-rPPG: A Robust Region of Interest Selection Method for Remote\n  Photoplethysmography to Extract Heart Rate","summary":"  The COVID-19 pandemic has underscored the need for low-cost, scalable\napproaches to measuring contactless vital signs, either during initial triage\nat a healthcare facility or virtual telemedicine visits. Remote\nphotoplethysmography (rPPG) can accurately estimate heart rate (HR) when\napplied to close-up videos of healthy volunteers in well-lit laboratory\nsettings. However, results from such highly optimized laboratory studies may\nnot be readily translated to healthcare settings. One significant barrier to\nthe practical application of rPPG in health care is the accurate localization\nof the region of interest (ROI). Clinical or telemedicine visits may involve\nsub-optimal lighting, movement artifacts, variable camera angle, and subject\ndistance. This paper presents an rPPG ROI selection method based on 3D facial\nlandmarks and patient head yaw angle. We then demonstrate the robustness of\nthis ROI selection method when coupled to the Plane-Orthogonal-to-Skin (POS)\nrPPG method when applied to videos of patients presenting to an Emergency\nDepartment for respiratory complaints. Our results demonstrate the\neffectiveness of our proposed approach in improving the accuracy and robustness\nof rPPG in a challenging clinical environment.\n","authors":["Sandeep Nagar","Mark Hasegawa-Johnson","David G. Beiser","Narendra Ahuja"],"pdf_url":"https://arxiv.org/pdf/2410.15851v1.pdf","comment":"preprint"},{"id":"http://arxiv.org/abs/2410.15849v1","updated":"2024-10-21T10:25:52Z","published":"2024-10-21T10:25:52Z","title":"Focus Where It Matters: Graph Selective State Focused Attention Networks","summary":"  Traditional graph neural networks (GNNs) lack scalability and lose individual\nnode characteristics due to over-smoothing, especially in the case of deeper\nnetworks. This results in sub-optimal feature representation, affecting the\nmodel's performance on tasks involving dynamically changing graphs. To address\nthis issue, we present Graph Selective States Focused Attention Networks\n(GSANs) based neural network architecture for graph-structured data. The GSAN\nis enabled by multi-head masked self-attention (MHMSA) and selective state\nspace modeling (S3M) layers to overcome the limitations of GNNs. In GSAN, the\nMHMSA allows GSAN to dynamically emphasize crucial node connections,\nparticularly in evolving graph environments. The S3M layer enables the network\nto adjust dynamically in changing node states and improving predictions of node\nbehavior in varying contexts without needing primary knowledge of the graph\nstructure. Furthermore, the S3M layer enhances the generalization of unseen\nstructures and interprets how node states influence link importance. With this,\nGSAN effectively outperforms inductive and transductive tasks and overcomes the\nissues that traditional GNNs experience. To analyze the performance behavior of\nGSAN, a set of state-of-the-art comparative experiments are conducted on graphs\nbenchmark datasets, including $Cora$, $Citeseer$, $Pubmed$ network citation,\nand $protein-protein-interaction$ datasets, as an outcome, GSAN improved the\nclassification accuracy by $1.56\\%$, $8.94\\%$, $0.37\\%$, and $1.54\\%$ on\n$F1-score$ respectively.\n","authors":["Shikhar Vashistha","Neetesh Kumar"],"pdf_url":"https://arxiv.org/pdf/2410.15849v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.15664v3","updated":"2024-10-21T10:22:17Z","published":"2024-06-21T21:44:27Z","title":"Flat Posterior Does Matter For Bayesian Model Averaging","summary":"  Bayesian neural network (BNN) approximates the posterior distribution of\nmodel parameters and utilizes the posterior for prediction via Bayesian Model\nAveraging (BMA). The quality of the posterior approximation is critical for\nachieving accurate and robust predictions. It is known that flatness in the\nloss landscape is strongly associated with generalization performance, and it\nnecessitates consideration to improve the quality of the posterior\napproximation. In this work, we empirically demonstrate that BNNs often\nstruggle to capture the flatness. Moreover, we provide both experimental and\ntheoretical evidence showing that BMA can be ineffective without ensuring\nflatness. To address this, we propose Sharpness-Aware Bayesian Model Averaging\n(SA-BMA), a novel optimizer that seeks flat posteriors by calculating\ndivergence in the parameter space. SA-BMA aligns with the intrinsic nature of\nBNN and the generalized version of existing sharpness-aware optimizers for DNN.\nIn addition, we suggest a Bayesian Transfer Learning scheme to efficiently\nleverage pre-trained DNN. We validate the efficacy of SA-BMA in enhancing\ngeneralization performance in few-shot classification and distribution shift by\nensuring flat posterior.\n","authors":["Sungjun Lim","Jeyoon Yeom","Sooyon Kim","Hoyoon Byun","Jinho Kang","Yohan Jung","Jiyoung Jung","Kyungwoo Song"],"pdf_url":"https://arxiv.org/pdf/2406.15664v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.15847v1","updated":"2024-10-21T10:19:45Z","published":"2024-10-21T10:19:45Z","title":"Random Token Fusion for Multi-View Medical Diagnosis","summary":"  In multi-view medical diagnosis, deep learning-based models often fuse\ninformation from different imaging perspectives to improve diagnostic\nperformance. However, existing approaches are prone to overfitting and rely\nheavily on view-specific features, which can lead to trivial solutions. In this\nwork, we introduce Random Token Fusion (RTF), a novel technique designed to\nenhance multi-view medical image analysis using vision transformers. By\nintegrating randomness into the feature fusion process during training, RTF\naddresses the issue of overfitting and enhances the robustness and accuracy of\ndiagnostic models without incurring any additional cost at inference. We\nvalidate our approach on standard mammography and chest X-ray benchmark\ndatasets. Through extensive experiments, we demonstrate that RTF consistently\nimproves the performance of existing fusion methods, paving the way for a new\ngeneration of multi-view medical foundation models.\n","authors":["Jingyu Guo","Christos Matsoukas","Fredrik Strand","Kevin Smith"],"pdf_url":"https://arxiv.org/pdf/2410.15847v1.pdf","comment":"Originally published at the NeurIPS 2024 Workshop on Advancements In\n  Medical Foundation Models: Explainability, Robustness, Security, and Beyond\n  (AIM-FM)"},{"id":"http://arxiv.org/abs/2410.15846v1","updated":"2024-10-21T10:16:56Z","published":"2024-10-21T10:16:56Z","title":"Modelling Concurrent RTP Flows for End-to-end Predictions of QoS in Real\n  Time Communications","summary":"  The Real-time Transport Protocol (RTP)-based real-time communications (RTC)\napplications, exemplified by video conferencing, have experienced an\nunparalleled surge in popularity and development in recent years. In pursuit of\noptimizing their performance, the prediction of Quality of Service (QoS)\nmetrics emerges as a pivotal endeavor, bolstering network monitoring and\nproactive solutions. However, contemporary approaches are confined to\nindividual RTP flows and metrics, falling short in relationship capture and\ncomputational efficiency. To this end, we propose Packet-to-Prediction (P2P), a\nnovel deep learning (DL) framework that hinges on raw packets to simultaneously\nprocess concurrent RTP flows and perform end-to-end prediction of multiple QoS\nmetrics. Specifically, we implement a streamlined architecture, namely\nlength-free Transformer with cross and neighbourhood attention, capable of\nhandling an unlimited number of RTP flows, and employ a multi-task learning\nparadigm to forecast four key metrics in a single shot. Our work is based on\nextensive traffic collected during real video calls, and conclusively, P2P\nexcels comparative models in both prediction performance and temporal\nefficiency.\n","authors":["Tailai Song","Paolo Garza","Michela Meo","Maurizio Matteo Munafò"],"pdf_url":"https://arxiv.org/pdf/2410.15846v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.15840v1","updated":"2024-10-21T10:03:03Z","published":"2024-10-21T10:03:03Z","title":"Private, Efficient and Scalable Kernel Learning for Medical Image\n  Analysis","summary":"  Medical imaging is key in modern medicine. From magnetic resonance imaging\n(MRI) to microscopic imaging for blood cell detection, diagnostic medical\nimaging reveals vital insights into patient health. To predict diseases or\nprovide individualized therapies, machine learning techniques like kernel\nmethods have been widely used. Nevertheless, there are multiple challenges for\nimplementing kernel methods. Medical image data often originates from various\nhospitals and cannot be combined due to privacy concerns, and the high\ndimensionality of image data presents another significant obstacle. While\nrandomised encoding offers a promising direction, existing methods often\nstruggle with a trade-off between accuracy and efficiency. Addressing the need\nfor efficient privacy-preserving methods on distributed image data, we\nintroduce OKRA (Orthonormal K-fRAmes), a novel randomized encoding-based\napproach for kernel-based machine learning. This technique, tailored for widely\nused kernel functions, significantly enhances scalability and speed compared to\ncurrent state-of-the-art solutions. Through experiments conducted on various\nclinical image datasets, we evaluated model quality, computational performance,\nand resource overhead. Additionally, our method outperforms comparable\napproaches\n","authors":["Anika Hannemann","Arjhun Swaminathan","Ali Burak Ünal","Mete Akgün"],"pdf_url":"https://arxiv.org/pdf/2410.15840v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.15827v1","updated":"2024-10-21T09:44:37Z","published":"2024-10-21T09:44:37Z","title":"Explainability of Highly Associated Fuzzy Churn Patterns in Binary\n  Classification","summary":"  Customer churn, particularly in the telecommunications sector, influences\nboth costs and profits. As the explainability of models becomes increasingly\nimportant, this study emphasizes not only the explainability of customer churn\nthrough machine learning models, but also the importance of identifying\nmultivariate patterns and setting soft bounds for intuitive interpretation. The\nmain objective is to use a machine learning model and fuzzy-set theory with\ntop-\\textit{k} HUIM to identify highly associated patterns of customer churn\nwith intuitive identification, referred to as Highly Associated Fuzzy Churn\nPatterns (HAFCP). Moreover, this method aids in uncovering association rules\namong multiple features across low, medium, and high distributions. Such\ndiscoveries are instrumental in enhancing the explainability of findings.\nExperiments show that when the top-5 HAFCPs are included in five datasets, a\nmixture of performance results is observed, with some showing notable\nimprovements. It becomes clear that high importance features enhance\nexplanatory power through their distribution and patterns associated with other\nfeatures. As a result, the study introduces an innovative approach that\nimproves the explainability and effectiveness of customer churn prediction\nmodels.\n","authors":["D. Y. C. Wang","Lars Arne Jordanger","Jerry Chun-Wei Lin"],"pdf_url":"https://arxiv.org/pdf/2410.15827v1.pdf","comment":"18 pages single columns, 4 figures, This paper is an extended version\n  of a work originally presented at the 6th International Workshop on\n  Utility-Driven Mining and Learning (held in conjunction with the 28th\n  Pacific-Asia Conference on Knowledge Discovery and Data Mining - PAKDD 2024)\n  on May 7, 2024"},{"id":"http://arxiv.org/abs/2402.04494v2","updated":"2024-10-21T09:37:12Z","published":"2024-02-07T00:36:24Z","title":"Amortized Planning with Large-Scale Transformers: A Case Study on Chess","summary":"  This paper uses chess, a landmark planning problem in AI, to assess\ntransformers' performance on a planning task where memorization is futile\n$\\unicode{x2013}$ even at a large scale. To this end, we release ChessBench, a\nlarge-scale benchmark dataset of 10 million chess games with legal move and\nvalue annotations (15 billion data points) provided by Stockfish 16, the\nstate-of-the-art chess engine. We train transformers with up to 270 million\nparameters on ChessBench via supervised learning and perform extensive\nablations to assess the impact of dataset size, model size, architecture type,\nand different prediction targets (state-values, action-values, and behavioral\ncloning). Our largest models learn to predict action-values for novel boards\nquite accurately, implying highly non-trivial generalization. Despite\nperforming no explicit search, our resulting chess policy solves challenging\nchess puzzles and achieves a surprisingly strong Lichess blitz Elo of 2895\nagainst humans (grandmaster level). We also compare to Leela Chess Zero and\nAlphaZero (trained without supervision via self-play) with and without search.\nWe show that, although a remarkably good approximation of Stockfish's\nsearch-based algorithm can be distilled into large-scale transformers via\nsupervised learning, perfect distillation is still beyond reach, thus making\nChessBench well-suited for future research.\n","authors":["Anian Ruoss","Grégoire Delétang","Sourabh Medapati","Jordi Grau-Moya","Li Kevin Wenliang","Elliot Catt","John Reid","Cannada A. Lewis","Joel Veness","Tim Genewein"],"pdf_url":"https://arxiv.org/pdf/2402.04494v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.15819v1","updated":"2024-10-21T09:35:57Z","published":"2024-10-21T09:35:57Z","title":"LiMTR: Time Series Motion Prediction for Diverse Road Users through\n  Multimodal Feature Integration","summary":"  Predicting the behavior of road users accurately is crucial to enable the\nsafe operation of autonomous vehicles in urban or densely populated areas.\nTherefore, there has been a growing interest in time series motion prediction\nresearch, leading to significant advancements in state-of-the-art techniques in\nrecent years. However, the potential of using LiDAR data to capture more\ndetailed local features, such as a person's gaze or posture, remains largely\nunexplored. To address this, we develop a novel multimodal approach for motion\nprediction based on the PointNet foundation model architecture, incorporating\nlocal LiDAR features. Evaluation on the Waymo Open Dataset shows a performance\nimprovement of 6.20% and 1.58% in minADE and mAP respectively, when integrated\nand compared with the previous state-of-the-art MTR. We open-source the code of\nour LiMTR model.\n","authors":["Camiel Oerlemans","Bram Grooten","Michiel Braat","Alaa Alassi","Emilia Silvas","Decebal Constantin Mocanu"],"pdf_url":"https://arxiv.org/pdf/2410.15819v1.pdf","comment":"Accepted at the NeurIPS 2024 workshop Time Series in the Age of Large\n  Models. Code available at https://github.com/Cing2/LiMTR"},{"id":"http://arxiv.org/abs/2410.15815v1","updated":"2024-10-21T09:28:46Z","published":"2024-10-21T09:28:46Z","title":"Solvation Free Energies from Neural Thermodynamic Integration","summary":"  We propose to compute solvation free energies via thermodynamic integration\nalong a neural-network potential interpolating between two target Hamiltonians.\nWe use a stochastic interpolant to define an interpolation between the\ndistributions at the level of samples and optimize a neural network potential\nto match the corresponding equilibrium potential at every intermediate\ntime-step. Once the alignment between the interpolating samples and the\ninterpolating potentials is sufficiently accurate, the free-energy difference\nbetween the two Hamiltonians can be estimated using (neural) thermodynamic\nintegration. We validate our method to compute solvation free energies on\nseveral benchmark systems: a Lennard-Jones particle in a Lennard-Jones fluid,\nas well as the insertion of both water and methane solutes in a water solvent\nat atomistic resolution.\n","authors":["Bálint Máté","François Fleuret","Tristan Bereau"],"pdf_url":"https://arxiv.org/pdf/2410.15815v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.15808v1","updated":"2024-10-21T09:23:50Z","published":"2024-10-21T09:23:50Z","title":"Mean-Field Simulation-Based Inference for Cosmological Initial\n  Conditions","summary":"  Reconstructing cosmological initial conditions (ICs) from late-time\nobservations is a difficult task, which relies on the use of computationally\nexpensive simulators alongside sophisticated statistical methods to navigate\nmulti-million dimensional parameter spaces. We present a simple method for\nBayesian field reconstruction based on modeling the posterior distribution of\nthe initial matter density field to be diagonal Gaussian in Fourier space, with\nits covariance and the mean estimator being the trainable parts of the\nalgorithm. Training and sampling are extremely fast (training: $\\sim 1 \\,\n\\mathrm{h}$ on a GPU, sampling: $\\lesssim 3 \\, \\mathrm{s}$ for 1000 samples at\nresolution $128^3$), and our method supports industry-standard\n(non-differentiable) $N$-body simulators. We verify the fidelity of the\nobtained IC samples in terms of summary statistics.\n","authors":["Oleg Savchenko","Florian List","Guillermo Franco Abellán","Noemi Anau Montel","Christoph Weniger"],"pdf_url":"https://arxiv.org/pdf/2410.15808v1.pdf","comment":"Accepted for the NeurIPS 2024 workshop Machine Learning and the\n  Physical Sciences; 5 + 4 pages, 3 figures"},{"id":"http://arxiv.org/abs/2410.15804v1","updated":"2024-10-21T09:22:16Z","published":"2024-10-21T09:22:16Z","title":"Deep Learning and Data Augmentation for Detecting Self-Admitted\n  Technical Debt","summary":"  Self-Admitted Technical Debt (SATD) refers to circumstances where developers\nuse textual artifacts to explain why the existing implementation is not\noptimal. Past research in detecting SATD has focused on either identifying SATD\n(classifying SATD items as SATD or not) or categorizing SATD (labeling\ninstances as SATD that pertain to requirement, design, code, test debt, etc.).\nHowever, the performance of these approaches remains suboptimal, particularly\nfor specific types of SATD, such as test and requirement debt, primarily due to\nextremely imbalanced datasets. To address these challenges, we build on earlier\nresearch by utilizing BiLSTM architecture for the binary identification of SATD\nand BERT architecture for categorizing different types of SATD. Despite their\neffectiveness, both architectures struggle with imbalanced data. Therefore, we\nemploy a large language model data augmentation strategy to mitigate this\nissue. Furthermore, we introduce a two-step approach to identify and categorize\nSATD across various datasets derived from different artifacts. Our\ncontributions include providing a balanced dataset for future SATD researchers\nand demonstrating that our approach significantly improves SATD identification\nand categorization performance compared to baseline methods.\n","authors":["Edi Sutoyo","Paris Avgeriou","Andrea Capiluppi"],"pdf_url":"https://arxiv.org/pdf/2410.15804v1.pdf","comment":"Accepted to be published at the 2024 31st Asia-Pacific Software\n  Engineering Conference (APSEC)"},{"id":"http://arxiv.org/abs/2410.02711v2","updated":"2024-10-21T09:22:05Z","published":"2024-10-03T17:35:38Z","title":"NETS: A Non-Equilibrium Transport Sampler","summary":"  We propose an algorithm, termed the Non-Equilibrium Transport Sampler (NETS),\nto sample from unnormalized probability distributions. NETS can be viewed as a\nvariant of annealed importance sampling (AIS) based on Jarzynski's equality, in\nwhich the stochastic differential equation used to perform the non-equilibrium\nsampling is augmented with an additional learned drift term that lowers the\nimpact of the unbiasing weights used in AIS. We show that this drift is the\nminimizer of a variety of objective functions, which can all be estimated in an\nunbiased fashion without backpropagating through solutions of the stochastic\ndifferential equations governing the sampling. We also prove that some these\nobjectives control the Kullback-Leibler divergence of the estimated\ndistribution from its target. NETS is shown to be unbiased and, in addition,\nhas a tunable diffusion coefficient which can be adjusted post-training to\nmaximize the effective sample size. We demonstrate the efficacy of the method\non standard benchmarks, high-dimensional Gaussian mixture distributions, and a\nmodel from statistical lattice field theory, for which it surpasses the\nperformances of related work and existing baselines.\n","authors":["Michael S. Albergo","Eric Vanden-Eijnden"],"pdf_url":"https://arxiv.org/pdf/2410.02711v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.15800v1","updated":"2024-10-21T09:16:06Z","published":"2024-10-21T09:16:06Z","title":"On the VC dimension of deep group convolutional neural networks","summary":"  We study the generalization capabilities of Group Convolutional Neural\nNetworks (GCNNs) with ReLU activation function by deriving upper and lower\nbounds for their Vapnik-Chervonenkis (VC) dimension. Specifically, we analyze\nhow factors such as the number of layers, weights, and input dimension affect\nthe VC dimension. We further compare the derived bounds to those known for\nother types of neural networks. Our findings extend previous results on the VC\ndimension of continuous GCNNs with two layers, thereby providing new insights\ninto the generalization properties of GCNNs, particularly regarding the\ndependence on the input resolution of the data.\n","authors":["Anna Sepliarskaia","Sophie Langer","Johannes Schmidt-Hieber"],"pdf_url":"https://arxiv.org/pdf/2410.15800v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2409.07825v3","updated":"2024-10-21T09:14:47Z","published":"2024-09-12T08:15:39Z","title":"Deep Multimodal Learning with Missing Modality: A Survey","summary":"  During multimodal model training and testing, certain data modalities may be\nabsent due to sensor limitations, cost constraints, privacy concerns, or data\nloss, negatively affecting performance. Multimodal learning techniques designed\nto handle missing modalities can mitigate this by ensuring model robustness\neven when some modalities are unavailable. This survey reviews recent progress\nin Multimodal Learning with Missing Modality (MLMM), focusing on deep learning\nmethods. It provides the first comprehensive survey that covers the motivation\nand distinctions between MLMM and standard multimodal learning setups, followed\nby a detailed analysis of current methods, applications, and datasets,\nconcluding with challenges and future directions.\n","authors":["Renjie Wu","Hu Wang","Hsiang-Ting Chen","Gustavo Carneiro"],"pdf_url":"https://arxiv.org/pdf/2409.07825v3.pdf","comment":"Submitted to ACM Computing Surveys"},{"id":"http://arxiv.org/abs/2407.13432v2","updated":"2024-10-21T09:12:21Z","published":"2024-07-18T12:01:09Z","title":"The Art of Imitation: Learning Long-Horizon Manipulation Tasks from Few\n  Demonstrations","summary":"  Task Parametrized Gaussian Mixture Models (TP-GMM) are a sample-efficient\nmethod for learning object-centric robot manipulation tasks. However, there are\nseveral open challenges to applying TP-GMMs in the wild. In this work, we\ntackle three crucial challenges synergistically. First, end-effector velocities\nare non-Euclidean and thus hard to model using standard GMMs. We thus propose\nto factorize the robot's end-effector velocity into its direction and\nmagnitude, and model them using Riemannian GMMs. Second, we leverage the\nfactorized velocities to segment and sequence skills from complex demonstration\ntrajectories. Through the segmentation, we further align skill trajectories and\nhence leverage time as a powerful inductive bias. Third, we present a method to\nautomatically detect relevant task parameters per skill from visual\nobservations. Our approach enables learning complex manipulation tasks from\njust five demonstrations while using only RGB-D observations. Extensive\nexperimental evaluations on RLBench demonstrate that our approach achieves\nstate-of-the-art performance with 20-fold improved sample efficiency. Our\npolicies generalize across different environments, object instances, and object\npositions, while the learned skills are reusable.\n","authors":["Jan Ole von Hartz","Tim Welschehold","Abhinav Valada","Joschka Boedecker"],"pdf_url":"https://arxiv.org/pdf/2407.13432v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2405.20648v2","updated":"2024-10-21T08:52:10Z","published":"2024-05-31T07:30:24Z","title":"Shotluck Holmes: A Family of Efficient Small-Scale Large Language Vision\n  Models For Video Captioning and Summarization","summary":"  Video is an increasingly prominent and information-dense medium, yet it poses\nsubstantial challenges for language models. A typical video consists of a\nsequence of shorter segments, or shots, that collectively form a coherent\nnarrative. Each shot is analogous to a word in a sentence where multiple data\nstreams of information (such as visual and auditory data) must be processed\nsimultaneously. Comprehension of the entire video requires not only\nunderstanding the visual-audio information of each shot but also requires that\nthe model links the ideas between each shot to generate a larger,\nall-encompassing story. Despite significant progress in the field, current\nworks often overlook videos' more granular shot-by-shot semantic information.\nIn this project, we propose a family of efficient large language vision models\n(LLVMs) to boost video summarization and captioning called Shotluck Holmes. By\nleveraging better pretraining and data collection strategies, we extend the\nabilities of existing small LLVMs from being able to understand a picture to\nbeing able to understand a sequence of frames. Specifically, we show that\nShotluck Holmes achieves better performance than state-of-the-art results on\nthe Shot2Story video captioning and summary task with significantly smaller and\nmore computationally efficient models.\n","authors":["Richard Luo","Austin Peng","Adithya Vasudev","Rishabh Jain"],"pdf_url":"https://arxiv.org/pdf/2405.20648v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.15787v1","updated":"2024-10-21T08:49:51Z","published":"2024-10-21T08:49:51Z","title":"Arithmetic Transformers Can Length-Generalize in Both Operand Length and\n  Count","summary":"  Transformers often struggle with length generalization, meaning they fail to\ngeneralize to sequences longer than those encountered during training. While\narithmetic tasks are commonly used to study length generalization, certain\ntasks are considered notoriously difficult, e.g., multi-operand addition\n(requiring generalization over both the number of operands and their lengths)\nand multiplication (requiring generalization over both operand lengths). In\nthis work, we achieve approximately 2-3x length generalization on both tasks,\nwhich is the first such achievement in arithmetic Transformers. We design\ntask-specific scratchpads enabling the model to focus on a fixed number of\ntokens per each next-token prediction step, and apply multi-level versions of\nPosition Coupling (Cho et al., 2024; McLeish et al., 2024) to let Transformers\nknow the right position to attend to. On the theory side, we prove that a\n1-layer Transformer using our method can solve multi-operand addition, up to\noperand length and operand count that are exponential in embedding dimension.\n","authors":["Hanseul Cho","Jaeyoung Cha","Srinadh Bhojanapalli","Chulhee Yun"],"pdf_url":"https://arxiv.org/pdf/2410.15787v1.pdf","comment":"38 pages, 16 figures"},{"id":"http://arxiv.org/abs/2408.16457v2","updated":"2024-10-21T08:47:29Z","published":"2024-08-29T11:45:01Z","title":"HYGENE: A Diffusion-based Hypergraph Generation Method","summary":"  Hypergraphs are powerful mathematical structures that can model complex,\nhigh-order relationships in various domains, including social networks,\nbioinformatics, and recommender systems. However, generating realistic and\ndiverse hypergraphs remains challenging due to their inherent complexity and\nlack of effective generative models. In this paper, we introduce a\ndiffusion-based Hypergraph Generation (HYGENE) method that addresses these\nchallenges through a progressive local expansion approach. HYGENE works on the\nbipartite representation of hypergraphs, starting with a single pair of\nconnected nodes and iteratively expanding it to form the target hypergraph. At\neach step, nodes and hyperedges are added in a localized manner using a\ndenoising diffusion process, which allows for the construction of the global\nstructure before refining local details. Our experiments demonstrated the\neffectiveness of HYGENE, proving its ability to closely mimic a variety of\nproperties in hypergraphs. To the best of our knowledge, this is the first\nattempt to employ deep learning models for hypergraph generation, and our work\naims to lay the groundwork for future research in this area.\n","authors":["Dorian Gailhard","Enzo Tartaglione","Lirida Naviner","Jhony H. Giraldo"],"pdf_url":"https://arxiv.org/pdf/2408.16457v2.pdf","comment":"arXiv admin note: text overlap with arXiv:2312.11529 by other authors"},{"id":"http://arxiv.org/abs/2410.06717v2","updated":"2024-10-21T08:45:30Z","published":"2024-10-09T09:41:28Z","title":"Exact full-RSB SAT/UNSAT transition in infinitely wide two-layer neural\n  networks","summary":"  We analyze the problem of storing random pattern-label associations using two\nclasses of continuous non-convex weights models, namely the perceptron with\nnegative margin and an infinite-width two-layer neural network with\nnon-overlapping receptive fields and generic activation function. Using a\nfull-RSB ansatz we compute the exact value of the SAT/UNSAT transition.\nFurthermore, in the case of the negative perceptron we show that the overlap\ndistribution of typical states displays an overlap gap (a disconnected support)\nin certain regions of the phase diagram defined by the value of the margin and\nthe density of patterns to be stored. This implies that some recent theorems\nthat ensure convergence of Approximate Message Passing (AMP) based algorithms\nto capacity are not applicable. Finally, we show that Gradient Descent is not\nable to reach the maximal capacity, irrespectively of the presence of an\noverlap gap for typical states. This finding, similarly to what occurs in\nbinary weight models, suggests that gradient-based algorithms are biased\ntowards highly atypical states, whose inaccessibility determines the\nalgorithmic threshold.\n","authors":["Brandon L. Annesi","Enrico M. Malatesta","Francesco Zamponi"],"pdf_url":"https://arxiv.org/pdf/2410.06717v2.pdf","comment":"38 pages, 12 figures"},{"id":"http://arxiv.org/abs/2407.18698v2","updated":"2024-10-21T08:43:41Z","published":"2024-07-26T12:23:54Z","title":"Adaptive Contrastive Search: Uncertainty-Guided Decoding for Open-Ended\n  Text Generation","summary":"  Decoding from the output distributions of large language models to produce\nhigh-quality text is a complex challenge in language modeling. Various\napproaches, such as beam search, sampling with temperature, $k-$sampling,\nnucleus $p-$sampling, typical decoding, contrastive decoding, and contrastive\nsearch, have been proposed to address this problem, aiming to improve\ncoherence, diversity, as well as resemblance to human-generated text. In this\nstudy, we introduce adaptive contrastive search, a novel decoding strategy\nextending contrastive search by incorporating an adaptive degeneration penalty,\nguided by the estimated uncertainty of the model at each generation step. This\nstrategy is designed to enhance both the creativity and diversity of the\nlanguage modeling process while at the same time producing coherent and\nhigh-quality generated text output. Our findings indicate performance\nenhancement in both aspects, across different model architectures and datasets,\nunderscoring the effectiveness of our method in text generation tasks. Our code\nbase, datasets, and models are publicly available.\n","authors":["Esteban Garces Arias","Julian Rodemann","Meimingwei Li","Christian Heumann","Matthias Aßenmacher"],"pdf_url":"https://arxiv.org/pdf/2407.18698v2.pdf","comment":"Accepted to EMNLP 2024 Findings"},{"id":"http://arxiv.org/abs/2410.15778v1","updated":"2024-10-21T08:42:30Z","published":"2024-10-21T08:42:30Z","title":"Reducing Hallucinations in Vision-Language Models via Latent Space\n  Steering","summary":"  Hallucination poses a challenge to the deployment of large vision-language\nmodels (LVLMs) in applications. Unlike in large language models (LLMs),\nhallucination in LVLMs often arises from misalignments between visual inputs\nand textual outputs. This paper investigates the underlying mechanisms of\nhallucination, focusing on the unique structure of LVLMs that distinguishes\nthem from large language models (LLMs). We identify that hallucinations often\narise from the sensitivity of text decoders to vision inputs, a natural\nphenomenon when image encoders and text decoders are pre-trained separately.\nInspired by this, we introduce Visual and Textual Intervention (VTI), a novel\ntechnique designed to reduce hallucinations by steering latent space\nrepresentations during inference to enhance the stability of vision features.\nAs a task-agnostic test-time intervention, VTI can be easily applied to any\nproblem without additional cost. Extensive experiments demonstrate that it can\neffectively reduce hallucinations and outperform baseline methods across\nmultiple metrics, highlighting the critical role of vision feature stability in\nLVLMs.\n","authors":["Sheng Liu","Haotian Ye","James Zou"],"pdf_url":"https://arxiv.org/pdf/2410.15778v1.pdf","comment":"21 pages"},{"id":"http://arxiv.org/abs/2410.15777v1","updated":"2024-10-21T08:42:10Z","published":"2024-10-21T08:42:10Z","title":"High-Fidelity Transfer of Functional Priors for Wide Bayesian Neural\n  Networks by Learning Activations","summary":"  Function-space priors in Bayesian Neural Networks provide a more intuitive\napproach to embedding beliefs directly into the model's output, thereby\nenhancing regularization, uncertainty quantification, and risk-aware\ndecision-making. However, imposing function-space priors on BNNs is\nchallenging. We address this task through optimization techniques that explore\nhow trainable activations can accommodate complex priors and match intricate\ntarget function distributions. We discuss critical learning challenges,\nincluding identifiability, loss construction, and symmetries that arise in this\ncontext. Furthermore, we enable evidence maximization to facilitate model\nselection by conditioning the functional priors on additional hyperparameters.\nOur empirical findings demonstrate that even BNNs with a single wide hidden\nlayer, when equipped with these adaptive trainable activations and conditioning\nstrategies, can effectively achieve high-fidelity function-space priors,\nproviding a robust and flexible framework for enhancing Bayesian neural network\nperformance.\n","authors":["Marcin Sendera","Amin Sorkhei","Tomasz Kuśmierczyk"],"pdf_url":"https://arxiv.org/pdf/2410.15777v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.09640v2","updated":"2024-10-21T08:33:44Z","published":"2024-10-12T20:33:37Z","title":"Provable Acceleration of Nesterov's Accelerated Gradient for Rectangular\n  Matrix Factorization and Linear Neural Networks","summary":"  We study the convergence rate of first-order methods for rectangular matrix\nfactorization, which is a canonical nonconvex optimization problem.\nSpecifically, given a rank-$r$ matrix $\\mathbf{A}\\in\\mathbb{R}^{m\\times n}$, we\nprove that gradient descent (GD) can find a pair of $\\epsilon$-optimal\nsolutions $\\mathbf{X}_T\\in\\mathbb{R}^{m\\times d}$ and\n$\\mathbf{Y}_T\\in\\mathbb{R}^{n\\times d}$, where $d\\geq r$, satisfying\n$\\lVert\\mathbf{X}_T\\mathbf{Y}_T^\\top-\\mathbf{A}\\rVert_\\mathrm{F}\\leq\\epsilon\\lVert\\mathbf{A}\\rVert_\\mathrm{F}$\nin $T=O(\\kappa^2\\log\\frac{1}{\\epsilon})$ iterations with high probability,\nwhere $\\kappa$ denotes the condition number of $\\mathbf{A}$. Furthermore, we\nprove that Nesterov's accelerated gradient (NAG) attains an iteration\ncomplexity of $O(\\kappa\\log\\frac{1}{\\epsilon})$, which is the best-known bound\nof first-order methods for rectangular matrix factorization. Different from\nsmall balanced random initialization in the existing literature, we adopt an\nunbalanced initialization, where $\\mathbf{X}_0$ is large and $\\mathbf{Y}_0$ is\n$0$. Moreover, our initialization and analysis can be further extended to\nlinear neural networks, where we prove that NAG can also attain an accelerated\nlinear convergence rate. In particular, we only require the width of the\nnetwork to be greater than or equal to the rank of the output label matrix. In\ncontrast, previous results achieving the same rate require excessive widths\nthat additionally depend on the condition number and the rank of the input data\nmatrix.\n","authors":["Zhenghao Xu","Yuqing Wang","Tuo Zhao","Rachel Ward","Molei Tao"],"pdf_url":"https://arxiv.org/pdf/2410.09640v2.pdf","comment":"30 pages (checklist included), fix typos"},{"id":"http://arxiv.org/abs/2410.10504v2","updated":"2024-10-21T08:33:05Z","published":"2024-10-14T13:46:58Z","title":"A Kernelizable Primal-Dual Formulation of the Multilinear Singular Value\n  Decomposition","summary":"  The ability to express a learning task in terms of a primal and a dual\noptimization problem lies at the core of a plethora of machine learning\nmethods. For example, Support Vector Machine (SVM), Least-Squares Support\nVector Machine (LS-SVM), Ridge Regression (RR), Lasso Regression (LR),\nPrincipal Component Analysis (PCA), and more recently Singular Value\nDecomposition (SVD) have all been defined either in terms of primal weights or\nin terms of dual Lagrange multipliers. The primal formulation is\ncomputationally advantageous in the case of large sample size while the dual is\npreferred for high-dimensional data. Crucially, said learning problems can be\nmade nonlinear through the introduction of a feature map in the primal problem,\nwhich corresponds to applying the kernel trick in the dual. In this paper we\nderive a primal-dual formulation of the Multilinear Singular Value\nDecomposition (MLSVD), which recovers as special cases both PCA and SVD.\nBesides enabling computational gains through the derived primal formulation, we\npropose a nonlinear extension of the MLSVD using feature maps, which results in\na dual problem where a kernel tensor arises. We discuss potential applications\nin the context of signal analysis and deep learning.\n","authors":["Frederiek Wesel","Kim Batselier"],"pdf_url":"https://arxiv.org/pdf/2410.10504v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.15772v1","updated":"2024-10-21T08:32:02Z","published":"2024-10-21T08:32:02Z","title":"Mislabeled examples detection viewed as probing machine learning models:\n  concepts, survey and extensive benchmark","summary":"  Mislabeled examples are ubiquitous in real-world machine learning datasets,\nadvocating the development of techniques for automatic detection. We show that\nmost mislabeled detection methods can be viewed as probing trained machine\nlearning models using a few core principles. We formalize a modular framework\nthat encompasses these methods, parameterized by only 4 building blocks, as\nwell as a Python library that demonstrates that these principles can actually\nbe implemented. The focus is on classifier-agnostic concepts, with an emphasis\non adapting methods developed for deep learning models to non-deep classifiers\nfor tabular data. We benchmark existing methods on (artificial) Completely At\nRandom (NCAR) as well as (realistic) Not At Random (NNAR) labeling noise from a\nvariety of tasks with imperfect labeling rules. This benchmark provides new\ninsights as well as limitations of existing methods in this setup.\n","authors":["Thomas George","Pierre Nodet","Alexis Bondu","Vincent Lemaire"],"pdf_url":"https://arxiv.org/pdf/2410.15772v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2402.16788v4","updated":"2024-10-21T08:27:23Z","published":"2024-02-26T18:01:41Z","title":"Why Transformers Need Adam: A Hessian Perspective","summary":"  SGD performs worse than Adam by a significant margin on Transformers, but the\nreason remains unclear. In this work, we provide an explanation through the\nlens of Hessian: (i) Transformers are \"heterogeneous\": the Hessian spectrum\nacross parameter blocks vary dramatically, a phenomenon we call \"block\nheterogeneity\"; (ii) Heterogeneity hampers SGD: SGD performs worse than Adam on\nproblems with block heterogeneity. To validate (i) and (ii), we check various\nTransformers, CNNs, MLPs, and quadratic problems, and find that SGD can perform\non par with Adam on problems without block heterogeneity, but performs worse\nthan Adam when the heterogeneity exists. Our initial theoretical analysis\nindicates that SGD performs worse because it applies one single learning rate\nto all blocks, which cannot handle the heterogeneity among blocks. This\nlimitation could be ameliorated if we use coordinate-wise learning rates, as\ndesigned in Adam.\n","authors":["Yushun Zhang","Congliang Chen","Tian Ding","Ziniu Li","Ruoyu Sun","Zhi-Quan Luo"],"pdf_url":"https://arxiv.org/pdf/2402.16788v4.pdf","comment":"Advances in Neural Information Processing Systems, 2024"},{"id":"http://arxiv.org/abs/2403.19381v2","updated":"2024-10-21T08:26:52Z","published":"2024-03-28T12:42:25Z","title":"On Uncertainty Quantification for Near-Bayes Optimal Algorithms","summary":"  Bayesian modelling allows for the quantification of predictive uncertainty\nwhich is crucial in safety-critical applications. Yet for many machine learning\n(ML) algorithms, it is difficult to construct or implement their Bayesian\ncounterpart. In this work we present a promising approach to address this\nchallenge, based on the hypothesis that commonly used ML algorithms are\nefficient across a wide variety of tasks and may thus be near Bayes-optimal\nw.r.t. an unknown task distribution. We prove that it is possible to recover\nthe Bayesian posterior defined by the task distribution, which is unknown but\noptimal in this setting, by building a martingale posterior using the\nalgorithm. We further propose a practical uncertainty quantification method\nthat apply to general ML algorithms. Experiments based on a variety of non-NN\nand NN algorithms demonstrate the efficacy of our method.\n","authors":["Ziyu Wang","Chris Holmes"],"pdf_url":"https://arxiv.org/pdf/2403.19381v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.14485v2","updated":"2024-10-21T08:26:40Z","published":"2024-10-18T14:10:16Z","title":"CaTs and DAGs: Integrating Directed Acyclic Graphs with Transformers and\n  Fully-Connected Neural Networks for Causally Constrained Predictions","summary":"  Artificial Neural Networks (ANNs), including fully-connected networks and\ntransformers, are highly flexible and powerful function approximators, widely\napplied in fields like computer vision and natural language processing.\nHowever, their inability to inherently respect causal structures can limit\ntheir robustness, making them vulnerable to covariate shift and difficult to\ninterpret/explain. This poses significant challenges for their reliability in\nreal-world applications. In this paper, we introduce Causal Fully-Connected\nNeural Networks (CFCNs) and Causal Transformers (CaTs), two general model\nfamilies designed to operate under predefined causal constraints, as specified\nby a Directed Acyclic Graph (DAG). These models retain the powerful function\napproximation abilities of traditional neural networks while adhering to the\nunderlying structural constraints, improving robustness, reliability, and\ninterpretability at inference time. This approach opens new avenues for\ndeploying neural networks in more demanding, real-world scenarios where\nrobustness and explainability is critical.\n","authors":["Matthew J. Vowels","Mathieu Rochat","Sina Akbari"],"pdf_url":"https://arxiv.org/pdf/2410.14485v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.15765v1","updated":"2024-10-21T08:24:44Z","published":"2024-10-21T08:24:44Z","title":"SeisLM: a Foundation Model for Seismic Waveforms","summary":"  We introduce the Seismic Language Model (SeisLM), a foundational model\ndesigned to analyze seismic waveforms -- signals generated by Earth's\nvibrations such as the ones originating from earthquakes. SeisLM is pretrained\non a large collection of open-source seismic datasets using a self-supervised\ncontrastive loss, akin to BERT in language modeling. This approach allows the\nmodel to learn general seismic waveform patterns from unlabeled data without\nbeing tied to specific downstream tasks. When fine-tuned, SeisLM excels in\nseismological tasks like event detection, phase-picking, onset time regression,\nand foreshock-aftershock classification. The code has been made publicly\navailable on https://github.com/liutianlin0121/seisLM.\n","authors":["Tianlin Liu","Jannes Münchmeyer","Laura Laurenti","Chris Marone","Maarten V. de Hoop","Ivan Dokmanić"],"pdf_url":"https://arxiv.org/pdf/2410.15765v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.15762v1","updated":"2024-10-21T08:21:25Z","published":"2024-10-21T08:21:25Z","title":"Solving Sparse \\& High-Dimensional-Output Regression via Compression","summary":"  Multi-Output Regression (MOR) has been widely used in scientific data\nanalysis for decision-making. Unlike traditional regression models, MOR aims to\nsimultaneously predict multiple real-valued outputs given an input. However,\nthe increasing dimensionality of the outputs poses significant challenges\nregarding interpretability and computational scalability for modern MOR\napplications. As a first step to address these challenges, this paper proposes\na Sparse \\& High-dimensional-Output REgression (SHORE) model by incorporating\nadditional sparsity requirements to resolve the output interpretability, and\nthen designs a computationally efficient two-stage optimization framework\ncapable of solving SHORE with provable accuracy via compression on outputs.\nTheoretically, we show that the proposed framework is computationally scalable\nwhile maintaining the same order of training loss and prediction loss\nbefore-and-after compression under arbitrary or relatively weak sample set\nconditions. Empirically, numerical results further validate the theoretical\nfindings, showcasing the efficiency and accuracy of the proposed framework.\n","authors":["Renyuan Li","Zhehui Chen","Guanyi Wang"],"pdf_url":"https://arxiv.org/pdf/2410.15762v1.pdf","comment":"Admitted in Neurips 2024"},{"id":"http://arxiv.org/abs/2410.15761v1","updated":"2024-10-21T08:21:00Z","published":"2024-10-21T08:21:00Z","title":"Learning-to-Defer for Extractive Question Answering","summary":"  Pre-trained language models have profoundly impacted the field of extractive\nquestion-answering, leveraging large-scale textual corpora to enhance\ncontextual language understanding. Despite their success, these models struggle\nin complex scenarios that demand nuanced interpretation or inferential\nreasoning beyond immediate textual cues. Furthermore, their size poses\ndeployment challenges on resource-constrained devices. Addressing these\nlimitations, we introduce an adapted two-stage Learning-to-Defer mechanism that\nenhances decision-making by enabling selective deference to human experts or\nlarger models without retraining language models in the context of\nquestion-answering. This approach not only maintains computational efficiency\nbut also significantly improves model reliability and accuracy in ambiguous\ncontexts. We establish the theoretical soundness of our methodology by proving\nBayes and $(\\mathcal{H}, \\mathcal{R})$--consistency of our surrogate loss\nfunction, guaranteeing the optimality of the final solution. Empirical\nevaluations on the SQuADv2 dataset illustrate performance gains from\nintegrating human expertise and leveraging larger models. Our results further\ndemonstrate that deferring a minimal number of queries allows the smaller model\nto achieve performance comparable to their larger counterparts while preserving\ncomputing efficiency, thus broadening the applicability of pre-trained language\nmodels in diverse operational environments.\n","authors":["Montreuil Yannis","Carlier Axel","Ng Lai Xing","Ooi Wei Tsang"],"pdf_url":"https://arxiv.org/pdf/2410.15761v1.pdf","comment":"25 pages, 17 main paper"},{"id":"http://arxiv.org/abs/2410.10270v3","updated":"2024-10-21T08:13:45Z","published":"2024-10-14T08:21:25Z","title":"QUIS: Question-guided Insights Generation for Automated Exploratory Data\n  Analysis","summary":"  Discovering meaningful insights from a large dataset, known as Exploratory\nData Analysis (EDA), is a challenging task that requires thorough exploration\nand analysis of the data. Automated Data Exploration (ADE) systems use\ngoal-oriented methods with Large Language Models and Reinforcement Learning\ntowards full automation. However, these methods require human involvement to\nanticipate goals that may limit insight extraction, while fully automated\nsystems demand significant computational resources and retraining for new\ndatasets. We introduce QUIS, a fully automated EDA system that operates in two\nstages: insight generation (ISGen) driven by question generation (QUGen). The\nQUGen module generates questions in iterations, refining them from previous\niterations to enhance coverage without human intervention or manually curated\nexamples. The ISGen module analyzes data to produce multiple relevant insights\nin response to each question, requiring no prior training and enabling QUIS to\nadapt to new datasets.\n","authors":["Abhijit Manatkar","Ashlesha Akella","Parthivi Gupta","Krishnasuri Narayanam"],"pdf_url":"https://arxiv.org/pdf/2410.10270v3.pdf","comment":"Accepted for EMNLP 2024 Industry Track"},{"id":"http://arxiv.org/abs/2410.15742v1","updated":"2024-10-21T08:01:08Z","published":"2024-10-21T08:01:08Z","title":"DeepVigor+: Scalable and Accurate Semi-Analytical Fault Resilience\n  Analysis for Deep Neural Network","summary":"  Growing exploitation of Machine Learning (ML) in safety-critical applications\nnecessitates rigorous safety analysis. Hardware reliability assessment is a\nmajor concern with respect to measuring the level of safety. Quantifying the\nreliability of emerging ML models, including Deep Neural Networks (DNNs), is\nhighly complex due to their enormous size in terms of the number of parameters\nand computations. Conventionally, Fault Injection (FI) is applied to perform a\nreliability measurement. However, performing FI on modern-day DNNs is\nprohibitively time-consuming if an acceptable confidence level is to be\nachieved. In order to speed up FI for large DNNs, statistical FI has been\nproposed. However, the run-time for the large DNN models is still considerably\nlong.\n  In this work, we introduce DeepVigor+, a scalable, fast and accurate\nsemi-analytical method as an efficient alternative for reliability measurement\nin DNNs. DeepVigor+ implements a fault propagation analysis model and attempts\nto acquire Vulnerability Factors (VFs) as reliability metrics in an optimal\nway. The results indicate that DeepVigor+ obtains VFs for DNN models with an\nerror less than 1\\% and 14.9 up to 26.9 times fewer simulations than the\nbest-known state-of-the-art statistical FI enabling an accurate reliability\nanalysis for emerging DNNs within a few minutes.\n","authors":["Mohammad Hasan Ahmadilivani","Jaan Raik","Masoud Daneshtalab","Maksim Jenihhin"],"pdf_url":"https://arxiv.org/pdf/2410.15742v1.pdf","comment":"14 pages, 9 figures, 8 tables, 16 equations. The source code is\n  accessible via: https://github.com/mhahmadilivany/DeepVigor"},{"id":"http://arxiv.org/abs/2410.13286v2","updated":"2024-10-21T08:00:06Z","published":"2024-10-17T07:32:24Z","title":"A Human-in-the-Loop Fairness-Aware Model Selection Framework for Complex\n  Fairness Objective Landscapes","summary":"  Fairness-aware Machine Learning (FairML) applications are often characterized\nby complex social objectives and legal requirements, frequently involving\nmultiple, potentially conflicting notions of fairness. Despite the well-known\nImpossibility Theorem of Fairness and extensive theoretical research on the\nstatistical and socio-technical trade-offs between fairness metrics, many\nFairML tools still optimize or constrain for a single fairness objective.\nHowever, this one-sided optimization can inadvertently lead to violations of\nother relevant notions of fairness. In this socio-technical and empirical\nstudy, we frame fairness as a many-objective (MaO) problem by treating fairness\nmetrics as conflicting objectives. We introduce ManyFairHPO, a\nhuman-in-the-loop, fairness-aware model selection framework that enables\npractitioners to effectively navigate complex and nuanced fairness objective\nlandscapes. ManyFairHPO aids in the identification, evaluation, and balancing\nof fairness metric conflicts and their related social consequences, leading to\nmore informed and socially responsible model-selection decisions. Through a\ncomprehensive empirical evaluation and a case study on the Law School\nAdmissions problem, we demonstrate the effectiveness of ManyFairHPO in\nbalancing multiple fairness objectives, mitigating risks such as\nself-fulfilling prophecies, and providing interpretable insights to guide\nstakeholders in making fairness-aware modeling decisions.\n","authors":["Jake Robertson","Thorsten Schmidt","Frank Hutter","Noor Awad"],"pdf_url":"https://arxiv.org/pdf/2410.13286v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.14066v2","updated":"2024-10-21T07:50:28Z","published":"2024-10-17T22:28:07Z","title":"Lightweight Correlation-Aware Table Compression","summary":"  The growing adoption of data lakes for managing relational data necessitates\nefficient, open storage formats that provide high scan performance and\ncompetitive compression ratios. While existing formats achieve fast scans\nthrough lightweight encoding techniques, they have reached a plateau in terms\nof minimizing storage footprint. Recently, correlation-aware compression\nschemes have been shown to reduce file sizes further. Yet, current approaches\neither incur significant scan overheads or require manual specification of\ncorrelations, limiting their practicability. We present $\\texttt{Virtual}$, a\nframework that integrates seamlessly with existing open formats to\nautomatically leverage data correlations, achieving substantial compression\ngains while having minimal scan performance overhead. Experiments on data-gov\ndatasets show that $\\texttt{Virtual}$ reduces file sizes by up to 40% compared\nto Apache Parquet.\n","authors":["Mihail Stoian","Alexander van Renen","Jan Kobiolka","Ping-Lin Kuo","Josif Grabocka","Andreas Kipf"],"pdf_url":"https://arxiv.org/pdf/2410.14066v2.pdf","comment":"Third Table Representation Learning Workshop (TRL @ NeurIPS 2024)"},{"id":"http://arxiv.org/abs/2410.15729v1","updated":"2024-10-21T07:44:57Z","published":"2024-10-21T07:44:57Z","title":"Two-stage Learning-to-Defer for Multi-Task Learning","summary":"  The Learning-to-Defer approach has been explored for classification and, more\nrecently, regression tasks separately. Many contemporary learning tasks,\nhowever, involves both classification and regression components. In this paper,\nwe introduce a Learning-to-Defer approach for multi-task learning that\nencompasses both classification and regression tasks. Our two-stage approach\nutilizes a rejector that defers decisions to the most accurate agent among a\npre-trained joint classifier-regressor models and one or more external experts.\nWe show that our surrogate loss is $(\\mathcal{H}, \\mathcal{F}, \\mathcal{R})$\nand Bayes--consistent, ensuring an effective approximation of the optimal\nsolution. Additionally, we derive learning bounds that demonstrate the benefits\nof employing multiple confident experts along a rich model in a two-stage\nlearning framework. Empirical experiments conducted on electronic health record\nanalysis tasks underscore the performance enhancements achieved through our\nmethod.\n","authors":["Montreuil Yannis","Yeo Shu Heng","Carlier Axel","Ng Lai Xing","Ooi Wei Tsang"],"pdf_url":"https://arxiv.org/pdf/2410.15729v1.pdf","comment":"32 pages, 17 main paper"},{"id":"http://arxiv.org/abs/2410.15728v1","updated":"2024-10-21T07:44:44Z","published":"2024-10-21T07:44:44Z","title":"Object-Centric Temporal Consistency via Conditional Autoregressive\n  Inductive Biases","summary":"  Unsupervised object-centric learning from videos is a promising approach\ntowards learning compositional representations that can be applied to various\ndownstream tasks, such as prediction and reasoning. Recently, it was shown that\npretrained Vision Transformers (ViTs) can be useful to learn object-centric\nrepresentations on real-world video datasets. However, while these approaches\nsucceed at extracting objects from the scenes, the slot-based representations\nfail to maintain temporal consistency across consecutive frames in a video,\ni.e. the mapping of objects to slots changes across the video. To address this,\nwe introduce Conditional Autoregressive Slot Attention (CA-SA), a framework\nthat enhances the temporal consistency of extracted object-centric\nrepresentations in video-centric vision tasks. Leveraging an autoregressive\nprior network to condition representations on previous timesteps and a novel\nconsistency loss function, CA-SA predicts future slot representations and\nimposes consistency across frames. We present qualitative and quantitative\nresults showing that our proposed method outperforms the considered baselines\non downstream tasks, such as video prediction and visual question-answering\ntasks.\n","authors":["Cristian Meo","Akihiro Nakano","Mircea Lică","Aniket Didolkar","Masahiro Suzuki","Anirudh Goyal","Mengmi Zhang","Justin Dauwels","Yutaka Matsuo","Yoshua Bengio"],"pdf_url":"https://arxiv.org/pdf/2410.15728v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2407.00843v2","updated":"2024-10-21T07:43:39Z","published":"2024-06-30T22:33:47Z","title":"A Unified Approach to Extract Interpretable Rules from Tree Ensembles\n  via Integer Programming","summary":"  Tree ensemble methods represent a popular machine learning model, known for\ntheir effectiveness in supervised classification and regression tasks. Their\nperformance derives from aggregating predictions of multiple decision trees,\nwhich are renowned for their interpretability properties. However, tree\nensemble methods do not reliably exhibit interpretable output. Our work aims to\nextract an optimized list of rules from a trained tree ensemble, providing the\nuser with a condensed, interpretable model that retains most of the predictive\npower of the full model. Our approach consists of solving a clean and neat set\npartitioning problem formulated through Integer Programming. The proposed\nmethod works with either tabular or time series data, for both classification\nand regression tasks, and does not require parameter tuning under the most\ncommon setting. Through rigorous computational experiments, we offer\nstatistically significant evidence that our method is competitive with other\nrule extraction methods and effectively handles time series.\n","authors":["Lorenzo Bonasera","Emilio Carrizosa"],"pdf_url":"https://arxiv.org/pdf/2407.00843v2.pdf","comment":"- Fixed several typos - Related work have been expanded - Discussion\n  of computational results has been improved for clearness"},{"id":"http://arxiv.org/abs/2410.15723v1","updated":"2024-10-21T07:42:43Z","published":"2024-10-21T07:42:43Z","title":"S-CFE: Simple Counterfactual Explanations","summary":"  We study the problem of finding optimal sparse, manifold-aligned\ncounterfactual explanations for classifiers. Canonically, this can be\nformulated as an optimization problem with multiple non-convex components,\nincluding classifier loss functions and manifold alignment (or\n\\emph{plausibility}) metrics. The added complexity of enforcing\n\\emph{sparsity}, or shorter explanations, complicates the problem further.\nExisting methods often focus on specific models and plausibility measures,\nrelying on convex $\\ell_1$ regularizers to enforce sparsity. In this paper, we\ntackle the canonical formulation using the accelerated proximal gradient (APG)\nmethod, a simple yet efficient first-order procedure capable of handling smooth\nnon-convex objectives and non-smooth $\\ell_p$ (where $0 \\leq p < 1$)\nregularizers. This enables our approach to seamlessly incorporate various\nclassifiers and plausibility measures while producing sparser solutions. Our\nalgorithm only requires differentiable data-manifold regularizers and supports\nbox constraints for bounded feature ranges, ensuring the generated\ncounterfactuals remain \\emph{actionable}. Finally, experiments on real-world\ndatasets demonstrate that our approach effectively produces sparse,\nmanifold-aligned counterfactual explanations while maintaining proximity to the\nfactual data and computational efficiency.\n","authors":["Shpresim Sadiku","Moritz Wagner","Sai Ganesh Nagarajan","Sebastian Pokutta"],"pdf_url":"https://arxiv.org/pdf/2410.15723v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.15721v1","updated":"2024-10-21T07:39:44Z","published":"2024-10-21T07:39:44Z","title":"Learning signals defined on graphs with optimal transport and Gaussian\n  process regression","summary":"  In computational physics, machine learning has now emerged as a powerful\ncomplementary tool to explore efficiently candidate designs in engineering\nstudies. Outputs in such supervised problems are signals defined on meshes, and\na natural question is the extension of general scalar output regression models\nto such complex outputs. Changes between input geometries in terms of both size\nand adjacency structure in particular make this transition non-trivial. In this\nwork, we propose an innovative strategy for Gaussian process regression where\ninputs are large and sparse graphs with continuous node attributes and outputs\nare signals defined on the nodes of the associated inputs. The methodology\nrelies on the combination of regularized optimal transport, dimension reduction\ntechniques, and the use of Gaussian processes indexed by graphs. In addition to\nenabling signal prediction, the main point of our proposal is to come with\nconfidence intervals on node values, which is crucial for uncertainty\nquantification and active learning. Numerical experiments highlight the\nefficiency of the method to solve real problems in fluid dynamics and solid\nmechanics.\n","authors":["Raphaël Carpintero Perez","Sébastien da Veiga","Josselin Garnier","Brian Staber"],"pdf_url":"https://arxiv.org/pdf/2410.15721v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.15716v1","updated":"2024-10-21T07:34:17Z","published":"2024-10-21T07:34:17Z","title":"Traffic Matrix Estimation based on Denoising Diffusion Probabilistic\n  Model","summary":"  The traffic matrix estimation (TME) problem has been widely researched for\ndecades of years. Recent progresses in deep generative models offer new\nopportunities to tackle TME problems in a more advanced way. In this paper, we\nleverage the powerful ability of denoising diffusion probabilistic models\n(DDPMs) on distribution learning, and for the first time adopt DDPM to address\nthe TME problem. To ensure a good performance of DDPM on learning the\ndistributions of TMs, we design a preprocessing module to reduce the dimensions\nof TMs while keeping the data variety of each OD flow. To improve the\nestimation accuracy, we parameterize the noise factors in DDPM and transform\nthe TME problem into a gradient-descent optimization problem. Finally, we\ncompared our method with the state-of-the-art TME methods using two real-world\nTM datasets, the experimental results strongly demonstrate the superiority of\nour method on both TM synthesis and TM estimation.\n","authors":["Xinyu Yuan","Yan Qiao","Pei Zhao","Rongyao Hu","Benchu Zhang"],"pdf_url":"https://arxiv.org/pdf/2410.15716v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.15714v1","updated":"2024-10-21T07:33:42Z","published":"2024-10-21T07:33:42Z","title":"Offline reinforcement learning for job-shop scheduling problems","summary":"  Recent advances in deep learning have shown significant potential for solving\ncombinatorial optimization problems in real-time. Unlike traditional methods,\ndeep learning can generate high-quality solutions efficiently, which is crucial\nfor applications like routing and scheduling. However, existing approaches like\ndeep reinforcement learning (RL) and behavioral cloning have notable\nlimitations, with deep RL suffering from slow learning and behavioral cloning\nrelying solely on expert actions, which can lead to generalization issues and\nneglect of the optimization objective. This paper introduces a novel offline RL\nmethod designed for combinatorial optimization problems with complex\nconstraints, where the state is represented as a heterogeneous graph and the\naction space is variable. Our approach encodes actions in edge attributes and\nbalances expected rewards with the imitation of expert solutions. We\ndemonstrate the effectiveness of this method on job-shop scheduling and\nflexible job-shop scheduling benchmarks, achieving superior performance\ncompared to state-of-the-art techniques.\n","authors":["Imanol Echeverria","Maialen Murua","Roberto Santana"],"pdf_url":"https://arxiv.org/pdf/2410.15714v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2206.10185v2","updated":"2024-10-21T07:30:29Z","published":"2022-06-21T08:39:12Z","title":"Federated Stochastic Approximation under Markov Noise and Heterogeneity:\n  Applications in Reinforcement Learning","summary":"  Since reinforcement learning algorithms are notoriously data-intensive, the\ntask of sampling observations from the environment is usually split across\nmultiple agents. However, transferring these observations from the agents to a\ncentral location can be prohibitively expensive in terms of communication cost,\nand it can also compromise the privacy of each agent's local behavior policy.\nFederated reinforcement learning is a framework in which $N$ agents\ncollaboratively learn a global model, without sharing their individual data and\npolicies. This global model is the unique fixed point of the average of $N$\nlocal operators, corresponding to the $N$ agents. Each agent maintains a local\ncopy of the global model and updates it using locally sampled data. In this\npaper, we show that by careful collaboration of the agents in solving this\njoint fixed point problem, we can find the global model $N$ times faster, also\nknown as linear speedup. We first propose a general framework for federated\nstochastic approximation with Markovian noise and heterogeneity, showing linear\nspeedup in convergence. We then apply this framework to federated reinforcement\nlearning algorithms, examining the convergence of federated on-policy TD,\noff-policy TD, and $Q$-learning.\n","authors":["Sajad Khodadadian","Pranay Sharma","Gauri Joshi","Siva Theja Maguluri"],"pdf_url":"https://arxiv.org/pdf/2206.10185v2.pdf","comment":"80 pages, 0 figure, accepted to ICML 2022 for long presentation"},{"id":"http://arxiv.org/abs/2410.14535v2","updated":"2024-10-21T07:28:25Z","published":"2024-10-18T15:23:29Z","title":"Comparing Differentiable and Dynamic Ray Tracing: Introducing the\n  Multipath Lifetime Map","summary":"  With the increasing presence of dynamic scenarios, such as Vehicle-to-Vehicle\ncommunications, radio propagation modeling tools must adapt to the rapidly\nchanging nature of the radio channel. Recently, both Differentiable and Dynamic\nRay Tracing frameworks have emerged to address these challenges. However, there\nis often confusion about how these approaches differ and which one should be\nused in specific contexts. In this paper, we provide an overview of these two\ntechniques and a comparative analysis against two state-of-the-art tools:\n3DSCAT from UniBo and Sionna from NVIDIA. To provide a more precise\ncharacterization of the scope of these methods, we introduce a novel\nsimulation-based metric, the Multipath Lifetime Map, which enables the\nevaluation of spatial and temporal coherence in radio channels only based on\nthe geometrical description of the environment. Finally, our metrics are\nevaluated on a classic urban street canyon scenario, yielding similar results\nto those obtained from measurement campaigns.\n","authors":["Jérome Eertmans","Enrico Maria Vittuci","Vittorio Degli Esposti","Laurent Jacques","Claude Oestges"],"pdf_url":"https://arxiv.org/pdf/2410.14535v2.pdf","comment":"5 pages, 5 figures, 1 table, submitted to EuCAP 2025"},{"id":"http://arxiv.org/abs/2410.15859v1","updated":"2024-10-21T10:39:05Z","published":"2024-10-21T10:39:05Z","title":"Mesa-Extrapolation: A Weave Position Encoding Method for Enhanced\n  Extrapolation in LLMs","summary":"  Large language models (LLMs), although having revolutionized many fields,\nstill suffer from the challenging extrapolation problem, where the inference\nability of LLMs sharply declines beyond their max training lengths. In this\nwork, we conduct a theoretical analysis to better understand why No Position\nEncoding (NoPE) fails outside its effective range, as well as examining the\npower of Position Encoding (PE) in this context. Our findings reveal that with\nmeticulous weave position, PE can indeed be extended beyond effective range.\nOur theorems establish that LLMs equipped with weave PE can achieve improved\nextrapolation performance without additional cost. Furthermore, we introduce a\nnovel weave PE method, Mesa-Extrapolation, which utilizes a chunk-based\ntriangular attention matrix and applies Stair PE to manage the final chunk.\nThis method not only retains competitive performance but also offers\nsubstantial benefits such as significantly reduced memory demand and faster\ninference speed. Extensive experiments validate the effectiveness of\nMesa-Extrapolation, demonstrating its potential as a scalable solution to\nenhancing LLMs applicative reach.\n","authors":["Xin Ma","Yang Liu","Jingjing Liu","Xiaoxu Ma"],"pdf_url":"https://arxiv.org/pdf/2410.15859v1.pdf","comment":"accepted by NeurIPS 2024"}],"Information Retrieval":[{"id":"http://arxiv.org/abs/2410.16156v1","updated":"2024-10-21T16:21:45Z","published":"2024-10-21T16:21:45Z","title":"Limpeh ga li gong: Challenges in Singlish Annotations","summary":"  Singlish, or Colloquial Singapore English, is a language formed from oral and\nsocial communication within multicultural Singapore. In this work, we work on a\nfundamental Natural Language Processing (NLP) task: Parts-Of-Speech (POS)\ntagging of Singlish sentences. For our analysis, we build a parallel Singlish\ndataset containing direct English translations and POS tags, with translation\nand POS annotation done by native Singlish speakers. Our experiments show that\nautomatic transition- and transformer- based taggers perform with only $\\sim\n80\\%$ accuracy when evaluated against human-annotated POS labels, suggesting\nthat there is indeed room for improvement on computation analysis of the\nlanguage. We provide an exposition of challenges in Singlish annotation: its\ninconsistencies in form and semantics, the highly context-dependent particles\nof the language, its structural unique expressions, and the variation of the\nlanguage on different mediums. Our task definition, resultant labels and\nresults reflects the challenges in analysing colloquial languages formulated\nfrom a variety of dialects, and paves the way for future studies beyond POS\ntagging.\n","authors":["Lynnette Hui Xian Ng","Luo Qi Chan"],"pdf_url":"https://arxiv.org/pdf/2410.16156v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.16148v1","updated":"2024-10-21T16:17:22Z","published":"2024-10-21T16:17:22Z","title":"PODTILE: Facilitating Podcast Episode Browsing with Auto-generated\n  Chapters","summary":"  Listeners of long-form talk-audio content, such as podcast episodes, often\nfind it challenging to understand the overall structure and locate relevant\nsections. A practical solution is to divide episodes into\nchapters--semantically coherent segments labeled with titles and timestamps.\nSince most episodes on our platform at Spotify currently lack creator-provided\nchapters, automating the creation of chapters is essential. Scaling the\nchapterization of podcast episodes presents unique challenges. First, episodes\ntend to be less structured than written texts, featuring spontaneous\ndiscussions with nuanced transitions. Second, the transcripts are usually\nlengthy, averaging about 16,000 tokens, which necessitates efficient processing\nthat can preserve context. To address these challenges, we introduce PODTILE, a\nfine-tuned encoder-decoder transformer to segment conversational data. The\nmodel simultaneously generates chapter transitions and titles for the input\ntranscript. To preserve context, each input text is augmented with global\ncontext, including the episode's title, description, and previous chapter\ntitles. In our intrinsic evaluation, PODTILE achieved an 11% improvement in\nROUGE score over the strongest baseline. Additionally, we provide insights into\nthe practical benefits of auto-generated chapters for listeners navigating\nepisode content. Our findings indicate that auto-generated chapters serve as a\nuseful tool for engaging with less popular podcasts. Finally, we present\nempirical evidence that using chapter titles can enhance effectiveness of\nsparse retrieval in search tasks.\n","authors":["Azin Ghazimatin","Ekaterina Garmash","Gustavo Penha","Kristen Sheets","Martin Achenbach","Oguz Semerci","Remi Galvez","Marcus Tannenberg","Sahitya Mantravadi","Divya Narayanan","Ofeliya Kalaydzhyan","Douglas Cole","Ben Carterette","Ann Clifton","Paul N. Bennett","Claudia Hauff","Mounia Lalmas"],"pdf_url":"https://arxiv.org/pdf/2410.16148v1.pdf","comment":"9 pages, 4 figures, CIKM industry track 2024"},{"id":"http://arxiv.org/abs/2410.16080v1","updated":"2024-10-21T14:58:38Z","published":"2024-10-21T14:58:38Z","title":"Unleashing the Potential of Multi-Channel Fusion in Retrieval for\n  Personalized Recommendations","summary":"  Recommender systems (RS) are pivotal in managing information overload in\nmodern digital services. A key challenge in RS is efficiently processing vast\nitem pools to deliver highly personalized recommendations under strict latency\nconstraints. Multi-stage cascade ranking addresses this by employing\ncomputationally efficient retrieval methods to cover diverse user interests,\nfollowed by more precise ranking models to refine the results. In the retrieval\nstage, multi-channel retrieval is often used to generate distinct item subsets\nfrom different candidate generators, leveraging the complementary strengths of\nthese methods to maximize coverage. However, forwarding all retrieved items\noverwhelms downstream rankers, necessitating truncation. Despite advancements\nin individual retrieval methods, multi-channel fusion, the process of\nefficiently merging multi-channel retrieval results, remains underexplored. We\nare the first to identify and systematically investigate multi-channel fusion\nin the retrieval stage. Current industry practices often rely on heuristic\napproaches and manual designs, which often lead to suboptimal performance.\nMoreover, traditional gradient-based methods like SGD are unsuitable for this\ntask due to the non-differentiable nature of the selection process. In this\npaper, we explore advanced channel fusion strategies by assigning\nsystematically optimized weights to each channel. We utilize black-box\noptimization techniques, including the Cross Entropy Method and Bayesian\nOptimization for global weight optimization, alongside policy gradient-based\napproaches for personalized merging. Our methods enhance both personalization\nand flexibility, achieving significant performance improvements across multiple\ndatasets and yielding substantial gains in real-world deployments, offering a\nscalable solution for optimizing multi-channel fusion in retrieval.\n","authors":["Junjie Huang","Jiarui Qin","Jianghao Lin","Ziming Feng","Yong Yu","Weinan Zhang"],"pdf_url":"https://arxiv.org/pdf/2410.16080v1.pdf","comment":"12 pages, 8 figures"},{"id":"http://arxiv.org/abs/2410.15996v1","updated":"2024-10-21T13:27:29Z","published":"2024-10-21T13:27:29Z","title":"Surprising Patterns in Musical Influence Networks","summary":"  Analyzing musical influence networks, such as those formed by artist\ninfluence or sampling, has provided valuable insights into contemporary Western\nmusic. Here, computational methods like centrality rankings help identify\ninfluential artists. However, little attention has been given to how influence\nchanges over time. In this paper, we apply Bayesian Surprise to track the\nevolution of musical influence networks. Using two networks -- one of artist\ninfluence and another of covers, remixes, and samples -- our results reveal\nsignificant periods of change in network structure. Additionally, we\ndemonstrate that Bayesian Surprise is a flexible framework for testing various\nhypotheses on network evolution with real-world data.\n","authors":["Flavio Figueiredo","Tales Panoutsos","Nazareno Andrade"],"pdf_url":"https://arxiv.org/pdf/2410.15996v1.pdf","comment":"To appear in the Latin American Musical Information Retrieval\n  Workshop"},{"id":"http://arxiv.org/abs/2409.14038v3","updated":"2024-10-21T12:54:33Z","published":"2024-09-21T06:49:34Z","title":"OAEI-LLM: A Benchmark Dataset for Understanding Large Language Model\n  Hallucinations in Ontology Matching","summary":"  Hallucinations of large language models (LLMs) commonly occur in\ndomain-specific downstream tasks, with no exception in ontology matching (OM).\nThe prevalence of using LLMs for OM raises the need for benchmarks to better\nunderstand LLM hallucinations. The OAEI-LLM dataset is an extended version of\nthe Ontology Alignment Evaluation Initiative (OAEI) datasets that evaluate\nLLM-specific hallucinations in OM tasks. We outline the methodology used in\ndataset construction and schema extension, and provide examples of potential\nuse cases.\n","authors":["Zhangcheng Qiang","Kerry Taylor","Weiqing Wang","Jing Jiang"],"pdf_url":"https://arxiv.org/pdf/2409.14038v3.pdf","comment":"5 pages, 1 figure, 1 table"},{"id":"http://arxiv.org/abs/2410.15944v1","updated":"2024-10-21T12:21:49Z","published":"2024-10-21T12:21:49Z","title":"Developing Retrieval Augmented Generation (RAG) based LLM Systems from\n  PDFs: An Experience Report","summary":"  This paper presents an experience report on the development of Retrieval\nAugmented Generation (RAG) systems using PDF documents as the primary data\nsource. The RAG architecture combines generative capabilities of Large Language\nModels (LLMs) with the precision of information retrieval. This approach has\nthe potential to redefine how we interact with and augment both structured and\nunstructured knowledge in generative models to enhance transparency, accuracy,\nand contextuality of responses. The paper details the end-to-end pipeline, from\ndata collection, preprocessing, to retrieval indexing and response generation,\nhighlighting technical challenges and practical solutions. We aim to offer\ninsights to researchers and practitioners developing similar systems using two\ndistinct approaches: OpenAI's Assistant API with GPT Series and Llama's\nopen-source models. The practical implications of this research lie in\nenhancing the reliability of generative AI systems in various sectors where\ndomain-specific knowledge and real-time information retrieval is important. The\nPython code used in this work is also available at:\nhttps://github.com/GPT-Laboratory/RAG-LLM-Development-Guidebook-from-PDFs.\n","authors":["Ayman Asad Khan","Md Toufique Hasan","Kai Kristian Kemell","Jussi Rasku","Pekka Abrahamsson"],"pdf_url":"https://arxiv.org/pdf/2410.15944v1.pdf","comment":"36 pages, 8 figures, 2 tables, and python code snippets"},{"id":"http://arxiv.org/abs/2410.15930v1","updated":"2024-10-21T11:59:14Z","published":"2024-10-21T11:59:14Z","title":"Centrality-aware Product Retrieval and Ranking","summary":"  This paper addresses the challenge of improving user experience on e-commerce\nplatforms by enhancing product ranking relevant to users' search queries.\nAmbiguity and complexity of user queries often lead to a mismatch between the\nuser's intent and retrieved product titles or documents. Recent approaches have\nproposed the use of Transformer-based models, which need millions of annotated\nquery-title pairs during the pre-training stage, and this data often does not\ntake user intent into account. To tackle this, we curate samples from existing\ndatasets at eBay, manually annotated with buyer-centric relevance scores and\ncentrality scores, which reflect how well the product title matches the users'\nintent. We introduce a User-intent Centrality Optimization (UCO) approach for\nexisting models, which optimises for the user intent in semantic product\nsearch. To that end, we propose a dual-loss based optimisation to handle hard\nnegatives, i.e., product titles that are semantically relevant but do not\nreflect the user's intent. Our contributions include curating challenging\nevaluation sets and implementing UCO, resulting in significant product ranking\nefficiency improvements observed for different evaluation metrics. Our work\naims to ensure that the most buyer-centric titles for a query are ranked\nhigher, thereby, enhancing the user experience on e-commerce platforms.\n","authors":["Hadeel Saadany","Swapnil Bhosale","Samarth Agrawal","Diptesh Kanojia","Constantin Orasan","Zhe Wu"],"pdf_url":"https://arxiv.org/pdf/2410.15930v1.pdf","comment":"EMNLP 2024: Industry track"},{"id":"http://arxiv.org/abs/2410.15884v1","updated":"2024-10-21T11:02:18Z","published":"2024-10-21T11:02:18Z","title":"Using GPT Models for Qualitative and Quantitative News Analytics in the\n  2024 US Presidental Election Process","summary":"  The paper considers an approach of using Google Search API and GPT-4o model\nfor qualitative and quantitative analyses of news through retrieval-augmented\ngeneration (RAG). This approach was applied to analyze news about the 2024 US\npresidential election process. Different news sources for different time\nperiods have been analyzed. Quantitative scores generated by GPT model have\nbeen analyzed using Bayesian regression to derive trend lines. The\ndistributions found for the regression parameters allow for the analysis of\nuncertainty in the election process. The obtained results demonstrate that\nusing the GPT models for news analysis, one can get informative analytics and\nprovide key insights that can be applied in further analyses of election\nprocesses.\n","authors":["Bohdan M. Pavlyshenko"],"pdf_url":"https://arxiv.org/pdf/2410.15884v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.15801v1","updated":"2024-10-21T09:18:30Z","published":"2024-10-21T09:18:30Z","title":"Improve Dense Passage Retrieval with Entailment Tuning","summary":"  Retrieval module can be plugged into many downstream NLP tasks to improve\ntheir performance, such as open-domain question answering and\nretrieval-augmented generation. The key to a retrieval system is to calculate\nrelevance scores to query and passage pairs. However, the definition of\nrelevance is often ambiguous. We observed that a major class of relevance\naligns with the concept of entailment in NLI tasks. Based on this observation,\nwe designed a method called entailment tuning to improve the embedding of dense\nretrievers. Specifically, we unify the form of retrieval data and NLI data\nusing existence claim as a bridge. Then, we train retrievers to predict the\nclaims entailed in a passage with a variant task of masked prediction. Our\nmethod can be efficiently plugged into current dense retrieval methods, and\nexperiments show the effectiveness of our method.\n","authors":["Lu Dai","Hao Liu","Hui Xiong"],"pdf_url":"https://arxiv.org/pdf/2410.15801v1.pdf","comment":"EMNLP 2024 Main"},{"id":"http://arxiv.org/abs/2410.06062v3","updated":"2024-10-21T09:13:48Z","published":"2024-10-08T14:09:12Z","title":"LLM-based SPARQL Query Generation from Natural Language over Federated\n  Knowledge Graphs","summary":"  We introduce a Retrieval-Augmented Generation (RAG) system for translating\nuser questions into accurate federated SPARQL queries over bioinformatics\nknowledge graphs (KGs) leveraging Large Language Models (LLMs). To enhance\naccuracy and reduce hallucinations in query generation, our system utilises\nmetadata from the KGs, including query examples and schema information, and\nincorporates a validation step to correct generated queries. The system is\navailable online at chat.expasy.org.\n","authors":["Vincent Emonet","Jerven Bolleman","Severine Duvaud","Tarcisio Mendes de Farias","Ana Claudia Sima"],"pdf_url":"https://arxiv.org/pdf/2410.06062v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.12400v2","updated":"2024-10-21T09:05:47Z","published":"2024-10-16T09:28:58Z","title":"QUIDS: Query Intent Generation via Dual Space Modeling","summary":"  Query understanding is a crucial component of Information Retrieval (IR),\naimed at identifying the underlying search intent of textual queries. However,\nmost existing approaches oversimplify this task into query classification or\nclustering, which fails to fully capture the nuanced intent behind the query.\nIn this paper, we address the task of query intent generation: to automatically\ngenerate detailed and precise intent descriptions for search queries using\nrelevant and irrelevant documents given a query. These intent descriptions can\nhelp users understand why the search engine considered the top-ranked documents\nrelevant, and provide more transparency to the retrieval process. We propose a\ndual-space model that uses semantic relevance and irrelevance information in\nthe returned documents to explain the understanding of the query intent.\nSpecifically, in the encoding process, we project, separate, and distinguish\nrelevant and irrelevant documents in the representation space. Then, we\nintroduce a semantic decoupling model in the novel disentangling space, where\nthe semantics of irrelevant information are removed from the relevant space,\nensuring that only the essential and relevant intent is captured. This process\nrefines the understanding of the query and provides more accurate explanations\nfor the search results. Experiments on benchmark data demonstrate that our\nmethods produce high-quality query intent descriptions, outperforming existing\nmethods for this task, as well as state-of-the-art query-based summarization\nmethods. A token-level visualization of attention scores reveals that our model\neffectively reduces the focus on irrelevant intent topics. Our findings open up\npromising research and application directions for query intent generation,\nparticularly in exploratory search.\n","authors":["Yumeng Wang","Xiuying Chen","Suzan Verberne"],"pdf_url":"https://arxiv.org/pdf/2410.12400v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.15737v1","updated":"2024-10-21T07:56:45Z","published":"2024-10-21T07:56:45Z","title":"Who's Who: Large Language Models Meet Knowledge Conflicts in Practice","summary":"  Retrieval-augmented generation (RAG) methods are viable solutions for\naddressing the static memory limits of pre-trained language models.\nNevertheless, encountering conflicting sources of information within the\nretrieval context is an inevitable practical challenge. In such situations, the\nlanguage models are recommended to transparently inform users about the\nconflicts rather than autonomously deciding what to present based on their\ninherent biases. To analyze how current large language models (LLMs) align with\nour recommendation, we introduce WhoQA, a public benchmark dataset to examine\nmodel's behavior in knowledge conflict situations. We induce conflicts by\nasking about a common property among entities having the same name, resulting\nin questions with up to 8 distinctive answers. WhoQA evaluation set includes 5K\nquestions across 13 Wikidata property types and 150K Wikipedia entities. Our\nexperiments show that despite the simplicity of WhoQA questions, knowledge\nconflicts significantly degrades LLMs' performance in RAG settings.\n","authors":["Quang Hieu Pham","Hoang Ngo","Anh Tuan Luu","Dat Quoc Nguyen"],"pdf_url":"https://arxiv.org/pdf/2410.15737v1.pdf","comment":"Accepted to EMNLP 2024 Findings"},{"id":"http://arxiv.org/abs/2410.14066v2","updated":"2024-10-21T07:50:28Z","published":"2024-10-17T22:28:07Z","title":"Lightweight Correlation-Aware Table Compression","summary":"  The growing adoption of data lakes for managing relational data necessitates\nefficient, open storage formats that provide high scan performance and\ncompetitive compression ratios. While existing formats achieve fast scans\nthrough lightweight encoding techniques, they have reached a plateau in terms\nof minimizing storage footprint. Recently, correlation-aware compression\nschemes have been shown to reduce file sizes further. Yet, current approaches\neither incur significant scan overheads or require manual specification of\ncorrelations, limiting their practicability. We present $\\texttt{Virtual}$, a\nframework that integrates seamlessly with existing open formats to\nautomatically leverage data correlations, achieving substantial compression\ngains while having minimal scan performance overhead. Experiments on data-gov\ndatasets show that $\\texttt{Virtual}$ reduces file sizes by up to 40% compared\nto Apache Parquet.\n","authors":["Mihail Stoian","Alexander van Renen","Jan Kobiolka","Ping-Lin Kuo","Josif Grabocka","Andreas Kipf"],"pdf_url":"https://arxiv.org/pdf/2410.14066v2.pdf","comment":"Third Table Representation Learning Workshop (TRL @ NeurIPS 2024)"},{"id":"http://arxiv.org/abs/2410.15586v1","updated":"2024-10-21T02:11:48Z","published":"2024-10-21T02:11:48Z","title":"Automatic Search of Multiword Place Names on Historical Maps","summary":"  Historical maps are invaluable sources of information about the past, and\nscanned historical maps are increasingly accessible in online libraries. To\nretrieve maps from these large libraries that contain specific places of\ninterest, previous work has applied computer vision techniques to recognize\nwords on historical maps, enabling searches for maps that contain specific\nplace names. However, searching for multiword place names is challenging due to\ncomplex layouts of text labels on historical maps. This paper proposes an\nefficient query method for searching a given multiword place name on historical\nmaps. Using existing methods to recognize words on historical maps, we link\nsingle-word text labels into potential multiword phrases by constructing\nminimum spanning trees. These trees aim to link pairs of text labels that are\nspatially close and have similar height, angle, and capitalization. We then\nquery these trees for the given multiword place name. We evaluate the proposed\nmethod in two experiments: 1) to evaluate the accuracy of the minimum spanning\ntree approach at linking multiword place names and 2) to evaluate the number\nand time range of maps retrieved by the query approach. The resulting maps\nreveal how places using multiword names have changed on a large number of maps\nfrom across history.\n","authors":["Rhett Olson","Jina Kim","Yao-Yi Chiang"],"pdf_url":"https://arxiv.org/pdf/2410.15586v1.pdf","comment":"4 pages, 4 figures, and 2 tables. To be published in proceedings ACM\n  SIGSPATIAL 2024 GeoSearch Workshop"},{"id":"http://arxiv.org/abs/2410.15576v1","updated":"2024-10-21T01:54:46Z","published":"2024-10-21T01:54:46Z","title":"A Survey of Conversational Search","summary":"  As a cornerstone of modern information access, search engines have become\nindispensable in everyday life. With the rapid advancements in AI and natural\nlanguage processing (NLP) technologies, particularly large language models\n(LLMs), search engines have evolved to support more intuitive and intelligent\ninteractions between users and systems. Conversational search, an emerging\nparadigm for next-generation search engines, leverages natural language\ndialogue to facilitate complex and precise information retrieval, thus\nattracting significant attention. Unlike traditional keyword-based search\nengines, conversational search systems enhance user experience by supporting\nintricate queries, maintaining context over multi-turn interactions, and\nproviding robust information integration and processing capabilities. Key\ncomponents such as query reformulation, search clarification, conversational\nretrieval, and response generation work in unison to enable these sophisticated\ninteractions. In this survey, we explore the recent advancements and potential\nfuture directions in conversational search, examining the critical modules that\nconstitute a conversational search system. We highlight the integration of LLMs\nin enhancing these systems and discuss the challenges and opportunities that\nlie ahead in this dynamic field. Additionally, we provide insights into\nreal-world applications and robust evaluations of current conversational search\nsystems, aiming to guide future research and development in conversational\nsearch.\n","authors":["Fengran Mo","Kelong Mao","Ziliang Zhao","Hongjin Qian","Haonan Chen","Yiruo Cheng","Xiaoxi Li","Yutao Zhu","Zhicheng Dou","Jian-Yun Nie"],"pdf_url":"https://arxiv.org/pdf/2410.15576v1.pdf","comment":"35 pages, 8 figures, continue to update"},{"id":"http://arxiv.org/abs/2410.16458v1","updated":"2024-10-21T19:34:40Z","published":"2024-10-21T19:34:40Z","title":"STAR: A Simple Training-free Approach for Recommendations using Large\n  Language Models","summary":"  Recent progress in large language models (LLMs) offers promising new\napproaches for recommendation system (RecSys) tasks. While the current\nstate-of-the-art methods rely on fine-tuning LLMs to achieve optimal results,\nthis process is costly and introduces significant engineering complexities.\nConversely, methods that bypass fine-tuning and use LLMs directly are less\nresource-intensive but often fail to fully capture both semantic and\ncollaborative information, resulting in sub-optimal performance compared to\ntheir fine-tuned counterparts. In this paper, we propose a Simple Training-free\nApproach for Recommendation (STAR), a framework that utilizes LLMs and can be\napplied to various recommendation tasks without the need for fine-tuning. Our\napproach involves a retrieval stage that uses semantic embeddings from LLMs\ncombined with collaborative user information to retrieve candidate items. We\nthen apply an LLM for pairwise ranking to enhance next-item prediction.\nExperimental results on the Amazon Review dataset show competitive performance\nfor next item prediction, even with our retrieval stage alone. Our full method\nachieves Hits@10 performance of +23.8% on Beauty, +37.5% on Toys and Games, and\n-1.8% on Sports and Outdoors relative to the best supervised models. This\nframework offers an effective alternative to traditional supervised models,\nhighlighting the potential of LLMs in recommendation systems without extensive\ntraining or custom architectures.\n","authors":["Dong-Ho Lee","Adam Kraft","Long Jin","Nikhil Mehta","Taibai Xu","Lichan Hong","Ed H. Chi","Xinyang Yi"],"pdf_url":"https://arxiv.org/pdf/2410.16458v1.pdf","comment":null}]},"2024-10-19T00:00:00Z":{"Information Retrieval":[{"id":"http://arxiv.org/abs/2406.16350v3","updated":"2024-10-19T18:04:52Z","published":"2024-06-24T06:46:32Z","title":"A Survey on Intent-aware Recommender Systems","summary":"  Many modern online services feature personalized recommendations. A central\nchallenge when providing such recommendations is that the reason why an\nindividual user accesses the service may change from visit to visit or even\nduring an ongoing usage session. To be effective, a recommender system should\ntherefore aim to take the users' probable intent of using the service at a\ncertain point in time into account. In recent years, researchers have thus\nstarted to address this challenge by incorporating intent-awareness into\nrecommender systems. Correspondingly, a number of technical approaches were put\nforward, including diversification techniques, intent prediction models or\nlatent intent modeling approaches. In this paper, we survey and categorize\nexisting approaches to building the next generation of Intent-Aware Recommender\nSystems (IARS). Based on an analysis of current evaluation practices, we\noutline open gaps and possible future directions in this area, which in\nparticular include the consideration of additional interaction signals and\ncontextual information to further improve the effectiveness of such systems.\n","authors":["Dietmar Jannach","Markus Zanker"],"pdf_url":"https://arxiv.org/pdf/2406.16350v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.03071v2","updated":"2024-10-19T20:40:34Z","published":"2024-10-04T01:28:56Z","title":"Enhancing Short-Text Topic Modeling with LLM-Driven Context Expansion\n  and Prefix-Tuned VAEs","summary":"  Topic modeling is a powerful technique for uncovering hidden themes within a\ncollection of documents. However, the effectiveness of traditional topic models\noften relies on sufficient word co-occurrence, which is lacking in short texts.\nTherefore, existing approaches, whether probabilistic or neural, frequently\nstruggle to extract meaningful patterns from such data, resulting in incoherent\ntopics. To address this challenge, we propose a novel approach that leverages\nlarge language models (LLMs) to extend short texts into more detailed sequences\nbefore applying topic modeling. To further improve the efficiency and solve the\nproblem of semantic inconsistency from LLM-generated texts, we propose to use\nprefix tuning to train a smaller language model coupled with a variational\nautoencoder for short-text topic modeling. Our method significantly improves\nshort-text topic modeling performance, as demonstrated by extensive experiments\non real-world datasets with extreme data sparsity, outperforming current\nstate-of-the-art topic models.\n","authors":["Pritom Saha Akash","Kevin Chen-Chuan Chang"],"pdf_url":"https://arxiv.org/pdf/2410.03071v2.pdf","comment":"EMNLP Findings 2024. arXiv admin note: substantial text overlap with\n  arXiv:2310.15420"},{"id":"http://arxiv.org/abs/2410.15174v1","updated":"2024-10-19T18:28:06Z","published":"2024-10-19T18:28:06Z","title":"Crafting Tomorrow: The Influence of Design Choices on Fresh Content in\n  Social Media Recommendation","summary":"  The rise in popularity of social media platforms, has resulted in millions of\nnew, content pieces being created every day. This surge in content creation\nunderscores the need to pay attention to our design choices as they can greatly\nimpact how long content remains relevant. In today's landscape where regularly\nrecommending new content is crucial, particularly in the absence of detailed\ninformation, a variety of factors such as UI features, algorithms and system\nsettings contribute to shaping the journey of content across the platform.\nWhile previous research has focused on how new content affects users'\nexperiences, this study takes a different approach by analyzing these decisions\nconsidering the content itself.\n  Through a series of carefully crafted experiments we explore how seemingly\nsmall decisions can influence the longevity of content, measured by metrics\nlike Content Progression (CVP) and Content Survival (CSR). We also emphasize\nthe importance of recognizing the stages that content goes through underscoring\nthe need to tailor strategies for each stage as a one size fits all approach\nmay not be effective. Additionally we argue for a departure from traditional\nexperimental setups in the study of content lifecycles, to avoid potential\nmisunderstandings while proposing advanced techniques, to achieve greater\nprecision and accuracy in the evaluation process.\n","authors":["Srijan Saket","Mohit Agarwal","Rishabh Mehrotra"],"pdf_url":"https://arxiv.org/pdf/2410.15174v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.15145v1","updated":"2024-10-19T16:12:22Z","published":"2024-10-19T16:12:22Z","title":"Mining Asymmetric Intertextuality","summary":"  This paper introduces a new task in Natural Language Processing (NLP) and\nDigital Humanities (DH): Mining Asymmetric Intertextuality. Asymmetric\nintertextuality refers to one-sided relationships between texts, where one text\ncites, quotes, or borrows from another without reciprocation. These\nrelationships are common in literature and historical texts, where a later work\nreferences aclassical or older text that remain static.\n  We propose a scalable and adaptive approach for mining asymmetric\nintertextuality, leveraging a split-normalize-merge paradigm. In this approach,\ndocuments are split into smaller chunks, normalized into structured data using\nLLM-assisted metadata extraction, and merged during querying to detect both\nexplicit and implicit intertextual relationships. Our system handles\nintertextuality at various levels, from direct quotations to paraphrasing and\ncross-document influence, using a combination of metadata filtering, vector\nsimilarity search, and LLM-based verification.\n  This method is particularly well-suited for dynamically growing corpora, such\nas expanding literary archives or historical databases. By enabling the\ncontinuous integration of new documents, the system can scale efficiently,\nmaking it highly valuable for digital humanities practitioners in literacy\nstudies, historical research and related fields.\n","authors":["Pak Kin Lau","Stuart Michael McManus"],"pdf_url":"https://arxiv.org/pdf/2410.15145v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.03538v2","updated":"2024-10-19T13:51:20Z","published":"2024-09-15T06:40:38Z","title":"Dreaming User Multimodal Representation Guided by The Platonic\n  Representation Hypothesis for Micro-Video Recommendation","summary":"  The proliferation of online micro-video platforms has underscored the\nnecessity for advanced recommender systems to mitigate information overload and\ndeliver tailored content. Despite advancements, accurately and promptly\ncapturing dynamic user interests remains a formidable challenge. Inspired by\nthe Platonic Representation Hypothesis, which posits that different data\nmodalities converge towards a shared statistical model of reality, we introduce\nDreamUMM (Dreaming User Multi-Modal Representation), a novel approach\nleveraging user historical behaviors to create real-time user representation in\na multimoda space. DreamUMM employs a closed-form solution correlating user\nvideo preferences with multimodal similarity, hypothesizing that user interests\ncan be effectively represented in a unified multimodal space. Additionally, we\npropose Candidate-DreamUMM for scenarios lacking recent user behavior data,\ninferring interests from candidate videos alone. Extensive online A/B tests\ndemonstrate significant improvements in user engagement metrics, including\nactive days and play count. The successful deployment of DreamUMM in two\nmicro-video platforms with hundreds of millions of daily active users,\nillustrates its practical efficacy and scalability in personalized micro-video\ncontent delivery. Our work contributes to the ongoing exploration of\nrepresentational convergence by providing empirical evidence supporting the\npotential for user interest representations to reside in a multimodal space.\n","authors":["Chengzhi Lin","Hezheng Lin","Shuchang Liu","Cangguang Ruan","LingJing Xu","Dezhao Yang","Chuyuan Wang","Yongqi Liu"],"pdf_url":"https://arxiv.org/pdf/2410.03538v2.pdf","comment":"4 Figure; 2 Table"},{"id":"http://arxiv.org/abs/2410.15098v1","updated":"2024-10-19T13:15:36Z","published":"2024-10-19T13:15:36Z","title":"Incorporating Group Prior into Variational Inference for Tail-User\n  Behavior Modeling in CTR Prediction","summary":"  User behavior modeling -- which aims to extract user interests from\nbehavioral data -- has shown great power in Click-through rate (CTR)\nprediction, a key component in recommendation systems. Recently,\nattention-based algorithms have become a promising direction, as attention\nmechanisms emphasize the relevant interactions from rich behaviors. However,\nthe methods struggle to capture the preferences of tail users with sparse\ninteraction histories. To address the problem, we propose a novel variational\ninference approach, namely Group Prior Sampler Variational Inference (GPSVI),\nwhich introduces group preferences as priors to refine latent user interests\nfor tail users. In GPSVI, the extent of adjustments depends on the estimated\nuncertainty of individual preference modeling. In addition, We further enhance\nthe expressive power of variational inference by a volume-preserving flow. An\nappealing property of the GPSVI method is its ability to revert to traditional\nattention for head users with rich behavioral data while consistently enhancing\nperformance for long-tail users with sparse behaviors. Rigorous analysis and\nextensive experiments demonstrate that GPSVI consistently improves the\nperformance of tail users. Moreover, online A/B testing on a large-scale\nreal-world recommender system further confirms the effectiveness of our\nproposed approach.\n","authors":["Han Xu","Taoxing Pan","Zhiqiang Liu","Xiaoxiao Xu","Lantao Hu"],"pdf_url":"https://arxiv.org/pdf/2410.15098v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.15026v1","updated":"2024-10-19T07:49:21Z","published":"2024-10-19T07:49:21Z","title":"A Recommendation Model Utilizing Separation Embedding and Self-Attention\n  for Feature Mining","summary":"  With the explosive growth of Internet data, users are facing the problem of\ninformation overload, which makes it a challenge to efficiently obtain the\nrequired resources. Recommendation systems have emerged in this context. By\nfiltering massive amounts of information, they provide users with content that\nmeets their needs, playing a key role in scenarios such as advertising\nrecommendation and product recommendation. However, traditional click-through\nrate prediction and TOP-K recommendation mechanisms are gradually unable to\nmeet the recommendations needs in modern life scenarios due to high\ncomputational complexity, large memory consumption, long feature selection\ntime, and insufficient feature interaction. This paper proposes a\nrecommendations system model based on a separation embedding cross-network. The\nmodel uses an embedding neural network layer to transform sparse feature\nvectors into dense embedding vectors, and can independently perform feature\ncross operations on different dimensions, thereby improving the accuracy and\ndepth of feature mining. Experimental results show that the model shows\nstronger adaptability and higher prediction accuracy in processing complex data\nsets, effectively solving the problems existing in existing models.\n","authors":["Wenyi Liu","Rui Wang","Yuanshuai Luo","Jianjun Wei","Zihao Zhao","Junming Huang"],"pdf_url":"https://arxiv.org/pdf/2410.15026v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.15016v1","updated":"2024-10-19T07:08:40Z","published":"2024-10-19T07:08:40Z","title":"Transit Pulse: Utilizing Social Media as a Source for Customer Feedback\n  and Information Extraction with Large Language Model","summary":"  Users of the transit system flood social networks daily with messages that\ncontain valuable insights crucial for improving service quality. These posts\nhelp transit agencies quickly identify emerging issues. Parsing topics and\nsentiments is key to gaining comprehensive insights to foster service\nexcellence. However, the volume of messages makes manual analysis impractical,\nand standard NLP techniques like Term Frequency-Inverse Document Frequency\n(TF-IDF) fall short in nuanced interpretation. Traditional sentiment analysis\nseparates topics and sentiments before integrating them, often missing the\ninteraction between them. This incremental approach complicates classification\nand reduces analytical productivity. To address these challenges, we propose a\nnovel approach to extracting and analyzing transit-related information,\nincluding sentiment and sarcasm detection, identification of unusual system\nproblems, and location data from social media. Our method employs Large\nLanguage Models (LLM), specifically Llama 3, for a streamlined analysis free\nfrom pre-established topic labels. To enhance the model's domain-specific\nknowledge, we utilize Retrieval-Augmented Generation (RAG), integrating\nexternal knowledge sources into the information extraction pipeline. We\nvalidated our method through extensive experiments comparing its performance\nwith traditional NLP approaches on user tweet data from the real world transit\nsystem. Our results demonstrate the potential of LLMs to transform social media\ndata analysis in the public transit domain, providing actionable insights and\nenhancing transit agencies' responsiveness by extracting a broader range of\ninformation.\n","authors":["Jiahao Wang","Amer Shalaby"],"pdf_url":"https://arxiv.org/pdf/2410.15016v1.pdf","comment":"17 pages, 21 figures"},{"id":"http://arxiv.org/abs/2410.14969v1","updated":"2024-10-19T04:20:23Z","published":"2024-10-19T04:20:23Z","title":"Visual Navigation of Digital Libraries: Retrieval and Classification of\n  Images in the National Library of Norway's Digitised Book Collection","summary":"  Digital tools for text analysis have long been essential for the\nsearchability and accessibility of digitised library collections. Recent\ncomputer vision advances have introduced similar capabilities for visual\nmaterials, with deep learning-based embeddings showing promise for analysing\nvisual heritage. Given that many books feature visuals in addition to text,\ntaking advantage of these breakthroughs is critical to making library\ncollections open and accessible. In this work, we present a proof-of-concept\nimage search application for exploring images in the National Library of\nNorway's pre-1900 books, comparing Vision Transformer (ViT), Contrastive\nLanguage-Image Pre-training (CLIP), and Sigmoid loss for Language-Image\nPre-training (SigLIP) embeddings for image retrieval and classification. Our\nresults show that the application performs well for exact image retrieval, with\nSigLIP embeddings slightly outperforming CLIP and ViT in both retrieval and\nclassification tasks. Additionally, SigLIP-based image classification can aid\nin cleaning image datasets from a digitisation pipeline.\n","authors":["Marie Roald","Magnus Breder Birkenes","Lars Gunnarsønn Bagøien Johnsen"],"pdf_url":"https://arxiv.org/pdf/2410.14969v1.pdf","comment":"13 pages, 2 figures, 4 tables, Accepted to the 2024 Computational\n  Humanities Research Conference (CHR)"},{"id":"http://arxiv.org/abs/2404.18424v3","updated":"2024-10-19T01:07:37Z","published":"2024-04-29T04:51:30Z","title":"PromptReps: Prompting Large Language Models to Generate Dense and Sparse\n  Representations for Zero-Shot Document Retrieval","summary":"  Utilizing large language models (LLMs) for zero-shot document ranking is done\nin one of two ways: (1) prompt-based re-ranking methods, which require no\nfurther training but are only feasible for re-ranking a handful of candidate\ndocuments due to computational costs; and (2) unsupervised contrastive trained\ndense retrieval methods, which can retrieve relevant documents from the entire\ncorpus but require a large amount of paired text data for contrastive training.\nIn this paper, we propose PromptReps, which combines the advantages of both\ncategories: no need for training and the ability to retrieve from the whole\ncorpus. Our method only requires prompts to guide an LLM to generate query and\ndocument representations for effective document retrieval. Specifically, we\nprompt the LLMs to represent a given text using a single word, and then use the\nlast token's hidden states and the corresponding logits associated with the\nprediction of the next token to construct a hybrid document retrieval system.\nThe retrieval system harnesses both dense text embedding and sparse\nbag-of-words representations given by the LLM. Our experimental evaluation on\nthe MSMARCO, TREC deep learning and BEIR zero-shot document retrieval datasets\nillustrates that this simple prompt-based LLM retrieval method can achieve a\nsimilar or higher retrieval effectiveness than state-of-the-art LLM embedding\nmethods that are trained with large amounts of unsupervised data, especially\nwhen using a larger LLM.\n","authors":["Shengyao Zhuang","Xueguang Ma","Bevan Koopman","Jimmy Lin","Guido Zuccon"],"pdf_url":"https://arxiv.org/pdf/2404.18424v3.pdf","comment":"EMNLP2024 main"}]},"2024-10-20T00:00:00Z":{"Information Retrieval":[{"id":"http://arxiv.org/abs/2410.10360v2","updated":"2024-10-20T07:53:50Z","published":"2024-10-14T10:26:57Z","title":"Parenting: Optimizing Knowledge Selection of Retrieval-Augmented\n  Language Models with Parameter Decoupling and Tailored Tuning","summary":"  Retrieval-Augmented Generation (RAG) offers an effective solution to the\nissues faced by Large Language Models (LLMs) in hallucination generation and\nknowledge obsolescence by incorporating externally retrieved knowledge.\nHowever, existing methods lack effective control mechanisms for integrating\ninternal and external knowledge. Inspired by human cognitive processes, we\npropose Parenting, a novel framework that decouples, identifies, and\npurposefully optimizes parameter subspaces related to adherence and robustness.\nSpecifically, Parenting utilizes a key parameter mining method that combines\nforward and backward propagation signals to localize subspaces representing\ndifferent capabilities. Then, Parenting employs a type-tailored tuning\nstrategy, applying specific and appropriate optimizations to different\nsubspaces, aiming to achieve a balanced enhancement of both adherence and\nrobustness. Extensive experiments on various datasets and models validate the\neffectiveness and generalizability of our method.\n","authors":["Yongxin Xu","Ruizhe Zhang","Xinke Jiang","Yujie Feng","Yuzhen Xiao","Xinyu Ma","Runchuan Zhu","Xu Chu","Junfeng Zhao","Yasha Wang"],"pdf_url":"https://arxiv.org/pdf/2410.10360v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.15511v1","updated":"2024-10-20T21:17:05Z","published":"2024-10-20T21:17:05Z","title":"ConTReGen: Context-driven Tree-structured Retrieval for Open-domain\n  Long-form Text Generation","summary":"  Open-domain long-form text generation requires generating coherent,\ncomprehensive responses that address complex queries with both breadth and\ndepth. This task is challenging due to the need to accurately capture diverse\nfacets of input queries. Existing iterative retrieval-augmented generation\n(RAG) approaches often struggle to delve deeply into each facet of complex\nqueries and integrate knowledge from various sources effectively. This paper\nintroduces ConTReGen, a novel framework that employs a context-driven,\ntree-structured retrieval approach to enhance the depth and relevance of\nretrieved content. ConTReGen integrates a hierarchical, top-down in-depth\nexploration of query facets with a systematic bottom-up synthesis, ensuring\ncomprehensive coverage and coherent integration of multifaceted information.\nExtensive experiments on multiple datasets, including LFQA and ODSUM, alongside\na newly introduced dataset, ODSUM-WikiHow, demonstrate that ConTReGen\noutperforms existing state-of-the-art RAG models.\n","authors":["Kashob Kumar Roy","Pritom Saha Akash","Kevin Chen-Chuan Chang","Lucian Popa"],"pdf_url":"https://arxiv.org/pdf/2410.15511v1.pdf","comment":"Accepted at EMNLP'24 Findings"},{"id":"http://arxiv.org/abs/2404.13207v3","updated":"2024-10-20T18:59:02Z","published":"2024-04-19T22:54:54Z","title":"STaRK: Benchmarking LLM Retrieval on Textual and Relational Knowledge\n  Bases","summary":"  Answering real-world complex queries, such as complex product search, often\nrequires accurate retrieval from semi-structured knowledge bases that involve\nblend of unstructured (e.g., textual descriptions of products) and structured\n(e.g., entity relations of products) information. However, many previous works\nstudied textual and relational retrieval tasks as separate topics. To address\nthe gap, we develop STARK, a large-scale Semi-structure retrieval benchmark on\nTextual and Relational Knowledge Bases. Our benchmark covers three domains:\nproduct search, academic paper search, and queries in precision medicine. We\ndesign a novel pipeline to synthesize realistic user queries that integrate\ndiverse relational information and complex textual properties, together with\ntheir ground-truth answers (items). We conduct rigorous human evaluation to\nvalidate the quality of our synthesized queries. We further enhance the\nbenchmark with high-quality human-generated queries to provide an authentic\nreference. STARK serves as a comprehensive testbed for evaluating the\nperformance of retrieval systems driven by large language models (LLMs). Our\nexperiments suggest that STARK presents significant challenges to the current\nretrieval and LLM systems, highlighting the need for more capable\nsemi-structured retrieval systems. The benchmark data and code are available on\nhttps://github.com/snap-stanford/STaRK.\n","authors":["Shirley Wu","Shiyu Zhao","Michihiro Yasunaga","Kexin Huang","Kaidi Cao","Qian Huang","Vassilis N. Ioannidis","Karthik Subbian","James Zou","Jure Leskovec"],"pdf_url":"https://arxiv.org/pdf/2404.13207v3.pdf","comment":"NeurIPS 2024 Track on Datasets and Benchmarks. 26 Pages, 6 Figures.\n  Website: https://stark.stanford.edu/"},{"id":"http://arxiv.org/abs/2410.15387v1","updated":"2024-10-20T13:21:52Z","published":"2024-10-20T13:21:52Z","title":"Deep Class-guided Hashing for Multi-label Cross-modal Retrieval","summary":"  Deep hashing, due to its low cost and efficient retrieval advantages, is\nwidely valued in cross-modal retrieval. However, existing cross-modal hashing\nmethods either explore the relationships between data points, which inevitably\nleads to intra-class dispersion, or explore the relationships between data\npoints and categories while ignoring the preservation of inter-class structural\nrelationships, resulting in the generation of suboptimal hash codes. How to\nmaintain both intra-class aggregation and inter-class structural relationships,\nIn response to this issue, this paper proposes a DCGH method. Specifically, we\nuse proxy loss as the mainstay to maintain intra-class aggregation of data,\ncombined with pairwise loss to maintain inter-class structural relationships,\nand on this basis, further propose a variance constraint to address the\nsemantic bias issue caused by the combination. A large number of comparative\nexperiments on three benchmark datasets show that the DCGH method has\ncomparable or even better performance compared to existing cross-modal\nretrieval methods. The code for the implementation of our DCGH framework is\navailable at https://github.com/donnotnormal/DCGH.\n","authors":["Hao Chen","Lei Zhu","Xinghui Zhu"],"pdf_url":"https://arxiv.org/pdf/2410.15387v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2405.09369v4","updated":"2024-10-20T11:05:15Z","published":"2024-05-15T14:20:37Z","title":"Diffusion-based Contrastive Learning for Sequential Recommendation","summary":"  Contrastive learning has been effectively utilized to enhance the training of\nsequential recommendation models by leveraging informative self-supervised\nsignals. Most existing approaches generate augmented views of the same user\nsequence through random augmentation and subsequently maximize their agreement\nin the representation space. However, these methods often neglect the\nrationality of the augmented samples. Due to significant uncertainty, random\naugmentation can disrupt the semantic information and interest evolution\npatterns inherent in the original user sequences. Moreover, pulling\nsemantically inconsistent sequences closer in the representation space can\nrender the user sequence embeddings insensitive to variations in user\npreferences, which contradicts the primary objective of sequential\nrecommendation. To address these limitations, we propose the Context-aware\nDiffusion-based Contrastive Learning for Sequential Recommendation, named\nCaDiRec. The core idea is to leverage context information to generate more\nreasonable augmented views. Specifically, CaDiRec employs a context-aware\ndiffusion model to generate alternative items for the given positions within a\nsequence. These generated items are aligned with their respective context\ninformation and can effectively replace the corresponding original items,\nthereby generating a positive view of the original sequence. By considering two\ndifferent augmentations of the same user sequence, we can construct a pair of\npositive samples for contrastive learning. To ensure representation cohesion,\nwe train the entire framework in an end-to-end manner, with shared item\nembeddings between the diffusion model and the recommendation model. Extensive\nexperiments on five benchmark datasets demonstrate the advantages of our\nproposed method over existing baselines.\n","authors":["Ziqiang Cui","Haolun Wu","Bowei He","Ji Cheng","Chen Ma"],"pdf_url":"https://arxiv.org/pdf/2405.09369v4.pdf","comment":null},{"id":"http://arxiv.org/abs/2405.10311v2","updated":"2024-10-20T05:49:18Z","published":"2024-05-16T17:58:45Z","title":"UniRAG: Universal Retrieval Augmentation for Multi-Modal Large Language\n  Models","summary":"  Recently, Multi-Modal (MM) Large Language Models (LLMs) have unlocked many\ncomplex use-cases that require MM understanding (e.g., image captioning or\nvisual question answering) and MM generation (e.g., text-guided image\ngeneration or editing) capabilities. To further improve the output fidelity of\nMM-LLMs we introduce UniRAG, a plug-and-play technique that adds relevant\nretrieved information to prompts as few-shot examples during inference. Unlike\nthe common belief that Retrieval Augmentation (RA) mainly improves generation\nor understanding of uncommon entities, our evaluation results on the MSCOCO\ndataset with common entities show that both proprietary models like GPT-4o and\nGemini-Pro and smaller open-source models like LLaVA, LaVIT, and Emu2\nsignificantly enhance their generation quality when their input prompts are\naugmented with relevant information retrieved by MM retrievers like UniIR\nmodels.\n","authors":["Sahel Sharifymoghaddam","Shivani Upadhyay","Wenhu Chen","Jimmy Lin"],"pdf_url":"https://arxiv.org/pdf/2405.10311v2.pdf","comment":"14 pages, 6 figures"},{"id":"http://arxiv.org/abs/2410.15272v1","updated":"2024-10-20T04:05:18Z","published":"2024-10-20T04:05:18Z","title":"Performance-Driven QUBO for Recommender Systems on Quantum Annealers","summary":"  We propose Counterfactual Analysis Quadratic Unconstrained Binary\nOptimization (CAQUBO) to solve QUBO problems for feature selection in\nrecommender systems. CAQUBO leverages counterfactual analysis to measure the\nimpact of individual features and feature combinations on model performance and\nemploys the measurements to construct the coefficient matrix for a quantum\nannealer to select the optimal feature combinations for recommender systems,\nthereby improving their final recommendation performance. By establishing\nexplicit connections between features and the recommendation performance, the\nproposed approach demonstrates superior performance compared to the\nstate-of-the-art quantum annealing methods. Extensive experiments indicate that\nintegrating quantum computing with counterfactual analysis holds great promise\nfor addressing these challenges.\n","authors":["Jiayang Niu","Jie Li","Ke Deng","Mark Sanderson","Yongli Ren"],"pdf_url":"https://arxiv.org/pdf/2410.15272v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.15262v1","updated":"2024-10-20T03:15:01Z","published":"2024-10-20T03:15:01Z","title":"HyQE: Ranking Contexts with Hypothetical Query Embeddings","summary":"  In retrieval-augmented systems, context ranking techniques are commonly\nemployed to reorder the retrieved contexts based on their relevance to a user\nquery. A standard approach is to measure this relevance through the similarity\nbetween contexts and queries in the embedding space. However, such similarity\noften fails to capture the relevance. Alternatively, large language models\n(LLMs) have been used for ranking contexts. However, they can encounter\nscalability issues when the number of candidate contexts grows and the context\nwindow sizes of the LLMs remain constrained. Additionally, these approaches\nrequire fine-tuning LLMs with domain-specific data. In this work, we introduce\na scalable ranking framework that combines embedding similarity and LLM\ncapabilities without requiring LLM fine-tuning. Our framework uses a\npre-trained LLM to hypothesize the user query based on the retrieved contexts\nand ranks the context based on the similarity between the hypothesized queries\nand the user query. Our framework is efficient at inference time and is\ncompatible with many other retrieval and ranking techniques. Experimental\nresults show that our method improves the ranking performance across multiple\nbenchmarks. The complete code and data are available at\nhttps://github.com/zwc662/hyqe\n","authors":["Weichao Zhou","Jiaxin Zhang","Hilaf Hasson","Anu Singh","Wenchao Li"],"pdf_url":"https://arxiv.org/pdf/2410.15262v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.02219v2","updated":"2024-10-20T02:40:57Z","published":"2024-10-03T05:23:39Z","title":"Multi-modal clothing recommendation model based on large model and VAE\n  enhancement","summary":"  Accurately recommending products has long been a subject requiring in-depth\nresearch. This study proposes a multimodal paradigm for clothing\nrecommendations. Specifically, it designs a multimodal analysis method that\nintegrates clothing description texts and images, utilizing a pre-trained large\nlanguage model to deeply explore the hidden meanings of users and products.\nAdditionally, a variational encoder is employed to learn the relationship\nbetween user information and products to address the cold start problem in\nrecommendation systems. This study also validates the significant performance\nadvantages of this method over various recommendation system methods through\nextensive ablation experiments, providing crucial practical guidance for the\ncomprehensive optimization of recommendation systems.\n","authors":["Bingjie Huang","Qingyi Lu","Shuaishuai Huang","Xue-she Wang","Haowei Yang"],"pdf_url":"https://arxiv.org/pdf/2410.02219v2.pdf","comment":null}],"Computer Vision and Pattern Recognition":[{"id":"http://arxiv.org/abs/2311.09614v2","updated":"2024-10-20T23:41:43Z","published":"2023-11-16T06:58:46Z","title":"Comprehensive Evaluation and Insights into the Use of Deep Neural\n  Networks to Detect and Quantify Lymphoma Lesions in PET/CT Images","summary":"  This study performs comprehensive evaluation of four neural network\narchitectures (UNet, SegResNet, DynUNet, and SwinUNETR) for lymphoma lesion\nsegmentation from PET/CT images. These networks were trained, validated, and\ntested on a diverse, multi-institutional dataset of 611 cases. Internal testing\n(88 cases; total metabolic tumor volume (TMTV) range [0.52, 2300] ml) showed\nSegResNet as the top performer with a median Dice similarity coefficient (DSC)\nof 0.76 and median false positive volume (FPV) of 4.55 ml; all networks had a\nmedian false negative volume (FNV) of 0 ml. On the unseen external test set\n(145 cases with TMTV range: [0.10, 2480] ml), SegResNet achieved the best\nmedian DSC of 0.68 and FPV of 21.46 ml, while UNet had the best FNV of 0.41 ml.\nWe assessed reproducibility of six lesion measures, calculated their prediction\nerrors, and examined DSC performance in relation to these lesion measures,\noffering insights into segmentation accuracy and clinical relevance.\nAdditionally, we introduced three lesion detection criteria, addressing the\nclinical need for identifying lesions, counting them, and segmenting based on\nmetabolic characteristics. We also performed expert intra-observer variability\nanalysis revealing the challenges in segmenting ``easy'' vs. ``hard'' cases, to\nassist in the development of more resilient segmentation algorithms. Finally,\nwe performed inter-observer agreement assessment underscoring the importance of\na standardized ground truth segmentation protocol involving multiple expert\nannotators. Code is available at:\nhttps://github.com/microsoft/lymphoma-segmentation-dnn\n","authors":["Shadab Ahamed","Yixi Xu","Claire Gowdy","Joo H. O","Ingrid Bloise","Don Wilson","Patrick Martineau","François Bénard","Fereshteh Yousefirizi","Rahul Dodhia","Juan M. Lavista","William B. Weeks","Carlos F. Uribe","Arman Rahmim"],"pdf_url":"https://arxiv.org/pdf/2311.09614v2.pdf","comment":"12 pages, 10 figures, 2 tables"},{"id":"http://arxiv.org/abs/2406.09588v3","updated":"2024-10-20T23:21:45Z","published":"2024-06-13T21:02:03Z","title":"Learning Color Equivariant Representations","summary":"  In this paper, we introduce group convolutional neural networks (GCNNs)\nequivariant to color variation. GCNNs have been designed for a variety of\ngeometric transformations from 2D and 3D rotation groups, to semi-groups such\nas scale. Despite the improved interpretability, accuracy and generalizability\nof these architectures, GCNNs have seen limited application in the context of\nperceptual quantities. Notably, the recent CEConv network uses a GCNN to\nachieve equivariance to hue transformations by convolving input images with a\nhue rotated RGB filter. However, this approach leads to invalid RGB values\nwhich break equivariance and degrade performance. We resolve these issues with\na lifting layer that transforms the input image directly, thereby circumventing\nthe issue of invalid RGB values and improving equivariance error by over three\norders of magnitude. Moreover, we extend the notion of color equivariance to\ninclude equivariance to saturation shift. Our hue-, saturation-, and\ncolor-equivariant networks achieve strong generalization to out-of-distribution\nperceptual variations and improved sample efficiency over conventional\narchitectures. We demonstrate the utility of our approach on synthetic and real\nworld datasets where we consistently outperform competitive baselines.\n","authors":["Felix O'Mahony","Yulong Yang","Christine Allen-Blanchette"],"pdf_url":"https://arxiv.org/pdf/2406.09588v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.15521v1","updated":"2024-10-20T22:05:13Z","published":"2024-10-20T22:05:13Z","title":"Lying mirror","summary":"  We introduce an all-optical system, termed the \"lying mirror\", to hide input\ninformation by transforming it into misleading, ordinary-looking patterns that\neffectively camouflage the underlying image data and deceive the observers.\nThis misleading transformation is achieved through passive light-matter\ninteractions of the incident light with an optimized structured diffractive\nsurface, enabling the optical concealment of any form of secret input data\nwithout any digital computing. These lying mirror designs were shown to\ncamouflage different types of input image data, exhibiting robustness against a\nrange of adversarial manipulations, including random image noise as well as\nunknown, random rotations, shifts, and scaling of the object features. The\nfeasibility of the lying mirror concept was also validated experimentally using\na structured micro-mirror array along with multi-wavelength illumination at\n480, 550 and 600 nm, covering the blue, green and red image channels. This\nframework showcases the power of structured diffractive surfaces for visual\ninformation processing and might find various applications in defense, security\nand entertainment.\n","authors":["Yuhang Li","Shiqi Chen","Bijie Bai","Aydogan Ozcan"],"pdf_url":"https://arxiv.org/pdf/2410.15521v1.pdf","comment":"21 Pages, 8 Figures"}]},"2024-10-22T00:00:00Z":{"Computation and Language":[{"id":"http://arxiv.org/abs/2407.02273v4","updated":"2024-10-22T06:48:54Z","published":"2024-07-02T14:02:53Z","title":"Language Model Alignment in Multilingual Trolley Problems","summary":"  We evaluate the moral alignment of large language models (LLMs) with human\npreferences in multilingual trolley problems. Building on the Moral Machine\nexperiment, which captures over 40 million human judgments across 200+\ncountries, we develop a cross-lingual corpus of moral dilemma vignettes in over\n100 languages called MultiTP. This dataset enables the assessment of LLMs'\ndecision-making processes in diverse linguistic contexts. Our analysis explores\nthe alignment of 19 different LLMs with human judgments, capturing preferences\nacross six moral dimensions: species, gender, fitness, status, age, and the\nnumber of lives involved. By correlating these preferences with the demographic\ndistribution of language speakers and examining the consistency of LLM\nresponses to various prompt paraphrasings, our findings provide insights into\ncross-lingual and ethical biases of LLMs and their intersection. We discover\nsignificant variance in alignment across languages, challenging the assumption\nof uniform moral reasoning in AI systems and highlighting the importance of\nincorporating diverse perspectives in AI ethics. The results underscore the\nneed for further research on the integration of multilingual dimensions in\nresponsible AI research to ensure fair and equitable AI interactions worldwide.\nOur code and data are at https://github.com/causalNLP/moralmachine\n","authors":["Zhijing Jin","Max Kleiman-Weiner","Giorgio Piatti","Sydney Levine","Jiarui Liu","Fernando Gonzalez","Francesco Ortu","András Strausz","Mrinmaya Sachan","Rada Mihalcea","Yejin Choi","Bernhard Schölkopf"],"pdf_url":"https://arxiv.org/pdf/2407.02273v4.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.16077v2","updated":"2024-10-22T09:37:45Z","published":"2024-10-21T14:55:59Z","title":"CartesianMoE: Boosting Knowledge Sharing among Experts via Cartesian\n  Product Routing in Mixture-of-Experts","summary":"  Large language models (LLM) have been attracting much attention from the\ncommunity recently, due to their remarkable performance in all kinds of\ndownstream tasks. According to the well-known scaling law, scaling up a dense\nLLM enhances its capabilities, but also significantly increases the\ncomputational complexity. Mixture-of-Experts (MoE) models address that by\nallowing the model size to grow without substantially raising training or\ninference costs. Yet MoE models face challenges regarding knowledge sharing\namong experts, making their performance somehow sensitive to routing accuracy.\nTo tackle that, previous works introduced shared experts and combined their\noutputs with those of the top $K$ routed experts in an ``addition'' manner. In\nthis paper, inspired by collective matrix factorization to learn shared\nknowledge among data, we propose CartesianMoE, which implements more effective\nknowledge sharing among experts in more like a ``multiplication'' manner.\nExtensive experimental results indicate that CartesianMoE outperforms previous\nMoE models for building LLMs, in terms of both perplexity and downstream task\nperformance. And we also find that CartesianMoE achieves better expert routing\nrobustness.\n","authors":["Zhenpeng Su","Xing Wu","Zijia Lin","Yizhe Xiong","Minxuan Lv","Guangyuan Ma","Hui Chen","Songlin Hu","Guiguang Ding"],"pdf_url":"https://arxiv.org/pdf/2410.16077v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.16070v2","updated":"2024-10-22T13:40:18Z","published":"2024-10-21T14:48:35Z","title":"On-Device LLMs for SMEs: Challenges and Opportunities","summary":"  This paper presents a systematic review of the infrastructure requirements\nfor deploying Large Language Models (LLMs) on-device within the context of\nsmall and medium-sized enterprises (SMEs), focusing on both hardware and\nsoftware perspectives. From the hardware viewpoint, we discuss the utilization\nof processing units like GPUs and TPUs, efficient memory and storage solutions,\nand strategies for effective deployment, addressing the challenges of limited\ncomputational resources typical in SME settings. From the software perspective,\nwe explore framework compatibility, operating system optimization, and the use\nof specialized libraries tailored for resource-constrained environments. The\nreview is structured to first identify the unique challenges faced by SMEs in\ndeploying LLMs on-device, followed by an exploration of the opportunities that\nboth hardware innovations and software adaptations offer to overcome these\nobstacles. Such a structured review provides practical insights, contributing\nsignificantly to the community by enhancing the technological resilience of\nSMEs in integrating LLMs.\n","authors":["Jeremy Stephen Gabriel Yee","Pai Chet Ng","Zhengkui Wang","Ian McLoughlin","Aik Beng Ng","Simon See"],"pdf_url":"https://arxiv.org/pdf/2410.16070v2.pdf","comment":"9 pages, 1 figure. The work is supported by the SIT-NVIDIA Joint AI\n  Centre"},{"id":"http://arxiv.org/abs/2410.15639v2","updated":"2024-10-22T03:14:46Z","published":"2024-10-21T04:57:09Z","title":"Can Large Language Models Invent Algorithms to Improve Themselves?","summary":"  Large Language Models (LLMs) have shown remarkable performance improvements\nand are rapidly gaining adoption in industry. However, the methods for\nimproving LLMs are still designed by humans, which restricts the invention of\nnew model-improving algorithms to human expertise and imagination. To address\nthis, we propose the Self-Developing framework, which enables LLMs to\nautonomously generate and learn model-improvement algorithms. In this\nframework, the seed model generates, applies, and learns model-improving\nalgorithms, continuously improving both the seed model and the algorithms\nthemselves. In mathematical reasoning tasks, Self-Developing not only creates\nmodels that surpass the seed model but also consistently outperforms models\ncreated using human-designed algorithms. Additionally, these LLM-discovered\nalgorithms demonstrate strong effectiveness, including transferability to\nout-of-domain models.\n","authors":["Yoichi Ishibashi","Taro Yano","Masafumi Oyamada"],"pdf_url":"https://arxiv.org/pdf/2410.15639v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.15608v2","updated":"2024-10-22T13:55:26Z","published":"2024-10-21T03:13:20Z","title":"Moonshine: Speech Recognition for Live Transcription and Voice Commands","summary":"  This paper introduces Moonshine, a family of speech recognition models\noptimized for live transcription and voice command processing. Moonshine is\nbased on an encoder-decoder transformer architecture and employs Rotary\nPosition Embedding (RoPE) instead of traditional absolute position embeddings.\nThe model is trained on speech segments of various lengths, but without using\nzero-padding, leading to greater efficiency for the encoder during inference\ntime. When benchmarked against OpenAI's Whisper tiny-en, Moonshine Tiny\ndemonstrates a 5x reduction in compute requirements for transcribing a\n10-second speech segment while incurring no increase in word error rates across\nstandard evaluation datasets. These results highlight Moonshine's potential for\nreal-time and resource-constrained applications.\n","authors":["Nat Jeffries","Evan King","Manjunath Kudlur","Guy Nicholson","James Wang","Pete Warden"],"pdf_url":"https://arxiv.org/pdf/2410.15608v2.pdf","comment":"7 pages, 6 figures, 3 tables"},{"id":"http://arxiv.org/abs/2410.17251v1","updated":"2024-10-22T17:59:57Z","published":"2024-10-22T17:59:57Z","title":"Altogether: Image Captioning via Re-aligning Alt-text","summary":"  This paper focuses on creating synthetic data to improve the quality of image\ncaptions. Existing works typically have two shortcomings. First, they caption\nimages from scratch, ignoring existing alt-text metadata, and second, lack\ntransparency if the captioners' training data (e.g. GPT) is unknown. In this\npaper, we study a principled approach Altogether based on the key idea to edit\nand re-align existing alt-texts associated with the images. To generate\ntraining data, we perform human annotation where annotators start with the\nexisting alt-text and re-align it to the image content in multiple rounds,\nconsequently constructing captions with rich visual concepts. This differs from\nprior work that carries out human annotation as a one-time description task\nsolely based on images and annotator knowledge. We train a captioner on this\ndata that generalizes the process of re-aligning alt-texts at scale. Our\nresults show our Altogether approach leads to richer image captions that also\nimprove text-to-image generation and zero-shot image classification tasks.\n","authors":["Hu Xu","Po-Yao Huang","Xiaoqing Ellen Tan","Ching-Feng Yeh","Jacob Kahn","Christine Jou","Gargi Ghosh","Omer Levy","Luke Zettlemoyer","Wen-tau Yih","Shang-Wen Li","Saining Xie","Christoph Feichtenhofer"],"pdf_url":"https://arxiv.org/pdf/2410.17251v1.pdf","comment":"accepted by EMNLP 2024; MetaCLIPv2"},{"id":"http://arxiv.org/abs/2410.17250v1","updated":"2024-10-22T17:59:56Z","published":"2024-10-22T17:59:56Z","title":"JMMMU: A Japanese Massive Multi-discipline Multimodal Understanding\n  Benchmark for Culture-aware Evaluation","summary":"  Accelerating research on Large Multimodal Models (LMMs) in non-English\nlanguages is crucial for enhancing user experiences across broader populations.\nIn this paper, we introduce JMMMU (Japanese MMMU), the first large-scale\nJapanese benchmark designed to evaluate LMMs on expert-level tasks based on the\nJapanese cultural context. To facilitate comprehensive culture-aware\nevaluation, JMMMU features two complementary subsets: (i) culture-agnostic (CA)\nsubset, where the culture-independent subjects (e.g., Math) are selected and\ntranslated into Japanese, enabling one-to-one comparison with its English\ncounterpart MMMU; and (ii) culture-specific (CS) subset, comprising newly\ncrafted subjects that reflect Japanese cultural context. Using the CA subset,\nwe observe performance drop in many LMMs when evaluated in Japanese, which is\npurely attributable to language variation. Using the CS subset, we reveal their\ninadequate Japanese cultural understanding. Further, by combining both subsets,\nwe identify that some LMMs perform well on the CA subset but not on the CS\nsubset, exposing a shallow understanding of the Japanese language that lacks\ndepth in cultural understanding. We hope this work will not only help advance\nLMM performance in Japanese but also serve as a guideline to create\nhigh-standard, culturally diverse benchmarks for multilingual LMM development.\nThe project page is https://mmmu-japanese-benchmark.github.io/JMMMU/.\n","authors":["Shota Onohara","Atsuyuki Miyai","Yuki Imajuku","Kazuki Egashira","Jeonghun Baek","Xiang Yue","Graham Neubig","Kiyoharu Aizawa"],"pdf_url":"https://arxiv.org/pdf/2410.17250v1.pdf","comment":"Project page: https://mmmu-japanese-benchmark.github.io/JMMMU/"},{"id":"http://arxiv.org/abs/2410.17247v1","updated":"2024-10-22T17:59:53Z","published":"2024-10-22T17:59:53Z","title":"PyramidDrop: Accelerating Your Large Vision-Language Models via Pyramid\n  Visual Redundancy Reduction","summary":"  In large vision-language models (LVLMs), images serve as inputs that carry a\nwealth of information. As the idiom \"A picture is worth a thousand words\"\nimplies, representing a single image in current LVLMs can require hundreds or\neven thousands of tokens. This results in significant computational costs,\nwhich grow quadratically as input image resolution increases, thereby severely\nimpacting the efficiency of both training and inference. Previous approaches\nhave attempted to reduce the number of image tokens either before or within the\nearly layers of LVLMs. However, these strategies inevitably result in the loss\nof crucial image information, ultimately diminishing model performance. To\naddress this challenge, we conduct an empirical study revealing that all visual\ntokens are necessary for LVLMs in the shallow layers, and token redundancy\nprogressively increases in the deeper layers of the model. To this end, we\npropose PyramidDrop, a visual redundancy reduction strategy for LVLMs to boost\ntheir efficiency in both training and inference with neglectable performance\nloss. Specifically, we partition the LVLM into several stages and drop part of\nthe image tokens at the end of each stage with a pre-defined ratio, creating\npyramid-like visual tokens across model layers. The dropping is based on a\nlightweight similarity calculation with a negligible time overhead. Extensive\nexperiments demonstrate that PyramidDrop can achieve a 40% training time and\n55% inference FLOPs acceleration of LLaVA-NeXT with comparable performance.\nBesides, the PyramidDrop could also serve as a plug-and-play strategy for\ninference acceleration without training, with better performance and lower\ninference cost than counterparts. We hope that the insights and approach\nintroduced by PyramidDrop will inspire future research to further investigate\nthe role of image tokens in LVLMs.\n","authors":["Long Xing","Qidong Huang","Xiaoyi Dong","Jiajie Lu","Pan Zhang","Yuhang Zang","Yuhang Cao","Conghui He","Jiaqi Wang","Feng Wu","Dahua Lin"],"pdf_url":"https://arxiv.org/pdf/2410.17247v1.pdf","comment":"10 pages"},{"id":"http://arxiv.org/abs/2410.17245v1","updated":"2024-10-22T17:59:39Z","published":"2024-10-22T17:59:39Z","title":"Towards Reliable Evaluation of Behavior Steering Interventions in LLMs","summary":"  Representation engineering methods have recently shown promise for enabling\nefficient steering of model behavior. However, evaluation pipelines for these\nmethods have primarily relied on subjective demonstrations, instead of\nquantitative, objective metrics. We aim to take a step towards addressing this\nissue by advocating for four properties missing from current evaluations: (i)\ncontexts sufficiently similar to downstream tasks should be used for assessing\nintervention quality; (ii) model likelihoods should be accounted for; (iii)\nevaluations should allow for standardized comparisons across different target\nbehaviors; and (iv) baseline comparisons should be offered. We introduce an\nevaluation pipeline grounded in these criteria, offering both a quantitative\nand visual analysis of how effectively a given method works. We use this\npipeline to evaluate two representation engineering methods on how effectively\nthey can steer behaviors such as truthfulness and corrigibility, finding that\nsome interventions are less effective than previously reported.\n","authors":["Itamar Pres","Laura Ruis","Ekdeep Singh Lubana","David Krueger"],"pdf_url":"https://arxiv.org/pdf/2410.17245v1.pdf","comment":"Accepted to the NeurIPS 2024 - Workshop on Foundation Model\n  Interventions"},{"id":"http://arxiv.org/abs/2410.17238v1","updated":"2024-10-22T17:56:08Z","published":"2024-10-22T17:56:08Z","title":"SELA: Tree-Search Enhanced LLM Agents for Automated Machine Learning","summary":"  Automated Machine Learning (AutoML) approaches encompass traditional methods\nthat optimize fixed pipelines for model selection and ensembling, as well as\nnewer LLM-based frameworks that autonomously build pipelines. While LLM-based\nagents have shown promise in automating machine learning tasks, they often\ngenerate low-diversity and suboptimal code, even after multiple iterations. To\novercome these limitations, we introduce Tree-Search Enhanced LLM Agents\n(SELA), an innovative agent-based system that leverages Monte Carlo Tree Search\n(MCTS) to optimize the AutoML process. By representing pipeline configurations\nas trees, our framework enables agents to conduct experiments intelligently and\niteratively refine their strategies, facilitating a more effective exploration\nof the machine learning solution space. This novel approach allows SELA to\ndiscover optimal pathways based on experimental feedback, improving the overall\nquality of the solutions. In an extensive evaluation across 20 machine learning\ndatasets, we compare the performance of traditional and agent-based AutoML\nmethods, demonstrating that SELA achieves a win rate of 65% to 80% against each\nbaseline across all datasets. These results underscore the significant\npotential of agent-based strategies in AutoML, offering a fresh perspective on\ntackling complex machine learning challenges.\n","authors":["Yizhou Chi","Yizhang Lin","Sirui Hong","Duyi Pan","Yaying Fei","Guanghao Mei","Bangbang Liu","Tianqi Pang","Jacky Kwok","Ceyao Zhang","Bang Liu","Chenglin Wu"],"pdf_url":"https://arxiv.org/pdf/2410.17238v1.pdf","comment":"The code is available at https://github.com/geekan/MetaGPT"},{"id":"http://arxiv.org/abs/2410.17236v1","updated":"2024-10-22T17:54:45Z","published":"2024-10-22T17:54:45Z","title":"Large Language Models Empowered Personalized Web Agents","summary":"  Web agents have emerged as a promising direction to automate Web task\ncompletion based on user instructions, significantly enhancing user experience.\nRecently, Web agents have evolved from traditional agents to Large Language\nModels (LLMs)-based Web agents. Despite their success, existing LLM-based Web\nagents overlook the importance of personalized data (e.g., user profiles and\nhistorical Web behaviors) in assisting the understanding of users' personalized\ninstructions and executing customized actions. To overcome the limitation, we\nfirst formulate the task of LLM-empowered personalized Web agents, which\nintegrate personalized data and user instructions to personalize instruction\ncomprehension and action execution. To address the absence of a comprehensive\nevaluation benchmark, we construct a Personalized Web Agent Benchmark\n(PersonalWAB), featuring user instructions, personalized user data, Web\nfunctions, and two evaluation paradigms across three personalized Web tasks.\nMoreover, we propose a Personalized User Memory-enhanced Alignment (PUMA)\nframework to adapt LLMs to the personalized Web agent task. PUMA utilizes a\nmemory bank with a task-specific retrieval strategy to filter relevant\nhistorical Web behaviors. Based on the behaviors, PUMA then aligns LLMs for\npersonalized action execution through fine-tuning and direct preference\noptimization. Extensive experiments validate the superiority of PUMA over\nexisting Web agents on PersonalWAB.\n","authors":["Hongru Cai","Yongqi Li","Wenjie Wang","Fengbin Zhu","Xiaoyu Shen","Wenjie Li","Tat-Seng Chua"],"pdf_url":"https://arxiv.org/pdf/2410.17236v1.pdf","comment":"The code and data are available on the project website\n  https://hongrucai.github.io/PersonalWAB/"},{"id":"http://arxiv.org/abs/2410.17235v1","updated":"2024-10-22T17:54:07Z","published":"2024-10-22T17:54:07Z","title":"Automated Spinal MRI Labelling from Reports Using a Large Language Model","summary":"  We propose a general pipeline to automate the extraction of labels from\nradiology reports using large language models, which we validate on spinal MRI\nreports. The efficacy of our labelling method is measured on five distinct\nconditions: spinal cancer, stenosis, spondylolisthesis, cauda equina\ncompression and herniation. Using open-source models, our method equals or\nsurpasses GPT-4 on a held-out set of reports. Furthermore, we show that the\nextracted labels can be used to train imaging models to classify the identified\nconditions in the accompanying MR scans. All classifiers trained using\nautomated labels achieve comparable performance to models trained using scans\nmanually annotated by clinicians. Code can be found at\nhttps://github.com/robinyjpark/AutoLabelClassifier.\n","authors":["Robin Y. Park","Rhydian Windsor","Amir Jamaludin","Andrew Zisserman"],"pdf_url":"https://arxiv.org/pdf/2410.17235v1.pdf","comment":"Accepted to Medical Image Computing and Computer Assisted\n  Intervention (MICCAI 2024, Spotlight). 11 pages plus appendix"},{"id":"http://arxiv.org/abs/2410.17234v1","updated":"2024-10-22T17:54:03Z","published":"2024-10-22T17:54:03Z","title":"Fine-Tuning Large Language Models to Appropriately Abstain with Semantic\n  Entropy","summary":"  Large Language Models (LLMs) are known to hallucinate, whereby they generate\nplausible but inaccurate text. This phenomenon poses significant risks in\ncritical applications, such as medicine or law, necessitating robust\nhallucination mitigation strategies. While recent works have proposed\nfine-tuning methods to teach LLMs to abstain from answering questions beyond\ntheir knowledge or capabilities, these methods rely on the existence of\nground-truth labels or are limited to short-form responses. To address these\nlimitations, we propose fine-tuning using semantic entropy, an uncertainty\nmeasure derived from introspection into the model which does not require\nexternal labels. We demonstrate that our approach matches or outperforms models\nfine-tuned using prior work and achieves strong performance for both short and\nlong-form generations on a range of datasets.\n","authors":["Benedict Aaron Tjandra","Muhammed Razzak","Jannik Kossen","Kunal Handa","Yarin Gal"],"pdf_url":"https://arxiv.org/pdf/2410.17234v1.pdf","comment":"Accepted to NeurIPS Safe Generative AI Workshop 2024"},{"id":"http://arxiv.org/abs/2407.12883v2","updated":"2024-10-22T17:49:31Z","published":"2024-07-16T17:58:27Z","title":"BRIGHT: A Realistic and Challenging Benchmark for Reasoning-Intensive\n  Retrieval","summary":"  Existing retrieval benchmarks primarily consist of information-seeking\nqueries (e.g., aggregated questions from search engines) where keyword or\nsemantic-based retrieval is usually sufficient. However, many complex\nreal-world queries require in-depth reasoning to identify relevant documents\nthat go beyond surface form matching. For example, finding documentation for a\ncoding question requires understanding the logic and syntax of the functions\ninvolved. To better benchmark retrieval on such challenging queries, we\nintroduce BRIGHT, the first text retrieval benchmark that requires intensive\nreasoning to retrieve relevant documents. Our dataset consists of 1,384\nreal-world queries spanning diverse domains, such as economics, psychology,\nmathematics, and coding. These queries are drawn from naturally occurring and\ncarefully curated human data. Extensive evaluation reveals that even\nstate-of-the-art retrieval models perform poorly on BRIGHT. The leading model\non the MTEB leaderboard (Muennighoff et al., 2023), which achieves a score of\n59.0 nDCG@10, produces a score of nDCG@10 of 18.3 on BRIGHT. We show that\nincorporating explicit reasoning about the query improves retrieval performance\nby up to 12.2 points. Moreover, incorporating retrieved documents from the\ntop-performing retriever boosts question-answering performance by over 6.6\npoints. We believe that BRIGHT paves the way for future research on retrieval\nsystems in more realistic and challenging settings.\n","authors":["Hongjin Su","Howard Yen","Mengzhou Xia","Weijia Shi","Niklas Muennighoff","Han-yu Wang","Haisu Liu","Quan Shi","Zachary S. Siegel","Michael Tang","Ruoxi Sun","Jinsung Yoon","Sercan O. Arik","Danqi Chen","Tao Yu"],"pdf_url":"https://arxiv.org/pdf/2407.12883v2.pdf","comment":"48 pages"},{"id":"http://arxiv.org/abs/2410.17225v1","updated":"2024-10-22T17:47:05Z","published":"2024-10-22T17:47:05Z","title":"Dhoroni: Exploring Bengali Climate Change and Environmental Views with a\n  Multi-Perspective News Dataset and Natural Language Processing","summary":"  Climate change poses critical challenges globally, disproportionately\naffecting low-income countries that often lack resources and linguistic\nrepresentation on the international stage. Despite Bangladesh's status as one\nof the most vulnerable nations to climate impacts, research gaps persist in\nBengali-language studies related to climate change and NLP. To address this\ndisparity, we introduce Dhoroni, a novel Bengali (Bangla) climate change and\nenvironmental news dataset, comprising a 2300 annotated Bangla news articles,\noffering multiple perspectives such as political influence,\nscientific/statistical data, authenticity, stance detection, and stakeholder\ninvolvement. Furthermore, we present an in-depth exploratory analysis of\nDhoroni and introduce BanglaBERT-Dhoroni family, a novel baseline model family\nfor climate and environmental opinion detection in Bangla, fine-tuned on our\ndataset. This research contributes significantly to enhancing accessibility and\nanalysis of climate discourse in Bengali (Bangla), addressing crucial\ncommunication and research gaps in climate-impacted regions like Bangladesh\nwith 180 million people.\n","authors":["Azmine Toushik Wasi","Wahid Faisal","Taj Ahmad","Abdur Rahman","Mst Rafia Islam"],"pdf_url":"https://arxiv.org/pdf/2410.17225v1.pdf","comment":"In Review"},{"id":"http://arxiv.org/abs/2410.17222v1","updated":"2024-10-22T17:45:47Z","published":"2024-10-22T17:45:47Z","title":"Context-aware Prompt Tuning: Advancing In-Context Learning with\n  Adversarial Methods","summary":"  Fine-tuning Large Language Models (LLMs) typically involves updating at least\na few billions of parameters. A more parameter-efficient approach is Prompt\nTuning (PT), which updates only a few learnable tokens, and differently,\nIn-Context Learning (ICL) adapts the model to a new task by simply including\nexamples in the input without any training. When applying optimization-based\nmethods, such as fine-tuning and PT for few-shot learning, the model is\nspecifically adapted to the small set of training examples, whereas ICL leaves\nthe model unchanged. This distinction makes traditional learning methods more\nprone to overfitting; in contrast, ICL is less sensitive to the few-shot\nscenario. While ICL is not prone to overfitting, it does not fully extract the\ninformation that exists in the training examples. This work introduces\nContext-aware Prompt Tuning (CPT), a method inspired by ICL, PT, and\nadversarial attacks. We build on the ICL strategy of concatenating examples\nbefore the input, but we extend this by PT-like learning, refining the context\nembedding through iterative optimization to extract deeper insights from the\ntraining examples. We carefully modify specific context tokens, considering the\nunique structure of input and output formats. Inspired by adversarial attacks,\nwe adjust the input based on the labels present in the context, focusing on\nminimizing, rather than maximizing, the loss. Moreover, we apply a projected\ngradient descent algorithm to keep token embeddings close to their original\nvalues, under the assumption that the user-provided data is inherently\nvaluable. Our method has been shown to achieve superior accuracy across\nmultiple classification tasks using various LLM models.\n","authors":["Tsachi Blau","Moshe Kimhi","Yonatan Belinkov","Alexander Bronstein","Chaim Baskin"],"pdf_url":"https://arxiv.org/pdf/2410.17222v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.17218v1","updated":"2024-10-22T17:43:39Z","published":"2024-10-22T17:43:39Z","title":"Creativity in AI: Progresses and Challenges","summary":"  Creativity is the ability to produce novel, useful, and surprising ideas, and\nhas been widely studied as a crucial aspect of human cognition. Machine\ncreativity on the other hand has been a long-standing challenge. With the rise\nof advanced generative AI, there has been renewed interest and debate regarding\nAI's creative capabilities. Therefore, it is imperative to revisit the state of\ncreativity in AI and identify key progresses and remaining challenges. In this\nwork, we survey leading works studying the creative capabilities of AI systems,\nfocusing on creative problem-solving, linguistic, artistic, and scientific\ncreativity. Our review suggests that while the latest AI models are largely\ncapable of producing linguistically and artistically creative outputs such as\npoems, images, and musical pieces, they struggle with tasks that require\ncreative problem-solving, abstract thinking and compositionality and their\ngenerations suffer from a lack of diversity, originality, long-range\nincoherence and hallucinations. We also discuss key questions concerning\ncopyright and authorship issues with generative models. Furthermore, we\nhighlight the need for a comprehensive evaluation of creativity that is\nprocess-driven and considers several dimensions of creativity. Finally, we\npropose future research directions to improve the creativity of AI outputs,\ndrawing inspiration from cognitive science and psychology.\n","authors":["Mete Ismayilzada","Debjit Paul","Antoine Bosselut","Lonneke van der Plas"],"pdf_url":"https://arxiv.org/pdf/2410.17218v1.pdf","comment":"44 pages"},{"id":"http://arxiv.org/abs/2410.17215v1","updated":"2024-10-22T17:40:32Z","published":"2024-10-22T17:40:32Z","title":"MiniPLM: Knowledge Distillation for Pre-Training Language Models","summary":"  Knowledge distillation (KD) is widely used to train small, high-performing\nstudent language models (LMs) using large teacher LMs. While effective in\nfine-tuning, KD during pre-training faces challenges in efficiency,\nflexibility, and effectiveness. Existing methods either incur high\ncomputational costs due to online teacher inference, require tokenization\nmatching between teacher and student LMs, or risk losing the difficulty and\ndiversity of the teacher-generated training data. To address these issues, we\npropose MiniPLM, a KD framework for pre-training LMs by refining the training\ndata distribution with the teacher's knowledge. For efficiency, MiniPLM\nperforms offline teacher LM inference, allowing KD for multiple student LMs\nwithout adding training-time costs. For flexibility, MiniPLM operates solely on\nthe training corpus, enabling KD across model families. For effectiveness,\nMiniPLM leverages the differences between large and small LMs to enhance the\ndifficulty and diversity of the training data, helping student LMs acquire\nversatile and sophisticated knowledge. Extensive experiments demonstrate that\nMiniPLM boosts the student LMs' performance on 9 widely used downstream tasks,\nimproves the language modeling capabilities, and reduces pre-training\ncomputation. The benefit of MiniPLM extends to large pre-training scales,\nevidenced by the extrapolation of the scaling curves. Further analysis reveals\nthat MiniPLM supports KD across model families and enhances the utilization of\npre-training data. Our model, code, and data are available at\nhttps://github.com/thu-coai/MiniPLM.\n","authors":["Yuxian Gu","Hao Zhou","Fandong Meng","Jie Zhou","Minlie Huang"],"pdf_url":"https://arxiv.org/pdf/2410.17215v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.10796v2","updated":"2024-10-22T17:35:03Z","published":"2024-10-14T17:57:09Z","title":"Context-Parametric Inversion: Why Instruction Finetuning May Not\n  Actually Improve Context Reliance","summary":"  A standard practice when using large language models is for users to\nsupplement their instruction with an input context containing new information\nfor the model to process. However, models struggle to reliably follow the input\ncontext, especially when it conflicts with their parametric knowledge from\npretraining. In-principle, one would expect models to adapt to the user context\nbetter after instruction finetuning, particularly when handling knowledge\nconflicts. However, we observe a surprising failure mode: during instruction\ntuning, the context reliance under knowledge conflicts initially increases as\nexpected, but then gradually decreases as instruction finetuning progresses.\nThis happens while the performance on standard benchmarks keeps on increasing\nfar after this drop. We call this phenomenon context-parametric inversion and\nobserve it across multiple general purpose instruction tuning datasets such as\nTULU, Alpaca and Ultrachat, across different model families like Llama,\nMistral, and Pythia. We perform various controlled studies and theoretical\nanalysis to show that context-parametric inversion occurs due to examples in\nthe instruction finetuning data where the input context provides information\nthat aligns with model's parametric knowledge. Our analysis suggests some\nnatural mitigation strategies with limited but insightful gains, and serves as\na useful starting point in addressing this deficiency in instruction\nfinetuning.\n","authors":["Sachin Goyal","Christina Baek","J. Zico Kolter","Aditi Raghunathan"],"pdf_url":"https://arxiv.org/pdf/2410.10796v2.pdf","comment":"Under Review"},{"id":"http://arxiv.org/abs/2410.17210v1","updated":"2024-10-22T17:34:59Z","published":"2024-10-22T17:34:59Z","title":"Exploring Possibilities of AI-Powered Legal Assistance in Bangladesh\n  through Large Language Modeling","summary":"  Purpose: Bangladesh's legal system struggles with major challenges like\ndelays, complexity, high costs, and millions of unresolved cases, which deter\nmany from pursuing legal action due to lack of knowledge or financial\nconstraints. This research seeks to develop a specialized Large Language Model\n(LLM) to assist in the Bangladeshi legal system. Methods: We created\nUKIL-DB-EN, an English corpus of Bangladeshi legal documents, by collecting and\nscraping data on various legal acts. We fine-tuned the GPT-2 model on this\ndataset to develop GPT2-UKIL-EN, an LLM focused on providing legal assistance\nin English. Results: The model was rigorously evaluated using semantic\nassessments, including case studies supported by expert opinions. The\nevaluation provided promising results, demonstrating the potential for the\nmodel to assist in legal matters within Bangladesh. Conclusion: Our work\nrepresents the first structured effort toward building an AI-based legal\nassistant for Bangladesh. While the results are encouraging, further\nrefinements are necessary to improve the model's accuracy, credibility, and\nsafety. This is a significant step toward creating a legal AI capable of\nserving the needs of a population of 180 million.\n","authors":["Azmine Toushik Wasi","Wahid Faisal","Mst Rafia Islam","Mahathir Mohammad Bappy"],"pdf_url":"https://arxiv.org/pdf/2410.17210v1.pdf","comment":"In Review"},{"id":"http://arxiv.org/abs/2410.17209v1","updated":"2024-10-22T17:31:37Z","published":"2024-10-22T17:31:37Z","title":"Audio-to-Score Conversion Model Based on Whisper methodology","summary":"  This thesis develops a Transformer model based on Whisper, which extracts\nmelodies and chords from music audio and records them into ABC notation. A\ncomprehensive data processing workflow is customized for ABC notation,\nincluding data cleansing, formatting, and conversion, and a mutation mechanism\nis implemented to increase the diversity and quality of training data. This\nthesis innovatively introduces the \"Orpheus' Score\", a custom notation system\nthat converts music information into tokens, designs a custom vocabulary\nlibrary, and trains a corresponding custom tokenizer. Experiments show that\ncompared to traditional algorithms, the model has significantly improved\naccuracy and performance. While providing a convenient audio-to-score tool for\nmusic enthusiasts, this work also provides new ideas and tools for research in\nmusic information processing.\n","authors":["Hongyao Zhang","Bohang Sun"],"pdf_url":"https://arxiv.org/pdf/2410.17209v1.pdf","comment":"5 pages, 7 figures"},{"id":"http://arxiv.org/abs/2410.17196v1","updated":"2024-10-22T17:15:20Z","published":"2024-10-22T17:15:20Z","title":"VoiceBench: Benchmarking LLM-Based Voice Assistants","summary":"  Building on the success of large language models (LLMs), recent advancements\nsuch as GPT-4o have enabled real-time speech interactions through LLM-based\nvoice assistants, offering a significantly improved user experience compared to\ntraditional text-based interactions. However, the absence of benchmarks\ndesigned to evaluate these speech interaction capabilities has hindered\nprogress of LLM-based voice assistants development. Current evaluations focus\nprimarily on automatic speech recognition (ASR) or general knowledge evaluation\nwith clean speeches, neglecting the more intricate, real-world scenarios that\ninvolve diverse speaker characteristics, environmental and content factors. To\naddress this, we introduce VoiceBench, the first benchmark designed to provide\na multi-faceted evaluation of LLM-based voice assistants. VoiceBench also\nincludes both real and synthetic spoken instructions that incorporate the above\nthree key real-world variations. Extensive experiments reveal the limitations\nof current LLM-based voice assistant models and offer valuable insights for\nfuture research and development in this field.\n","authors":["Yiming Chen","Xianghu Yue","Chen Zhang","Xiaoxue Gao","Robby T. Tan","Haizhou Li"],"pdf_url":"https://arxiv.org/pdf/2410.17196v1.pdf","comment":"Work in progress. Data is available at\n  https://github.com/MatthewCYM/VoiceBench"},{"id":"http://arxiv.org/abs/2410.17195v1","updated":"2024-10-22T17:13:38Z","published":"2024-10-22T17:13:38Z","title":"Language Model Non-myopic Generation for Reasoning and Planning","summary":"  Large Language Models have demonstrated remarkable abilities in reasoning and\nplanning by breaking down complex problems into sequential steps. Despite their\nsuccess in various domains like mathematical problem-solving and coding, LLMs\nface challenges in ensuring reliable and optimal planning due to their inherent\nmyopic nature of autoregressive decoding. This paper revisits LLM reasoning\nfrom an optimal-control perspective, proposing a novel method,\nPredictive-Decoding, that leverages Model Predictive Control to enhance\nplanning accuracy. By re-weighting LLM distributions based on foresight\ntrajectories, Predictive-Decoding aims to mitigate early errors and promote\nnon-myopic planning. Our experiments show significant improvements in a wide\nrange of tasks for math, coding, and agents. Furthermore, Predictive-Decoding\ndemonstrates computational efficiency, outperforming search baselines with\nreduced computational resources. This study provides insights into optimizing\nLLM planning capabilities.\n","authors":["Chang Ma","Haiteng Zhao","Junlei Zhang","Junxian He","Lingpeng Kong"],"pdf_url":"https://arxiv.org/pdf/2410.17195v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.08213v2","updated":"2024-10-22T17:07:14Z","published":"2024-03-13T03:22:02Z","title":"Can Large Language Models Identify Authorship?","summary":"  The ability to accurately identify authorship is crucial for verifying\ncontent authenticity and mitigating misinformation. Large Language Models\n(LLMs) have demonstrated an exceptional capacity for reasoning and\nproblem-solving. However, their potential in authorship analysis remains\nunder-explored. Traditional studies have depended on hand-crafted stylistic\nfeatures, whereas state-of-the-art approaches leverage text embeddings from\npre-trained language models. These methods, which typically require fine-tuning\non labeled data, often suffer from performance degradation in cross-domain\napplications and provide limited explainability. This work seeks to address\nthree research questions: (1) Can LLMs perform zero-shot, end-to-end authorship\nverification effectively? (2) Are LLMs capable of accurately attributing\nauthorship among multiple candidates authors (e.g., 10 and 20)? (3) Can LLMs\nprovide explainability in authorship analysis, particularly through the role of\nlinguistic features? Moreover, we investigate the integration of explicit\nlinguistic features to guide LLMs in their reasoning processes. Our assessment\ndemonstrates LLMs' proficiency in both tasks without the need for\ndomain-specific fine-tuning, providing explanations into their decision making\nvia a detailed analysis of linguistic features. This establishes a new\nbenchmark for future research on LLM-based authorship analysis.\n","authors":["Baixiang Huang","Canyu Chen","Kai Shu"],"pdf_url":"https://arxiv.org/pdf/2403.08213v2.pdf","comment":"Accepted to EMNLP 2024 Findings. The main paper is 9 pages long, with\n  16 pages total. The code, results, dataset, and additional resources are\n  available on the project website: https://llm-authorship.github.io/"},{"id":"http://arxiv.org/abs/2409.13686v2","updated":"2024-10-22T17:06:17Z","published":"2024-09-20T17:54:16Z","title":"The Impact of Large Language Models in Academia: from Writing to\n  Speaking","summary":"  Large language models (LLMs) are increasingly impacting human society,\nparticularly in textual information. Based on more than 30,000 papers and 1,000\npresentations from machine learning conferences, we examined and compared the\nwords used in writing and speaking, representing the first large-scale study of\nhow LLMs influence the two main modes of verbal communication and expression\nwithin the same group of people. Our empirical results show that LLM-style\nwords such as \"significant\" have been used more frequently in abstracts and\noral presentations. The impact on speaking is beginning to emerge and is likely\nto grow in the future, calling attention to the implicit influence and ripple\neffect of LLMs on human society.\n","authors":["Mingmeng Geng","Caixi Chen","Yanru Wu","Dongping Chen","Yao Wan","Pan Zhou"],"pdf_url":"https://arxiv.org/pdf/2409.13686v2.pdf","comment":"23 pages"},{"id":"http://arxiv.org/abs/2405.06643v2","updated":"2024-10-22T17:05:17Z","published":"2024-03-06T23:02:30Z","title":"Levels of AI Agents: from Rules to Large Language Models","summary":"  AI agents are defined as artificial entities to perceive the environment,\nmake decisions and take actions. Inspired by the 6 levels of autonomous driving\nby Society of Automotive Engineers, the AI agents are also categorized based on\nutilities and strongness, as the following levels: L0, no AI, with tools taking\ninto account perception plus actions; L1, using rule-based AI; L2, making\nrule-based AI replaced by IL/RL-based AI, with additional reasoning & decision\nmaking; L3, applying LLM-based AI instead of IL/RL-based AI, additionally\nsetting up memory & reflection; L4, based on L3, facilitating autonomous\nlearning & generalization; L5, based on L4, appending personality of emotion\nand character and collaborative behavior with multi-agents.\n","authors":["Yu Huang"],"pdf_url":"https://arxiv.org/pdf/2405.06643v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2407.14344v2","updated":"2024-10-22T16:59:12Z","published":"2024-07-19T14:28:07Z","title":"LLMs left, right, and center: Assessing GPT's capabilities to label\n  political bias from web domains","summary":"  This research investigates whether OpenAI's GPT-4, a state-of-the-art large\nlanguage model, can accurately classify the political bias of news sources\nbased solely on their URLs. Given the subjective nature of political labels,\nthird-party bias ratings like those from Ad Fontes Media, AllSides, and Media\nBias/Fact Check (MBFC) are often used in research to analyze news source\ndiversity. This study aims to determine if GPT-4 can replicate these human\nratings on a seven-degree scale (\"far-left\" to \"far-right\"). The analysis\ncompares GPT-4's classifications against MBFC's, and controls for website\npopularity using Open PageRank scores. Findings reveal a high correlation\n($\\text{Spearman's } \\rho = .89$, $n = 5,877$, $p < 0.001$) between GPT-4's and\nMBFC's ratings, indicating the model's potential reliability. However, GPT-4\nabstained from classifying approximately $\\frac{2}{3}$ of the dataset. It is\nmore likely to abstain from rating unpopular websites, which also suffer from\nless accurate assessments. The LLM tends to avoid classifying sources that MBFC\nconsiders to be centrist, resulting in more polarized outputs. Finally, this\nanalysis shows a slight leftward skew in GPT's classifications compared to\nMBFC's. Therefore, while this paper suggests that while GPT-4 can be a\nscalable, cost-effective tool for political bias classification of news\nwebsites, its use should be as a complement to human judgment to mitigate\nbiases.\n","authors":["Raphael Hernandes","Giulio Corsi"],"pdf_url":"https://arxiv.org/pdf/2407.14344v2.pdf","comment":"12 pages, 4 figures"},{"id":"http://arxiv.org/abs/2410.17174v1","updated":"2024-10-22T16:51:27Z","published":"2024-10-22T16:51:27Z","title":"From Attention to Activation: Unravelling the Enigmas of Large Language\n  Models","summary":"  We study two strange phenomena in auto-regressive Transformers: (1) the\ndominance of the first token in attention heads; (2) the occurrence of large\noutlier activations in the hidden states. We find that popular large language\nmodels, such as Llama attend maximally to the first token in 98% of attention\nheads, a behaviour we attribute to the softmax function. To mitigate this\nissue, we propose a reformulation of softmax to softmax-1. Furthermore, we\nidentify adaptive optimisers, e.g. Adam, as the primary contributor to the\nlarge outlier activations and introduce OrthoAdam, a novel optimiser that\nutilises orthogonal matrices to transform gradients, to address this issue.\nFinally, not only do our methods prevent these phenomena from occurring, but\nadditionally, they enable Transformers to sustain their performance when\nquantised using basic algorithms, something that standard methods are unable to\ndo. In summary, our methods reduce the attention proportion on the first token\nfrom 65% to 3.3%, the activation kurtosis in the hidden states from 1657 to\n3.1, and perplexity penalty under 4-bit weight quantisation from 3565 to 0.3.\n","authors":["Prannay Kaul","Chengcheng Ma","Ismail Elezi","Jiankang Deng"],"pdf_url":"https://arxiv.org/pdf/2410.17174v1.pdf","comment":"10 pages"},{"id":"http://arxiv.org/abs/2410.17170v1","updated":"2024-10-22T16:50:00Z","published":"2024-10-22T16:50:00Z","title":"Self-calibration for Language Model Quantization and Pruning","summary":"  Quantization and pruning are fundamental approaches for model compression,\nenabling efficient inference for language models. In a post-training setting,\nstate-of-the-art quantization and pruning methods require calibration data, a\nsmall set of unlabeled examples. Conventionally, randomly sampled web text is\nused, aiming to reflect the model training data. However, this poses two key\nproblems: (1) unrepresentative calibration examples can harm model performance,\nand (2) organizations increasingly avoid releasing model training data. In this\npaper, we propose self-calibration as a solution. Our approach requires no\nexternal data, instead leveraging the model itself to generate synthetic\ncalibration data as a better approximation of the pre-training data\ndistribution. We extensively compare the performance of self-calibration with\nseveral baselines, across a variety of models, compression methods, and tasks.\nOur approach proves consistently competitive in maximizing downstream task\nperformance, frequently outperforming even using real data.\n","authors":["Miles Williams","George Chrysostomou","Nikolaos Aletras"],"pdf_url":"https://arxiv.org/pdf/2410.17170v1.pdf","comment":"Work in progress"},{"id":"http://arxiv.org/abs/2410.17161v1","updated":"2024-10-22T16:34:36Z","published":"2024-10-22T16:34:36Z","title":"Interchangeable Token Embeddings for Extendable Vocabulary and\n  Alpha-Equivalence","summary":"  We propose a novel approach for learning interchangeable tokens in language\nmodels to obtain an extendable vocabulary that can generalize to new tokens.\nOur method is designed to address alpha-equivalence, the principle that\nrenaming bound variables in a syntactic expression preserves semantics. This\nproperty arises in many formal languages such as temporal logics, in which all\nproposition symbols represent the same concept but are distinguishable from\neach other. To handle such tokens, we develop a dual-part embedding approach.\nThe first part is shared across all interchangeable tokens, thereby enforcing\nthat they represent the same core concept. The second part is randomly\ngenerated for each token, which enables distinguishability. We evaluate our\nmethod in a Transformer encoder-decoder model on two tasks: solving linear\ntemporal logic formulae and copying with extendable vocabulary. Our method\ndemonstrates promising generalization capabilities in addition to introducing a\nfavorable inductive bias for alpha-equivalence.\n","authors":["İlker Işık","Ramazan Gokberk Cinbis","Ebru Aydin Gol"],"pdf_url":"https://arxiv.org/pdf/2410.17161v1.pdf","comment":"14 pages, 5 figures"},{"id":"http://arxiv.org/abs/2410.17152v1","updated":"2024-10-22T16:29:33Z","published":"2024-10-22T16:29:33Z","title":"Improving Pinterest Search Relevance Using Large Language Models","summary":"  To improve relevance scoring on Pinterest Search, we integrate Large Language\nModels (LLMs) into our search relevance model, leveraging carefully designed\ntext representations to predict the relevance of Pins effectively. Our approach\nuses search queries alongside content representations that include captions\nextracted from a generative visual language model. These are further enriched\nwith link-based text data, historically high-quality engaged queries,\nuser-curated boards, Pin titles and Pin descriptions, creating robust models\nfor predicting search relevance. We use a semi-supervised learning approach to\nefficiently scale up the amount of training data, expanding beyond the\nexpensive human labeled data available. By utilizing multilingual LLMs, our\nsystem extends training data to include unseen languages and domains, despite\ninitial data and annotator expertise being confined to English. Furthermore, we\ndistill from the LLM-based model into real-time servable model architectures\nand features. We provide comprehensive offline experimental validation for our\nproposed techniques and demonstrate the gains achieved through the final\ndeployed system at scale.\n","authors":["Han Wang","Mukuntha Narayanan Sundararaman","Onur Gungor","Yu Xu","Krishna Kamath","Rakesh Chalasani","Kurchi Subhra Hazra","Jinfeng Rao"],"pdf_url":"https://arxiv.org/pdf/2410.17152v1.pdf","comment":"CIKM 2024 Workshop on Industrial Recommendation Systems"},{"id":"http://arxiv.org/abs/2410.14594v2","updated":"2024-10-22T16:27:12Z","published":"2024-10-18T16:44:22Z","title":"Toolshed: Scale Tool-Equipped Agents with Advanced RAG-Tool Fusion and\n  Tool Knowledge Bases","summary":"  Recent advancements in tool-equipped Agents (LLMs) have enabled complex tasks\nlike secure database interactions and multi-agent code development. However,\nscaling tool capacity beyond agent reasoning or model limits remains a\nchallenge. In this paper, we address these challenges by introducing Toolshed\nKnowledge Bases, a tool knowledge base (vector database) designed to store\nenhanced tool representations and optimize tool selection for large-scale\ntool-equipped Agents. Additionally, we propose Advanced RAG-Tool Fusion, a\nnovel ensemble of tool-applied advanced retrieval-augmented generation (RAG)\ntechniques across the pre-retrieval, intra-retrieval, and post-retrieval\nphases, without requiring model fine-tuning. During pre-retrieval, tool\ndocuments are enhanced with key information and stored in the Toolshed\nKnowledge Base. Intra-retrieval focuses on query planning and transformation to\nincrease retrieval accuracy. Post-retrieval refines the retrieved tool\ndocuments and enables self-reflection. Furthermore, by varying both the total\nnumber of tools (tool-M) an Agent has access to and the tool selection\nthreshold (top-k), we address trade-offs between retrieval accuracy, agent\nperformance, and token cost. Our approach achieves 46%, 56%, and 47% absolute\nimprovements on the ToolE single-tool, ToolE multi-tool and Seal-Tools\nbenchmark datasets, respectively (Recall@5).\n","authors":["Elias Lumer","Vamse Kumar Subbiah","James A. Burke","Pradeep Honaganahalli Basavaraju","Austin Huber"],"pdf_url":"https://arxiv.org/pdf/2410.14594v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.17145v1","updated":"2024-10-22T16:26:03Z","published":"2024-10-22T16:26:03Z","title":"Can General-Purpose Large Language Models Generalize to English-Thai\n  Machine Translation ?","summary":"  Large language models (LLMs) perform well on common tasks but struggle with\ngeneralization in low-resource and low-computation settings. We examine this\nlimitation by testing various LLMs and specialized translation models on\nEnglish-Thai machine translation and code-switching datasets. Our findings\nreveal that under more strict computational constraints, such as 4-bit\nquantization, LLMs fail to translate effectively. In contrast, specialized\nmodels, with comparable or lower computational requirements, consistently\noutperform LLMs. This underscores the importance of specialized models for\nmaintaining performance under resource constraints.\n","authors":["Jirat Chiaranaipanich","Naiyarat Hanmatheekuna","Jitkapat Sawatphol","Krittamate Tiankanon","Jiramet Kinchagawat","Amrest Chinkamol","Parinthapat Pengpun","Piyalitt Ittichaiwong","Peerat Limkonchotiwat"],"pdf_url":"https://arxiv.org/pdf/2410.17145v1.pdf","comment":"Accepted in GenBench EMNLP 2024"},{"id":"http://arxiv.org/abs/2410.14669v2","updated":"2024-10-22T16:07:22Z","published":"2024-10-18T17:58:21Z","title":"NaturalBench: Evaluating Vision-Language Models on Natural Adversarial\n  Samples","summary":"  Vision-language models (VLMs) have made significant progress in recent\nvisual-question-answering (VQA) benchmarks that evaluate complex\nvisio-linguistic reasoning. However, are these models truly effective? In this\nwork, we show that VLMs still struggle with natural images and questions that\nhumans can easily answer, which we term natural adversarial samples. We also\nfind it surprisingly easy to generate these VQA samples from natural image-text\ncorpora using off-the-shelf models like CLIP and ChatGPT. We propose a\nsemi-automated approach to collect a new benchmark, NaturalBench, for reliably\nevaluating VLMs with 10,000 human-verified VQA samples. Crucially, we adopt a\n$\\textbf{vision-centric}$ design by pairing each question with two images that\nyield different answers, preventing blind solutions from answering without\nusing the images. This makes NaturalBench more challenging than previous\nbenchmarks that can be solved with commonsense priors. We evaluate 53\nstate-of-the-art VLMs on NaturalBench, showing that models like\nLLaVA-OneVision, Cambrian-1, Llama3.2-Vision, Molmo, Qwen2-VL, and even GPT-4o\nlag 50%-70% behind human performance (over 90%). We analyze why NaturalBench is\nhard from two angles: (1) Compositionality: Solving NaturalBench requires\ndiverse visio-linguistic skills, including understanding attribute bindings,\nobject relationships, and advanced reasoning like logic and counting. To this\nend, unlike prior work that uses a single tag per sample, we tag each\nNaturalBench sample with 1 to 8 skill tags for fine-grained evaluation. (2)\nBiases: NaturalBench exposes severe biases in VLMs, as models often choose the\nsame answer regardless of the image. Lastly, we apply our benchmark curation\nmethod to diverse data sources, including long captions (over 100 words) and\nnon-English languages like Chinese and Hindi, highlighting its potential for\ndynamic evaluations of VLMs.\n","authors":["Baiqi Li","Zhiqiu Lin","Wenxuan Peng","Jean de Dieu Nyandwi","Daniel Jiang","Zixian Ma","Simran Khanuja","Ranjay Krishna","Graham Neubig","Deva Ramanan"],"pdf_url":"https://arxiv.org/pdf/2410.14669v2.pdf","comment":"Accepted to NeurIPS 24; We open-source our dataset at:\n  https://huggingface.co/datasets/BaiqiL/NaturalBench ; Project page at:\n  https://linzhiqiu.github.io/papers/naturalbench/"},{"id":"http://arxiv.org/abs/2410.17131v1","updated":"2024-10-22T16:04:03Z","published":"2024-10-22T16:04:03Z","title":"Aligning Large Language Models via Self-Steering Optimization","summary":"  Automated alignment develops alignment systems with minimal human\nintervention. The key to automated alignment lies in providing learnable and\naccurate preference signals for preference learning without human annotation.\nIn this paper, we introduce Self-Steering Optimization ($SSO$), an algorithm\nthat autonomously generates high-quality preference signals based on predefined\nprinciples during iterative training, eliminating the need for manual\nannotation. $SSO$ maintains the accuracy of signals by ensuring a consistent\ngap between chosen and rejected responses while keeping them both on-policy to\nsuit the current policy model's learning capacity. $SSO$ can benefit the online\nand offline training of the policy model, as well as enhance the training of\nreward models. We validate the effectiveness of $SSO$ with two foundation\nmodels, Qwen2 and Llama3.1, indicating that it provides accurate, on-policy\npreference signals throughout iterative training. Without any manual annotation\nor external models, $SSO$ leads to significant performance improvements across\nsix subjective or objective benchmarks. Besides, the preference data generated\nby $SSO$ significantly enhanced the performance of the reward model on\nRewardbench. Our work presents a scalable approach to preference optimization,\npaving the way for more efficient and effective automated alignment.\n","authors":["Hao Xiang","Bowen Yu","Hongyu Lin","Keming Lu","Yaojie Lu","Xianpei Han","Le Sun","Jingren Zhou","Junyang Lin"],"pdf_url":"https://arxiv.org/pdf/2410.17131v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.17127v1","updated":"2024-10-22T16:00:26Z","published":"2024-10-22T16:00:26Z","title":"PAPILLON: PrivAcy Preservation from Internet-based and Local Language\n  MOdel ENsembles","summary":"  Users can divulge sensitive information to proprietary LLM providers, raising\nsignificant privacy concerns. While open-source models, hosted locally on the\nuser's machine, alleviate some concerns, models that users can host locally are\noften less capable than proprietary frontier models. Toward preserving user\nprivacy while retaining the best quality, we propose Privacy-Conscious\nDelegation, a novel task for chaining API-based and local models. We utilize\nrecent public collections of user-LLM interactions to construct a natural\nbenchmark called PUPA, which contains personally identifiable information\n(PII). To study potential approaches, we devise PAPILLON, a multi-stage LLM\npipeline that uses prompt optimization to address a simpler version of our\ntask. Our best pipeline maintains high response quality for 85.5% of user\nqueries while restricting privacy leakage to only 7.5%. We still leave a large\nmargin to the generation quality of proprietary LLMs for future work. Our data\nand code will be available at https://github.com/siyan-sylvia-li/PAPILLON.\n","authors":["Li Siyan","Vethavikashini Chithrra Raghuram","Omar Khattab","Julia Hirschberg","Zhou Yu"],"pdf_url":"https://arxiv.org/pdf/2410.17127v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.17126v1","updated":"2024-10-22T15:59:58Z","published":"2024-10-22T15:59:58Z","title":"Exploring RL-based LLM Training for Formal Language Tasks with\n  Programmed Rewards","summary":"  Proximal Policy Optimization (PPO) is commonly used in Reinforcement Learning\nfrom Human Feedback to align large language models (LLMs) with downstream\ntasks. This paper investigates the feasibility of using PPO for direct\nreinforcement learning (RL) from explicitly programmed reward signals, as\nopposed to indirect learning from human feedback via an intermediary reward\nmodel. We focus on tasks expressed through formal languages, such as\nmathematics and programming, where explicit reward functions can be programmed\nto automatically assess the quality of generated outputs. We apply this\napproach to a sentiment alignment task, a simple arithmetic task, and a more\ncomplex game synthesis task. The sentiment alignment task replicates prior\nresearch and serves to validate our experimental setup. Our results show that\npure RL-based training for the two formal language tasks is challenging, with\nsuccess being limited even for the simple arithmetic task. We propose a novel\nbatch-entropy regularization term to aid exploration, although training is not\nyet entirely stable. Our findings suggest that direct RL training of LLMs may\nbe more suitable for relatively minor changes, such as alignment, than for\nlearning new tasks altogether, even if an informative reward signal can be\nexpressed programmatically.\n","authors":["Alexander G. Padula","Dennis J. N. J. Soemers"],"pdf_url":"https://arxiv.org/pdf/2410.17126v1.pdf","comment":"Accepted at BNAIC 2024"},{"id":"http://arxiv.org/abs/2410.17112v1","updated":"2024-10-22T15:37:46Z","published":"2024-10-22T15:37:46Z","title":"Enhancing Answer Attribution for Faithful Text Generation with Large\n  Language Models","summary":"  The increasing popularity of Large Language Models (LLMs) in recent years has\nchanged the way users interact with and pose questions to AI-based\nconversational systems. An essential aspect for increasing the trustworthiness\nof generated LLM answers is the ability to trace the individual claims from\nresponses back to relevant sources that support them, the process known as\nanswer attribution. While recent work has started exploring the task of answer\nattribution in LLMs, some challenges still remain. In this work, we first\nperform a case study analyzing the effectiveness of existing answer attribution\nmethods, with a focus on subtasks of answer segmentation and evidence\nretrieval. Based on the observed shortcomings, we propose new methods for\nproducing more independent and contextualized claims for better retrieval and\nattribution. The new methods are evaluated and shown to improve the performance\nof answer attribution components. We end with a discussion and outline of\nfuture directions for the task.\n","authors":["Juraj Vladika","Luca Mülln","Florian Matthes"],"pdf_url":"https://arxiv.org/pdf/2410.17112v1.pdf","comment":"Accepted to KDIR 2024 (part of IC3K 2024)"},{"id":"http://arxiv.org/abs/2410.17099v1","updated":"2024-10-22T15:22:58Z","published":"2024-10-22T15:22:58Z","title":"Human-LLM Hybrid Text Answer Aggregation for Crowd Annotations","summary":"  The quality is a crucial issue for crowd annotations. Answer aggregation is\nan important type of solution. The aggregated answers estimated from multiple\ncrowd answers to the same instance are the eventually collected annotations,\nrather than the individual crowd answers themselves. Recently, the capability\nof Large Language Models (LLMs) on data annotation tasks has attracted interest\nfrom researchers. Most of the existing studies mainly focus on the average\nperformance of individual crowd workers; several recent works studied the\nscenarios of aggregation on categorical labels and LLMs used as label creators.\nHowever, the scenario of aggregation on text answers and the role of LLMs as\naggregators are not yet well-studied. In this paper, we investigate the\ncapability of LLMs as aggregators in the scenario of close-ended crowd text\nanswer aggregation. We propose a human-LLM hybrid text answer aggregation\nmethod with a Creator-Aggregator Multi-Stage (CAMS) crowdsourcing framework. We\nmake the experiments based on public crowdsourcing datasets. The results show\nthe effectiveness of our approach based on the collaboration of crowd workers\nand LLMs.\n","authors":["Jiyi Li"],"pdf_url":"https://arxiv.org/pdf/2410.17099v1.pdf","comment":"Accepted in EMNLP 2024"},{"id":"http://arxiv.org/abs/2410.14516v2","updated":"2024-10-22T15:20:00Z","published":"2024-10-18T14:55:14Z","title":"Do LLMs \"know\" internally when they follow instructions?","summary":"  Instruction-following is crucial for building AI agents with large language\nmodels (LLMs), as these models must adhere strictly to user-provided\nconstraints and guidelines. However, LLMs often fail to follow even simple and\nclear instructions. To improve instruction-following behavior and prevent\nundesirable outputs, a deeper understanding of how LLMs' internal states relate\nto these outcomes is required. Our analysis of LLM internal states reveal a\ndimension in the input embedding space linked to successful\ninstruction-following. We demonstrate that modifying representations along this\ndimension improves instruction-following success rates compared to random\nchanges, without compromising response quality. Further investigation reveals\nthat this dimension is more closely related to the phrasing of prompts rather\nthan the inherent difficulty of the task or instructions. This discovery also\nsuggests explanations for why LLMs sometimes fail to follow clear instructions\nand why prompt engineering is often effective, even when the content remains\nlargely unchanged. This work provides insight into the internal workings of\nLLMs' instruction-following, paving the way for reliable LLM agents.\n","authors":["Juyeon Heo","Christina Heinze-Deml","Oussama Elachqar","Shirley Ren","Udhay Nallasamy","Andy Miller","Kwan Ho Ryan Chan","Jaya Narain"],"pdf_url":"https://arxiv.org/pdf/2410.14516v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2209.13023v2","updated":"2024-10-22T15:18:55Z","published":"2022-09-26T20:49:18Z","title":"Lex2Sent: A bagging approach to unsupervised sentiment analysis","summary":"  Unsupervised text classification, with its most common form being sentiment\nanalysis, used to be performed by counting words in a text that were stored in\na lexicon, which assigns each word to one class or as a neutral word. In recent\nyears, these lexicon-based methods fell out of favor and were replaced by\ncomputationally demanding fine-tuning techniques for encoder-only models such\nas BERT and zero-shot classification using decoder-only models such as GPT-4.\nIn this paper, we propose an alternative approach: Lex2Sent, which provides\nimprovement over classic lexicon methods but does not require any GPU or\nexternal hardware. To classify texts, we train embedding models to determine\nthe distances between document embeddings and the embeddings of the parts of a\nsuitable lexicon. We employ resampling, which results in a bagging effect,\nboosting the performance of the classification. We show that our model\noutperforms lexica and provides a basis for a high performing few-shot\nfine-tuning approach in the task of binary sentiment analysis.\n","authors":["Kai-Robin Lange","Jonas Rieger","Carsten Jentsch"],"pdf_url":"https://arxiv.org/pdf/2209.13023v2.pdf","comment":"11 pages, 1 figure"},{"id":"http://arxiv.org/abs/2410.14582v2","updated":"2024-10-22T15:16:14Z","published":"2024-10-18T16:32:10Z","title":"Do LLMs estimate uncertainty well in instruction-following?","summary":"  Large language models (LLMs) could be valuable personal AI agents across\nvarious domains, provided they can precisely follow user instructions. However,\nrecent studies have shown significant limitations in LLMs'\ninstruction-following capabilities, raising concerns about their reliability in\nhigh-stakes applications. Accurately estimating LLMs' uncertainty in adhering\nto instructions is critical to mitigating deployment risks. We present, to our\nknowledge, the first systematic evaluation of the uncertainty estimation\nabilities of LLMs in the context of instruction-following. Our study identifies\nkey challenges with existing instruction-following benchmarks, where multiple\nfactors are entangled with uncertainty stems from instruction-following,\ncomplicating the isolation and comparison across methods and models. To address\nthese issues, we introduce a controlled evaluation setup with two benchmark\nversions of data, enabling a comprehensive comparison of uncertainty estimation\nmethods under various conditions. Our findings show that existing uncertainty\nmethods struggle, particularly when models make subtle errors in instruction\nfollowing. While internal model states provide some improvement, they remain\ninadequate in more complex scenarios. The insights from our controlled\nevaluation setups provide a crucial understanding of LLMs' limitations and\npotential for uncertainty estimation in instruction-following tasks, paving the\nway for more trustworthy AI agents.\n","authors":["Juyeon Heo","Miao Xiong","Christina Heinze-Deml","Jaya Narain"],"pdf_url":"https://arxiv.org/pdf/2410.14582v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.17088v1","updated":"2024-10-22T15:14:54Z","published":"2024-10-22T15:14:54Z","title":"Science Out of Its Ivory Tower: Improving Accessibility with\n  Reinforcement Learning","summary":"  A vast amount of scholarly work is published daily, yet much of it remains\ninaccessible to the general public due to dense jargon and complex language. To\naddress this challenge in science communication, we introduce a reinforcement\nlearning framework that fine-tunes a language model to rewrite scholarly\nabstracts into more comprehensible versions. Guided by a carefully balanced\ncombination of word- and sentence-level accessibility rewards, our language\nmodel effectively substitutes technical terms with more accessible\nalternatives, a task which models supervised fine-tuned or guided by\nconventional readability measures struggle to accomplish. Our best model\nadjusts the readability level of scholarly abstracts by approximately six U.S.\ngrade levels -- in other words, from a postgraduate to a high school level.\nThis translates to roughly a 90% relative boost over the supervised fine-tuning\nbaseline, all while maintaining factual accuracy and high-quality language. An\nin-depth analysis of our approach shows that balanced rewards lead to\nsystematic modifications in the base model, likely contributing to smoother\noptimization and superior performance. We envision this work as a step toward\nbridging the gap between scholarly research and the general public,\nparticularly younger readers and those without a college degree.\n","authors":["Haining Wang","Jason Clark","Hannah McKelvey","Leila Sterman","Zheng Gao","Zuoyu Tian","Sandra Kübler","Xiaozhong Liu"],"pdf_url":"https://arxiv.org/pdf/2410.17088v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.16264v3","updated":"2024-10-22T15:09:58Z","published":"2024-06-24T02:03:57Z","title":"One Thousand and One Pairs: A \"novel\" challenge for long-context\n  language models","summary":"  Synthetic long-context LLM benchmarks (e.g., \"needle-in-the-haystack\") test\nonly surface-level retrieval capabilities, but how well can long-context LLMs\nretrieve, synthesize, and reason over information across book-length inputs? We\naddress this question by creating NoCha, a dataset of 1,001 minimally different\npairs of true and false claims about 67 recently-published English fictional\nbooks, written by human readers of those books. In contrast to existing\nlong-context benchmarks, our annotators confirm that the largest share of pairs\nin NoCha require global reasoning over the entire book to verify. Our\nexperiments show that while human readers easily perform this task, it is\nenormously challenging for all ten long-context LLMs that we evaluate: no\nopen-weight model performs above random chance (despite their strong\nperformance on synthetic benchmarks), while GPT-4o achieves the highest\naccuracy at 55.8%. Further analysis reveals that (1) on average, models perform\nmuch better on pairs that require only sentence-level retrieval vs. global\nreasoning; (2) model-generated explanations for their decisions are often\ninaccurate even for correctly-labeled claims; and (3) models perform\nsubstantially worse on speculative fiction books that contain extensive\nworld-building. The methodology proposed in NoCha allows for the evolution of\nthe benchmark dataset and the easy analysis of future models.\n","authors":["Marzena Karpinska","Katherine Thai","Kyle Lo","Tanya Goyal","Mohit Iyyer"],"pdf_url":"https://arxiv.org/pdf/2406.16264v3.pdf","comment":"EMNLP 2024, camera ready"},{"id":"http://arxiv.org/abs/2408.10943v2","updated":"2024-10-22T15:07:35Z","published":"2024-08-20T15:33:16Z","title":"SysBench: Can Large Language Models Follow System Messages?","summary":"  Large Language Models (LLMs) have become instrumental across various\napplications, with the customization of these models to specific scenarios\nbecoming increasingly critical. System message, a fundamental component of\nLLMs, is consist of carefully crafted instructions that guide the behavior of\nmodel to meet intended goals. Despite the recognized potential of system\nmessages to optimize AI-driven solutions, there is a notable absence of a\ncomprehensive benchmark for evaluating how well LLMs follow system messages. To\nfill this gap, we introduce SysBench, a benchmark that systematically analyzes\nsystem message following ability in terms of three limitations of existing\nLLMs: constraint violation, instruction misjudgement and multi-turn\ninstability. Specifically, we manually construct evaluation dataset based on\nsix prevalent types of constraints, including 500 tailor-designed system\nmessages and multi-turn user conversations covering various interaction\nrelationships. Additionally, we develop a comprehensive evaluation protocol to\nmeasure model performance. Finally, we conduct extensive evaluation across\nvarious existing LLMs, measuring their ability to follow specified constraints\ngiven in system messages. The results highlight both the strengths and\nweaknesses of existing models, offering key insights and directions for future\nresearch. The open source library SysBench is available at\nhttps://github.com/PKU-Baichuan-MLSystemLab/SysBench.\n","authors":["Yanzhao Qin","Tao Zhang","Tao Zhang","Yanjun Shen","Wenjing Luo","Haoze Sun","Yan Zhang","Yujing Qiao","Weipeng Chen","Zenan Zhou","Wentao Zhang","Bin Cui"],"pdf_url":"https://arxiv.org/pdf/2408.10943v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.17081v1","updated":"2024-10-22T15:02:37Z","published":"2024-10-22T15:02:37Z","title":"Continuous Speech Tokenizer in Text To Speech","summary":"  The fusion of speech and language in the era of large language models has\ngarnered significant attention. Discrete speech token is often utilized in\ntext-to-speech tasks for speech compression and portability, which is\nconvenient for joint training with text and have good compression efficiency.\nHowever, we found that the discrete speech tokenizer still suffers from\ninformation loss. Therefore, we propose a simple yet effective continuous\nspeech tokenizer and a text-to-speech model based on continuous speech tokens.\nOur results show that the speech language model based on the continuous speech\ntokenizer has better continuity and higher estimated Mean Opinion Scores (MoS).\nThis enhancement is attributed to better information preservation rate of the\ncontinuous speech tokenizer across both low and high frequencies in the\nfrequency domain.\n","authors":["Yixing Li","Ruobing Xie","Xingwu Sun","Yu Cheng","Zhanhui Kang"],"pdf_url":"https://arxiv.org/pdf/2410.17081v1.pdf","comment":"4 pages. Under review"},{"id":"http://arxiv.org/abs/2410.17051v1","updated":"2024-10-22T14:30:40Z","published":"2024-10-22T14:30:40Z","title":"Data-driven Coreference-based Ontology Building","summary":"  While coreference resolution is traditionally used as a component in\nindividual document understanding, in this work we take a more global view and\nexplore what can we learn about a domain from the set of all document-level\ncoreference relations that are present in a large corpus. We derive coreference\nchains from a corpus of 30 million biomedical abstracts and construct a graph\nbased on the string phrases within these chains, establishing connections\nbetween phrases if they co-occur within the same coreference chain. We then use\nthe graph structure and the betweeness centrality measure to distinguish\nbetween edges denoting hierarchy, identity and noise, assign directionality to\nedges denoting hierarchy, and split nodes (strings) that correspond to multiple\ndistinct concepts. The result is a rich, data-driven ontology over concepts in\nthe biomedical domain, parts of which overlaps significantly with\nhuman-authored ontologies. We release the coreference chains and resulting\nontology under a creative-commons license, along with the code.\n","authors":["Shir Ashury-Tahan","Amir David Nissan Cohen","Nadav Cohen","Yoram Louzoun","Yoav Goldberg"],"pdf_url":"https://arxiv.org/pdf/2410.17051v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.17050v1","updated":"2024-10-22T14:30:03Z","published":"2024-10-22T14:30:03Z","title":"UnStar: Unlearning with Self-Taught Anti-Sample Reasoning for LLMs","summary":"  The key components of machine learning are data samples for training, model\nfor learning patterns, and loss function for optimizing accuracy. Analogously,\nunlearning can potentially be achieved through anti-data samples (or\nanti-samples), unlearning method, and reversed loss function. While prior\nresearch has explored unlearning methods and reversed loss functions, the\npotential of anti-samples remains largely untapped. In this paper, we introduce\nUnSTAR: Unlearning with Self-Taught Anti-Sample Reasoning for large language\nmodels (LLMs). Our contributions are threefold; first, we propose a novel\nconcept of anti-sample-induced unlearning; second, we generate anti-samples by\nleveraging misleading rationales, which help reverse learned associations and\naccelerate the unlearning process; and third, we enable fine-grained targeted\nunlearning, allowing for the selective removal of specific associations without\nimpacting related knowledge - something not achievable by previous works.\nResults demonstrate that anti-samples offer an efficient, targeted unlearning\nstrategy for LLMs, opening new avenues for privacy-preserving machine learning\nand model modification.\n","authors":["Yash Sinha","Murari Mandal","Mohan Kankanhalli"],"pdf_url":"https://arxiv.org/pdf/2410.17050v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.17040v1","updated":"2024-10-22T14:12:43Z","published":"2024-10-22T14:12:43Z","title":"Arabic Dataset for LLM Safeguard Evaluation","summary":"  The growing use of large language models (LLMs) has raised concerns regarding\ntheir safety. While many studies have focused on English, the safety of LLMs in\nArabic, with its linguistic and cultural complexities, remains under-explored.\nHere, we aim to bridge this gap. In particular, we present an\nArab-region-specific safety evaluation dataset consisting of 5,799 questions,\nincluding direct attacks, indirect attacks, and harmless requests with\nsensitive words, adapted to reflect the socio-cultural context of the Arab\nworld. To uncover the impact of different stances in handling sensitive and\ncontroversial topics, we propose a dual-perspective evaluation framework. It\nassesses the LLM responses from both governmental and opposition viewpoints.\nExperiments over five leading Arabic-centric and multilingual LLMs reveal\nsubstantial disparities in their safety performance. This reinforces the need\nfor culturally specific datasets to ensure the responsible deployment of LLMs.\n","authors":["Yasser Ashraf","Yuxia Wang","Bin Gu","Preslav Nakov","Timothy Baldwin"],"pdf_url":"https://arxiv.org/pdf/2410.17040v1.pdf","comment":"17 pages, 6 figures, 10 tables"},{"id":"http://arxiv.org/abs/2404.18923v4","updated":"2024-10-22T14:08:52Z","published":"2024-04-29T17:58:36Z","title":"Holmes: A Benchmark to Assess the Linguistic Competence of Language\n  Models","summary":"  We introduce Holmes, a new benchmark designed to assess language models (LMs)\nlinguistic competence - their unconscious understanding of linguistic\nphenomena. Specifically, we use classifier-based probing to examine LMs'\ninternal representations regarding distinct linguistic phenomena (e.g.,\npart-of-speech tagging). As a result, we meet recent calls to disentangle LMs'\nlinguistic competence from other cognitive abilities, such as following\ninstructions in prompting-based evaluations. Composing Holmes, we review over\n270 probing studies and include more than 200 datasets to assess syntax,\nmorphology, semantics, reasoning, and discourse phenomena. Analyzing over 50\nLMs reveals that, aligned with known trends, their linguistic competence\ncorrelates with model size. However, surprisingly, model architecture and\ninstruction tuning also significantly influence performance, particularly in\nmorphology and syntax. Finally, we propose FlashHolmes, a streamlined version\nthat reduces the computation load while maintaining high-ranking precision.\n","authors":["Andreas Waldis","Yotam Perlitz","Leshem Choshen","Yufang Hou","Iryna Gurevych"],"pdf_url":"https://arxiv.org/pdf/2404.18923v4.pdf","comment":null},{"id":"http://arxiv.org/abs/2404.13948v2","updated":"2024-10-22T14:07:57Z","published":"2024-04-22T07:49:36Z","title":"Typos that Broke the RAG's Back: Genetic Attack on RAG Pipeline by\n  Simulating Documents in the Wild via Low-level Perturbations","summary":"  The robustness of recent Large Language Models (LLMs) has become increasingly\ncrucial as their applicability expands across various domains and real-world\napplications. Retrieval-Augmented Generation (RAG) is a promising solution for\naddressing the limitations of LLMs, yet existing studies on the robustness of\nRAG often overlook the interconnected relationships between RAG components or\nthe potential threats prevalent in real-world databases, such as minor textual\nerrors. In this work, we investigate two underexplored aspects when assessing\nthe robustness of RAG: 1) vulnerability to noisy documents through low-level\nperturbations and 2) a holistic evaluation of RAG robustness. Furthermore, we\nintroduce a novel attack method, the Genetic Attack on RAG (\\textit{GARAG}),\nwhich targets these aspects. Specifically, GARAG is designed to reveal\nvulnerabilities within each component and test the overall system functionality\nagainst noisy documents. We validate RAG robustness by applying our\n\\textit{GARAG} to standard QA datasets, incorporating diverse retrievers and\nLLMs. The experimental results show that GARAG consistently achieves high\nattack success rates. Also, it significantly devastates the performance of each\ncomponent and their synergy, highlighting the substantial risk that minor\ntextual inaccuracies pose in disrupting RAG systems in the real world.\n","authors":["Sukmin Cho","Soyeong Jeong","Jeongyeon Seo","Taeho Hwang","Jong C. Park"],"pdf_url":"https://arxiv.org/pdf/2404.13948v2.pdf","comment":"Findings of EMNLP Camera-ready version"},{"id":"http://arxiv.org/abs/2410.17035v1","updated":"2024-10-22T14:06:31Z","published":"2024-10-22T14:06:31Z","title":"DIRI: Adversarial Patient Reidentification with Large Language Models\n  for Evaluating Clinical Text Anonymization","summary":"  Sharing protected health information (PHI) is critical for furthering\nbiomedical research. Before data can be distributed, practitioners often\nperform deidentification to remove any PHI contained in the text. Contemporary\ndeidentification methods are evaluated on highly saturated datasets (tools\nachieve near-perfect accuracy) which may not reflect the full variability or\ncomplexity of real-world clinical text and annotating them is resource\nintensive, which is a barrier to real-world applications. To address this gap,\nwe developed an adversarial approach using a large language model (LLM) to\nre-identify the patient corresponding to a redacted clinical note and evaluated\nthe performance with a novel De-Identification/Re-Identification (DIRI) method.\nOur method uses a large language model to reidentify the patient corresponding\nto a redacted clinical note. We demonstrate our method on medical data from\nWeill Cornell Medicine anonymized with three deidentification tools: rule-based\nPhilter and two deep-learning-based models, BiLSTM-CRF and ClinicalBERT.\nAlthough ClinicalBERT was the most effective, masking all identified PII, our\ntool still reidentified 9% of clinical notes Our study highlights significant\nweaknesses in current deidentification technologies while providing a tool for\niterative development and improvement.\n","authors":["John X. Morris","Thomas R. Campion","Sri Laasya Nutheti","Yifan Peng","Akhil Raj","Ramin Zabih","Curtis L. Cole"],"pdf_url":"https://arxiv.org/pdf/2410.17035v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.17028v1","updated":"2024-10-22T13:52:51Z","published":"2024-10-22T13:52:51Z","title":"Can a Machine Distinguish High and Low Amount of Social Creak in Speech?","summary":"  Objectives: ncreased prevalence of social creak particularly among female\nspeakers has been reported in several studies. The study of social creak has\nbeen previously conducted by combining perceptual evaluation of speech with\nconventional acoustical parameters such as the harmonic-to-noise ratio and\ncepstral peak prominence. In the current study, machine learning (ML) was used\nto automatically distinguish speech of low amount of social creak from speech\nof high amount of social creak.\n  Methods: The amount of creak in continuous speech samples produced in Finnish\nby 90 female speakers was first perceptually assessed by two voice specialists.\nBased on their assessments, the speech samples were divided into two categories\n(low $vs$. high amount of creak). Using the speech signals and their creak\nlabels, seven different ML models were trained. Three spectral representations\nwere used as feature for each model.\n  Results: The results show that the best performance (accuracy of 71.1\\%) was\nobtained by the following two systems: an Adaboost classifier using the\nmel-spectrogram feature and a decision tree classifier using the mel-frequency\ncepstral coefficient feature.\n  Conclusions: The study of social creak is becoming increasingly popular in\nsociolinguistic and vocological research. The conventional human perceptual\nassessment of the amount of creak is laborious and therefore ML technology\ncould be used to assist researchers studying social creak. The classification\nsystems reported in this study could be considered as baselines in future\nML-based studies on social creak.\n","authors":["Anne-Maria Laukkanen","Sudarsana Reddy Kadiri","Shrikanth Narayanan","Paavo Alku"],"pdf_url":"https://arxiv.org/pdf/2410.17028v1.pdf","comment":"Accepted in Journal of Voice"},{"id":"http://arxiv.org/abs/2410.17021v1","updated":"2024-10-22T13:47:38Z","published":"2024-10-22T13:47:38Z","title":"SG-FSM: A Self-Guiding Zero-Shot Prompting Paradigm for Multi-Hop\n  Question Answering Based on Finite State Machine","summary":"  Large Language Models with chain-of-thought prompting, such as OpenAI-o1,\nhave shown impressive capabilities in natural language inference tasks.\nHowever, Multi-hop Question Answering (MHQA) remains challenging for many\nexisting models due to issues like hallucination, error propagation, and\nlimited context length. To address these challenges and enhance LLMs'\nperformance on MHQA, we propose the Self-Guiding prompting Finite State Machine\n(SG-FSM), designed to strengthen multi-hop reasoning abilities. Unlike\ntraditional chain-of-thought methods, SG-FSM tackles MHQA by iteratively\nbreaking down complex questions into sub-questions, correcting itself to\nimprove accuracy. It processes one sub-question at a time, dynamically deciding\nthe next step based on the current context and results, functioning much like\nan automaton. Experiments across various benchmarks demonstrate the\neffectiveness of our approach, outperforming strong baselines on challenging\ndatasets such as Musique. SG-FSM reduces hallucination, enabling recovery of\nthe correct final answer despite intermediate errors. It also improves\nadherence to specified output formats, simplifying evaluation significantly.\n","authors":["Xiaochen Wang","Junqing He","Liang Chen","Reza Haf Zhe Yang","Yiru Wang","Xiangdi Meng","Kunhao Pan","Zhifang Sui"],"pdf_url":"https://arxiv.org/pdf/2410.17021v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.17018v1","updated":"2024-10-22T13:39:47Z","published":"2024-10-22T13:39:47Z","title":"Exploring Forgetting in Large Language Model Pre-Training","summary":"  Catastrophic forgetting remains a formidable obstacle to building an\nomniscient model in large language models (LLMs). Despite the pioneering\nresearch on task-level forgetting in LLM fine-tuning, there is scant focus on\nforgetting during pre-training. We systematically explored the existence and\nmeasurement of forgetting in pre-training, questioning traditional metrics such\nas perplexity (PPL) and introducing new metrics to better detect entity memory\nretention. Based on our revised assessment of forgetting metrics, we explored\nlow-cost, straightforward methods to mitigate forgetting during the\npre-training phase. Further, we carefully analyzed the learning curves,\noffering insights into the dynamics of forgetting. Extensive evaluations and\nanalyses on forgetting of pre-training could facilitate future research on\nLLMs.\n","authors":["Chonghua Liao","Ruobing Xie","Xingwu Sun","Haowen Sun","Zhanhui Kang"],"pdf_url":"https://arxiv.org/pdf/2410.17018v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.10851v2","updated":"2024-10-22T13:08:02Z","published":"2024-10-06T12:53:07Z","title":"LLM Gesticulator: Leveraging Large Language Models for Scalable and\n  Controllable Co-Speech Gesture Synthesis","summary":"  In this work, we present LLM Gesticulator, an LLM-based audio-driven\nco-speech gesture generation framework that synthesizes full-body animations\nthat are rhythmically aligned with the input audio while exhibiting natural\nmovements and editability. Compared to previous work, our model demonstrates\nsubstantial scalability. As the size of the backbone LLM model increases, our\nframework shows proportional improvements in evaluation metrics (a.k.a. scaling\nlaw). Our method also exhibits strong controllability where the content, style\nof the generated gestures can be controlled by text prompt. To the best of our\nknowledge, LLM gesticulator is the first work that use LLM on the co-speech\ngeneration task. Evaluation with existing objective metrics and user studies\nindicate that our framework outperforms prior works.\n","authors":["Haozhou Pang","Tianwei Ding","Lanshan He","Ming Tao","Lu Zhang","Qi Gan"],"pdf_url":"https://arxiv.org/pdf/2410.10851v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.16977v1","updated":"2024-10-22T12:56:04Z","published":"2024-10-22T12:56:04Z","title":"IPL: Leveraging Multimodal Large Language Models for Intelligent Product\n  Listing","summary":"  Unlike professional Business-to-Consumer (B2C) e-commerce platforms (e.g.,\nAmazon), Consumer-to-Consumer (C2C) platforms (e.g., Facebook marketplace) are\nmainly targeting individual sellers who usually lack sufficient experience in\ne-commerce. Individual sellers often struggle to compose proper descriptions\nfor selling products. With the recent advancement of Multimodal Large Language\nModels (MLLMs), we attempt to integrate such state-of-the-art generative AI\ntechnologies into the product listing process. To this end, we develop IPL, an\nIntelligent Product Listing tool tailored to generate descriptions using\nvarious product attributes such as category, brand, color, condition, etc. IPL\nenables users to compose product descriptions by merely uploading photos of the\nselling product. More importantly, it can imitate the content style of our C2C\nplatform Xianyu. This is achieved by employing domain-specific instruction\ntuning on MLLMs and adopting the multi-modal Retrieval-Augmented Generation\n(RAG) process. A comprehensive empirical evaluation demonstrates that the\nunderlying model of IPL significantly outperforms the base model in\ndomain-specific tasks while producing less hallucination. IPL has been\nsuccessfully deployed in our production system, where 72% of users have their\npublished product listings based on the generated content, and those product\nlistings are shown to have a quality score 5.6% higher than those without AI\nassistance.\n","authors":["Kang Chen","Qingheng Zhang","Chengbao Lian","Yixin Ji","Xuwei Liu","Shuguang Han","Guoqiang Wu","Fei Huang","Jufeng Chen"],"pdf_url":"https://arxiv.org/pdf/2410.16977v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.16973v1","updated":"2024-10-22T12:51:51Z","published":"2024-10-22T12:51:51Z","title":"Learning Mathematical Rules with Large Language Models","summary":"  In this paper, we study the ability of large language models to learn\nspecific mathematical rules such as distributivity or simplifying equations. We\npresent an empirical analysis of their ability to generalize these rules, as\nwell as to reuse them in the context of word problems. For this purpose, we\nprovide a rigorous methodology to build synthetic data incorporating such\nrules, and perform fine-tuning of large language models on such data. Our\nexperiments show that our model can learn and generalize these rules to some\nextent, as well as suitably reuse them in the context of word problems.\n","authors":["Antoine Gorceix","Bastien Le Chenadec","Ahmad Rammal","Nelson Vadori","Manuela Veloso"],"pdf_url":"https://arxiv.org/pdf/2410.16973v1.pdf","comment":"4th MATH-AI Workshop at NeurIPS'24"},{"id":"http://arxiv.org/abs/2410.16930v1","updated":"2024-10-22T12:00:58Z","published":"2024-10-22T12:00:58Z","title":"Math Neurosurgery: Isolating Language Models' Math Reasoning Abilities\n  Using Only Forward Passes","summary":"  Math reasoning is a highly active area of Large Language Model (LLM) research\nbecause it is a hallmark of artificial intelligence. However, few works have\nexplored how math reasoning is encoded within LLM parameters and if it is a\nskill that can be isolated within a model. Doing so could allow targeted\nintervention to improve math performance without altering non-math behavior and\nfoster understanding of how models encode math reasoning. We introduce Math\nNeurosurgery (MathNeuro), a method for isolating math-specific parameters in\nLLMs using only forward passes. MathNeuro builds on existing work by using\nweights and activations to calculate parameter importance, but isolates\nmath-specific parameters by removing those important for general language\ntasks. Pruning parameters MathNeuro identifies deletes a LLM's math reasoning\nability without destroying its general language ability. Scaling these\nparameters by a small constant improves a pretrained or instruction-tuned LLM's\nperformance by 4-17% on GSM8K while leaving non-math behavior unaltered.\nMathNeuro is also data efficient: most of its effectiveness holds when\nidentifying math-specific parameters using a single sample. MathNeuro\nhighlights the potential for future work to intervene on math-specific\nparameters.\n","authors":["Bryan R. Christ","Zack Gottesman","Jonathan Kropko","Thomas Hartvigsen"],"pdf_url":"https://arxiv.org/pdf/2410.16930v1.pdf","comment":"21 pages, 29 figures"},{"id":"http://arxiv.org/abs/2410.07114v3","updated":"2024-10-22T11:55:46Z","published":"2024-09-19T19:48:31Z","title":"System 2 thinking in OpenAI's o1-preview model: Near-perfect performance\n  on a mathematics exam","summary":"  The processes underlying human cognition are often divided into System 1,\nwhich involves fast, intuitive thinking, and System 2, which involves slow,\ndeliberate reasoning. Previously, large language models were criticized for\nlacking the deeper, more analytical capabilities of System 2. In September\n2024, OpenAI introduced the o1 model series, designed to handle System 2-like\nreasoning. While OpenAI's benchmarks are promising, independent validation is\nstill needed. In this study, we tested the o1-preview model twice on the Dutch\n'Mathematics B' final exam. It scored a near-perfect 76 and 74 out of 76\npoints. For context, only 24 out of 16,414 students in the Netherlands achieved\na perfect score. By comparison, the GPT-4o model scored 66 and 62 out of 76,\nwell above the Dutch average of 40.63 points. Neither model had access to the\nexam figures. Since there was a risk of model contamination (i.e., the\nknowledge cutoff of o1-preview and GPT-4o was after the exam was published\nonline), we repeated the procedure with a new Mathematics B exam that was\npublished after the cutoff date. The results again indicated that o1-preview\nperformed strongly (97.8th percentile), which suggests that contamination was\nnot a factor. We also show that there is some variability in the output of\no1-preview, which means that sometimes there is 'luck' (the answer is correct)\nor 'bad luck' (the output has diverged into something that is incorrect). We\ndemonstrate that a self-consistency approach, where repeated prompts are given\nand the most common answer is selected, is a useful strategy for identifying\nthe correct answer. It is concluded that while OpenAI's new model series holds\ngreat potential, certain risks must be considered.\n","authors":["Joost de Winter","Dimitra Dodou","Yke Bauke Eisma"],"pdf_url":"https://arxiv.org/pdf/2410.07114v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.16919v1","updated":"2024-10-22T11:52:22Z","published":"2024-10-22T11:52:22Z","title":"EnvBridge: Bridging Diverse Environments with Cross-Environment\n  Knowledge Transfer for Embodied AI","summary":"  In recent years, Large Language Models (LLMs) have demonstrated high\nreasoning capabilities, drawing attention for their applications as agents in\nvarious decision-making processes. One notably promising application of LLM\nagents is robotic manipulation. Recent research has shown that LLMs can\ngenerate text planning or control code for robots, providing substantial\nflexibility and interaction capabilities. However, these methods still face\nchallenges in terms of flexibility and applicability across different\nenvironments, limiting their ability to adapt autonomously. Current approaches\ntypically fall into two categories: those relying on environment-specific\npolicy training, which restricts their transferability, and those generating\ncode actions based on fixed prompts, which leads to diminished performance when\nconfronted with new environments. These limitations significantly constrain the\ngeneralizability of agents in robotic manipulation. To address these\nlimitations, we propose a novel method called EnvBridge. This approach involves\nthe retention and transfer of successful robot control codes from source\nenvironments to target environments. EnvBridge enhances the agent's\nadaptability and performance across diverse settings by leveraging insights\nfrom multiple environments. Notably, our approach alleviates environmental\nconstraints, offering a more flexible and generalizable solution for robotic\nmanipulation tasks. We validated the effectiveness of our method using robotic\nmanipulation benchmarks: RLBench, MetaWorld, and CALVIN. Our experiments\ndemonstrate that LLM agents can successfully leverage diverse knowledge sources\nto solve complex tasks. Consequently, our approach significantly enhances the\nadaptability and robustness of robotic manipulation agents in planning across\ndiverse environments.\n","authors":["Tomoyuki Kagaya","Yuxuan Lou","Thong Jing Yuan","Subramanian Lakshmi","Jayashree Karlekar","Sugiri Pranata","Natsuki Murakami","Akira Kinose","Koki Oguri","Felix Wick","Yang You"],"pdf_url":"https://arxiv.org/pdf/2410.16919v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2407.07457v3","updated":"2024-10-22T10:54:15Z","published":"2024-07-10T08:20:47Z","title":"GLBench: A Comprehensive Benchmark for Graph with Large Language Models","summary":"  The emergence of large language models (LLMs) has revolutionized the way we\ninteract with graphs, leading to a new paradigm called GraphLLM. Despite the\nrapid development of GraphLLM methods in recent years, the progress and\nunderstanding of this field remain unclear due to the lack of a benchmark with\nconsistent experimental protocols. To bridge this gap, we introduce GLBench,\nthe first comprehensive benchmark for evaluating GraphLLM methods in both\nsupervised and zero-shot scenarios. GLBench provides a fair and thorough\nevaluation of different categories of GraphLLM methods, along with traditional\nbaselines such as graph neural networks. Through extensive experiments on a\ncollection of real-world datasets with consistent data processing and splitting\nstrategies, we have uncovered several key findings. Firstly, GraphLLM methods\noutperform traditional baselines in supervised settings, with LLM-as-enhancers\nshowing the most robust performance. However, using LLMs as predictors is less\neffective and often leads to uncontrollable output issues. We also notice that\nno clear scaling laws exist for current GraphLLM methods. In addition, both\nstructures and semantics are crucial for effective zero-shot transfer, and our\nproposed simple baseline can even outperform several models tailored for\nzero-shot scenarios. The data and code of the benchmark can be found at\nhttps://github.com/NineAbyss/GLBench.\n","authors":["Yuhan Li","Peisong Wang","Xiao Zhu","Aochuan Chen","Haiyun Jiang","Deng Cai","Victor Wai Kin Chan","Jia Li"],"pdf_url":"https://arxiv.org/pdf/2407.07457v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.15689v2","updated":"2024-10-22T10:49:57Z","published":"2024-08-28T10:25:53Z","title":"TempoFormer: A Transformer for Temporally-aware Representations in\n  Change Detection","summary":"  Dynamic representation learning plays a pivotal role in understanding the\nevolution of linguistic content over time. On this front both context and time\ndynamics as well as their interplay are of prime importance. Current approaches\nmodel context via pre-trained representations, which are typically temporally\nagnostic. Previous work on modelling context and temporal dynamics has used\nrecurrent methods, which are slow and prone to overfitting. Here we introduce\nTempoFormer, the first task-agnostic transformer-based and temporally-aware\nmodel for dynamic representation learning. Our approach is jointly trained on\ninter and intra context dynamics and introduces a novel temporal variation of\nrotary positional embeddings. The architecture is flexible and can be used as\nthe temporal representation foundation of other models or applied to different\ntransformer-based architectures. We show new SOTA performance on three\ndifferent real-time change detection tasks.\n","authors":["Talia Tseriotou","Adam Tsakalidis","Maria Liakata"],"pdf_url":"https://arxiv.org/pdf/2408.15689v2.pdf","comment":"Accepted by EMNLP Main 2024"},{"id":"http://arxiv.org/abs/2405.15319v2","updated":"2024-10-22T10:31:59Z","published":"2024-05-24T08:00:00Z","title":"Stacking Your Transformers: A Closer Look at Model Growth for Efficient\n  LLM Pre-Training","summary":"  LLMs are computationally expensive to pre-train due to their large scale.\nModel growth emerges as a promising approach by leveraging smaller models to\naccelerate the training of larger ones. However, the viability of these model\ngrowth methods in efficient LLM pre-training remains underexplored. This work\nidentifies three critical $\\underline{\\textit{O}}$bstacles: ($\\textit{O}$1)\nlack of comprehensive evaluation, ($\\textit{O}$2) untested viability for\nscaling, and ($\\textit{O}$3) lack of empirical guidelines. To tackle\n$\\textit{O}$1, we summarize existing approaches into four atomic growth\noperators and systematically evaluate them in a standardized LLM pre-training\nsetting. Our findings reveal that a depthwise stacking operator, called\n$G_{\\text{stack}}$, exhibits remarkable acceleration in training, leading to\ndecreased loss and improved overall performance on eight standard NLP\nbenchmarks compared to strong baselines. Motivated by these promising results,\nwe conduct extensive experiments to delve deeper into $G_{\\text{stack}}$ to\naddress $\\textit{O}$2 and $\\textit{O}$3. For $\\textit{O}$2 (untested\nscalability), our study shows that $G_{\\text{stack}}$ is scalable and\nconsistently performs well, with experiments up to 7B LLMs after growth and\npre-training LLMs with 750B tokens. For example, compared to a conventionally\ntrained 7B model using 300B tokens, our $G_{\\text{stack}}$ model converges to\nthe same loss with 194B tokens, resulting in a 54.6\\% speedup. We further\naddress $\\textit{O}$3 (lack of empirical guidelines) by formalizing guidelines\nto determine growth timing and growth factor for $G_{\\text{stack}}$, making it\npractical in general LLM pre-training. We also provide in-depth discussions and\ncomprehensive ablation studies of $G_{\\text{stack}}$. Our code and pre-trained\nmodel are available at https://llm-stacking.github.io.\n","authors":["Wenyu Du","Tongxu Luo","Zihan Qiu","Zeyu Huang","Yikang Shen","Reynold Cheng","Yike Guo","Jie Fu"],"pdf_url":"https://arxiv.org/pdf/2405.15319v2.pdf","comment":"NeurIPS 2024 Spotlight"},{"id":"http://arxiv.org/abs/2410.14262v2","updated":"2024-10-22T10:12:00Z","published":"2024-10-18T08:18:18Z","title":"Good Parenting is all you need -- Multi-agentic LLM Hallucination\n  Mitigation","summary":"  This study explores the ability of Large Language Model (LLM) agents to\ndetect and correct hallucinations in AI-generated content. A primary agent was\ntasked with creating a blog about a fictional Danish artist named Flipfloppidy,\nwhich was then reviewed by another agent for factual inaccuracies. Most LLMs\nhallucinated the existence of this artist. Across 4,900 test runs involving\nvarious combinations of primary and reviewing agents, advanced AI models such\nas Llama3-70b and GPT-4 variants demonstrated near-perfect accuracy in\nidentifying hallucinations and successfully revised outputs in 85% to 100% of\ncases following feedback. These findings underscore the potential of advanced\nAI models to significantly enhance the accuracy and reliability of generated\ncontent, providing a promising approach to improving AI workflow orchestration.\n","authors":["Ted Kwartler","Matthew Berman","Alan Aqrawi"],"pdf_url":"https://arxiv.org/pdf/2410.14262v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.16855v1","updated":"2024-10-22T09:43:39Z","published":"2024-10-22T09:43:39Z","title":"Tracing the Development of the Virtual Particle Concept Using Semantic\n  Change Detection","summary":"  Virtual particles are peculiar objects. They figure prominently in much of\ntheoretical and experimental research in elementary particle physics. But\nexactly what they are is far from obvious. In particular, to what extent they\nshould be considered \"real\" remains a matter of controversy in philosophy of\nscience. Also their origin and development has only recently come into focus of\nscholarship in the history of science. In this study, we propose using the\nintriguing case of virtual particles to discuss the efficacy of Semantic Change\nDetection (SCD) based on contextualized word embeddings from a domain-adapted\nBERT model in studying specific scientific concepts. We find that the SCD\nmetrics align well with qualitative research insights in the history and\nphilosophy of science, as well as with the results obtained from Dependency\nParsing to determine the frequency and connotations of the term \"virtual.\"\nStill, the metrics of SCD provide additional insights over and above the\nqualitative research and the Dependency Parsing. Among other things, the\nmetrics suggest that the concept of the virtual particle became more stable\nafter 1950 but at the same time also more polysemous.\n","authors":["Michael Zichert","Adrian Wüthrich"],"pdf_url":"https://arxiv.org/pdf/2410.16855v1.pdf","comment":"CHR 2024: Computational Humanities Research Conference"},{"id":"http://arxiv.org/abs/2410.16848v1","updated":"2024-10-22T09:35:42Z","published":"2024-10-22T09:35:42Z","title":"ETHIC: Evaluating Large Language Models on Long-Context Tasks with High\n  Information Coverage","summary":"  Recent advancements in large language models (LLM) capable of processing\nextremely long texts highlight the need for a dedicated evaluation benchmark to\nassess their long-context capabilities. However, existing methods, like the\nneedle-in-a-haystack test, do not effectively assess whether these models fully\nutilize contextual information, raising concerns about the reliability of\ncurrent evaluation techniques. To thoroughly examine the effectiveness of\nexisting benchmarks, we introduce a new metric called information coverage\n(IC), which quantifies the proportion of the input context necessary for\nanswering queries. Our findings indicate that current benchmarks exhibit low\nIC; although the input context may be extensive, the actual usable context is\noften limited. To address this, we present ETHIC, a novel benchmark designed to\nassess LLMs' ability to leverage the entire context. Our benchmark comprises\n2,648 test instances spanning four long-context tasks with high IC scores in\nthe domains of books, debates, medicine, and law. Our evaluations reveal\nsignificant performance drops in contemporary LLMs, highlighting a critical\nchallenge in managing long contexts. Our benchmark is available at\nhttps://github.com/dmis-lab/ETHIC.\n","authors":["Taewhoo Lee","Chanwoong Yoon","Kyochul Jang","Donghyeon Lee","Minju Song","Hyunjae Kim","Jaewoo Kang"],"pdf_url":"https://arxiv.org/pdf/2410.16848v1.pdf","comment":"15 pages, 5 figures"},{"id":"http://arxiv.org/abs/2410.16843v1","updated":"2024-10-22T09:25:21Z","published":"2024-10-22T09:25:21Z","title":"Trustworthy Alignment of Retrieval-Augmented Large Language Models via\n  Reinforcement Learning","summary":"  Trustworthiness is an essential prerequisite for the real-world application\nof large language models. In this paper, we focus on the trustworthiness of\nlanguage models with respect to retrieval augmentation. Despite being supported\nwith external evidence, retrieval-augmented generation still suffers from\nhallucinations, one primary cause of which is the conflict between contextual\nand parametric knowledge. We deem that retrieval-augmented language models have\nthe inherent capabilities of supplying response according to both contextual\nand parametric knowledge. Inspired by aligning language models with human\npreference, we take the first step towards aligning retrieval-augmented\nlanguage models to a status where it responds relying merely on the external\nevidence and disregards the interference of parametric knowledge. Specifically,\nwe propose a reinforcement learning based algorithm Trustworthy-Alignment,\ntheoretically and experimentally demonstrating large language models'\ncapability of reaching a trustworthy status without explicit supervision on how\nto respond. Our work highlights the potential of large language models on\nexploring its intrinsic abilities by its own and expands the application\nscenarios of alignment from fulfilling human preference to creating trustworthy\nagents.\n","authors":["Zongmeng Zhang","Yufeng Shi","Jinhua Zhu","Wengang Zhou","Xiang Qi","Peng Zhang","Houqiang Li"],"pdf_url":"https://arxiv.org/pdf/2410.16843v1.pdf","comment":"ICML 2024"},{"id":"http://arxiv.org/abs/2410.16842v1","updated":"2024-10-22T09:25:04Z","published":"2024-10-22T09:25:04Z","title":"Assessment of Transformer-Based Encoder-Decoder Model for Human-Like\n  Summarization","summary":"  In recent times, extracting valuable information from large text is making\nsignificant progress. Especially in the current era of social media, people\nexpect quick bites of information. Automatic text summarization seeks to tackle\nthis by slimming large texts down into more manageable summaries. This\nimportant research area can aid in decision-making by digging out salient\ncontent from large text. With the progress in deep learning models, significant\nwork in language models has emerged. The encoder-decoder framework in deep\nlearning has become the central approach for automatic text summarization. This\nwork leverages transformer-based BART model for human-like summarization which\nis an open-ended problem with many challenges. On training and fine-tuning the\nencoder-decoder model, it is tested with diverse sample articles and the\nquality of summaries of diverse samples is assessed based on human evaluation\nparameters. Further, the finetuned model performance is compared with the\nbaseline pretrained model based on evaluation metrics like ROUGE score and\nBERTScore. Additionally, domain adaptation of the model is required for\nimproved performance of abstractive summarization of dialogues between\ninterlocutors. On investigating, the above popular evaluation metrics are found\nto be insensitive to factual errors. Further investigation of the summaries\ngenerated by finetuned model is done using the contemporary evaluation metrics\nof factual consistency like WeCheck and SummaC. Empirical results on BBC News\narticles highlight that the gold standard summaries written by humans are more\nfactually consistent by 17% than the abstractive summaries generated by\nfinetuned model.\n","authors":["Sindhu Nair","Y. S. Rao","Radha Shankarmani"],"pdf_url":"https://arxiv.org/pdf/2410.16842v1.pdf","comment":"Pre-print"},{"id":"http://arxiv.org/abs/2404.04846v2","updated":"2024-10-22T09:16:49Z","published":"2024-04-07T07:39:45Z","title":"F-MALLOC: Feed-forward Memory Allocation for Continual Learning in\n  Neural Machine Translation","summary":"  In the evolving landscape of Neural Machine Translation (NMT), the\npretrain-then-finetune paradigm has yielded impressive results. However, the\npersistent challenge of Catastrophic Forgetting (CF) remains a hurdle. While\nprevious work has introduced Continual Learning (CL) methods to address CF,\nthese approaches grapple with the delicate balance between avoiding forgetting\nand maintaining system extensibility. To address this, we propose a CL method,\nnamed $\\textbf{F-MALLOC}$ ($\\textbf{F}$eed-forward $\\textbf{M}$emory\n$\\textbf{ALLOC}ation)$. F-MALLOC is inspired by recent insights highlighting\nthat feed-forward layers emulate neural memories and encapsulate crucial\ntranslation knowledge. It decomposes feed-forward layers into discrete memory\ncells and allocates these memories to different tasks. By learning to allocate\nand safeguard these memories, our method effectively alleviates CF while\nensuring robust extendability. Besides, we propose a comprehensive assessment\nprotocol for multi-stage CL of NMT systems. Experiments conducted following\nthis new protocol showcase the superior performance of F-MALLOC, evidenced by\nhigher BLEU scores and almost zero forgetting.\n","authors":["Junhong Wu","Yuchen Liu","Chengqing Zong"],"pdf_url":"https://arxiv.org/pdf/2404.04846v2.pdf","comment":"Accepted to the main conference of NAACL 2024"},{"id":"http://arxiv.org/abs/2410.16834v1","updated":"2024-10-22T09:14:21Z","published":"2024-10-22T09:14:21Z","title":"Analyzing and Evaluating Correlation Measures in NLG Meta-Evaluation","summary":"  The correlation between NLG automatic evaluation metrics and human evaluation\nis often regarded as a critical criterion for assessing the capability of an\nevaluation metric. However, different grouping methods and correlation\ncoefficients result in various types of correlation measures used in\nmeta-evaluation. In specific evaluation scenarios, prior work often directly\nfollows conventional measure settings, but the characteristics and differences\nbetween these measures have not gotten sufficient attention. Therefore, this\npaper analyzes 12 common correlation measures using a large amount of\nreal-world data from six widely-used NLG evaluation datasets and 32 evaluation\nmetrics, revealing that different measures indeed impact the meta-evaluation\nresults. Furthermore, we propose three perspectives that reflect the capability\nof meta-evaluation and find that the measure using global grouping and Pearson\ncorrelation exhibits the best overall performance, involving the discriminative\npower, ranking consistency, and sensitivity to score granularity.\n","authors":["Mingqi Gao","Xinyu Hu","Li Lin","Xiaojun Wan"],"pdf_url":"https://arxiv.org/pdf/2410.16834v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.07563v2","updated":"2024-10-22T09:06:38Z","published":"2024-10-10T02:59:36Z","title":"PLaMo-100B: A Ground-Up Language Model Designed for Japanese Proficiency","summary":"  We introduce PLaMo-100B, a large-scale language model designed for Japanese\nproficiency. The model was trained from scratch using 2 trillion tokens, with\narchitecture such as QK Normalization and Z-Loss to ensure training stability\nduring the training process. Post-training techniques, including Supervised\nFine-Tuning and Direct Preference Optimization, were applied to refine the\nmodel's performance. Benchmark evaluations suggest that PLaMo-100B performs\nwell, particularly in Japanese-specific tasks, achieving results that are\ncompetitive with frontier models like GPT-4. The base model is available at\nhttps://huggingface.co/pfnet/plamo-100b.\n","authors":["Preferred Elements"," :","Kenshin Abe","Kaizaburo Chubachi","Yasuhiro Fujita","Yuta Hirokawa","Kentaro Imajo","Toshiki Kataoka","Hiroyoshi Komatsu","Hiroaki Mikami","Tsuguo Mogami","Shogo Murai","Kosuke Nakago","Daisuke Nishino","Toru Ogawa","Daisuke Okanohara","Yoshihiko Ozaki","Shotaro Sano","Shuji Suzuki","Tianqi Xu","Toshihiko Yanase"],"pdf_url":"https://arxiv.org/pdf/2410.07563v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2409.14710v2","updated":"2024-10-22T09:00:19Z","published":"2024-09-23T05:12:13Z","title":"ERABAL: Enhancing Role-Playing Agents through Boundary-Aware Learning","summary":"  Role-playing is an emerging application in the field of Human-Computer\nInteraction (HCI), primarily implemented through the alignment training of a\nlarge language model (LLM) with assigned characters. Despite significant\nprogress, role-playing agents (RPLAs) still struggle with maintaining\nrole-consistency across conversations, particularly when confronted with\nboundary queries subtly related to character attributes. In this paper, we\npresent ERABAL, a framework aimed at enhancing RPLAs' role-playing capabilities\nthrough boundary-aware learning. ERABAL encompasses a generation pipeline for\nrole-specific dialogues and a concomitant methodology for alignment training.\nThrough comprehensive evaluations, we demonstrate that ERABAL is both efficient\nand effective. By training with significantly fewer dialogues than those used\nin leading approaches, ERABAL achieves notable improvements across\nWikiRoleEval, CharacterEval, and the role-playing subset of MT-Bench compared\nto the generalist baseline models. Our code and datasets will be made publicly\navailable to support further research.\n","authors":["Yihong Tang","Jiao Ou","Che Liu","Fuzheng Zhang","Di Zhang","Kun Gai"],"pdf_url":"https://arxiv.org/pdf/2409.14710v2.pdf","comment":"arXiv admin note: substantial text overlap with arXiv:2402.10618"},{"id":"http://arxiv.org/abs/2407.04185v3","updated":"2024-10-22T08:53:02Z","published":"2024-07-04T23:26:56Z","title":"HAF-RM: A Hybrid Alignment Framework for Reward Model Training","summary":"  The reward model has become increasingly important in alignment, assessment,\nand data construction for large language models (LLMs). Most existing\nresearchers focus on enhancing reward models through data improvements,\nfollowing the conventional training framework for reward models that directly\noptimizes the predicted rewards. In this paper, we propose a hybrid alignment\nframework HaF-RM for reward model training by introducing an additional\nconstraint on token-level policy probabilities in addition to the reward score.\nIt can simultaneously supervise the internal preference model at the token\nlevel and optimize the mapping layer of the reward model at the sequence level.\nTheoretical justifications and experiment results on five datasets show the\nvalidity and effectiveness of our proposed hybrid framework for training a\nhigh-quality reward model. By decoupling the reward modeling procedure and\nincorporating hybrid supervision, our HaF-RM framework offers a principled and\neffective approach to enhancing the performance and alignment of reward models,\na critical component in the responsible development of powerful language\nmodels. We release our code at https://haf-rm.github.io.\n","authors":["Shujun Liu","Xiaoyu Shen","Yuhang Lai","Siyuan Wang","Shengbin Yue","Zengfeng Huang","Xuanjing Huang","Zhongyu Wei"],"pdf_url":"https://arxiv.org/pdf/2407.04185v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.16812v1","updated":"2024-10-22T08:38:50Z","published":"2024-10-22T08:38:50Z","title":"Optimizing Chain-of-Thought Reasoning: Tackling Arranging Bottleneck via\n  Plan Augmentation","summary":"  Multi-step reasoning ability of large language models is crucial in tasks\nsuch as math and tool utilization. Current researches predominantly focus on\nenhancing model performance in these multi-step reasoning tasks through\nfine-tuning with Chain-of-Thought (CoT) steps, yet these methods tend to be\nheuristic, without exploring nor resolving the bottleneck. In this study, we\nsubdivide CoT reasoning into two parts: arranging and executing, and identify\nthat the bottleneck of models mainly lies in arranging rather than executing.\nBased on this finding, we propose a plan-based training and reasoning method\nthat guides models to generate arranging steps through abstract plans. We\nexperiment on both math (GSM8k) and tool utilization (ToolBench) benchmarks.\nResults show that compared to fine-tuning directly with CoT data, our approach\nachieves a better performance on alleviating arranging bottleneck, particularly\nexcelling in long-distance reasoning generalization.\n","authors":["Yuli Qiu","Jiashu Yao","Heyan Huang","Yuhang Guo"],"pdf_url":"https://arxiv.org/pdf/2410.16812v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.16803v1","updated":"2024-10-22T08:28:05Z","published":"2024-10-22T08:28:05Z","title":"Context-aware Inductive Knowledge Graph Completion with Latent Type\n  Constraints and Subgraph Reasoning","summary":"  Inductive knowledge graph completion (KGC) aims to predict missing triples\nwith unseen entities. Recent works focus on modeling reasoning paths between\nthe head and tail entity as direct supporting evidence. However, these methods\ndepend heavily on the existence and quality of reasoning paths, which limits\ntheir general applicability in different scenarios. In addition, we observe\nthat latent type constraints and neighboring facts inherent in KGs are also\nvital in inferring missing triples. To effectively utilize all useful\ninformation in KGs, we introduce CATS, a novel context-aware inductive KGC\nsolution. With sufficient guidance from proper prompts and supervised\nfine-tuning, CATS activates the strong semantic understanding and reasoning\ncapabilities of large language models to assess the existence of query triples,\nwhich consist of two modules. First, the type-aware reasoning module evaluates\nwhether the candidate entity matches the latent entity type as required by the\nquery relation. Then, the subgraph reasoning module selects relevant reasoning\npaths and neighboring facts, and evaluates their correlation to the query\ntriple. Experiment results on three widely used datasets demonstrate that CATS\nsignificantly outperforms state-of-the-art methods in 16 out of 18\ntransductive, inductive, and few-shot settings with an average absolute MRR\nimprovement of 7.2%.\n","authors":["Muzhi Li","Cehao Yang","Chengjin Xu","Zixing Song","Xuhui Jiang","Jian Guo","Ho-fung Leung","Irwin King"],"pdf_url":"https://arxiv.org/pdf/2410.16803v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.16801v1","updated":"2024-10-22T08:27:23Z","published":"2024-10-22T08:27:23Z","title":"Controlled Low-Rank Adaptation with Subspace Regularization for\n  Continued Training on Large Language Models","summary":"  Large language models (LLMs) exhibit remarkable capabilities in natural\nlanguage processing but face catastrophic forgetting when learning new tasks,\nwhere adaptation to a new domain leads to a substantial decline in performance\non previous tasks. In this paper, we propose Controlled LoRA (CLoRA), a\nsubspace regularization method on LoRA structure. Aiming to reduce the scale of\noutput change while introduce minimal constraint on model capacity, CLoRA\nimposes constraint on the direction of updating matrix null space. Experimental\nresults on commonly used LLM finetuning tasks reveal that CLoRA significantly\noutperforms existing LoRA subsequent methods on both in-domain and outdomain\nevaluations, highlighting the superority of CLoRA as a effective\nparameter-efficient finetuning method with catastrophic forgetting mitigating.\nFurther investigation for model parameters indicates that CLoRA effectively\nbalances the trade-off between model capacity and degree of forgetting.\n","authors":["Yuheng Lu","Bingshuo Qian","Caixia Yuan","Huixing Jiang","Xiaojie Wang"],"pdf_url":"https://arxiv.org/pdf/2410.16801v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.16788v1","updated":"2024-10-22T08:04:32Z","published":"2024-10-22T08:04:32Z","title":"Correct after Answer: Enhancing Multi-Span Question Answering with\n  Post-Processing Method","summary":"  Multi-Span Question Answering (MSQA) requires models to extract one or\nmultiple answer spans from a given context to answer a question. Prior work\nmainly focuses on designing specific methods or applying heuristic strategies\nto encourage models to predict more correct predictions. However, these models\nare trained on gold answers and fail to consider the incorrect predictions.\nThrough a statistical analysis, we observe that models with stronger abilities\ndo not predict less incorrect predictions compared with other models. In this\nwork, we propose Answering-Classifying-Correcting (ACC) framework, which\nemploys a post-processing strategy to handle incorrect predictions.\nSpecifically, the ACC framework first introduces a classifier to classify the\npredictions into three types and exclude \"wrong predictions\", then introduces a\ncorrector to modify \"partially correct predictions\". Experiments on several\nMSQA datasets show that ACC framework significantly improves the Exact Match\n(EM) scores, and further analysis demostrates that ACC framework efficiently\nreduces the number of incorrect predictions, improving the quality of\npredictions.\n","authors":["Jiayi Lin","Chenyang Zhang","Haibo Tong","Dongyu Zhang","Qingqing Hong","Bingxuan Hou","Junli Wang"],"pdf_url":"https://arxiv.org/pdf/2410.16788v1.pdf","comment":"Accepted by EMNLP 2024 Findings"},{"id":"http://arxiv.org/abs/2410.16780v1","updated":"2024-10-22T07:53:41Z","published":"2024-10-22T07:53:41Z","title":"Beyond Retrieval: Generating Narratives in Conversational Recommender\n  Systems","summary":"  The recent advances in Large Language Model's generation and reasoning\ncapabilities present an opportunity to develop truly conversational\nrecommendation systems. However, effectively integrating recommender system\nknowledge into LLMs for natural language generation which is tailored towards\nrecommendation tasks remains a challenge. This paper addresses this challenge\nby making two key contributions.\n  First, we introduce a new dataset (REGEN) for natural language generation\ntasks in conversational recommendations. REGEN (Reviews Enhanced with\nGEnerative Narratives) extends the Amazon Product Reviews dataset with rich\nuser narratives, including personalized explanations of product preferences,\nproduct endorsements for recommended items, and summaries of user purchase\nhistory. REGEN is made publicly available to facilitate further research.\nFurthermore, we establish benchmarks using well-known generative metrics, and\nperform an automated evaluation of the new dataset using a rater LLM. Second,\nthe paper introduces a fusion architecture (CF model with an LLM) which serves\nas a baseline for REGEN. And to the best of our knowledge, represents the first\nattempt to analyze the capabilities of LLMs in understanding recommender\nsignals and generating rich narratives. We demonstrate that LLMs can\neffectively learn from simple fusion architectures utilizing interaction-based\nCF embeddings, and this can be further enhanced using the metadata and\npersonalization data associated with items. Our experiments show that combining\nCF and content embeddings leads to improvements of 4-12% in key language\nmetrics compared to using either type of embedding individually. We also\nprovide an analysis to interpret how CF and content embeddings contribute to\nthis new generative task.\n","authors":["Krishna Sayana","Raghavendra Vasudeva","Yuri Vasilevski","Kun Su","Liam Hebert","Hubert Pham","Ambarish Jash","Sukhdeep Sodhi"],"pdf_url":"https://arxiv.org/pdf/2410.16780v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.16775v1","updated":"2024-10-22T07:45:18Z","published":"2024-10-22T07:45:18Z","title":"Context-Aware LLM Translation System Using Conversation Summarization\n  and Dialogue History","summary":"  Translating conversational text, particularly in customer support contexts,\npresents unique challenges due to its informal and unstructured nature. We\npropose a context-aware LLM translation system that leverages conversation\nsummarization and dialogue history to enhance translation quality for the\nEnglish-Korean language pair. Our approach incorporates the two most recent\ndialogues as raw data and a summary of earlier conversations to manage context\nlength effectively. We demonstrate that this method significantly improves\ntranslation accuracy, maintaining coherence and consistency across\nconversations. This system offers a practical solution for customer support\ntranslation tasks, addressing the complexities of conversational text.\n","authors":["Mingi Sung","Seungmin Lee","Jiwon Kim","Sejoon Kim"],"pdf_url":"https://arxiv.org/pdf/2410.16775v1.pdf","comment":"Accepted to WMT 2024"},{"id":"http://arxiv.org/abs/2410.14748v2","updated":"2024-10-22T07:19:40Z","published":"2024-10-17T19:38:55Z","title":"ETF: An Entity Tracing Framework for Hallucination Detection in Code\n  Summaries","summary":"  Recent advancements in large language models (LLMs) have significantly\nenhanced their ability to understand both natural language and code, driving\ntheir use in tasks like natural language-to-code (NL2Code) and code\nsummarization. However, LLMs are prone to hallucination-outputs that stray from\nintended meanings. Detecting hallucinations in code summarization is especially\ndifficult due to the complex interplay between programming and natural\nlanguages. We introduce a first-of-its-kind dataset with $\\sim$10K samples,\ncurated specifically for hallucination detection in code summarization. We\nfurther propose a novel Entity Tracing Framework (ETF) that a) utilizes static\nprogram analysis to identify code entities from the program and b) uses LLMs to\nmap and verify these entities and their intents within generated code\nsummaries. Our experimental analysis demonstrates the effectiveness of the\nframework, leading to a 0.73 F1 score. This approach provides an interpretable\nmethod for detecting hallucinations by grounding entities, allowing us to\nevaluate summary accuracy.\n","authors":["Kishan Maharaj","Vitobha Munigala","Srikanth G. Tamilselvam","Prince Kumar","Sayandeep Sen","Palani Kodeswaran","Abhijit Mishra","Pushpak Bhattacharyya"],"pdf_url":"https://arxiv.org/pdf/2410.14748v2.pdf","comment":"11 pages, 6 Figures, 5 Tables"},{"id":"http://arxiv.org/abs/2410.14059v2","updated":"2024-10-22T06:47:43Z","published":"2024-10-17T22:03:52Z","title":"UCFE: A User-Centric Financial Expertise Benchmark for Large Language\n  Models","summary":"  This paper introduces the UCFE: User-Centric Financial Expertise benchmark,\nan innovative framework designed to evaluate the ability of large language\nmodels (LLMs) to handle complex real-world financial tasks. UCFE benchmark\nadopts a hybrid approach that combines human expert evaluations with dynamic,\ntask-specific interactions to simulate the complexities of evolving financial\nscenarios. Firstly, we conducted a user study involving 804 participants,\ncollecting their feedback on financial tasks. Secondly, based on this feedback,\nwe created our dataset that encompasses a wide range of user intents and\ninteractions. This dataset serves as the foundation for benchmarking 12 LLM\nservices using the LLM-as-Judge methodology. Our results show a significant\nalignment between benchmark scores and human preferences, with a Pearson\ncorrelation coefficient of 0.78, confirming the effectiveness of the UCFE\ndataset and our evaluation approach. UCFE benchmark not only reveals the\npotential of LLMs in the financial sector but also provides a robust framework\nfor assessing their performance and user satisfaction. The benchmark dataset\nand evaluation code are available.\n","authors":["Yuzhe Yang","Yifei Zhang","Yan Hu","Yilin Guo","Ruoli Gan","Yueru He","Mingcong Lei","Xiao Zhang","Haining Wang","Qianqian Xie","Jimin Huang","Honghai Yu","Benyou Wang"],"pdf_url":"https://arxiv.org/pdf/2410.14059v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.16736v1","updated":"2024-10-22T06:43:28Z","published":"2024-10-22T06:43:28Z","title":"Forewarned is Forearmed: Leveraging LLMs for Data Synthesis through\n  Failure-Inducing Exploration","summary":"  Large language models (LLMs) have significantly benefited from training on\ndiverse, high-quality task-specific data, leading to impressive performance\nacross a range of downstream applications. Current methods often rely on\nhuman-annotated data or predefined task templates to direct powerful LLMs in\nsynthesizing task-relevant data for effective model training. However, this\ndependence on manually designed components may constrain the scope of generated\ndata, potentially overlooking critical edge cases or novel scenarios that could\nchallenge the model. In this paper, we present a novel approach, ReverseGen,\ndesigned to automatically generate effective training samples that expose the\nweaknesses of LLMs. Specifically, we introduce a dedicated proposer trained to\nproduce queries that lead target models to generate unsatisfactory responses.\nThese failure-inducing queries are then used to construct training data,\nhelping to address the models' shortcomings and improve overall performance.\nOur approach is flexible and can be applied to models of various scales (3B,\n7B, and 8B). We evaluate ReverseGen on three key applications (safety, honesty,\nand math), demonstrating that our generated data is both highly effective and\ndiverse. Models fine-tuned with ReverseGen-generated data consistently\noutperform those trained on human-annotated or general model-generated data,\noffering a new perspective on data synthesis for task-specific LLM enhancement.\n","authors":["Qintong Li","Jiahui Gao","Sheng Wang","Renjie Pi","Xueliang Zhao","Chuan Wu","Xin Jiang","Zhenguo Li","Lingpeng Kong"],"pdf_url":"https://arxiv.org/pdf/2410.16736v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.12074v3","updated":"2024-10-22T06:38:07Z","published":"2024-06-17T20:20:47Z","title":"COMMUNITY-CROSS-INSTRUCT: Unsupervised Instruction Generation for\n  Aligning Large Language Models to Online Communities","summary":"  Social scientists use surveys to probe the opinions and beliefs of\npopulations, but these methods are slow, costly, and prone to biases. Recent\nadvances in large language models (LLMs) enable the creating of computational\nrepresentations or \"digital twins\" of populations that generate human-like\nresponses mimicking the population's language, styles, and attitudes. We\nintroduce Community-Cross-Instruct, an unsupervised framework for aligning LLMs\nto online communities to elicit their beliefs. Given a corpus of a community's\nonline discussions, Community-Cross-Instruct automatically generates\ninstruction-output pairs by an advanced LLM to (1) finetune a foundational LLM\nto faithfully represent that community, and (2) evaluate the alignment of the\nfinetuned model to the community. We demonstrate the method's utility in\naccurately representing political and diet communities on Reddit. Unlike prior\nmethods requiring human-authored instructions, Community-Cross-Instruct\ngenerates instructions in a fully unsupervised manner, enhancing scalability\nand generalization across domains. This work enables cost-effective and\nautomated surveying of diverse online communities.\n","authors":["Zihao He","Minh Duc Chu","Rebecca Dorn","Siyi Guo","Kristina Lerman"],"pdf_url":"https://arxiv.org/pdf/2406.12074v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.17378v2","updated":"2024-10-22T06:32:10Z","published":"2024-06-25T08:55:12Z","title":"A Text is Worth Several Tokens: Text Embedding from LLMs Secretly Aligns\n  Well with The Key Tokens","summary":"  Text embeddings from large language models (LLMs) have achieved excellent\nresults in tasks such as information retrieval, semantic textual similarity,\netc. In this work, we show an interesting finding: when feeding a text into the\nembedding LLMs, the obtained text embedding will be able to be aligned with the\nkey tokens in the input text. We first fully analyze this phenomenon on eight\nembedding LLMs and show that this phenomenon is universal and is not affected\nby model architecture, training strategy, and embedding method. With a deeper\nanalysis, we then find that the main change in embedding space between the\nembedding LLMs and their original generative LLMs is in the first principal\ncomponent. By adjusting the first principal component, we can align text\nembedding with the key tokens. Finally, we give several examples to demonstrate\nthe vast application potential of this finding: (1) we propose a simple and\npractical sparse retrieval method based on the aligned tokens, which can\nachieve 80\\% of the dense retrieval effect of the same model while reducing the\ncomputation significantly; (2) we show that our findings provide a fresh\nperspective to help understand fuzzy concepts (e.g., semantic relatedness vs.\nsemantic similarity) and emerging technologies (e.g., instruction-following\nembedding) in this field.\n","authors":["Zhijie Nie","Richong Zhang","Zhanyu Wu"],"pdf_url":"https://arxiv.org/pdf/2406.17378v2.pdf","comment":"Work in Progress"},{"id":"http://arxiv.org/abs/2410.16726v1","updated":"2024-10-22T06:25:16Z","published":"2024-10-22T06:25:16Z","title":"Enhancing Low-Resource ASR through Versatile TTS: Bridging the Data Gap","summary":"  While automatic speech recognition (ASR) systems have achieved remarkable\nperformance with large-scale datasets, their efficacy remains inadequate in\nlow-resource settings, encompassing dialects, accents, minority languages, and\nlong-tail hotwords, domains with significant practical relevance. With the\nadvent of versatile and powerful text-to-speech (TTS) models, capable of\ngenerating speech with human-level naturalness, expressiveness, and diverse\nspeaker profiles, leveraging TTS for ASR data augmentation provides a\ncost-effective and practical approach to enhancing ASR performance.\nComprehensive experiments on an unprecedentedly rich variety of low-resource\ndatasets demonstrate consistent and substantial performance improvements,\nproving that the proposed method of enhancing low-resource ASR through a\nversatile TTS model is highly effective and has broad application prospects.\nFurthermore, we delve deeper into key characteristics of synthesized speech\ndata that contribute to ASR improvement, examining factors such as text\ndiversity, speaker diversity, and the volume of synthesized data, with text\ndiversity being studied for the first time in this work. We hope our findings\nprovide helpful guidance and reference for the practical application of\nTTS-based data augmentation and push the advancement of low-resource ASR one\nstep further.\n","authors":["Guanrou Yang","Fan Yu","Ziyang Ma","Zhihao Du","Zhifu Gao","Shiliang Zhang","Xie Chen"],"pdf_url":"https://arxiv.org/pdf/2410.16726v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2401.16635v3","updated":"2024-10-22T06:19:20Z","published":"2024-01-30T00:17:37Z","title":"Improving Reinforcement Learning from Human Feedback with Efficient\n  Reward Model Ensemble","summary":"  Reinforcement Learning from Human Feedback (RLHF) is a widely adopted\napproach for aligning large language models with human values. However, RLHF\nrelies on a reward model that is trained with a limited amount of human\npreference data, which could lead to inaccurate predictions. As a result, RLHF\nmay produce outputs that are misaligned with human values. To mitigate this\nissue, we contribute a reward ensemble method that allows the reward model to\nmake more accurate predictions. As using an ensemble of large language\nmodel-based reward models can be computationally and resource-expensive, we\nexplore efficient ensemble methods including linear-layer ensemble and\nLoRA-based ensemble. Empirically, we run Best-of-$n$ and Proximal Policy\nOptimization with our ensembled reward models, and verify that our ensemble\nmethods help improve the alignment performance of RLHF outputs.\n","authors":["Shun Zhang","Zhenfang Chen","Sunli Chen","Yikang Shen","Zhiqing Sun","Chuang Gan"],"pdf_url":"https://arxiv.org/pdf/2401.16635v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.16714v1","updated":"2024-10-22T05:51:34Z","published":"2024-10-22T05:51:34Z","title":"Magnetic Preference Optimization: Achieving Last-iterate Convergence for\n  Language Models Alignment","summary":"  Self-play methods have demonstrated remarkable success in enhancing model\ncapabilities across various domains. In the context of Reinforcement Learning\nfrom Human Feedback (RLHF), self-play not only boosts Large Language Model\n(LLM) performance but also overcomes the limitations of traditional\nBradley-Terry (BT) model assumptions by finding the Nash equilibrium (NE) of a\npreference-based, two-player constant-sum game. However, existing methods\neither guarantee only average-iterate convergence, incurring high storage and\ninference costs, or converge to the NE of a regularized game, failing to\naccurately reflect true human preferences. In this paper, we introduce Magnetic\nPreference Optimization (MPO), a novel approach capable of achieving\nlast-iterate convergence to the NE of the original game, effectively overcoming\nthe limitations of existing methods. Building upon Magnetic Mirror Descent\n(MMD), MPO attains a linear convergence rate, making it particularly suitable\nfor fine-tuning LLMs. To ensure our algorithm is both theoretically sound and\npractically viable, we present a simple yet effective implementation that\nadapts the theoretical insights to the RLHF setting. Empirical results\ndemonstrate that MPO can significantly enhance the performance of LLMs,\nhighlighting the potential of self-play methods in alignment.\n","authors":["Mingzhi Wang","Chengdong Ma","Qizhi Chen","Linjian Meng","Yang Han","Jiancong Xiao","Zhaowei Zhang","Jing Huo","Weijie J. Su","Yaodong Yang"],"pdf_url":"https://arxiv.org/pdf/2410.16714v1.pdf","comment":"Under review"},{"id":"http://arxiv.org/abs/2404.11216v2","updated":"2024-10-22T05:45:46Z","published":"2024-04-17T10:00:56Z","title":"Position Engineering: Boosting Large Language Models through Positional\n  Information Manipulation","summary":"  The performance of large language models (LLMs) is significantly influenced\nby the quality of the prompts provided. In response, researchers have developed\nenormous prompt engineering strategies aimed at modifying the prompt text to\nenhance task performance. In this paper, we introduce a novel technique termed\nposition engineering, which offers a more efficient way to guide large language\nmodels. Unlike prompt engineering, which requires substantial effort to modify\nthe text provided to LLMs, position engineering merely involves altering the\npositional information in the prompt without modifying the text itself. We have\nevaluated position engineering in two widely-used LLM scenarios:\nretrieval-augmented generation (RAG) and in-context learning (ICL). Our\nfindings show that position engineering substantially improves upon the\nbaseline in both cases. Position engineering thus represents a promising new\nstrategy for exploiting the capabilities of large language models.\n","authors":["Zhiyuan He","Huiqiang Jiang","Zilong Wang","Yuqing Yang","Luna Qiu","Lili Qiu"],"pdf_url":"https://arxiv.org/pdf/2404.11216v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.02246v3","updated":"2024-10-22T05:44:04Z","published":"2024-03-04T17:34:34Z","title":"PHAnToM: Persona-based Prompting Has An Effect on Theory-of-Mind\n  Reasoning in Large Language Models","summary":"  The use of LLMs in natural language reasoning has shown mixed results,\nsometimes rivaling or even surpassing human performance in simpler\nclassification tasks while struggling with social-cognitive reasoning, a domain\nwhere humans naturally excel. These differences have been attributed to many\nfactors, such as variations in prompting and the specific LLMs used. However,\nno reasons appear conclusive, and no clear mechanisms have been established in\nprior work. In this study, we empirically evaluate how role-playing prompting\ninfluences Theory-of-Mind (ToM) reasoning capabilities. Grounding our rsearch\nin psychological theory, we propose the mechanism that, beyond the inherent\nvariance in the complexity of reasoning tasks, performance differences arise\nbecause of socially-motivated prompting differences. In an era where prompt\nengineering with role-play is a typical approach to adapt LLMs to new contexts,\nour research advocates caution as models that adopt specific personas might\npotentially result in errors in social-cognitive reasoning.\n","authors":["Fiona Anting Tan","Gerard Christopher Yeo","Kokil Jaidka","Fanyou Wu","Weijie Xu","Vinija Jain","Aman Chadha","Yang Liu","See-Kiong Ng"],"pdf_url":"https://arxiv.org/pdf/2403.02246v3.pdf","comment":"8 pages"},{"id":"http://arxiv.org/abs/2410.16712v1","updated":"2024-10-22T05:39:24Z","published":"2024-10-22T05:39:24Z","title":"DENOASR: Debiasing ASRs through Selective Denoising","summary":"  Automatic Speech Recognition (ASR) systems have been examined and shown to\nexhibit biases toward particular groups of individuals, influenced by factors\nsuch as demographic traits, accents, and speech styles. Noise can\ndisproportionately impact speakers with certain accents, dialects, or speaking\nstyles, leading to biased error rates. In this work, we introduce a novel\nframework DENOASR, which is a selective denoising technique to reduce the\ndisparity in the word error rates between the two gender groups, male and\nfemale. We find that a combination of two popular speech denoising techniques,\nviz. DEMUCS and LE, can be effectively used to mitigate ASR disparity without\ncompromising their overall performance. Experiments using two state-of-the-art\nopen-source ASRs - OpenAI WHISPER and NVIDIA NEMO - on multiple benchmark\ndatasets, including TIE, VOX-POPULI, TEDLIUM, and FLEURS, show that there is a\npromising reduction in the average word error rate gap across the two gender\ngroups. For a given dataset, the denoising is selectively applied on speech\nsamples having speech intelligibility below a certain threshold, estimated\nusing a small validation sample, thus ameliorating the need for large-scale\nhuman-written ground-truth transcripts. Our findings suggest that selective\ndenoising can be an elegant approach to mitigate biases in present-day ASR\nsystems.\n","authors":["Anand Kumar Rai","Siddharth D Jaiswal","Shubham Prakash","Bendi Pragnya Sree","Animesh Mukherjee"],"pdf_url":"https://arxiv.org/pdf/2410.16712v1.pdf","comment":"Paper accepted at IEEE ICKG 2024"},{"id":"http://arxiv.org/abs/2410.16710v1","updated":"2024-10-22T05:32:40Z","published":"2024-10-22T05:32:40Z","title":"Influential Language Data Selection via Gradient Trajectory Pursuit","summary":"  Curating a desirable dataset for training has been the core of building\nhighly capable large language models (Touvron et al., 2023; Achiam et al.,\n2023; Team et al.,2024). Gradient influence scores (Pruthi et al., 2020; Xia et\nal., 2024) are shown to be correlated with model performance and are commonly\nused as the criterion for data selection. However, existing methods are built\nupon either individual sample rankings or inefficient matching process, leading\nto suboptimal performance or scaling up issues.In this paper, we propose\nGradient Trajectory Pursuit (GTP), an algorithm that performs pursuit of\ngradient trajectories via jointly selecting data points under an L0-norm\nregularized objective. The proposed algorithm highlights: (1) joint selection\ninstead of independent top-k selection, which automatically de-duplicates\nsamples; (2) higher efficiency with compressive sampling processes, which can\nbe further sped up using a distributed framework. In the experiments, we\ndemonstrate the algorithm in both in-domain and target-domain selection\nbenchmarks and show that it outperforms top-k selection and competitive\nalgorithms consistently, for example, our algorithm chooses as low as 0.5% data\nto achieve full performance on the targeted instruction tuning tasks\n","authors":["Zhiwei Deng","Tao Li","Yang Li"],"pdf_url":"https://arxiv.org/pdf/2410.16710v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.16708v1","updated":"2024-10-22T05:25:54Z","published":"2024-10-22T05:25:54Z","title":"Atomic Fact Decomposition Helps Attributed Question Answering","summary":"  Attributed Question Answering (AQA) aims to provide both a trustworthy answer\nand a reliable attribution report for a given question. Retrieval is a widely\nadopted approach, including two general paradigms: Retrieval-Then-Read (RTR)\nand post-hoc retrieval. Recently, Large Language Models (LLMs) have shown\nremarkable proficiency, prompting growing interest in AQA among researchers.\nHowever, RTR-based AQA often suffers from irrelevant knowledge and rapidly\nchanging information, even when LLMs are adopted, while post-hoc\nretrieval-based AQA struggles with comprehending long-form answers with complex\nlogic, and precisely identifying the content needing revision and preserving\nthe original intent. To tackle these problems, this paper proposes an Atomic\nfact decomposition-based Retrieval and Editing (ARE) framework, which\ndecomposes the generated long-form answers into molecular clauses and atomic\nfacts by the instruction-tuned LLMs. Notably, the instruction-tuned LLMs are\nfine-tuned using a well-constructed dataset, generated from large scale\nKnowledge Graphs (KGs). This process involves extracting one-hop neighbors from\na given set of entities and transforming the result into coherent long-form\ntext. Subsequently, ARE leverages a search engine to retrieve evidences related\nto atomic facts, inputting these evidences into an LLM-based verifier to\ndetermine whether the facts require expansion for re-retrieval or editing.\nFurthermore, the edited facts are backtracked into the original answer, with\nevidence aggregated based on the relationship between molecular clauses and\natomic facts. Extensive evaluations demonstrate the superior performance of our\nproposed method over the state-of-the-arts on several datasets, with an\nadditionally proposed new metric $Attr_{p}$ for evaluating the precision of\nevidence attribution.\n","authors":["Zhichao Yan","Jiapu Wang","Jiaoyan Chen","Xiaoli Li","Ru Li","Jeff Z. Pan"],"pdf_url":"https://arxiv.org/pdf/2410.16708v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.16703v1","updated":"2024-10-22T05:16:19Z","published":"2024-10-22T05:16:19Z","title":"PLDR-LLM: Large Language Model from Power Law Decoder Representations","summary":"  We present the Large Language Model from Power Law Decoder Representations\n(PLDR-LLM), a language model that leverages non-linear and linear\ntransformations through Power Law Graph Attention mechanism to generate\nwell-defined deductive and inductive outputs. We pretrain the PLDR-LLMs of\nvarying layer sizes with a small batch size of 32 and $\\sim$8B tokens from the\nRefinedWeb dataset, and show that they achieve competitive performance in\nzero-shot and few-shot settings compared to scaled dot-product LLMs of similar\nmodel size reported in the literature. We show that deductive outputs of\nPLDR-LLMs can be used to compare model characteristics or improve the\nperformance by introducing the Directed Acyclic Graph (DAG) loss as a metric\nand regularizer. Our results indicate that the initial maximum learning rate\nand warm-up steps have a lasting impact on deductive outputs throughout the\npretraining. We provide a detailed description of PLDR-LLM architecture, its\nimplementation and the pretraining procedure.\n","authors":["Burc Gokden"],"pdf_url":"https://arxiv.org/pdf/2410.16703v1.pdf","comment":"22 pages, 4 figures, 10 tables"},{"id":"http://arxiv.org/abs/2407.00219v2","updated":"2024-10-22T05:13:15Z","published":"2024-06-28T20:06:30Z","title":"Evaluating Human Alignment and Model Faithfulness of LLM Rationale","summary":"  We study how well large language models (LLMs) explain their generations\nthrough rationales -- a set of tokens extracted from the input text that\nreflect the decision-making process of LLMs. Specifically, we systematically\nstudy rationales derived using two approaches: (1) popular prompting-based\nmethods, where prompts are used to guide LLMs in generating rationales, and (2)\ntechnical attribution-based methods, which leverage attention or gradients to\nidentify important tokens. Our analysis spans three classification datasets\nwith annotated rationales, encompassing tasks with varying performance levels.\nWhile prompting-based self-explanations are widely used, our study reveals that\nthese explanations are not always as \"aligned\" with the human rationale as\nattribution-based explanations. Even more so, fine-tuning LLMs to enhance\nclassification task accuracy does not enhance the alignment of prompting-based\nrationales. Still, it does considerably improve the alignment of\nattribution-based methods (e.g., InputXGradient). More importantly, we show\nthat prompting-based self-explanation is also less \"faithful\" than\nattribution-based explanations, failing to provide a reliable account of the\nmodel's decision-making process. To evaluate faithfulness, unlike prior studies\nthat excluded misclassified examples, we evaluate all instances and also\nexamine the impact of fine-tuning and accuracy on alignment and faithfulness.\nOur findings suggest that inconclusive faithfulness results reported in earlier\nstudies may stem from low classification accuracy. These findings underscore\nthe importance of more rigorous and comprehensive evaluations of LLM\nrationales.\n","authors":["Mohsen Fayyaz","Fan Yin","Jiao Sun","Nanyun Peng"],"pdf_url":"https://arxiv.org/pdf/2407.00219v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.16682v1","updated":"2024-10-22T04:27:03Z","published":"2024-10-22T04:27:03Z","title":"Methods of improving LLM training stability","summary":"  Training stability of large language models(LLMs) is an important research\ntopic. Reproducing training instabilities can be costly, so we use a small\nlanguage model with 830M parameters and experiment with higher learning rates\nto force models to diverge. One of the sources of training instability is the\ngrowth of logits in attention layers. We extend the focus of the previous work\nand look not only at the magnitude of the logits but at all outputs of linear\nlayers in the Transformer block. We observe that with a high learning rate the\nL2 norm of all linear layer outputs can grow with each training step and the\nmodel diverges. Specifically we observe that QKV, Proj and FC2 layers have the\nlargest growth of the output magnitude. This prompts us to explore several\noptions: 1) apply layer normalization not only after QK layers but also after\nProj and FC2 layers too; 2) apply layer normalization after the QKV layer (and\nremove pre normalization). 3) apply QK layer normalization together with\nsoftmax capping. We show that with the last two methods we can increase\nlearning rate by 1.5x (without model divergence) in comparison to an approach\nbased on QK layer normalization only. Also we observe significant perplexity\nimprovements for all three methods in comparison to the baseline model.\n","authors":["Oleg Rybakov","Mike Chrzanowski","Peter Dykas","Jinze Xue","Ben Lanir"],"pdf_url":"https://arxiv.org/pdf/2410.16682v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.16676v1","updated":"2024-10-22T04:18:19Z","published":"2024-10-22T04:18:19Z","title":"Improving Causal Reasoning in Large Language Models: A Survey","summary":"  Causal reasoning (CR) is a crucial aspect of intelligence, essential for\nproblem-solving, decision-making, and understanding the world. While large\nlanguage models (LLMs) can generate rationales for their outputs, their ability\nto reliably perform causal reasoning remains uncertain, often falling short in\ntasks requiring a deep understanding of causality. In this survey, we provide a\ncomprehensive review of research aimed at enhancing LLMs for causal reasoning.\nWe categorize existing methods based on the role of LLMs: either as reasoning\nengines or as helpers providing knowledge or data to traditional CR methods,\nfollowed by a detailed discussion of the methodologies in each category. We\nthen evaluate the performance of LLMs on various causal reasoning tasks,\nproviding key findings and in-depth analysis. Finally, we provide insights from\ncurrent studies and highlight promising directions for future research. We aim\nfor this work to serve as a comprehensive resource, fostering further\nadvancements in causal reasoning with LLMs. Resources are available at\nhttps://github.com/chendl02/Awesome-LLM-causal-reasoning.\n","authors":["Siheng Xiong","Delin Chen","Qingyang Wu","Longxuan Yu","Qingzhen Liu","Dawei Li","Zhikai Chen","Xiaoze Liu","Liangming Pan"],"pdf_url":"https://arxiv.org/pdf/2410.16676v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2402.08777v3","updated":"2024-10-22T04:14:08Z","published":"2024-02-13T20:21:29Z","title":"DNABERT-S: Pioneering Species Differentiation with Species-Aware DNA\n  Embeddings","summary":"  We introduce DNABERT-S, a tailored genome model that develops species-aware\nembeddings to naturally cluster and segregate DNA sequences of different\nspecies in the embedding space. Differentiating species from genomic sequences\n(i.e., DNA and RNA) is vital yet challenging, since many real-world species\nremain uncharacterized, lacking known genomes for reference. Embedding-based\nmethods are therefore used to differentiate species in an unsupervised manner.\nDNABERT-S builds upon a pre-trained genome foundation model named DNABERT-2. To\nencourage effective embeddings to error-prone long-read DNA sequences, we\nintroduce Manifold Instance Mixup (MI-Mix), a contrastive objective that mixes\nthe hidden representations of DNA sequences at randomly selected layers and\ntrains the model to recognize and differentiate these mixed proportions at the\noutput layer. We further enhance it with the proposed Curriculum Contrastive\nLearning (C$^2$LR) strategy. Empirical results on 23 diverse datasets show\nDNABERT-S's effectiveness, especially in realistic label-scarce scenarios. For\nexample, it identifies twice more species from a mixture of unlabeled genomic\nsequences, doubles the Adjusted Rand Index (ARI) in species clustering, and\noutperforms the top baseline's performance in 10-shot species classification\nwith just a 2-shot training. Model, codes, and data are publicly available at\n\\url{https://github.com/MAGICS-LAB/DNABERT_S}.\n","authors":["Zhihan Zhou","Weimin Wu","Harrison Ho","Jiayi Wang","Lizhen Shi","Ramana V Davuluri","Zhong Wang","Han Liu"],"pdf_url":"https://arxiv.org/pdf/2402.08777v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.05286v3","updated":"2024-10-22T03:58:20Z","published":"2024-03-08T13:10:59Z","title":"LLM4Decompile: Decompiling Binary Code with Large Language Models","summary":"  Decompilation aims to convert binary code to high-level source code, but\ntraditional tools like Ghidra often produce results that are difficult to read\nand execute. Motivated by the advancements in Large Language Models (LLMs), we\npropose LLM4Decompile, the first and largest open-source LLM series (1.3B to\n33B) trained to decompile binary code. We optimize the LLM training process and\nintroduce the LLM4Decompile-End models to decompile binary directly. The\nresulting models significantly outperform GPT-4o and Ghidra on the HumanEval\nand ExeBench benchmarks by over 100% in terms of re-executability rate.\nAdditionally, we improve the standard refinement approach to fine-tune the\nLLM4Decompile-Ref models, enabling them to effectively refine the decompiled\ncode from Ghidra and achieve a further 16.2% improvement over the\nLLM4Decompile-End. LLM4Decompile demonstrates the potential of LLMs to\nrevolutionize binary code decompilation, delivering remarkable improvements in\nreadability and executability while complementing conventional tools for\noptimal results. Our code, dataset, and models are released at\nhttps://github.com/albertan017/LLM4Decompile\n","authors":["Hanzhuo Tan","Qi Luo","Jing Li","Yuqun Zhang"],"pdf_url":"https://arxiv.org/pdf/2403.05286v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.16665v1","updated":"2024-10-22T03:38:37Z","published":"2024-10-22T03:38:37Z","title":"SafetyAnalyst: Interpretable, transparent, and steerable LLM safety\n  moderation","summary":"  The ideal LLM content moderation system would be both structurally\ninterpretable (so its decisions can be explained to users) and steerable (to\nreflect a community's values or align to safety standards). However, current\nsystems fall short on both of these dimensions. To address this gap, we present\nSafetyAnalyst, a novel LLM safety moderation framework. Given a prompt,\nSafetyAnalyst creates a structured \"harm-benefit tree,\" which identifies 1) the\nactions that could be taken if a compliant response were provided, 2) the\nharmful and beneficial effects of those actions (along with their likelihood,\nseverity, and immediacy), and 3) the stakeholders that would be impacted by\nthose effects. It then aggregates this structured representation into a\nharmfulness score based on a parameterized set of safety preferences, which can\nbe transparently aligned to particular values. Using extensive harm-benefit\nfeatures generated by SOTA LLMs on 19k prompts, we fine-tuned an open-weight LM\nto specialize in generating harm-benefit trees through symbolic knowledge\ndistillation. On a comprehensive set of prompt safety benchmarks, we show that\nour system (average F1=0.75) outperforms existing LLM safety moderation systems\n(average F1$<$0.72) on prompt harmfulness classification, while offering the\nadditional advantages of interpretability and steerability.\n","authors":["Jing-Jing Li","Valentina Pyatkin","Max Kleiman-Weiner","Liwei Jiang","Nouha Dziri","Anne G. E. Collins","Jana Schaich Borg","Maarten Sap","Yejin Choi","Sydney Levine"],"pdf_url":"https://arxiv.org/pdf/2410.16665v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.01812v3","updated":"2024-10-22T03:30:01Z","published":"2024-09-14T02:35:29Z","title":"From Text to Multimodality: Exploring the Evolution and Impact of Large\n  Language Models in Medical Practice","summary":"  Large Language Models (LLMs) have rapidly evolved from text-based systems to\nmultimodal platforms, significantly impacting various sectors including\nhealthcare. This comprehensive review explores the progression of LLMs to\nMultimodal Large Language Models (MLLMs) and their growing influence in medical\npractice. We examine the current landscape of MLLMs in healthcare, analyzing\ntheir applications across clinical decision support, medical imaging, patient\nengagement, and research. The review highlights the unique capabilities of\nMLLMs in integrating diverse data types, such as text, images, and audio, to\nprovide more comprehensive insights into patient health. We also address the\nchallenges facing MLLM implementation, including data limitations, technical\nhurdles, and ethical considerations. By identifying key research gaps, this\npaper aims to guide future investigations in areas such as dataset development,\nmodality alignment methods, and the establishment of ethical guidelines. As\nMLLMs continue to shape the future of healthcare, understanding their potential\nand limitations is crucial for their responsible and effective integration into\nmedical practice.\n","authors":["Qian Niu","Keyu Chen","Ming Li","Pohsun Feng","Ziqian Bi","Lawrence KQ Yan","Yichao Zhang","Caitlyn Heqi Yin","Cheng Fei","Junyu Liu","Benji Peng"],"pdf_url":"https://arxiv.org/pdf/2410.01812v3.pdf","comment":"12 pages, 1 figure"},{"id":"http://arxiv.org/abs/2410.16659v1","updated":"2024-10-22T03:21:59Z","published":"2024-10-22T03:21:59Z","title":"RKadiyala at SemEval-2024 Task 8: Black-Box Word-Level Text Boundary\n  Detection in Partially Machine Generated Texts","summary":"  With increasing usage of generative models for text generation and widespread\nuse of machine generated texts in various domains, being able to distinguish\nbetween human written and machine generated texts is a significant challenge.\nWhile existing models and proprietary systems focus on identifying whether\ngiven text is entirely human written or entirely machine generated, only a few\nsystems provide insights at sentence or paragraph level at likelihood of being\nmachine generated at a non reliable accuracy level, working well only for a set\nof domains and generators. This paper introduces few reliable approaches for\nthe novel task of identifying which part of a given text is machine generated\nat a word level while comparing results from different approaches and methods.\nWe present a comparison with proprietary systems , performance of our model on\nunseen domains' and generators' texts. The findings reveal significant\nimprovements in detection accuracy along with comparison on other aspects of\ndetection capabilities. Finally we discuss potential avenues for improvement\nand implications of our work. The proposed model is also well suited for\ndetecting which parts of a text are machine generated in outputs of Instruct\nvariants of many LLMs.\n","authors":["Ram Mohan Rao Kadiyala"],"pdf_url":"https://arxiv.org/pdf/2410.16659v1.pdf","comment":"published at naacl 2024"},{"id":"http://arxiv.org/abs/2410.16658v1","updated":"2024-10-22T03:19:16Z","published":"2024-10-22T03:19:16Z","title":"Adsorb-Agent: Autonomous Identification of Stable Adsorption\n  Configurations via Large Language Model Agent","summary":"  Adsorption energy is a key reactivity descriptor in catalysis, enabling the\nefficient screening of potential catalysts. However, determining adsorption\nenergy involves comparing the energies of multiple adsorbate-catalyst\nconfigurations, which is computationally demanding due to a large number of\npossible configurations. Current algorithmic approaches typically enumerate\nadsorption sites and configurations without leveraging theoretical insights to\nguide the initial setup. In this work, we present Adsorb-Agent, a Large\nLanguage Model (LLM) agent designed to efficiently derive system-specific\nstable adsorption configurations with minimal human intervention. Adsorb-Agent\nleverages built-in knowledge and emergent reasoning capabilities, significantly\nreducing the number of initial configurations required while improving accuracy\nin predicting the minimum adsorption energy. We demonstrate its performance\nusing two example systems, NNH-CuPd3 (111) and NNH-Mo3Pd (111), for the\nNitrogen Reduction Reaction (NRR), a sustainable alternative to the Haber-Bosch\nprocess. Adsorb-Agent outperforms conventional \"heuristic\" and \"random\"\nalgorithms by identifying lower-energy configurations with fewer initial\nsetups, reducing computational costs while enhancing accuracy. This highlights\nits potential to accelerate catalyst discovery.\n","authors":["Janghoon Ock","Tirtha Vinchurkar","Yayati Jadhav","Amir Barati Farimani"],"pdf_url":"https://arxiv.org/pdf/2410.16658v1.pdf","comment":"11 pages, 3 figures"},{"id":"http://arxiv.org/abs/2410.16645v1","updated":"2024-10-22T02:45:09Z","published":"2024-10-22T02:45:09Z","title":"Chatting with Bots: AI, Speech Acts, and the Edge of Assertion","summary":"  This paper addresses the question of whether large language model-powered\nchatbots are capable of assertion. According to what we call the Thesis of\nChatbot Assertion (TCA), chatbots are the kinds of things that can assert, and\nat least some of the output produced by current-generation chatbots qualifies\nas assertion. We provide some motivation for TCA, arguing that it ought to be\ntaken seriously and not simply dismissed. We also review recent objections to\nTCA, arguing that these objections are weighty. We thus confront the following\ndilemma: how can we do justice to both the considerations for and against TCA?\nWe consider two influential responses to this dilemma - the first appeals to\nthe notion of proxy-assertion; the second appeals to fictionalism - and argue\nthat neither is satisfactory. Instead, reflecting on the ontogenesis of\nassertion, we argue that we need to make space for a category of\nproto-assertion. We then apply the category of proto-assertion to chatbots,\narguing that treating chatbots as proto-assertors provides a satisfactory\nresolution to the dilemma of chatbot assertion.\n","authors":["Iwan Williams","Tim Bayne"],"pdf_url":"https://arxiv.org/pdf/2410.16645v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.16640v1","updated":"2024-10-22T02:38:48Z","published":"2024-10-22T02:38:48Z","title":"A Statistical Analysis of LLMs' Self-Evaluation Using Proverbs","summary":"  Large language models (LLMs) such as ChatGPT, GPT-4, Claude-3, and Llama are\nbeing integrated across a variety of industries. Despite this rapid\nproliferation, experts are calling for caution in the interpretation and\nadoption of LLMs, owing to numerous associated ethical concerns. Research has\nalso uncovered shortcomings in LLMs' reasoning and logical abilities, raising\nquestions on the potential of LLMs as evaluation tools. In this paper, we\ninvestigate LLMs' self-evaluation capabilities on a novel proverb reasoning\ntask. We introduce a novel proverb database consisting of 300 proverb pairs\nthat are similar in intent but different in wordings, across topics spanning\ngender, wisdom, and society. We propose tests to evaluate textual consistencies\nas well as numerical consistencies across similar proverbs, and demonstrate the\neffectiveness of our method and dataset in identifying failures in LLMs'\nself-evaluation which in turn can highlight issues related to gender\nstereotypes and lack of cultural understanding in LLMs.\n","authors":["Ryosuke Sonoda","Ramya Srinivasan"],"pdf_url":"https://arxiv.org/pdf/2410.16640v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2409.16167v3","updated":"2024-10-22T02:29:22Z","published":"2024-09-24T15:08:41Z","title":"Merging LoRAs like Playing LEGO: Pushing the Modularity of LoRA to\n  Extremes Through Rank-Wise Clustering","summary":"  Low-Rank Adaptation (LoRA) has emerged as a popular technique for fine-tuning\nlarge language models (LLMs) to various domains due to its modular design and\nwidespread availability on platforms like Huggingface. This modularity has\nsparked interest in combining multiple LoRAs to enhance LLM capabilities.\nHowever, existing methods for LoRA composition primarily focus on task-specific\nadaptations that require additional training, and current model merging\ntechniques often fail to fully leverage LoRA's modular nature, leading to\nparameter interference and performance degradation. In this paper, we\ninvestigate the feasibility of disassembling and reassembling multiple LoRAs at\na finer granularity, analogous to assembling LEGO blocks. We introduce the\nconcept of Minimal Semantic Units (MSUs), where the parameters corresponding to\neach rank in LoRA function as independent units. These MSUs demonstrate\npermutation invariance and concatenation-summation equivalence properties,\nenabling flexible combinations to create new LoRAs. Building on these insights,\nwe propose the LoRA-LEGO framework. This framework conducts rank-wise parameter\nclustering by grouping MSUs from different LoRAs into $k$ clusters. The\ncentroid of each cluster serves as a representative MSU, enabling the assembly\nof a merged LoRA with an adjusted rank of $k$. Additionally, we apply a dual\nreweighting strategy to optimize the scale of the merged LoRA. Experiments\nacross various benchmarks demonstrate that our method outperforms existing\napproaches in LoRA merging.\n","authors":["Ziyu Zhao","Tao Shen","Didi Zhu","Zexi Li","Jing Su","Xuwu Wang","Kun Kuang","Fei Wu"],"pdf_url":"https://arxiv.org/pdf/2409.16167v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.16638v1","updated":"2024-10-22T02:27:57Z","published":"2024-10-22T02:27:57Z","title":"LLMScan: Causal Scan for LLM Misbehavior Detection","summary":"  Despite the success of Large Language Models (LLMs) across various fields,\ntheir potential to generate untruthful, biased and harmful responses poses\nsignificant risks, particularly in critical applications. This highlights the\nurgent need for systematic methods to detect and prevent such misbehavior.\nWhile existing approaches target specific issues such as harmful responses,\nthis work introduces LLMScan, an innovative LLM monitoring technique based on\ncausality analysis, offering a comprehensive solution. LLMScan systematically\nmonitors the inner workings of an LLM through the lens of causal inference,\noperating on the premise that the LLM's `brain' behaves differently when\nmisbehaving. By analyzing the causal contributions of the LLM's input tokens\nand transformer layers, LLMScan effectively detects misbehavior. Extensive\nexperiments across various tasks and models reveal clear distinctions in the\ncausal distributions between normal behavior and misbehavior, enabling the\ndevelopment of accurate, lightweight detectors for a variety of misbehavior\ndetection tasks.\n","authors":["Mengdi Zhang","Kai Kiat Goh","Peixin Zhang","Jun Sun"],"pdf_url":"https://arxiv.org/pdf/2410.16638v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.16633v1","updated":"2024-10-22T02:21:42Z","published":"2024-10-22T02:21:42Z","title":"Graph-Structured Trajectory Extraction from Travelogues","summary":"  Previous studies on sequence-based extraction of human movement trajectories\nhave an issue of inadequate trajectory representation. Specifically, a pair of\nlocations may not be lined up in a sequence especially when one location\nincludes the other geographically. In this study, we propose a graph\nrepresentation that retains information on the geographic hierarchy as well as\nthe temporal order of visited locations, and have constructed a benchmark\ndataset for graph-structured trajectory extraction. The experiments with our\nbaselines have demonstrated that it is possible to accurately predict visited\nlocations and the order among them, but it remains a challenge to predict the\nhierarchical relations.\n","authors":["Aitaro Yamamoto","Hiroyuki Otomo","Hiroki Ouchi","Shohei Higashiyama","Hiroki Teranishi","Hiroyuki Shindo","Taro Watanabe"],"pdf_url":"https://arxiv.org/pdf/2410.16633v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2405.10523v2","updated":"2024-10-22T01:58:40Z","published":"2024-05-17T04:05:05Z","title":"Adaptable and Reliable Text Classification using Large Language Models","summary":"  Text classification is fundamental in Natural Language Processing (NLP), and\nthe advent of Large Language Models (LLMs) has revolutionized the field. This\npaper introduces an adaptable and reliable text classification paradigm, which\nleverages LLMs as the core component to address text classification tasks. Our\nsystem simplifies the traditional text classification workflows, reducing the\nneed for extensive preprocessing and domain-specific expertise to deliver\nadaptable and reliable text classification results. We evaluated the\nperformance of several LLMs, machine learning algorithms, and neural\nnetwork-based architectures on four diverse datasets. Results demonstrate that\ncertain LLMs surpass traditional methods in sentiment analysis, spam SMS\ndetection, and multi-label classification. Furthermore, it is shown that the\nsystem's performance can be further enhanced through few-shot or fine-tuning\nstrategies, making the fine-tuned model the top performer across all datasets.\nSource code and datasets are available in this GitHub repository:\nhttps://github.com/yeyimilk/llm-zero-shot-classifiers.\n","authors":["Zhiqiang Wang","Yiran Pang","Yanbin Lin","Xingquan Zhu"],"pdf_url":"https://arxiv.org/pdf/2405.10523v2.pdf","comment":"ICDM Workshop ARRL 2024"},{"id":"http://arxiv.org/abs/2406.16030v2","updated":"2024-10-22T01:31:31Z","published":"2024-06-23T06:38:56Z","title":"Zero-Shot Cross-Lingual NER Using Phonemic Representations for\n  Low-Resource Languages","summary":"  Existing zero-shot cross-lingual NER approaches require substantial prior\nknowledge of the target language, which is impractical for low-resource\nlanguages. In this paper, we propose a novel approach to NER using phonemic\nrepresentation based on the International Phonetic Alphabet (IPA) to bridge the\ngap between representations of different languages. Our experiments show that\nour method significantly outperforms baseline models in extremely low-resource\nlanguages, with the highest average F1 score (46.38%) and lowest standard\ndeviation (12.67), particularly demonstrating its robustness with non-Latin\nscripts. Our codes are available at\nhttps://github.com/Gabriel819/zeroshot_ner.git\n","authors":["Jimin Sohn","Haeji Jung","Alex Cheng","Jooeon Kang","Yilin Du","David R. Mortensen"],"pdf_url":"https://arxiv.org/pdf/2406.16030v2.pdf","comment":"Accepted to EMNLP 2024 Main Conference"},{"id":"http://arxiv.org/abs/2410.14978v2","updated":"2024-10-22T01:29:36Z","published":"2024-10-19T05:01:56Z","title":"Subversive Characters and Stereotyping Readers: Characterizing Queer\n  Relationalities with Dialogue-Based Relation Extraction","summary":"  Television is often seen as a site for subcultural identification and\nsubversive fantasy, including in queer cultures. How might we measure\nsubversion, or the degree to which the depiction of social relationship between\na dyad (e.g. two characters who are colleagues) deviates from its typical\nrepresentation on TV? To explore this question, we introduce the task of\nstereotypic relationship extraction. Built on cognitive stylistics, linguistic\nanthropology, and dialogue relation extraction, in this paper, we attempt to\nmodel the cognitive process of stereotyping TV characters in dialogic\ninteractions. Given a dyad, we want to predict: what social relationship do the\nspeakers exhibit through their words? Subversion is then characterized by the\ndiscrepancy between the distribution of the model's predictions and the ground\ntruth labels. To demonstrate the usefulness of this task and gesture at a\nmethodological intervention, we enclose four case studies to characterize the\nrepresentation of queer relationalities in the Big Bang Theory, Frasier, and\nGilmore Girls, as we explore the suspicious and reparative modes of reading\nwith our computational methods.\n","authors":["Kent K. Chang","Anna Ho","David Bamman"],"pdf_url":"https://arxiv.org/pdf/2410.14978v2.pdf","comment":"CHR 2024: Computational Humanities Research Conference"},{"id":"http://arxiv.org/abs/2409.13705v2","updated":"2024-10-22T01:01:56Z","published":"2024-09-05T14:35:35Z","title":"Debiasing Text Safety Classifiers through a Fairness-Aware Ensemble","summary":"  Increasing use of large language models (LLMs) demand performant guardrails\nto ensure the safety of inputs and outputs of LLMs. When these safeguards are\ntrained on imbalanced data, they can learn the societal biases. We present a\nlight-weight, post-processing method for mitigating counterfactual fairness in\nclosed-source text safety classifiers. Our approach involves building an\nensemble that not only outperforms the input classifiers and policy-aligns\nthem, but also acts as a debiasing regularizer. We introduce two\nthreshold-agnostic metrics to assess the counterfactual fairness of a model,\nand demonstrate how combining these metrics with Fair Data Reweighting (FDW)\nhelps mitigate biases. We create an expanded Open AI dataset, and a new\ntemplated LLM-generated dataset based on user-prompts, both of which are\ncounterfactually balanced across identity groups and cover four key areas of\nsafety; we will work towards publicly releasing these datasets. Our results\nshow that our approach improves counterfactual fairness with minimal impact on\nmodel performance.\n","authors":["Olivia Sturman","Aparna Joshi","Bhaktipriya Radharapu","Piyush Kumar","Renee Shelby"],"pdf_url":"https://arxiv.org/pdf/2409.13705v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.16597v1","updated":"2024-10-22T00:47:54Z","published":"2024-10-22T00:47:54Z","title":"Distill-SynthKG: Distilling Knowledge Graph Synthesis Workflow for\n  Improved Coverage and Efficiency","summary":"  Knowledge graphs (KGs) generated by large language models (LLMs) are becoming\nincreasingly valuable for Retrieval-Augmented Generation (RAG) applications\nthat require knowledge-intensive reasoning. However, existing KG extraction\nmethods predominantly rely on prompt-based approaches, which are inefficient\nfor processing large-scale corpora. These approaches often suffer from\ninformation loss, particularly with long documents, due to the lack of\nspecialized design for KG construction. Additionally, there is a gap in\nevaluation datasets and methodologies for ontology-free KG construction. To\novercome these limitations, we propose SynthKG, a multi-step, document-level\nontology-free KG synthesis workflow based on LLMs. By fine-tuning a smaller LLM\non the synthesized document-KG pairs, we streamline the multi-step process into\na single-step KG generation approach called Distill-SynthKG, substantially\nreducing the number of LLM inference calls. Furthermore, we re-purpose existing\nquestion-answering datasets to establish KG evaluation datasets and introduce\nnew evaluation metrics. Using KGs produced by Distill-SynthKG, we also design a\nnovel graph-based retrieval framework for RAG. Experimental results demonstrate\nthat Distill-SynthKG not only surpasses all baseline models in KG quality --\nincluding models up to eight times larger -- but also consistently excels in\nretrieval and question-answering tasks. Our proposed graph retrieval framework\nalso outperforms all KG-retrieval methods across multiple benchmark datasets.\nWe release the SynthKG dataset and Distill-SynthKG model publicly to support\nfurther research and development.\n","authors":["Prafulla Kumar Choubey","Xin Su","Man Luo","Xiangyu Peng","Caiming Xiong","Tiep Le","Shachar Rosenman","Vasudev Lal","Phil Mui","Ricky Ho","Phillip Howard","Chien-Sheng Wu"],"pdf_url":"https://arxiv.org/pdf/2410.16597v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.11020v3","updated":"2024-10-22T00:42:39Z","published":"2024-10-14T19:16:56Z","title":"Improving the Language Understanding Capabilities of Large Language\n  Models Using Reinforcement Learning","summary":"  Large language models (LLMs), built on decoder-only transformers, excel in\nnatural language generation and adapt to diverse tasks using zero-shot and\nfew-shot prompting. However, these prompting methods often struggle on natural\nlanguage understanding (NLU) tasks, where encoder-only models like BERT-base\noutperform LLMs on benchmarks like GLUE and SuperGLUE. This paper explores two\napproaches-supervised fine-tuning (SFT) and proximal policy optimization\n(PPO)-to enhance LLMs' NLU abilities. To reduce the cost of full-model\nfine-tuning, we integrate low-rank adaptation (LoRA) layers, limiting updates\nto these layers during both SFT and PPO. In SFT, task-specific prompts are\nconcatenated with input queries and ground-truth labels, optimizing with\nnext-token prediction. Despite this, LLMs still underperform compared to models\nlike BERT-base on several NLU tasks. To close this gap, we apply PPO, a\nreinforcement learning technique that treats each token generation as an action\nand uses a reward function based on alignment with ground-truth answers. PPO\nthen updates the model to maximize these rewards, aligning outputs with correct\nlabels. Our experiments with LLAMA2-7B show that PPO improves performance, with\na 6.3-point gain over SFT on GLUE. PPO exceeds zero-shot by 38.7 points and\nfew-shot by 26.1 points on GLUE, while surpassing these by 28.8 and 28.5 points\non SuperGLUE. Additionally, PPO outperforms BERT-large by 2.7 points on GLUE\nand 9.3 points on SuperGLUE. The improvements are consistent across models like\nQwen2.5-7B and MPT-7B, highlighting PPO's robustness in enhancing LLMs' NLU\ncapabilities.\n","authors":["Bokai Hu","Sai Ashish Somayajula","Xin Pan","Zihan Huang","Pengtao Xie"],"pdf_url":"https://arxiv.org/pdf/2410.11020v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.16592v1","updated":"2024-10-22T00:30:08Z","published":"2024-10-22T00:30:08Z","title":"ViMGuard: A Novel Multi-Modal System for Video Misinformation Guarding","summary":"  The rise of social media and short-form video (SFV) has facilitated a\nbreeding ground for misinformation. With the emergence of large language\nmodels, significant research has gone into curbing this misinformation problem\nwith automatic false claim detection for text. Unfortunately, the automatic\ndetection of misinformation in SFV is a more complex problem that remains\nlargely unstudied. While text samples are monomodal (only containing words),\nSFVs comprise three different modalities: words, visuals, and non-linguistic\naudio. In this work, we introduce Video Masked Autoencoders for Misinformation\nGuarding (ViMGuard), the first deep-learning architecture capable of\nfact-checking an SFV through analysis of all three of its constituent\nmodalities. ViMGuard leverages a dual-component system. First, Video and Audio\nMasked Autoencoders analyze the visual and non-linguistic audio elements of a\nvideo to discern its intention; specifically whether it intends to make an\ninformative claim. If it is deemed that the SFV has informative intent, it is\npassed through our second component: a Retrieval Augmented Generation system\nthat validates the factual accuracy of spoken words. In evaluation, ViMGuard\noutperformed three cutting-edge fact-checkers, thus setting a new standard for\nSFV fact-checking and marking a significant stride toward trustworthy news on\nsocial platforms. To promote further testing and iteration, VimGuard was\ndeployed into a Chrome extension and all code was open-sourced on GitHub.\n","authors":["Andrew Kan","Christopher Kan","Zaid Nabulsi"],"pdf_url":"https://arxiv.org/pdf/2410.16592v1.pdf","comment":"7 pages, 2 figures"},{"id":"http://arxiv.org/abs/2407.05841v2","updated":"2024-10-22T00:16:21Z","published":"2024-07-08T11:38:49Z","title":"An Empirical Comparison of Vocabulary Expansion and Initialization\n  Approaches for Language Models","summary":"  Language Models (LMs) excel in natural language processing tasks for English\nbut show reduced performance in most other languages. This problem is commonly\ntackled by continually pre-training and fine-tuning these models for said\nlanguages. A significant issue in this process is the limited vocabulary\ncoverage in the original model's tokenizer, leading to inadequate\nrepresentation of new languages and necessitating an expansion of the\ntokenizer. The initialization of the embeddings corresponding to new vocabulary\nitems presents a further challenge. Current strategies require cross-lingual\nembeddings and lack a solid theoretical foundation as well as comparisons with\nstrong baselines. In this paper, we first establish theoretically that\ninitializing within the convex hull of existing embeddings is a good\ninitialization, followed by a novel but simple approach, Constrained Word2Vec\n(CW2V), which does not require cross-lingual embeddings. Our study evaluates\ndifferent initialization methods for expanding RoBERTa and LLaMA 2 across four\nlanguages and five tasks. The results show that CW2V performs equally well or\neven better than more advanced techniques. Additionally, simpler approaches\nlike multivariate initialization perform on par with these advanced methods\nindicating that efficient large-scale multilingual continued pretraining can be\nachieved even with simpler initialization methods. We release our code publicly\n(https://github.com/AI4Bharat/VocabAdaptation_LLM/tree/CW2V).\n","authors":["Nandini Mundra","Aditya Nanda Kishore","Raj Dabre","Ratish Puduppully","Anoop Kunchukuttan","Mitesh M. Khapra"],"pdf_url":"https://arxiv.org/pdf/2407.05841v2.pdf","comment":"CONLL 2024 (EMNLP 2024)"},{"id":"http://arxiv.org/abs/2410.16589v1","updated":"2024-10-22T00:14:36Z","published":"2024-10-22T00:14:36Z","title":"Dynamic Adaptive Rank Space Exploration for Efficient Sentiment Analysis\n  with Large Language Models","summary":"  Sentiment analysis has become increasingly important for assessing public\nopinion and informing decision-making. Large language models (LLMs) have\nrevolutionized this field by capturing nuanced language patterns. However,\nadapting LLMs to domain-specific sentiment analysis tasks remains challenging\ndue to computational constraints and the need for optimal fine-tuning. To\naddress these challenges, we propose a novel Dynamic Adaptive Rank Space\nExploration (DARSE) framework for efficient and effective sentiment analysis\nusing LLMs. DARSE consists of a coarse-grained greedy algorithm to identify the\noptimal rank range, a fine-grained exploration algorithm to refine rank\nselection, and a dynamic rank allocation method to determine the optimal rank\ncombination for each LLM layer. Extensive experiments demonstrate that DARSE\nsignificantly improves sentiment analysis accuracy, achieving a 15.1%\nimprovement in MSE and a 4.3% improvement in accuracy compared to previous\nwork. Our framework strikes a balance between computational efficiency and\nmodel performance, making it a promising approach for sentiment analysis with\nLLMs.\n","authors":["Hongcheng Ding","Fuzhen Hu","Xuanze Zhao","Zixiao Jiang","Shamsul Nahar Abdullah","Deshinta Arrova Dewi"],"pdf_url":"https://arxiv.org/pdf/2410.16589v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2405.11100v2","updated":"2024-10-22T00:02:28Z","published":"2024-05-17T21:27:32Z","title":"Are Large Language Models Moral Hypocrites? A Study Based on Moral\n  Foundations","summary":"  Large language models (LLMs) have taken centre stage in debates on Artificial\nIntelligence. Yet there remains a gap in how to assess LLMs' conformity to\nimportant human values. In this paper, we investigate whether state-of-the-art\nLLMs, GPT-4 and Claude 2.1 (Gemini Pro and LLAMA 2 did not generate valid\nresults) are moral hypocrites. We employ two research instruments based on the\nMoral Foundations Theory: (i) the Moral Foundations Questionnaire (MFQ), which\ninvestigates which values are considered morally relevant in abstract moral\njudgements; and (ii) the Moral Foundations Vignettes (MFVs), which evaluate\nmoral cognition in concrete scenarios related to each moral foundation. We\ncharacterise conflicts in values between these different abstractions of moral\nevaluation as hypocrisy. We found that both models displayed reasonable\nconsistency within each instrument compared to humans, but they displayed\ncontradictory and hypocritical behaviour when we compared the abstract values\npresent in the MFQ to the evaluation of concrete moral violations of the MFV.\n","authors":["José Luiz Nunes","Guilherme F. C. F. Almeida","Marcelo de Araujo","Simone D. J. Barbosa"],"pdf_url":"https://arxiv.org/pdf/2405.11100v2.pdf","comment":"Final version available at:\n  https://ojs.aaai.org/index.php/AIES/article/view/31704 13 pages, 4 figures, 2\n  tables"},{"id":"http://arxiv.org/abs/2410.17477v1","updated":"2024-10-22T23:24:15Z","published":"2024-10-22T23:24:15Z","title":"Do Robot Snakes Dream like Electric Sheep? Investigating the Effects of\n  Architectural Inductive Biases on Hallucination","summary":"  The growth in prominence of large language models (LLMs) in everyday life can\nbe largely attributed to their generative abilities, yet some of this is also\nowed to the risks and costs associated with their use. On one front is their\ntendency to \\textit{hallucinate} false or misleading information, limiting\ntheir reliability. On another is the increasing focus on the computational\nlimitations associated with traditional self-attention based LLMs, which has\nbrought about new alternatives, in particular recurrent models, meant to\novercome them. Yet it remains uncommon to consider these two concerns\nsimultaneously. Do changes in architecture exacerbate/alleviate existing\nconcerns about hallucinations? Do they affect how and where they occur? Through\nan extensive evaluation, we study how these architecture-based inductive biases\naffect the propensity to hallucinate. While hallucination remains a general\nphenomenon not limited to specific architectures, the situations in which they\noccur and the ease with which specific types of hallucinations can be induced\ncan significantly differ based on the model architecture. These findings\nhighlight the need for better understanding both these problems in conjunction\nwith each other, as well as consider how to design more universal techniques\nfor handling hallucinations.\n","authors":["Jerry Huang","Prasanna Parthasarathi","Mehdi Rezagholizadeh","Boxing Chen","Sarath Chandar"],"pdf_url":"https://arxiv.org/pdf/2410.17477v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2409.11402v2","updated":"2024-10-22T23:13:34Z","published":"2024-09-17T17:59:06Z","title":"NVLM: Open Frontier-Class Multimodal LLMs","summary":"  We introduce NVLM 1.0, a family of frontier-class multimodal large language\nmodels (LLMs) that achieve state-of-the-art results on vision-language tasks,\nrivaling the leading proprietary models (e.g., GPT-4o) and open-access models\n(e.g., Llama 3-V 405B and InternVL 2). Remarkably, NVLM 1.0 shows improved\ntext-only performance over its LLM backbone after multimodal training. In terms\nof model design, we perform a comprehensive comparison between decoder-only\nmultimodal LLMs (e.g., LLaVA) and cross-attention-based models (e.g.,\nFlamingo). Based on the strengths and weaknesses of both approaches, we propose\na novel architecture that enhances both training efficiency and multimodal\nreasoning capabilities. Furthermore, we introduce a 1-D tile-tagging design for\ntile-based dynamic high-resolution images, which significantly boosts\nperformance on multimodal reasoning and OCR-related tasks. Regarding training\ndata, we meticulously curate and provide detailed information on our multimodal\npretraining and supervised fine-tuning datasets. Our findings indicate that\ndataset quality and task diversity are more important than scale, even during\nthe pretraining phase, across all architectures. Notably, we develop\nproduction-grade multimodality for the NVLM-1.0 models, enabling them to excel\nin vision-language tasks while maintaining and even improving text-only\nperformance compared to their LLM backbones. To achieve this, we craft and\nintegrate a high-quality text-only dataset into multimodal training, alongside\na substantial amount of multimodal math and reasoning data, leading to enhanced\nmath and coding capabilities across modalities. To advance research in the\nfield, we release the model weights at https://huggingface.co/nvidia/NVLM-D-72B\nand will open-source the training code for the community soon.\n","authors":["Wenliang Dai","Nayeon Lee","Boxin Wang","Zhuolin Yang","Zihan Liu","Jon Barker","Tuomas Rintamaki","Mohammad Shoeybi","Bryan Catanzaro","Wei Ping"],"pdf_url":"https://arxiv.org/pdf/2409.11402v2.pdf","comment":"Fixed the typos. For more information, please visit our project page\n  at: https://research.nvidia.com/labs/adlr/NVLM-1"},{"id":"http://arxiv.org/abs/2410.17462v1","updated":"2024-10-22T22:43:14Z","published":"2024-10-22T22:43:14Z","title":"Decoding Time Series with LLMs: A Multi-Agent Framework for Cross-Domain\n  Annotation","summary":"  Time series data is ubiquitous across various domains, including\nmanufacturing, finance, and healthcare. High-quality annotations are essential\nfor effectively understanding time series and facilitating downstream tasks;\nhowever, obtaining such annotations is challenging, particularly in\nmission-critical domains. In this paper, we propose TESSA, a multi-agent system\ndesigned to automatically generate both general and domain-specific annotations\nfor time series data. TESSA introduces two agents: a general annotation agent\nand a domain-specific annotation agent. The general agent captures common\npatterns and knowledge across multiple source domains, leveraging both\ntime-series-wise and text-wise features to generate general annotations.\nMeanwhile, the domain-specific agent utilizes limited annotations from the\ntarget domain to learn domain-specific terminology and generate targeted\nannotations. Extensive experiments on multiple synthetic and real-world\ndatasets demonstrate that TESSA effectively generates high-quality annotations,\noutperforming existing methods.\n","authors":["Minhua Lin","Zhengzhang Chen","Yanchi Liu","Xujiang Zhao","Zongyu Wu","Junxiang Wang","Xiang Zhang","Suhang Wang","Haifeng Chen"],"pdf_url":"https://arxiv.org/pdf/2410.17462v1.pdf","comment":"23 pages, 9 figures, 24 tables"},{"id":"http://arxiv.org/abs/2410.14872v2","updated":"2024-10-22T22:18:14Z","published":"2024-10-18T21:38:21Z","title":"How to Evaluate Reward Models for RLHF","summary":"  We introduce a new benchmark for reward models that quantifies their ability\nto produce strong language models through RLHF (Reinforcement Learning from\nHuman Feedback). The gold-standard approach is to run a full RLHF training\npipeline and directly probe downstream LLM performance. However, this process\nis prohibitively expensive. To address this, we build a predictive model of\ndownstream LLM performance by evaluating the reward model on proxy tasks. These\nproxy tasks consist of a large-scale human preference and a verifiable\ncorrectness preference dataset, in which we measure 12 metrics across 12\ndomains. To investigate which reward model metrics are most correlated to\ngold-standard RLHF outcomes, we launch an end-to-end RLHF experiment on a\nlarge-scale crowdsourced human preference platform to view real reward model\ndownstream performance as ground truth. Ultimately, we compile our data and\nfindings into Preference Proxy Evaluations (PPE), the first reward model\nbenchmark explicitly linked to post-RLHF real-world human preference\nperformance, which we open-source for public use and further development. Our\ncode and evaluations can be found at https://github.com/lmarena/PPE .\n","authors":["Evan Frick","Tianle Li","Connor Chen","Wei-Lin Chiang","Anastasios N. Angelopoulos","Jiantao Jiao","Banghua Zhu","Joseph E. Gonzalez","Ion Stoica"],"pdf_url":"https://arxiv.org/pdf/2410.14872v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.13639v2","updated":"2024-10-22T22:05:16Z","published":"2024-10-17T15:09:03Z","title":"A Comparative Study on Reasoning Patterns of OpenAI's o1 Model","summary":"  Enabling Large Language Models (LLMs) to handle a wider range of complex\ntasks (e.g., coding, math) has drawn great attention from many researchers. As\nLLMs continue to evolve, merely increasing the number of model parameters\nyields diminishing performance improvements and heavy computational costs.\nRecently, OpenAI's o1 model has shown that inference strategies (i.e.,\nTest-time Compute methods) can also significantly enhance the reasoning\ncapabilities of LLMs. However, the mechanisms behind these methods are still\nunexplored. In our work, to investigate the reasoning patterns of o1, we\ncompare o1 with existing Test-time Compute methods (BoN, Step-wise BoN, Agent\nWorkflow, and Self-Refine) by using OpenAI's GPT-4o as a backbone on general\nreasoning benchmarks in three domains (i.e., math, coding, commonsense\nreasoning). Specifically, first, our experiments show that the o1 model has\nachieved the best performance on most datasets. Second, as for the methods of\nsearching diverse responses (e.g., BoN), we find the reward models' capability\nand the search space both limit the upper boundary of these methods. Third, as\nfor the methods that break the problem into many sub-problems, the Agent\nWorkflow has achieved better performance than Step-wise BoN due to the\ndomain-specific system prompt for planning better reasoning processes. Fourth,\nit is worth mentioning that we have summarized six reasoning patterns of o1,\nand provided a detailed analysis on several reasoning benchmarks.\n","authors":["Siwei Wu","Zhongyuan Peng","Xinrun Du","Tuney Zheng","Minghao Liu","Jialong Wu","Jiachen Ma","Yizhi Li","Jian Yang","Wangchunshu Zhou","Qunshu Lin","Junbo Zhao","Zhaoxiang Zhang","Wenhao Huang","Ge Zhang","Chenghua Lin","J. H. Liu"],"pdf_url":"https://arxiv.org/pdf/2410.13639v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.17450v1","updated":"2024-10-22T21:55:54Z","published":"2024-10-22T21:55:54Z","title":"Interação entre robôs humanoides: desenvolvendo a\n  colaboração e comunicação autônoma","summary":"  This study investigates the interaction between humanoid robots NAO and\nPepper, emphasizing their potential applications in educational settings. NAO,\nwidely used in education, and Pepper, designed for social interactions, of er\nnew opportunities for autonomous communication and collaboration. Through a\nseries of programmed interactions, the robots demonstrated their ability to\ncommunicate and coordinate actions autonomously, highlighting their potential\nas tools for enhancing learning environments. The research also explores the\nintegration of emerging technologies, such as artificial intelligence, into\nthese systems, allowing robots to learn from each other and adapt their\nbehavior. The findings suggest that NAO and Pepper can significantly contribute\nto both technical learning and the development of social and emotional skills\nin students, of ering innovative pedagogical approaches through the use of\nhumanoid robotics.\n","authors":["Moraes Pablo","Peters Christopher","Rodríguez Mónica","Sodre Hiago","Mazondo Ahilen","Sandin Vincent","Barcelona Sebastian","Moraes William","Fernández Santiago","Assunção Nathalie","de Vargas Bruna","Dörnbach Tobias","Kelbouscas André","Grando Ricardo"],"pdf_url":"https://arxiv.org/pdf/2410.17450v1.pdf","comment":"in Portuguese language"},{"id":"http://arxiv.org/abs/2410.17448v1","updated":"2024-10-22T21:50:52Z","published":"2024-10-22T21:50:52Z","title":"In Context Learning and Reasoning for Symbolic Regression with Large\n  Language Models","summary":"  Large Language Models (LLMs) are transformer-based machine learning models\nthat have shown remarkable performance in tasks for which they were not\nexplicitly trained. Here, we explore the potential of LLMs to perform symbolic\nregression -- a machine-learning method for finding simple and accurate\nequations from datasets. We prompt GPT-4 to suggest expressions from data,\nwhich are then optimized and evaluated using external Python tools. These\nresults are fed back to GPT-4, which proposes improved expressions while\noptimizing for complexity and loss. Using chain-of-thought prompting, we\ninstruct GPT-4 to analyze the data, prior expressions, and the scientific\ncontext (expressed in natural language) for each problem before generating new\nexpressions. We evaluated the workflow in rediscovery of five well-known\nscientific equations from experimental data, and on an additional dataset\nwithout a known equation. GPT-4 successfully rediscovered all five equations,\nand in general, performed better when prompted to use a scratchpad and consider\nscientific context. We also demonstrate how strategic prompting improves the\nmodel's performance and how the natural language interface simplifies\nintegrating theory with data. Although this approach does not outperform\nestablished SR programs where target equations are more complex, LLMs can\nnonetheless iterate toward improved solutions while following instructions and\nincorporating scientific context in natural language.\n","authors":["Samiha Sharlin","Tyler R. Josephson"],"pdf_url":"https://arxiv.org/pdf/2410.17448v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.17439v1","updated":"2024-10-22T21:30:58Z","published":"2024-10-22T21:30:58Z","title":"Evaluating AI-Generated Essays with GRE Analytical Writing Assessment","summary":"  The recent revolutionary advance in generative AI enables the generation of\nrealistic and coherent texts by large language models (LLMs). Despite many\nexisting evaluation metrics on the quality of the generated texts, there is\nstill a lack of rigorous assessment of how well LLMs perform in complex and\ndemanding writing assessments. This study examines essays generated by ten\nleading LLMs for the analytical writing assessment of the Graduate Record Exam\n(GRE). We assessed these essays using both human raters and the e-rater\nautomated scoring engine as used in the GRE scoring pipeline. Notably, the\ntop-performing GPT-4o received an average score of 4.67, falling between\n\"generally thoughtful, well-developed analysis of the issue and conveys meaning\nclearly\" and \"presents a competent analysis of the issue and conveys meaning\nwith acceptable clarity\" according to the GRE scoring guideline. We also\nevaluated the detection accuracy of these essays, with detectors trained on\nessays generated by the same and different LLMs.\n","authors":["Yang Zhong","Jiangang Hao","Michael Fauss","Chen Li","Yuan Wang"],"pdf_url":"https://arxiv.org/pdf/2410.17439v1.pdf","comment":"20 pages, 6 figures"},{"id":"http://arxiv.org/abs/2410.17423v1","updated":"2024-10-22T20:52:51Z","published":"2024-10-22T20:52:51Z","title":"Artificial Intelligence in Brazilian News: A Mixed-Methods Analysis","summary":"  The current surge in Artificial Intelligence (AI) interest, reflected in\nheightened media coverage since 2009, has sparked significant debate on AI's\nimplications for privacy, social justice, workers' rights, and democracy. The\nmedia plays a crucial role in shaping public perception and acceptance of AI\ntechnologies. However, research into how AI appears in media has primarily\nfocused on anglophone contexts, leaving a gap in understanding how AI is\nrepresented globally. This study addresses this gap by analyzing 3,560 news\narticles from Brazilian media published between July 1, 2023, and February 29,\n2024, from 13 popular online news outlets. Using Computational Grounded Theory\n(CGT), the study applies Latent Dirichlet Allocation (LDA), BERTopic, and\nNamed-Entity Recognition to investigate the main topics in AI coverage and the\nentities represented. The findings reveal that Brazilian news coverage of AI is\ndominated by topics related to applications in the workplace and product\nlaunches, with limited space for societal concerns, which mostly focus on\ndeepfakes and electoral integrity. The analysis also highlights a significant\npresence of industry-related entities, indicating a strong influence of\ncorporate agendas in the country's news. This study underscores the need for a\nmore critical and nuanced discussion of AI's societal impacts in Brazilian\nmedia.\n","authors":["Raphael Hernandes","Giulio Corsi"],"pdf_url":"https://arxiv.org/pdf/2410.17423v1.pdf","comment":"18 pages, 8 figures, 3 tables"},{"id":"http://arxiv.org/abs/2407.12843v2","updated":"2024-10-22T20:50:56Z","published":"2024-07-04T15:10:51Z","title":"NutriBench: A Dataset for Evaluating Large Language Models in\n  Carbohydrate Estimation from Meal Descriptions","summary":"  Accurate nutrition estimation helps people make informed dietary choices and\nis essential in the prevention of serious health complications. We present\nNutriBench, the first publicly available natural language meal description\nnutrition benchmark. NutriBench consists of 11,857 meal descriptions generated\nfrom real-world global dietary intake data. The data is human-verified and\nannotated with macro-nutrient labels, including carbohydrates, proteins, fats,\nand calories. We conduct an extensive evaluation of NutriBench on the task of\ncarbohydrate estimation, testing twelve leading Large Language Models (LLMs),\nincluding GPT-4o, Llama3.1, Qwen2, Gemma2, and OpenBioLLM models, using\nstandard, Chain-of-Thought and Retrieval-Augmented Generation strategies.\nAdditionally, we present a study involving professional nutritionists, finding\nthat LLMs can provide more accurate and faster estimates. Finally, we perform a\nreal-world risk assessment by simulating the effect of carbohydrate predictions\non the blood glucose levels of individuals with diabetes. Our work highlights\nthe opportunities and challenges of using LLMs for nutrition estimation,\ndemonstrating their potential to aid professionals and laypersons and improve\nhealth outcomes. Our benchmark is publicly available at:\nhttps://mehak126.github.io/nutribench.html\n","authors":["Andong Hua","Mehak Preet Dhaliwal","Ryan Burke","Yao Qin"],"pdf_url":"https://arxiv.org/pdf/2407.12843v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.17413v1","updated":"2024-10-22T20:39:21Z","published":"2024-10-22T20:39:21Z","title":"Scalable Influence and Fact Tracing for Large Language Model Pretraining","summary":"  Training data attribution (TDA) methods aim to attribute model outputs back\nto specific training examples, and the application of these methods to large\nlanguage model (LLM) outputs could significantly advance model transparency and\ndata curation. However, it has been challenging to date to apply these methods\nto the full scale of LLM pretraining. In this paper, we refine existing\ngradient-based methods to work effectively at scale, allowing us to retrieve\ninfluential examples for an 8B-parameter language model from a pretraining\ncorpus of over 160B tokens with no need for subsampling or pre-filtering. Our\nmethod combines several techniques, including optimizer state correction, a\ntask-specific Hessian approximation, and normalized encodings, which we find to\nbe critical for performance at scale. In quantitative evaluations on a fact\ntracing task, our method performs best at identifying examples that influence\nmodel predictions, but classical, model-agnostic retrieval methods such as BM25\nstill perform better at finding passages which explicitly contain relevant\nfacts. These results demonstrate a misalignment between factual attribution and\ncausal influence. With increasing model size and training tokens, we find that\ninfluence more closely aligns with attribution. Finally, we examine different\ntypes of examples identified as influential by our method, finding that while\nmany directly entail a particular fact, others support the same output by\nreinforcing priors on relation types, common entities, and names.\n","authors":["Tyler A. Chang","Dheeraj Rajagopal","Tolga Bolukbasi","Lucas Dixon","Ian Tenney"],"pdf_url":"https://arxiv.org/pdf/2410.17413v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.17401v1","updated":"2024-10-22T20:18:26Z","published":"2024-10-22T20:18:26Z","title":"AdvWeb: Controllable Black-box Attacks on VLM-powered Web Agents","summary":"  Vision Language Models (VLMs) have revolutionized the creation of generalist\nweb agents, empowering them to autonomously complete diverse tasks on\nreal-world websites, thereby boosting human efficiency and productivity.\nHowever, despite their remarkable capabilities, the safety and security of\nthese agents against malicious attacks remain critically underexplored, raising\nsignificant concerns about their safe deployment. To uncover and exploit such\nvulnerabilities in web agents, we provide AdvWeb, a novel black-box attack\nframework designed against web agents. AdvWeb trains an adversarial prompter\nmodel that generates and injects adversarial prompts into web pages, misleading\nweb agents into executing targeted adversarial actions such as inappropriate\nstock purchases or incorrect bank transactions, actions that could lead to\nsevere real-world consequences. With only black-box access to the web agent, we\ntrain and optimize the adversarial prompter model using DPO, leveraging both\nsuccessful and failed attack strings against the target agent. Unlike prior\napproaches, our adversarial string injection maintains stealth and control: (1)\nthe appearance of the website remains unchanged before and after the attack,\nmaking it nearly impossible for users to detect tampering, and (2) attackers\ncan modify specific substrings within the generated adversarial string to\nseamlessly change the attack objective (e.g., purchasing stocks from a\ndifferent company), enhancing attack flexibility and efficiency. We conduct\nextensive evaluations, demonstrating that AdvWeb achieves high success rates in\nattacking SOTA GPT-4V-based VLM agent across various web tasks. Our findings\nexpose critical vulnerabilities in current LLM/VLM-based agents, emphasizing\nthe urgent need for developing more reliable web agents and effective defenses.\nOur code and data are available at https://ai-secure.github.io/AdvWeb/ .\n","authors":["Chejian Xu","Mintong Kang","Jiawei Zhang","Zeyi Liao","Lingbo Mo","Mengqi Yuan","Huan Sun","Bo Li"],"pdf_url":"https://arxiv.org/pdf/2410.17401v1.pdf","comment":"15 pages"},{"id":"http://arxiv.org/abs/2405.06626v2","updated":"2024-10-22T20:05:32Z","published":"2024-05-10T17:40:02Z","title":"Characterizing the Accuracy -- Efficiency Trade-off of Low-rank\n  Decomposition in Language Models","summary":"  Recent large language models (LLMs) employ billions of parameters to enable\nbroad problem-solving capabilities. Such language models also tend to be\nmemory-bound because of the dominance of matrix-vector and matrix-matrix\nmultiplications with low arithmetic intensity. Therefore, optimizing the memory\nfootprint and traffic is an important optimization direction for LLMs today.\nModel compression methods such as quantization and parameter pruning have been\nactively explored to achieve memory footprint and traffic optimization.\nHowever, the accuracy-efficiency trade-off of rank pruning (i.e., low-rank\ndecomposition) for LLMs is not well-understood yet. Therefore, in this work, we\ncharacterize the accuracy-efficiency trade-off of a low-rank decomposition\nmethod, specifically Tucker decomposition, on recent language models, including\nan open-source LLM, Llama 2. We formalize the low-rank decomposition design\nspace and show that the decomposition design space is enormous (e.g.,\nO($2^{39}$) for Llama2-7B). To navigate such a vast design space, we formulate\nit and perform thorough case studies of accuracy-efficiency trade-offs using\nsix widely used LLM benchmarks on BERT and Llama 2 models. Our results show\nthat we can achieve a 9\\% model size reduction with minimal accuracy drops,\nwhich range from 4\\%p (\\%p refers to \"percentage point,\" which refers to the\nabsolute difference between two percentage numbers; 74\\% -> 78\\% = 4\\%p\nincrease) to 10\\%p, depending on the difficulty of the benchmark, without any\nretraining to recover accuracy after decomposition. The results show that\nlow-rank decomposition can be a promising direction for LLM-based applications\nthat require real-time service at scale (e.g., AI agent and real-time coding\nassistant), where the latency is as important as the model accuracy.\n","authors":["Chakshu Moar","Faraz Tahmasebi","Michael Pellauer","Hyoukjun Kwon"],"pdf_url":"https://arxiv.org/pdf/2405.06626v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2405.12856v4","updated":"2024-10-22T19:53:58Z","published":"2024-05-21T15:13:12Z","title":"LLM Processes: Numerical Predictive Distributions Conditioned on Natural\n  Language","summary":"  Machine learning practitioners often face significant challenges in formally\nintegrating their prior knowledge and beliefs into predictive models, limiting\nthe potential for nuanced and context-aware analyses. Moreover, the expertise\nneeded to integrate this prior knowledge into probabilistic modeling typically\nlimits the application of these models to specialists. Our goal is to build a\nregression model that can process numerical data and make probabilistic\npredictions at arbitrary locations, guided by natural language text which\ndescribes a user's prior knowledge. Large Language Models (LLMs) provide a\nuseful starting point for designing such a tool since they 1) provide an\ninterface where users can incorporate expert insights in natural language and\n2) provide an opportunity for leveraging latent problem-relevant knowledge\nencoded in LLMs that users may not have themselves. We start by exploring\nstrategies for eliciting explicit, coherent numerical predictive distributions\nfrom LLMs. We examine these joint predictive distributions, which we call LLM\nProcesses, over arbitrarily-many quantities in settings such as forecasting,\nmulti-dimensional regression, black-box optimization, and image modeling. We\ninvestigate the practical details of prompting to elicit coherent predictive\ndistributions, and demonstrate their effectiveness at regression. Finally, we\ndemonstrate the ability to usefully incorporate text into numerical\npredictions, improving predictive performance and giving quantitative structure\nthat reflects qualitative descriptions. This lets us begin to explore the rich,\ngrounded hypothesis space that LLMs implicitly encode.\n","authors":["James Requeima","John Bronskill","Dami Choi","Richard E. Turner","David Duvenaud"],"pdf_url":"https://arxiv.org/pdf/2405.12856v4.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.17385v1","updated":"2024-10-22T19:39:15Z","published":"2024-10-22T19:39:15Z","title":"Do Vision-Language Models Represent Space and How? Evaluating Spatial\n  Frame of Reference Under Ambiguities","summary":"  Spatial expressions in situated communication can be ambiguous, as their\nmeanings vary depending on the frames of reference (FoR) adopted by speakers\nand listeners. While spatial language understanding and reasoning by\nvision-language models (VLMs) have gained increasing attention, potential\nambiguities in these models are still under-explored. To address this issue, we\npresent the COnsistent Multilingual Frame Of Reference Test (COMFORT), an\nevaluation protocol to systematically assess the spatial reasoning capabilities\nof VLMs. We evaluate nine state-of-the-art VLMs using COMFORT. Despite showing\nsome alignment with English conventions in resolving ambiguities, our\nexperiments reveal significant shortcomings of VLMs: notably, the models (1)\nexhibit poor robustness and consistency, (2) lack the flexibility to\naccommodate multiple FoRs, and (3) fail to adhere to language-specific or\nculture-specific conventions in cross-lingual tests, as English tends to\ndominate other languages. With a growing effort to align vision-language models\nwith human cognitive intuitions, we call for more attention to the ambiguous\nnature and cross-cultural diversity of spatial reasoning.\n","authors":["Zheyuan Zhang","Fengyuan Hu","Jayjun Lee","Freda Shi","Parisa Kordjamshidi","Joyce Chai","Ziqiao Ma"],"pdf_url":"https://arxiv.org/pdf/2410.17385v1.pdf","comment":"Accepted to Pluralistic Alignment @ NeurIPS 2024 | Project page:\n  https://spatial-comfort.github.io/"},{"id":"http://arxiv.org/abs/2410.17375v1","updated":"2024-10-22T19:15:35Z","published":"2024-10-22T19:15:35Z","title":"AMUSD: Asynchronous Multi-Device Speculative Decoding for LLM\n  Acceleration","summary":"  Large language models typically generate tokens autoregressively, using each\ntoken as input for the next. Recent work on Speculative Decoding has sought to\naccelerate this process by employing a smaller, faster draft model to more\nquickly generate candidate tokens. These candidates are then verified in\nparallel by the larger (original) verify model, resulting in overall speedup\ncompared to using the larger model by itself in an autoregressive fashion. In\nthis work, we introduce AMUSD (Asynchronous Multi-device Speculative Decoding),\na system that further accelerates generation by decoupling the draft and verify\nphases into a continuous, asynchronous approach. Unlike conventional\nspeculative decoding, where only one model (draft or verify) performs token\ngeneration at a time, AMUSD enables both models to perform predictions\nindependently on separate devices (e.g., GPUs). We evaluate our approach over\nmultiple datasets and show that AMUSD achieves an average 29% improvement over\nspeculative decoding and up to 1.96$\\times$ speedup over conventional\nautoregressive decoding, while achieving identical output quality. Our system\nis open-source and available at https://github.com/BradMcDanel/AMUSD/.\n","authors":["Bradley McDanel"],"pdf_url":"https://arxiv.org/pdf/2410.17375v1.pdf","comment":"4 pages, 5 figures, 1 table, 1 algorithm"},{"id":"http://arxiv.org/abs/2405.11724v2","updated":"2024-10-22T19:07:08Z","published":"2024-05-20T01:57:34Z","title":"Token-wise Influential Training Data Retrieval for Large Language Models","summary":"  Given a Large Language Model (LLM) generation, how can we identify which\ntraining data led to this generation? In this paper, we proposed RapidIn, a\nscalable framework adapting to LLMs for estimating the influence of each\ntraining data. The proposed framework consists of two stages: caching and\nretrieval. First, we compress the gradient vectors by over 200,000x, allowing\nthem to be cached on disk or in GPU/CPU memory. Then, given a generation,\nRapidIn efficiently traverses the cached gradients to estimate the influence\nwithin minutes, achieving over a 6,326x speedup. Moreover, RapidIn supports\nmulti-GPU parallelization to substantially accelerate caching and retrieval.\nOur empirical result confirms the efficiency and effectiveness of RapidIn.\n","authors":["Huawei Lin","Jikai Long","Zhaozhuo Xu","Weijie Zhao"],"pdf_url":"https://arxiv.org/pdf/2405.11724v2.pdf","comment":"Accepted to ACL 2024. Keywords: Influence Function, Influence\n  Estimation, Training Data Attribution"},{"id":"http://arxiv.org/abs/2402.13459v2","updated":"2024-10-22T19:01:35Z","published":"2024-02-21T01:30:03Z","title":"Learning to Poison Large Language Models During Instruction Tuning","summary":"  The advent of Large Language Models (LLMs) has marked significant\nachievements in language processing and reasoning capabilities. Despite their\nadvancements, LLMs face vulnerabilities to data poisoning attacks, where\nadversaries insert backdoor triggers into training data to manipulate outputs\nfor malicious purposes. This work further identifies additional security risks\nin LLMs by designing a new data poisoning attack tailored to exploit the\ninstruction tuning process. We propose a novel gradient-guided backdoor trigger\nlearning (GBTL) algorithm to identify adversarial triggers efficiently,\nensuring an evasion of detection by conventional defenses while maintaining\ncontent integrity. Through experimental validation across various tasks,\nincluding sentiment analysis, domain generation, and question answering, our\npoisoning strategy demonstrates a high success rate in compromising various\nLLMs' outputs. We further propose two defense strategies against data poisoning\nattacks, including in-context learning (ICL) and continuous learning (CL),\nwhich effectively rectify the behavior of LLMs and significantly reduce the\ndecline in performance. Our work highlights the significant security risks\npresent during the instruction tuning of LLMs and emphasizes the necessity of\nsafeguarding LLMs against data poisoning attacks.\n","authors":["Yao Qiang","Xiangyu Zhou","Saleh Zare Zade","Mohammad Amin Roshani","Prashant Khanduri","Douglas Zytko","Dongxiao Zhu"],"pdf_url":"https://arxiv.org/pdf/2402.13459v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.15226v2","updated":"2024-10-22T18:54:23Z","published":"2024-10-19T22:14:07Z","title":"On the Diversity of Synthetic Data and its Impact on Training Large\n  Language Models","summary":"  The rise of Large Language Models (LLMs) has accentuated the need for\ndiverse, high-quality pre-training data. Synthetic data emerges as a viable\nsolution to the challenges of data scarcity and inaccessibility. While previous\nliterature has focused predominantly on the quality and quantity of real data,\nour work enables the measurement of diversity in synthetic data and explores\nits impact on LLM performance. We study the downstream effects of synthetic\ndata diversity during both the pre-training and fine-tuning stages by\nintroducing a new diversity metric, \\textit{LLM cluster-agent}, designed to\nevaluate the diversity of synthetic datasets. Through a series of controlled\nexperiments with models of 350M and 1.4B parameters, we demonstrate that the\nproposed cluster-based LLM scoring of diversity correlates positively with both\npre-training and supervised fine-tuning performance. Our findings also reveal\nthat synthetic data diversity in pre-training affects supervised fine-tuning\nmore significantly than pre-training itself, even for smaller models. We hope\nthis study advances our understanding of the optimal use of synthetic data in\nLLM training and opens new avenues for efficient data generation processes.\n","authors":["Hao Chen","Abdul Waheed","Xiang Li","Yidong Wang","Jindong Wang","Bhiksha Raj","Marah I. Abdin"],"pdf_url":"https://arxiv.org/pdf/2410.15226v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.17542v3","updated":"2024-10-22T18:51:01Z","published":"2024-06-25T13:29:14Z","title":"CDQuant: Greedy Coordinate Descent for Accurate LLM Quantization","summary":"  Large language models (LLMs) have recently demonstrated remarkable\nperformance across diverse language tasks. But their deployment is often\nconstrained by their substantial computational and storage requirements.\nQuantization has emerged as a key technique for addressing this challenge,\nenabling the compression of large models with minimal impact on performance.\nThe recent GPTQ algorithm, a post-training quantization (PTQ) method, has\nproven highly effective for compressing LLMs, sparking a wave of research that\nleverages GPTQ as a core component. Recognizing the pivotal role of GPTQ in the\nPTQ landscape, we introduce CDQuant, a simple and scalable alternative to GPTQ\nwith improved performance. CDQuant uses greedy coordinate descent to minimize\nthe layer-wise reconstruction loss to achieve high-quality quantized weights.\nOur algorithm is easy to implement and scales efficiently to models with\nhundreds of billions of parameters. We perform extensive evaluation on Gemma,\nand PaLM2 model families, and demonstrate that CDQuant consistently outperforms\nGPTQ in 2-4 bit weight quantization. Moreover, CDQuant improves the performance\nof state-of-the-art PTQ techniques such as QuIP and FrameQuant when used as a\nreplacement for their GPTQ component, resulting in further gains in quality.\n","authors":["Pranav Ajit Nair","Arun Sai Suggala"],"pdf_url":"https://arxiv.org/pdf/2406.17542v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.17355v1","updated":"2024-10-22T18:47:46Z","published":"2024-10-22T18:47:46Z","title":"All Entities are Not Created Equal: Examining the Long Tail for\n  Fine-Grained Entity Typing","summary":"  Pre-trained language models (PLMs) are trained on large amounts of data,\nwhich helps capture world knowledge alongside linguistic competence. Due to\nthis, they are extensively used for ultra-fine entity typing tasks, where they\nprovide the entity knowledge held in its parameter space. Given that PLMs learn\nfrom co-occurrence patterns, they likely contain more knowledge or less\nknowledge about entities depending on their how frequent they are in the\npre-training data. In this work, we probe PLMs to elicit encoded entity\nprobabilities and demonstrate that they highly correlate with their frequency\nin large-scale internet data. Then, we demonstrate that entity-typing\napproaches that rely on PLMs struggle with entities at the long tail on the\ndistribution. Our findings suggests that we need to go beyond PLMs to produce\nsolutions that perform well for rare, new or infrequent entities.\n","authors":["Advait Deshmukh","Ashwin Umadi","Dananjay Srinivas","Maria Leonor Pacheco"],"pdf_url":"https://arxiv.org/pdf/2410.17355v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2407.17678v5","updated":"2024-10-22T18:26:51Z","published":"2024-07-25T00:27:07Z","title":"S2-Attention: Hardware-Aware Context Sharding Among Attention Heads","summary":"  Sparse attention, which selectively attends to a subset of tokens in the\ncontext was supposed to be efficient. However, its theoretical reduction in\nFLOPs has rarely translated into wall-clock speed-up over its dense attention\ncounterparts due to the lack of hardware-aware optimizations like\nFlashAttention. Meanwhile, it remains unclear whether sparse attention can\nmaintain the model's quality at a scale of today's large language models (LLMs)\nand how. This paper presents Sparsely-Sharded(S2) Attention, a Triton library\nthat provides kernel optimization for sparse attention customizable at both\nper-head and per-context-range levels. S2-Attention enables the exploration of\nnovel and high-performance sparse attention techniques, which we demonstrate\nthrough extensive ablations across a wide range of sparse attention designs at\nvarious model scales. From these insights, we present several basic guidelines\nto design sparse attention that can achieve not only practical efficiency\nimprovements, but also strong downstream performance. To achieve high\nparallelization and optimized memory IO, sparse attention should shard the\ncontext heterogeneously across attention heads, where each head attends to a\ndifferent subset of tokens while collectively covering the full context.\nMeanwhile, we find hybrid architectures combining sparse and dense attention\nparticularly beneficial in practice. S2-Attention achieves wall-clock speedup\nof 8.79X, 15.87X, 25.3X compared to the strong FlashAttention-2 baseline with\nstrong downstream performance on-par with full attention and perfect retrieval\nperformance at a 128k context length. At inference, for 7B models, our model,\nwith the help of our S2-Attention kernel, achieves 4.5x speed-up compared to\ndense counterparts. S2-Attention is released with easy-to-customize APIs for\ndirect usage in Megatron and vLLM.\n","authors":["Xihui Lin","Yunan Zhang","Suyu Ge","Liliang Ren","Barun Patra","Vishrav Chaudhary","Hao Peng","Xia Song"],"pdf_url":"https://arxiv.org/pdf/2407.17678v5.pdf","comment":"10 pages"},{"id":"http://arxiv.org/abs/2410.02024v3","updated":"2024-10-22T18:22:11Z","published":"2024-10-02T20:45:51Z","title":"FLAG: Financial Long Document Classification via AMR-based GNN","summary":"  The advent of large language models (LLMs) has initiated much research into\ntheir various financial applications. However, in applying LLMs on long\ndocuments, semantic relations are not explicitly incorporated, and a full or\narbitrarily sparse attention operation is employed. In recent years, progress\nhas been made in Abstract Meaning Representation (AMR), which is a graph-based\nrepresentation of text to preserve its semantic relations. Since AMR can\nrepresent semantic relationships at a deeper level, it can be beneficially\nutilized by graph neural networks (GNNs) for constructing effective\ndocument-level graph representations built upon LLM embeddings to predict\ntarget metrics in the financial domain. We propose FLAG: Financial Long\ndocument classification via AMR-based GNN, an AMR graph based framework to\ngenerate document-level embeddings for long financial document classification.\nWe construct document-level graphs from sentence-level AMR graphs, endow them\nwith specialized LLM word embeddings in the financial domain, apply a deep\nlearning mechanism that utilizes a GNN, and examine the efficacy of our\nAMR-based approach in predicting labeled target data from long financial\ndocuments. Extensive experiments are conducted on a dataset of quarterly\nearnings calls transcripts of companies in various sectors of the economy, as\nwell as on a corpus of more recent earnings calls of companies in the S&P 1500\nComposite Index. We find that our AMR-based approach outperforms fine-tuning\nLLMs directly on text in predicting stock price movement trends at different\ntime horizons in both datasets. Our work also outperforms previous work\nutilizing document graphs and GNNs for text classification.\n","authors":["Bolun \"Namir\" Xia","Aparna Gupta","Mohammed J. Zaki"],"pdf_url":"https://arxiv.org/pdf/2410.02024v3.pdf","comment":"8 pages, 3 figures, to be published in CIFEr Conference 2024 as\n  \"Semantic Graph Learning for Trend Prediction from Long Financial Documents\""},{"id":"http://arxiv.org/abs/2410.17337v1","updated":"2024-10-22T18:11:43Z","published":"2024-10-22T18:11:43Z","title":"Captions Speak Louder than Images (CASLIE): Generalizing Foundation\n  Models for E-commerce from High-quality Multimodal Instruction Data","summary":"  Leveraging multimodal data to drive breakthroughs in e-commerce applications\nthrough Multimodal Foundation Models (MFMs) is gaining increasing attention\nfrom the research community. However, there are significant challenges that\nhinder the optimal use of multimodal e-commerce data by foundation models: (1)\nthe scarcity of large-scale, high-quality multimodal benchmark datasets; and\n(2) the lack of effective multimodal information integration methods. To\naddress these challenges, in this paper, we introduce MMECInstruct, the\nfirst-ever, large-scale, and high-quality multimodal instruction dataset for\ne-commerce. We also develop CASLIE, a simple, lightweight, yet effective\nframework for integrating multimodal information for e-commerce. Leveraging\nMMECInstruct, we fine-tune a series of e-commerce MFMs within CASLIE, denoted\nas CASLIE models. Our comprehensive evaluation demonstrates that CASLIE models\nsubstantially outperform 5 categories of advanced baseline models in the\nin-domain evaluation. Moreover, CASLIE models show strong generalizability to\nout-of-domain settings. MMECInstruct and CASLIE models are publicly accessible\nthrough https://ninglab.github.io/CASLIE/.\n","authors":["Xinyi Ling","Bo Peng","Hanwen Du","Zhihui Zhu","Xia Ning"],"pdf_url":"https://arxiv.org/pdf/2410.17337v1.pdf","comment":"Xinyi Ling and Bo Peng contributed equally to this paper"},{"id":"http://arxiv.org/abs/2410.17333v1","updated":"2024-10-22T18:08:25Z","published":"2024-10-22T18:08:25Z","title":"Are Large Language Models Ready for Travel Planning?","summary":"  While large language models (LLMs) show promise in hospitality and tourism,\ntheir ability to provide unbiased service across demographic groups remains\nunclear. This paper explores gender and ethnic biases when LLMs are utilized as\ntravel planning assistants. To investigate this issue, we apply machine\nlearning techniques to analyze travel suggestions generated from three\nopen-source LLMs. Our findings reveal that the performance of race and gender\nclassifiers substantially exceeds random chance, indicating differences in how\nLLMs engage with varied subgroups. Specifically, outputs align with cultural\nexpectations tied to certain races and genders. To minimize the effect of these\nstereotypes, we used a stop-word classification strategy, which decreased\nidentifiable differences, with no disrespectful terms found. However,\nhallucinations related to African American and gender minority groups were\nnoted. In conclusion, while LLMs can generate travel plans seemingly free from\nbias, it remains essential to verify the accuracy and appropriateness of their\nrecommendations.\n","authors":["Ruiping Ren","Xing Yao","Shu Cole","Haining Wang"],"pdf_url":"https://arxiv.org/pdf/2410.17333v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.17309v1","updated":"2024-10-22T18:00:00Z","published":"2024-10-22T18:00:00Z","title":"Literature Meets Data: A Synergistic Approach to Hypothesis Generation","summary":"  AI holds promise for transforming scientific processes, including hypothesis\ngeneration. Prior work on hypothesis generation can be broadly categorized into\ntheory-driven and data-driven approaches. While both have proven effective in\ngenerating novel and plausible hypotheses, it remains an open question whether\nthey can complement each other. To address this, we develop the first method\nthat combines literature-based insights with data to perform LLM-powered\nhypothesis generation. We apply our method on five different datasets and\ndemonstrate that integrating literature and data outperforms other baselines\n(8.97\\% over few-shot, 15.75\\% over literature-based alone, and 3.37\\% over\ndata-driven alone). Additionally, we conduct the first human evaluation to\nassess the utility of LLM-generated hypotheses in assisting human\ndecision-making on two challenging tasks: deception detection and AI generated\ncontent detection. Our results show that human accuracy improves significantly\nby 7.44\\% and 14.19\\% on these tasks, respectively. These findings suggest that\nintegrating literature-based and data-driven approaches provides a\ncomprehensive and nuanced framework for hypothesis generation and could open\nnew avenues for scientific inquiry.\n","authors":["Haokun Liu","Yangqiaoyu Zhou","Mingxuan Li","Chenfei Yuan","Chenhao Tan"],"pdf_url":"https://arxiv.org/pdf/2410.17309v1.pdf","comment":"30 pages, 7 figures, code link:\n  https://github.com/ChicagoHAI/hypothesis-generation"},{"id":"http://arxiv.org/abs/2311.18567v2","updated":"2024-10-22T17:21:21Z","published":"2023-11-30T13:58:13Z","title":"The Causal Influence of Grammatical Gender on Distributional Semantics","summary":"  How much meaning influences gender assignment across languages is an active\narea of research in linguistics and cognitive science. We can view current\napproaches as aiming to determine where gender assignment falls on a spectrum,\nfrom being fully arbitrarily determined to being largely semantically\ndetermined. For the latter case, there is a formulation of the neo-Whorfian\nhypothesis, which claims that even inanimate noun gender influences how people\nconceive of and talk about objects (using the choice of adjective used to\nmodify inanimate nouns as a proxy for meaning). We offer a novel, causal\ngraphical model that jointly represents the interactions between a noun's\ngrammatical gender, its meaning, and adjective choice. In accordance with past\nresults, we find a significant relationship between the gender of nouns and the\nadjectives that modify them. However, when we control for the meaning of the\nnoun, the relationship between grammatical gender and adjective choice is near\nzero and insignificant.\n","authors":["Karolina Stańczak","Kevin Du","Adina Williams","Isabelle Augenstein","Ryan Cotterell"],"pdf_url":"https://arxiv.org/pdf/2311.18567v2.pdf","comment":null}],"Computer Vision and Pattern Recognition":[{"id":"http://arxiv.org/abs/2410.16261v2","updated":"2024-10-22T08:09:52Z","published":"2024-10-21T17:58:20Z","title":"Mini-InternVL: A Flexible-Transfer Pocket Multimodal Model with 5%\n  Parameters and 90% Performance","summary":"  Multimodal large language models (MLLMs) have demonstrated impressive\nperformance in vision-language tasks across a broad spectrum of domains.\nHowever, the large model scale and associated high computational costs pose\nsignificant challenges for training and deploying MLLMs on consumer-grade GPUs\nor edge devices, thereby hindering their widespread application. In this work,\nwe introduce Mini-InternVL, a series of MLLMs with parameters ranging from 1B\nto 4B, which achieves 90% of the performance with only 5% of the parameters.\nThis significant improvement in efficiency and effectiveness makes our models\nmore accessible and applicable in various real-world scenarios. To further\npromote the adoption of our models, we develop a unified adaptation framework\nfor Mini-InternVL, which enables our models to transfer and outperform\nspecialized models in downstream tasks, including autonomous driving, medical\nimages, and remote sensing. We believe that our study can provide valuable\ninsights and resources to advance the development of efficient and effective\nMLLMs. Code is available at https://github.com/OpenGVLab/InternVL.\n","authors":["Zhangwei Gao","Zhe Chen","Erfei Cui","Yiming Ren","Weiyun Wang","Jinguo Zhu","Hao Tian","Shenglong Ye","Junjun He","Xizhou Zhu","Lewei Lu","Tong Lu","Yu Qiao","Jifeng Dai","Wenhai Wang"],"pdf_url":"https://arxiv.org/pdf/2410.16261v2.pdf","comment":"Technical report"},{"id":"http://arxiv.org/abs/2410.16152v2","updated":"2024-10-22T03:37:37Z","published":"2024-10-21T16:19:34Z","title":"Warped Diffusion: Solving Video Inverse Problems with Image Diffusion\n  Models","summary":"  Using image models naively for solving inverse video problems often suffers\nfrom flickering, texture-sticking, and temporal inconsistency in generated\nvideos. To tackle these problems, in this paper, we view frames as continuous\nfunctions in the 2D space, and videos as a sequence of continuous warping\ntransformations between different frames. This perspective allows us to train\nfunction space diffusion models only on images and utilize them to solve\ntemporally correlated inverse problems. The function space diffusion models\nneed to be equivariant with respect to the underlying spatial transformations.\nTo ensure temporal consistency, we introduce a simple post-hoc test-time\nguidance towards (self)-equivariant solutions. Our method allows us to deploy\nstate-of-the-art latent diffusion models such as Stable Diffusion XL to solve\nvideo inverse problems. We demonstrate the effectiveness of our method for\nvideo inpainting and $8\\times$ video super-resolution, outperforming existing\ntechniques based on noise transformations. We provide generated video results:\nhttps://giannisdaras.github.io/warped_diffusion.github.io/.\n","authors":["Giannis Daras","Weili Nie","Karsten Kreis","Alex Dimakis","Morteza Mardani","Nikola Borislavov Kovachki","Arash Vahdat"],"pdf_url":"https://arxiv.org/pdf/2410.16152v2.pdf","comment":"Accepted in NeurIPS 2024"},{"id":"http://arxiv.org/abs/2410.15980v2","updated":"2024-10-22T06:35:13Z","published":"2024-10-21T13:06:21Z","title":"Granularity Matters in Long-Tail Learning","summary":"  Balancing training on long-tail data distributions remains a long-standing\nchallenge in deep learning. While methods such as re-weighting and re-sampling\nhelp alleviate the imbalance issue, limited sample diversity continues to\nhinder models from learning robust and generalizable feature representations,\nparticularly for tail classes. In contrast to existing methods, we offer a\nnovel perspective on long-tail learning, inspired by an observation: datasets\nwith finer granularity tend to be less affected by data imbalance. In this\npaper, we investigate this phenomenon through both quantitative and qualitative\nstudies, showing that increased granularity enhances the generalization of\nlearned features in tail categories. Motivated by these findings, we propose a\nmethod to increase dataset granularity through category extrapolation.\nSpecifically, we introduce open-set auxiliary classes that are visually similar\nto existing ones, aiming to enhance representation learning for both head and\ntail classes. This forms the core contribution and insight of our approach. To\nautomate the curation of auxiliary data, we leverage large language models\n(LLMs) as knowledge bases to search for auxiliary categories and retrieve\nrelevant images through web crawling. To prevent the overwhelming presence of\nauxiliary classes from disrupting training, we introduce a neighbor-silencing\nloss that encourages the model to focus on class discrimination within the\ntarget dataset. During inference, the classifier weights for auxiliary\ncategories are masked out, leaving only the target class weights for use.\nExtensive experiments and ablation studies on three standard long-tail\nbenchmarks demonstrate the effectiveness of our approach, notably outperforming\nstrong baseline methods that use the same amount of data. The code will be made\npublicly available.\n","authors":["Shizhen Zhao","Xin Wen","Jiahui Liu","Chuofan Ma","Chunfeng Yuan","Xiaojuan Qi"],"pdf_url":"https://arxiv.org/pdf/2410.15980v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.15957v2","updated":"2024-10-22T06:26:45Z","published":"2024-10-21T12:36:27Z","title":"CamI2V: Camera-Controlled Image-to-Video Diffusion Model","summary":"  Recently, camera pose, as a user-friendly and physics-related condition, has\nbeen introduced into text-to-video diffusion model for camera control. However,\nexisting methods simply inject camera conditions through a side input. These\napproaches neglect the inherent physical knowledge of camera pose, resulting in\nimprecise camera control, inconsistencies, and also poor interpretability. In\nthis paper, we emphasize the necessity of integrating explicit physical\nconstraints into model design. Epipolar attention is proposed for modeling all\ncross-frame relationships from a novel perspective of noised condition. This\nensures that features are aggregated from corresponding epipolar lines in all\nnoised frames, overcoming the limitations of current attention mechanisms in\ntracking displaced features across frames, especially when features move\nsignificantly with the camera and become obscured by noise. Additionally, we\nintroduce register tokens to handle cases without intersections between frames,\ncommonly caused by rapid camera movements, dynamic objects, or occlusions. To\nsupport image-to-video, we propose the multiple guidance scale to allow for\nprecise control for image, text, and camera, respectively. Furthermore, we\nestablish a more robust and reproducible evaluation pipeline to solve the\ninaccuracy and instability of existing camera control measurement. We achieve a\n25.5% improvement in camera controllability on RealEstate10K while maintaining\nstrong generalization to out-of-domain images. Only 24GB and 12GB are required\nfor training and inference, respectively. We plan to release checkpoints, along\nwith training and evaluation codes. Dynamic videos are best viewed at\nhttps://zgctroy.github.io/CamI2V.\n","authors":["Guangcong Zheng","Teng Li","Rui Jiang","Yehao Lu","Tao Wu","Xi Li"],"pdf_url":"https://arxiv.org/pdf/2410.15957v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.15778v2","updated":"2024-10-22T05:01:28Z","published":"2024-10-21T08:42:30Z","title":"Reducing Hallucinations in Vision-Language Models via Latent Space\n  Steering","summary":"  Hallucination poses a challenge to the deployment of large vision-language\nmodels (LVLMs) in applications. Unlike in large language models (LLMs),\nhallucination in LVLMs often arises from misalignments between visual inputs\nand textual outputs. This paper investigates the underlying mechanisms of\nhallucination, focusing on the unique structure of LVLMs that distinguishes\nthem from large language models (LLMs). We identify that hallucinations often\narise from the sensitivity of text decoders to vision inputs, a natural\nphenomenon when image encoders and text decoders are pre-trained separately.\nInspired by this, we introduce Visual and Textual Intervention (VTI), a novel\ntechnique designed to reduce hallucinations by steering latent space\nrepresentations during inference to enhance the stability of vision features.\nAs a task-agnostic test-time intervention, VTI can be easily applied to any\nproblem without additional cost. Extensive experiments demonstrate that it can\neffectively reduce hallucinations and outperform baseline methods across\nmultiple metrics, highlighting the critical role of vision feature stability in\nLVLMs.\n","authors":["Sheng Liu","Haotian Ye","Lei Xing","James Zou"],"pdf_url":"https://arxiv.org/pdf/2410.15778v2.pdf","comment":"21 pages"},{"id":"http://arxiv.org/abs/2410.13621v4","updated":"2024-10-22T01:47:06Z","published":"2024-10-17T14:55:09Z","title":"EP-SAM: Weakly Supervised Histopathology Segmentation via Enhanced\n  Prompt with Segment Anything","summary":"  This work proposes a novel approach beyond supervised learning for effective\npathological image analysis, addressing the challenge of limited robust labeled\ndata. Pathological diagnosis of diseases like cancer has conventionally relied\non the evaluation of morphological features by physicians and pathologists.\nHowever, recent advancements in compute-aided diagnosis (CAD) systems are\ngaining significant attention as diagnostic support tools. Although the\nadvancement of deep learning has improved CAD significantly, segmentation\nmodels typically require large pixel-level annotated dataset, and such labeling\nis expensive. Existing studies not based on supervised approaches still\nstruggle with limited generalization, and no practical approach has emerged\nyet. To address this issue, we present a weakly supervised semantic\nsegmentation (WSSS) model by combining class activation map and Segment\nAnything Model (SAM)-based pseudo-labeling. For effective pretraining, we adopt\nthe SAM-a foundation model that is pretrained on large datasets and operates in\nzero-shot configurations using only coarse prompts. The proposed approach\ntransfer enhanced Attention Dropout Layer's knowledge to SAM, thereby\ngenerating pseudo-labels. To demonstrate the superiority of the proposed\nmethod, experimental studies are conducted on histopathological breast cancer\ndatasets. The proposed method outperformed other WSSS methods across three\ndatasets, demonstrating its efficiency by achieving this with only 12GB of GPU\nmemory during training. Our code is available at :\nhttps://github.com/QI-NemoSong/EP-SAM\n","authors":["Joonhyeon Song","Seohwan Yun","Seongho Yoon","Joohyeok Kim","Sangmin Lee"],"pdf_url":"https://arxiv.org/pdf/2410.13621v4.pdf","comment":"10 pages, 7 figures"},{"id":"http://arxiv.org/abs/2410.15636v2","updated":"2024-10-22T07:10:45Z","published":"2024-10-21T04:47:01Z","title":"LucidFusion: Generating 3D Gaussians with Arbitrary Unposed Images","summary":"  Recent large reconstruction models have made notable progress in generating\nhigh-quality 3D objects from single images. However, these methods often\nstruggle with controllability, as they lack information from multiple views,\nleading to incomplete or inconsistent 3D reconstructions. To address this\nlimitation, we introduce LucidFusion, a flexible end-to-end feed-forward\nframework that leverages the Relative Coordinate Map (RCM). Unlike traditional\nmethods linking images to 3D world thorough pose, LucidFusion utilizes RCM to\nalign geometric features coherently across different views, making it highly\nadaptable for 3D generation from arbitrary, unposed images. Furthermore,\nLucidFusion seamlessly integrates with the original single-image-to-3D\npipeline, producing detailed 3D Gaussians at a resolution of $512 \\times 512$,\nmaking it well-suited for a wide range of applications.\n","authors":["Hao He","Yixun Liang","Luozhou Wang","Yuanhao Cai","Xinli Xu","Hao-Xiang Guo","Xiang Wen","Yingcong Chen"],"pdf_url":"https://arxiv.org/pdf/2410.15636v2.pdf","comment":"17 pages, 12 figures, [project\n  page](https://heye0507.github.io/LucidFusion_page/)"},{"id":"http://arxiv.org/abs/2410.15629v2","updated":"2024-10-22T12:02:29Z","published":"2024-10-21T04:25:43Z","title":"Fully Explicit Dynamic Gaussian Splatting","summary":"  3D Gaussian Splatting has shown fast and high-quality rendering results in\nstatic scenes by leveraging dense 3D prior and explicit representations.\nUnfortunately, the benefits of the prior and representation do not involve\nnovel view synthesis for dynamic motions. Ironically, this is because the main\nbarrier is the reliance on them, which requires increasing training and\nrendering times to account for dynamic motions. In this paper, we design a\nExplicit 4D Gaussian Splatting(Ex4DGS). Our key idea is to firstly separate\nstatic and dynamic Gaussians during training, and to explicitly sample\npositions and rotations of the dynamic Gaussians at sparse timestamps. The\nsampled positions and rotations are then interpolated to represent both\nspatially and temporally continuous motions of objects in dynamic scenes as\nwell as reducing computational cost. Additionally, we introduce a progressive\ntraining scheme and a point-backtracking technique that improves Ex4DGS's\nconvergence. We initially train Ex4DGS using short timestamps and progressively\nextend timestamps, which makes it work well with a few point clouds. The\npoint-backtracking is used to quantify the cumulative error of each Gaussian\nover time, enabling the detection and removal of erroneous Gaussians in dynamic\nscenes. Comprehensive experiments on various scenes demonstrate the\nstate-of-the-art rendering quality from our method, achieving fast rendering of\n62 fps on a single 2080Ti GPU.\n","authors":["Junoh Lee","Chang-Yeon Won","Hyunjun Jung","Inhwan Bae","Hae-Gon Jeon"],"pdf_url":"https://arxiv.org/pdf/2410.15629v2.pdf","comment":"Accepted at NeurIPS 2024"},{"id":"http://arxiv.org/abs/2410.17251v1","updated":"2024-10-22T17:59:57Z","published":"2024-10-22T17:59:57Z","title":"Altogether: Image Captioning via Re-aligning Alt-text","summary":"  This paper focuses on creating synthetic data to improve the quality of image\ncaptions. Existing works typically have two shortcomings. First, they caption\nimages from scratch, ignoring existing alt-text metadata, and second, lack\ntransparency if the captioners' training data (e.g. GPT) is unknown. In this\npaper, we study a principled approach Altogether based on the key idea to edit\nand re-align existing alt-texts associated with the images. To generate\ntraining data, we perform human annotation where annotators start with the\nexisting alt-text and re-align it to the image content in multiple rounds,\nconsequently constructing captions with rich visual concepts. This differs from\nprior work that carries out human annotation as a one-time description task\nsolely based on images and annotator knowledge. We train a captioner on this\ndata that generalizes the process of re-aligning alt-texts at scale. Our\nresults show our Altogether approach leads to richer image captions that also\nimprove text-to-image generation and zero-shot image classification tasks.\n","authors":["Hu Xu","Po-Yao Huang","Xiaoqing Ellen Tan","Ching-Feng Yeh","Jacob Kahn","Christine Jou","Gargi Ghosh","Omer Levy","Luke Zettlemoyer","Wen-tau Yih","Shang-Wen Li","Saining Xie","Christoph Feichtenhofer"],"pdf_url":"https://arxiv.org/pdf/2410.17251v1.pdf","comment":"accepted by EMNLP 2024; MetaCLIPv2"},{"id":"http://arxiv.org/abs/2410.17249v1","updated":"2024-10-22T17:59:56Z","published":"2024-10-22T17:59:56Z","title":"SpectroMotion: Dynamic 3D Reconstruction of Specular Scenes","summary":"  We present SpectroMotion, a novel approach that combines 3D Gaussian\nSplatting (3DGS) with physically-based rendering (PBR) and deformation fields\nto reconstruct dynamic specular scenes. Previous methods extending 3DGS to\nmodel dynamic scenes have struggled to accurately represent specular surfaces.\nOur method addresses this limitation by introducing a residual correction\ntechnique for accurate surface normal computation during deformation,\ncomplemented by a deformable environment map that adapts to time-varying\nlighting conditions. We implement a coarse-to-fine training strategy that\nsignificantly enhances both scene geometry and specular color prediction. We\ndemonstrate that our model outperforms prior methods for view synthesis of\nscenes containing dynamic specular objects and that it is the only existing\n3DGS method capable of synthesizing photorealistic real-world dynamic specular\nscenes, outperforming state-of-the-art methods in rendering complex, dynamic,\nand specular scenes.\n","authors":["Cheng-De Fan","Chen-Wei Chang","Yi-Ruei Liu","Jie-Ying Lee","Jiun-Long Huang","Yu-Chee Tseng","Yu-Lun Liu"],"pdf_url":"https://arxiv.org/pdf/2410.17249v1.pdf","comment":"Project page: https://cdfan0627.github.io/spectromotion/"},{"id":"http://arxiv.org/abs/2410.17250v1","updated":"2024-10-22T17:59:56Z","published":"2024-10-22T17:59:56Z","title":"JMMMU: A Japanese Massive Multi-discipline Multimodal Understanding\n  Benchmark for Culture-aware Evaluation","summary":"  Accelerating research on Large Multimodal Models (LMMs) in non-English\nlanguages is crucial for enhancing user experiences across broader populations.\nIn this paper, we introduce JMMMU (Japanese MMMU), the first large-scale\nJapanese benchmark designed to evaluate LMMs on expert-level tasks based on the\nJapanese cultural context. To facilitate comprehensive culture-aware\nevaluation, JMMMU features two complementary subsets: (i) culture-agnostic (CA)\nsubset, where the culture-independent subjects (e.g., Math) are selected and\ntranslated into Japanese, enabling one-to-one comparison with its English\ncounterpart MMMU; and (ii) culture-specific (CS) subset, comprising newly\ncrafted subjects that reflect Japanese cultural context. Using the CA subset,\nwe observe performance drop in many LMMs when evaluated in Japanese, which is\npurely attributable to language variation. Using the CS subset, we reveal their\ninadequate Japanese cultural understanding. Further, by combining both subsets,\nwe identify that some LMMs perform well on the CA subset but not on the CS\nsubset, exposing a shallow understanding of the Japanese language that lacks\ndepth in cultural understanding. We hope this work will not only help advance\nLMM performance in Japanese but also serve as a guideline to create\nhigh-standard, culturally diverse benchmarks for multilingual LMM development.\nThe project page is https://mmmu-japanese-benchmark.github.io/JMMMU/.\n","authors":["Shota Onohara","Atsuyuki Miyai","Yuki Imajuku","Kazuki Egashira","Jeonghun Baek","Xiang Yue","Graham Neubig","Kiyoharu Aizawa"],"pdf_url":"https://arxiv.org/pdf/2410.17250v1.pdf","comment":"Project page: https://mmmu-japanese-benchmark.github.io/JMMMU/"},{"id":"http://arxiv.org/abs/2410.17247v1","updated":"2024-10-22T17:59:53Z","published":"2024-10-22T17:59:53Z","title":"PyramidDrop: Accelerating Your Large Vision-Language Models via Pyramid\n  Visual Redundancy Reduction","summary":"  In large vision-language models (LVLMs), images serve as inputs that carry a\nwealth of information. As the idiom \"A picture is worth a thousand words\"\nimplies, representing a single image in current LVLMs can require hundreds or\neven thousands of tokens. This results in significant computational costs,\nwhich grow quadratically as input image resolution increases, thereby severely\nimpacting the efficiency of both training and inference. Previous approaches\nhave attempted to reduce the number of image tokens either before or within the\nearly layers of LVLMs. However, these strategies inevitably result in the loss\nof crucial image information, ultimately diminishing model performance. To\naddress this challenge, we conduct an empirical study revealing that all visual\ntokens are necessary for LVLMs in the shallow layers, and token redundancy\nprogressively increases in the deeper layers of the model. To this end, we\npropose PyramidDrop, a visual redundancy reduction strategy for LVLMs to boost\ntheir efficiency in both training and inference with neglectable performance\nloss. Specifically, we partition the LVLM into several stages and drop part of\nthe image tokens at the end of each stage with a pre-defined ratio, creating\npyramid-like visual tokens across model layers. The dropping is based on a\nlightweight similarity calculation with a negligible time overhead. Extensive\nexperiments demonstrate that PyramidDrop can achieve a 40% training time and\n55% inference FLOPs acceleration of LLaVA-NeXT with comparable performance.\nBesides, the PyramidDrop could also serve as a plug-and-play strategy for\ninference acceleration without training, with better performance and lower\ninference cost than counterparts. We hope that the insights and approach\nintroduced by PyramidDrop will inspire future research to further investigate\nthe role of image tokens in LVLMs.\n","authors":["Long Xing","Qidong Huang","Xiaoyi Dong","Jiajie Lu","Pan Zhang","Yuhang Zang","Yuhang Cao","Conghui He","Jiaqi Wang","Feng Wu","Dahua Lin"],"pdf_url":"https://arxiv.org/pdf/2410.17247v1.pdf","comment":"10 pages"},{"id":"http://arxiv.org/abs/2410.17243v1","updated":"2024-10-22T17:59:30Z","published":"2024-10-22T17:59:30Z","title":"Breaking the Memory Barrier: Near Infinite Batch Size Scaling for\n  Contrastive Loss","summary":"  Contrastive loss is a powerful approach for representation learning, where\nlarger batch sizes enhance performance by providing more negative samples to\nbetter distinguish between similar and dissimilar data. However, scaling batch\nsizes is constrained by the quadratic growth in GPU memory consumption,\nprimarily due to the full instantiation of the similarity matrix. To address\nthis, we propose a tile-based computation strategy that partitions the\ncontrastive loss calculation into arbitrary small blocks, avoiding full\nmaterialization of the similarity matrix. Furthermore, we introduce a\nmulti-level tiling strategy to leverage the hierarchical structure of\ndistributed systems, employing ring-based communication at the GPU level to\noptimize synchronization and fused kernels at the CUDA core level to reduce I/O\noverhead. Experimental results show that the proposed method scales batch sizes\nto unprecedented levels. For instance, it enables contrastive training of a\nCLIP-ViT-L/14 model with a batch size of 4M or 12M using 8 or 32 A800 80GB\nwithout sacrificing any accuracy. Compared to SOTA memory-efficient solutions,\nit achieves a two-order-of-magnitude reduction in memory while maintaining\ncomparable speed. The code will be made publicly available.\n","authors":["Zesen Cheng","Hang Zhang","Kehan Li","Sicong Leng","Zhiqiang Hu","Fei Wu","Deli Zhao","Xin Li","Lidong Bing"],"pdf_url":"https://arxiv.org/pdf/2410.17243v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.17242v1","updated":"2024-10-22T17:58:28Z","published":"2024-10-22T17:58:28Z","title":"LVSM: A Large View Synthesis Model with Minimal 3D Inductive Bias","summary":"  We propose the Large View Synthesis Model (LVSM), a novel transformer-based\napproach for scalable and generalizable novel view synthesis from sparse-view\ninputs. We introduce two architectures: (1) an encoder-decoder LVSM, which\nencodes input image tokens into a fixed number of 1D latent tokens, functioning\nas a fully learned scene representation, and decodes novel-view images from\nthem; and (2) a decoder-only LVSM, which directly maps input images to\nnovel-view outputs, completely eliminating intermediate scene representations.\nBoth models bypass the 3D inductive biases used in previous methods -- from 3D\nrepresentations (e.g., NeRF, 3DGS) to network designs (e.g., epipolar\nprojections, plane sweeps) -- addressing novel view synthesis with a fully\ndata-driven approach. While the encoder-decoder model offers faster inference\ndue to its independent latent representation, the decoder-only LVSM achieves\nsuperior quality, scalability, and zero-shot generalization, outperforming\nprevious state-of-the-art methods by 1.5 to 3.5 dB PSNR. Comprehensive\nevaluations across multiple datasets demonstrate that both LVSM variants\nachieve state-of-the-art novel view synthesis quality. Notably, our models\nsurpass all previous methods even with reduced computational resources (1-2\nGPUs). Please see our website for more details:\nhttps://haian-jin.github.io/projects/LVSM/ .\n","authors":["Haian Jin","Hanwen Jiang","Hao Tan","Kai Zhang","Sai Bi","Tianyuan Zhang","Fujun Luan","Noah Snavely","Zexiang Xu"],"pdf_url":"https://arxiv.org/pdf/2410.17242v1.pdf","comment":"project page: https://haian-jin.github.io/projects/LVSM/"},{"id":"http://arxiv.org/abs/2410.17241v1","updated":"2024-10-22T17:57:12Z","published":"2024-10-22T17:57:12Z","title":"Frontiers in Intelligent Colonoscopy","summary":"  Colonoscopy is currently one of the most sensitive screening methods for\ncolorectal cancer. This study investigates the frontiers of intelligent\ncolonoscopy techniques and their prospective implications for multimodal\nmedical applications. With this goal, we begin by assessing the current\ndata-centric and model-centric landscapes through four tasks for colonoscopic\nscene perception, including classification, detection, segmentation, and\nvision-language understanding. This assessment enables us to identify\ndomain-specific challenges and reveals that multimodal research in colonoscopy\nremains open for further exploration. To embrace the coming multimodal era, we\nestablish three foundational initiatives: a large-scale multimodal instruction\ntuning dataset ColonINST, a colonoscopy-designed multimodal language model\nColonGPT, and a multimodal benchmark. To facilitate ongoing monitoring of this\nrapidly evolving field, we provide a public website for the latest updates:\nhttps://github.com/ai4colonoscopy/IntelliScope.\n","authors":["Ge-Peng Ji","Jingyi Liu","Peng Xu","Nick Barnes","Fahad Shahbaz Khan","Salman Khan","Deng-Ping Fan"],"pdf_url":"https://arxiv.org/pdf/2410.17241v1.pdf","comment":"[work in progress] A comprehensive survey of intelligent colonoscopy\n  in the multimodal era"},{"id":"http://arxiv.org/abs/2410.17235v1","updated":"2024-10-22T17:54:07Z","published":"2024-10-22T17:54:07Z","title":"Automated Spinal MRI Labelling from Reports Using a Large Language Model","summary":"  We propose a general pipeline to automate the extraction of labels from\nradiology reports using large language models, which we validate on spinal MRI\nreports. The efficacy of our labelling method is measured on five distinct\nconditions: spinal cancer, stenosis, spondylolisthesis, cauda equina\ncompression and herniation. Using open-source models, our method equals or\nsurpasses GPT-4 on a held-out set of reports. Furthermore, we show that the\nextracted labels can be used to train imaging models to classify the identified\nconditions in the accompanying MR scans. All classifiers trained using\nautomated labels achieve comparable performance to models trained using scans\nmanually annotated by clinicians. Code can be found at\nhttps://github.com/robinyjpark/AutoLabelClassifier.\n","authors":["Robin Y. Park","Rhydian Windsor","Amir Jamaludin","Andrew Zisserman"],"pdf_url":"https://arxiv.org/pdf/2410.17235v1.pdf","comment":"Accepted to Medical Image Computing and Computer Assisted\n  Intervention (MICCAI 2024, Spotlight). 11 pages plus appendix"},{"id":"http://arxiv.org/abs/2405.20090v3","updated":"2024-10-22T17:36:30Z","published":"2024-05-30T14:27:20Z","title":"Typography Leads Semantic Diversifying: Amplifying Adversarial\n  Transferability across Multimodal Large Language Models","summary":"  Recently, Multimodal Large Language Models (MLLMs) achieve remarkable\nperformance in numerous zero-shot tasks due to their outstanding cross-modal\ninteraction and comprehension abilities. However, MLLMs are found to still be\nvulnerable to human-imperceptible adversarial examples. In the exploration of\nsecurity vulnerabilities in real-world scenarios, transferability, which can\nachieve cross-model impact, is considered the greatest threat posed by\nadversarial examples. However, there is currently no systematic research on the\nthreat of cross-MLLMs adversarial transferability. Therefore, this paper as the\nfirst step to provide a comprehensive evaluation of the transferability of\nadversarial examples generated by various MLLMs. Furthermore, leveraging two\nkey factors that influence transferability performance: 1) The strength of\ninformation diversity involved in the adversarial generation process; 2)\nEditing across vision-language modality information. We propose a boosting\nmethod called Typography Augment Transferability Method (TATM) to investigate\nthe adversarial transferability performance across MLLMs further. Through\nextensive experimental validation, our TATM demonstrates exceptional\nperformance in real-world applications of \"Harmful Word Insertion\" and\n\"Important Information Protection\".\n","authors":["Hao Cheng","Erjia Xiao","Jiayan Yang","Jiahang Cao","Qiang Zhang","Le Yang","Jize Zhang","Kaidi Xu","Jindong Gu","Renjing Xu"],"pdf_url":"https://arxiv.org/pdf/2405.20090v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.17207v1","updated":"2024-10-22T17:27:16Z","published":"2024-10-22T17:27:16Z","title":"EPContrast: Effective Point-level Contrastive Learning for Large-scale\n  Point Cloud Understanding","summary":"  The acquisition of inductive bias through point-level contrastive learning\nholds paramount significance in point cloud pre-training. However, the square\ngrowth in computational requirements with the scale of the point cloud poses a\nsubstantial impediment to the practical deployment and execution. To address\nthis challenge, this paper proposes an Effective Point-level Contrastive\nLearning method for large-scale point cloud understanding dubbed\n\\textbf{EPContrast}, which consists of AGContrast and ChannelContrast. In\npractice, AGContrast constructs positive and negative pairs based on asymmetric\ngranularity embedding, while ChannelContrast imposes contrastive supervision\nbetween channel feature maps. EPContrast offers point-level contrastive loss\nwhile concurrently mitigating the computational resource burden. The efficacy\nof EPContrast is substantiated through comprehensive validation on S3DIS and\nScanNetV2, encompassing tasks such as semantic segmentation, instance\nsegmentation, and object detection. In addition, rich ablation experiments\ndemonstrate remarkable bias induction capabilities under label-efficient and\none-epoch training settings.\n","authors":["Zhiyi Pan","Guoqing Liu","Wei Gao","Thomas H. Li"],"pdf_url":"https://arxiv.org/pdf/2410.17207v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.17193v1","updated":"2024-10-22T17:13:19Z","published":"2024-10-22T17:13:19Z","title":"Emphasizing Discriminative Features for Dataset Distillation in Complex\n  Scenarios","summary":"  Dataset distillation has demonstrated strong performance on simple datasets\nlike CIFAR, MNIST, and TinyImageNet but struggles to achieve similar results in\nmore complex scenarios. In this paper, we propose EDF (emphasizes the\ndiscriminative features), a dataset distillation method that enhances key\ndiscriminative regions in synthetic images using Grad-CAM activation maps. Our\napproach is inspired by a key observation: in simple datasets, high-activation\nareas typically occupy most of the image, whereas in complex scenarios, the\nsize of these areas is much smaller. Unlike previous methods that treat all\npixels equally when synthesizing images, EDF uses Grad-CAM activation maps to\nenhance high-activation areas. From a supervision perspective, we downplay\nsupervision signals that have lower losses, as they contain common patterns.\nAdditionally, to help the DD community better explore complex scenarios, we\nbuild the Complex Dataset Distillation (Comp-DD) benchmark by meticulously\nselecting sixteen subsets, eight easy and eight hard, from ImageNet-1K. In\nparticular, EDF consistently outperforms SOTA results in complex scenarios,\nsuch as ImageNet-1K subsets. Hopefully, more researchers will be inspired and\nencouraged to improve the practicality and efficacy of DD. Our code and\nbenchmark will be made public at https://github.com/NUS-HPC-AI-Lab/EDF.\n","authors":["Kai Wang","Zekai Li","Zhi-Qi Cheng","Samir Khaki","Ahmad Sajedi","Ramakrishna Vedantam","Konstantinos N Plataniotis","Alexander Hauptmann","Yang You"],"pdf_url":"https://arxiv.org/pdf/2410.17193v1.pdf","comment":"24 pages, 13 figures"},{"id":"http://arxiv.org/abs/2408.11982v3","updated":"2024-10-22T16:58:09Z","published":"2024-08-21T20:32:45Z","title":"AIM 2024 Challenge on Compressed Video Quality Assessment: Methods and\n  Results","summary":"  Video quality assessment (VQA) is a crucial task in the development of video\ncompression standards, as it directly impacts the viewer experience. This paper\npresents the results of the Compressed Video Quality Assessment challenge, held\nin conjunction with the Advances in Image Manipulation (AIM) workshop at ECCV\n2024. The challenge aimed to evaluate the performance of VQA methods on a\ndiverse dataset of 459 videos, encoded with 14 codecs of various compression\nstandards (AVC/H.264, HEVC/H.265, AV1, and VVC/H.266) and containing a\ncomprehensive collection of compression artifacts. To measure the methods\nperformance, we employed traditional correlation coefficients between their\npredictions and subjective scores, which were collected via large-scale\ncrowdsourced pairwise human comparisons. For training purposes, participants\nwere provided with the Compressed Video Quality Assessment Dataset (CVQAD), a\npreviously developed dataset of 1022 videos. Up to 30 participating teams\nregistered for the challenge, while we report the results of 6 teams, which\nsubmitted valid final solutions and code for reproducing the results. Moreover,\nwe calculated and present the performance of state-of-the-art VQA methods on\nthe developed dataset, providing a comprehensive benchmark for future research.\nThe dataset, results, and online leaderboard are publicly available at\nhttps://challenges.videoprocessing.ai/challenges/compressedvideo-quality-assessment.html.\n","authors":["Maksim Smirnov","Aleksandr Gushchin","Anastasia Antsiferova","Dmitry Vatolin","Radu Timofte","Ziheng Jia","Zicheng Zhang","Wei Sun","Jiaying Qian","Yuqin Cao","Yinan Sun","Yuxin Zhu","Xiongkuo Min","Guangtao Zhai","Kanjar De","Qing Luo","Ao-Xiang Zhang","Peng Zhang","Haibo Lei","Linyan Jiang","Yaqing Li","Wenhui Meng","Zhenzhong Chen","Zhengxue Cheng","Jiahao Xiao","Jun Xu","Chenlong He","Qi Zheng","Ruoxi Zhu","Min Li","Yibo Fan","Zhengzhong Tu"],"pdf_url":"https://arxiv.org/pdf/2408.11982v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.17172v1","updated":"2024-10-22T16:50:34Z","published":"2024-10-22T16:50:34Z","title":"KANICE: Kolmogorov-Arnold Networks with Interactive Convolutional\n  Elements","summary":"  We introduce KANICE (Kolmogorov-Arnold Networks with Interactive\nConvolutional Elements), a novel neural architecture that combines\nConvolutional Neural Networks (CNNs) with Kolmogorov-Arnold Network (KAN)\nprinciples. KANICE integrates Interactive Convolutional Blocks (ICBs) and KAN\nlinear layers into a CNN framework. This leverages KANs' universal\napproximation capabilities and ICBs' adaptive feature learning. KANICE captures\ncomplex, non-linear data relationships while enabling dynamic,\ncontext-dependent feature extraction based on the Kolmogorov-Arnold\nrepresentation theorem. We evaluated KANICE on four datasets: MNIST,\nFashion-MNIST, EMNIST, and SVHN, comparing it against standard CNNs, CNN-KAN\nhybrids, and ICB variants. KANICE consistently outperformed baseline models,\nachieving 99.35% accuracy on MNIST and 90.05% on the SVHN dataset.\n  Furthermore, we introduce KANICE-mini, a compact variant designed for\nefficiency. A comprehensive ablation study demonstrates that KANICE-mini\nachieves comparable performance to KANICE with significantly fewer parameters.\nKANICE-mini reached 90.00% accuracy on SVHN with 2,337,828 parameters, compared\nto KANICE's 25,432,000. This study highlights the potential of KAN-based\narchitectures in balancing performance and computational efficiency in image\nclassification tasks. Our work contributes to research in adaptive neural\nnetworks, integrates mathematical theorems into deep learning architectures,\nand explores the trade-offs between model complexity and performance, advancing\ncomputer vision and pattern recognition. The source code for this paper is\npublicly accessible through our GitHub repository\n(https://github.com/m-ferdaus/kanice).\n","authors":["Md Meftahul Ferdaus","Mahdi Abdelguerfi","Elias Ioup","David Dobson","Kendall N. Niles","Ken Pathak","Steven Sloan"],"pdf_url":"https://arxiv.org/pdf/2410.17172v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.17149v1","updated":"2024-10-22T16:28:21Z","published":"2024-10-22T16:28:21Z","title":"Are Visual-Language Models Effective in Action Recognition? A\n  Comparative Study","summary":"  Current vision-language foundation models, such as CLIP, have recently shown\nsignificant improvement in performance across various downstream tasks.\nHowever, whether such foundation models significantly improve more complex\nfine-grained action recognition tasks is still an open question. To answer this\nquestion and better find out the future research direction on human behavior\nanalysis in-the-wild, this paper provides a large-scale study and insight on\ncurrent state-of-the-art vision foundation models by comparing their transfer\nability onto zero-shot and frame-wise action recognition tasks. Extensive\nexperiments are conducted on recent fine-grained, human-centric action\nrecognition datasets (e.g., Toyota Smarthome, Penn Action, UAV-Human, TSU,\nCharades) including action classification and segmentation.\n","authors":["Mahmoud Ali","Di Yang","François Brémond"],"pdf_url":"https://arxiv.org/pdf/2410.17149v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.17146v1","updated":"2024-10-22T16:26:05Z","published":"2024-10-22T16:26:05Z","title":"LiNeS: Post-training Layer Scaling Prevents Forgetting and Enhances\n  Model Merging","summary":"  Large pre-trained models exhibit impressive zero-shot performance across\ndiverse tasks, but fine-tuning often leads to catastrophic forgetting, where\nimprovements on a target domain degrade generalization on other tasks. To\naddress this challenge, we introduce LiNeS, Layer-increasing Network Scaling, a\npost-training editing technique designed to preserve pre-trained generalization\nwhile enhancing fine-tuned task performance. LiNeS scales parameter updates\nlinearly based on their layer depth within the network, maintaining shallow\nlayers close to their pre-trained values to preserve general features while\nallowing deeper layers to retain task-specific representations. We further\nextend this approach to multi-task model merging scenarios, where layer-wise\nscaling of merged parameters reduces negative task interference. LiNeS\ndemonstrates significant improvements in both single-task and multi-task\nsettings across various benchmarks in vision and natural language processing.\nIt mitigates forgetting, enhances out-of-distribution generalization,\nintegrates seamlessly with existing multi-task model merging baselines\nimproving their performance across benchmarks and model sizes, and can boost\ngeneralization when merging LLM policies aligned with different rewards via\nRLHF. Importantly, our method is simple to implement and complementary to many\nexisting techniques.\n","authors":["Ke Wang","Nikolaos Dimitriadis","Alessandro Favero","Guillermo Ortiz-Jimenez","Francois Fleuret","Pascal Frossard"],"pdf_url":"https://arxiv.org/pdf/2410.17146v1.pdf","comment":"The first two authors contributed equally to this work; Project\n  website: \\url{https://lines-merging.github.io/}"},{"id":"http://arxiv.org/abs/2410.17144v1","updated":"2024-10-22T16:19:55Z","published":"2024-10-22T16:19:55Z","title":"YOLO-TS: Real-Time Traffic Sign Detection with Enhanced Accuracy Using\n  Optimized Receptive Fields and Anchor-Free Fusion","summary":"  Ensuring safety in both autonomous driving and advanced driver-assistance\nsystems (ADAS) depends critically on the efficient deployment of traffic sign\nrecognition technology. While current methods show effectiveness, they often\ncompromise between speed and accuracy. To address this issue, we present a\nnovel real-time and efficient road sign detection network, YOLO-TS. This\nnetwork significantly improves performance by optimizing the receptive fields\nof multi-scale feature maps to align more closely with the size distribution of\ntraffic signs in various datasets. Moreover, our innovative feature-fusion\nstrategy, leveraging the flexibility of Anchor-Free methods, allows for\nmulti-scale object detection on a high-resolution feature map abundant in\ncontextual information, achieving remarkable enhancements in both accuracy and\nspeed. To mitigate the adverse effects of the grid pattern caused by dilated\nconvolutions on the detection of smaller objects, we have devised a unique\nmodule that not only mitigates this grid effect but also widens the receptive\nfield to encompass an extensive range of spatial contextual information, thus\nboosting the efficiency of information usage. Evaluation on challenging public\ndatasets, TT100K and CCTSDB2021, demonstrates that YOLO-TS surpasses existing\nstate-of-the-art methods in terms of both accuracy and speed. The code for our\nmethod will be available.\n","authors":["Junzhou Chen","Heqiang Huang","Ronghui Zhang","Nengchao Lyu","Yanyong Guo","Hong-Ning Dai","Hong Yan"],"pdf_url":"https://arxiv.org/pdf/2410.17144v1.pdf","comment":"13 pages, 9 figures and 7 tables"},{"id":"http://arxiv.org/abs/2409.12961v2","updated":"2024-10-22T16:17:13Z","published":"2024-09-19T17:59:51Z","title":"Oryx MLLM: On-Demand Spatial-Temporal Understanding at Arbitrary\n  Resolution","summary":"  Visual data comes in various forms, ranging from small icons of just a few\npixels to long videos spanning hours. Existing multi-modal LLMs usually\nstandardize these diverse visual inputs to a fixed resolution for visual\nencoders and yield similar numbers of tokens for LLMs. This approach is\nnon-optimal for multimodal understanding and inefficient for processing inputs\nwith long and short visual contents. To solve the problem, we propose Oryx, a\nunified multimodal architecture for the spatial-temporal understanding of\nimages, videos, and multi-view 3D scenes. Oryx offers an on-demand solution to\nseamlessly and efficiently process visual inputs with arbitrary spatial sizes\nand temporal lengths through two core innovations: 1) a pre-trained OryxViT\nmodel that can encode images at any resolution into LLM-friendly visual\nrepresentations; 2) a dynamic compressor module that supports 1x to 16x\ncompression on visual tokens by request. These design features enable Oryx to\naccommodate extremely long visual contexts, such as videos, with lower\nresolution and high compression while maintaining high recognition precision\nfor tasks like document understanding with native resolution and no\ncompression. Beyond the architectural improvements, enhanced data curation and\nspecialized training on long-context retrieval and spatial-aware data help Oryx\nachieve strong capabilities in image, video, and 3D multimodal understanding\nsimultaneously. Our work is open-sourced at https://github.com/Oryx-mllm/Oryx.\n","authors":["Zuyan Liu","Yuhao Dong","Ziwei Liu","Winston Hu","Jiwen Lu","Yongming Rao"],"pdf_url":"https://arxiv.org/pdf/2409.12961v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.17136v1","updated":"2024-10-22T16:08:09Z","published":"2024-10-22T16:08:09Z","title":"AlphaChimp: Tracking and Behavior Recognition of Chimpanzees","summary":"  Understanding non-human primate behavior is crucial for improving animal\nwelfare, modeling social behavior, and gaining insights into both distinctly\nhuman and shared behaviors. Despite recent advances in computer vision,\nautomated analysis of primate behavior remains challenging due to the\ncomplexity of their social interactions and the lack of specialized algorithms.\nExisting methods often struggle with the nuanced behaviors and frequent\nocclusions characteristic of primate social dynamics. This study aims to\ndevelop an effective method for automated detection, tracking, and recognition\nof chimpanzee behaviors in video footage. Here we show that our proposed\nmethod, AlphaChimp, an end-to-end approach that simultaneously detects\nchimpanzee positions and estimates behavior categories from videos,\nsignificantly outperforms existing methods in behavior recognition. AlphaChimp\nachieves approximately 10% higher tracking accuracy and a 20% improvement in\nbehavior recognition compared to state-of-the-art methods, particularly\nexcelling in the recognition of social behaviors. This superior performance\nstems from AlphaChimp's innovative architecture, which integrates temporal\nfeature fusion with a Transformer-based self-attention mechanism, enabling more\neffective capture and interpretation of complex social interactions among\nchimpanzees. Our approach bridges the gap between computer vision and\nprimatology, enhancing technical capabilities and deepening our understanding\nof primate communication and sociality. We release our code and models and hope\nthis will facilitate future research in animal social dynamics. This work\ncontributes to ethology, cognitive science, and artificial intelligence,\noffering new perspectives on social intelligence.\n","authors":["Xiaoxuan Ma","Yutang Lin","Yuan Xu","Stephan P. Kaufhold","Jack Terwilliger","Andres Meza","Yixin Zhu","Federico Rossano","Yizhou Wang"],"pdf_url":"https://arxiv.org/pdf/2410.17136v1.pdf","comment":"An eXpressive extension of ChimpACT [arXiv:2310.16447], proposes\n  AlphaChimp for tracking and behavior recognition of chimpanzees. arXiv admin\n  note: substantial text overlap with arXiv:2310.16447"},{"id":"http://arxiv.org/abs/2410.14669v2","updated":"2024-10-22T16:07:22Z","published":"2024-10-18T17:58:21Z","title":"NaturalBench: Evaluating Vision-Language Models on Natural Adversarial\n  Samples","summary":"  Vision-language models (VLMs) have made significant progress in recent\nvisual-question-answering (VQA) benchmarks that evaluate complex\nvisio-linguistic reasoning. However, are these models truly effective? In this\nwork, we show that VLMs still struggle with natural images and questions that\nhumans can easily answer, which we term natural adversarial samples. We also\nfind it surprisingly easy to generate these VQA samples from natural image-text\ncorpora using off-the-shelf models like CLIP and ChatGPT. We propose a\nsemi-automated approach to collect a new benchmark, NaturalBench, for reliably\nevaluating VLMs with 10,000 human-verified VQA samples. Crucially, we adopt a\n$\\textbf{vision-centric}$ design by pairing each question with two images that\nyield different answers, preventing blind solutions from answering without\nusing the images. This makes NaturalBench more challenging than previous\nbenchmarks that can be solved with commonsense priors. We evaluate 53\nstate-of-the-art VLMs on NaturalBench, showing that models like\nLLaVA-OneVision, Cambrian-1, Llama3.2-Vision, Molmo, Qwen2-VL, and even GPT-4o\nlag 50%-70% behind human performance (over 90%). We analyze why NaturalBench is\nhard from two angles: (1) Compositionality: Solving NaturalBench requires\ndiverse visio-linguistic skills, including understanding attribute bindings,\nobject relationships, and advanced reasoning like logic and counting. To this\nend, unlike prior work that uses a single tag per sample, we tag each\nNaturalBench sample with 1 to 8 skill tags for fine-grained evaluation. (2)\nBiases: NaturalBench exposes severe biases in VLMs, as models often choose the\nsame answer regardless of the image. Lastly, we apply our benchmark curation\nmethod to diverse data sources, including long captions (over 100 words) and\nnon-English languages like Chinese and Hindi, highlighting its potential for\ndynamic evaluations of VLMs.\n","authors":["Baiqi Li","Zhiqiu Lin","Wenxuan Peng","Jean de Dieu Nyandwi","Daniel Jiang","Zixian Ma","Simran Khanuja","Ranjay Krishna","Graham Neubig","Deva Ramanan"],"pdf_url":"https://arxiv.org/pdf/2410.14669v2.pdf","comment":"Accepted to NeurIPS 24; We open-source our dataset at:\n  https://huggingface.co/datasets/BaiqiL/NaturalBench ; Project page at:\n  https://linzhiqiu.github.io/papers/naturalbench/"},{"id":"http://arxiv.org/abs/2410.17101v1","updated":"2024-10-22T15:28:18Z","published":"2024-10-22T15:28:18Z","title":"CLAP: Concave Linear APproximation for Quadratic Graph Matching","summary":"  Solving point-wise feature correspondence in visual data is a fundamental\nproblem in computer vision. A powerful model that addresses this challenge is\nto formulate it as graph matching, which entails solving a Quadratic Assignment\nProblem (QAP) with node-wise and edge-wise constraints. However, solving such a\nQAP can be both expensive and difficult due to numerous local extreme points.\nIn this work, we introduce a novel linear model and solver designed to\naccelerate the computation of graph matching. Specifically, we employ a\npositive semi-definite matrix approximation to establish the structural\nattribute constraint.We then transform the original QAP into a linear model\nthat is concave for maximization. This model can subsequently be solved using\nthe Sinkhorn optimal transport algorithm, known for its enhanced efficiency and\nnumerical stability compared to existing approaches. Experimental results on\nthe widely used benchmark PascalVOC showcase that our algorithm achieves\nstate-of-the-art performance with significantly improved efficiency. Source\ncode: https://github.com/xmlyqing00/clap\n","authors":["Yongqing Liang","Huijun Han","Xin Li"],"pdf_url":"https://arxiv.org/pdf/2410.17101v1.pdf","comment":"Accepted as an oral paper in International Symposium on Visual\n  Computing (ISCV2024)"},{"id":"http://arxiv.org/abs/2410.17098v1","updated":"2024-10-22T15:22:53Z","published":"2024-10-22T15:22:53Z","title":"Masked Differential Privacy","summary":"  Privacy-preserving computer vision is an important emerging problem in\nmachine learning and artificial intelligence. The prevalent methods tackling\nthis problem use differential privacy or anonymization and obfuscation\ntechniques to protect the privacy of individuals. In both cases, the utility of\nthe trained model is sacrificed heavily in this process. In this work, we\npropose an effective approach called masked differential privacy (MaskDP),\nwhich allows for controlling sensitive regions where differential privacy is\napplied, in contrast to applying DP on the entire input. Our method operates\nselectively on the data and allows for defining non-sensitive spatio-temporal\nregions without DP application or combining differential privacy with other\nprivacy techniques within data samples. Experiments on four challenging action\nrecognition datasets demonstrate that our proposed techniques result in better\nutility-privacy trade-offs compared to standard differentially private training\nin the especially demanding $\\epsilon<1$ regime.\n","authors":["David Schneider","Sina Sajadmanesh","Vikash Sehwag","Saquib Sarfraz","Rainer Stiefelhagen","Lingjuan Lyu","Vivek Sharma"],"pdf_url":"https://arxiv.org/pdf/2410.17098v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.17082v1","updated":"2024-10-22T15:07:07Z","published":"2024-10-22T15:07:07Z","title":"A Survey on Deep Learning-based Gaze Direction Regression: Searching for\n  the State-of-the-art","summary":"  In this paper, we present a survey of deep learning-based methods for the\nregression of gaze direction vector from head and eye images. We describe in\ndetail numerous published methods with a focus on the input data, architecture\nof the model, and loss function used to supervise the model. Additionally, we\npresent a list of datasets that can be used to train and evaluate gaze\ndirection regression methods. Furthermore, we noticed that the results reported\nin the literature are often not comparable one to another due to differences in\nthe validation or even test subsets used. To address this problem, we\nre-evaluated several methods on the commonly used in-the-wild Gaze360 dataset\nusing the same validation setup. The experimental results show that the latest\nmethods, although claiming state-of-the-art results, significantly underperform\ncompared with some older methods. Finally, we show that the temporal models\noutperform the static models under static test conditions.\n","authors":["Franko Šikić","Donik Vršnak","Sven Lončarić"],"pdf_url":"https://arxiv.org/pdf/2410.17082v1.pdf","comment":"Accepted on SPRA 2024 (Istanbul, Turkey)"},{"id":"http://arxiv.org/abs/2407.05180v2","updated":"2024-10-22T14:54:42Z","published":"2024-04-22T10:33:06Z","title":"ReCAP: Recursive Cross Attention Network for Pseudo-Label Generation in\n  Robotic Surgical Skill Assessment","summary":"  In surgical skill assessment, Objective Structured Assessments of Technical\nSkills (OSATS scores) and the Global Rating Scale (GRS) are established tools\nfor evaluating the performance of surgeons during training. These metrics,\ncoupled with feedback on their performance, enable surgeons to improve and\nachieve standards of practice. Recent studies on the open-source dataset\nJIGSAW, which contains both GRS and OSATS labels, have focused on regressing\nGRS scores from kinematic signals, video data, or a combination of both. In\nthis paper, we argue that regressing the GRS score, a unitless value, by itself\nis too restrictive, and variations throughout the surgical trial do not hold\nsignificant clinical meaning. To address this gap, we developed a recurrent\ntransformer model that outputs the surgeon's performance throughout their\ntraining session by relating the model's hidden states to five OSATS scores\nderived from kinematic signals. These scores are averaged and aggregated to\nproduce a GRS prediction, enabling assessment of the model's performance\nagainst the state-of-the-art (SOTA). We report Spearman's Correlation\nCoefficient (SCC), demonstrating that our model outperforms SOTA models for all\ntasks, except for Suturing under the leave-one-subject-out (LOSO) scheme (SCC\n0.68-0.89), while achieving comparable performance for suturing and across\ntasks under the leave-one-user-out (LOUO) scheme (SCC 0.45-0.68) and beating\nSOTA for Needle Passing (0.69). We argue that relating final OSATS scores to\nshort instances throughout a surgeon's procedure is more clinically meaningful\nthan a single GRS score. This approach also allows us to translate quantitative\npredictions into qualitative feedback, which is crucial for any automated\nsurgical skill assessment pipeline. A senior surgeon validated our model's\nbehaviour and agreed with the semi-supervised predictions 77 \\% (p = 0.006) of\nthe time.\n","authors":["Julien Quarez","Matthew Elliot","Oscar Maccormac","Marc Modat","Sebastien Ourselin","Jonathan Shapey","Alejandro Granados"],"pdf_url":"https://arxiv.org/pdf/2407.05180v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.17066v1","updated":"2024-10-22T14:46:20Z","published":"2024-10-22T14:46:20Z","title":"Neuronal Competition Groups with Supervised STDP for Spike-Based\n  Classification","summary":"  Spike Timing-Dependent Plasticity (STDP) is a promising substitute to\nbackpropagation for local training of Spiking Neural Networks (SNNs) on\nneuromorphic hardware. STDP allows SNNs to address classification tasks by\ncombining unsupervised STDP for feature extraction and supervised STDP for\nclassification. Unsupervised STDP is usually employed with Winner-Takes-All\n(WTA) competition to learn distinct patterns. However, WTA for supervised STDP\nclassification faces unbalanced competition challenges. In this paper, we\npropose a method to effectively implement WTA competition in a spiking\nclassification layer employing first-spike coding and supervised STDP training.\nWe introduce the Neuronal Competition Group (NCG), an architecture that\nimproves classification capabilities by promoting the learning of various\npatterns per class. An NCG is a group of neurons mapped to a specific class,\nimplementing intra-class WTA and a novel competition regulation mechanism based\non two-compartment thresholds. We incorporate our proposed architecture into\nspiking classification layers trained with state-of-the-art supervised STDP\nrules. On top of two different unsupervised feature extractors, we obtain\nsignificant accuracy improvements on image recognition datasets such as\nCIFAR-10 and CIFAR-100. We show that our competition regulation mechanism is\ncrucial for ensuring balanced competition and improved class separation.\n","authors":["Gaspard Goupy","Pierre Tirilly","Ioan Marius Bilasco"],"pdf_url":"https://arxiv.org/pdf/2410.17066v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.17064v1","updated":"2024-10-22T14:44:47Z","published":"2024-10-22T14:44:47Z","title":"Multi Kernel Estimation based Object Segmentation","summary":"  This paper presents a novel approach for multi-kernel estimation by enhancing\nthe KernelGAN algorithm, which traditionally estimates a single kernel for the\nentire image. We introduce Multi-KernelGAN, which extends KernelGAN's\ncapabilities by estimating two distinct kernels based on object segmentation\nmasks. Our approach is validated through three distinct methods: texture-based\npatch Fast Fourier Transform (FFT) calculation, detail-based segmentation, and\ndeep learning-based object segmentation using YOLOv8 and the Segment Anything\nModel (SAM). Among these methods, the combination of YOLO and SAM yields the\nbest results for kernel estimation. Experimental results demonstrate that our\nmulti-kernel estimation technique outperforms conventional single-kernel\nmethods in super-resolution tasks.\n","authors":["Haim Goldfisher","Asaf Yekutiel"],"pdf_url":"https://arxiv.org/pdf/2410.17064v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2405.13675v4","updated":"2024-10-22T14:28:56Z","published":"2024-05-22T14:16:30Z","title":"Context and Geometry Aware Voxel Transformer for Semantic Scene\n  Completion","summary":"  Vision-based Semantic Scene Completion (SSC) has gained much attention due to\nits widespread applications in various 3D perception tasks. Existing\nsparse-to-dense approaches typically employ shared context-independent queries\nacross various input images, which fails to capture distinctions among them as\nthe focal regions of different inputs vary and may result in undirected feature\naggregation of cross-attention. Additionally, the absence of depth information\nmay lead to points projected onto the image plane sharing the same 2D position\nor similar sampling points in the feature map, resulting in depth ambiguity. In\nthis paper, we present a novel context and geometry aware voxel transformer. It\nutilizes a context aware query generator to initialize context-dependent\nqueries tailored to individual input images, effectively capturing their unique\ncharacteristics and aggregating information within the region of interest.\nFurthermore, it extend deformable cross-attention from 2D to 3D pixel space,\nenabling the differentiation of points with similar image coordinates based on\ntheir depth coordinates. Building upon this module, we introduce a neural\nnetwork named CGFormer to achieve semantic scene completion. Simultaneously,\nCGFormer leverages multiple 3D representations (i.e., voxel and TPV) to boost\nthe semantic and geometric representation abilities of the transformed 3D\nvolume from both local and global perspectives. Experimental results\ndemonstrate that CGFormer achieves state-of-the-art performance on the\nSemanticKITTI and SSCBench-KITTI-360 benchmarks, attaining a mIoU of 16.87 and\n20.05, as well as an IoU of 45.99 and 48.07, respectively. Remarkably, CGFormer\neven outperforms approaches employing temporal images as inputs or much larger\nimage backbone networks.\n","authors":["Zhu Yu","Runmin Zhang","Jiacheng Ying","Junchen Yu","Xiaohai Hu","Lun Luo","Si-Yuan Cao","Hui-Liang Shen"],"pdf_url":"https://arxiv.org/pdf/2405.13675v4.pdf","comment":"NIPS 2024 Spotlight"},{"id":"http://arxiv.org/abs/2410.14980v2","updated":"2024-10-22T14:27:32Z","published":"2024-10-19T05:10:07Z","title":"DCDepth: Progressive Monocular Depth Estimation in Discrete Cosine\n  Domain","summary":"  In this paper, we introduce DCDepth, a novel framework for the long-standing\nmonocular depth estimation task. Moving beyond conventional pixel-wise depth\nestimation in the spatial domain, our approach estimates the frequency\ncoefficients of depth patches after transforming them into the discrete cosine\ndomain. This unique formulation allows for the modeling of local depth\ncorrelations within each patch. Crucially, the frequency transformation\nsegregates the depth information into various frequency components, with\nlow-frequency components encapsulating the core scene structure and\nhigh-frequency components detailing the finer aspects. This decomposition forms\nthe basis of our progressive strategy, which begins with the prediction of\nlow-frequency components to establish a global scene context, followed by\nsuccessive refinement of local details through the prediction of\nhigher-frequency components. We conduct comprehensive experiments on\nNYU-Depth-V2, TOFDC, and KITTI datasets, and demonstrate the state-of-the-art\nperformance of DCDepth. Code is available at https://github.com/w2kun/DCDepth.\n","authors":["Kun Wang","Zhiqiang Yan","Junkai Fan","Wanlu Zhu","Xiang Li","Jun Li","Jian Yang"],"pdf_url":"https://arxiv.org/pdf/2410.14980v2.pdf","comment":"Accepted by NeurIPS-2024"},{"id":"http://arxiv.org/abs/2405.14677v2","updated":"2024-10-22T14:21:19Z","published":"2024-05-23T15:12:15Z","title":"RectifID: Personalizing Rectified Flow with Anchored Classifier Guidance","summary":"  Customizing diffusion models to generate identity-preserving images from\nuser-provided reference images is an intriguing new problem. The prevalent\napproaches typically require training on extensive domain-specific images to\nachieve identity preservation, which lacks flexibility across different use\ncases. To address this issue, we exploit classifier guidance, a training-free\ntechnique that steers diffusion models using an existing classifier, for\npersonalized image generation. Our study shows that based on a recent rectified\nflow framework, the major limitation of vanilla classifier guidance in\nrequiring a special classifier can be resolved with a simple fixed-point\nsolution, allowing flexible personalization with off-the-shelf image\ndiscriminators. Moreover, its solving procedure proves to be stable when\nanchored to a reference flow trajectory, with a convergence guarantee. The\nderived method is implemented on rectified flow with different off-the-shelf\nimage discriminators, delivering advantageous personalization results for human\nfaces, live subjects, and certain objects. Code is available at\nhttps://github.com/feifeiobama/RectifID.\n","authors":["Zhicheng Sun","Zhenhao Yang","Yang Jin","Haozhe Chi","Kun Xu","Kun Xu","Liwei Chen","Hao Jiang","Yang Song","Kun Gai","Yadong Mu"],"pdf_url":"https://arxiv.org/pdf/2405.14677v2.pdf","comment":"NeurIPS 2024"},{"id":"http://arxiv.org/abs/2409.16320v2","updated":"2024-10-22T14:09:10Z","published":"2024-09-21T03:45:05Z","title":"Developing a Thailand solar irradiance map using Himawari-8 satellite\n  imageries and deep learning models","summary":"  This paper presents an online platform that shows Thailand's solar irradiance\nmap every 30 minutes. It is available at https://www.cusolarforecast.com. The\nmethodology for estimating global horizontal irradiance (GHI) across Thailand\nrelies on cloud index extracted from Himawari-8 satellite imagery, Ineichen\nclear-sky model with locally-tuned Linke turbidity, and machine learning\nmodels. The methods take clear-sky irradiance, cloud index, re-analyzed GHI and\ntemperature data from the MERRA-2 database, and date-time as inputs for GHI\nestimation models, including LightGBM, LSTM, Informer, and Transformer. These\nare benchmarked with the estimate from a commercial service X by evaluating\n15-minute ground GHI data from 53 ground stations over 1.5 years from\n2022-2023. The results show that the four models have competitive performances\nand outperform the service X. The best model is LightGBM, with an MAE of 78.58\nW/sqm and RMSE of 118.97 W/sqm. Obtaining re-analyzed MERRA-2 data for Thailand\nis not economically feasible for deployment. When removing these features, the\nInformer model has a winning performance of 78.67 W/sqm in MAE. The obtained\nperformance aligns with existing literature by taking the climate zone and time\ngranularity of data into consideration. As the map shows an estimate of GHI\nover 93,000 grids with a frequent update, the paper also describes a\ncomputational framework for displaying the entire map. It tests the runtime\nperformance of deep learning models in the GHI estimation process.\n","authors":["Suwichaya Suwanwimolkul","Natanon Tongamrak","Nuttamon Thungka","Naebboon Hoonchareon","Jitkomut Songsiri"],"pdf_url":"https://arxiv.org/pdf/2409.16320v2.pdf","comment":"23 pages, 14 figures"},{"id":"http://arxiv.org/abs/2403.07389v2","updated":"2024-10-22T14:07:54Z","published":"2024-03-12T07:57:33Z","title":"Auxiliary CycleGAN-guidance for Task-Aware Domain Translation from\n  Duplex to Monoplex IHC Images","summary":"  Generative models enable the translation from a source image domain where\nreadily trained models are available to a target domain unseen during training.\nWhile Cycle Generative Adversarial Networks (GANs) are well established, the\nassociated cycle consistency constrain relies on that an invertible mapping\nexists between the two domains. This is, however, not the case for the\ntranslation between images stained with chromogenic monoplex and duplex\nimmunohistochemistry (IHC) assays. Focusing on the translation from the latter\nto the first, we propose - through the introduction of a novel training design,\nan alternative constrain leveraging a set of immunofluorescence (IF) images as\nan auxiliary unpaired image domain. Quantitative and qualitative results on a\ndownstream segmentation task show the benefit of the proposed method in\ncomparison to baseline approaches.\n","authors":["Nicolas Brieu","Nicolas Triltsch","Philipp Wortmann","Dominik Winter","Shashank Saran","Marlon Rebelatto","Günter Schmidt"],"pdf_url":"https://arxiv.org/pdf/2403.07389v2.pdf","comment":"5 pages"},{"id":"http://arxiv.org/abs/2410.17020v1","updated":"2024-10-22T13:44:10Z","published":"2024-10-22T13:44:10Z","title":"LFME: A Simple Framework for Learning from Multiple Experts in Domain\n  Generalization","summary":"  Domain generalization (DG) methods aim to maintain good performance in an\nunseen target domain by using training data from multiple source domains. While\nsuccess on certain occasions are observed, enhancing the baseline across most\nscenarios remains challenging. This work introduces a simple yet effective\nframework, dubbed learning from multiple experts (LFME), that aims to make the\ntarget model an expert in all source domains to improve DG. Specifically,\nbesides learning the target model used in inference, LFME will also train\nmultiple experts specialized in different domains, whose output probabilities\nprovide professional guidance by simply regularizing the logit of the target\nmodel. Delving deep into the framework, we reveal that the introduced logit\nregularization term implicitly provides effects of enabling the target model to\nharness more information, and mining hard samples from the experts during\ntraining. Extensive experiments on benchmarks from different DG tasks\ndemonstrate that LFME is consistently beneficial to the baseline and can\nachieve comparable performance to existing arts. Code is available\nat~\\url{https://github.com/liangchen527/LFME}.\n","authors":["Liang Chen","Yong Zhang","Yibing Song","Zhiqiang Shen","Lingqiao Liu"],"pdf_url":"https://arxiv.org/pdf/2410.17020v1.pdf","comment":"Accepted by NeurIPS 2024"},{"id":"http://arxiv.org/abs/2410.17017v1","updated":"2024-10-22T13:37:55Z","published":"2024-10-22T13:37:55Z","title":"SPVSoAP3D: A Second-order Average Pooling Approach to enhance 3D Place\n  Recognition in Horticultural Environments","summary":"  3D LiDAR-based place recognition has been extensively researched in urban\nenvironments, yet it remains underexplored in agricultural settings. Unlike\nurban contexts, horticultural environments, characterized by their permeability\nto laser beams, result in sparse and overlapping LiDAR scans with suboptimal\ngeometries. This phenomenon leads to intra- and inter-row descriptor ambiguity.\nIn this work, we address this challenge by introducing SPVSoAP3D, a novel\nmodeling approach that combines a voxel-based feature extraction network with\nan aggregation technique based on a second-order average pooling operator,\ncomplemented by a descriptor enhancement stage. Furthermore, we augment the\nexisting HORTO-3DLM dataset by introducing two new sequences derived from\nhorticultural environments. We evaluate the performance of SPVSoAP3D against\nstate-of-the-art (SOTA) models, including OverlapTransformer, PointNetVLAD, and\nLOGG3D-Net, utilizing a cross-validation protocol on both the newly introduced\nsequences and the existing HORTO-3DLM dataset. The findings indicate that the\naverage operator is more suitable for horticultural environments compared to\nthe max operator and other first-order pooling techniques. Additionally, the\nresults highlight the improvements brought by the descriptor enhancement stage.\n","authors":["T. Barros","C. Premebida","S. Aravecchia","C. Pradalier","U. J. Nunes"],"pdf_url":"https://arxiv.org/pdf/2410.17017v1.pdf","comment":"This work has been accepted to IROS 2024"},{"id":"http://arxiv.org/abs/2205.07708v3","updated":"2024-10-22T13:34:45Z","published":"2022-05-16T14:21:30Z","title":"Exploring Diversity-based Active Learning for 3D Object Detection in\n  Autonomous Driving","summary":"  3D object detection has recently received much attention due to its great\npotential in autonomous vehicle (AV). The success of deep learning based object\ndetectors relies on the availability of large-scale annotated datasets, which\nis time-consuming and expensive to compile, especially for 3D bounding box\nannotation. In this work, we investigate diversity-based active learning (AL)\nas a potential solution to alleviate the annotation burden. Given limited\nannotation budget, only the most informative frames and objects are\nautomatically selected for human to annotate. Technically, we take the\nadvantage of the multimodal information provided in an AV dataset, and propose\na novel acquisition function that enforces spatial and temporal diversity in\nthe selected samples. We benchmark the proposed method against other AL\nstrategies under realistic annotation cost measurement, where the realistic\ncosts for annotating a frame and a 3D bounding box are both taken into\nconsideration. We demonstrate the effectiveness of the proposed method on the\nnuScenes dataset and show that it outperforms existing AL strategies\nsignificantly. Code is available at\nhttps://github.com/Linkon87/Exploring-Diversity-based-Active-Learning-for-3D-Object-Detection-in-Autonomous-Driving\n","authors":["Jinpeng Lin","Zhihao Liang","Shengheng Deng","Lile Cai","Tao Jiang","Tianrui Li","Kui Jia","Xun Xu"],"pdf_url":"https://arxiv.org/pdf/2205.07708v3.pdf","comment":"IEEE Transactions on Intelligent Transportation Systems. Code is\n  available at\n  https://github.com/Linkon87/Exploring-Diversity-based-Active-Learning-for-3D-Object-Detection-in-Autonomous-Driving"},{"id":"http://arxiv.org/abs/2406.12142v2","updated":"2024-10-22T13:32:34Z","published":"2024-06-17T23:08:46Z","title":"Slicing Through Bias: Explaining Performance Gaps in Medical Image\n  Analysis using Slice Discovery Methods","summary":"  Machine learning models have achieved high overall accuracy in medical image\nanalysis. However, performance disparities on specific patient groups pose\nchallenges to their clinical utility, safety, and fairness. This can affect\nknown patient groups - such as those based on sex, age, or disease subtype - as\nwell as previously unknown and unlabeled groups. Furthermore, the root cause of\nsuch observed performance disparities is often challenging to uncover,\nhindering mitigation efforts. In this paper, to address these issues, we\nleverage Slice Discovery Methods (SDMs) to identify interpretable\nunderperforming subsets of data and formulate hypotheses regarding the cause of\nobserved performance disparities. We introduce a novel SDM and apply it in a\ncase study on the classification of pneumothorax and atelectasis from chest\nx-rays. Our study demonstrates the effectiveness of SDMs in hypothesis\nformulation and yields an explanation of previously observed but unexplained\nperformance disparities between male and female patients in widely used chest\nX-ray datasets and models. Our findings indicate shortcut learning in both\nclassification tasks, through the presence of chest drains and ECG wires,\nrespectively. Sex-based differences in the prevalence of these shortcut\nfeatures appear to cause the observed classification performance gap,\nrepresenting a previously underappreciated interaction between shortcut\nlearning and model fairness analyses.\n","authors":["Vincent Olesen","Nina Weng","Aasa Feragen","Eike Petersen"],"pdf_url":"https://arxiv.org/pdf/2406.12142v2.pdf","comment":"MICCAI 2024 Workshop on Fairness of AI in Medical Imaging"},{"id":"http://arxiv.org/abs/2410.17001v1","updated":"2024-10-22T13:23:05Z","published":"2024-10-22T13:23:05Z","title":"Joint Point Cloud Upsampling and Cleaning with Octree-based CNNs","summary":"  Recovering dense and uniformly distributed point clouds from sparse or noisy\ndata remains a significant challenge. Recently, great progress has been made on\nthese tasks, but usually at the cost of increasingly intricate modules or\ncomplicated network architectures, leading to long inference time and huge\nresource consumption. Instead, we embrace simplicity and present a simple yet\nefficient method for jointly upsampling and cleaning point clouds. Our method\nleverages an off-the-shelf octree-based 3D U-Net (OUNet) with minor\nmodifications, enabling the upsampling and cleaning tasks within a single\nnetwork. Our network directly processes each input point cloud as a whole\ninstead of processing each point cloud patch as in previous works, which\nsignificantly eases the implementation and brings at least 47 times faster\ninference. Extensive experiments demonstrate that our method achieves\nstate-of-the-art performances under huge efficiency advantages on a series of\nbenchmarks. We expect our method to serve simple baselines and inspire\nresearchers to rethink the method design on point cloud upsampling and\ncleaning.\n","authors":["Jihe Li","Bo Pang","Peng-Shuai Wang"],"pdf_url":"https://arxiv.org/pdf/2410.17001v1.pdf","comment":"Accepted by Computational Visual Media"},{"id":"http://arxiv.org/abs/2410.16999v1","updated":"2024-10-22T13:21:36Z","published":"2024-10-22T13:21:36Z","title":"AGSENet: A Robust Road Ponding Detection Method for Proactive Traffic\n  Safety","summary":"  Road ponding, a prevalent traffic hazard, poses a serious threat to road\nsafety by causing vehicles to lose control and leading to accidents ranging\nfrom minor fender benders to severe collisions. Existing technologies struggle\nto accurately identify road ponding due to complex road textures and variable\nponding coloration influenced by reflection characteristics. To address this\nchallenge, we propose a novel approach called Self-Attention-based Global\nSaliency-Enhanced Network (AGSENet) for proactive road ponding detection and\ntraffic safety improvement. AGSENet incorporates saliency detection techniques\nthrough the Channel Saliency Information Focus (CSIF) and Spatial Saliency\nInformation Enhancement (SSIE) modules. The CSIF module, integrated into the\nencoder, employs self-attention to highlight similar features by fusing spatial\nand channel information. The SSIE module, embedded in the decoder, refines edge\nfeatures and reduces noise by leveraging correlations across different feature\nlevels. To ensure accurate and reliable evaluation, we corrected significant\nmislabeling and missing annotations in the Puddle-1000 dataset. Additionally,\nwe constructed the Foggy-Puddle and Night-Puddle datasets for road ponding\ndetection in low-light and foggy conditions, respectively. Experimental results\ndemonstrate that AGSENet outperforms existing methods, achieving IoU\nimprovements of 2.03\\%, 0.62\\%, and 1.06\\% on the Puddle-1000, Foggy-Puddle,\nand Night-Puddle datasets, respectively, setting a new state-of-the-art in this\nfield. Finally, we verified the algorithm's reliability on edge computing\ndevices. This work provides a valuable reference for proactive warning research\nin road traffic safety.\n","authors":["Ronghui Zhang","Shangyu Yang","Dakang Lyu","Zihan Wang","Junzhou Chen","Yilong Ren","Bolin Gao","Zhihan Lv"],"pdf_url":"https://arxiv.org/pdf/2410.16999v1.pdf","comment":"21 pages, 15 figures"},{"id":"http://arxiv.org/abs/2410.16995v1","updated":"2024-10-22T13:17:20Z","published":"2024-10-22T13:17:20Z","title":"E-3DGS: Gaussian Splatting with Exposure and Motion Events","summary":"  Estimating Neural Radiance Fields (NeRFs) from images captured under optimal\nconditions has been extensively explored in the vision community. However,\nrobotic applications often face challenges such as motion blur, insufficient\nillumination, and high computational overhead, which adversely affect\ndownstream tasks like navigation, inspection, and scene visualization. To\naddress these challenges, we propose E-3DGS, a novel event-based approach that\npartitions events into motion (from camera or object movement) and exposure\n(from camera exposure), using the former to handle fast-motion scenes and using\nthe latter to reconstruct grayscale images for high-quality training and\noptimization of event-based 3D Gaussian Splatting (3DGS). We introduce a novel\nintegration of 3DGS with exposure events for high-quality reconstruction of\nexplicit scene representations. Our versatile framework can operate on motion\nevents alone for 3D reconstruction, enhance quality using exposure events, or\nadopt a hybrid mode that balances quality and effectiveness by optimizing with\ninitial exposure events followed by high-speed motion events. We also introduce\nEME-3D, a real-world 3D dataset with exposure events, motion events, camera\ncalibration parameters, and sparse point clouds. Our method is faster and\ndelivers better reconstruction quality than event-based NeRF while being more\ncost-effective than NeRF methods that combine event and RGB data by using a\nsingle event sensor. By combining motion and exposure events, E-3DGS sets a new\nbenchmark for event-based 3D reconstruction with robust performance in\nchallenging conditions and lower hardware demands. The source code and dataset\nwill be available at https://github.com/MasterHow/E-3DGS.\n","authors":["Xiaoting Yin","Hao Shi","Yuhan Bao","Zhenshan Bing","Yiyi Liao","Kailun Yang","Kaiwei Wang"],"pdf_url":"https://arxiv.org/pdf/2410.16995v1.pdf","comment":"The source code and dataset will be available at\n  https://github.com/MasterHow/E-3DGS"},{"id":"http://arxiv.org/abs/2404.06050v2","updated":"2024-10-22T13:15:20Z","published":"2024-04-09T06:27:35Z","title":"Incremental Joint Learning of Depth, Pose and Implicit Scene\n  Representation on Monocular Camera in Large-scale Scenes","summary":"  Dense scene reconstruction for photo-realistic view synthesis has various\napplications, such as VR/AR, autonomous vehicles. However, most existing\nmethods have difficulties in large-scale scenes due to three core challenges:\n\\textit{(a) inaccurate depth input.} Accurate depth input is impossible to get\nin real-world large-scale scenes. \\textit{(b) inaccurate pose estimation.} Most\nexisting approaches rely on accurate pre-estimated camera poses. \\textit{(c)\ninsufficient scene representation capability.} A single global radiance field\nlacks the capacity to effectively scale to large-scale scenes. To this end, we\npropose an incremental joint learning framework, which can achieve accurate\ndepth, pose estimation, and large-scale scene reconstruction. A vision\ntransformer-based network is adopted as the backbone to enhance performance in\nscale information estimation. For pose estimation, a feature-metric bundle\nadjustment (FBA) method is designed for accurate and robust camera tracking in\nlarge-scale scenes. In terms of implicit scene representation, we propose an\nincremental scene representation method to construct the entire large-scale\nscene as multiple local radiance fields to enhance the scalability of 3D scene\nrepresentation. Extended experiments have been conducted to demonstrate the\neffectiveness and accuracy of our method in depth estimation, pose estimation,\nand large-scale scene reconstruction.\n","authors":["Tianchen Deng","Nailin Wang","Chongdi Wang","Shenghai Yuan","Jingchuan Wang","Danwei Wang","Weidong Chen"],"pdf_url":"https://arxiv.org/pdf/2404.06050v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2407.09553v3","updated":"2024-10-22T13:04:29Z","published":"2024-06-28T08:21:49Z","title":"DPEC: Dual-Path Error Compensation Method for Enhanced Low-Light Image\n  Clarity","summary":"  For the task of low-light image enhancement, deep learning-based algorithms\nhave demonstrated superiority and effectiveness compared to traditional\nmethods. Existing deep learning algorithms are proposed mainly based on the\nRetinex theory but overlook the noise and color distortion present in the\ninput, which frequently results in significant noise amplification and local\ncolor distortion in the final results. To address this, we propose a Dual-Path\nError Compensation method (DPEC), which aims to improve image quality in\nlow-light conditions. DPEC performs precise pixel-level error estimation, which\naccurately captures subtle pixels differences, and independent denoising, which\neffectively removes unnecessary noise. This method restores image brightness\nwhile preserving local texture details and avoiding noise amplification.\nFurthermore, to compensate for the traditional CNN's limited ability to capture\nlong-range semantic information and considering both computational speed and\nresource efficiency, we integrated the VMamba architecture into the backbone of\nDPEC. In addition, we introduced the HIS-Retinex loss to constrain the training\nof DPEC, ensuring that the overall brightness distribution of the images more\nclosely aligns with real-world conditions. Comprehensive quantitative and\nqualitative experimental results demonstrate that our algorithm significantly\noutperforms state-of-the-art methods across six benchmark tests.\n","authors":["Shuang Wang","Qianwen Lu","Yihe Nie","Qingchuan Tao","Yanmei Yu"],"pdf_url":"https://arxiv.org/pdf/2407.09553v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.16978v1","updated":"2024-10-22T12:56:58Z","published":"2024-10-22T12:56:58Z","title":"Multi-Layer Gaussian Splatting for Immersive Anatomy Visualization","summary":"  In medical image visualization, path tracing of volumetric medical data like\nCT scans produces lifelike three-dimensional visualizations. Immersive VR\ndisplays can further enhance the understanding of complex anatomies. Going\nbeyond the diagnostic quality of traditional 2D slices, they enable interactive\n3D evaluation of anatomies, supporting medical education and planning.\nRendering high-quality visualizations in real-time, however, is computationally\nintensive and impractical for compute-constrained devices like mobile headsets.\n  We propose a novel approach utilizing GS to create an efficient but static\nintermediate representation of CT scans. We introduce a layered GS\nrepresentation, incrementally including different anatomical structures while\nminimizing overlap and extending the GS training to remove inactive Gaussians.\nWe further compress the created model with clustering across layers.\n  Our approach achieves interactive frame rates while preserving anatomical\nstructures, with quality adjustable to the target hardware. Compared to\nstandard GS, our representation retains some of the explorative qualities\ninitially enabled by immersive path tracing. Selective activation and clipping\nof layers are possible at rendering time, adding a degree of interactivity to\notherwise static GS models. This could enable scenarios where high\ncomputational demands would otherwise prohibit using path-traced medical\nvolumes.\n","authors":["Constantin Kleinbeck","Hannah Schieber","Klaus Engel","Ralf Gutjahr","Daniel Roth"],"pdf_url":"https://arxiv.org/pdf/2410.16978v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.16592v2","updated":"2024-10-22T12:46:00Z","published":"2024-06-24T12:33:21Z","title":"Toward Fairer Face Recognition Datasets","summary":"  Face recognition and verification are two computer vision tasks whose\nperformance has progressed with the introduction of deep representations.\nHowever, ethical, legal, and technical challenges due to the sensitive\ncharacter of face data and biases in real training datasets hinder their\ndevelopment. Generative AI addresses privacy by creating fictitious identities,\nbut fairness problems persist. We promote fairness by introducing a demographic\nattributes balancing mechanism in generated training datasets. We experiment\nwith an existing real dataset, three generated training datasets, and the\nbalanced versions of a diffusion-based dataset. We propose a comprehensive\nevaluation that considers accuracy and fairness equally and includes a rigorous\nregression-based statistical analysis of attributes. The analysis shows that\nbalancing reduces demographic unfairness. Also, a performance gap persists\ndespite generation becoming more accurate with time. The proposed balancing\nmethod and comprehensive verification evaluation promote fairer and transparent\nface recognition and verification.\n","authors":["Alexandre Fournier-Mongieux","Michael Soumm","Adrian Popescu","Bertrand Luvison","Hervé Le Borgne"],"pdf_url":"https://arxiv.org/pdf/2406.16592v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.13717v5","updated":"2024-10-22T12:42:06Z","published":"2023-11-22T22:21:26Z","title":"Feature Extraction for Generative Medical Imaging Evaluation: New\n  Evidence Against an Evolving Trend","summary":"  Fr\\'echet Inception Distance (FID) is a widely used metric for assessing\nsynthetic image quality. It relies on an ImageNet-based feature extractor,\nmaking its applicability to medical imaging unclear. A recent trend is to adapt\nFID to medical imaging through feature extractors trained on medical images.\nOur study challenges this practice by demonstrating that ImageNet-based\nextractors are more consistent and aligned with human judgment than their\nRadImageNet counterparts. We evaluated sixteen StyleGAN2 networks across four\nmedical imaging modalities and four data augmentation techniques with Fr\\'echet\ndistances (FDs) computed using eleven ImageNet or RadImageNet-trained feature\nextractors. Comparison with human judgment via visual Turing tests revealed\nthat ImageNet-based extractors produced rankings consistent with human\njudgment, with the FD derived from the ImageNet-trained SwAV extractor\nsignificantly correlating with expert evaluations. In contrast,\nRadImageNet-based rankings were volatile and inconsistent with human judgment.\nOur findings challenge prevailing assumptions, providing novel evidence that\nmedical image-trained feature extractors do not inherently improve FDs and can\neven compromise their reliability. Our code is available at\nhttps://github.com/mckellwoodland/fid-med-eval.\n","authors":["McKell Woodland","Austin Castelo","Mais Al Taie","Jessica Albuquerque Marques Silva","Mohamed Eltaher","Frank Mohn","Alexander Shieh","Suprateek Kundu","Joshua P. Yung","Ankit B. Patel","Kristy K. Brock"],"pdf_url":"https://arxiv.org/pdf/2311.13717v5.pdf","comment":"This preprint has not undergone peer review or any post-submission\n  improvements or corrections. The Version of Record of this contribution is\n  published in LNCS vol. 15012, and is available online at\n  https://doi.org/10.1007/978-3-031-72390-2_9"},{"id":"http://arxiv.org/abs/2410.16958v1","updated":"2024-10-22T12:38:39Z","published":"2024-10-22T12:38:39Z","title":"Leaky ReLUs That Differ in Forward and Backward Pass Facilitate\n  Activation Maximization in Deep Neural Networks","summary":"  Activation maximization (AM) strives to generate optimal input stimuli,\nrevealing features that trigger high responses in trained deep neural networks.\nAM is an important method of explainable AI. We demonstrate that AM fails to\nproduce optimal input stimuli for simple functions containing ReLUs or Leaky\nReLUs, casting doubt on the practical usefulness of AM and the visual\ninterpretation of the generated images. This paper proposes a solution based on\nusing Leaky ReLUs with a high negative slope in the backward pass while keeping\nthe original, usually zero, slope in the forward pass. The approach\nsignificantly increases the maxima found by AM. The resulting ProxyGrad\nalgorithm implements a novel optimization technique for neural networks that\nemploys a secondary network as a proxy for gradient computation. This proxy\nnetwork is designed to have a simpler loss landscape with fewer local maxima\nthan the original network. Our chosen proxy network is an identical copy of the\noriginal network, including its weights, with distinct negative slopes in the\nLeaky ReLUs. Moreover, we show that ProxyGrad can be used to train the weights\nof Convolutional Neural Networks for classification such that, on some of the\ntested benchmarks, they outperform traditional networks.\n","authors":["Christoph Linse","Erhardt Barth","Thomas Martinetz"],"pdf_url":"https://arxiv.org/pdf/2410.16958v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.16955v1","updated":"2024-10-22T12:36:03Z","published":"2024-10-22T12:36:03Z","title":"PGCS: Physical Law embedded Generative Cloud Synthesis in Remote Sensing\n  Images","summary":"  Data quantity and quality are both critical for information extraction and\nanalyzation in remote sensing. However, the current remote sensing datasets\noften fail to meet these two requirements, for which cloud is a primary factor\ndegrading the data quantity and quality. This limitation affects the precision\nof results in remote sensing application, particularly those derived from\ndata-driven techniques. In this paper, a physical law embedded generative cloud\nsynthesis method (PGCS) is proposed to generate diverse realistic cloud images\nto enhance real data and promote the development of algorithms for subsequent\ntasks, such as cloud correction, cloud detection, and data augmentation for\nclassification, recognition, and segmentation. The PGCS method involves two key\nphases: spatial synthesis and spectral synthesis. In the spatial synthesis\nphase, a style-based generative adversarial network is utilized to simulate the\nspatial characteristics, generating an infinite number of single-channel\nclouds. In the spectral synthesis phase, the atmospheric scattering law is\nembedded through a local statistics and global fitting method, converting the\nsingle-channel clouds into multi-spectral clouds. The experimental results\ndemonstrate that PGCS achieves a high accuracy in both phases and performs\nbetter than three other existing cloud synthesis methods. Two cloud correction\nmethods are developed from PGCS and exhibits a superior performance compared to\nstate-of-the-art methods in the cloud correction task. Furthermore, the\napplication of PGCS with data from various sensors was investigated and\nsuccessfully extended. Code will be provided at\nhttps://github.com/Liying-Xu/PGCS.\n","authors":["Liying Xu","Huifang Li","Huanfeng Shen","Mingyang Lei","Tao Jiang"],"pdf_url":"https://arxiv.org/pdf/2410.16955v1.pdf","comment":"20 pages, 16 figures"},{"id":"http://arxiv.org/abs/2410.16953v1","updated":"2024-10-22T12:33:38Z","published":"2024-10-22T12:33:38Z","title":"Towards Real Zero-Shot Camouflaged Object Segmentation without\n  Camouflaged Annotations","summary":"  Camouflaged Object Segmentation (COS) faces significant challenges due to the\nscarcity of annotated data, where meticulous pixel-level annotation is both\nlabor-intensive and costly, primarily due to the intricate object-background\nboundaries. Addressing the core question, \"Can COS be effectively achieved in a\nzero-shot manner without manual annotations for any camouflaged object?\" we\naffirmatively respond and introduce a robust zero-shot COS framework. This\nframework leverages the inherent local pattern bias of COS and employs a broad\nsemantic feature space derived from salient object segmentation (SOS) for\nefficient zero-shot transfer. We incorporate an Masked Image Modeling (MIM)\nbased image encoder optimized for Parameter-Efficient Fine-Tuning (PEFT), a\nMultimodal Large Language Model (M-LLM), and a Multi-scale Fine-grained\nAlignment (MFA) mechanism. The MIM pre-trained image encoder focuses on\ncapturing essential low-level features, while the M-LLM generates caption\nembeddings processed alongside these visual cues. These embeddings are\nprecisely aligned using MFA, enabling our framework to accurately interpret and\nnavigate complex semantic contexts. To optimize operational efficiency, we\nintroduce a learnable codebook that represents the M-LLM during inference,\nsignificantly reducing computational overhead. Our framework demonstrates its\nversatility and efficacy through rigorous experimentation, achieving\nstate-of-the-art performance in zero-shot COS with $F_{\\beta}^w$ scores of\n72.9\\% on CAMO and 71.7\\% on COD10K. By removing the M-LLM during inference, we\nachieve an inference speed comparable to that of traditional end-to-end models,\nreaching 18.1 FPS. Code: https://github.com/R-LEI360725/ZSCOS-CaMF\n","authors":["Cheng Lei","Jie Fan","Xinran Li","Tianzhu Xiang","Ao Li","Ce Zhu","Le Zhang"],"pdf_url":"https://arxiv.org/pdf/2410.16953v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2409.10353v2","updated":"2024-10-22T12:31:51Z","published":"2024-09-16T15:04:14Z","title":"Taming Diffusion Models for Image Restoration: A Review","summary":"  Diffusion models have achieved remarkable progress in generative modelling,\nparticularly in enhancing image quality to conform to human preferences.\nRecently, these models have also been applied to low-level computer vision for\nphoto-realistic image restoration (IR) in tasks such as image denoising,\ndeblurring, dehazing, etc. In this review paper, we introduce key constructions\nin diffusion models and survey contemporary techniques that make use of\ndiffusion models in solving general IR tasks. Furthermore, we point out the\nmain challenges and limitations of existing diffusion-based IR frameworks and\nprovide potential directions for future work.\n","authors":["Ziwei Luo","Fredrik K. Gustafsson","Zheng Zhao","Jens Sjölund","Thomas B. Schön"],"pdf_url":"https://arxiv.org/pdf/2409.10353v2.pdf","comment":"Review paper; any comments and suggestions are most welcome!"},{"id":"http://arxiv.org/abs/2407.21497v3","updated":"2024-10-22T12:23:20Z","published":"2024-07-31T10:11:57Z","title":"Mitral Regurgitation Recognition based on Unsupervised\n  Out-of-Distribution Detection with Residual Diffusion Amplification","summary":"  Mitral regurgitation (MR) is a serious heart valve disease. Early and\naccurate diagnosis of MR via ultrasound video is critical for timely clinical\ndecision-making and surgical intervention. However, manual MR diagnosis heavily\nrelies on the operator's experience, which may cause misdiagnosis and\ninter-observer variability. Since MR data is limited and has large intra-class\nvariability, we propose an unsupervised out-of-distribution (OOD) detection\nmethod to identify MR rather than building a deep classifier. To our knowledge,\nwe are the first to explore OOD in MR ultrasound videos. Our method consists of\na feature extractor, a feature reconstruction model, and a residual\naccumulation amplification algorithm. The feature extractor obtains features\nfrom the video clips and feeds them into the feature reconstruction model to\nrestore the original features. The residual accumulation amplification\nalgorithm then iteratively performs noise feature reconstruction, amplifying\nthe reconstructed error of OOD features. This algorithm is straightforward yet\nefficient and can seamlessly integrate as a plug-and-play component in\nreconstruction-based OOD detection methods. We validated the proposed method on\na large ultrasound dataset containing 893 non-MR and 267 MR videos.\nExperimental results show that our OOD detection method can effectively\nidentify MR samples.\n","authors":["Zhe Liu","Xiliang Zhu","Tong Han","Yuhao Huang","Jian Wang","Lian Liu","Fang Wang","Dong Ni","Zhongshan Gou","Xin Yang"],"pdf_url":"https://arxiv.org/pdf/2407.21497v3.pdf","comment":"Accepted by MICCAI MLMI 2024, 11 pages, 3 figures"},{"id":"http://arxiv.org/abs/2410.16947v1","updated":"2024-10-22T12:21:39Z","published":"2024-10-22T12:21:39Z","title":"ISImed: A Framework for Self-Supervised Learning using Intrinsic Spatial\n  Information in Medical Images","summary":"  This paper demonstrates that spatial information can be used to learn\ninterpretable representations in medical images using Self-Supervised Learning\n(SSL). Our proposed method, ISImed, is based on the observation that medical\nimages exhibit a much lower variability among different images compared to\nclassic data vision benchmarks. By leveraging this resemblance of human body\nstructures across multiple images, we establish a self-supervised objective\nthat creates a latent representation capable of capturing its location in the\nphysical realm. More specifically, our method involves sampling image crops and\ncreating a distance matrix that compares the learned representation vectors of\nall possible combinations of these crops to the true distance between them. The\nintuition is, that the learned latent space is a positional encoding for a\ngiven image crop. We hypothesize, that by learning these positional encodings,\ncomprehensive image representations have to be generated. To test this\nhypothesis and evaluate our method, we compare our learned representation with\ntwo state-of-the-art SSL benchmarking methods on two publicly available medical\nimaging datasets. We show that our method can efficiently learn representations\nthat capture the underlying structure of the data and can be used to transfer\nto a downstream classification task.\n","authors":["Nabil Jabareen","Dongsheng Yuan","Sören Lukassen"],"pdf_url":"https://arxiv.org/pdf/2410.16947v1.pdf","comment":"11 pages, 4 figures"},{"id":"http://arxiv.org/abs/2410.16945v1","updated":"2024-10-22T12:20:15Z","published":"2024-10-22T12:20:15Z","title":"IdenBAT: Disentangled Representation Learning for Identity-Preserved\n  Brain Age Transformation","summary":"  Brain age transformation aims to convert reference brain images into\nsynthesized images that accurately reflect the age-specific features of a\ntarget age group. The primary objective of this task is to modify only the\nage-related attributes of the reference image while preserving all other\nage-irrelevant attributes. However, achieving this goal poses substantial\nchallenges due to the inherent entanglement of various image attributes within\nfeatures extracted from a backbone encoder, resulting in simultaneous\nalterations during the image generation. To address this challenge, we propose\na novel architecture that employs disentangled representation learning for\nidentity-preserved brain age transformation called IdenBAT. This approach\nfacilitates the decomposition of image features, ensuring the preservation of\nindividual traits while selectively transforming age-related characteristics to\nmatch those of the target age group. Through comprehensive experiments\nconducted on both 2D and full-size 3D brain datasets, our method adeptly\nconverts input images to target age while retaining individual characteristics\naccurately. Furthermore, our approach demonstrates superiority over existing\nstate-of-the-art regarding performance fidelity.\n","authors":["Junyeong Maeng","Kwanseok Oh","Wonsik Jung","Heung-Il Suk"],"pdf_url":"https://arxiv.org/pdf/2410.16945v1.pdf","comment":"16 pages, 8 figures, 2 tables"},{"id":"http://arxiv.org/abs/2410.16942v1","updated":"2024-10-22T12:18:24Z","published":"2024-10-22T12:18:24Z","title":"DiP-GO: A Diffusion Pruner via Few-step Gradient Optimization","summary":"  Diffusion models have achieved remarkable progress in the field of image\ngeneration due to their outstanding capabilities. However, these models require\nsubstantial computing resources because of the multi-step denoising process\nduring inference. While traditional pruning methods have been employed to\noptimize these models, the retraining process necessitates large-scale training\ndatasets and extensive computational costs to maintain generalization ability,\nmaking it neither convenient nor efficient. Recent studies attempt to utilize\nthe similarity of features across adjacent denoising stages to reduce\ncomputational costs through simple and static strategies. However, these\nstrategies cannot fully harness the potential of the similar feature patterns\nacross adjacent timesteps. In this work, we propose a novel pruning method that\nderives an efficient diffusion model via a more intelligent and differentiable\npruner. At the core of our approach is casting the model pruning process into a\nSubNet search process. Specifically, we first introduce a SuperNet based on\nstandard diffusion via adding some backup connections built upon the similar\nfeatures. We then construct a plugin pruner network and design optimization\nlosses to identify redundant computation. Finally, our method can identify an\noptimal SubNet through few-step gradient optimization and a simple\npost-processing procedure. We conduct extensive experiments on various\ndiffusion models including Stable Diffusion series and DiTs. Our DiP-GO\napproach achieves 4.4 x speedup for SD-1.5 without any loss of accuracy,\nsignificantly outperforming the previous state-of-the-art methods.\n","authors":["Haowei Zhu","Dehua Tang","Ji Liu","Mingjie Lu","Jintu Zheng","Jinzhang Peng","Dong Li","Yu Wang","Fan Jiang","Lu Tian","Spandan Tiwari","Ashish Sirasao","Jun-Hai Yong","Bin Wang","Emad Barsoum"],"pdf_url":"https://arxiv.org/pdf/2410.16942v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.16939v1","updated":"2024-10-22T12:13:47Z","published":"2024-10-22T12:13:47Z","title":"LIMIS: Towards Language-based Interactive Medical Image Segmentation","summary":"  Within this work, we introduce LIMIS: The first purely language-based\ninteractive medical image segmentation model. We achieve this by adapting\nGrounded SAM to the medical domain and designing a language-based model\ninteraction strategy that allows radiologists to incorporate their knowledge\ninto the segmentation process. LIMIS produces high-quality initial segmentation\nmasks by leveraging medical foundation models and allows users to adapt\nsegmentation masks using only language, opening up interactive segmentation to\nscenarios where physicians require using their hands for other tasks. We\nevaluate LIMIS on three publicly available medical datasets in terms of\nperformance and usability with experts from the medical domain confirming its\nhigh-quality segmentation masks and its interactive usability.\n","authors":["Lena Heinemann","Alexander Jaus","Zdravko Marinov","Moon Kim","Maria Francesca Spadea","Jens Kleesiek","Rainer Stiefelhagen"],"pdf_url":"https://arxiv.org/pdf/2410.16939v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2405.15330v2","updated":"2024-10-22T12:01:45Z","published":"2024-05-24T08:12:41Z","title":"Towards Understanding the Working Mechanism of Text-to-Image Diffusion\n  Model","summary":"  Recently, the strong latent Diffusion Probabilistic Model (DPM) has been\napplied to high-quality Text-to-Image (T2I) generation (e.g., Stable\nDiffusion), by injecting the encoded target text prompt into the gradually\ndenoised diffusion image generator. Despite the success of DPM in practice, the\nmechanism behind it remains to be explored. To fill this blank, we begin by\nexamining the intermediate statuses during the gradual denoising generation\nprocess in DPM. The empirical observations indicate, the shape of image is\nreconstructed after the first few denoising steps, and then the image is filled\nwith details (e.g., texture). The phenomenon is because the low-frequency\nsignal (shape relevant) of the noisy image is not corrupted until the final\nstage in the forward process (initial stage of generation) of adding noise in\nDPM. Inspired by the observations, we proceed to explore the influence of each\ntoken in the text prompt during the two stages. After a series of experiments\nof T2I generations conditioned on a set of text prompts. We conclude that in\nthe earlier generation stage, the image is mostly decided by the special token\n[\\texttt{EOS}] in the text prompt, and the information in the text prompt is\nalready conveyed in this stage. After that, the diffusion model completes the\ndetails of generated images by information from themselves. Finally, we propose\nto apply this observation to accelerate the process of T2I generation by\nproperly removing text guidance, which finally accelerates the sampling up to\n25\\%+.\n","authors":["Mingyang Yi","Aoxue Li","Yi Xin","Zhenguo Li"],"pdf_url":"https://arxiv.org/pdf/2405.15330v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.16910v1","updated":"2024-10-22T11:35:36Z","published":"2024-10-22T11:35:36Z","title":"Hierarchical Clustering for Conditional Diffusion in Image Generation","summary":"  Finding clusters of data points with similar characteristics and generating\nnew cluster-specific samples can significantly enhance our understanding of\ncomplex data distributions. While clustering has been widely explored using\nVariational Autoencoders, these models often lack generation quality in\nreal-world datasets. This paper addresses this gap by introducing\nTreeDiffusion, a deep generative model that conditions Diffusion Models on\nhierarchical clusters to obtain high-quality, cluster-specific generations. The\nproposed pipeline consists of two steps: a VAE-based clustering model that\nlearns the hierarchical structure of the data, and a conditional diffusion\nmodel that generates realistic images for each cluster. We propose this\ntwo-stage process to ensure that the generated samples remain representative of\ntheir respective clusters and enhance image fidelity to the level of diffusion\nmodels. A key strength of our method is its ability to create images for each\ncluster, providing better visualization of the learned representations by the\nclustering model, as demonstrated through qualitative results. This method\neffectively addresses the generative limitations of VAE-based approaches while\npreserving their clustering performance. Empirically, we demonstrate that\nconditioning diffusion models on hierarchical clusters significantly enhances\ngenerative performance, thereby advancing the state of generative clustering\nmodels.\n","authors":["Jorge da Silva Goncalves","Laura Manduchi","Moritz Vandenhirtz","Julia E. Vogt"],"pdf_url":"https://arxiv.org/pdf/2410.16910v1.pdf","comment":"25 pages, submitted to ICLR 2025"},{"id":"http://arxiv.org/abs/2410.16908v1","updated":"2024-10-22T11:28:39Z","published":"2024-10-22T11:28:39Z","title":"Mitigating Vanishing Activations in Deep CapsNets Using Channel Pruning","summary":"  Capsule Networks outperform Convolutional Neural Networks in learning the\npart-whole relationships with viewpoint invariance, and the credit goes to\ntheir multidimensional capsules. It was assumed that increasing the number of\ncapsule layers in the capsule networks would enhance the model performance.\nHowever, recent studies found that Capsule Networks lack scalability due to\nvanishing activations in the capsules of deeper layers. This paper thoroughly\ninvestigates the vanishing activation problem in deep Capsule Networks. To\nanalyze this issue and understand how increasing capsule dimensions can\nfacilitate deeper networks, various Capsule Network models are constructed and\nevaluated with different numbers of capsules, capsule dimensions, and\nintermediate layers for this paper. Unlike traditional model pruning, which\nreduces the number of model parameters and expedites model training, this study\nuses pruning to mitigate the vanishing activations in the deeper capsule\nlayers. In addition, the backbone network and capsule layers are pruned with\ndifferent pruning ratios to reduce the number of inactive capsules and achieve\nbetter model accuracy than the unpruned models.\n","authors":["Siddharth Sahu","Abdulrahman Altahhan"],"pdf_url":"https://arxiv.org/pdf/2410.16908v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.16898v1","updated":"2024-10-22T11:03:06Z","published":"2024-10-22T11:03:06Z","title":"MBD: Multi b-value Denoising of Diffusion Magnetic Resonance Images","summary":"  We propose a novel approach to denoising diffusion magnetic resonance images\n(dMRI) using convolutional neural networks, that exploits the benefits of data\nacquired at multiple b-values to offset the need for many redundant\nobservations. Denoising is especially relevant in dMRI since noise can have a\ndeleterious impact on both quantification accuracy and image preprocessing. The\nmost successful methods proposed to date, like Marchenko-Pastur Principal\nComponent Analysis (MPPCA) denoising, are tailored to diffusion-weighting\nrepeated for many encoding directions. They exploit high redundancy of the\ndataset that oversamples the diffusion-encoding direction space, since many\ndirections have collinear components.\n  However, there are many dMRI techniques that do not entail a large number of\nencoding directions or repetitions, and are therefore less suited to this\napproach. For example, clinical dMRI exams may include as few as three encoding\ndirections, with low or negligible data redundancy across directions. Moreover,\npromising new dMRI approaches, like spherical b-tensor encoding (STE), benefit\nfrom high b-values while sensitizing the signal to diffusion along all\ndirections in just a single shot.\n  We introduce a convolutional neural network approach that we call\nmulti-b-value-based denoising (MBD). MBD exploits the similarity in\ndiffusion-weighted images (DWI) across different b-values but along the same\ndiffusion encoding direction. It allows denoising of diffusion images with high\nnoise variance while avoiding blurring, and using just a small number input\nimages.\n","authors":["Jakub Jurek","Andrzej Materka","Kamil Ludwisiak","Agata Majos","Filip Szczepankiewicz"],"pdf_url":"https://arxiv.org/pdf/2410.16898v1.pdf","comment":"this is a biomedical engineering work using machine learning to\n  enhance medical images"},{"id":"http://arxiv.org/abs/2410.16897v1","updated":"2024-10-22T11:02:32Z","published":"2024-10-22T11:02:32Z","title":"Enhancing Generalization in Convolutional Neural Networks through\n  Regularization with Edge and Line Features","summary":"  This paper proposes a novel regularization approach to bias Convolutional\nNeural Networks (CNNs) toward utilizing edge and line features in their hidden\nlayers. Rather than learning arbitrary kernels, we constrain the convolution\nlayers to edge and line detection kernels. This intentional bias regularizes\nthe models, improving generalization performance, especially on small datasets.\nAs a result, test accuracies improve by margins of 5-11 percentage points\nacross four challenging fine-grained classification datasets with limited\ntraining data and an identical number of trainable parameters. Instead of\ntraditional convolutional layers, we use Pre-defined Filter Modules, which\nconvolve input data using a fixed set of 3x3 pre-defined edge and line filters.\nA subsequent ReLU erases information that did not trigger any positive\nresponse. Next, a 1x1 convolutional layer generates linear combinations.\nNotably, the pre-defined filters are a fixed component of the architecture,\nremaining unchanged during the training phase. Our findings reveal that the\nnumber of dimensions spanned by the set of pre-defined filters has a low impact\non recognition performance. However, the size of the set of filters matters,\nwith nine or more filters providing optimal results.\n","authors":["Christoph Linse","Beatrice Brückner","Thomas Martinetz"],"pdf_url":"https://arxiv.org/pdf/2410.16897v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.16892v1","updated":"2024-10-22T10:55:59Z","published":"2024-10-22T10:55:59Z","title":"VistaDream: Sampling multiview consistent images for single-view scene\n  reconstruction","summary":"  In this paper, we propose VistaDream a novel framework to reconstruct a 3D\nscene from a single-view image. Recent diffusion models enable generating\nhigh-quality novel-view images from a single-view input image. Most existing\nmethods only concentrate on building the consistency between the input image\nand the generated images while losing the consistency between the generated\nimages. VistaDream addresses this problem by a two-stage pipeline. In the first\nstage, VistaDream begins with building a global coarse 3D scaffold by zooming\nout a little step with inpainted boundaries and an estimated depth map. Then,\non this global scaffold, we use iterative diffusion-based RGB-D inpainting to\ngenerate novel-view images to inpaint the holes of the scaffold. In the second\nstage, we further enhance the consistency between the generated novel-view\nimages by a novel training-free Multiview Consistency Sampling (MCS) that\nintroduces multi-view consistency constraints in the reverse sampling process\nof diffusion models. Experimental results demonstrate that without training or\nfine-tuning existing diffusion models, VistaDream achieves consistent and\nhigh-quality novel view synthesis using just single-view images and outperforms\nbaseline methods by a large margin. The code, videos, and interactive demos are\navailable at https://vistadream-project-page.github.io/.\n","authors":["Haiping Wang","Yuan Liu","Ziwei Liu","Wenping Wang","Zhen Dong","Bisheng Yang"],"pdf_url":"https://arxiv.org/pdf/2410.16892v1.pdf","comment":"Project Page: https://vistadream-project-page.github.io/"},{"id":"http://arxiv.org/abs/2410.16884v1","updated":"2024-10-22T10:42:08Z","published":"2024-10-22T10:42:08Z","title":"Network Inversion for Training-Like Data Reconstruction","summary":"  Machine Learning models are often trained on proprietary and private data\nthat cannot be shared, though the trained models themselves are distributed\nopenly assuming that sharing model weights is privacy preserving, as training\ndata is not expected to be inferred from the model weights. In this paper, we\npresent Training-Like Data Reconstruction (TLDR), a network inversion-based\napproach to reconstruct training-like data from trained models. To begin with,\nwe introduce a comprehensive network inversion technique that learns the input\nspace corresponding to different classes in the classifier using a single\nconditioned generator. While inversion may typically return random and\narbitrary input images for a given output label, we modify the inversion\nprocess to incentivize the generator to reconstruct training-like data by\nexploiting key properties of the classifier with respect to the training data\nalong with some prior knowledge about the images. To validate our approach, we\nconduct empirical evaluations on multiple standard vision classification\ndatasets, thereby highlighting the potential privacy risks involved in sharing\nmachine learning models.\n","authors":["Pirzada Suhail","Amit Sethi"],"pdf_url":"https://arxiv.org/pdf/2410.16884v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.16868v1","updated":"2024-10-22T10:12:57Z","published":"2024-10-22T10:12:57Z","title":"Rethinking generalization of classifiers in separable classes scenarios\n  and over-parameterized regimes","summary":"  We investigate the learning dynamics of classifiers in scenarios where\nclasses are separable or classifiers are over-parameterized. In both cases,\nEmpirical Risk Minimization (ERM) results in zero training error. However,\nthere are many global minima with a training error of zero, some of which\ngeneralize well and some of which do not. We show that in separable classes\nscenarios the proportion of \"bad\" global minima diminishes exponentially with\nthe number of training data n. Our analysis provides bounds and learning curves\ndependent solely on the density distribution of the true error for the given\nclassifier function set, irrespective of the set's size or complexity (e.g.,\nnumber of parameters). This observation may shed light on the unexpectedly good\ngeneralization of over-parameterized Neural Networks. For the\nover-parameterized scenario, we propose a model for the density distribution of\nthe true error, yielding learning curves that align with experiments on MNIST\nand CIFAR-10.\n","authors":["Julius Martinetz","Christoph Linse","Thomas Martinetz"],"pdf_url":"https://arxiv.org/pdf/2410.16868v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2310.05375v6","updated":"2024-10-22T09:52:42Z","published":"2023-10-09T03:11:08Z","title":"IPDreamer: Appearance-Controllable 3D Object Generation with Complex\n  Image Prompts","summary":"  Recent advances in 3D generation have been remarkable, with methods such as\nDreamFusion leveraging large-scale text-to-image diffusion-based models to\nguide 3D object generation. These methods enable the synthesis of detailed and\nphotorealistic textured objects. However, the appearance of 3D objects produced\nby such text-to-3D models is often unpredictable, and it is hard for\nsingle-image-to-3D methods to deal with images lacking a clear subject,\ncomplicating the generation of appearance-controllable 3D objects from complex\nimages. To address these challenges, we present IPDreamer, a novel method that\ncaptures intricate appearance features from complex $\\textbf{I}$mage\n$\\textbf{P}$rompts and aligns the synthesized 3D object with these extracted\nfeatures, enabling high-fidelity, appearance-controllable 3D object generation.\nOur experiments demonstrate that IPDreamer consistently generates high-quality\n3D objects that align with both the textual and complex image prompts,\nhighlighting its promising capability in appearance-controlled, complex 3D\nobject generation. Our code is available at\nhttps://github.com/zengbohan0217/IPDreamer.\n","authors":["Bohan Zeng","Shanglin Li","Yutang Feng","Ling Yang","Hong Li","Sicheng Gao","Jiaming Liu","Conghui He","Wentao Zhang","Jianzhuang Liu","Baochang Zhang","Shuicheng Yan"],"pdf_url":"https://arxiv.org/pdf/2310.05375v6.pdf","comment":"20 pages, 12 figures"},{"id":"http://arxiv.org/abs/2410.16857v1","updated":"2024-10-22T09:46:09Z","published":"2024-10-22T09:46:09Z","title":"Nash Meets Wertheimer: Using Good Continuation in Jigsaw Puzzles","summary":"  Jigsaw puzzle solving is a challenging task for computer vision since it\nrequires high-level spatial and semantic reasoning. To solve the problem,\nexisting approaches invariably use color and/or shape information but in many\nreal-world scenarios, such as in archaeological fresco reconstruction, this\nkind of clues is often unreliable due to severe physical and pictorial\ndeterioration of the individual fragments. This makes state-of-the-art\napproaches entirely unusable in practice. On the other hand, in such cases,\nsimple geometrical patterns such as lines or curves offer a powerful yet\nunexplored clue. In an attempt to fill in this gap, in this paper we introduce\na new challenging version of the puzzle solving problem in which one\ndeliberately ignores conventional color and shape features and relies solely on\nthe presence of linear geometrical patterns. The reconstruction process is then\nonly driven by one of the most fundamental principles of Gestalt perceptual\norganization, namely Wertheimer's {\\em law of good continuation}. In order to\ntackle this problem, we formulate the puzzle solving problem as the problem of\nfinding a Nash equilibrium of a (noncooperative) multiplayer game and use\nclassical multi-population replicator dynamics to solve it. The proposed\napproach is general and allows us to deal with pieces of arbitrary shape, size\nand orientation. We evaluate our approach on both synthetic and real-world data\nand compare it with state-of-the-art algorithms. The results show the intrinsic\ncomplexity of our purely line-based puzzle problem as well as the relative\neffectiveness of our game-theoretic formulation.\n","authors":["Marina Khoroshiltseva","Luca Palmieri","Sinem Aslan","Sebastiano Vascon","Marcello Pelillo"],"pdf_url":"https://arxiv.org/pdf/2410.16857v1.pdf","comment":"to be published in ACCV2024"},{"id":"http://arxiv.org/abs/2402.02500v3","updated":"2024-10-22T09:42:39Z","published":"2024-02-04T14:18:45Z","title":"Point Cloud Matters: Rethinking the Impact of Different Observation\n  Spaces on Robot Learning","summary":"  In robot learning, the observation space is crucial due to the distinct\ncharacteristics of different modalities, which can potentially become a\nbottleneck alongside policy design. In this study, we explore the influence of\nvarious observation spaces on robot learning, focusing on three predominant\nmodalities: RGB, RGB-D, and point cloud. We introduce OBSBench, a benchmark\ncomprising two simulators and 125 tasks, along with standardized pipelines for\nvarious encoders and policy baselines. Extensive experiments on diverse\ncontact-rich manipulation tasks reveal a notable trend: point cloud-based\nmethods, even those with the simplest designs, frequently outperform their RGB\nand RGB-D counterparts. This trend persists in both scenarios: training from\nscratch and utilizing pre-training. Furthermore, our findings demonstrate that\npoint cloud observations often yield better policy performance and\nsignificantly stronger generalization capabilities across various geometric and\nvisual conditions. These outcomes suggest that the 3D point cloud is a valuable\nobservation modality for intricate robotic tasks. We also suggest that\nincorporating both appearance and coordinate information can enhance the\nperformance of point cloud methods. We hope our work provides valuable insights\nand guidance for designing more generalizable and robust robotic models. Codes\nare available at https://github.com/HaoyiZhu/PointCloudMatters.\n","authors":["Haoyi Zhu","Yating Wang","Di Huang","Weicai Ye","Wanli Ouyang","Tong He"],"pdf_url":"https://arxiv.org/pdf/2402.02500v3.pdf","comment":"38th Conference on Neural Information Processing Systems (NeurIPS\n  2024) Track on Datasets and Benchmarks"},{"id":"http://arxiv.org/abs/2410.16853v1","updated":"2024-10-22T09:37:29Z","published":"2024-10-22T09:37:29Z","title":"Bridging the Modality Gap: Dimension Information Alignment and Sparse\n  Spatial Constraint for Image-Text Matching","summary":"  Many contrastive learning based models have achieved advanced performance in\nimage-text matching tasks. The key of these models lies in analyzing the\ncorrelation between image-text pairs, which involves cross-modal interaction of\nembeddings in corresponding dimensions. However, the embeddings of different\nmodalities are from different models or modules, and there is a significant\nmodality gap. Directly interacting such embeddings lacks rationality and may\ncapture inaccurate correlation. Therefore, we propose a novel method called\nDIAS to bridge the modality gap from two aspects: (1) We align the information\nrepresentation of embeddings from different modalities in corresponding\ndimension to ensure the correlation calculation is based on interactions of\nsimilar information. (2) The spatial constraints of inter- and intra-modalities\nunmatched pairs are introduced to ensure the effectiveness of semantic\nalignment of the model. Besides, a sparse correlation algorithm is proposed to\nselect strong correlated spatial relationships, enabling the model to learn\nmore significant features and avoid being misled by weak correlation. Extensive\nexperiments demonstrate the superiority of DIAS, achieving 4.3\\%-10.2\\% rSum\nimprovements on Flickr30k and MSCOCO benchmarks.\n","authors":["Xiang Ma","Xuemei Li","Lexin Fang","Caiming Zhang"],"pdf_url":"https://arxiv.org/pdf/2410.16853v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2309.09534v2","updated":"2024-10-22T09:27:26Z","published":"2023-09-18T07:26:58Z","title":"Selective Volume Mixup for Video Action Recognition","summary":"  The recent advances in Convolutional Neural Networks (CNNs) and Vision\nTransformers have convincingly demonstrated high learning capability for video\naction recognition on large datasets. Nevertheless, deep models often suffer\nfrom the overfitting effect on small-scale datasets with a limited number of\ntraining videos. A common solution is to exploit the existing image\naugmentation strategies for each frame individually including Mixup, Cutmix,\nand RandAugment, which are not particularly optimized for video data. In this\npaper, we propose a novel video augmentation strategy named Selective Volume\nMixup (SV-Mix) to improve the generalization ability of deep models with\nlimited training videos. SV-Mix devises a learnable selective module to choose\nthe most informative volumes from two videos and mixes the volumes up to\nachieve a new training video. Technically, we propose two new modules, i.e., a\nspatial selective module to select the local patches for each spatial position,\nand a temporal selective module to mix the entire frames for each timestamp and\nmaintain the spatial pattern. At each time, we randomly choose one of the two\nmodules to expand the diversity of training samples. The selective modules are\njointly optimized with the video action recognition framework to find the\noptimal augmentation strategy. We empirically demonstrate the merits of the\nSV-Mix augmentation on a wide range of video action recognition benchmarks and\nconsistently boot the performances of both CNN-based and transformer-based\nmodels.\n","authors":["Yi Tan","Zhaofan Qiu","Yanbin Hao","Ting Yao","Tao Mei"],"pdf_url":"https://arxiv.org/pdf/2309.09534v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.16840v1","updated":"2024-10-22T09:20:03Z","published":"2024-10-22T09:20:03Z","title":"MPDS: A Movie Posters Dataset for Image Generation with Diffusion Model","summary":"  Movie posters are vital for captivating audiences, conveying themes, and\ndriving market competition in the film industry. While traditional designs are\nlaborious, intelligent generation technology offers efficiency gains and design\nenhancements. Despite exciting progress in image generation, current models\noften fall short in producing satisfactory poster results. The primary issue\nlies in the absence of specialized poster datasets for targeted model training.\nIn this work, we propose a Movie Posters DataSet (MPDS), tailored for\ntext-to-image generation models to revolutionize poster production. As\ndedicated to posters, MPDS stands out as the first image-text pair dataset to\nour knowledge, composing of 373k+ image-text pairs and 8k+ actor images\n(covering 4k+ actors). Detailed poster descriptions, such as movie titles,\ngenres, casts, and synopses, are meticulously organized and standardized based\non public movie synopsis, also named movie-synopsis prompt. To bolster poster\ndescriptions as well as reduce differences from movie synopsis, further, we\nleverage a large-scale vision-language model to automatically produce\nvision-perceptive prompts for each poster, then perform manual rectification\nand integration with movie-synopsis prompt. In addition, we introduce a prompt\nof poster captions to exhibit text elements in posters like actor names and\nmovie titles. For movie poster generation, we develop a multi-condition\ndiffusion framework that takes poster prompt, poster caption, and actor image\n(for personalization) as inputs, yielding excellent results through the\nlearning of a diffusion model. Experiments demonstrate the valuable role of our\nproposed MPDS dataset in advancing personalized movie poster generation. MPDS\nis available at https://anonymous.4open.science/r/MPDS-373k-BD3B.\n","authors":["Meng Xu","Tong Zhang","Fuyun Wang","Yi Lei","Xin Liu","Zhen Cui"],"pdf_url":"https://arxiv.org/pdf/2410.16840v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2405.15574v3","updated":"2024-10-22T09:05:30Z","published":"2024-05-24T14:04:03Z","title":"Meteor: Mamba-based Traversal of Rationale for Large Language and Vision\n  Models","summary":"  The rapid development of large language and vision models (LLVMs) has been\ndriven by advances in visual instruction tuning. Recently, open-source LLVMs\nhave curated high-quality visual instruction tuning datasets and utilized\nadditional vision encoders or multiple computer vision models in order to\nnarrow the performance gap with powerful closed-source LLVMs. These\nadvancements are attributed to multifaceted information required for diverse\ncapabilities, including fundamental image understanding, real-world knowledge\nabout common-sense and non-object concepts (e.g., charts, diagrams, symbols,\nsigns, and math problems), and step-by-step procedures for solving complex\nquestions. Drawing from the multifaceted information, we present a new\nefficient LLVM, Mamba-based traversal of rationales (Meteor), which leverages\nmultifaceted rationale to enhance understanding and answering capabilities. To\nembed lengthy rationales containing abundant information, we employ the Mamba\narchitecture, capable of processing sequential data with linear time\ncomplexity. We introduce a new concept of traversal of rationale that\nfacilitates efficient embedding of rationale. Subsequently, the backbone\nmultimodal language model (MLM) is trained to generate answers with the aid of\nrationale. Through these steps, Meteor achieves significant improvements in\nvision language performances across multiple evaluation benchmarks requiring\ndiverse capabilities, without scaling up the model size or employing additional\nvision encoders and computer vision models.\n","authors":["Byung-Kwan Lee","Chae Won Kim","Beomchan Park","Yong Man Ro"],"pdf_url":"https://arxiv.org/pdf/2405.15574v3.pdf","comment":"Code is available in https://github.com/ByungKwanLee/Meteor"},{"id":"http://arxiv.org/abs/2410.16824v1","updated":"2024-10-22T08:57:17Z","published":"2024-10-22T08:57:17Z","title":"PerspectiveNet: Multi-View Perception for Dynamic Scene Understanding","summary":"  Generating detailed descriptions from multiple cameras and viewpoints is\nchallenging due to the complex and inconsistent nature of visual data. In this\npaper, we introduce PerspectiveNet, a lightweight yet efficient model for\ngenerating long descriptions across multiple camera views. Our approach\nutilizes a vision encoder, a compact connector module to convert visual\nfeatures into a fixed-size tensor, and large language models (LLMs) to harness\nthe strong natural language generation capabilities of LLMs. The connector\nmodule is designed with three main goals: mapping visual features onto LLM\nembeddings, emphasizing key information needed for description generation, and\nproducing a fixed-size feature matrix. Additionally, we augment our solution\nwith a secondary task, the correct frame sequence detection, enabling the model\nto search for the correct sequence of frames to generate descriptions. Finally,\nwe integrate the connector module, the secondary task, the LLM, and a visual\nfeature extraction model into a single architecture, which is trained for the\nTraffic Safety Description and Analysis task. This task requires generating\ndetailed, fine-grained descriptions of events from multiple cameras and\nviewpoints. The resulting model is lightweight, ensuring efficient training and\ninference, while remaining highly effective.\n","authors":["Vinh Nguyen"],"pdf_url":"https://arxiv.org/pdf/2410.16824v1.pdf","comment":"6 pages, 2 figures"},{"id":"http://arxiv.org/abs/2405.20674v2","updated":"2024-10-22T08:50:16Z","published":"2024-05-31T08:18:39Z","title":"4Diffusion: Multi-view Video Diffusion Model for 4D Generation","summary":"  Current 4D generation methods have achieved noteworthy efficacy with the aid\nof advanced diffusion generative models. However, these methods lack multi-view\nspatial-temporal modeling and encounter challenges in integrating diverse prior\nknowledge from multiple diffusion models, resulting in inconsistent temporal\nappearance and flickers. In this paper, we propose a novel 4D generation\npipeline, namely 4Diffusion, aimed at generating spatial-temporally consistent\n4D content from a monocular video. We first design a unified diffusion model\ntailored for multi-view video generation by incorporating a learnable motion\nmodule into a frozen 3D-aware diffusion model to capture multi-view\nspatial-temporal correlations. After training on a curated dataset, our\ndiffusion model acquires reasonable temporal consistency and inherently\npreserves the generalizability and spatial consistency of the 3D-aware\ndiffusion model. Subsequently, we propose 4D-aware Score Distillation Sampling\nloss, which is based on our multi-view video diffusion model, to optimize 4D\nrepresentation parameterized by dynamic NeRF. This aims to eliminate\ndiscrepancies arising from multiple diffusion models, allowing for generating\nspatial-temporally consistent 4D content. Moreover, we devise an anchor loss to\nenhance the appearance details and facilitate the learning of dynamic NeRF.\nExtensive qualitative and quantitative experiments demonstrate that our method\nachieves superior performance compared to previous methods.\n","authors":["Haiyu Zhang","Xinyuan Chen","Yaohui Wang","Xihui Liu","Yunhong Wang","Yu Qiao"],"pdf_url":"https://arxiv.org/pdf/2405.20674v2.pdf","comment":"NeurIPS 2024. Project Page: https://aejion.github.io/4diffusion/"},{"id":"http://arxiv.org/abs/2410.16820v1","updated":"2024-10-22T08:48:41Z","published":"2024-10-22T08:48:41Z","title":"AttriPrompter: Auto-Prompting with Attribute Semantics for Zero-shot\n  Nuclei Detection via Visual-Language Pre-trained Models","summary":"  Large-scale visual-language pre-trained models (VLPMs) have demonstrated\nexceptional performance in downstream object detection through text prompts for\nnatural scenes. However, their application to zero-shot nuclei detection on\nhistopathology images remains relatively unexplored, mainly due to the\nsignificant gap between the characteristics of medical images and the\nweb-originated text-image pairs used for pre-training. This paper aims to\ninvestigate the potential of the object-level VLPM, Grounded Language-Image\nPre-training (GLIP), for zero-shot nuclei detection. Specifically, we propose\nan innovative auto-prompting pipeline, named AttriPrompter, comprising\nattribute generation, attribute augmentation, and relevance sorting, to avoid\nsubjective manual prompt design. AttriPrompter utilizes VLPMs' text-to-image\nalignment to create semantically rich text prompts, which are then fed into\nGLIP for initial zero-shot nuclei detection. Additionally, we propose a\nself-trained knowledge distillation framework, where GLIP serves as the teacher\nwith its initial predictions used as pseudo labels, to address the challenges\nposed by high nuclei density, including missed detections, false positives, and\noverlapping instances. Our method exhibits remarkable performance in label-free\nnuclei detection, outperforming all existing unsupervised methods and\ndemonstrating excellent generality. Notably, this work highlights the\nastonishing potential of VLPMs pre-trained on natural image-text pairs for\ndownstream tasks in the medical field as well. Code will be released at\nhttps://github.com/wuyongjianCODE/AttriPrompter.\n","authors":["Yongjian Wu","Yang Zhou","Jiya Saiyin","Bingzheng Wei","Maode Lai","Jianzhong Shou","Yan Xu"],"pdf_url":"https://arxiv.org/pdf/2410.16820v1.pdf","comment":"This article has been accepted for publication in a future issue of\n  IEEE Transactions on Medical Imaging (TMI), but has not been fully edited.\n  Content may change prior to final publication. Citation information: DOI:\n  https://doi.org/10.1109/TMI.2024.3473745 . Code:\n  https://github.com/wuyongjianCODE/AttriPrompter"},{"id":"http://arxiv.org/abs/2407.11965v2","updated":"2024-10-22T08:31:44Z","published":"2024-07-16T17:59:29Z","title":"UrbanWorld: An Urban World Model for 3D City Generation","summary":"  Cities, as the essential environment of human life, encompass diverse\nphysical elements such as buildings, roads and vegetation, which continuously\ninteract with dynamic entities like people and vehicles. Crafting realistic,\ninteractive 3D urban environments is essential for nurturing AGI systems and\nconstructing AI agents capable of perceiving, decision-making, and acting like\nhumans in real-world environments. However, creating high-fidelity 3D urban\nenvironments usually entails extensive manual labor from designers, involving\nintricate detailing and representation of complex urban elements. Therefore,\naccomplishing this automatically remains a longstanding challenge. Toward this\nproblem, we propose UrbanWorld, the first generative urban world model that can\nautomatically create a customized, realistic and interactive 3D urban world\nwith flexible control conditions. UrbanWorld incorporates four key stages in\nthe generation pipeline: flexible 3D layout generation from OSM data or urban\nlayout with semantic and height maps, urban scene design with Urban MLLM,\ncontrollable urban asset rendering via progressive 3D diffusion, and\nMLLM-assisted scene refinement. We conduct extensive quantitative analysis on\nfive visual metrics, demonstrating that UrbanWorld achieves SOTA generation\nrealism. Next, we provide qualitative results about the controllable generation\ncapabilities of UrbanWorld using both textual and image-based prompts. Lastly,\nwe verify the interactive nature of these environments by showcasing the agent\nperception and navigation within the created environments. We contribute\nUrbanWorld as an open-source tool available at\nhttps://github.com/Urban-World/UrbanWorld.\n","authors":["Yu Shang","Yuming Lin","Yu Zheng","Hangyu Fan","Jingtao Ding","Jie Feng","Jiansheng Chen","Li Tian","Yong Li"],"pdf_url":"https://arxiv.org/pdf/2407.11965v2.pdf","comment":"14 pages"},{"id":"http://arxiv.org/abs/2406.05723v2","updated":"2024-10-22T08:28:13Z","published":"2024-06-09T10:30:25Z","title":"Binarized Diffusion Model for Image Super-Resolution","summary":"  Advanced diffusion models (DMs) perform impressively in image\nsuper-resolution (SR), but the high memory and computational costs hinder their\ndeployment. Binarization, an ultra-compression algorithm, offers the potential\nfor effectively accelerating DMs. Nonetheless, due to the model structure and\nthe multi-step iterative attribute of DMs, existing binarization methods result\nin significant performance degradation. In this paper, we introduce a novel\nbinarized diffusion model, BI-DiffSR, for image SR. First, for the model\nstructure, we design a UNet architecture optimized for binarization. We propose\nthe consistent-pixel-downsample (CP-Down) and consistent-pixel-upsample (CP-Up)\nto maintain dimension consistent and facilitate the full-precision information\ntransfer. Meanwhile, we design the channel-shuffle-fusion (CS-Fusion) to\nenhance feature fusion in skip connection. Second, for the activation\ndifference across timestep, we design the timestep-aware redistribution (TaR)\nand activation function (TaA). The TaR and TaA dynamically adjust the\ndistribution of activations based on different timesteps, improving the\nflexibility and representation alability of the binarized module. Comprehensive\nexperiments demonstrate that our BI-DiffSR outperforms existing binarization\nmethods. Code is released at: https://github.com/zhengchen1999/BI-DiffSR.\n","authors":["Zheng Chen","Haotong Qin","Yong Guo","Xiongfei Su","Xin Yuan","Linghe Kong","Yulun Zhang"],"pdf_url":"https://arxiv.org/pdf/2406.05723v2.pdf","comment":"Accepted to NeurIPS 2024. Code is available at\n  https://github.com/zhengchen1999/BI-DiffSR"},{"id":"http://arxiv.org/abs/2410.16802v1","updated":"2024-10-22T08:27:43Z","published":"2024-10-22T08:27:43Z","title":"Evaluating the Effectiveness of Attack-Agnostic Features for Morphing\n  Attack Detection","summary":"  Morphing attacks have diversified significantly over the past years, with new\nmethods based on generative adversarial networks (GANs) and diffusion models\nposing substantial threats to face recognition systems. Recent research has\ndemonstrated the effectiveness of features extracted from large vision models\npretrained on bonafide data only (attack-agnostic features) for detecting deep\ngenerative images. Building on this, we investigate the potential of these\nimage representations for morphing attack detection (MAD). We develop\nsupervised detectors by training a simple binary linear SVM on the extracted\nfeatures and one-class detectors by modeling the distribution of bonafide\nfeatures with a Gaussian Mixture Model (GMM). Our method is evaluated across a\ncomprehensive set of attacks and various scenarios, including generalization to\nunseen attacks, different source datasets, and print-scan data. Our results\nindicate that attack-agnostic features can effectively detect morphing attacks,\noutperforming traditional supervised and one-class detectors from the\nliterature in most scenarios. Additionally, we provide insights into the\nstrengths and limitations of each considered representation and discuss\npotential future research directions to further enhance the robustness and\ngeneralizability of our approach.\n","authors":["Laurent Colbois","Sébastien Marcel"],"pdf_url":"https://arxiv.org/pdf/2410.16802v1.pdf","comment":"Published in the 2024 IEEE International Joint Conference on\n  Biometrics (IJCB)"},{"id":"http://arxiv.org/abs/2410.16794v1","updated":"2024-10-22T08:17:20Z","published":"2024-10-22T08:17:20Z","title":"One-Step Diffusion Distillation through Score Implicit Matching","summary":"  Despite their strong performances on many generative tasks, diffusion models\nrequire a large number of sampling steps in order to generate realistic\nsamples. This has motivated the community to develop effective methods to\ndistill pre-trained diffusion models into more efficient models, but these\nmethods still typically require few-step inference or perform substantially\nworse than the underlying model. In this paper, we present Score Implicit\nMatching (SIM) a new approach to distilling pre-trained diffusion models into\nsingle-step generator models, while maintaining almost the same sample\ngeneration ability as the original model as well as being data-free with no\nneed of training samples for distillation. The method rests upon the fact that,\nalthough the traditional score-based loss is intractable to minimize for\ngenerator models, under certain conditions we can efficiently compute the\ngradients for a wide class of score-based divergences between a diffusion model\nand a generator. SIM shows strong empirical performances for one-step\ngenerators: on the CIFAR10 dataset, it achieves an FID of 2.06 for\nunconditional generation and 1.96 for class-conditional generation. Moreover,\nby applying SIM to a leading transformer-based diffusion model, we distill a\nsingle-step generator for text-to-image (T2I) generation that attains an\naesthetic score of 6.42 with no performance decline over the original\nmulti-step counterpart, clearly outperforming the other one-step generators\nincluding SDXL-TURBO of 5.33, SDXL-LIGHTNING of 5.34 and HYPER-SDXL of 5.85. We\nwill release this industry-ready one-step transformer-based T2I generator along\nwith this paper.\n","authors":["Weijian Luo","Zemin Huang","Zhengyang Geng","J. Zico Kolter","Guo-jun Qi"],"pdf_url":"https://arxiv.org/pdf/2410.16794v1.pdf","comment":"Accepted by NeurIPS 2024"},{"id":"http://arxiv.org/abs/2406.00432v2","updated":"2024-10-22T07:59:51Z","published":"2024-06-01T13:10:43Z","title":"Localize, Understand, Collaborate: Semantic-Aware Dragging via Intention\n  Reasoner","summary":"  Flexible and accurate drag-based editing is a challenging task that has\nrecently garnered significant attention. Current methods typically model this\nproblem as automatically learning \"how to drag\" through point dragging and\noften produce one deterministic estimation, which presents two key limitations:\n1) Overlooking the inherently ill-posed nature of drag-based editing, where\nmultiple results may correspond to a given input, as illustrated in Fig.1; 2)\nIgnoring the constraint of image quality, which may lead to unexpected\ndistortion. To alleviate this, we propose LucidDrag, which shifts the focus\nfrom \"how to drag\" to \"what-then-how\" paradigm. LucidDrag comprises an\nintention reasoner and a collaborative guidance sampling mechanism. The former\ninfers several optimal editing strategies, identifying what content and what\nsemantic direction to be edited. Based on the former, the latter addresses \"how\nto drag\" by collaboratively integrating existing editing guidance with the\nnewly proposed semantic guidance and quality guidance. Specifically, semantic\nguidance is derived by establishing a semantic editing direction based on\nreasoned intentions, while quality guidance is achieved through classifier\nguidance using an image fidelity discriminator. Both qualitative and\nquantitative comparisons demonstrate the superiority of LucidDrag over previous\nmethods.\n","authors":["Xing Cui","Peipei Li","Zekun Li","Xuannan Liu","Yueying Zou","Zhaofeng He"],"pdf_url":"https://arxiv.org/pdf/2406.00432v2.pdf","comment":"Accepted by NeurIPS 2024"},{"id":"http://arxiv.org/abs/2406.12214v3","updated":"2024-10-22T07:58:01Z","published":"2024-06-18T02:28:02Z","title":"Is Your HD Map Constructor Reliable under Sensor Corruptions?","summary":"  Driving systems often rely on high-definition (HD) maps for precise\nenvironmental information, which is crucial for planning and navigation. While\ncurrent HD map constructors perform well under ideal conditions, their\nresilience to real-world challenges, \\eg, adverse weather and sensor failures,\nis not well understood, raising safety concerns. This work introduces MapBench,\nthe first comprehensive benchmark designed to evaluate the robustness of HD map\nconstruction methods against various sensor corruptions. Our benchmark\nencompasses a total of 29 types of corruptions that occur from cameras and\nLiDAR sensors. Extensive evaluations across 31 HD map constructors reveal\nsignificant performance degradation of existing methods under adverse weather\nconditions and sensor failures, underscoring critical safety concerns. We\nidentify effective strategies for enhancing robustness, including innovative\napproaches that leverage multi-modal fusion, advanced data augmentation, and\narchitectural techniques. These insights provide a pathway for developing more\nreliable HD map construction methods, which are essential for the advancement\nof autonomous driving technology. The benchmark toolkit and affiliated code and\nmodel checkpoints have been made publicly accessible.\n","authors":["Xiaoshuai Hao","Mengchuan Wei","Yifan Yang","Haimei Zhao","Hui Zhang","Yi Zhou","Qiang Wang","Weiming Li","Lingdong Kong","Jing Zhang"],"pdf_url":"https://arxiv.org/pdf/2406.12214v3.pdf","comment":"NeurIPS 2024; 40 pages, 17 figures, 23 tables; Code at\n  https://mapbench.github.io/"},{"id":"http://arxiv.org/abs/2211.12702v2","updated":"2024-10-22T07:57:55Z","published":"2022-11-23T04:48:49Z","title":"Evaluating Feature Attribution Methods for Electrocardiogram","summary":"  The performance of cardiac arrhythmia detection with electrocardiograms(ECGs)\nhas been considerably improved since the introduction of deep learning models.\nIn practice, the high performance alone is not sufficient and a proper\nexplanation is also required. Recently, researchers have started adopting\nfeature attribution methods to address this requirement, but it has been\nunclear which of the methods are appropriate for ECG. In this work, we identify\nand customize three evaluation metrics for feature attribution methods based on\nthe characteristics of ECG: localization score, pointing game, and degradation\nscore. Using the three evaluation metrics, we evaluate and analyze eleven\nwidely-used feature attribution methods. We find that some of the feature\nattribution methods are much more adequate for explaining ECG, where Grad-CAM\noutperforms the second-best method by a large margin.\n","authors":["Jangwon Suh","Jimyeong Kim","Euna Jung","Wonjong Rhee"],"pdf_url":"https://arxiv.org/pdf/2211.12702v2.pdf","comment":"This is preliminary research related to\n  https://www.sciencedirect.com/science/article/pii/S0010482524011739 . Code is\n  available at https://github.com/SNU-DRL/Attribution-ECG"},{"id":"http://arxiv.org/abs/2408.10787v3","updated":"2024-10-22T07:51:43Z","published":"2024-08-20T12:27:53Z","title":"A Lightweight Modular Framework for Low-Cost Open-Vocabulary Object\n  Detection Training","summary":"  Object detection is a fundamental challenge in computer vision, centered on\nrecognizing objects within images, with diverse applications in areas like\nimage analysis, robotics, and autonomous vehicles. Although existing methods\nhave achieved great success, they are often constrained by a fixed vocabulary\nof objects. To overcome this limitation, approaches like MDETR have redefined\nobject detection by incorporating region-level vision-language pre-training,\nenabling open-vocabulary object detectors. However, these methods are\ncomputationally heavy due to the simultaneous training of large models for both\nvision and language representations. To address this, we introduce a\nlightweight framework that significantly reduces the number of parameters while\npreserving, or even improving, performance. Our solution is applied to MDETR,\nresulting in the development of Lightweight MDETR (LightMDETR), an optimized\nversion of MDETR designed to enhance computational efficiency without\nsacrificing accuracy. The core of our approach involves freezing the MDETR\nbackbone and training only the Universal Projection module (UP), which bridges\nvision and language representations. A learnable modality token parameter\nallows the UP to seamlessly switch between modalities. Evaluations on tasks\nlike phrase grounding, referring expression comprehension, and segmentation\nshow that LightMDETR not only reduces computational costs but also outperforms\nseveral state-of-the-art methods in terms of accuracy.\n","authors":["Bilal Faye","Binta Sow","Hanane Azzag","Mustapha Lebbah"],"pdf_url":"https://arxiv.org/pdf/2408.10787v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.16770v1","updated":"2024-10-22T07:40:20Z","published":"2024-10-22T07:40:20Z","title":"The Scene Language: Representing Scenes with Programs, Words, and\n  Embeddings","summary":"  We introduce the Scene Language, a visual scene representation that concisely\nand precisely describes the structure, semantics, and identity of visual\nscenes. It represents a scene with three key components: a program that\nspecifies the hierarchical and relational structure of entities in the scene,\nwords in natural language that summarize the semantic class of each entity, and\nembeddings that capture the visual identity of each entity. This representation\ncan be inferred from pre-trained language models via a training-free inference\ntechnique, given text or image inputs. The resulting scene can be rendered into\nimages using traditional, neural, or hybrid graphics renderers. Together, this\nforms a robust, automated system for high-quality 3D and 4D scene generation.\nCompared with existing representations like scene graphs, our proposed Scene\nLanguage generates complex scenes with higher fidelity, while explicitly\nmodeling the scene structures to enable precise control and editing.\n","authors":["Yunzhi Zhang","Zizhang Li","Matt Zhou","Shangzhe Wu","Jiajun Wu"],"pdf_url":"https://arxiv.org/pdf/2410.16770v1.pdf","comment":"Project page:\n  https://ai.stanford.edu/~yzzhang/projects/scene-language/"},{"id":"http://arxiv.org/abs/2004.04454v2","updated":"2024-10-22T07:40:17Z","published":"2020-04-09T09:52:49Z","title":"TensorProjection Layer: A Tensor-Based Dimension Reduction Method in\n  Deep Neural Networks","summary":"  In this paper, we propose a dimension reduction method specifically designed\nfor tensor-structured feature data in deep neural networks. The method is\nimplemented as a hidden layer, called the TensorProjection layer, which\ntransforms input tensors into output tensors with reduced dimensions through\nmode-wise projections. The projection directions are treated as model\nparameters of the layer and are optimized during model training. Our method can\nserve as an alternative to pooling layers for summarizing image data, or to\nconvolutional layers as a technique for reducing the number of channels. We\nconduct experiments on tasks such as medical image classification and\nsegmentation, integrating the TensorProjection layer into commonly used\nbaseline architectures to evaluate its effectiveness. Numerical experiments\nindicate that the proposed method can outperform traditional downsampling\nmethods, such as pooling layers, in our tasks, suggesting it as a promising\nalternative for feature summarization.\n","authors":["Toshinari Morimoto","Su-Yun Huang"],"pdf_url":"https://arxiv.org/pdf/2004.04454v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.16769v1","updated":"2024-10-22T07:37:47Z","published":"2024-10-22T07:37:47Z","title":"DSORT-MCU: Detecting Small Objects in Real-Time on Microcontroller Units","summary":"  Advances in lightweight neural networks have revolutionized computer vision\nin a broad range of IoT applications, encompassing remote monitoring and\nprocess automation. However, the detection of small objects, which is crucial\nfor many of these applications, remains an underexplored area in current\ncomputer vision research, particularly for low-power embedded devices that host\nresource-constrained processors. To address said gap, this paper proposes an\nadaptive tiling method for lightweight and energy-efficient object detection\nnetworks, including YOLO-based models and the popular FOMO network. The\nproposed tiling enables object detection on low-power MCUs with no compromise\non accuracy compared to large-scale detection models. The benefit of the\nproposed method is demonstrated by applying it to FOMO and TinyissimoYOLO\nnetworks on a novel RISC-V-based MCU with built-in ML accelerators. Extensive\nexperimental results show that the proposed tiling method boosts the F1-score\nby up to 225% for both FOMO and TinyissimoYOLO networks while reducing the\naverage object count error by up to 76% with FOMO and up to 89% for\nTinyissimoYOLO. Furthermore, the findings of this work indicate that using a\nsoft F1 loss over the popular binary cross-entropy loss can serve as an\nimplicit non-maximum suppression for the FOMO network. To evaluate the\nreal-world performance, the networks are deployed on the RISC-V based GAP9\nmicrocontroller from GreenWaves Technologies, showcasing the proposed method's\nability to strike a balance between detection performance ($58% - 95%$ F1\nscore), low latency (0.6 ms/Inference - 16.2 ms/Inference}), and energy\nefficiency (31 uJ/Inference} - 1.27 mJ/Inference) while performing multiple\npredictions using high-resolution images on a MCU.\n","authors":["Liam Boyle","Julian Moosmann","Nicolas Baumann","Seonyeong Heo","Michele Magno"],"pdf_url":"https://arxiv.org/pdf/2410.16769v1.pdf","comment":"arXiv admin note: text overlap with arXiv:2311.07163"},{"id":"http://arxiv.org/abs/2306.16759v3","updated":"2024-10-22T07:29:07Z","published":"2023-06-29T07:55:43Z","title":"Boosting the Generalization Ability for Hyperspectral Image\n  Classification using Spectral-spatial Axial Aggregation Transformer","summary":"  In the hyperspectral image classification (HSIC) task, the most commonly used\nmodel validation paradigm is partitioning the training-test dataset through\npixel-wise random sampling. By training on a small amount of data, the deep\nlearning model can achieve almost perfect accuracy. However, in our\nexperiments, we found that the high accuracy was reached because the training\nand test datasets share a lot of information. On non-overlapping dataset\npartitions, well-performing models suffer significant performance degradation.\nTo this end, we propose a spectral-spatial axial aggregation transformer model,\nnamely SaaFormer, that preserves generalization across dataset partitions.\nSaaFormer applies a multi-level spectral extraction structure to segment the\nspectrum into multiple spectrum clips, such that the wavelength continuity of\nthe spectrum across the channel are preserved. For each spectrum clip, the\naxial aggregation attention mechanism, which integrates spatial features along\nmultiple spectral axes is applied to mine the spectral characteristic. The\nmulti-level spectral extraction and the axial aggregation attention emphasize\nspectral characteristic to improve the model generalization. The experimental\nresults on five publicly available datasets demonstrate that our model exhibits\ncomparable performance on the random partition, while significantly\noutperforming other methods on non-overlapping partitions. Moreover, SaaFormer\nshows excellent performance on background classification.\n","authors":["Enzhe Zhao","Zhichang Guo","Shengzhu Shi","Yao Li","Jia Li","Dazhi Zhang"],"pdf_url":"https://arxiv.org/pdf/2306.16759v3.pdf","comment":"arXiv admin note: text overlap with arXiv:2107.02988 by other authors"},{"id":"http://arxiv.org/abs/2410.04183v2","updated":"2024-10-22T07:24:05Z","published":"2024-10-05T14:57:52Z","title":"Unsupervised Assessment of Landscape Shifts Based on Persistent Entropy\n  and Topological Preservation","summary":"  In Continual Learning (CL) contexts, concept drift typically refers to the\nanalysis of changes in data distribution. A drift in the input data can have\nnegative consequences on a learning predictor and the system's stability. The\nmajority of concept drift methods emphasize the analysis of statistical changes\nin non-stationary data over time. In this context, we consider another\nperspective, where the concept drift also integrates substantial changes in the\ntopological characteristics of the data stream. In this article, we introduce a\nnovel framework for monitoring changes in multi-dimensional data streams. We\nexplore variations in the topological structures of the data, presenting\nanother angle on the standard concept drift. Our developed approach is based on\npersistent entropy and topology-preserving projections in a continual learning\nscenario. The framework operates in both unsupervised and supervised\nenvironments. To show the utility of the proposed framework, we analyze the\nmodel across three scenarios using data streams generated with MNIST samples.\nThe obtained results reveal the potential of applying topological data analysis\nfor shift detection and encourage further research in this area.\n","authors":["Sebastian Basterrech"],"pdf_url":"https://arxiv.org/pdf/2410.04183v2.pdf","comment":"KDD'2024. Workshop on Drift Detection and Landscape Shifts"},{"id":"http://arxiv.org/abs/2401.06960v2","updated":"2024-10-22T07:17:47Z","published":"2024-01-13T03:17:57Z","title":"Transformer for Object Re-Identification: A Survey","summary":"  Object Re-identification (Re-ID) aims to identify specific objects across\ndifferent times and scenes, which is a widely researched task in computer\nvision. For a prolonged period, this field has been predominantly driven by\ndeep learning technology based on convolutional neural networks. In recent\nyears, the emergence of Vision Transformers has spurred a growing number of\nstudies delving deeper into Transformer-based Re-ID, continuously breaking\nperformance records and witnessing significant progress in the Re-ID field.\nOffering a powerful, flexible, and unified solution, Transformers cater to a\nwide array of Re-ID tasks with unparalleled efficacy. This paper provides a\ncomprehensive review and in-depth analysis of the Transformer-based Re-ID. In\ncategorizing existing works into Image/Video-Based Re-ID, Re-ID with limited\ndata/annotations, Cross-Modal Re-ID, and Special Re-ID Scenarios, we thoroughly\nelucidate the advantages demonstrated by the Transformer in addressing a\nmultitude of challenges across these domains. Considering the trending\nunsupervised Re-ID, we propose a new Transformer baseline, UntransReID,\nachieving state-of-the-art performance on both single/cross modal tasks. For\nthe under-explored animal Re-ID, we devise a standardized experimental\nbenchmark and conduct extensive experiments to explore the applicability of\nTransformer for this task and facilitate future research. Finally, we discuss\nsome important yet under-investigated open issues in the large foundation model\nera, we believe it will serve as a new handbook for researchers in this field.\nA periodically updated website will be available at\nhttps://github.com/mangye16/ReID-Survey.\n","authors":["Mang Ye","Shuoyi Chen","Chenyue Li","Wei-Shi Zheng","David Crandall","Bo Du"],"pdf_url":"https://arxiv.org/pdf/2401.06960v2.pdf","comment":"Accepted by International Journal of Computer Vision (IJCV) in\n  October 2024"},{"id":"http://arxiv.org/abs/2410.16746v1","updated":"2024-10-22T07:00:43Z","published":"2024-10-22T07:00:43Z","title":"SpikMamba: When SNN meets Mamba in Event-based Human Action Recognition","summary":"  Human action recognition (HAR) plays a key role in various applications such\nas video analysis, surveillance, autonomous driving, robotics, and healthcare.\nMost HAR algorithms are developed from RGB images, which capture detailed\nvisual information. However, these algorithms raise concerns in\nprivacy-sensitive environments due to the recording of identifiable features.\nEvent cameras offer a promising solution by capturing scene brightness changes\nsparsely at the pixel level, without capturing full images. Moreover, event\ncameras have high dynamic ranges that can effectively handle scenarios with\ncomplex lighting conditions, such as low light or high contrast environments.\nHowever, using event cameras introduces challenges in modeling the spatially\nsparse and high temporal resolution event data for HAR. To address these\nissues, we propose the SpikMamba framework, which combines the energy\nefficiency of spiking neural networks and the long sequence modeling capability\nof Mamba to efficiently capture global features from spatially sparse and high\na temporal resolution event data. Additionally, to improve the locality of\nmodeling, a spiking window-based linear attention mechanism is used. Extensive\nexperiments show that SpikMamba achieves remarkable recognition performance,\nsurpassing the previous state-of-the-art by 1.45%, 7.22%, 0.15%, and 3.92% on\nthe PAF, HARDVS, DVS128, and E-FAction datasets, respectively. The code is\navailable at https://github.com/Typistchen/SpikMamba.\n","authors":["Jiaqi Chen","Yan Yang","Shizhuo Deng","Da Teng","Liyuan Pan"],"pdf_url":"https://arxiv.org/pdf/2410.16746v1.pdf","comment":"8 pages, 4 figures"},{"id":"http://arxiv.org/abs/2410.16744v1","updated":"2024-10-22T06:58:37Z","published":"2024-10-22T06:58:37Z","title":"Time-Resolved MNIST Dataset for Single-Photon Recognition","summary":"  Time-resolved single photon imaging is a promising imaging modality\ncharacterized by the unique capability of timestamping the arrivals of single\nphotons. Single-Photon Avalanche Diodes (SPADs) are the leading technology for\nimplementing modern time-resolved pixels, suitable for passive imaging with\nasynchronous readout. However, they are currently limited to small sized\narrays, thus there is a lack of datasets for passive time-resolved SPAD\nimaging, which in turn hinders research on this peculiar imaging data. In this\npaper we describe a realistic simulation process for SPAD imaging, which takes\ninto account both the stochastic nature of photon arrivals and all the noise\nsources involved in the acquisition process of time-resolved SPAD arrays. We\nhave implemented this simulator in a software prototype able to generate\narbitrary-sized time-resolved SPAD arrays operating in passive mode. Starting\nfrom a reference image, our simulator generates a realistic stream of\ntimestamped photon detections. We use our simulator to generate a time-resolved\nversion of MNIST, which we make publicly available. Our dataset has the purpose\nof encouraging novel research directions in time-resolved SPAD imaging, as well\nas investigating the performance of CNN classifiers in extremely low-light\nconditions.\n","authors":["Aleksi Suonsivu","Lauri Salmela","Edoardo Peretti","Leevi Uosukainen","Radu Ciprian Bilcu","Giacomo Boracchi"],"pdf_url":"https://arxiv.org/pdf/2410.16744v1.pdf","comment":"12 pages, 4 figures. Accepted for Workshop on Synthetic Data for\n  Computer Vision at ECCV 2024"},{"id":"http://arxiv.org/abs/2212.04681v3","updated":"2024-10-22T06:56:00Z","published":"2022-12-09T06:06:47Z","title":"Dynamic Test-Time Augmentation via Differentiable Functions","summary":"  Distribution shifts, which often occur in the real world, degrade the\naccuracy of deep learning systems, and thus improving robustness to\ndistribution shifts is essential for practical applications. To improve\nrobustness, we study an image enhancement method that generates\nrecognition-friendly images without retraining the recognition model. We\npropose a novel image enhancement method, DynTTA, which is based on\ndifferentiable data augmentation techniques and generates a blended image from\nmany augmented images to improve the recognition accuracy under distribution\nshifts. In addition to standard data augmentations, DynTTA also incorporates\ndeep neural network-based image transformation, further improving the\nrobustness. Because DynTTA is composed of differentiable functions, it can be\ndirectly trained with the classification loss of the recognition model. In\nexperiments with widely used image recognition datasets using various\nclassification models, DynTTA improves the robustness with almost no reduction\nin classification accuracy for clean images, thus outperforming the existing\nmethods. Furthermore, the results show that robustness is significantly\nimproved by estimating the training-time augmentations for distribution-shifted\ndatasets using DynTTA and retraining the recognition model with the estimated\naugmentations. DynTTA is a promising approach for applications that require\nboth clean accuracy and robustness. Our code is available at\n\\url{https://github.com/s-enmt/DynTTA}.\n","authors":["Shohei Enomoto","Monikka Roslianna Busto","Takeharu Eda"],"pdf_url":"https://arxiv.org/pdf/2212.04681v3.pdf","comment":"IEEE Access"},{"id":"http://arxiv.org/abs/2407.11664v2","updated":"2024-10-22T06:41:38Z","published":"2024-07-16T12:36:26Z","title":"Mask-guided cross-image attention for zero-shot in-silico\n  histopathologic image generation with a diffusion model","summary":"  Creating in-silico data with generative AI promises a cost-effective\nalternative to staining, imaging, and annotating whole slide images in\ncomputational pathology. Diffusion models are the state-of-the-art solution for\ngenerating in-silico images, offering unparalleled fidelity and realism. Using\nappearance transfer diffusion models allows for zero-shot image generation,\nfacilitating fast application and making model training unnecessary. However\ncurrent appearance transfer diffusion models are designed for natural images,\nwhere the main task is to transfer the foreground object from an origin to a\ntarget domain, while the background is of insignificant importance. In\ncomputational pathology, specifically in oncology, it is however not\nstraightforward to define which objects in an image should be classified as\nforeground and background, as all objects in an image may be of critical\nimportance for the detailed understanding the tumor micro-environment. We\ncontribute to the applicability of appearance transfer diffusion models to\nimmunohistochemistry-stained images by modifying the appearance transfer\nguidance to alternate between class-specific AdaIN feature statistics matchings\nusing existing segmentation masks. The performance of the proposed method is\ndemonstrated on the downstream task of supervised epithelium segmentation,\nshowing that the number of manual annotations required for model training can\nbe reduced by 75%, outperforming the baseline approach. Additionally, we\nconsulted with a certified pathologist to investigate future improvements. We\nanticipate this work to inspire the application of zero-shot diffusion models\nin computational pathology, providing an efficient method to generate in-silico\nimages with unmatched fidelity and realism, which prove meaningful for\ndownstream tasks, such as training existing deep learning models or finetuning\nfoundation models.\n","authors":["Dominik Winter","Nicolas Triltsch","Marco Rosati","Anatoliy Shumilov","Ziya Kokaragac","Yuri Popov","Thomas Padel","Laura Sebastian Monasor","Ross Hill","Markus Schick","Nicolas Brieu"],"pdf_url":"https://arxiv.org/pdf/2407.11664v2.pdf","comment":"5 pages"},{"id":"http://arxiv.org/abs/2410.16732v1","updated":"2024-10-22T06:30:37Z","published":"2024-10-22T06:30:37Z","title":"Polyp-E: Benchmarking the Robustness of Deep Segmentation Models via\n  Polyp Editing","summary":"  Automatic polyp segmentation is helpful to assist clinical diagnosis and\ntreatment. In daily clinical practice, clinicians exhibit robustness in\nidentifying polyps with both location and size variations. It is uncertain if\ndeep segmentation models can achieve comparable robustness in automated\ncolonoscopic analysis. To benchmark the model robustness, we focus on\nevaluating the robustness of segmentation models on the polyps with various\nattributes (e.g. location and size) and healthy samples. Based on the Latent\nDiffusion Model, we perform attribute editing on real polyps and build a new\ndataset named Polyp-E. Our synthetic dataset boasts exceptional realism, to the\nextent that clinical experts find it challenging to discern them from real\ndata. We evaluate several existing polyp segmentation models on the proposed\nbenchmark. The results reveal most of the models are highly sensitive to\nattribute variations. As a novel data augmentation technique, the proposed\nediting pipeline can improve both in-distribution and out-of-distribution\ngeneralization ability. The code and datasets will be released.\n","authors":["Runpu Wei","Zijin Yin","Kongming Liang","Min Min","Chengwei Pan","Gang Yu","Haonan Huang","Yan Liu","Zhanyu Ma"],"pdf_url":"https://arxiv.org/pdf/2410.16732v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.16719v1","updated":"2024-10-22T05:59:29Z","published":"2024-10-22T05:59:29Z","title":"Progressive Compositionality In Text-to-Image Generative Models","summary":"  Despite the impressive text-to-image (T2I) synthesis capabilities of\ndiffusion models, they often struggle to understand compositional relationships\nbetween objects and attributes, especially in complex settings. Existing\nsolutions have tackled these challenges by optimizing the cross-attention\nmechanism or learning from the caption pairs with minimal semantic changes.\nHowever, can we generate high-quality complex contrastive images that diffusion\nmodels can directly discriminate based on visual representations? In this work,\nwe leverage large-language models (LLMs) to compose realistic, complex\nscenarios and harness Visual-Question Answering (VQA) systems alongside\ndiffusion models to automatically curate a contrastive dataset, ConPair,\nconsisting of 15k pairs of high-quality contrastive images. These pairs feature\nminimal visual discrepancies and cover a wide range of attribute categories,\nespecially complex and natural scenarios. To learn effectively from these error\ncases, i.e., hard negative images, we propose EvoGen, a new multi-stage\ncurriculum for contrastive learning of diffusion models. Through extensive\nexperiments across a wide range of compositional scenarios, we showcase the\neffectiveness of our proposed framework on compositional T2I benchmarks.\n","authors":["Xu Han","Linghao Jin","Xiaofeng Liu","Paul Pu Liang"],"pdf_url":"https://arxiv.org/pdf/2410.16719v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.16711v1","updated":"2024-10-22T05:37:51Z","published":"2024-10-22T05:37:51Z","title":"Development of CNN Architectures using Transfer Learning Methods for\n  Medical Image Classification","summary":"  The application of deep learning-based architecture has seen a tremendous\nrise in recent years. For example, medical image classification using deep\nlearning achieved breakthrough results. Convolutional Neural Networks (CNNs)\nare implemented predominantly in medical image classification and segmentation.\nOn the other hand, transfer learning has emerged as a prominent supporting tool\nfor enhancing the efficiency and accuracy of deep learning models. This paper\ninvestigates the development of CNN architectures using transfer learning\ntechniques in the field of medical image classification using a timeline\nmapping model for key image classification challenges. Our findings help make\nan informed decision while selecting the optimum and state-of-the-art CNN\narchitectures.\n","authors":["Ganga Prasad Basyal","David Zeng","Bhaskar Pm Rimal"],"pdf_url":"https://arxiv.org/pdf/2410.16711v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.16707v1","updated":"2024-10-22T05:22:49Z","published":"2024-10-22T05:22:49Z","title":"DI-MaskDINO: A Joint Object Detection and Instance Segmentation Model","summary":"  This paper is motivated by an interesting phenomenon: the performance of\nobject detection lags behind that of instance segmentation (i.e., performance\nimbalance) when investigating the intermediate results from the beginning\ntransformer decoder layer of MaskDINO (i.e., the SOTA model for joint detection\nand segmentation). This phenomenon inspires us to think about a question: will\nthe performance imbalance at the beginning layer of transformer decoder\nconstrain the upper bound of the final performance? With this question in mind,\nwe further conduct qualitative and quantitative pre-experiments, which validate\nthe negative impact of detection-segmentation imbalance issue on the model\nperformance. To address this issue, this paper proposes DI-MaskDINO model, the\ncore idea of which is to improve the final performance by alleviating the\ndetection-segmentation imbalance. DI-MaskDINO is implemented by configuring our\nproposed De-Imbalance (DI) module and Balance-Aware Tokens Optimization (BATO)\nmodule to MaskDINO. DI is responsible for generating balance-aware query, and\nBATO uses the balance-aware query to guide the optimization of the initial\nfeature tokens. The balance-aware query and optimized feature tokens are\nrespectively taken as the Query and Key&Value of transformer decoder to perform\njoint object detection and instance segmentation. DI-MaskDINO outperforms\nexisting joint object detection and instance segmentation models on COCO and\nBDD100K benchmarks, achieving +1.2 $AP^{box}$ and +0.9 $AP^{mask}$ improvements\ncompared to SOTA joint detection and segmentation model MaskDINO. In addition,\nDI-MaskDINO also obtains +1.0 $AP^{box}$ improvement compared to SOTA object\ndetection model DINO and +3.0 $AP^{mask}$ improvement compared to SOTA\nsegmentation model Mask2Former.\n","authors":["Zhixiong Nan","Xianghong Li","Tao Xiang","Jifeng Dai"],"pdf_url":"https://arxiv.org/pdf/2410.16707v1.pdf","comment":"16 pages, 3 figures, Conference on Neural Information Processing\n  Systems"},{"id":"http://arxiv.org/abs/2410.16695v1","updated":"2024-10-22T04:57:28Z","published":"2024-10-22T04:57:28Z","title":"MPT: A Large-scale Multi-Phytoplankton Tracking Benchmark","summary":"  Phytoplankton are a crucial component of aquatic ecosystems, and effective\nmonitoring of them can provide valuable insights into ocean environments and\necosystem changes. Traditional phytoplankton monitoring methods are often\ncomplex and lack timely analysis. Therefore, deep learning algorithms offer a\npromising approach for automated phytoplankton monitoring. However, the lack of\nlarge-scale, high-quality training samples has become a major bottleneck in\nadvancing phytoplankton tracking. In this paper, we propose a challenging\nbenchmark dataset, Multiple Phytoplankton Tracking (MPT), which covers diverse\nbackground information and variations in motion during observation. The dataset\nincludes 27 species of phytoplankton and zooplankton, 14 different backgrounds\nto simulate diverse and complex underwater environments, and a total of 140\nvideos. To enable accurate real-time observation of phytoplankton, we introduce\na multi-object tracking method, Deviation-Corrected Multi-Scale Feature Fusion\nTracker(DSFT), which addresses issues such as focus shifts during tracking and\nthe loss of small target information when computing frame-to-frame similarity.\nSpecifically, we introduce an additional feature extractor to predict the\nresiduals of the standard feature extractor's output, and compute multi-scale\nframe-to-frame similarity based on features from different layers of the\nextractor. Extensive experiments on the MPT have demonstrated the validity of\nthe dataset and the superiority of DSFT in tracking phytoplankton, providing an\neffective solution for phytoplankton monitoring.\n","authors":["Yang Yu","Yuezun Li","Xin Sun","Junyu Dong"],"pdf_url":"https://arxiv.org/pdf/2410.16695v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.05338v6","updated":"2024-10-22T04:22:16Z","published":"2024-06-08T03:44:25Z","title":"MotionClone: Training-Free Motion Cloning for Controllable Video\n  Generation","summary":"  Motion-based controllable video generation offers the potential for creating\ncaptivating visual content. Existing methods typically necessitate model\ntraining to encode particular motion cues or incorporate fine-tuning to inject\ncertain motion patterns, resulting in limited flexibility and generalization.\nIn this work, we propose MotionClone, a training-free framework that enables\nmotion cloning from reference videos to versatile motion-controlled video\ngeneration, including text-to-video and image-to-video. Based on the\nobservation that the dominant components in temporal-attention maps drive\nmotion synthesis, while the rest mainly capture noisy or very subtle motions,\nMotionClone utilizes sparse temporal attention weights as motion\nrepresentations for motion guidance, facilitating diverse motion transfer\nacross varying scenarios. Meanwhile, MotionClone allows for the direct\nextraction of motion representation through a single denoising step, bypassing\nthe cumbersome inversion processes and thus promoting both efficiency and\nflexibility. Extensive experiments demonstrate that MotionClone exhibits\nproficiency in both global camera motion and local object motion, with notable\nsuperiority in terms of motion fidelity, textual alignment, and temporal\nconsistency.\n","authors":["Pengyang Ling","Jiazi Bu","Pan Zhang","Xiaoyi Dong","Yuhang Zang","Tong Wu","Huaian Chen","Jiaqi Wang","Yi Jin"],"pdf_url":"https://arxiv.org/pdf/2406.05338v6.pdf","comment":"18 pages, 14 figures,\n  https://bujiazi.github.io/motionclone.github.io/"},{"id":"http://arxiv.org/abs/2410.16671v1","updated":"2024-10-22T04:03:36Z","published":"2024-10-22T04:03:36Z","title":"NucleiMix: Realistic Data Augmentation for Nuclei Instance Segmentation","summary":"  Nuclei instance segmentation is an essential task in pathology image\nanalysis, serving as the foundation for many downstream applications. The\nrelease of several public datasets has significantly advanced research in this\narea, yet many existing methods struggle with data imbalance issues. To address\nthis challenge, this study introduces a data augmentation method, called\nNucleiMix, which is designed to balance the distribution of nuclei types by\nincreasing the number of rare-type nuclei within datasets. NucleiMix operates\nin two phases. In the first phase, it identifies candidate locations similar to\nthe surroundings of rare-type nuclei and inserts rare-type nuclei into the\ncandidate locations. In the second phase, it employs a progressive inpainting\nstrategy using a pre-trained diffusion model to seamlessly integrate rare-type\nnuclei into their new environments in replacement of major-type nuclei or\nbackground locations. We systematically evaluate the effectiveness of NucleiMix\non three public datasets using two popular nuclei instance segmentation models.\nThe results demonstrate the superior ability of NucleiMix to synthesize\nrealistic rare-type nuclei and to enhance the quality of nuclei segmentation\nand classification in an accurate and robust manner.\n","authors":["Jiamu Wang","Jin Tae Kwak"],"pdf_url":"https://arxiv.org/pdf/2410.16671v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2401.10090v5","updated":"2024-10-22T03:48:13Z","published":"2024-01-18T15:56:23Z","title":"Cross-Modality Perturbation Synergy Attack for Person Re-identification","summary":"  In recent years, there has been significant research focusing on addressing\nsecurity concerns in single-modal person re-identification (ReID) systems that\nare based on RGB images. However, the safety of cross-modality scenarios, which\nare more commonly encountered in practical applications involving images\ncaptured by infrared cameras, has not received adequate attention. The main\nchallenge in cross-modality ReID lies in effectively dealing with visual\ndifferences between different modalities. For instance, infrared images are\ntypically grayscale, unlike visible images that contain color information.\nExisting attack methods have primarily focused on the characteristics of the\nvisible image modality, overlooking the features of other modalities and the\nvariations in data distribution among different modalities. This oversight can\npotentially undermine the effectiveness of these methods in image retrieval\nacross diverse modalities. This study represents the first exploration into the\nsecurity of cross-modality ReID models and proposes a universal perturbation\nattack specifically designed for cross-modality ReID. This attack optimizes\nperturbations by leveraging gradients from diverse modality data, thereby\ndisrupting the discriminator and reinforcing the differences between\nmodalities. We conducted experiments on three widely used cross-modality\ndatasets, namely RegDB, SYSU, and LLCM. The results not only demonstrate the\neffectiveness of our method but also provide insights for future improvements\nin the robustness of cross-modality ReID systems.\n","authors":["Yunpeng Gong","Zhun Zhong","Yansong Qu","Zhiming Luo","Rongrong Ji","Min Jiang"],"pdf_url":"https://arxiv.org/pdf/2401.10090v5.pdf","comment":"Accepted at the Thirty-eighth Annual Conference on Neural Information\n  Processing Systems (NeurIPS 2024)"},{"id":"http://arxiv.org/abs/2407.04833v4","updated":"2024-10-22T03:41:08Z","published":"2024-07-05T19:38:10Z","title":"3D Adaptive Structural Convolution Network for Domain-Invariant Point\n  Cloud Recognition","summary":"  Adapting deep learning networks for point cloud data recognition in\nself-driving vehicles faces challenges due to the variability in datasets and\nsensor technologies, emphasizing the need for adaptive techniques to maintain\naccuracy across different conditions. In this paper, we introduce the 3D\nAdaptive Structural Convolution Network (3D-ASCN), a cutting-edge framework for\n3D point cloud recognition. It combines 3D convolution kernels, a structural\ntree structure, and adaptive neighborhood sampling for effective geometric\nfeature extraction. This method obtains domain-invariant features and\ndemonstrates robust, adaptable performance on a variety of point cloud\ndatasets, ensuring compatibility across diverse sensor configurations without\nthe need for parameter adjustments. This highlights its potential to\nsignificantly enhance the reliability and efficiency of self-driving vehicle\ntechnology.\n","authors":["Younggun Kim","Beomsik Cho","Seonghoon Ryoo","Soomok Lee"],"pdf_url":"https://arxiv.org/pdf/2407.04833v4.pdf","comment":"11 pages, 3 figures"},{"id":"http://arxiv.org/abs/2407.00664v2","updated":"2024-10-22T03:34:43Z","published":"2024-06-30T11:22:36Z","title":"SCMIL: Sparse Context-aware Multiple Instance Learning for Predicting\n  Cancer Survival Probability Distribution in Whole Slide Images","summary":"  Cancer survival prediction is a challenging task that involves analyzing of\nthe tumor microenvironment within Whole Slide Image (WSI). Previous methods\ncannot effectively capture the intricate interaction features among instances\nwithin the local area of WSI. Moreover, existing methods for cancer survival\nprediction based on WSI often fail to provide better clinically meaningful\npredictions. To overcome these challenges, we propose a Sparse Context-aware\nMultiple Instance Learning (SCMIL) framework for predicting cancer survival\nprobability distributions. SCMIL innovatively segments patches into various\nclusters based on their morphological features and spatial location\ninformation, subsequently leveraging sparse self-attention to discern the\nrelationships between these patches with a context-aware perspective.\nConsidering many patches are irrelevant to the task, we introduce a learnable\npatch filtering module called SoftFilter, which ensures that only interactions\nbetween task-relevant patches are considered. To enhance the clinical relevance\nof our prediction, we propose a register-based mixture density network to\nforecast the survival probability distribution for individual patients. We\nevaluate SCMIL on two public WSI datasets from the The Cancer Genome Atlas\n(TCGA) specifically focusing on lung adenocarcinom (LUAD) and kidney renal\nclear cell carcinoma (KIRC). Our experimental results indicate that SCMIL\noutperforms current state-of-the-art methods for survival prediction, offering\nmore clinically meaningful and interpretable outcomes. Our code is accessible\nat https://github.com/yang-ze-kang/SCMIL.\n","authors":["Zekang Yang","Hong Liu","Xiangdong Wang"],"pdf_url":"https://arxiv.org/pdf/2407.00664v2.pdf","comment":"Accepted by MICCAI2024"},{"id":"http://arxiv.org/abs/2410.16662v1","updated":"2024-10-22T03:28:41Z","published":"2024-10-22T03:28:41Z","title":"Visual Question Answering in Ophthalmology: A Progressive and Practical\n  Perspective","summary":"  Accurate diagnosis of ophthalmic diseases relies heavily on the\ninterpretation of multimodal ophthalmic images, a process often time-consuming\nand expertise-dependent. Visual Question Answering (VQA) presents a potential\ninterdisciplinary solution by merging computer vision and natural language\nprocessing to comprehend and respond to queries about medical images. This\nreview article explores the recent advancements and future prospects of VQA in\nophthalmology from both theoretical and practical perspectives, aiming to\nprovide eye care professionals with a deeper understanding and tools for\nleveraging the underlying models. Additionally, we discuss the promising trend\nof large language models (LLM) in enhancing various components of the VQA\nframework to adapt to multimodal ophthalmic tasks. Despite the promising\noutlook, ophthalmic VQA still faces several challenges, including the scarcity\nof annotated multimodal image datasets, the necessity of comprehensive and\nunified evaluation methods, and the obstacles to achieving effective real-world\napplications. This article highlights these challenges and clarifies future\ndirections for advancing ophthalmic VQA with LLMs. The development of LLM-based\nophthalmic VQA systems calls for collaborative efforts between medical\nprofessionals and AI experts to overcome existing obstacles and advance the\ndiagnosis and care of eye diseases.\n","authors":["Xiaolan Chen","Ruoyu Chen","Pusheng Xu","Weiyi Zhang","Xianwen Shang","Mingguang He","Danli Shi"],"pdf_url":"https://arxiv.org/pdf/2410.16662v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.16657v1","updated":"2024-10-22T03:02:29Z","published":"2024-10-22T03:02:29Z","title":"Dual-Model Defense: Safeguarding Diffusion Models from Membership\n  Inference Attacks through Disjoint Data Splitting","summary":"  Diffusion models have demonstrated remarkable capabilities in image\nsynthesis, but their recently proven vulnerability to Membership Inference\nAttacks (MIAs) poses a critical privacy concern. This paper introduces two\nnovel and efficient approaches (DualMD and DistillMD) to protect diffusion\nmodels against MIAs while maintaining high utility. Both methods are based on\ntraining two separate diffusion models on disjoint subsets of the original\ndataset. DualMD then employs a private inference pipeline that utilizes both\nmodels. This strategy significantly reduces the risk of black-box MIAs by\nlimiting the information any single model contains about individual training\nsamples. The dual models can also generate \"soft targets\" to train a private\nstudent model in DistillMD, enhancing privacy guarantees against all types of\nMIAs. Extensive evaluations of DualMD and DistillMD against state-of-the-art\nMIAs across various datasets in white-box and black-box settings demonstrate\ntheir effectiveness in substantially reducing MIA success rates while\npreserving competitive image generation performance. Notably, our experiments\nreveal that DistillMD not only defends against MIAs but also mitigates model\nmemorization, indicating that both vulnerabilities stem from overfitting and\ncan be addressed simultaneously with our unified approach.\n","authors":["Bao Q. Tran","Viet Nguyen","Anh Tran","Toan Tran"],"pdf_url":"https://arxiv.org/pdf/2410.16657v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.15472v2","updated":"2024-10-22T02:59:51Z","published":"2024-10-20T19:02:41Z","title":"Multi-Layer Feature Fusion with Cross-Channel Attention-Based U-Net for\n  Kidney Tumor Segmentation","summary":"  Renal tumors, especially renal cell carcinoma (RCC), show significant\nheterogeneity, posing challenges for diagnosis using radiology images such as\nMRI, echocardiograms, and CT scans. U-Net based deep learning techniques are\nemerging as a promising approach for automated medical image segmentation for\nminimally invasive diagnosis of renal tumors. However, current techniques need\nfurther improvements in accuracy to become clinically useful to radiologists.\nIn this study, we present an improved U-Net based model for end-to-end\nautomated semantic segmentation of CT scan images to identify renal tumors. The\nmodel uses residual connections across convolution layers, integrates a\nmulti-layer feature fusion (MFF) and cross-channel attention (CCA) within\nencoder blocks, and incorporates skip connections augmented with additional\ninformation derived using MFF and CCA. We evaluated our model on the KiTS19\ndataset, which contains data from 210 patients. For kidney segmentation, our\nmodel achieves a Dice Similarity Coefficient (DSC) of 0.97 and a Jaccard index\n(JI) of 0.95. For renal tumor segmentation, our model achieves a DSC of 0.96\nand a JI of 0.91. Based on a comparison of available DSC scores, our model\noutperforms the current leading models.\n","authors":["Fnu Neha","Arvind K. Bansal"],"pdf_url":"https://arxiv.org/pdf/2410.15472v2.pdf","comment":"8 pages"},{"id":"http://arxiv.org/abs/2410.16646v1","updated":"2024-10-22T02:45:46Z","published":"2024-10-22T02:45:46Z","title":"TopoDiffusionNet: A Topology-aware Diffusion Model","summary":"  Diffusion models excel at creating visually impressive images but often\nstruggle to generate images with a specified topology. The Betti number, which\nrepresents the number of structures in an image, is a fundamental measure in\ntopology. Yet, diffusion models fail to satisfy even this basic constraint.\nThis limitation restricts their utility in applications requiring exact\ncontrol, like robotics and environmental modeling. To address this, we propose\nTopoDiffusionNet (TDN), a novel approach that enforces diffusion models to\nmaintain the desired topology. We leverage tools from topological data\nanalysis, particularly persistent homology, to extract the topological\nstructures within an image. We then design a topology-based objective function\nto guide the denoising process, preserving intended structures while\nsuppressing noisy ones. Our experiments across four datasets demonstrate\nsignificant improvements in topological accuracy. TDN is the first to integrate\ntopology with diffusion models, opening new avenues of research in this area.\n","authors":["Saumya Gupta","Dimitris Samaras","Chao Chen"],"pdf_url":"https://arxiv.org/pdf/2410.16646v1.pdf","comment":"20 pages, 11 figures, 7 tables"},{"id":"http://arxiv.org/abs/2309.06118v6","updated":"2024-10-22T02:42:30Z","published":"2023-09-12T10:33:19Z","title":"CHITNet: A Complementary to Harmonious Information Transfer Network for\n  Infrared and Visible Image Fusion","summary":"  Current infrared and visible image fusion (IVIF) methods go to great lengths\nto excavate complementary features and design complex fusion strategies, which\nis extremely challenging. To this end, we rethink the IVIF outside the box,\nproposing a complementary to harmonious information transfer network (CHITNet).\nIt reasonably transfers complementary information into harmonious one, which\nintegrates both the shared and complementary features from two modalities.\nSpecifically, to skillfully sidestep aggregating complementary information in\nIVIF, we design a mutual information transfer (MIT) module to mutually\nrepresent features from two modalities, roughly transferring complementary\ninformation into harmonious one. Then, a harmonious information acquisition\nsupervised by source image (HIASSI) module is devised to further ensure the\ncomplementary to harmonious information transfer after MIT. Meanwhile, we also\npropose a structure information preservation (SIP) module to guarantee that the\nedge structure information of the source images can be transferred to the\nfusion results. Moreover, a mutual promotion training paradigm with interaction\nloss is adopted to facilitate better collaboration among MIT, HIASSI and SIP.\nIn this way, the proposed method is able to generate fused images with higher\nqualities. Extensive experimental results demonstrate the superiority of\nCHITNet over state-of-the-art algorithms in terms of visual quality and\nquantitative evaluations.\n","authors":["Keying Du","Huafeng Li","Yafei Zhang","Zhengtao Yu"],"pdf_url":"https://arxiv.org/pdf/2309.06118v6.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.16642v1","updated":"2024-10-22T02:41:37Z","published":"2024-10-22T02:41:37Z","title":"Fire and Smoke Detection with Burning Intensity Representation","summary":"  An effective Fire and Smoke Detection (FSD) and analysis system is of\nparamount importance due to the destructive potential of fire disasters.\nHowever, many existing FSD methods directly employ generic object detection\ntechniques without considering the transparency of fire and smoke, which leads\nto imprecise localization and reduces detection performance. To address this\nissue, a new Attentive Fire and Smoke Detection Model (a-FSDM) is proposed.\nThis model not only retains the robust feature extraction and fusion\ncapabilities of conventional detection algorithms but also redesigns the\ndetection head specifically for transparent targets in FSD, termed the\nAttentive Transparency Detection Head (ATDH). In addition, Burning Intensity\n(BI) is introduced as a pivotal feature for fire-related downstream risk\nassessments in traditional FSD methodologies. Extensive experiments on multiple\nFSD datasets showcase the effectiveness and versatility of the proposed FSD\nmodel. The project is available at\n\\href{https://xiaoyihan6.github.io/FSD/}{https://xiaoyihan6.github.io/FSD/}.\n","authors":["Xiaoyi Han","Yanfei Wu","Nan Pu","Zunlei Feng","Qifei Zhang","Yijun Bei","Lechao Cheng"],"pdf_url":"https://arxiv.org/pdf/2410.16642v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.02216v2","updated":"2024-10-22T02:33:25Z","published":"2023-06-03T23:53:57Z","title":"Forgettable Federated Linear Learning with Certified Data Unlearning","summary":"  The advent of Federated Learning (FL) has revolutionized the way distributed\nsystems handle collaborative model training while preserving user privacy.\nRecently, Federated Unlearning (FU) has emerged to address demands for the\n\"right to be forgotten\"\" and unlearning of the impact of poisoned clients\nwithout requiring retraining in FL. Most FU algorithms require the cooperation\nof retained or target clients (clients to be unlearned), introducing additional\ncommunication overhead and potential security risks. In addition, some FU\nmethods need to store historical models to execute the unlearning process.\nThese challenges hinder the efficiency and memory constraints of the current FU\nmethods. Moreover, due to the complexity of nonlinear models and their training\nstrategies, most existing FU methods for deep neural networks (DNN) lack\ntheoretical certification. In this work, we introduce a novel FL training and\nunlearning strategy in DNN, termed Forgettable Federated Linear Learning\n(F^2L^2). F^2L^2 considers a common practice of using pre-trained models to\napproximate DNN linearly, allowing them to achieve similar performance as the\noriginal networks via Federated Linear Training (FLT). We then present\nFedRemoval, a certified, efficient, and secure unlearning strategy that enables\nthe server to unlearn a target client without requiring client communication or\nadding additional storage. We have conducted extensive empirical validation on\nsmall- to large-scale datasets, using both convolutional neural networks and\nmodern foundation models. These experiments demonstrate the effectiveness of\nF^2L^2 in balancing model accuracy with the successful unlearning of target\nclients. F^2L^2 represents a promising pipeline for efficient and trustworthy\nFU. The code is available here.\n","authors":["Ruinan Jin","Minghui Chen","Qiong Zhang","Xiaoxiao Li"],"pdf_url":"https://arxiv.org/pdf/2306.02216v2.pdf","comment":"17 pages, 6 figures"},{"id":"http://arxiv.org/abs/2410.16631v1","updated":"2024-10-22T02:19:23Z","published":"2024-10-22T02:19:23Z","title":"Benchmarking Multi-Scene Fire and Smoke Detection","summary":"  The current irregularities in existing public Fire and Smoke Detection (FSD)\ndatasets have become a bottleneck in the advancement of FSD technology. Upon\nin-depth analysis, we identify the core issue as the lack of standardized\ndataset construction, uniform evaluation systems, and clear performance\nbenchmarks. To address this issue and drive innovation in FSD technology, we\nsystematically gather diverse resources from public sources to create a more\ncomprehensive and refined FSD benchmark. Additionally, recognizing the\ninadequate coverage of existing dataset scenes, we strategically expand scenes,\nrelabel, and standardize existing public FSD datasets to ensure accuracy and\nconsistency. We aim to establish a standardized, realistic, unified, and\nefficient FSD research platform that mirrors real-life scenes closely. Through\nour efforts, we aim to provide robust support for the breakthrough and\ndevelopment of FSD technology. The project is available at\n\\href{https://xiaoyihan6.github.io/FSD/}{https://xiaoyihan6.github.io/FSD/}.\n","authors":["Xiaoyi Han","Nan Pu","Zunlei Feng","Yijun Bei","Qifei Zhang","Lechao Cheng","Liang Xue"],"pdf_url":"https://arxiv.org/pdf/2410.16631v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.16624v1","updated":"2024-10-22T02:16:02Z","published":"2024-10-22T02:16:02Z","title":"EVC-MF: End-to-end Video Captioning Network with Multi-scale Features","summary":"  Conventional approaches for video captioning leverage a variety of\noffline-extracted features to generate captions. Despite the availability of\nvarious offline-feature-extractors that offer diverse information from\ndifferent perspectives, they have several limitations due to fixed parameters.\nConcretely, these extractors are solely pre-trained on image/video\ncomprehension tasks, making them less adaptable to video caption datasets.\nAdditionally, most of these extractors only capture features prior to the\nclassifier of the pre-training task, ignoring a significant amount of valuable\nshallow information. Furthermore, employing multiple offline-features may\nintroduce redundant information. To address these issues, we propose an\nend-to-end encoder-decoder-based network (EVC-MF) for video captioning, which\nefficiently utilizes multi-scale visual and textual features to generate video\ndescriptions. Specifically, EVC-MF consists of three modules. Firstly, instead\nof relying on multiple feature extractors, we directly feed video frames into a\ntransformer-based network to obtain multi-scale visual features and update\nfeature extractor parameters. Secondly, we fuse the multi-scale features and\ninput them into a masked encoder to reduce redundancy and encourage learning\nuseful features. Finally, we utilize an enhanced transformer-based decoder,\nwhich can efficiently leverage shallow textual information, to generate video\ndescriptions. To evaluate our proposed model, we conduct extensive experiments\non benchmark datasets. The results demonstrate that EVC-MF yields competitive\nperformance compared with the state-of-theart methods.\n","authors":["Tian-Zi Niu","Zhen-Duo Chen","Xin Luo","Xin-Shun Xu"],"pdf_url":"https://arxiv.org/pdf/2410.16624v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.09564v2","updated":"2024-10-22T02:14:24Z","published":"2024-06-13T20:12:46Z","title":"Towards Domain Adaptive Neural Contextual Bandits","summary":"  Contextual bandit algorithms are essential for solving real-world decision\nmaking problems. In practice, collecting a contextual bandit's feedback from\ndifferent domains may involve different costs. For example, measuring drug\nreaction from mice (as a source domain) and humans (as a target domain).\nUnfortunately, adapting a contextual bandit algorithm from a source domain to a\ntarget domain with distribution shift still remains a major challenge and\nlargely unexplored. In this paper, we introduce the first general domain\nadaptation method for contextual bandits. Our approach learns a bandit model\nfor the target domain by collecting feedback from the source domain. Our\ntheoretical analysis shows that our algorithm maintains a sub-linear regret\nbound even adapting across domains. Empirical results show that our approach\noutperforms the state-of-the-art contextual bandit algorithms on real-world\ndatasets.\n","authors":["Ziyan Wang","Xiaoming Huo","Hao Wang"],"pdf_url":"https://arxiv.org/pdf/2406.09564v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.02622v2","updated":"2024-10-22T01:41:21Z","published":"2023-11-05T11:27:03Z","title":"Hierarchical Simplicity Bias of Neural Networks","summary":"  Neural networks often exhibit simplicity bias, favoring simpler features over\nmore complex ones, even when both are equally predictive. We introduce a novel\nmethod called imbalanced label coupling to explore and extend this simplicity\nbias across multiple hierarchical levels. Our approach demonstrates that\ntrained networks sequentially consider features of increasing complexity based\non their correlation with labels in the training set, regardless of their\nactual predictive power. For example, in CIFAR-10, simple spurious features can\ncause misclassifications where most cats are predicted as dogs and most trucks\nas automobiles. We empirically show that last-layer retraining with target data\ndistribution \\citep{kirichenko2022last} is insufficient to fully recover core\nfeatures when spurious features perfectly correlate with target labels in our\nsynthetic datasets. Our findings deepen the understanding of the implicit\nbiases inherent in neural networks.\n","authors":["Zhehang Du"],"pdf_url":"https://arxiv.org/pdf/2311.02622v2.pdf","comment":"20 pages, 21 figures, revised version, accepted at OPT2024: 16th\n  Annual Workshop on Optimization for Machine Learning"},{"id":"http://arxiv.org/abs/2410.16602v1","updated":"2024-10-22T01:08:21Z","published":"2024-10-22T01:08:21Z","title":"Foundation Models for Remote Sensing and Earth Observation: A Survey","summary":"  Remote Sensing (RS) is a crucial technology for observing, monitoring, and\ninterpreting our planet, with broad applications across geoscience, economics,\nhumanitarian fields, etc. While artificial intelligence (AI), particularly deep\nlearning, has achieved significant advances in RS, unique challenges persist in\ndeveloping more intelligent RS systems, including the complexity of Earth's\nenvironments, diverse sensor modalities, distinctive feature patterns, varying\nspatial and spectral resolutions, and temporal dynamics. Meanwhile, recent\nbreakthroughs in large Foundation Models (FMs) have expanded AI's potential\nacross many domains due to their exceptional generalizability and zero-shot\ntransfer capabilities. However, their success has largely been confined to\nnatural data like images and video, with degraded performance and even failures\nfor RS data of various non-optical modalities. This has inspired growing\ninterest in developing Remote Sensing Foundation Models (RSFMs) to address the\ncomplex demands of Earth Observation (EO) tasks, spanning the surface,\natmosphere, and oceans. This survey systematically reviews the emerging field\nof RSFMs. It begins with an outline of their motivation and background,\nfollowed by an introduction of their foundational concepts. It then categorizes\nand reviews existing RSFM studies including their datasets and technical\ncontributions across Visual Foundation Models (VFMs), Visual-Language Models\n(VLMs), Large Language Models (LLMs), and beyond. In addition, we benchmark\nthese models against publicly available datasets, discuss existing challenges,\nand propose future research directions in this rapidly evolving field.\n","authors":["Aoran Xiao","Weihao Xuan","Junjue Wang","Jiaxing Huang","Dacheng Tao","Shijian Lu","Naoto Yokoya"],"pdf_url":"https://arxiv.org/pdf/2410.16602v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.11194v2","updated":"2024-10-22T00:42:31Z","published":"2024-08-20T21:02:54Z","title":"Compress Guidance in Conditional Diffusion Sampling","summary":"  We found that enforcing guidance throughout the sampling process is often\ncounterproductive due to the model-fitting issue, where samples are 'tuned' to\nmatch the classifier's parameters rather than generalizing the expected\ncondition. This work identifies and quantifies the problem, demonstrating that\nreducing or excluding guidance at numerous timesteps can mitigate this issue.\nBy distributing a small amount of guidance over a large number of sampling\ntimesteps, we observe a significant improvement in image quality and diversity\nwhile also reducing the required guidance timesteps by nearly 40%. This\napproach addresses a major challenge in applying guidance effectively to\ngenerative tasks. Consequently, our proposed method, termed Compress Guidance,\nallows for the exclusion of a substantial number of guidance timesteps while\nstill surpassing baseline models in image quality. We validate our approach\nthrough benchmarks on label-conditional and text-to-image generative tasks\nacross various datasets and models.\n","authors":["Anh-Dung Dinh","Daochang Liu","Chang Xu"],"pdf_url":"https://arxiv.org/pdf/2408.11194v2.pdf","comment":"10 pages, 5 figures, Computer Vision and Machine Learning"},{"id":"http://arxiv.org/abs/2410.16239v2","updated":"2024-10-22T22:22:14Z","published":"2024-10-21T17:42:41Z","title":"MoRE: Multi-Modal Contrastive Pre-training with Transformers on X-Rays,\n  ECGs, and Diagnostic Report","summary":"  In this paper, we introduce a novel Multi-Modal Contrastive Pre-training\nFramework that synergistically combines X-rays, electrocardiograms (ECGs), and\nradiology/cardiology reports. Our approach leverages transformers to encode\nthese diverse modalities into a unified representation space, aiming to enhance\ndiagnostic accuracy and facilitate comprehensive patient assessments. We\nutilize LoRA-Peft to significantly reduce trainable parameters in the LLM and\nincorporate recent linear attention dropping strategy in the Vision\nTransformer(ViT) for smoother attention. Furthermore, we provide novel\nmultimodal attention explanations and retrieval for our model. To the best of\nour knowledge, we are the first to propose an integrated model that combines\nX-ray, ECG, and Radiology/Cardiology Report with this approach. By utilizing\ncontrastive loss, MoRE effectively aligns modality-specific features into a\ncoherent embedding, which supports various downstream tasks such as zero-shot\nclassification and multimodal retrieval. Employing our proposed methodology, we\nachieve state-of-the-art (SOTA) on the Mimic-IV, CheXpert, Edema Severity, and\nPtbXl downstream datasets, surpassing existing multimodal approaches. Our\nproposed framework shows significant improvements in capturing intricate\ninter-modal relationships and its robustness in medical diagnosis that\nestablishes a framework for future research in multimodal learning in the\nhealthcare sector.\n","authors":["Samrajya Thapa","Koushik Howlader","Subhankar Bhattacharjee","Wei le"],"pdf_url":"https://arxiv.org/pdf/2410.16239v2.pdf","comment":"10 pages, 5 figures, 9 tables. Supplementary detail in Appendix. Code\n  made available in Github for reproducibility"},{"id":"http://arxiv.org/abs/2409.11402v2","updated":"2024-10-22T23:13:34Z","published":"2024-09-17T17:59:06Z","title":"NVLM: Open Frontier-Class Multimodal LLMs","summary":"  We introduce NVLM 1.0, a family of frontier-class multimodal large language\nmodels (LLMs) that achieve state-of-the-art results on vision-language tasks,\nrivaling the leading proprietary models (e.g., GPT-4o) and open-access models\n(e.g., Llama 3-V 405B and InternVL 2). Remarkably, NVLM 1.0 shows improved\ntext-only performance over its LLM backbone after multimodal training. In terms\nof model design, we perform a comprehensive comparison between decoder-only\nmultimodal LLMs (e.g., LLaVA) and cross-attention-based models (e.g.,\nFlamingo). Based on the strengths and weaknesses of both approaches, we propose\na novel architecture that enhances both training efficiency and multimodal\nreasoning capabilities. Furthermore, we introduce a 1-D tile-tagging design for\ntile-based dynamic high-resolution images, which significantly boosts\nperformance on multimodal reasoning and OCR-related tasks. Regarding training\ndata, we meticulously curate and provide detailed information on our multimodal\npretraining and supervised fine-tuning datasets. Our findings indicate that\ndataset quality and task diversity are more important than scale, even during\nthe pretraining phase, across all architectures. Notably, we develop\nproduction-grade multimodality for the NVLM-1.0 models, enabling them to excel\nin vision-language tasks while maintaining and even improving text-only\nperformance compared to their LLM backbones. To achieve this, we craft and\nintegrate a high-quality text-only dataset into multimodal training, alongside\na substantial amount of multimodal math and reasoning data, leading to enhanced\nmath and coding capabilities across modalities. To advance research in the\nfield, we release the model weights at https://huggingface.co/nvidia/NVLM-D-72B\nand will open-source the training code for the community soon.\n","authors":["Wenliang Dai","Nayeon Lee","Boxin Wang","Zhuolin Yang","Zihan Liu","Jon Barker","Tuomas Rintamaki","Mohammad Shoeybi","Bryan Catanzaro","Wei Ping"],"pdf_url":"https://arxiv.org/pdf/2409.11402v2.pdf","comment":"Fixed the typos. For more information, please visit our project page\n  at: https://research.nvidia.com/labs/adlr/NVLM-1"},{"id":"http://arxiv.org/abs/2410.17434v1","updated":"2024-10-22T21:21:37Z","published":"2024-10-22T21:21:37Z","title":"LongVU: Spatiotemporal Adaptive Compression for Long Video-Language\n  Understanding","summary":"  Multimodal Large Language Models (MLLMs) have shown promising progress in\nunderstanding and analyzing video content. However, processing long videos\nremains a significant challenge constrained by LLM's context size. To address\nthis limitation, we propose LongVU, a spatiotemporal adaptive compression\nmechanism thats reduces the number of video tokens while preserving visual\ndetails of long videos. Our idea is based on leveraging cross-modal query and\ninter-frame dependencies to adaptively reduce temporal and spatial redundancy\nin videos. Specifically, we leverage DINOv2 features to remove redundant frames\nthat exhibit high similarity. Then we utilize text-guided cross-modal query for\nselective frame feature reduction. Further, we perform spatial token reduction\nacross frames based on their temporal dependencies. Our adaptive compression\nstrategy effectively processes a large number of frames with little visual\ninformation loss within given context length. Our LongVU consistently surpass\nexisting methods across a variety of video understanding benchmarks, especially\non hour-long video understanding tasks such as VideoMME and MLVU. Given a\nlight-weight LLM, our LongVU also scales effectively into a smaller size with\nstate-of-the-art video understanding performance.\n","authors":["Xiaoqian Shen","Yunyang Xiong","Changsheng Zhao","Lemeng Wu","Jun Chen","Chenchen Zhu","Zechun Liu","Fanyi Xiao","Balakrishnan Varadarajan","Florian Bordes","Zhuang Liu","Hu Xu","Hyunwoo J. Kim","Bilge Soran","Raghuraman Krishnamoorthi","Mohamed Elhoseiny","Vikas Chandra"],"pdf_url":"https://arxiv.org/pdf/2410.17434v1.pdf","comment":"Project page: https://vision-cair.github.io/LongVU"},{"id":"http://arxiv.org/abs/2410.17427v1","updated":"2024-10-22T20:56:04Z","published":"2024-10-22T20:56:04Z","title":"SigCLR: Sigmoid Contrastive Learning of Visual Representations","summary":"  We propose SigCLR: Sigmoid Contrastive Learning of Visual Representations.\nSigCLR utilizes the logistic loss that only operates on pairs and does not\nrequire a global view as in the cross-entropy loss used in SimCLR. We show that\nlogistic loss shows competitive performance on CIFAR-10, CIFAR-100, and Tiny-IN\ncompared to other established SSL objectives. Our findings verify the\nimportance of learnable bias as in the case of SigLUP, however, it requires a\nfixed temperature as in the SimCLR to excel. Overall, SigCLR is a promising\nreplacement for the SimCLR which is ubiquitous and has shown tremendous success\nin various domains.\n","authors":["Ömer Veysel Çağatan"],"pdf_url":"https://arxiv.org/pdf/2410.17427v1.pdf","comment":"Neurips 2024 SSL Workshop"},{"id":"http://arxiv.org/abs/2312.02521v3","updated":"2024-10-22T20:52:38Z","published":"2023-12-05T06:04:16Z","title":"RetriBooru: Leakage-Free Retrieval of Conditions from Reference Images\n  for Subject-Driven Generation","summary":"  Diffusion-based methods have demonstrated remarkable capabilities in\ngenerating a diverse array of high-quality images, sparking interests for\nstyled avatars, virtual try-on, and more. Previous methods use the same\nreference image as the target. An overlooked aspect is the leakage of the\ntarget's spatial information, style, etc. from the reference, harming the\ngenerated diversity and causing shortcuts. However, this approach continues as\nwidely available datasets usually consist of single images not grouped by\nidentities, and it is expensive to recollect large-scale same-identity data.\nMoreover, existing metrics adopt decoupled evaluation on text alignment and\nidentity preservation, which fail at distinguishing between balanced outputs\nand those that over-fit to one aspect. In this paper, we propose a multi-level,\nsame-identity dataset RetriBooru, which groups anime characters by both face\nand cloth identities. RetriBooru enables adopting reference images of the same\ncharacter and outfits as the target, while keeping flexible gestures and\nactions. We benchmark previous methods on our dataset, and demonstrate the\neffectiveness of training with a reference image different from target (but\nsame identity). We introduce a new concept composition task, where the\nconditioning encoder learns to retrieve different concepts from several\nreference images, and modify a baseline network RetriNet for the new task.\nFinally, we introduce a novel class of metrics named Similarity Weighted\nDiversity (SWD), to measure the overlooked diversity and better evaluate the\nalignment between similarity and diversity.\n","authors":["Haoran Tang","Jieren Deng","Zhihong Pan","Hao Tian","Pratik Chaudhari","Xin Zhou"],"pdf_url":"https://arxiv.org/pdf/2312.02521v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.17422v1","updated":"2024-10-22T20:51:45Z","published":"2024-10-22T20:51:45Z","title":"AG-SLAM: Active Gaussian Splatting SLAM","summary":"  We present AG-SLAM, the first active SLAM system utilizing 3D Gaussian\nSplatting (3DGS) for online scene reconstruction. In recent years, radiance\nfield scene representations, including 3DGS have been widely used in SLAM and\nexploration, but actively planning trajectories for robotic exploration is\nstill unvisited. In particular, many exploration methods assume precise\nlocalization and thus do not mitigate the significant risk of constructing a\ntrajectory, which is difficult for a SLAM system to operate on. This can cause\ncamera tracking failure and lead to failures in real-world robotic\napplications. Our method leverages Fisher Information to balance the dual\nobjectives of maximizing the information gain for the environment while\nminimizing the cost of localization errors. Experiments conducted on the Gibson\nand Habitat-Matterport 3D datasets demonstrate state-of-the-art results of the\nproposed method.\n","authors":["Wen Jiang","Boshu Lei","Katrina Ashton","Kostas Daniilidis"],"pdf_url":"https://arxiv.org/pdf/2410.17422v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2401.01984v5","updated":"2024-10-22T20:39:52Z","published":"2024-01-03T21:24:44Z","title":"AUPIMO: Redefining Visual Anomaly Detection Benchmarks with High Speed\n  and Low Tolerance","summary":"  Recent advances in visual anomaly detection research have seen AUROC and\nAUPRO scores on public benchmark datasets such as MVTec and VisA converge\ntowards perfect recall, giving the impression that these benchmarks are\nnear-solved. However, high AUROC and AUPRO scores do not always reflect\nqualitative performance, which limits the validity of these metrics in\nreal-world applications. We argue that the artificial ceiling imposed by the\nlack of an adequate evaluation metric restrains progression of the field, and\nit is crucial that we revisit the evaluation metrics used to rate our\nalgorithms. In response, we introduce Per-IMage Overlap (PIMO), a novel metric\nthat addresses the shortcomings of AUROC and AUPRO. PIMO retains the\nrecall-based nature of the existing metrics but introduces two distinctions:\nthe assignment of curves (and respective area under the curve) is per-image,\nand its X-axis relies solely on normal images. Measuring recall per image\nsimplifies instance score indexing and is more robust to noisy annotations. As\nwe show, it also accelerates computation and enables the usage of statistical\ntests to compare models. By imposing low tolerance for false positives on\nnormal images, PIMO provides an enhanced model validation procedure and\nhighlights performance variations across datasets. Our experiments demonstrate\nthat PIMO offers practical advantages and nuanced performance insights that\nredefine anomaly detection benchmarks -- notably challenging the perception\nthat MVTec AD and VisA datasets have been solved by contemporary models.\nAvailable on GitHub: https://github.com/jpcbertoldo/aupimo.\n","authors":["Joao P. C. Bertoldo","Dick Ameln","Ashwin Vaidya","Samet Akçay"],"pdf_url":"https://arxiv.org/pdf/2401.01984v5.pdf","comment":"Accepted to BMVC 2024. Official implementation:\n  https://github.com/jpcbertoldo/aupimo. Integrated in anomalib\n  https://github.com/openvinotoolkit/anomalib. This research was conducted\n  during Google Summer of Code 2023 (GSoC 2023) with the anomalib team from\n  Intel's OpenVINO Toolkit"},{"id":"http://arxiv.org/abs/2410.17409v1","updated":"2024-10-22T20:33:10Z","published":"2024-10-22T20:33:10Z","title":"Geometric Graph Neural Network Modeling of Human Interactions in Crowded\n  Environments","summary":"  Modeling human trajectories in crowded environments is challenging due to the\ncomplex nature of pedestrian behavior and interactions. This paper proposes a\ngeometric graph neural network (GNN) architecture that integrates domain\nknowledge from psychological studies to model pedestrian interactions and\npredict future trajectories. Unlike prior studies using complete graphs, we\ndefine interaction neighborhoods using pedestrians' field of view, motion\ndirection, and distance-based kernel functions to construct graph\nrepresentations of crowds. Evaluations across multiple datasets demonstrate\nimproved prediction accuracy through reduced average and final displacement\nerror metrics. Our findings underscore the importance of integrating domain\nknowledge with data-driven approaches for effective modeling of human\ninteractions in crowds.\n","authors":["Sara Honarvar","Yancy Diaz-Mercado"],"pdf_url":"https://arxiv.org/pdf/2410.17409v1.pdf","comment":"\\c{opyright} 2024 the authors. This work has been accepted to IFAC\n  for publication under a Creative Commons Licence CC-BY-NC-ND"},{"id":"http://arxiv.org/abs/2403.09240v2","updated":"2024-10-22T20:26:09Z","published":"2024-03-14T10:03:58Z","title":"XReal: Realistic Anatomy and Pathology-Aware X-ray Generation via\n  Controllable Diffusion Model","summary":"  Large-scale generative models have demonstrated impressive capabilities in\nproducing visually compelling images, with increasing applications in medical\nimaging. However, they continue to grapple with hallucination challenges and\nthe generation of anatomically inaccurate outputs. These limitations are mainly\ndue to the reliance on textual inputs and lack of spatial control over the\ngenerated images, hindering the potential usefulness of such models in\nreal-life settings. In this work, we present XReal, a novel controllable\ndiffusion model for generating realistic chest X-ray images through precise\nanatomy and pathology location control. Our lightweight method comprises an\nAnatomy Controller and a Pathology Controller to introduce spatial control over\nanatomy and pathology in a pre-trained Text-to-Image Diffusion Model,\nrespectively, without fine-tuning the model. XReal outperforms state-of-the-art\nX-ray diffusion models in quantitative metrics and radiologists' ratings,\nshowing significant gains in anatomy and pathology realism. Our model holds\npromise for advancing generative models in medical imaging, offering greater\nprecision and adaptability while inviting further exploration in this evolving\nfield. The code and pre-trained model weights are publicly available at\nhttps://github.com/BioMedIA-MBZUAI/XReal.\n","authors":["Anees Ur Rehman Hashmi","Ibrahim Almakky","Mohammad Areeb Qazi","Santosh Sanjeev","Vijay Ram Papineni","Jagalpathy Jagdish","Mohammad Yaqub"],"pdf_url":"https://arxiv.org/pdf/2403.09240v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.17396v1","updated":"2024-10-22T20:02:38Z","published":"2024-10-22T20:02:38Z","title":"Efficient Feature Extraction Using Light-Weight CNN Attention-Based Deep\n  Learning Architectures for Ultrasound Fetal Plane Classification","summary":"  Ultrasound fetal imaging is beneficial to support prenatal development\nbecause it is affordable and non-intrusive. Nevertheless, fetal plane\nclassification (FPC) remains challenging and time-consuming for obstetricians\nsince it depends on nuanced clinical aspects, which increases the difficulty in\nidentifying relevant features of the fetal anatomy. Thus, to assist with its\naccurate feature extraction, a lightweight artificial intelligence architecture\nleveraging convolutional neural networks and attention mechanisms is proposed\nto classify the largest benchmark ultrasound dataset. The approach fine-tunes\nfrom lightweight EfficientNet feature extraction backbones pre-trained on the\nImageNet1k. to classify key fetal planes such as the brain, femur, thorax,\ncervix, and abdomen. Our methodology incorporates the attention mechanism to\nrefine features and 3-layer perceptrons for classification, achieving superior\nperformance with the highest Top-1 accuracy of 96.25%, Top-2 accuracy of 99.80%\nand F1-Score of 0.9576. Importantly, the model has 40x fewer trainable\nparameters than existing benchmark ensemble or transformer pipelines,\nfacilitating easy deployment on edge devices to help clinical practitioners\nwith real-time FPC. The findings are also interpreted using GradCAM to carry\nout clinical correlation to aid doctors with diagnostics and improve treatment\nplans for expectant mothers.\n","authors":["Arrun Sivasubramanian","Divya Sasidharan","Sowmya V","Vinayakumar Ravi"],"pdf_url":"https://arxiv.org/pdf/2410.17396v1.pdf","comment":"Submitted to Computers in Biology and Medicine journal"},{"id":"http://arxiv.org/abs/2403.00946v2","updated":"2024-10-22T20:01:45Z","published":"2024-03-01T19:50:22Z","title":"Fine-tuning with Very Large Dropout","summary":"  It is impossible today to pretend that the practice of machine learning is\ncompatible with the idea that training and testing data follow the same\ndistribution. Several authors have recently used ensemble techniques to show\nhow scenarios involving multiple data distributions are best served by\nrepresentations that are both richer than those obtained by regularizing for\nthe best in-distribution performance, and richer than those obtained under the\ninfluence of the implicit sparsity bias of common stochastic gradient\nprocedures.\n  This contribution investigates the use of very high dropout rates instead of\nensembles to obtain such rich representations. Although training a deep network\nfrom scratch using such dropout rates is virtually impossible, fine-tuning a\nlarge pre-trained model under such conditions is not only possible but also\nachieves out-of-distribution performances that exceed those of both ensembles\nand weight averaging methods such as model soups. This result has practical\nsignificance because the importance of the fine-tuning scenario has\nconsiderably grown in recent years. This result also provides interesting\ninsights on the nature of rich representations and on the intrinsically linear\nnature of fine-tuning a large network using a comparatively small dataset.\n","authors":["Jianyu Zhang","Léon Bottou"],"pdf_url":"https://arxiv.org/pdf/2403.00946v2.pdf","comment":"Fine-tuning with very large dropout outperforms weight-averaging and\n  ensemble on ResNet and large vision transformer"},{"id":"http://arxiv.org/abs/2410.17393v1","updated":"2024-10-22T20:01:00Z","published":"2024-10-22T20:01:00Z","title":"Denoise-I2W: Mapping Images to Denoising Words for Accurate Zero-Shot\n  Composed Image Retrieval","summary":"  Zero-Shot Composed Image Retrieval (ZS-CIR) supports diverse tasks with a\nbroad range of visual content manipulation intentions that can be related to\ndomain, scene, object, and attribute. A key challenge for ZS-CIR is to\naccurately map image representation to a pseudo-word token that captures the\nmanipulation intention relevant image information for generalized CIR. However,\nexisting methods between the retrieval and pre-training stages lead to\nsignificant redundancy in the pseudo-word tokens. In this paper, we propose a\nnovel denoising image-to-word mapping approach, named Denoise-I2W, for mapping\nimages into denoising pseudo-word tokens that, without intention-irrelevant\nvisual information, enhance accurate ZS-CIR. Specifically, a pseudo triplet\nconstruction module first automatically constructs pseudo triples\n(\\textit{i.e.,} a pseudo-reference image, a pseudo-manipulation text, and a\ntarget image) for pre-training the denoising mapping network. Then, a\npseudo-composed mapping module maps the pseudo-reference image to a pseudo-word\ntoken and combines it with the pseudo-manipulation text with manipulation\nintention. This combination aligns with the target image, facilitating\ndenoising intention-irrelevant visual information for mapping. Our proposed\nDenoise-I2W is a model-agnostic and annotation-free approach. It demonstrates\nstrong generalization capabilities across three state-of-the-art ZS-CIR models\non four benchmark datasets. By integrating Denoise-I2W with existing best\nmodels, we obtain consistent and significant performance boosts ranging from\n1.45\\% to 4.17\\% over the best methods without increasing inference costs. and\nachieve new state-of-the-art results on ZS-CIR. Our code is available at\n\\url{https://github.com/Pter61/denoise-i2w-tmm}.\n","authors":["Yuanmin Tang","Jing Yu","Keke Gai","Jiamin Zhuang","Gaopeng Gou","Gang Xiong","Qi Wu"],"pdf_url":"https://arxiv.org/pdf/2410.17393v1.pdf","comment":"This work was submitted to IJCAI 2024, with a score of weak accept\n  and borderline accept"},{"id":"http://arxiv.org/abs/2410.17385v1","updated":"2024-10-22T19:39:15Z","published":"2024-10-22T19:39:15Z","title":"Do Vision-Language Models Represent Space and How? Evaluating Spatial\n  Frame of Reference Under Ambiguities","summary":"  Spatial expressions in situated communication can be ambiguous, as their\nmeanings vary depending on the frames of reference (FoR) adopted by speakers\nand listeners. While spatial language understanding and reasoning by\nvision-language models (VLMs) have gained increasing attention, potential\nambiguities in these models are still under-explored. To address this issue, we\npresent the COnsistent Multilingual Frame Of Reference Test (COMFORT), an\nevaluation protocol to systematically assess the spatial reasoning capabilities\nof VLMs. We evaluate nine state-of-the-art VLMs using COMFORT. Despite showing\nsome alignment with English conventions in resolving ambiguities, our\nexperiments reveal significant shortcomings of VLMs: notably, the models (1)\nexhibit poor robustness and consistency, (2) lack the flexibility to\naccommodate multiple FoRs, and (3) fail to adhere to language-specific or\nculture-specific conventions in cross-lingual tests, as English tends to\ndominate other languages. With a growing effort to align vision-language models\nwith human cognitive intuitions, we call for more attention to the ambiguous\nnature and cross-cultural diversity of spatial reasoning.\n","authors":["Zheyuan Zhang","Fengyuan Hu","Jayjun Lee","Freda Shi","Parisa Kordjamshidi","Joyce Chai","Ziqiao Ma"],"pdf_url":"https://arxiv.org/pdf/2410.17385v1.pdf","comment":"Accepted to Pluralistic Alignment @ NeurIPS 2024 | Project page:\n  https://spatial-comfort.github.io/"},{"id":"http://arxiv.org/abs/2410.17377v1","updated":"2024-10-22T19:26:05Z","published":"2024-10-22T19:26:05Z","title":"PtychoFormer: A Transformer-based Model for Ptychographic Phase\n  Retrieval","summary":"  Ptychography is a computational method of microscopy that recovers\nhigh-resolution transmission images of samples from a series of diffraction\npatterns. While conventional phase retrieval algorithms can iteratively recover\nthe images, they require oversampled diffraction patterns, incur significant\ncomputational costs, and struggle to recover the absolute phase of the sample's\ntransmission function. Deep learning algorithms for ptychography are a\npromising approach to resolving the limitations of iterative algorithms. We\npresent PtychoFormer, a hierarchical transformer-based model for data-driven\nsingle-shot ptychographic phase retrieval. PtychoFormer processes subsets of\ndiffraction patterns, generating local inferences that are seamlessly stitched\ntogether to produce a high-quality reconstruction. Our model exhibits tolerance\nto sparsely scanned diffraction patterns and achieves up to 3600 times faster\nimaging speed than the extended ptychographic iterative engine (ePIE). We also\npropose the extended-PtychoFormer (ePF), a hybrid approach that combines the\nbenefits of PtychoFormer with the ePIE. ePF minimizes global phase shifts and\nsignificantly enhances reconstruction quality, achieving state-of-the-art phase\nretrieval in ptychography.\n","authors":["Ryuma Nakahata","Shehtab Zaman","Mingyuan Zhang","Fake Lu","Kenneth Chiu"],"pdf_url":"https://arxiv.org/pdf/2410.17377v1.pdf","comment":"20 pages, 12 figures"},{"id":"http://arxiv.org/abs/2307.15250v4","updated":"2024-10-22T19:09:54Z","published":"2023-07-28T01:20:12Z","title":"D2S: Representing sparse descriptors and 3D coordinates for camera\n  relocalization","summary":"  State-of-the-art visual localization methods mostly rely on complex\nprocedures to match local descriptors and 3D point clouds. However, these\nprocedures can incur significant costs in terms of inference, storage, and\nupdates over time. In this study, we propose a direct learning-based approach\nthat utilizes a simple network named D2S to represent complex local descriptors\nand their scene coordinates. Our method is characterized by its simplicity and\ncost-effectiveness. It solely leverages a single RGB image for localization\nduring the testing phase and only requires a lightweight model to encode a\ncomplex sparse scene. The proposed D2S employs a combination of a simple loss\nfunction and graph attention to selectively focus on robust descriptors while\ndisregarding areas such as clouds, trees, and several dynamic objects. This\nselective attention enables D2S to effectively perform a binary-semantic\nclassification for sparse descriptors. Additionally, we propose a simple\noutdoor dataset to evaluate the capabilities of visual localization methods in\nscene-specific generalization and self-updating from unlabeled observations.\nOur approach outperforms the previous regression-based methods in both indoor\nand outdoor environments. It demonstrates the ability to generalize beyond\ntraining data, including scenarios involving transitions from day to night and\nadapting to domain shifts. The source code, trained models, dataset, and demo\nvideos are available at the following link: https://thpjp.github.io/d2s.\n","authors":["Bach-Thuan Bui","Huy-Hoang Bui","Dinh-Tuan Tran","Joo-Ho Lee"],"pdf_url":"https://arxiv.org/pdf/2307.15250v4.pdf","comment":"Accepted to IEEE Robotics and Automation Letters"},{"id":"http://arxiv.org/abs/2407.00633v2","updated":"2024-10-22T18:52:19Z","published":"2024-06-30T09:15:21Z","title":"DEAR: Disentangled Environment and Agent Representations for\n  Reinforcement Learning without Reconstruction","summary":"  Reinforcement Learning (RL) algorithms can learn robotic control tasks from\nvisual observations, but they often require a large amount of data, especially\nwhen the visual scene is complex and unstructured. In this paper, we explore\nhow the agent's knowledge of its shape can improve the sample efficiency of\nvisual RL methods. We propose a novel method, Disentangled Environment and\nAgent Representations (DEAR), that uses the segmentation mask of the agent as\nsupervision to learn disentangled representations of the environment and the\nagent through feature separation constraints. Unlike previous approaches, DEAR\ndoes not require reconstruction of visual observations. These representations\nare then used as an auxiliary loss to the RL objective, encouraging the agent\nto focus on the relevant features of the environment. We evaluate DEAR on two\nchallenging benchmarks: Distracting DeepMind control suite and Franka Kitchen\nmanipulation tasks. Our findings demonstrate that DEAR surpasses\nstate-of-the-art methods in sample efficiency, achieving comparable or superior\nperformance with reduced parameters. Our results indicate that integrating\nagent knowledge into visual RL methods has the potential to enhance their\nlearning efficiency and robustness.\n","authors":["Ameya Pore","Riccardo Muradore","Diego Dall'Alba"],"pdf_url":"https://arxiv.org/pdf/2407.00633v2.pdf","comment":"6 pages, 7 figures, 2 tables. Accepted at 2024 IEEE/RSJ International\n  Conference on Intelligent Robots and Systems (IROS 2024)"},{"id":"http://arxiv.org/abs/2305.17828v2","updated":"2024-10-22T18:51:50Z","published":"2023-05-28T23:42:35Z","title":"Counter-Hypothetical Particle Filters for Single Object Pose Tracking","summary":"  Particle filtering is a common technique for six degrees of freedom (6D) pose\nestimation due to its ability to tractably represent belief over object pose.\nHowever, the particle filter is prone to particle deprivation due to the\nhigh-dimensional nature of 6D pose. When particle deprivation occurs, it can\ncause mode collapse of the underlying belief distribution during importance\nsampling. If the region surrounding the true state suffers from mode collapse,\nrecovering its belief is challenging since the area is no longer represented in\nthe probability mass formed by the particles. Previous methods mitigate this\nproblem by randomizing and resetting particles in the belief distribution, but\ndetermining the frequency of reinvigoration has relied on hand-tuning abstract\nheuristics. In this paper, we estimate the necessary reinvigoration rate at\neach time step by introducing a Counter-Hypothetical likelihood function, which\nis used alongside the standard likelihood. Inspired by the notions of\nplausibility and implausibility from Evidential Reasoning, the addition of our\nCounter-Hypothetical likelihood function assigns a level of doubt to each\nparticle. The competing cumulative values of confidence and doubt across the\nparticle set are used to estimate the level of failure within the filter, in\norder to determine the portion of particles to be reinvigorated. We demonstrate\nthe effectiveness of our method on the rigid body object 6D pose tracking task.\n","authors":["Elizabeth A. Olson","Jana Pavlasek","Jasmine A. Berry","Odest Chadwicke Jenkins"],"pdf_url":"https://arxiv.org/pdf/2305.17828v2.pdf","comment":"International Conference on Robotics and Automation (ICRA) 2023"},{"id":"http://arxiv.org/abs/2410.17357v1","updated":"2024-10-22T18:50:20Z","published":"2024-10-22T18:50:20Z","title":"Image-aware Evaluation of Generated Medical Reports","summary":"  The paper proposes a novel evaluation metric for automatic medical report\ngeneration from X-ray images, VLScore. It aims to overcome the limitations of\nexisting evaluation methods, which either focus solely on textual similarities,\nignoring clinical aspects, or concentrate only on a single clinical aspect, the\npathology, neglecting all other factors. The key idea of our metric is to\nmeasure the similarity between radiology reports while considering the\ncorresponding image. We demonstrate the benefit of our metric through\nevaluation on a dataset where radiologists marked errors in pairs of reports,\nshowing notable alignment with radiologists' judgments. In addition, we provide\na new dataset for evaluating metrics. This dataset includes well-designed\nperturbations that distinguish between significant modifications (e.g., removal\nof a diagnosis) and insignificant ones. It highlights the weaknesses in current\nevaluation metrics and provides a clear framework for analysis.\n","authors":["Gefen Dawidowicz","Elad Hirsch","Ayellet Tal"],"pdf_url":"https://arxiv.org/pdf/2410.17357v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.15392v2","updated":"2024-10-22T18:22:20Z","published":"2024-10-20T13:44:24Z","title":"EF-3DGS: Event-Aided Free-Trajectory 3D Gaussian Splatting","summary":"  Scene reconstruction from casually captured videos has wide applications in\nreal-world scenarios. With recent advancements in differentiable rendering\ntechniques, several methods have attempted to simultaneously optimize scene\nrepresentations (NeRF or 3DGS) and camera poses. Despite recent progress,\nexisting methods relying on traditional camera input tend to fail in high-speed\n(or equivalently low-frame-rate) scenarios. Event cameras, inspired by\nbiological vision, record pixel-wise intensity changes asynchronously with high\ntemporal resolution, providing valuable scene and motion information in blind\ninter-frame intervals. In this paper, we introduce the event camera to aid\nscene construction from a casually captured video for the first time, and\npropose Event-Aided Free-Trajectory 3DGS, called EF-3DGS, which seamlessly\nintegrates the advantages of event cameras into 3DGS through three key\ncomponents. First, we leverage the Event Generation Model (EGM) to fuse events\nand frames, supervising the rendered views observed by the event stream.\nSecond, we adopt the Contrast Maximization (CMax) framework in a piece-wise\nmanner to extract motion information by maximizing the contrast of the Image of\nWarped Events (IWE), thereby calibrating the estimated poses. Besides, based on\nthe Linear Event Generation Model (LEGM), the brightness information encoded in\nthe IWE is also utilized to constrain the 3DGS in the gradient domain. Third,\nto mitigate the absence of color information of events, we introduce\nphotometric bundle adjustment (PBA) to ensure view consistency across events\nand frames. We evaluate our method on the public Tanks and Temples benchmark\nand a newly collected real-world dataset, RealEv-DAVIS. Our project page is\nhttps://lbh666.github.io/ef-3dgs/.\n","authors":["Bohao Liao","Wei Zhai","Zengyu Wan","Tianzhu Zhang","Yang Cao","Zheng-Jun Zha"],"pdf_url":"https://arxiv.org/pdf/2410.15392v2.pdf","comment":"Project Page: https://lbh666.github.io/ef-3dgs/"},{"id":"http://arxiv.org/abs/2410.17331v1","updated":"2024-10-22T18:04:00Z","published":"2024-10-22T18:04:00Z","title":"Offline Evaluation of Set-Based Text-to-Image Generation","summary":"  Text-to-Image (TTI) systems often support people during ideation, the early\nstages of a creative process when exposure to a broad set of relevant images\ncan help explore the design space. Since ideation is an important subclass of\nTTI tasks, understanding how to quantitatively evaluate TTI systems according\nto how well they support ideation is crucial to promoting research and\ndevelopment for these users. However, existing evaluation metrics for TTI\nremain focused on distributional similarity metrics like Fr\\'echet Inception\nDistance (FID). We take an alternative approach and, based on established\nmethods from ranking evaluation, develop TTI evaluation metrics with explicit\nmodels of how users browse and interact with sets of spatially arranged\ngenerated images. Our proposed offline evaluation metrics for TTI not only\ncapture how relevant generated images are with respect to the user's ideation\nneed but also take into consideration the diversity and arrangement of the set\nof generated images. We analyze our proposed family of TTI metrics using human\nstudies on image grids generated by three different TTI systems based on\nsubsets of the widely used benchmarks such as MS-COCO captions and Localized\nNarratives as well as prompts used in naturalistic settings. Our results\ndemonstrate that grounding metrics in how people use systems is an important\nand understudied area of benchmark design.\n","authors":["Negar Arabzadeh","Fernando Diaz","Junfeng He"],"pdf_url":"https://arxiv.org/pdf/2410.17331v1.pdf","comment":null}],"Information Retrieval":[{"id":"http://arxiv.org/abs/2410.15586v2","updated":"2024-10-22T03:07:11Z","published":"2024-10-21T02:11:48Z","title":"Automatic Search of Multiword Place Names on Historical Maps","summary":"  Historical maps are invaluable sources of information about the past, and\nscanned historical maps are increasingly accessible in online libraries. To\nretrieve maps from these large libraries that contain specific places of\ninterest, previous work has applied computer vision techniques to recognize\nwords on historical maps, enabling searches for maps that contain specific\nplace names. However, searching for multiword place names is challenging due to\ncomplex layouts of text labels on historical maps. This paper proposes an\nefficient query method for searching a given multiword place name on historical\nmaps. Using existing methods to recognize words on historical maps, we link\nsingle-word text labels into potential multiword phrases by constructing\nminimum spanning trees. These trees aim to link pairs of text labels that are\nspatially close and have similar height, angle, and capitalization. We then\nquery these trees for the given multiword place name. We evaluate the proposed\nmethod in two experiments: 1) to evaluate the accuracy of the minimum spanning\ntree approach at linking multiword place names and 2) to evaluate the number\nand time range of maps retrieved by the query approach. The resulting maps\nreveal how places using multiword names have changed on a large number of maps\nfrom across history.\n","authors":["Rhett Olson","Jina Kim","Yao-Yi Chiang"],"pdf_url":"https://arxiv.org/pdf/2410.15586v2.pdf","comment":"4 pages, 4 figures, and 2 tables. To be published in proceedings ACM\n  SIGSPATIAL 2024 GeoSearch Workshop"},{"id":"http://arxiv.org/abs/2410.13428v3","updated":"2024-10-22T07:33:52Z","published":"2024-10-17T10:51:34Z","title":"Generate and Instantiate What You Prefer: Text-Guided Diffusion for\n  Sequential Recommendation","summary":"  Recent advancements in generative recommendation systems, particularly in the\nrealm of sequential recommendation tasks, have shown promise in enhancing\ngeneralization to new items. Among these approaches, diffusion-based generative\nrecommendation has emerged as an effective tool, leveraging its ability to\ncapture data distributions and generate high-quality samples. Despite\neffectiveness, two primary challenges have been identified: 1) the lack of\nconsistent modeling of data distribution for oracle items; and 2) the\ndifficulty in scaling to more informative control signals beyond historical\ninteractions. These issues stem from the uninformative nature of ID embeddings,\nwhich necessitate random initialization and limit the incorporation of\nadditional control signals. To address these limitations, we propose iDreamRec\nto involve more concrete prior knowledge to establish item embeddings,\nparticularly through detailed item text descriptions and advanced Text\nEmbedding Models (TEM). More importantly, by converting item descriptions into\nembeddings aligned with TEM, we enable the integration of intention\ninstructions as control signals to guide the generation of oracle items.\nExperimental results on four datasets demonstrate that iDreamRec not only\noutperforms existing diffusion-based generative recommenders but also\nfacilitates the incorporation of intention instructions for more precise and\neffective recommendation generation.\n","authors":["Guoqing Hu","Zhengyi Yang","Zhibo Cai","An Zhang","Xiang Wang"],"pdf_url":"https://arxiv.org/pdf/2410.13428v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.13226v2","updated":"2024-10-22T12:28:28Z","published":"2024-10-17T05:17:01Z","title":"Research on Travel Route Planing Problems Based on Greedy Algorithm","summary":"  The route planning problem based on the greedy algorithm represents a method\nof identifying the optimal or near-optimal route between a given start point\nand end point. In this paper, the PCA method is employed initially to downscale\nthe city evaluation indexes, extract the key principal components, and then\ndownscale the data using the KMO and TOPSIS algorithms, all of which are based\non the MindSpore framework. Secondly, for the dataset that does not pass the\nKMO test, the entropy weight method and TOPSIS method will be employed for\ncomprehensive evaluation. Finally, a route planning algorithm is proposed and\noptimised based on the greedy algorithm, which provides personalised route\ncustomisation according to the different needs of tourists. In addition, the\nlocal travelling efficiency, the time required to visit tourist attractions and\nthe necessary daily breaks are considered in order to reduce the cost and avoid\nfalling into the locally optimal solution.\n","authors":["Yiquan Wang"],"pdf_url":"https://arxiv.org/pdf/2410.13226v2.pdf","comment":"5 pages, 3 figures"},{"id":"http://arxiv.org/abs/2410.17236v1","updated":"2024-10-22T17:54:45Z","published":"2024-10-22T17:54:45Z","title":"Large Language Models Empowered Personalized Web Agents","summary":"  Web agents have emerged as a promising direction to automate Web task\ncompletion based on user instructions, significantly enhancing user experience.\nRecently, Web agents have evolved from traditional agents to Large Language\nModels (LLMs)-based Web agents. Despite their success, existing LLM-based Web\nagents overlook the importance of personalized data (e.g., user profiles and\nhistorical Web behaviors) in assisting the understanding of users' personalized\ninstructions and executing customized actions. To overcome the limitation, we\nfirst formulate the task of LLM-empowered personalized Web agents, which\nintegrate personalized data and user instructions to personalize instruction\ncomprehension and action execution. To address the absence of a comprehensive\nevaluation benchmark, we construct a Personalized Web Agent Benchmark\n(PersonalWAB), featuring user instructions, personalized user data, Web\nfunctions, and two evaluation paradigms across three personalized Web tasks.\nMoreover, we propose a Personalized User Memory-enhanced Alignment (PUMA)\nframework to adapt LLMs to the personalized Web agent task. PUMA utilizes a\nmemory bank with a task-specific retrieval strategy to filter relevant\nhistorical Web behaviors. Based on the behaviors, PUMA then aligns LLMs for\npersonalized action execution through fine-tuning and direct preference\noptimization. Extensive experiments validate the superiority of PUMA over\nexisting Web agents on PersonalWAB.\n","authors":["Hongru Cai","Yongqi Li","Wenjie Wang","Fengbin Zhu","Xiaoyu Shen","Wenjie Li","Tat-Seng Chua"],"pdf_url":"https://arxiv.org/pdf/2410.17236v1.pdf","comment":"The code and data are available on the project website\n  https://hongrucai.github.io/PersonalWAB/"},{"id":"http://arxiv.org/abs/2407.12883v2","updated":"2024-10-22T17:49:31Z","published":"2024-07-16T17:58:27Z","title":"BRIGHT: A Realistic and Challenging Benchmark for Reasoning-Intensive\n  Retrieval","summary":"  Existing retrieval benchmarks primarily consist of information-seeking\nqueries (e.g., aggregated questions from search engines) where keyword or\nsemantic-based retrieval is usually sufficient. However, many complex\nreal-world queries require in-depth reasoning to identify relevant documents\nthat go beyond surface form matching. For example, finding documentation for a\ncoding question requires understanding the logic and syntax of the functions\ninvolved. To better benchmark retrieval on such challenging queries, we\nintroduce BRIGHT, the first text retrieval benchmark that requires intensive\nreasoning to retrieve relevant documents. Our dataset consists of 1,384\nreal-world queries spanning diverse domains, such as economics, psychology,\nmathematics, and coding. These queries are drawn from naturally occurring and\ncarefully curated human data. Extensive evaluation reveals that even\nstate-of-the-art retrieval models perform poorly on BRIGHT. The leading model\non the MTEB leaderboard (Muennighoff et al., 2023), which achieves a score of\n59.0 nDCG@10, produces a score of nDCG@10 of 18.3 on BRIGHT. We show that\nincorporating explicit reasoning about the query improves retrieval performance\nby up to 12.2 points. Moreover, incorporating retrieved documents from the\ntop-performing retriever boosts question-answering performance by over 6.6\npoints. We believe that BRIGHT paves the way for future research on retrieval\nsystems in more realistic and challenging settings.\n","authors":["Hongjin Su","Howard Yen","Mengzhou Xia","Weijia Shi","Niklas Muennighoff","Han-yu Wang","Haisu Liu","Quan Shi","Zachary S. Siegel","Michael Tang","Ruoxi Sun","Jinsung Yoon","Sercan O. Arik","Danqi Chen","Tao Yu"],"pdf_url":"https://arxiv.org/pdf/2407.12883v2.pdf","comment":"48 pages"},{"id":"http://arxiv.org/abs/2410.17152v1","updated":"2024-10-22T16:29:33Z","published":"2024-10-22T16:29:33Z","title":"Improving Pinterest Search Relevance Using Large Language Models","summary":"  To improve relevance scoring on Pinterest Search, we integrate Large Language\nModels (LLMs) into our search relevance model, leveraging carefully designed\ntext representations to predict the relevance of Pins effectively. Our approach\nuses search queries alongside content representations that include captions\nextracted from a generative visual language model. These are further enriched\nwith link-based text data, historically high-quality engaged queries,\nuser-curated boards, Pin titles and Pin descriptions, creating robust models\nfor predicting search relevance. We use a semi-supervised learning approach to\nefficiently scale up the amount of training data, expanding beyond the\nexpensive human labeled data available. By utilizing multilingual LLMs, our\nsystem extends training data to include unseen languages and domains, despite\ninitial data and annotator expertise being confined to English. Furthermore, we\ndistill from the LLM-based model into real-time servable model architectures\nand features. We provide comprehensive offline experimental validation for our\nproposed techniques and demonstrate the gains achieved through the final\ndeployed system at scale.\n","authors":["Han Wang","Mukuntha Narayanan Sundararaman","Onur Gungor","Yu Xu","Krishna Kamath","Rakesh Chalasani","Kurchi Subhra Hazra","Jinfeng Rao"],"pdf_url":"https://arxiv.org/pdf/2410.17152v1.pdf","comment":"CIKM 2024 Workshop on Industrial Recommendation Systems"},{"id":"http://arxiv.org/abs/2410.17134v1","updated":"2024-10-22T16:06:33Z","published":"2024-10-22T16:06:33Z","title":"TELII: Temporal Event Level Inverted Indexing for Cohort Discovery on a\n  Large Covid-19 EHR Dataset","summary":"  Cohort discovery is a crucial step in clinical research on Electronic Health\nRecord (EHR) data. Temporal queries, which are common in cohort discovery, can\nbe time-consuming and prone to errors when processed on large EHR datasets. In\nthis work, we introduce TELII, a temporal event level inverted indexing method\ndesigned for cohort discovery on large EHR datasets. TELII is engineered to\npre-compute and store the relations along with the time difference between\nevents, thereby providing fast and accurate temporal query capabilities. We\nimplemented TELII for the OPTUM de-identified COVID-19 EHR dataset, which\ncontains data from 8.87 million patients. We demonstrate four common temporal\nquery tasks and their implementation using TELII with a MongoDB backend. Our\nresults show that the temporal query speed for TELII is up to 2000 times faster\nthan that of existing non-temporal inverted indexes. TELII achieves\nmillisecond-level response times, enabling users to quickly explore event\nrelations and find preliminary evidence for their research questions. Not only\nis TELII practical and straightforward to implement, but it also offers easy\nadaptability to other EHR datasets. These advantages underscore TELII's\npotential to serve as the query engine for EHR-based applications, ensuring\nfast, accurate, and user-friendly query responses.\n","authors":["Yan Huang"],"pdf_url":"https://arxiv.org/pdf/2410.17134v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.17112v1","updated":"2024-10-22T15:37:46Z","published":"2024-10-22T15:37:46Z","title":"Enhancing Answer Attribution for Faithful Text Generation with Large\n  Language Models","summary":"  The increasing popularity of Large Language Models (LLMs) in recent years has\nchanged the way users interact with and pose questions to AI-based\nconversational systems. An essential aspect for increasing the trustworthiness\nof generated LLM answers is the ability to trace the individual claims from\nresponses back to relevant sources that support them, the process known as\nanswer attribution. While recent work has started exploring the task of answer\nattribution in LLMs, some challenges still remain. In this work, we first\nperform a case study analyzing the effectiveness of existing answer attribution\nmethods, with a focus on subtasks of answer segmentation and evidence\nretrieval. Based on the observed shortcomings, we propose new methods for\nproducing more independent and contextualized claims for better retrieval and\nattribution. The new methods are evaluated and shown to improve the performance\nof answer attribution components. We end with a discussion and outline of\nfuture directions for the task.\n","authors":["Juraj Vladika","Luca Mülln","Florian Matthes"],"pdf_url":"https://arxiv.org/pdf/2410.17112v1.pdf","comment":"Accepted to KDIR 2024 (part of IC3K 2024)"},{"id":"http://arxiv.org/abs/2312.10463v4","updated":"2024-10-22T12:40:25Z","published":"2023-12-16T14:42:46Z","title":"RecPrompt: A Self-tuning Prompting Framework for News Recommendation\n  Using Large Language Models","summary":"  News recommendations heavily rely on Natural Language Processing (NLP)\nmethods to analyze, understand, and categorize content, enabling personalized\nsuggestions based on user interests and reading behaviors. Large Language\nModels (LLMs) like GPT-4 have shown promising performance in understanding\nnatural language. However, the extent of their applicability to news\nrecommendation systems remains to be validated. This paper introduces\nRecPrompt, the first self-tuning prompting framework for news recommendation,\nleveraging the capabilities of LLMs to perform complex news recommendation\ntasks. This framework incorporates a news recommender and a prompt optimizer\nthat applies an iterative bootstrapping process to enhance recommendations\nthrough automatic prompt engineering. Extensive experimental results with 400\nusers show that RecPrompt can achieve an improvement of 3.36% in AUC, 10.49% in\nMRR, 9.64% in nDCG@5, and 6.20% in nDCG@10 compared to deep neural models.\nAdditionally, we introduce TopicScore, a novel metric to assess explainability\nby evaluating LLM's ability to summarize topics of interest for users. The\nresults show LLM's effectiveness in accurately identifying topics of interest\nand delivering comprehensive topic-based explanations.\n","authors":["Dairui Liu","Boming Yang","Honghui Du","Derek Greene","Neil Hurley","Aonghus Lawlor","Ruihai Dong","Irene Li"],"pdf_url":"https://arxiv.org/pdf/2312.10463v4.pdf","comment":"5 pages, 2 figures, and 2 tables"},{"id":"http://arxiv.org/abs/2410.16853v1","updated":"2024-10-22T09:37:29Z","published":"2024-10-22T09:37:29Z","title":"Bridging the Modality Gap: Dimension Information Alignment and Sparse\n  Spatial Constraint for Image-Text Matching","summary":"  Many contrastive learning based models have achieved advanced performance in\nimage-text matching tasks. The key of these models lies in analyzing the\ncorrelation between image-text pairs, which involves cross-modal interaction of\nembeddings in corresponding dimensions. However, the embeddings of different\nmodalities are from different models or modules, and there is a significant\nmodality gap. Directly interacting such embeddings lacks rationality and may\ncapture inaccurate correlation. Therefore, we propose a novel method called\nDIAS to bridge the modality gap from two aspects: (1) We align the information\nrepresentation of embeddings from different modalities in corresponding\ndimension to ensure the correlation calculation is based on interactions of\nsimilar information. (2) The spatial constraints of inter- and intra-modalities\nunmatched pairs are introduced to ensure the effectiveness of semantic\nalignment of the model. Besides, a sparse correlation algorithm is proposed to\nselect strong correlated spatial relationships, enabling the model to learn\nmore significant features and avoid being misled by weak correlation. Extensive\nexperiments demonstrate the superiority of DIAS, achieving 4.3\\%-10.2\\% rSum\nimprovements on Flickr30k and MSCOCO benchmarks.\n","authors":["Xiang Ma","Xuemei Li","Lexin Fang","Caiming Zhang"],"pdf_url":"https://arxiv.org/pdf/2410.16853v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.16838v1","updated":"2024-10-22T09:17:05Z","published":"2024-10-22T09:17:05Z","title":"Neural Collaborative Filtering Classification Model to Obtain Prediction\n  Reliabilities","summary":"  Neural collaborative filtering is the state of art field in the recommender\nsystems area; it provides some models that obtain accurate predictions and\nrecommendations. These models are regression-based, and they just return rating\npredictions. This paper proposes the use of a classification-based approach,\nreturning both rating predictions and their reliabilities. The extra\ninformation (prediction reliabilities) can be used in a variety of relevant\ncollaborative filtering areas such as detection of shilling attacks,\nrecommendations explanation or navigational tools to show users and items\ndependences. Additionally, recommendation reliabilities can be gracefully\nprovided to users: \"probably you will like this film\", \"almost certainly you\nwill like this song\", etc. This paper provides the proposed neural\narchitecture; it also tests that the quality of its recommendation results is\nas good as the state of art baselines. Remarkably, individual rating\npredictions are improved by using the proposed architecture compared to\nbaselines. Experiments have been performed making use of four popular public\ndatasets, showing generalizable quality results. Overall, the proposed\narchitecture improves individual rating predictions quality, maintains\nrecommendation results and opens the doors to a set of relevant collaborative\nfiltering fields.\n","authors":["Jesús Bobadilla","Abraham Gutiérrez","Santiago Alonso","Ángel González-Prieto"],"pdf_url":"https://arxiv.org/pdf/2410.16838v1.pdf","comment":"9 pages, 7 figures"},{"id":"http://arxiv.org/abs/2410.16823v1","updated":"2024-10-22T08:49:43Z","published":"2024-10-22T08:49:43Z","title":"Bridging Search and Recommendation in Generative Retrieval: Does One\n  Task Help the Other?","summary":"  Generative retrieval for search and recommendation is a promising paradigm\nfor retrieving items, offering an alternative to traditional methods that\ndepend on external indexes and nearest-neighbor searches. Instead, generative\nmodels directly associate inputs with item IDs. Given the breakthroughs of\nLarge Language Models (LLMs), these generative systems can play a crucial role\nin centralizing a variety of Information Retrieval (IR) tasks in a single model\nthat performs tasks such as query understanding, retrieval, recommendation,\nexplanation, re-ranking, and response generation. Despite the growing interest\nin such a unified generative approach for IR systems, the advantages of using a\nsingle, multi-task model over multiple specialized models are not well\nestablished in the literature. This paper investigates whether and when such a\nunified approach can outperform task-specific models in the IR tasks of search\nand recommendation, broadly co-existing in multiple industrial online\nplatforms, such as Spotify, YouTube, and Netflix. Previous work shows that (1)\nthe latent representations of items learned by generative recommenders are\nbiased towards popularity, and (2) content-based and\ncollaborative-filtering-based information can improve an item's\nrepresentations. Motivated by this, our study is guided by two hypotheses: [H1]\nthe joint training regularizes the estimation of each item's popularity, and\n[H2] the joint training regularizes the item's latent representations, where\nsearch captures content-based aspects of an item and recommendation captures\ncollaborative-filtering aspects. Our extensive experiments with both simulated\nand real-world data support both [H1] and [H2] as key contributors to the\neffectiveness improvements observed in the unified search and recommendation\ngenerative models over the single-task approaches.\n","authors":["Gustavo Penha","Ali Vardasbi","Enrico Palumbo","Marco de Nadai","Hugues Bouchard"],"pdf_url":"https://arxiv.org/pdf/2410.16823v1.pdf","comment":"Accepted for publication in the 18th ACM Conference on Recommender\n  Systems (RecSys'24)"},{"id":"http://arxiv.org/abs/2410.16780v1","updated":"2024-10-22T07:53:41Z","published":"2024-10-22T07:53:41Z","title":"Beyond Retrieval: Generating Narratives in Conversational Recommender\n  Systems","summary":"  The recent advances in Large Language Model's generation and reasoning\ncapabilities present an opportunity to develop truly conversational\nrecommendation systems. However, effectively integrating recommender system\nknowledge into LLMs for natural language generation which is tailored towards\nrecommendation tasks remains a challenge. This paper addresses this challenge\nby making two key contributions.\n  First, we introduce a new dataset (REGEN) for natural language generation\ntasks in conversational recommendations. REGEN (Reviews Enhanced with\nGEnerative Narratives) extends the Amazon Product Reviews dataset with rich\nuser narratives, including personalized explanations of product preferences,\nproduct endorsements for recommended items, and summaries of user purchase\nhistory. REGEN is made publicly available to facilitate further research.\nFurthermore, we establish benchmarks using well-known generative metrics, and\nperform an automated evaluation of the new dataset using a rater LLM. Second,\nthe paper introduces a fusion architecture (CF model with an LLM) which serves\nas a baseline for REGEN. And to the best of our knowledge, represents the first\nattempt to analyze the capabilities of LLMs in understanding recommender\nsignals and generating rich narratives. We demonstrate that LLMs can\neffectively learn from simple fusion architectures utilizing interaction-based\nCF embeddings, and this can be further enhanced using the metadata and\npersonalization data associated with items. Our experiments show that combining\nCF and content embeddings leads to improvements of 4-12% in key language\nmetrics compared to using either type of embedding individually. We also\nprovide an analysis to interpret how CF and content embeddings contribute to\nthis new generative task.\n","authors":["Krishna Sayana","Raghavendra Vasudeva","Yuri Vasilevski","Kun Su","Liam Hebert","Hubert Pham","Ambarish Jash","Sukhdeep Sodhi"],"pdf_url":"https://arxiv.org/pdf/2410.16780v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.16755v1","updated":"2024-10-22T07:20:37Z","published":"2024-10-22T07:20:37Z","title":"Coarse-to-fine Dynamic Uplift Modeling for Real-time Video\n  Recommendation","summary":"  With the rise of short video platforms, video recommendation technology faces\nmore complex challenges. Currently, there are multiple non-personalized modules\nin the video recommendation pipeline that urgently need personalized modeling\ntechniques for improvement. Inspired by the success of uplift modeling in\nonline marketing, we attempt to implement uplift modeling in the video\nrecommendation scenario. However, we face two main challenges: 1) Design and\nutilization of treatments, and 2) Capture of user real-time interest. To\naddress them, we design adjusting the distribution of videos with varying\ndurations as the treatment and propose Coarse-to-fine Dynamic Uplift Modeling\n(CDUM) for real-time video recommendation. CDUM consists of two modules, CPM\nand FIC. The former module fully utilizes the offline features of users to\nmodel their long-term preferences, while the latter module leverages online\nreal-time contextual features and request-level candidates to model users'\nreal-time interests. These two modules work together to dynamically identify\nand targeting specific user groups and applying treatments effectively.\nFurther, we conduct comprehensive experiments on the offline public and\nindustrial datasets and online A/B test, demonstrating the superiority and\neffectiveness of our proposed CDUM. Our proposed CDUM is eventually fully\ndeployed on the Kuaishou platform, serving hundreds of millions of users every\nday. The source code will be provided after the paper is accepted.\n","authors":["Chang Meng","Chenhao Zhai","Xueliang Wang","Shuchang Liu","Xiaoqiang Feng","Lantao Hu","Xiu Li","Han Li","Kun Gai"],"pdf_url":"https://arxiv.org/pdf/2410.16755v1.pdf","comment":"9 pages, 4 figures, 5 tables"},{"id":"http://arxiv.org/abs/2406.17378v2","updated":"2024-10-22T06:32:10Z","published":"2024-06-25T08:55:12Z","title":"A Text is Worth Several Tokens: Text Embedding from LLMs Secretly Aligns\n  Well with The Key Tokens","summary":"  Text embeddings from large language models (LLMs) have achieved excellent\nresults in tasks such as information retrieval, semantic textual similarity,\netc. In this work, we show an interesting finding: when feeding a text into the\nembedding LLMs, the obtained text embedding will be able to be aligned with the\nkey tokens in the input text. We first fully analyze this phenomenon on eight\nembedding LLMs and show that this phenomenon is universal and is not affected\nby model architecture, training strategy, and embedding method. With a deeper\nanalysis, we then find that the main change in embedding space between the\nembedding LLMs and their original generative LLMs is in the first principal\ncomponent. By adjusting the first principal component, we can align text\nembedding with the key tokens. Finally, we give several examples to demonstrate\nthe vast application potential of this finding: (1) we propose a simple and\npractical sparse retrieval method based on the aligned tokens, which can\nachieve 80\\% of the dense retrieval effect of the same model while reducing the\ncomputation significantly; (2) we show that our findings provide a fresh\nperspective to help understand fuzzy concepts (e.g., semantic relatedness vs.\nsemantic similarity) and emerging technologies (e.g., instruction-following\nembedding) in this field.\n","authors":["Zhijie Nie","Richong Zhang","Zhanyu Wu"],"pdf_url":"https://arxiv.org/pdf/2406.17378v2.pdf","comment":"Work in Progress"},{"id":"http://arxiv.org/abs/2410.16629v1","updated":"2024-10-22T02:18:44Z","published":"2024-10-22T02:18:44Z","title":"Cutting Through the Confusion and Hype: Understanding the True Potential\n  of Generative AI","summary":"  This paper explores the nuanced landscape of generative AI (genAI),\nparticularly focusing on neural network-based models like Large Language Models\n(LLMs). While genAI garners both optimistic enthusiasm and sceptical criticism,\nthis work seeks to provide a balanced examination of its capabilities,\nlimitations, and the profound impact it may have on societal functions and\npersonal interactions. The first section demystifies language-based genAI\nthrough detailed discussions on how LLMs learn, their computational needs,\ndistinguishing features from supporting technologies, and the inherent\nlimitations in their accuracy and reliability. Real-world examples illustrate\nthe practical applications and implications of these technologies. The latter\npart of the paper adopts a systems perspective, evaluating how the integration\nof LLMs with existing technologies can enhance productivity and address\nemerging concerns. It highlights the need for significant investment to\nunderstand the implications of recent advancements, advocating for a\nwell-informed dialogue to ethically and responsibly integrate genAI into\ndiverse sectors. The paper concludes with prospective developments and\nrecommendations, emphasizing a forward-looking approach to harnessing genAI`s\npotential while mitigating its risks.\n","authors":["Ante Prodan","Jo-An Occhipinti","Rehez Ahlip","Goran Ujdur","Harris A. Eyre","Kyle Goosen","Luke Penza","Mark Heffernan"],"pdf_url":"https://arxiv.org/pdf/2410.16629v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.16597v1","updated":"2024-10-22T00:47:54Z","published":"2024-10-22T00:47:54Z","title":"Distill-SynthKG: Distilling Knowledge Graph Synthesis Workflow for\n  Improved Coverage and Efficiency","summary":"  Knowledge graphs (KGs) generated by large language models (LLMs) are becoming\nincreasingly valuable for Retrieval-Augmented Generation (RAG) applications\nthat require knowledge-intensive reasoning. However, existing KG extraction\nmethods predominantly rely on prompt-based approaches, which are inefficient\nfor processing large-scale corpora. These approaches often suffer from\ninformation loss, particularly with long documents, due to the lack of\nspecialized design for KG construction. Additionally, there is a gap in\nevaluation datasets and methodologies for ontology-free KG construction. To\novercome these limitations, we propose SynthKG, a multi-step, document-level\nontology-free KG synthesis workflow based on LLMs. By fine-tuning a smaller LLM\non the synthesized document-KG pairs, we streamline the multi-step process into\na single-step KG generation approach called Distill-SynthKG, substantially\nreducing the number of LLM inference calls. Furthermore, we re-purpose existing\nquestion-answering datasets to establish KG evaluation datasets and introduce\nnew evaluation metrics. Using KGs produced by Distill-SynthKG, we also design a\nnovel graph-based retrieval framework for RAG. Experimental results demonstrate\nthat Distill-SynthKG not only surpasses all baseline models in KG quality --\nincluding models up to eight times larger -- but also consistently excels in\nretrieval and question-answering tasks. Our proposed graph retrieval framework\nalso outperforms all KG-retrieval methods across multiple benchmark datasets.\nWe release the SynthKG dataset and Distill-SynthKG model publicly to support\nfurther research and development.\n","authors":["Prafulla Kumar Choubey","Xin Su","Man Luo","Xiangyu Peng","Caiming Xiong","Tiep Le","Shachar Rosenman","Vasudev Lal","Phil Mui","Ricky Ho","Phillip Howard","Chien-Sheng Wu"],"pdf_url":"https://arxiv.org/pdf/2410.16597v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.16586v1","updated":"2024-10-22T00:11:41Z","published":"2024-10-22T00:11:41Z","title":"Optimizing LLMs with Direct Preferences: A Data Efficiency Perspective","summary":"  Aligning the output of Large Language Models (LLMs) with human preferences\n(e.g., by means of reinforcement learning with human feedback, or RLHF) is\nessential for ensuring their effectiveness in real-world scenarios. Despite\nsignificant advancements in LLM alignment techniques, the impact of different\ntype of preference data on model performance has yet to be systematically\nexplored. In this study, we investigate the scalability, data efficiency, and\neffectiveness of Direct Preference Optimization (DPO) in fine-tuning\npre-trained LLMs, aiming to reduce their dependency on extensive amounts of\npreference data, which is expensive to collect. We (1) systematically compare\nthe performance of models fine-tuned with varying percentages of a combined\npreference judgement dataset to define the improvement curve of DPO and assess\nits effectiveness in data-constrained environments; and (2) provide insights\nfor the development of an optimal approach for selective preference data usage.\nOur study reveals that increasing the amount of data used for training\ngenerally enhances and stabilizes model performance. Moreover, the use of a\ncombination of diverse datasets significantly improves model effectiveness.\nFurthermore, when models are trained separately using different types of\nprompts, models trained with conversational prompts outperformed those trained\nwith question answering prompts.\n","authors":["Pietro Bernardelle","Gianluca Demartini"],"pdf_url":"https://arxiv.org/pdf/2410.16586v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.17406v1","updated":"2024-10-22T20:28:57Z","published":"2024-10-22T20:28:57Z","title":"ProveRAG: Provenance-Driven Vulnerability Analysis with Automated\n  Retrieval-Augmented LLMs","summary":"  In cybersecurity, security analysts face the challenge of mitigating newly\ndiscovered vulnerabilities in real-time, with over 300,000 Common\nVulnerabilities and Exposures (CVEs) identified since 1999. The sheer volume of\nknown vulnerabilities complicates the detection of patterns for unknown\nthreats. While LLMs can assist, they often hallucinate and lack alignment with\nrecent threats. Over 25,000 vulnerabilities have been identified so far in\n2024, which are introduced after popular LLMs' (e.g., GPT-4) training data\ncutoff. This raises a major challenge of leveraging LLMs in cybersecurity,\nwhere accuracy and up-to-date information are paramount. In this work, we aim\nto improve the adaptation of LLMs in vulnerability analysis by mimicking how\nanalysts perform such tasks. We propose ProveRAG, an LLM-powered system\ndesigned to assist in rapidly analyzing CVEs with automated retrieval\naugmentation of web data while self-evaluating its responses with verifiable\nevidence. ProveRAG incorporates a self-critique mechanism to help alleviate\nomission and hallucination common in the output of LLMs applied in\ncybersecurity applications. The system cross-references data from verifiable\nsources (NVD and CWE), giving analysts confidence in the actionable insights\nprovided. Our results indicate that ProveRAG excels in delivering verifiable\nevidence to the user with over 99% and 97% accuracy in exploitation and\nmitigation strategies, respectively. This system outperforms direct prompting\nand chunking retrieval in vulnerability analysis by overcoming temporal and\ncontext-window limitations. ProveRAG guides analysts to secure their systems\nmore effectively while documenting the process for future audits.\n","authors":["Reza Fayyazi","Stella Hoyos Trueba","Michael Zuzak","Shanchieh Jay Yang"],"pdf_url":"https://arxiv.org/pdf/2410.17406v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2405.11724v2","updated":"2024-10-22T19:07:08Z","published":"2024-05-20T01:57:34Z","title":"Token-wise Influential Training Data Retrieval for Large Language Models","summary":"  Given a Large Language Model (LLM) generation, how can we identify which\ntraining data led to this generation? In this paper, we proposed RapidIn, a\nscalable framework adapting to LLMs for estimating the influence of each\ntraining data. The proposed framework consists of two stages: caching and\nretrieval. First, we compress the gradient vectors by over 200,000x, allowing\nthem to be cached on disk or in GPU/CPU memory. Then, given a generation,\nRapidIn efficiently traverses the cached gradients to estimate the influence\nwithin minutes, achieving over a 6,326x speedup. Moreover, RapidIn supports\nmulti-GPU parallelization to substantially accelerate caching and retrieval.\nOur empirical result confirms the efficiency and effectiveness of RapidIn.\n","authors":["Huawei Lin","Jikai Long","Zhaozhuo Xu","Weijie Zhao"],"pdf_url":"https://arxiv.org/pdf/2405.11724v2.pdf","comment":"Accepted to ACL 2024. Keywords: Influence Function, Influence\n  Estimation, Training Data Attribution"},{"id":"http://arxiv.org/abs/2410.17337v1","updated":"2024-10-22T18:11:43Z","published":"2024-10-22T18:11:43Z","title":"Captions Speak Louder than Images (CASLIE): Generalizing Foundation\n  Models for E-commerce from High-quality Multimodal Instruction Data","summary":"  Leveraging multimodal data to drive breakthroughs in e-commerce applications\nthrough Multimodal Foundation Models (MFMs) is gaining increasing attention\nfrom the research community. However, there are significant challenges that\nhinder the optimal use of multimodal e-commerce data by foundation models: (1)\nthe scarcity of large-scale, high-quality multimodal benchmark datasets; and\n(2) the lack of effective multimodal information integration methods. To\naddress these challenges, in this paper, we introduce MMECInstruct, the\nfirst-ever, large-scale, and high-quality multimodal instruction dataset for\ne-commerce. We also develop CASLIE, a simple, lightweight, yet effective\nframework for integrating multimodal information for e-commerce. Leveraging\nMMECInstruct, we fine-tune a series of e-commerce MFMs within CASLIE, denoted\nas CASLIE models. Our comprehensive evaluation demonstrates that CASLIE models\nsubstantially outperform 5 categories of advanced baseline models in the\nin-domain evaluation. Moreover, CASLIE models show strong generalizability to\nout-of-domain settings. MMECInstruct and CASLIE models are publicly accessible\nthrough https://ninglab.github.io/CASLIE/.\n","authors":["Xinyi Ling","Bo Peng","Hanwen Du","Zhihui Zhu","Xia Ning"],"pdf_url":"https://arxiv.org/pdf/2410.17337v1.pdf","comment":"Xinyi Ling and Bo Peng contributed equally to this paper"},{"id":"http://arxiv.org/abs/2410.17331v1","updated":"2024-10-22T18:04:00Z","published":"2024-10-22T18:04:00Z","title":"Offline Evaluation of Set-Based Text-to-Image Generation","summary":"  Text-to-Image (TTI) systems often support people during ideation, the early\nstages of a creative process when exposure to a broad set of relevant images\ncan help explore the design space. Since ideation is an important subclass of\nTTI tasks, understanding how to quantitatively evaluate TTI systems according\nto how well they support ideation is crucial to promoting research and\ndevelopment for these users. However, existing evaluation metrics for TTI\nremain focused on distributional similarity metrics like Fr\\'echet Inception\nDistance (FID). We take an alternative approach and, based on established\nmethods from ranking evaluation, develop TTI evaluation metrics with explicit\nmodels of how users browse and interact with sets of spatially arranged\ngenerated images. Our proposed offline evaluation metrics for TTI not only\ncapture how relevant generated images are with respect to the user's ideation\nneed but also take into consideration the diversity and arrangement of the set\nof generated images. We analyze our proposed family of TTI metrics using human\nstudies on image grids generated by three different TTI systems based on\nsubsets of the widely used benchmarks such as MS-COCO captions and Localized\nNarratives as well as prompts used in naturalistic settings. Our results\ndemonstrate that grounding metrics in how people use systems is an important\nand understudied area of benchmark design.\n","authors":["Negar Arabzadeh","Fernando Diaz","Junfeng He"],"pdf_url":"https://arxiv.org/pdf/2410.17331v1.pdf","comment":null}],"Machine Learning":[{"id":"http://arxiv.org/abs/2410.16152v2","updated":"2024-10-22T03:37:37Z","published":"2024-10-21T16:19:34Z","title":"Warped Diffusion: Solving Video Inverse Problems with Image Diffusion\n  Models","summary":"  Using image models naively for solving inverse video problems often suffers\nfrom flickering, texture-sticking, and temporal inconsistency in generated\nvideos. To tackle these problems, in this paper, we view frames as continuous\nfunctions in the 2D space, and videos as a sequence of continuous warping\ntransformations between different frames. This perspective allows us to train\nfunction space diffusion models only on images and utilize them to solve\ntemporally correlated inverse problems. The function space diffusion models\nneed to be equivariant with respect to the underlying spatial transformations.\nTo ensure temporal consistency, we introduce a simple post-hoc test-time\nguidance towards (self)-equivariant solutions. Our method allows us to deploy\nstate-of-the-art latent diffusion models such as Stable Diffusion XL to solve\nvideo inverse problems. We demonstrate the effectiveness of our method for\nvideo inpainting and $8\\times$ video super-resolution, outperforming existing\ntechniques based on noise transformations. We provide generated video results:\nhttps://giannisdaras.github.io/warped_diffusion.github.io/.\n","authors":["Giannis Daras","Weili Nie","Karsten Kreis","Alex Dimakis","Morteza Mardani","Nikola Borislavov Kovachki","Arash Vahdat"],"pdf_url":"https://arxiv.org/pdf/2410.16152v2.pdf","comment":"Accepted in NeurIPS 2024"},{"id":"http://arxiv.org/abs/2410.16100v2","updated":"2024-10-22T12:16:03Z","published":"2024-10-21T15:27:18Z","title":"ExDBN: Exact learning of Dynamic Bayesian Networks","summary":"  Causal learning from data has received much attention in recent years. One\nway of capturing causal relationships is by utilizing Bayesian networks. There,\none recovers a weighted directed acyclic graph, in which random variables are\nrepresented by vertices, and the weights associated with each edge represent\nthe strengths of the causal relationships between them. This concept is\nextended to capture dynamic effects by introducing a dependency on past data,\nwhich may be captured by the structural equation model, which is utilized in\nthe present contribution to formulate a score-based learning approach. A\nmixed-integer quadratic program is formulated and an algorithmic solution\nproposed, in which the pre-generation of exponentially many acyclicity\nconstraints is avoided by utilizing the so-called branch-and-cut (\"lazy\nconstraint\") method. Comparing the novel approach to the state of the art, we\nshow that the proposed approach turns out to produce excellent results when\napplied to small and medium-sized synthetic instances of up to 25 time-series.\nLastly, two interesting applications in bio-science and finance, to which the\nmethod is directly applied, further stress the opportunities in developing\nhighly accurate, globally convergent solvers that can handle modest instances.\n","authors":["Pavel Rytir","Ales Wodecki","Georgios Korpas","Jakub Marecek"],"pdf_url":"https://arxiv.org/pdf/2410.16100v2.pdf","comment":"12 pages"},{"id":"http://arxiv.org/abs/2410.16077v2","updated":"2024-10-22T09:37:45Z","published":"2024-10-21T14:55:59Z","title":"CartesianMoE: Boosting Knowledge Sharing among Experts via Cartesian\n  Product Routing in Mixture-of-Experts","summary":"  Large language models (LLM) have been attracting much attention from the\ncommunity recently, due to their remarkable performance in all kinds of\ndownstream tasks. According to the well-known scaling law, scaling up a dense\nLLM enhances its capabilities, but also significantly increases the\ncomputational complexity. Mixture-of-Experts (MoE) models address that by\nallowing the model size to grow without substantially raising training or\ninference costs. Yet MoE models face challenges regarding knowledge sharing\namong experts, making their performance somehow sensitive to routing accuracy.\nTo tackle that, previous works introduced shared experts and combined their\noutputs with those of the top $K$ routed experts in an ``addition'' manner. In\nthis paper, inspired by collective matrix factorization to learn shared\nknowledge among data, we propose CartesianMoE, which implements more effective\nknowledge sharing among experts in more like a ``multiplication'' manner.\nExtensive experimental results indicate that CartesianMoE outperforms previous\nMoE models for building LLMs, in terms of both perplexity and downstream task\nperformance. And we also find that CartesianMoE achieves better expert routing\nrobustness.\n","authors":["Zhenpeng Su","Xing Wu","Zijia Lin","Yizhe Xiong","Minxuan Lv","Guangyuan Ma","Hui Chen","Songlin Hu","Guiguang Ding"],"pdf_url":"https://arxiv.org/pdf/2410.16077v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.06003v4","updated":"2024-10-22T03:30:35Z","published":"2024-10-08T13:04:02Z","title":"Is the MMI Criterion Necessary for Interpretability? Degenerating\n  Non-causal Features to Plain Noise for Self-Rationalization","summary":"  An important line of research in the field of explainability is to extract a\nsmall subset of crucial rationales from the full input. The most widely used\ncriterion for rationale extraction is the maximum mutual information (MMI)\ncriterion. However, in certain datasets, there are spurious features\nnon-causally correlated with the label and also get high mutual information,\ncomplicating the loss landscape of MMI. Although some penalty-based methods\nhave been developed to penalize the spurious features (e.g., invariance\npenalty, intervention penalty, etc) to help MMI work better, these are merely\nremedial measures. In the optimization objectives of these methods, spurious\nfeatures are still distinguished from plain noise, which hinders the discovery\nof causal rationales. This paper aims to develop a new criterion that treats\nspurious features as plain noise, allowing the model to work on datasets rich\nin spurious features as if it were working on clean datasets, thereby making\nrationale extraction easier. We theoretically observe that removing either\nplain noise or spurious features from the input does not alter the conditional\ndistribution of the remaining components relative to the task label. However,\nsignificant changes in the conditional distribution occur only when causal\nfeatures are eliminated. Based on this discovery, the paper proposes a\ncriterion for \\textbf{M}aximizing the \\textbf{R}emaining \\textbf{D}iscrepancy\n(MRD). Experiments on six widely used datasets show that our MRD criterion\nimproves rationale quality (measured by the overlap with human-annotated\nrationales) by up to $10.4\\%$ as compared to several recent competitive MMI\nvariants. Code: \\url{https://github.com/jugechengzi/Rationalization-MRD}.\n","authors":["Wei Liu","Zhiying Deng","Zhongyu Niu","Jun Wang","Haozhao Wang","YuanKai Zhang","Ruixuan Li"],"pdf_url":"https://arxiv.org/pdf/2410.06003v4.pdf","comment":"Accepted at NeurIPS 2024. arXiv admin note: text overlap with\n  arXiv:2309.13391"},{"id":"http://arxiv.org/abs/2410.15910v2","updated":"2024-10-22T05:06:36Z","published":"2024-10-21T11:33:14Z","title":"Diverse Policies Recovering via Pointwise Mutual Information Weighted\n  Imitation Learning","summary":"  Recovering a spectrum of diverse policies from a set of expert trajectories\nis an important research topic in imitation learning. After determining a\nlatent style for a trajectory, previous diverse policies recovering methods\nusually employ a vanilla behavioral cloning learning objective conditioned on\nthe latent style, treating each state-action pair in the trajectory with equal\nimportance. Based on an observation that in many scenarios, behavioral styles\nare often highly relevant with only a subset of state-action pairs, this paper\npresents a new principled method in diverse polices recovery. In particular,\nafter inferring or assigning a latent style for a trajectory, we enhance the\nvanilla behavioral cloning by incorporating a weighting mechanism based on\npointwise mutual information. This additional weighting reflects the\nsignificance of each state-action pair's contribution to learning the style,\nthus allowing our method to focus on state-action pairs most representative of\nthat style. We provide theoretical justifications for our new objective, and\nextensive empirical evaluations confirm the effectiveness of our method in\nrecovering diverse policies from expert data.\n","authors":["Hanlin Yang","Jian Yao","Weiming Liu","Qing Wang","Hanmin Qin","Hansheng Kong","Kirk Tang","Jiechao Xiong","Chao Yu","Kai Li","Junliang Xing","Hongwu Chen","Juchao Zhuo","Qiang Fu","Yang Wei","Haobo Fu"],"pdf_url":"https://arxiv.org/pdf/2410.15910v2.pdf","comment":"18 pages, 6 figures"},{"id":"http://arxiv.org/abs/2410.15859v2","updated":"2024-10-22T08:00:00Z","published":"2024-10-21T10:39:05Z","title":"Mesa-Extrapolation: A Weave Position Encoding Method for Enhanced\n  Extrapolation in LLMs","summary":"  Large language models (LLMs), although having revolutionized many fields,\nstill suffer from the challenging extrapolation problem, where the inference\nability of LLMs sharply declines beyond their max training lengths. In this\nwork, we conduct a theoretical analysis to better understand why No Position\nEncoding (NoPE) fails outside its effective range, as well as examining the\npower of Position Encoding (PE) in this context. Our findings reveal that with\nmeticulous weave position, PE can indeed be extended beyond effective range.\nOur theorems establish that LLMs equipped with weave PE can achieve improved\nextrapolation performance without additional cost. Furthermore, we introduce a\nnovel weave PE method, Mesa-Extrapolation, which utilizes a chunk-based\ntriangular attention matrix and applies Stair PE to manage the final chunk.\nThis method not only retains competitive performance but also offers\nsubstantial benefits such as significantly reduced memory demand and faster\ninference speed. Extensive experiments validate the effectiveness of\nMesa-Extrapolation, demonstrating its potential as a scalable solution to\nenhancing LLMs applicative reach.\n","authors":["Xin Ma","Yang Liu","Jingjing Liu","Xiaoxu Ma"],"pdf_url":"https://arxiv.org/pdf/2410.15859v2.pdf","comment":"Accepted by NeurIPS 2024; 13 pages and 30 pages appendix"},{"id":"http://arxiv.org/abs/2410.15778v2","updated":"2024-10-22T05:01:28Z","published":"2024-10-21T08:42:30Z","title":"Reducing Hallucinations in Vision-Language Models via Latent Space\n  Steering","summary":"  Hallucination poses a challenge to the deployment of large vision-language\nmodels (LVLMs) in applications. Unlike in large language models (LLMs),\nhallucination in LVLMs often arises from misalignments between visual inputs\nand textual outputs. This paper investigates the underlying mechanisms of\nhallucination, focusing on the unique structure of LVLMs that distinguishes\nthem from large language models (LLMs). We identify that hallucinations often\narise from the sensitivity of text decoders to vision inputs, a natural\nphenomenon when image encoders and text decoders are pre-trained separately.\nInspired by this, we introduce Visual and Textual Intervention (VTI), a novel\ntechnique designed to reduce hallucinations by steering latent space\nrepresentations during inference to enhance the stability of vision features.\nAs a task-agnostic test-time intervention, VTI can be easily applied to any\nproblem without additional cost. Extensive experiments demonstrate that it can\neffectively reduce hallucinations and outperform baseline methods across\nmultiple metrics, highlighting the critical role of vision feature stability in\nLVLMs.\n","authors":["Sheng Liu","Haotian Ye","Lei Xing","James Zou"],"pdf_url":"https://arxiv.org/pdf/2410.15778v2.pdf","comment":"21 pages"},{"id":"http://arxiv.org/abs/2410.17242v1","updated":"2024-10-22T17:58:28Z","published":"2024-10-22T17:58:28Z","title":"LVSM: A Large View Synthesis Model with Minimal 3D Inductive Bias","summary":"  We propose the Large View Synthesis Model (LVSM), a novel transformer-based\napproach for scalable and generalizable novel view synthesis from sparse-view\ninputs. We introduce two architectures: (1) an encoder-decoder LVSM, which\nencodes input image tokens into a fixed number of 1D latent tokens, functioning\nas a fully learned scene representation, and decodes novel-view images from\nthem; and (2) a decoder-only LVSM, which directly maps input images to\nnovel-view outputs, completely eliminating intermediate scene representations.\nBoth models bypass the 3D inductive biases used in previous methods -- from 3D\nrepresentations (e.g., NeRF, 3DGS) to network designs (e.g., epipolar\nprojections, plane sweeps) -- addressing novel view synthesis with a fully\ndata-driven approach. While the encoder-decoder model offers faster inference\ndue to its independent latent representation, the decoder-only LVSM achieves\nsuperior quality, scalability, and zero-shot generalization, outperforming\nprevious state-of-the-art methods by 1.5 to 3.5 dB PSNR. Comprehensive\nevaluations across multiple datasets demonstrate that both LVSM variants\nachieve state-of-the-art novel view synthesis quality. Notably, our models\nsurpass all previous methods even with reduced computational resources (1-2\nGPUs). Please see our website for more details:\nhttps://haian-jin.github.io/projects/LVSM/ .\n","authors":["Haian Jin","Hanwen Jiang","Hao Tan","Kai Zhang","Sai Bi","Tianyuan Zhang","Fujun Luan","Noah Snavely","Zexiang Xu"],"pdf_url":"https://arxiv.org/pdf/2410.17242v1.pdf","comment":"project page: https://haian-jin.github.io/projects/LVSM/"},{"id":"http://arxiv.org/abs/2410.17238v1","updated":"2024-10-22T17:56:08Z","published":"2024-10-22T17:56:08Z","title":"SELA: Tree-Search Enhanced LLM Agents for Automated Machine Learning","summary":"  Automated Machine Learning (AutoML) approaches encompass traditional methods\nthat optimize fixed pipelines for model selection and ensembling, as well as\nnewer LLM-based frameworks that autonomously build pipelines. While LLM-based\nagents have shown promise in automating machine learning tasks, they often\ngenerate low-diversity and suboptimal code, even after multiple iterations. To\novercome these limitations, we introduce Tree-Search Enhanced LLM Agents\n(SELA), an innovative agent-based system that leverages Monte Carlo Tree Search\n(MCTS) to optimize the AutoML process. By representing pipeline configurations\nas trees, our framework enables agents to conduct experiments intelligently and\niteratively refine their strategies, facilitating a more effective exploration\nof the machine learning solution space. This novel approach allows SELA to\ndiscover optimal pathways based on experimental feedback, improving the overall\nquality of the solutions. In an extensive evaluation across 20 machine learning\ndatasets, we compare the performance of traditional and agent-based AutoML\nmethods, demonstrating that SELA achieves a win rate of 65% to 80% against each\nbaseline across all datasets. These results underscore the significant\npotential of agent-based strategies in AutoML, offering a fresh perspective on\ntackling complex machine learning challenges.\n","authors":["Yizhou Chi","Yizhang Lin","Sirui Hong","Duyi Pan","Yaying Fei","Guanghao Mei","Bangbang Liu","Tianqi Pang","Jacky Kwok","Ceyao Zhang","Bang Liu","Chenglin Wu"],"pdf_url":"https://arxiv.org/pdf/2410.17238v1.pdf","comment":"The code is available at https://github.com/geekan/MetaGPT"},{"id":"http://arxiv.org/abs/2410.17234v1","updated":"2024-10-22T17:54:03Z","published":"2024-10-22T17:54:03Z","title":"Fine-Tuning Large Language Models to Appropriately Abstain with Semantic\n  Entropy","summary":"  Large Language Models (LLMs) are known to hallucinate, whereby they generate\nplausible but inaccurate text. This phenomenon poses significant risks in\ncritical applications, such as medicine or law, necessitating robust\nhallucination mitigation strategies. While recent works have proposed\nfine-tuning methods to teach LLMs to abstain from answering questions beyond\ntheir knowledge or capabilities, these methods rely on the existence of\nground-truth labels or are limited to short-form responses. To address these\nlimitations, we propose fine-tuning using semantic entropy, an uncertainty\nmeasure derived from introspection into the model which does not require\nexternal labels. We demonstrate that our approach matches or outperforms models\nfine-tuned using prior work and achieves strong performance for both short and\nlong-form generations on a range of datasets.\n","authors":["Benedict Aaron Tjandra","Muhammed Razzak","Jannik Kossen","Kunal Handa","Yarin Gal"],"pdf_url":"https://arxiv.org/pdf/2410.17234v1.pdf","comment":"Accepted to NeurIPS Safe Generative AI Workshop 2024"},{"id":"http://arxiv.org/abs/2410.17233v1","updated":"2024-10-22T17:53:34Z","published":"2024-10-22T17:53:34Z","title":"Few-shot In-Context Preference Learning Using Large Language Models","summary":"  Designing reward functions is a core component of reinforcement learning but\ncan be challenging for truly complex behavior. Reinforcement Learning from\nHuman Feedback (RLHF) has been used to alleviate this challenge by replacing a\nhand-coded reward function with a reward function learned from preferences.\nHowever, it can be exceedingly inefficient to learn these rewards as they are\noften learned tabula rasa. We investigate whether Large Language Models (LLMs)\ncan reduce this query inefficiency by converting an iterative series of human\npreferences into code representing the rewards. We propose In-Context\nPreference Learning (ICPL), a method that uses the grounding of an LLM to\naccelerate learning reward functions from preferences. ICPL takes the\nenvironment context and task description, synthesizes a set of reward\nfunctions, and then repeatedly updates the reward functions using human\nrankings of videos of the resultant policies. Using synthetic preferences, we\ndemonstrate that ICPL is orders of magnitude more efficient than RLHF and is\neven competitive with methods that use ground-truth reward functions instead of\npreferences. Finally, we perform a series of human preference-learning trials\nand observe that ICPL extends beyond synthetic settings and can work\neffectively with humans-in-the-loop. Additional information and videos are\nprovided at https://sites.google.com/view/few-shot-icpl/home.\n","authors":["Chao Yu","Hong Lu","Jiaxuan Gao","Qixin Tan","Xinting Yang","Yu Wang","Yi Wu","Eugene Vinitsky"],"pdf_url":"https://arxiv.org/pdf/2410.17233v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.17230v1","updated":"2024-10-22T17:51:23Z","published":"2024-10-22T17:51:23Z","title":"Optimal Robust Estimation under Local and Global Corruptions: Stronger\n  Adversary and Smaller Error","summary":"  Algorithmic robust statistics has traditionally focused on the contamination\nmodel where a small fraction of the samples are arbitrarily corrupted. We\nconsider a recent contamination model that combines two kinds of corruptions:\n(i) small fraction of arbitrary outliers, as in classical robust statistics,\nand (ii) local perturbations, where samples may undergo bounded shifts on\naverage. While each noise model is well understood individually, the combined\ncontamination model poses new algorithmic challenges, with only partial results\nknown. Existing efficient algorithms are limited in two ways: (i) they work\nonly for a weak notion of local perturbations, and (ii) they obtain suboptimal\nerror for isotropic subgaussian distributions (among others). The latter\nlimitation led [NGS24, COLT'24] to hypothesize that improving the error might,\nin fact, be computationally hard. Perhaps surprisingly, we show that\ninformation theoretically optimal error can indeed be achieved in polynomial\ntime, under an even \\emph{stronger} local perturbation model (the\nsliced-Wasserstein metric as opposed to the Wasserstein metric). Notably, our\nanalysis reveals that the entire family of stability-based robust mean\nestimators continues to work optimally in a black-box manner for the combined\ncontamination model. This generalization is particularly useful in real-world\nscenarios where the specific form of data corruption is not known in advance.\nWe also present efficient algorithms for distribution learning and principal\ncomponent analysis in the combined contamination model.\n","authors":["Thanasis Pittas","Ankit Pensia"],"pdf_url":"https://arxiv.org/pdf/2410.17230v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.12101v2","updated":"2024-10-22T17:48:56Z","published":"2024-10-15T22:52:45Z","title":"The Persian Rug: solving toy models of superposition using large-scale\n  symmetries","summary":"  We present a complete mechanistic description of the algorithm learned by a\nminimal non-linear sparse data autoencoder in the limit of large input\ndimension. The model, originally presented in arXiv:2209.10652, compresses\nsparse data vectors through a linear layer and decompresses using another\nlinear layer followed by a ReLU activation. We notice that when the data is\npermutation symmetric (no input feature is privileged) large models reliably\nlearn an algorithm that is sensitive to individual weights only through their\nlarge-scale statistics. For these models, the loss function becomes\nanalytically tractable. Using this understanding, we give the explicit scalings\nof the loss at high sparsity, and show that the model is near-optimal among\nrecently proposed architectures. In particular, changing or adding to the\nactivation function any elementwise or filtering operation can at best improve\nthe model's performance by a constant factor. Finally, we forward-engineer a\nmodel with the requisite symmetries and show that its loss precisely matches\nthat of the trained models. Unlike the trained model weights, the low\nrandomness in the artificial weights results in miraculous fractal structures\nresembling a Persian rug, to which the algorithm is oblivious. Our work\ncontributes to neural network interpretability by introducing techniques for\nunderstanding the structure of autoencoders. Code to reproduce our results can\nbe found at https://github.com/KfirD/PersianRug .\n","authors":["Aditya Cowsik","Kfir Dolev","Alex Infanger"],"pdf_url":"https://arxiv.org/pdf/2410.12101v2.pdf","comment":"Improved arguments, presentation. No changes to results"},{"id":"http://arxiv.org/abs/2410.17225v1","updated":"2024-10-22T17:47:05Z","published":"2024-10-22T17:47:05Z","title":"Dhoroni: Exploring Bengali Climate Change and Environmental Views with a\n  Multi-Perspective News Dataset and Natural Language Processing","summary":"  Climate change poses critical challenges globally, disproportionately\naffecting low-income countries that often lack resources and linguistic\nrepresentation on the international stage. Despite Bangladesh's status as one\nof the most vulnerable nations to climate impacts, research gaps persist in\nBengali-language studies related to climate change and NLP. To address this\ndisparity, we introduce Dhoroni, a novel Bengali (Bangla) climate change and\nenvironmental news dataset, comprising a 2300 annotated Bangla news articles,\noffering multiple perspectives such as political influence,\nscientific/statistical data, authenticity, stance detection, and stakeholder\ninvolvement. Furthermore, we present an in-depth exploratory analysis of\nDhoroni and introduce BanglaBERT-Dhoroni family, a novel baseline model family\nfor climate and environmental opinion detection in Bangla, fine-tuned on our\ndataset. This research contributes significantly to enhancing accessibility and\nanalysis of climate discourse in Bengali (Bangla), addressing crucial\ncommunication and research gaps in climate-impacted regions like Bangladesh\nwith 180 million people.\n","authors":["Azmine Toushik Wasi","Wahid Faisal","Taj Ahmad","Abdur Rahman","Mst Rafia Islam"],"pdf_url":"https://arxiv.org/pdf/2410.17225v1.pdf","comment":"In Review"},{"id":"http://arxiv.org/abs/2410.17221v1","updated":"2024-10-22T17:45:45Z","published":"2024-10-22T17:45:45Z","title":"Scalable spectral representations for network multiagent control","summary":"  Network Markov Decision Processes (MDPs), a popular model for multi-agent\ncontrol, pose a significant challenge to efficient learning due to the\nexponential growth of the global state-action space with the number of agents.\nIn this work, utilizing the exponential decay property of network dynamics, we\nfirst derive scalable spectral local representations for network MDPs, which\ninduces a network linear subspace for the local $Q$-function of each agent.\nBuilding on these local spectral representations, we design a scalable\nalgorithmic framework for continuous state-action network MDPs, and provide\nend-to-end guarantees for the convergence of our algorithm. Empirically, we\nvalidate the effectiveness of our scalable representation-based approach on two\nbenchmark problems, and demonstrate the advantages of our approach over generic\nfunction approximation approaches to representing the local $Q$-functions.\n","authors":["Zhaolin Ren"," Runyu"," Zhang","Bo Dai","Na Li"],"pdf_url":"https://arxiv.org/pdf/2410.17221v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.17216v1","updated":"2024-10-22T17:41:14Z","published":"2024-10-22T17:41:14Z","title":"Hierarchical Upper Confidence Bounds for Constrained Online Learning","summary":"  The multi-armed bandit (MAB) problem is a foundational framework in\nsequential decision-making under uncertainty, extensively studied for its\napplications in areas such as clinical trials, online advertising, and resource\nallocation. Traditional MAB formulations, however, do not adequately capture\nscenarios where decisions are structured hierarchically, involve multi-level\nconstraints, or feature context-dependent action spaces. In this paper, we\nintroduce the hierarchical constrained bandits (HCB) framework, which extends\nthe contextual bandit problem to incorporate hierarchical decision structures\nand multi-level constraints. We propose the hierarchical constrained upper\nconfidence bound (HC-UCB) algorithm, designed to address the complexities of\nthe HCB problem by leveraging confidence bounds within a hierarchical setting.\nOur theoretical analysis establishes sublinear regret bounds for HC-UCB and\nprovides high-probability guarantees for constraint satisfaction at all\nhierarchical levels. Furthermore, we derive a minimax lower bound on the regret\nfor the HCB problem, demonstrating the near-optimality of our algorithm. The\nresults are significant for real-world applications where decision-making\nprocesses are inherently hierarchical and constrained, offering a robust and\nefficient solution that balances exploration and exploitation across multiple\nlevels of decision-making.\n","authors":["Ali Baheri"],"pdf_url":"https://arxiv.org/pdf/2410.17216v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2407.05145v2","updated":"2024-10-22T17:39:13Z","published":"2024-07-06T17:53:53Z","title":"On high-dimensional modifications of the nearest neighbor classifier","summary":"  Nearest neighbor classifier is arguably the most simple and popular\nnonparametric classifier available in the literature. However, due to the\nconcentration of pairwise distances and the violation of the neighborhood\nstructure, this classifier often suffers in high-dimension, low-sample size\n(HDLSS) situations, especially when the scale difference between the competing\nclasses dominates their location difference. Several attempts have been made in\nthe literature to take care of this problem. In this article, we discuss some\nof these existing methods and propose some new ones. We carry out some\ntheoretical investigations in this regard and analyze several simulated and\nbenchmark datasets to compare the empirical performances of proposed methods\nwith some of the existing ones.\n","authors":["Annesha Ghosh","Bilol Banerjee","Anil K. Ghosh"],"pdf_url":"https://arxiv.org/pdf/2407.05145v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.17212v1","updated":"2024-10-22T17:37:18Z","published":"2024-10-22T17:37:18Z","title":"Neuroevolution Neural Architecture Search for Evolving RNNs in Stock\n  Return Prediction and Portfolio Trading","summary":"  Stock return forecasting is a major component of numerous finance\napplications. Predicted stock returns can be incorporated into portfolio\ntrading algorithms to make informed buy or sell decisions which can optimize\nreturns. In such portfolio trading applications, the predictive performance of\na time series forecasting model is crucial. In this work, we propose the use of\nthe Evolutionary eXploration of Augmenting Memory Models (EXAMM) algorithm to\nprogressively evolve recurrent neural networks (RNNs) for stock return\npredictions. RNNs are evolved independently for each stocks and portfolio\ntrading decisions are made based on the predicted stock returns. The portfolio\nused for testing consists of the 30 companies in the Dow-Jones Index (DJI) with\neach stock have the same weight. Results show that using these evolved RNNs and\na simple daily long-short strategy can generate higher returns than both the\nDJI index and the S&P 500 Index for both 2022 (bear market) and 2023 (bull\nmarket).\n","authors":["Zimeng Lyu","Amulya Saxena","Rohaan Nadeem","Hao Zhang","Travis Desell"],"pdf_url":"https://arxiv.org/pdf/2410.17212v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.10796v2","updated":"2024-10-22T17:35:03Z","published":"2024-10-14T17:57:09Z","title":"Context-Parametric Inversion: Why Instruction Finetuning May Not\n  Actually Improve Context Reliance","summary":"  A standard practice when using large language models is for users to\nsupplement their instruction with an input context containing new information\nfor the model to process. However, models struggle to reliably follow the input\ncontext, especially when it conflicts with their parametric knowledge from\npretraining. In-principle, one would expect models to adapt to the user context\nbetter after instruction finetuning, particularly when handling knowledge\nconflicts. However, we observe a surprising failure mode: during instruction\ntuning, the context reliance under knowledge conflicts initially increases as\nexpected, but then gradually decreases as instruction finetuning progresses.\nThis happens while the performance on standard benchmarks keeps on increasing\nfar after this drop. We call this phenomenon context-parametric inversion and\nobserve it across multiple general purpose instruction tuning datasets such as\nTULU, Alpaca and Ultrachat, across different model families like Llama,\nMistral, and Pythia. We perform various controlled studies and theoretical\nanalysis to show that context-parametric inversion occurs due to examples in\nthe instruction finetuning data where the input context provides information\nthat aligns with model's parametric knowledge. Our analysis suggests some\nnatural mitigation strategies with limited but insightful gains, and serves as\na useful starting point in addressing this deficiency in instruction\nfinetuning.\n","authors":["Sachin Goyal","Christina Baek","J. Zico Kolter","Aditi Raghunathan"],"pdf_url":"https://arxiv.org/pdf/2410.10796v2.pdf","comment":"Under Review"},{"id":"http://arxiv.org/abs/2406.15291v2","updated":"2024-10-22T17:31:39Z","published":"2024-06-21T16:35:27Z","title":"Pessimistic asynchronous sampling in high-cost Bayesian optimization","summary":"  Asynchronous Bayesian optimization is a recently implemented technique that\nallows for parallel operation of experimental systems and disjointed workflows.\nContrasting with serial Bayesian optimization which individually selects\nexperiments one at a time after conducting a measurement for each experiment,\nasynchronous policies sequentially assign multiple experiments before\nmeasurements can be taken and evaluate new measurements continuously as they\nare made available. This technique allows for faster data generation and\ntherefore faster optimization of an experimental space. This work extends the\ncapabilities of asynchronous optimization methods beyond prior studies by\nevaluating four additional policies that incorporate pessimistic predictions in\nthe training data set. Combined with a conventional policy that uses model\npredictions, the five total policies were evaluated in a simulated environment\nand benchmarked with serial sampling. Under some conditions and parameter space\ndimensionalities, the pessimistic prediction asynchronous policy reached\noptimum experimental conditions in significantly fewer experiments than\nequivalent serial policies and proved to be less susceptible to convergence\nonto local optima at higher dimensions. Without accounting for the faster\nsampling rate, the pessimistic asynchronous algorithm presented in this work\ncould result in more efficient algorithm driven optimization of high-cost\nexperimental spaces. Accounting for sampling rate, the presented asynchronous\nalgorithm could allow for faster optimization in experimental spaces where\nmultiple experiments can be run before results are collected.\n","authors":["Amanda A. Volk","Kristofer G. Reyes","Jeffrey G. Ethier","Luke A. Baldwin"],"pdf_url":"https://arxiv.org/pdf/2406.15291v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.17209v1","updated":"2024-10-22T17:31:37Z","published":"2024-10-22T17:31:37Z","title":"Audio-to-Score Conversion Model Based on Whisper methodology","summary":"  This thesis develops a Transformer model based on Whisper, which extracts\nmelodies and chords from music audio and records them into ABC notation. A\ncomprehensive data processing workflow is customized for ABC notation,\nincluding data cleansing, formatting, and conversion, and a mutation mechanism\nis implemented to increase the diversity and quality of training data. This\nthesis innovatively introduces the \"Orpheus' Score\", a custom notation system\nthat converts music information into tokens, designs a custom vocabulary\nlibrary, and trains a corresponding custom tokenizer. Experiments show that\ncompared to traditional algorithms, the model has significantly improved\naccuracy and performance. While providing a convenient audio-to-score tool for\nmusic enthusiasts, this work also provides new ideas and tools for research in\nmusic information processing.\n","authors":["Hongyao Zhang","Bohang Sun"],"pdf_url":"https://arxiv.org/pdf/2410.17209v1.pdf","comment":"5 pages, 7 figures"},{"id":"http://arxiv.org/abs/2308.02594v4","updated":"2024-10-22T17:29:53Z","published":"2023-08-03T21:08:51Z","title":"SMARLA: A Safety Monitoring Approach for Deep Reinforcement Learning\n  Agents","summary":"  Deep Reinforcement Learning (DRL) has made significant advancements in\nvarious fields, such as autonomous driving, healthcare, and robotics, by\nenabling agents to learn optimal policies through interactions with their\nenvironments. However, the application of DRL in safety-critical domains\npresents challenges, particularly concerning the safety of the learned\npolicies. DRL agents, which are focused on maximizing rewards, may select\nunsafe actions, leading to safety violations. Runtime safety monitoring is thus\nessential to ensure the safe operation of these agents, especially in\nunpredictable and dynamic environments. This paper introduces SMARLA, a\nblack-box safety monitoring approach specifically designed for DRL agents.\nSMARLA utilizes machine learning to predict safety violations by observing the\nagent's behavior during execution. The approach is based on Q-values, which\nreflect the expected reward for taking actions in specific states. SMARLA\nemploys state abstraction to reduce the complexity of the state space,\nenhancing the predictive capabilities of the monitoring model. Such abstraction\nenables the early detection of unsafe states, allowing for the implementation\nof corrective and preventive measures before incidents occur. We quantitatively\nand qualitatively validated SMARLA on three well-known case studies widely used\nin DRL research. Empirical results reveal that SMARLA is accurate at predicting\nsafety violations, with a low false positive rate, and can predict violations\nat an early stage, approximately halfway through the execution of the agent,\nbefore violations occur. We also discuss different decision criteria, based on\nconfidence intervals of the predicted violation probabilities, to trigger\nsafety mechanisms aiming at a trade-off between early detection and low false\npositive rates.\n","authors":["Amirhossein Zolfagharian","Manel Abdellatif","Lionel C. Briand","Ramesh S"],"pdf_url":"https://arxiv.org/pdf/2308.02594v4.pdf","comment":null},{"id":"http://arxiv.org/abs/2312.08410v3","updated":"2024-10-22T17:29:47Z","published":"2023-12-13T11:27:15Z","title":"Universal approximation property of Banach space-valued random feature\n  models including random neural networks","summary":"  We introduce a Banach space-valued extension of random feature learning, a\ndata-driven supervised machine learning technique for large-scale kernel\napproximation. By randomly initializing the feature maps, only the linear\nreadout needs to be trained, which reduces the computational complexity\nsubstantially. Viewing random feature models as Banach space-valued random\nvariables, we prove a universal approximation result in the corresponding\nBochner space. Moreover, we derive approximation rates and an explicit\nalgorithm to learn an element of the given Banach space by such models. The\nframework of this paper includes random trigonometric/Fourier regression and in\nparticular random neural networks which are single-hidden-layer feedforward\nneural networks whose weights and biases are randomly initialized, whence only\nthe linear readout needs to be trained. For the latter, we can then lift the\nuniversal approximation property of deterministic neural networks to random\nneural networks, even within function spaces over non-compact domains, e.g.,\nweighted spaces, $L^p$-spaces, and (weighted) Sobolev spaces, where the latter\nincludes the approximation of the (weak) derivatives. In addition, we analyze\nwhen the training costs for approximating a given function grow polynomially in\nboth the input/output dimension and the reciprocal of a pre-specified tolerated\napproximation error. Furthermore, we demonstrate in a numerical example the\nempirical advantages of random feature models over their deterministic\ncounterparts.\n","authors":["Ariel Neufeld","Philipp Schmocker"],"pdf_url":"https://arxiv.org/pdf/2312.08410v3.pdf","comment":"64 pages, 3 figures"},{"id":"http://arxiv.org/abs/2410.14062v2","updated":"2024-10-22T17:23:30Z","published":"2024-10-17T22:07:53Z","title":"Data-driven rainfall prediction at a regional scale: a case study with\n  Ghana","summary":"  With a warming planet, tropical regions are expected to experience the brunt\nof climate change, with more intense and more volatile rainfall events.\nCurrently, state-of-the-art numerical weather prediction (NWP) models are known\nto struggle to produce skillful rainfall forecasts in tropical regions of\nAfrica. There is thus a pressing need for improved rainfall forecasting in\nthese regions. Over the last decade or so, the increased availability of\nlarge-scale meteorological datasets and the development of powerful machine\nlearning models have opened up new opportunities for data-driven weather\nforecasting. Focusing on Ghana in this study, we use these tools to develop two\nU-Net convolutional neural network (CNN) models, to predict 24h rainfall at 12h\nand 30h lead-time. The models were trained using data from the ERA5 reanalysis\ndataset, and the GPM-IMERG dataset. A special attention was paid to\ninterpretability. We developed a novel statistical methodology that allowed us\nto probe the relative importance of the meteorological variables input in our\nmodel, offering useful insights into the factors that drive precipitation in\nthe Ghana region. Empirically, we found that our 12h lead-time model has\nperformances that match, and in some accounts are better than the 18h lead-time\nforecasts produced by the ECMWF (as available in the TIGGE dataset). We also\nfound that combining our data-driven model with classical NWP further improves\nforecast accuracy.\n","authors":["Indrajit Kalita","Lucia Vilallonga","Yves Atchade"],"pdf_url":"https://arxiv.org/pdf/2410.14062v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2409.17932v2","updated":"2024-10-22T17:16:43Z","published":"2024-09-26T15:08:52Z","title":"Sample Compression Unleashed: New Generalization Bounds for Real Valued\n  Losses","summary":"  The sample compression theory provides generalization guarantees for\npredictors that can be fully defined using a subset of the training dataset and\na (short) message string, generally defined as a binary sequence. Previous\nworks provided generalization bounds for the zero-one loss, which is\nrestrictive notably when applied to deep learning approaches. In this paper, we\npresent a general framework for deriving new sample compression bounds that\nhold for real-valued unbounded losses. Using the Pick-To-Learn (P2L)\nmeta-algorithm, which transforms the training method of any machine-learning\npredictor to yield sample-compressed predictors, we empirically demonstrate the\ntightness of the bounds and their versatility by evaluating them on random\nforests and multiple types of neural networks.\n","authors":["Mathieu Bazinet","Valentina Zantedeschi","Pascal Germain"],"pdf_url":"https://arxiv.org/pdf/2409.17932v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.17194v1","updated":"2024-10-22T17:13:34Z","published":"2024-10-22T17:13:34Z","title":"Representation Shattering in Transformers: A Synthetic Study with\n  Knowledge Editing","summary":"  Knowledge Editing (KE) algorithms alter models' internal weights to perform\ntargeted updates to incorrect, outdated, or otherwise unwanted factual\nassociations. In order to better define the possibilities and limitations of\nthese approaches, recent work has shown that applying KE can adversely affect\nmodels' factual recall accuracy and diminish their general reasoning abilities.\nWhile these studies give broad insights into the potential harms of KE\nalgorithms, e.g., via performance evaluations on benchmarks, we argue little is\nunderstood as to why such destructive failures occur. Is it possible KE methods\ndistort representations of concepts beyond the targeted fact, hence hampering\nabilities at broad? If so, what is the extent of this distortion? To take a\nstep towards addressing such questions, we define a novel synthetic task\nwherein a Transformer is trained from scratch to internalize a ``structured''\nknowledge graph. The structure enforces relationships between entities of the\ngraph, such that editing a factual association has \"trickling effects\" on other\nentities in the graph (e.g., altering X's parent is Y to Z affects who X's\nsiblings' parent is). Through evaluations of edited models and analysis of\nextracted representations, we show that KE inadvertently affects\nrepresentations of entities beyond the targeted one, distorting relevant\nstructures that allow a model to infer unseen knowledge about an entity. We\ncall this phenomenon representation shattering and demonstrate that it results\nin degradation of factual recall and reasoning performance more broadly. To\ncorroborate our findings in a more naturalistic setup, we perform preliminary\nexperiments with a pretrained GPT-2-XL model and reproduce the representation\nshattering effect therein as well. Overall, our work yields a precise\nmechanistic hypothesis to explain why KE has adverse effects on model\ncapabilities.\n","authors":["Kento Nishi","Maya Okawa","Rahul Ramesh","Mikail Khona","Ekdeep Singh Lubana","Hidenori Tanaka"],"pdf_url":"https://arxiv.org/pdf/2410.17194v1.pdf","comment":"Under review"},{"id":"http://arxiv.org/abs/2410.17191v1","updated":"2024-10-22T17:12:21Z","published":"2024-10-22T17:12:21Z","title":"On Functional Dimension and Persistent Pseudodimension","summary":"  For any fixed feedforward ReLU neural network architecture, it is well-known\nthat many different parameter settings can determine the same function. It is\nless well-known that the degree of this redundancy is inhomogeneous across\nparameter space. In this work, we discuss two locally applicable complexity\nmeasures for ReLU network classes and what we know about the relationship\nbetween them: (1) the local functional dimension [14, 18], and (2) a local\nversion of VC dimension that we call persistent pseudodimension. The former is\neasy to compute on finite batches of points; the latter should give local\nbounds on the generalization gap, which would inform an understanding of the\nmechanics of the double descent phenomenon [7].\n","authors":["J. Elisenda Grigsby","Kathryn Lindsey"],"pdf_url":"https://arxiv.org/pdf/2410.17191v1.pdf","comment":"41 pages"},{"id":"http://arxiv.org/abs/2409.13686v2","updated":"2024-10-22T17:06:17Z","published":"2024-09-20T17:54:16Z","title":"The Impact of Large Language Models in Academia: from Writing to\n  Speaking","summary":"  Large language models (LLMs) are increasingly impacting human society,\nparticularly in textual information. Based on more than 30,000 papers and 1,000\npresentations from machine learning conferences, we examined and compared the\nwords used in writing and speaking, representing the first large-scale study of\nhow LLMs influence the two main modes of verbal communication and expression\nwithin the same group of people. Our empirical results show that LLM-style\nwords such as \"significant\" have been used more frequently in abstracts and\noral presentations. The impact on speaking is beginning to emerge and is likely\nto grow in the future, calling attention to the implicit influence and ripple\neffect of LLMs on human society.\n","authors":["Mingmeng Geng","Caixi Chen","Yanru Wu","Dongping Chen","Yao Wan","Pan Zhou"],"pdf_url":"https://arxiv.org/pdf/2409.13686v2.pdf","comment":"23 pages"},{"id":"http://arxiv.org/abs/2410.15473v2","updated":"2024-10-22T16:57:37Z","published":"2024-10-20T19:11:24Z","title":"A Bayesian Framework for Clustered Federated Learning","summary":"  One of the main challenges of federated learning (FL) is handling\nnon-independent and identically distributed (non-IID) client data, which may\noccur in practice due to unbalanced datasets and use of different data sources\nacross clients. Knowledge sharing and model personalization are key strategies\nfor addressing this issue. Clustered federated learning is a class of FL\nmethods that groups clients that observe similarly distributed data into\nclusters, such that every client is typically associated with one data\ndistribution and participates in training a model for that distribution along\ntheir cluster peers. In this paper, we present a unified Bayesian framework for\nclustered FL which associates clients to clusters. Then we propose several\npractical algorithms to handle the, otherwise growing, data associations in a\nway that trades off performance and computational complexity. This work\nprovides insights on client-cluster associations and enables client knowledge\nsharing in new ways. The proposed framework circumvents the need for unique\nclient-cluster associations, which is seen to increase the performance of the\nresulting models in a variety of experiments.\n","authors":["Peng Wu","Tales Imbiriba","Pau Closas"],"pdf_url":"https://arxiv.org/pdf/2410.15473v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.17175v1","updated":"2024-10-22T16:51:36Z","published":"2024-10-22T16:51:36Z","title":"Remote Timing Attacks on Efficient Language Model Inference","summary":"  Scaling up language models has significantly increased their capabilities.\nBut larger models are slower models, and so there is now an extensive body of\nwork (e.g., speculative sampling or parallel decoding) that improves the\n(average case) efficiency of language model generation. But these techniques\nintroduce data-dependent timing characteristics. We show it is possible to\nexploit these timing differences to mount a timing attack. By monitoring the\n(encrypted) network traffic between a victim user and a remote language model,\nwe can learn information about the content of messages by noting when responses\nare faster or slower. With complete black-box access, on open source systems we\nshow how it is possible to learn the topic of a user's conversation (e.g.,\nmedical advice vs. coding assistance) with 90%+ precision, and on production\nsystems like OpenAI's ChatGPT and Anthropic's Claude we can distinguish between\nspecific messages or infer the user's language. We further show that an active\nadversary can leverage a boosting attack to recover PII placed in messages\n(e.g., phone numbers or credit card numbers) for open source systems. We\nconclude with potential defenses and directions for future work.\n","authors":["Nicholas Carlini","Milad Nasr"],"pdf_url":"https://arxiv.org/pdf/2410.17175v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.11338v3","updated":"2024-10-22T16:39:19Z","published":"2023-06-20T07:14:37Z","title":"FDINet: Protecting against DNN Model Extraction via Feature Distortion\n  Index","summary":"  Machine Learning as a Service (MLaaS) platforms have gained popularity due to\ntheir accessibility, cost-efficiency, scalability, and rapid development\ncapabilities. However, recent research has highlighted the vulnerability of\ncloud-based models in MLaaS to model extraction attacks. In this paper, we\nintroduce FDINET, a novel defense mechanism that leverages the feature\ndistribution of deep neural network (DNN) models. Concretely, by analyzing the\nfeature distribution from the adversary's queries, we reveal that the feature\ndistribution of these queries deviates from that of the model's training set.\nBased on this key observation, we propose Feature Distortion Index (FDI), a\nmetric designed to quantitatively measure the feature distribution deviation of\nreceived queries. The proposed FDINET utilizes FDI to train a binary detector\nand exploits FDI similarity to identify colluding adversaries from distributed\nextraction attacks. We conduct extensive experiments to evaluate FDINET against\nsix state-of-the-art extraction attacks on four benchmark datasets and four\npopular model architectures. Empirical results demonstrate the following\nfindings FDINET proves to be highly effective in detecting model extraction,\nachieving a 100% detection accuracy on DFME and DaST. FDINET is highly\nefficient, using just 50 queries to raise an extraction alarm with an average\nconfidence of 96.08% for GTSRB. FDINET exhibits the capability to identify\ncolluding adversaries with an accuracy exceeding 91%. Additionally, it\ndemonstrates the ability to detect two types of adaptive attacks.\n","authors":["Hongwei Yao","Zheng Li","Haiqin Weng","Feng Xue","Zhan Qin","Kui Ren"],"pdf_url":"https://arxiv.org/pdf/2306.11338v3.pdf","comment":"Accepted to IEEE Transactions on Dependable and Secure Computing"},{"id":"http://arxiv.org/abs/2410.17161v1","updated":"2024-10-22T16:34:36Z","published":"2024-10-22T16:34:36Z","title":"Interchangeable Token Embeddings for Extendable Vocabulary and\n  Alpha-Equivalence","summary":"  We propose a novel approach for learning interchangeable tokens in language\nmodels to obtain an extendable vocabulary that can generalize to new tokens.\nOur method is designed to address alpha-equivalence, the principle that\nrenaming bound variables in a syntactic expression preserves semantics. This\nproperty arises in many formal languages such as temporal logics, in which all\nproposition symbols represent the same concept but are distinguishable from\neach other. To handle such tokens, we develop a dual-part embedding approach.\nThe first part is shared across all interchangeable tokens, thereby enforcing\nthat they represent the same core concept. The second part is randomly\ngenerated for each token, which enables distinguishability. We evaluate our\nmethod in a Transformer encoder-decoder model on two tasks: solving linear\ntemporal logic formulae and copying with extendable vocabulary. Our method\ndemonstrates promising generalization capabilities in addition to introducing a\nfavorable inductive bias for alpha-equivalence.\n","authors":["İlker Işık","Ramazan Gokberk Cinbis","Ebru Aydin Gol"],"pdf_url":"https://arxiv.org/pdf/2410.17161v1.pdf","comment":"14 pages, 5 figures"},{"id":"http://arxiv.org/abs/2410.17159v1","updated":"2024-10-22T16:33:54Z","published":"2024-10-22T16:33:54Z","title":"LiNo: Advancing Recursive Residual Decomposition of Linear and Nonlinear\n  Patterns for Robust Time Series Forecasting","summary":"  Forecasting models are pivotal in a data-driven world with vast volumes of\ntime series data that appear as a compound of vast Linear and Nonlinear\npatterns. Recent deep time series forecasting models struggle to utilize\nseasonal and trend decomposition to separate the entangled components. Such a\nstrategy only explicitly extracts simple linear patterns like trends, leaving\nthe other linear modes and vast unexplored nonlinear patterns to the residual.\nTheir flawed linear and nonlinear feature extraction models and shallow-level\ndecomposition limit their adaptation to the diverse patterns present in\nreal-world scenarios. Given this, we innovate Recursive Residual Decomposition\nby introducing explicit extraction of both linear and nonlinear patterns. This\ndeeper-level decomposition framework, which is named LiNo, captures linear\npatterns using a Li block which can be a moving average kernel, and models\nnonlinear patterns using a No block which can be a Transformer encoder. The\nextraction of these two patterns is performed alternatively and recursively. To\nachieve the full potential of LiNo, we develop the current simple linear\npattern extractor to a general learnable autoregressive model, and design a\nnovel No block that can handle all essential nonlinear patterns. Remarkably,\nthe proposed LiNo achieves state-of-the-art on thirteen real-world benchmarks\nunder univariate and multivariate forecasting scenarios. Experiments show that\ncurrent forecasting models can deliver more robust and precise results through\nthis advanced Recursive Residual Decomposition. We hope this work could offer\ninsight into designing more effective forecasting models. Code is available at\nthis Repository: https://github.com/Levi-Ackman/LiNo.\n","authors":["Guoqi Yu","Yaoming Li","Xiaoyu Guo","Dayu Wang","Zirui Liu","Shujun Wang","Tong Yang"],"pdf_url":"https://arxiv.org/pdf/2410.17159v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.17147v1","updated":"2024-10-22T16:27:29Z","published":"2024-10-22T16:27:29Z","title":"Covariance estimation using Markov chain Monte Carlo","summary":"  We investigate the complexity of covariance matrix estimation for Gibbs\ndistributions based on dependent samples from a Markov chain. We show that when\n$\\pi$ satisfies a Poincar\\'e inequality and the chain possesses a spectral gap,\nwe can achieve similar sample complexity using MCMC as compared to an estimator\nconstructed using i.i.d. samples, with potentially much better query\ncomplexity. As an application of our methods, we show improvements for the\nquery complexity in both constrained and unconstrained settings for concrete\ninstances of MCMC. In particular, we provide guarantees regarding isotropic\nrounding procedures for sampling uniformly on convex bodies.\n","authors":["Yunbum Kook","Matthew S. Zhang"],"pdf_url":"https://arxiv.org/pdf/2410.17147v1.pdf","comment":"30 pages"},{"id":"http://arxiv.org/abs/2406.01205v2","updated":"2024-10-22T16:26:55Z","published":"2024-06-03T11:15:16Z","title":"ControlSpeech: Towards Simultaneous Zero-shot Speaker Cloning and\n  Zero-shot Language Style Control With Decoupled Codec","summary":"  In this paper, we present ControlSpeech, a text-to-speech (TTS) system\ncapable of fully cloning the speaker's voice and enabling arbitrary control and\nadjustment of speaking style, merely based on a few seconds of audio prompt and\na simple textual style description prompt. Prior zero-shot TTS models and\ncontrollable TTS models either could only mimic the speaker's voice without\nfurther control and adjustment capabilities or were unrelated to\nspeaker-specific voice generation. Therefore, ControlSpeech focuses on a more\nchallenging new task-a TTS system with controllable timbre, content, and style\nat the same time. ControlSpeech takes speech prompts, content prompts, and\nstyle prompts as inputs and utilizes bidirectional attention and mask-based\nparallel decoding to capture corresponding codec representations in a discrete\ndecoupling codec space. Moreover, we discovered the issue of text style\ncontrollability in a many-to-many mapping fashion and proposed the Style\nMixture Semantic Density (SMSD) model to resolve this problem. SMSD module\nwhich is based on Gaussian mixture density networks, is designed to enhance the\nfine-grained partitioning and sampling capabilities of style semantic\ninformation and generate speech with more diverse styles. In terms of\nexperiments, we make available a controllable model toolkit called\nControlToolkit with a new style controllable dataset, some replicated baseline\nmodels and propose new metrics to evaluate both the control capability and the\nquality of generated audio in ControlSpeech. The relevant ablation studies\nvalidate the necessity of each component in ControlSpeech is necessary. We hope\nthat ControlSpeech can establish the next foundation paradigm of controllable\nspeech synthesis. The relevant code and demo are available at\nhttps://github.com/jishengpeng/ControlSpeech .\n","authors":["Shengpeng Ji","Jialong Zuo","Wen Wang","Minghui Fang","Siqi Zheng","Qian Chen","Ziyue Jiang","Hai Huang","Zehan Wang","Xize Cheng","Zhou Zhao"],"pdf_url":"https://arxiv.org/pdf/2406.01205v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.02581v3","updated":"2024-10-22T16:26:40Z","published":"2024-10-03T15:25:37Z","title":"Boosting Sample Efficiency and Generalization in Multi-agent\n  Reinforcement Learning via Equivariance","summary":"  Multi-Agent Reinforcement Learning (MARL) struggles with sample inefficiency\nand poor generalization [1]. These challenges are partially due to a lack of\nstructure or inductive bias in the neural networks typically used in learning\nthe policy. One such form of structure that is commonly observed in multi-agent\nscenarios is symmetry. The field of Geometric Deep Learning has developed\nEquivariant Graph Neural Networks (EGNN) that are equivariant (or symmetric) to\nrotations, translations, and reflections of nodes. Incorporating equivariance\nhas been shown to improve learning efficiency and decrease error [ 2 ]. In this\npaper, we demonstrate that EGNNs improve the sample efficiency and\ngeneralization in MARL. However, we also show that a naive application of EGNNs\nto MARL results in poor early exploration due to a bias in the EGNN structure.\nTo mitigate this bias, we present Exploration-enhanced Equivariant Graph Neural\nNetworks or E2GN2. We compare E2GN2 to other common function approximators\nusing common MARL benchmarks MPE and SMACv2. E2GN2 demonstrates a significant\nimprovement in sample efficiency, greater final reward convergence, and a 2x-5x\ngain in over standard GNNs in our generalization tests. These results pave the\nway for more reliable and effective solutions in complex multi-agent systems.\n","authors":["Joshua McClellan","Naveed Haghani","John Winder","Furong Huang","Pratap Tokekar"],"pdf_url":"https://arxiv.org/pdf/2410.02581v3.pdf","comment":"accepted as a poster at NeurIPS 2024"},{"id":"http://arxiv.org/abs/2410.17146v1","updated":"2024-10-22T16:26:05Z","published":"2024-10-22T16:26:05Z","title":"LiNeS: Post-training Layer Scaling Prevents Forgetting and Enhances\n  Model Merging","summary":"  Large pre-trained models exhibit impressive zero-shot performance across\ndiverse tasks, but fine-tuning often leads to catastrophic forgetting, where\nimprovements on a target domain degrade generalization on other tasks. To\naddress this challenge, we introduce LiNeS, Layer-increasing Network Scaling, a\npost-training editing technique designed to preserve pre-trained generalization\nwhile enhancing fine-tuned task performance. LiNeS scales parameter updates\nlinearly based on their layer depth within the network, maintaining shallow\nlayers close to their pre-trained values to preserve general features while\nallowing deeper layers to retain task-specific representations. We further\nextend this approach to multi-task model merging scenarios, where layer-wise\nscaling of merged parameters reduces negative task interference. LiNeS\ndemonstrates significant improvements in both single-task and multi-task\nsettings across various benchmarks in vision and natural language processing.\nIt mitigates forgetting, enhances out-of-distribution generalization,\nintegrates seamlessly with existing multi-task model merging baselines\nimproving their performance across benchmarks and model sizes, and can boost\ngeneralization when merging LLM policies aligned with different rewards via\nRLHF. Importantly, our method is simple to implement and complementary to many\nexisting techniques.\n","authors":["Ke Wang","Nikolaos Dimitriadis","Alessandro Favero","Guillermo Ortiz-Jimenez","Francois Fleuret","Pascal Frossard"],"pdf_url":"https://arxiv.org/pdf/2410.17146v1.pdf","comment":"The first two authors contributed equally to this work; Project\n  website: \\url{https://lines-merging.github.io/}"},{"id":"http://arxiv.org/abs/2410.17145v1","updated":"2024-10-22T16:26:03Z","published":"2024-10-22T16:26:03Z","title":"Can General-Purpose Large Language Models Generalize to English-Thai\n  Machine Translation ?","summary":"  Large language models (LLMs) perform well on common tasks but struggle with\ngeneralization in low-resource and low-computation settings. We examine this\nlimitation by testing various LLMs and specialized translation models on\nEnglish-Thai machine translation and code-switching datasets. Our findings\nreveal that under more strict computational constraints, such as 4-bit\nquantization, LLMs fail to translate effectively. In contrast, specialized\nmodels, with comparable or lower computational requirements, consistently\noutperform LLMs. This underscores the importance of specialized models for\nmaintaining performance under resource constraints.\n","authors":["Jirat Chiaranaipanich","Naiyarat Hanmatheekuna","Jitkapat Sawatphol","Krittamate Tiankanon","Jiramet Kinchagawat","Amrest Chinkamol","Parinthapat Pengpun","Piyalitt Ittichaiwong","Peerat Limkonchotiwat"],"pdf_url":"https://arxiv.org/pdf/2410.17145v1.pdf","comment":"Accepted in GenBench EMNLP 2024"},{"id":"http://arxiv.org/abs/2410.17142v1","updated":"2024-10-22T16:19:13Z","published":"2024-10-22T16:19:13Z","title":"Coniferest: a complete active anomaly detection framework","summary":"  We present coniferest, an open source generic purpose active anomaly\ndetection framework written in Python. The package design and implemented\nalgorithms are described. Currently, static outlier detection analysis is\nsupported via the Isolation forest algorithm. Moreover, Active Anomaly\nDiscovery (AAD) and Pineforest algorithms are available to tackle active\nanomaly detection problems. The algorithms and package performance are\nevaluated on a series of synthetic datasets. We also describe a few success\ncases which resulted from applying the package to real astronomical data in\nactive anomaly detection tasks within the SNAD project.\n","authors":["M. V. Kornilov","V. S. Korolev","K. L. Malanchev","A. D. Lavrukhina","E. Russeil","T. A. Semenikhin","E. Gangler","E. E. O. Ishida","M. V. Pruzhinskaya","A. A. Volnova","S. Sreejith"],"pdf_url":"https://arxiv.org/pdf/2410.17142v1.pdf","comment":"13 pages, 1 figure"},{"id":"http://arxiv.org/abs/2410.17135v1","updated":"2024-10-22T16:07:55Z","published":"2024-10-22T16:07:55Z","title":"Reinforcement Learning for Data-Driven Workflows in Radio\n  Interferometry. I. Principal Demonstration in Calibration","summary":"  Radio interferometry is an observational technique used to study\nastrophysical phenomena. Data gathered by an interferometer requires\nsubstantial processing before astronomers can extract the scientific\ninformation from it. Data processing consists of a sequence of calibration and\nanalysis procedures where choices must be made about the sequence of procedures\nas well as the specific configuration of the procedure itself. These choices\nare typically based on a combination of measurable data characteristics, an\nunderstanding of the instrument itself, an appreciation of the trade-offs\nbetween compute cost and accuracy, and a learned understanding of what is\nconsidered \"best practice\". A metric of absolute correctness is not always\navailable and validity is often subject to human judgment. The underlying\nprinciples and software configurations to discern a reasonable workflow for a\ngiven dataset is the subject of training workshops for students and scientists.\nOur goal is to use objective metrics that quantify best practice, and\nnumerically map out the decision space with respect to our metrics. With these\nobjective metrics we demonstrate an automated, data-driven, decision system\nthat is capable of sequencing the optimal action(s) for processing\ninterferometric data. This paper introduces a simplified description of the\nprinciples behind interferometry and the procedures required for data\nprocessing. We highlight the issues with current automation approaches and\npropose our ideas for solving these bottlenecks. A prototype is demonstrated\nand the results are discussed.\n","authors":["Brian M. Kirk","Urvashi Rau","Ramyaa Ramyaa"],"pdf_url":"https://arxiv.org/pdf/2410.17135v1.pdf","comment":"22 pages, 13 figures; accepted for publication in The Astronomical\n  Journal October 18, 2024"},{"id":"http://arxiv.org/abs/2410.17128v1","updated":"2024-10-22T16:00:44Z","published":"2024-10-22T16:00:44Z","title":"Understanding Transfer Learning via Mean-field Analysis","summary":"  We propose a novel framework for exploring generalization errors of transfer\nlearning through the lens of differential calculus on the space of probability\nmeasures. In particular, we consider two main transfer learning scenarios,\n$\\alpha$-ERM and fine-tuning with the KL-regularized empirical risk\nminimization and establish generic conditions under which the generalization\nerror and the population risk convergence rates for these scenarios are\nstudied. Based on our theoretical results, we show the benefits of transfer\nlearning with a one-hidden-layer neural network in the mean-field regime under\nsome suitable integrability and regularity assumptions on the loss and\nactivation functions.\n","authors":["Gholamali Aminian","Samuel N. Cohen","Łukasz Szpruch"],"pdf_url":"https://arxiv.org/pdf/2410.17128v1.pdf","comment":"Under review"},{"id":"http://arxiv.org/abs/2410.17126v1","updated":"2024-10-22T15:59:58Z","published":"2024-10-22T15:59:58Z","title":"Exploring RL-based LLM Training for Formal Language Tasks with\n  Programmed Rewards","summary":"  Proximal Policy Optimization (PPO) is commonly used in Reinforcement Learning\nfrom Human Feedback to align large language models (LLMs) with downstream\ntasks. This paper investigates the feasibility of using PPO for direct\nreinforcement learning (RL) from explicitly programmed reward signals, as\nopposed to indirect learning from human feedback via an intermediary reward\nmodel. We focus on tasks expressed through formal languages, such as\nmathematics and programming, where explicit reward functions can be programmed\nto automatically assess the quality of generated outputs. We apply this\napproach to a sentiment alignment task, a simple arithmetic task, and a more\ncomplex game synthesis task. The sentiment alignment task replicates prior\nresearch and serves to validate our experimental setup. Our results show that\npure RL-based training for the two formal language tasks is challenging, with\nsuccess being limited even for the simple arithmetic task. We propose a novel\nbatch-entropy regularization term to aid exploration, although training is not\nyet entirely stable. Our findings suggest that direct RL training of LLMs may\nbe more suitable for relatively minor changes, such as alignment, than for\nlearning new tasks altogether, even if an informative reward signal can be\nexpressed programmatically.\n","authors":["Alexander G. Padula","Dennis J. N. J. Soemers"],"pdf_url":"https://arxiv.org/pdf/2410.17126v1.pdf","comment":"Accepted at BNAIC 2024"},{"id":"http://arxiv.org/abs/2410.17118v1","updated":"2024-10-22T15:49:53Z","published":"2024-10-22T15:49:53Z","title":"Learning Load Balancing with GNN in MPTCP-Enabled Heterogeneous Networks","summary":"  Hybrid light fidelity (LiFi) and wireless fidelity (WiFi) networks are a\npromising paradigm of heterogeneous network (HetNet), attributed to the\ncomplementary physical properties of optical spectra and radio frequency.\nHowever, the current development of such HetNets is mostly bottlenecked by the\nexisting transmission control protocol (TCP), which restricts the user\nequipment (UE) to connecting one access point (AP) at a time. While the ongoing\ninvestigation on multipath TCP (MPTCP) can bring significant benefits, it\ncomplicates the network topology of HetNets, making the existing load balancing\n(LB) learning models less effective. Driven by this, we propose a graph neural\nnetwork (GNN)-based model to tackle the LB problem for MPTCP-enabled HetNets,\nwhich results in a partial mesh topology. Such a topology can be modeled as a\ngraph, with the channel state information and data rate requirement embedded as\nnode features, while the LB solutions are deemed as edge labels. Compared to\nthe conventional deep neural network (DNN), the proposed GNN-based model\nexhibits two key strengths: i) it can better interpret a complex network\ntopology; and ii) it can handle various numbers of APs and UEs with a single\ntrained model. Simulation results show that against the traditional\noptimisation method, the proposed learning model can achieve near-optimal\nthroughput within a gap of 11.5%, while reducing the inference time by 4 orders\nof magnitude. In contrast to the DNN model, the new method can improve the\nnetwork throughput by up to 21.7%, at a similar inference time level.\n","authors":["Han Ji","Xiping Wu","Zhihong Zeng","Chen Chen"],"pdf_url":"https://arxiv.org/pdf/2410.17118v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.09656v5","updated":"2024-10-22T15:36:34Z","published":"2023-02-19T19:03:26Z","title":"Credal Bayesian Deep Learning","summary":"  Uncertainty quantification and robustness to distribution shifts are\nimportant goals in machine learning and artificial intelligence. Although\nBayesian Neural Networks (BNNs) allow for uncertainty in the predictions to be\nassessed, different sources of predictive uncertainty cannot be distinguished\nproperly. We present Credal Bayesian Deep Learning (CBDL). Heuristically, CBDL\nallows to train an (uncountably) infinite ensemble of BNNs, using only finitely\nmany elements. This is possible thanks to prior and likelihood finitely\ngenerated credal sets (FGCSs), a concept from the imprecise probability\nliterature. Intuitively, convex combinations of a finite collection of\nprior-likelihood pairs are able to represent infinitely many such pairs. After\ntraining, CBDL outputs a set of posteriors on the parameters of the neural\nnetwork. At inference time, such posterior set is used to derive a set of\npredictive distributions that is in turn utilized to distinguish between\n(predictive) aleatoric and epistemic uncertainties, and to quantify them. The\npredictive set also produces either (i) a collection of outputs enjoying\ndesirable probabilistic guarantees, or (ii) the single output that is deemed\nthe best, that is, the one having the highest predictive lower probability --\nanother imprecise-probabilistic concept. CBDL is more robust than single BNNs\nto prior and likelihood misspecification, and to distribution shift. We show\nthat CBDL is better at quantifying and disentangling different types of\n(predictive) uncertainties than single BNNs and ensemble of BNNs. In addition,\nwe apply CBDL to two case studies to demonstrate its downstream tasks\ncapabilities: one, for motion prediction in autonomous driving scenarios, and\ntwo, to model blood glucose and insulin dynamics for artificial pancreas\ncontrol. We show that CBDL performs better when compared to an ensemble of BNNs\nbaseline.\n","authors":["Michele Caprio","Souradeep Dutta","Kuk Jin Jang","Vivian Lin","Radoslav Ivanov","Oleg Sokolsky","Insup Lee"],"pdf_url":"https://arxiv.org/pdf/2302.09656v5.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.17111v1","updated":"2024-10-22T15:36:04Z","published":"2024-10-22T15:36:04Z","title":"Permutation Picture of Graph Combinatorial Optimization Problems","summary":"  This paper proposes a framework that formulates a wide range of graph\ncombinatorial optimization problems using permutation-based representations.\nThese problems include the travelling salesman problem, maximum independent\nset, maximum cut, and various other related problems. This work potentially\nopens up new avenues for algorithm design in neural combinatorial optimization,\nbridging the gap between discrete and continuous optimization techniques.\n","authors":["Yimeng Min"],"pdf_url":"https://arxiv.org/pdf/2410.17111v1.pdf","comment":"15 pages, 2 figures"},{"id":"http://arxiv.org/abs/2410.17099v1","updated":"2024-10-22T15:22:58Z","published":"2024-10-22T15:22:58Z","title":"Human-LLM Hybrid Text Answer Aggregation for Crowd Annotations","summary":"  The quality is a crucial issue for crowd annotations. Answer aggregation is\nan important type of solution. The aggregated answers estimated from multiple\ncrowd answers to the same instance are the eventually collected annotations,\nrather than the individual crowd answers themselves. Recently, the capability\nof Large Language Models (LLMs) on data annotation tasks has attracted interest\nfrom researchers. Most of the existing studies mainly focus on the average\nperformance of individual crowd workers; several recent works studied the\nscenarios of aggregation on categorical labels and LLMs used as label creators.\nHowever, the scenario of aggregation on text answers and the role of LLMs as\naggregators are not yet well-studied. In this paper, we investigate the\ncapability of LLMs as aggregators in the scenario of close-ended crowd text\nanswer aggregation. We propose a human-LLM hybrid text answer aggregation\nmethod with a Creator-Aggregator Multi-Stage (CAMS) crowdsourcing framework. We\nmake the experiments based on public crowdsourcing datasets. The results show\nthe effectiveness of our approach based on the collaboration of crowd workers\nand LLMs.\n","authors":["Jiyi Li"],"pdf_url":"https://arxiv.org/pdf/2410.17099v1.pdf","comment":"Accepted in EMNLP 2024"},{"id":"http://arxiv.org/abs/2410.17086v1","updated":"2024-10-22T15:13:13Z","published":"2024-10-22T15:13:13Z","title":"Exploration and Persuasion","summary":"  How to incentivize self-interested agents to explore when they prefer to\nexploit? Consider a population of self-interested agents that make decisions\nunder uncertainty. They \"explore\" to acquire new information and \"exploit\" this\ninformation to make good decisions. Collectively they need to balance these two\nobjectives, but their incentives are skewed toward exploitation. This is\nbecause exploration is costly, but its benefits are spread over many agents in\nthe future.\n  \"Incentivized Exploration\" addresses this issue via strategic communication.\nConsider a benign ``principal\" which can communicate with the agents and make\nrecommendations, but cannot force the agents to comply. Moreover, suppose the\nprincipal can observe the agents' decisions and the outcomes of these\ndecisions. The goal is to design a communication and recommendation policy\nwhich (i) achieves a desirable balance between exploration and exploitation,\nand (ii) incentivizes the agents to follow recommendations. What makes it\nfeasible is \"information asymmetry\": the principal knows more than any one\nagent, as it collects information from many. It is essential that the principal\ndoes not fully reveal all its knowledge to the agents.\n  Incentivized exploration combines two important problems in, resp., machine\nlearning and theoretical economics. First, if agents always follow\nrecommendations, the principal faces a multi-armed bandit problem: essentially,\ndesign an algorithm that balances exploration and exploitation. Second,\ninteraction with a single agent corresponds to \"Bayesian persuasion\", where a\nprincipal leverages information asymmetry to convince an agent to take a\nparticular action. We provide a brief but self-contained introduction to each\nproblem through the lens of incentivized exploration, solving a key special\ncase of the former as a sub-problem of the latter.\n","authors":["Aleksandrs Slivkins"],"pdf_url":"https://arxiv.org/pdf/2410.17086v1.pdf","comment":"This is a chapter published in \"Online and Matching-Based Markets\",\n  Cambridge University Press, 2023. It has been available from the author's\n  website since 2021"},{"id":"http://arxiv.org/abs/2401.00691v3","updated":"2024-10-22T15:06:05Z","published":"2024-01-01T08:03:52Z","title":"Stochastic Gradient Descent for Nonparametric Regression","summary":"  This paper introduces an iterative algorithm for training nonparametric\nadditive models that enjoys favorable memory storage and computational\nrequirements. The algorithm can be viewed as the functional counterpart of\nstochastic gradient descent, applied to the coefficients of a truncated basis\nexpansion of the component functions. We show that the resulting estimator\nsatisfies an oracle inequality that allows for model mis-specification. In the\nwell-specified setting, by choosing the learning rate carefully across three\ndistinct stages of training, we demonstrate that its risk is minimax optimal in\nterms of the dependence on the dimensionality of the data and the size of the\ntraining sample. We also provide polynomial convergence rates even when the\ncovariates do not have full support on their domain.\n","authors":["Xin Chen","Jason M. Klusowski"],"pdf_url":"https://arxiv.org/pdf/2401.00691v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2407.05180v2","updated":"2024-10-22T14:54:42Z","published":"2024-04-22T10:33:06Z","title":"ReCAP: Recursive Cross Attention Network for Pseudo-Label Generation in\n  Robotic Surgical Skill Assessment","summary":"  In surgical skill assessment, Objective Structured Assessments of Technical\nSkills (OSATS scores) and the Global Rating Scale (GRS) are established tools\nfor evaluating the performance of surgeons during training. These metrics,\ncoupled with feedback on their performance, enable surgeons to improve and\nachieve standards of practice. Recent studies on the open-source dataset\nJIGSAW, which contains both GRS and OSATS labels, have focused on regressing\nGRS scores from kinematic signals, video data, or a combination of both. In\nthis paper, we argue that regressing the GRS score, a unitless value, by itself\nis too restrictive, and variations throughout the surgical trial do not hold\nsignificant clinical meaning. To address this gap, we developed a recurrent\ntransformer model that outputs the surgeon's performance throughout their\ntraining session by relating the model's hidden states to five OSATS scores\nderived from kinematic signals. These scores are averaged and aggregated to\nproduce a GRS prediction, enabling assessment of the model's performance\nagainst the state-of-the-art (SOTA). We report Spearman's Correlation\nCoefficient (SCC), demonstrating that our model outperforms SOTA models for all\ntasks, except for Suturing under the leave-one-subject-out (LOSO) scheme (SCC\n0.68-0.89), while achieving comparable performance for suturing and across\ntasks under the leave-one-user-out (LOUO) scheme (SCC 0.45-0.68) and beating\nSOTA for Needle Passing (0.69). We argue that relating final OSATS scores to\nshort instances throughout a surgeon's procedure is more clinically meaningful\nthan a single GRS score. This approach also allows us to translate quantitative\npredictions into qualitative feedback, which is crucial for any automated\nsurgical skill assessment pipeline. A senior surgeon validated our model's\nbehaviour and agreed with the semi-supervised predictions 77 \\% (p = 0.006) of\nthe time.\n","authors":["Julien Quarez","Matthew Elliot","Oscar Maccormac","Marc Modat","Sebastien Ourselin","Jonathan Shapey","Alejandro Granados"],"pdf_url":"https://arxiv.org/pdf/2407.05180v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.17075v1","updated":"2024-10-22T14:52:46Z","published":"2024-10-22T14:52:46Z","title":"Combinatorial Logistic Bandits","summary":"  We introduce a novel framework called combinatorial logistic bandits (CLogB),\nwhere in each round, a subset of base arms (called the super arm) is selected,\nwith the outcome of each base arm being binary and its expectation following a\nlogistic parametric model. The feedback is governed by a general arm triggering\nprocess. Our study covers CLogB with reward functions satisfying two smoothness\nconditions, capturing application scenarios such as online content delivery,\nonline learning to rank, and dynamic channel allocation. We first propose a\nsimple yet efficient algorithm, CLogUCB, utilizing a variance-agnostic\nexploration bonus. Under the 1-norm triggering probability modulated (TPM)\nsmoothness condition, CLogUCB achieves a regret bound of\n$\\tilde{O}(d\\sqrt{\\kappa KT})$, where $\\tilde{O}$ ignores logarithmic factors,\n$d$ is the dimension of the feature vector, $\\kappa$ represents the\nnonlinearity of the logistic model, and $K$ is the maximum number of base arms\na super arm can trigger. This result improves on prior work by a factor of\n$\\tilde{O}(\\sqrt{\\kappa})$. We then enhance CLogUCB with a variance-adaptive\nversion, VA-CLogUCB, which attains a regret bound of $\\tilde{O}(d\\sqrt{KT})$\nunder the same 1-norm TPM condition, improving another\n$\\tilde{O}(\\sqrt{\\kappa})$ factor. VA-CLogUCB shows even greater promise under\nthe stronger triggering probability and variance modulated (TPVM) condition,\nachieving a leading $\\tilde{O}(d\\sqrt{T})$ regret, thus removing the additional\ndependency on the action-size $K$. Furthermore, we enhance the computational\nefficiency of VA-CLogUCB by eliminating the nonconvex optimization process when\nthe context feature map is time-invariant while maintaining the tight\n$\\tilde{O}(d\\sqrt{T})$ regret. Finally, experiments on synthetic and real-world\ndatasets demonstrate the superior performance of our algorithms compared to\nbenchmark algorithms.\n","authors":["Xutong Liu","Xiangxiang Dai","Xuchuang Wang","Mohammad Hajiesmaili","John C. S. Lui"],"pdf_url":"https://arxiv.org/pdf/2410.17075v1.pdf","comment":"Accepted to ACM SIGMETRICS 2025"},{"id":"http://arxiv.org/abs/2401.03069v4","updated":"2024-10-22T14:50:29Z","published":"2024-01-05T21:30:13Z","title":"Towards Enhancing the Reproducibility of Deep Learning Bugs: An\n  Empirical Study","summary":"  Context: Deep learning has achieved remarkable progress in various domains.\nHowever, like any software system, deep learning systems contain bugs, some of\nwhich can have severe impacts, as evidenced by crashes involving autonomous\nvehicles. Despite substantial advancements in deep learning techniques, little\nresearch has focused on reproducing deep learning bugs, which is an essential\nstep for their resolution. Existing literature suggests that only 3% of deep\nlearning bugs are reproducible, underscoring the need for further research.\n  Objective: This paper examines the reproducibility of deep learning bugs. We\nidentify edit actions and useful information that could improve the\nreproducibility of deep learning bugs.\n  Method: First, we construct a dataset of 668 deep-learning bugs from Stack\nOverflow and GitHub across three frameworks and 22 architectures. Second, out\nof the 668 bugs, we select 165 bugs using stratified sampling and attempt to\ndetermine their reproducibility. While reproducing these bugs, we identify edit\nactions and useful information for their reproduction. Third, we used the\nApriori algorithm to identify useful information and edit actions required to\nreproduce specific types of bugs. Finally, we conducted a user study involving\n22 developers to assess the effectiveness of our findings in real-life\nsettings.\n  Results: We successfully reproduced 148 out of 165 bugs attempted. We\nidentified ten edit actions and five useful types of component information that\ncan help us reproduce the deep learning bugs. With the help of our findings,\nthe developers were able to reproduce 22.92% more bugs and reduce their\nreproduction time by 24.35%.\n  Conclusions: Our research addresses the critical issue of deep learning bug\nreproducibility. Practitioners and researchers can leverage our findings to\nimprove deep learning bug reproducibility.\n","authors":["Mehil B. Shah","Mohammad Masudur Rahman","Foutse Khomh"],"pdf_url":"https://arxiv.org/pdf/2401.03069v4.pdf","comment":"Accepted at the Journal of Empirical Software Engineering (EMSE)"},{"id":"http://arxiv.org/abs/2410.17066v1","updated":"2024-10-22T14:46:20Z","published":"2024-10-22T14:46:20Z","title":"Neuronal Competition Groups with Supervised STDP for Spike-Based\n  Classification","summary":"  Spike Timing-Dependent Plasticity (STDP) is a promising substitute to\nbackpropagation for local training of Spiking Neural Networks (SNNs) on\nneuromorphic hardware. STDP allows SNNs to address classification tasks by\ncombining unsupervised STDP for feature extraction and supervised STDP for\nclassification. Unsupervised STDP is usually employed with Winner-Takes-All\n(WTA) competition to learn distinct patterns. However, WTA for supervised STDP\nclassification faces unbalanced competition challenges. In this paper, we\npropose a method to effectively implement WTA competition in a spiking\nclassification layer employing first-spike coding and supervised STDP training.\nWe introduce the Neuronal Competition Group (NCG), an architecture that\nimproves classification capabilities by promoting the learning of various\npatterns per class. An NCG is a group of neurons mapped to a specific class,\nimplementing intra-class WTA and a novel competition regulation mechanism based\non two-compartment thresholds. We incorporate our proposed architecture into\nspiking classification layers trained with state-of-the-art supervised STDP\nrules. On top of two different unsupervised feature extractors, we obtain\nsignificant accuracy improvements on image recognition datasets such as\nCIFAR-10 and CIFAR-100. We show that our competition regulation mechanism is\ncrucial for ensuring balanced competition and improved class separation.\n","authors":["Gaspard Goupy","Pierre Tirilly","Ioan Marius Bilasco"],"pdf_url":"https://arxiv.org/pdf/2410.17066v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.16532v2","updated":"2024-10-22T14:40:15Z","published":"2024-08-29T13:43:36Z","title":"WavTokenizer: an Efficient Acoustic Discrete Codec Tokenizer for Audio\n  Language Modeling","summary":"  Language models have been effectively applied to modeling natural signals,\nsuch as images, video, speech, and audio. A crucial component of these models\nis the codec tokenizer, which compresses high-dimensional natural signals into\nlower-dimensional discrete tokens. In this paper, we introduce WavTokenizer,\nwhich offers several advantages over previous SOTA acoustic codec models in the\naudio domain: 1)extreme compression. By compressing the layers of quantizers\nand the temporal dimension of the discrete codec, one-second audio of 24kHz\nsampling rate requires only a single quantizer with 40 or 75 tokens. 2)improved\nsubjective quality. Despite the reduced number of tokens, WavTokenizer achieves\nstate-of-the-art reconstruction quality with outstanding UTMOS scores and\ninherently contains richer semantic information. Specifically, we achieve these\nresults by designing a broader VQ space, extended contextual windows, and\nimproved attention networks, as well as introducing a powerful multi-scale\ndiscriminator and an inverse Fourier transform structure. We conducted\nextensive reconstruction experiments in the domains of speech, audio, and\nmusic. WavTokenizer exhibited strong performance across various objective and\nsubjective metrics compared to state-of-the-art models. We also tested semantic\ninformation, VQ utilization, and adaptability to generative models.\nComprehensive ablation studies confirm the necessity of each module in\nWavTokenizer. The related code, demos, and pre-trained models are available at\nhttps://github.com/jishengpeng/WavTokenizer.\n","authors":["Shengpeng Ji","Ziyue Jiang","Wen Wang","Yifu Chen","Minghui Fang","Jialong Zuo","Qian Yang","Xize Cheng","Zehan Wang","Ruiqi Li","Ziang Zhang","Xiaoda Yang","Rongjie Huang","Yidi Jiang","Qian Chen","Siqi Zheng","Wen Wang","Zhou Zhao"],"pdf_url":"https://arxiv.org/pdf/2408.16532v2.pdf","comment":"Working in progress"},{"id":"http://arxiv.org/abs/2410.17055v1","updated":"2024-10-22T14:36:44Z","published":"2024-10-22T14:36:44Z","title":"Optimal Design for Reward Modeling in RLHF","summary":"  Reinforcement Learning from Human Feedback (RLHF) has become a popular\napproach to align language models (LMs) with human preferences. This method\ninvolves collecting a large dataset of human pairwise preferences across\nvarious text generations and using it to infer (implicitly or explicitly) a\nreward model. Numerous methods have been proposed to learn the reward model and\nalign a LM with it. However, the costly process of collecting human preferences\nhas received little attention and could benefit from theoretical insights. This\npaper addresses this issue and aims to formalize the reward training model in\nRLHF. We frame the selection of an effective dataset as a simple regret\nminimization task, using a linear contextual dueling bandit method. Given the\npotentially large number of arms, this approach is more coherent than the\nbest-arm identification setting. We then propose an offline framework for\nsolving this problem. Under appropriate assumptions - linearity of the reward\nmodel in the embedding space, and boundedness of the reward parameter - we\nderive bounds on the simple regret. Finally, we provide a lower bound that\nmatches our upper bound up to constant and logarithmic terms. To our knowledge,\nthis is the first theoretical contribution in this area to provide an offline\napproach as well as worst-case guarantees.\n","authors":["Antoine Scheid","Etienne Boursier","Alain Durmus","Michael I. Jordan","Pierre Ménard","Eric Moulines","Michal Valko"],"pdf_url":"https://arxiv.org/pdf/2410.17055v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.17050v1","updated":"2024-10-22T14:30:03Z","published":"2024-10-22T14:30:03Z","title":"UnStar: Unlearning with Self-Taught Anti-Sample Reasoning for LLMs","summary":"  The key components of machine learning are data samples for training, model\nfor learning patterns, and loss function for optimizing accuracy. Analogously,\nunlearning can potentially be achieved through anti-data samples (or\nanti-samples), unlearning method, and reversed loss function. While prior\nresearch has explored unlearning methods and reversed loss functions, the\npotential of anti-samples remains largely untapped. In this paper, we introduce\nUnSTAR: Unlearning with Self-Taught Anti-Sample Reasoning for large language\nmodels (LLMs). Our contributions are threefold; first, we propose a novel\nconcept of anti-sample-induced unlearning; second, we generate anti-samples by\nleveraging misleading rationales, which help reverse learned associations and\naccelerate the unlearning process; and third, we enable fine-grained targeted\nunlearning, allowing for the selective removal of specific associations without\nimpacting related knowledge - something not achievable by previous works.\nResults demonstrate that anti-samples offer an efficient, targeted unlearning\nstrategy for LLMs, opening new avenues for privacy-preserving machine learning\nand model modification.\n","authors":["Yash Sinha","Murari Mandal","Mohan Kankanhalli"],"pdf_url":"https://arxiv.org/pdf/2410.17050v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.17049v1","updated":"2024-10-22T14:27:43Z","published":"2024-10-22T14:27:43Z","title":"A Comparison of Baseline Models and a Transformer Network for SOC\n  Prediction in Lithium-Ion Batteries","summary":"  Accurately predicting the state of charge of Lithium-ion batteries is\nessential to the performance of battery management systems of electric\nvehicles. One of the main reasons for the slow global adoption of electric cars\nis driving range anxiety. The ability of a battery management system to\naccurately estimate the state of charge can help alleviate this problem. In\nthis paper, a comparison between data-driven state-of-charge estimation methods\nis conducted. The paper compares different neural network-based models and\ncommon regression models for SOC estimation. These models include several\nablated transformer networks, a neural network, a lasso regression model, a\nlinear regression model and a decision tree. Results of various experiments\nconducted on data obtained from natural driving cycles of the BMW i3 battery\nshow that the decision tree outperformed all other models including the more\ncomplex transformer network with self-attention and positional encoding.\n","authors":["Hadeel Aboueidah","Abdulrahman Altahhan"],"pdf_url":"https://arxiv.org/pdf/2410.17049v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.03372v3","updated":"2024-10-22T14:24:55Z","published":"2023-06-06T03:21:28Z","title":"Online Tensor Learning: Computational and Statistical Trade-offs,\n  Adaptivity and Optimal Regret","summary":"  Large tensor learning algorithms are typically computationally expensive and\nrequire storing a vast amount of data. In this paper, we propose a unified\nonline Riemannian gradient descent (oRGrad) algorithm for tensor learning,\nwhich is computationally efficient, consumes much less memory, and can handle\nsequentially arriving data while making timely predictions. The algorithm is\napplicable to both linear and generalized linear models. If the time horizon T\nis known, oRGrad achieves statistical optimality by choosing an appropriate\nfixed step size. We find that noisy tensor completion particularly benefits\nfrom online algorithms by avoiding the trimming procedure and ensuring sharp\nentry-wise statistical error, which is often technically challenging for\noffline methods. The regret of oRGrad is analyzed, revealing a fascinating\ntrilemma concerning the computational convergence rate, statistical error, and\nregret bound. By selecting an appropriate constant step size, oRGrad achieves\nan $O(T^{1/2})$ regret. We then introduce the adaptive-oRGrad algorithm, which\ncan achieve the optimal $O(\\log T)$ regret by adaptively selecting step sizes,\nregardless of whether the time horizon is known. The adaptive-oRGrad algorithm\ncan attain a statistically optimal error rate without knowing the horizon.\nComprehensive numerical simulations corroborate our theoretical findings. We\nshow that oRGrad significantly outperforms its offline counterpart in\npredicting the solar F10.7 index with tensor predictors that monitor space\nweather impacts.\n","authors":["Jingyang Li","Jian-Feng Cai","Yang Chen","Dong Xia"],"pdf_url":"https://arxiv.org/pdf/2306.03372v3.pdf","comment":"Add initialization algorithms and new application"},{"id":"http://arxiv.org/abs/2405.14677v2","updated":"2024-10-22T14:21:19Z","published":"2024-05-23T15:12:15Z","title":"RectifID: Personalizing Rectified Flow with Anchored Classifier Guidance","summary":"  Customizing diffusion models to generate identity-preserving images from\nuser-provided reference images is an intriguing new problem. The prevalent\napproaches typically require training on extensive domain-specific images to\nachieve identity preservation, which lacks flexibility across different use\ncases. To address this issue, we exploit classifier guidance, a training-free\ntechnique that steers diffusion models using an existing classifier, for\npersonalized image generation. Our study shows that based on a recent rectified\nflow framework, the major limitation of vanilla classifier guidance in\nrequiring a special classifier can be resolved with a simple fixed-point\nsolution, allowing flexible personalization with off-the-shelf image\ndiscriminators. Moreover, its solving procedure proves to be stable when\nanchored to a reference flow trajectory, with a convergence guarantee. The\nderived method is implemented on rectified flow with different off-the-shelf\nimage discriminators, delivering advantageous personalization results for human\nfaces, live subjects, and certain objects. Code is available at\nhttps://github.com/feifeiobama/RectifID.\n","authors":["Zhicheng Sun","Zhenhao Yang","Yang Jin","Haozhe Chi","Kun Xu","Kun Xu","Liwei Chen","Hao Jiang","Yang Song","Kun Gai","Yadong Mu"],"pdf_url":"https://arxiv.org/pdf/2405.14677v2.pdf","comment":"NeurIPS 2024"},{"id":"http://arxiv.org/abs/2410.17043v1","updated":"2024-10-22T14:19:29Z","published":"2024-10-22T14:19:29Z","title":"Optimizing Mixture-of-Experts Inference Time Combining Model Deployment\n  and Communication Scheduling","summary":"  As machine learning models scale in size and complexity, their computational\nrequirements become a significant barrier. Mixture-of-Experts (MoE) models\nalleviate this issue by selectively activating relevant experts. Despite this,\nMoE models are hindered by high communication overhead from all-to-all\noperations, low GPU utilization due to the synchronous communication\nconstraint, and complications from heterogeneous GPU environments.\n  This paper presents Aurora, which optimizes both model deployment and\nall-to-all communication scheduling to address these challenges in MoE\ninference. Aurora achieves minimal communication times by strategically\nordering token transmissions in all-to-all communications. It improves GPU\nutilization by colocating experts from different models on the same device,\navoiding the limitations of synchronous all-to-all communication. We analyze\nAurora's optimization strategies theoretically across four common GPU cluster\nsettings: exclusive vs. colocated models on GPUs, and homogeneous vs.\nheterogeneous GPUs. Aurora provides optimal solutions for three cases, and for\nthe remaining NP-hard scenario, it offers a polynomial-time sub-optimal\nsolution with only a 1.07x degradation from the optimal.\n  Aurora is the first approach to minimize MoE inference time via optimal model\ndeployment and communication scheduling across various scenarios. Evaluations\ndemonstrate that Aurora significantly accelerates inference, achieving speedups\nof up to 2.38x in homogeneous clusters and 3.54x in heterogeneous environments.\nMoreover, Aurora enhances GPU utilization by up to 1.5x compared to existing\nmethods.\n","authors":["Jialong Li","Shreyansh Tripathi","Lakshay Rastogi","Yiming Lei","Rui Pan","Yiting Xia"],"pdf_url":"https://arxiv.org/pdf/2410.17043v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.17042v1","updated":"2024-10-22T14:16:49Z","published":"2024-10-22T14:16:49Z","title":"Deep Memory Search: A Metaheuristic Approach for Optimizing Heuristic\n  Search","summary":"  Metaheuristic search methods have proven to be essential tools for tackling\ncomplex optimization challenges, but their full potential is often constrained\nby conventional algorithmic frameworks. In this paper, we introduce a novel\napproach called Deep Heuristic Search (DHS), which models metaheuristic search\nas a memory-driven process. DHS employs multiple search layers and memory-based\nexploration-exploitation mechanisms to navigate large, dynamic search spaces.\nBy utilizing model-free memory representations, DHS enhances the ability to\ntraverse temporal trajectories without relying on probabilistic transition\nmodels. The proposed method demonstrates significant improvements in search\nefficiency and performance across a range of heuristic optimization problems.\n","authors":["Abdel-Rahman Hedar","Alaa E. Abdel-Hakim","Wael Deabes","Youseef Alotaibi","Kheir Eddine Bouazza"],"pdf_url":"https://arxiv.org/pdf/2410.17042v1.pdf","comment":"10 pages, 6 figures"},{"id":"http://arxiv.org/abs/2404.06997v3","updated":"2024-10-22T14:09:57Z","published":"2024-04-10T13:24:27Z","title":"Agent-driven Generative Semantic Communication with Cross-Modality and\n  Prediction","summary":"  In the era of 6G, with compelling visions of intelligent transportation\nsystems and digital twins, remote surveillance is poised to become a ubiquitous\npractice. Substantial data volume and frequent updates present challenges in\nwireless networks. To address these challenges, we propose a novel agent-driven\ngenerative semantic communication (A-GSC) framework based on reinforcement\nlearning. In contrast to the existing research on semantic communication\n(SemCom), which mainly focuses on either semantic extraction or semantic\nsampling, we seamlessly integrate both by jointly considering the intrinsic\nattributes of source information and the contextual information regarding the\ntask. Notably, the introduction of generative artificial intelligence (GAI)\nenables the independent design of semantic encoders and decoders. In this work,\nwe develop an agent-assisted semantic encoder with cross-modality capability,\nwhich can track the semantic changes, channel condition, to perform adaptive\nsemantic extraction and sampling. Accordingly, we design a semantic decoder\nwith both predictive and generative capabilities, consisting of two tailored\nmodules. Moreover, the effectiveness of the designed models has been verified\nusing the UA-DETRAC dataset, demonstrating the performance gains of the overall\nA-GSC framework in both energy saving and reconstruction accuracy.\n","authors":["Wanting Yang","Zehui Xiong","Yanli Yuan","Wenchao Jiang","Tony Q. S. Quek","Merouane Debbah"],"pdf_url":"https://arxiv.org/pdf/2404.06997v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2409.16320v2","updated":"2024-10-22T14:09:10Z","published":"2024-09-21T03:45:05Z","title":"Developing a Thailand solar irradiance map using Himawari-8 satellite\n  imageries and deep learning models","summary":"  This paper presents an online platform that shows Thailand's solar irradiance\nmap every 30 minutes. It is available at https://www.cusolarforecast.com. The\nmethodology for estimating global horizontal irradiance (GHI) across Thailand\nrelies on cloud index extracted from Himawari-8 satellite imagery, Ineichen\nclear-sky model with locally-tuned Linke turbidity, and machine learning\nmodels. The methods take clear-sky irradiance, cloud index, re-analyzed GHI and\ntemperature data from the MERRA-2 database, and date-time as inputs for GHI\nestimation models, including LightGBM, LSTM, Informer, and Transformer. These\nare benchmarked with the estimate from a commercial service X by evaluating\n15-minute ground GHI data from 53 ground stations over 1.5 years from\n2022-2023. The results show that the four models have competitive performances\nand outperform the service X. The best model is LightGBM, with an MAE of 78.58\nW/sqm and RMSE of 118.97 W/sqm. Obtaining re-analyzed MERRA-2 data for Thailand\nis not economically feasible for deployment. When removing these features, the\nInformer model has a winning performance of 78.67 W/sqm in MAE. The obtained\nperformance aligns with existing literature by taking the climate zone and time\ngranularity of data into consideration. As the map shows an estimate of GHI\nover 93,000 grids with a frequent update, the paper also describes a\ncomputational framework for displaying the entire map. It tests the runtime\nperformance of deep learning models in the GHI estimation process.\n","authors":["Suwichaya Suwanwimolkul","Natanon Tongamrak","Nuttamon Thungka","Naebboon Hoonchareon","Jitkomut Songsiri"],"pdf_url":"https://arxiv.org/pdf/2409.16320v2.pdf","comment":"23 pages, 14 figures"},{"id":"http://arxiv.org/abs/2410.15608v2","updated":"2024-10-22T13:55:26Z","published":"2024-10-21T03:13:20Z","title":"Moonshine: Speech Recognition for Live Transcription and Voice Commands","summary":"  This paper introduces Moonshine, a family of speech recognition models\noptimized for live transcription and voice command processing. Moonshine is\nbased on an encoder-decoder transformer architecture and employs Rotary\nPosition Embedding (RoPE) instead of traditional absolute position embeddings.\nThe model is trained on speech segments of various lengths, but without using\nzero-padding, leading to greater efficiency for the encoder during inference\ntime. When benchmarked against OpenAI's Whisper tiny-en, Moonshine Tiny\ndemonstrates a 5x reduction in compute requirements for transcribing a\n10-second speech segment while incurring no increase in word error rates across\nstandard evaluation datasets. These results highlight Moonshine's potential for\nreal-time and resource-constrained applications.\n","authors":["Nat Jeffries","Evan King","Manjunath Kudlur","Guy Nicholson","James Wang","Pete Warden"],"pdf_url":"https://arxiv.org/pdf/2410.15608v2.pdf","comment":"7 pages, 6 figures, 3 tables"},{"id":"http://arxiv.org/abs/2410.17028v1","updated":"2024-10-22T13:52:51Z","published":"2024-10-22T13:52:51Z","title":"Can a Machine Distinguish High and Low Amount of Social Creak in Speech?","summary":"  Objectives: ncreased prevalence of social creak particularly among female\nspeakers has been reported in several studies. The study of social creak has\nbeen previously conducted by combining perceptual evaluation of speech with\nconventional acoustical parameters such as the harmonic-to-noise ratio and\ncepstral peak prominence. In the current study, machine learning (ML) was used\nto automatically distinguish speech of low amount of social creak from speech\nof high amount of social creak.\n  Methods: The amount of creak in continuous speech samples produced in Finnish\nby 90 female speakers was first perceptually assessed by two voice specialists.\nBased on their assessments, the speech samples were divided into two categories\n(low $vs$. high amount of creak). Using the speech signals and their creak\nlabels, seven different ML models were trained. Three spectral representations\nwere used as feature for each model.\n  Results: The results show that the best performance (accuracy of 71.1\\%) was\nobtained by the following two systems: an Adaboost classifier using the\nmel-spectrogram feature and a decision tree classifier using the mel-frequency\ncepstral coefficient feature.\n  Conclusions: The study of social creak is becoming increasingly popular in\nsociolinguistic and vocological research. The conventional human perceptual\nassessment of the amount of creak is laborious and therefore ML technology\ncould be used to assist researchers studying social creak. The classification\nsystems reported in this study could be considered as baselines in future\nML-based studies on social creak.\n","authors":["Anne-Maria Laukkanen","Sudarsana Reddy Kadiri","Shrikanth Narayanan","Paavo Alku"],"pdf_url":"https://arxiv.org/pdf/2410.17028v1.pdf","comment":"Accepted in Journal of Voice"},{"id":"http://arxiv.org/abs/2410.17020v1","updated":"2024-10-22T13:44:10Z","published":"2024-10-22T13:44:10Z","title":"LFME: A Simple Framework for Learning from Multiple Experts in Domain\n  Generalization","summary":"  Domain generalization (DG) methods aim to maintain good performance in an\nunseen target domain by using training data from multiple source domains. While\nsuccess on certain occasions are observed, enhancing the baseline across most\nscenarios remains challenging. This work introduces a simple yet effective\nframework, dubbed learning from multiple experts (LFME), that aims to make the\ntarget model an expert in all source domains to improve DG. Specifically,\nbesides learning the target model used in inference, LFME will also train\nmultiple experts specialized in different domains, whose output probabilities\nprovide professional guidance by simply regularizing the logit of the target\nmodel. Delving deep into the framework, we reveal that the introduced logit\nregularization term implicitly provides effects of enabling the target model to\nharness more information, and mining hard samples from the experts during\ntraining. Extensive experiments on benchmarks from different DG tasks\ndemonstrate that LFME is consistently beneficial to the baseline and can\nachieve comparable performance to existing arts. Code is available\nat~\\url{https://github.com/liangchen527/LFME}.\n","authors":["Liang Chen","Yong Zhang","Yibing Song","Zhiqiang Shen","Lingqiao Liu"],"pdf_url":"https://arxiv.org/pdf/2410.17020v1.pdf","comment":"Accepted by NeurIPS 2024"},{"id":"http://arxiv.org/abs/2406.02362v3","updated":"2024-10-22T13:43:01Z","published":"2024-06-04T14:39:51Z","title":"Temporal Graph Rewiring with Expander Graphs","summary":"  Evolving relations in real-world networks are often modelled by temporal\ngraphs. Temporal Graph Neural Networks (TGNNs) emerged to model evolutionary\nbehaviour of such graphs by leveraging the message passing primitive at the\ncore of Graph Neural Networks (GNNs). It is well-known that GNNs are vulnerable\nto several issues directly related to the input graph topology, such as\nunder-reaching and over-squashing - we argue that these issues can often get\nexacerbated in temporal graphs, particularly as the result of stale nodes and\nedges. While graph rewiring techniques have seen frequent usage in GNNs to make\nthe graph topology more favourable for message passing, they have not seen any\nmainstream usage on TGNNs. In this work, we propose Temporal Graph Rewiring\n(TGR), the first approach for graph rewiring on temporal graphs, to the best of\nour knowledge. TGR constructs message passing highways between temporally\ndistant nodes in a continuous-time dynamic graph by utilizing expander graph\npropagation, a prominent framework used for graph rewiring on static graphs\nwhich makes minimal assumptions on the underlying graph structure. On the\nchallenging TGB benchmark, TGR achieves state-of-the-art results on\ntgbl-review, tgbl-coin, tgbl-comment and tgbl-flight datasets at the time of\nwriting. For tgbl-review, TGR has 50.5% improvement in MRR over the base TGN\nmodel and 22.2% improvement over the base TNCN model. The significant\nimprovement over base models demonstrates clear benefits of temporal graph\nrewiring.\n","authors":["Katarina Petrović","Shenyang Huang","Farimah Poursafaei","Petar Veličković"],"pdf_url":"https://arxiv.org/pdf/2406.02362v3.pdf","comment":"14 pages, 2 figures"},{"id":"http://arxiv.org/abs/2311.18460v3","updated":"2024-10-22T13:37:04Z","published":"2023-11-30T11:11:26Z","title":"Causal Fairness under Unobserved Confounding: A Neural Sensitivity\n  Framework","summary":"  Fairness for machine learning predictions is widely required in practice for\nlegal, ethical, and societal reasons. Existing work typically focuses on\nsettings without unobserved confounding, even though unobserved confounding can\nlead to severe violations of causal fairness and, thus, unfair predictions. In\nthis work, we analyze the sensitivity of causal fairness to unobserved\nconfounding. Our contributions are three-fold. First, we derive bounds for\ncausal fairness metrics under different sources of unobserved confounding. This\nenables practitioners to examine the sensitivity of their machine learning\nmodels to unobserved confounding in fairness-critical applications. Second, we\npropose a novel neural framework for learning fair predictions, which allows us\nto offer worst-case guarantees of the extent to which causal fairness can be\nviolated due to unobserved confounding. Third, we demonstrate the effectiveness\nof our framework in a series of experiments, including a real-world case study\nabout predicting prison sentences. To the best of our knowledge, ours is the\nfirst work to study causal fairness under unobserved confounding. To this end,\nour work is of direct practical value as a refutation strategy to ensure the\nfairness of predictions in high-stakes applications.\n","authors":["Maresa Schröder","Dennis Frauen","Stefan Feuerriegel"],"pdf_url":"https://arxiv.org/pdf/2311.18460v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.10060v2","updated":"2024-10-22T13:35:07Z","published":"2024-06-14T14:16:39Z","title":"PRIMER: Perception-Aware Robust Learning-based Multiagent Trajectory\n  Planner","summary":"  In decentralized multiagent trajectory planners, agents need to communicate\nand exchange their positions to generate collision-free trajectories. However,\ndue to localization errors/uncertainties, trajectory deconfliction can fail\neven if trajectories are perfectly shared between agents. To address this\nissue, we first present PARM and PARM*, perception-aware, decentralized,\nasynchronous multiagent trajectory planners that enable a team of agents to\nnavigate uncertain environments while deconflicting trajectories and avoiding\nobstacles using perception information. PARM* differs from PARM as it is less\nconservative, using more computation to find closer-to-optimal solutions. While\nthese methods achieve state-of-the-art performance, they suffer from high\ncomputational costs as they need to solve large optimization problems onboard,\nmaking it difficult for agents to replan at high rates. To overcome this\nchallenge, we present our second key contribution, PRIMER, a learning-based\nplanner trained with imitation learning (IL) using PARM* as the expert\ndemonstrator. PRIMER leverages the low computational requirements at deployment\nof neural networks and achieves a computation speed up to 5500 times faster\nthan optimization-based approaches.\n","authors":["Kota Kondo","Claudius T. Tewari","Andrea Tagliabue","Jesus Tordesillas","Parker C. Lusk","Jonathan P. How"],"pdf_url":"https://arxiv.org/pdf/2406.10060v2.pdf","comment":"7 pages, 3 figures"},{"id":"http://arxiv.org/abs/2405.15551v2","updated":"2024-10-22T13:32:59Z","published":"2024-05-24T13:37:48Z","title":"Thinking Forward: Memory-Efficient Federated Finetuning of Language\n  Models","summary":"  Finetuning large language models (LLMs) in federated learning (FL) settings\nhas become increasingly important as it allows resource-constrained devices to\nfinetune a model using private data. However, finetuning LLMs using\nbackpropagation requires excessive memory (especially from intermediate\nactivations) for resource-constrained devices. While Forward-mode\nAuto-Differentiation (AD) can significantly reduce memory footprint from\nactivations, we observe that directly applying it to LLM finetuning results in\nslow convergence and poor accuracy. In this paper, we introduce Spry, an FL\nalgorithm that splits trainable weights of an LLM among participating clients,\nsuch that each client computes gradients using forward-mode AD that are closer\nestimations of the true gradients. Spry achieves a low memory footprint, high\naccuracy, and fast convergence. We formally prove that the global gradients in\nSpry are unbiased estimators of true global gradients for homogeneous data\ndistributions across clients, while heterogeneity increases bias of the\nestimates. We also derive Spry's convergence rate, showing that the gradients\ndecrease inversely proportional to the number of FL rounds, indicating the\nconvergence up to the limits of heterogeneity. Empirically, Spry reduces the\nmemory footprint during training by 1.4-7.1x in contrast to backpropagation,\nwhile reaching comparable accuracy, across a wide range of language tasks,\nmodels, and FL settings. Spry reduces the convergence time by 1.2-20.3x and\nachieves 5.2-13.5% higher accuracy against zero-order methods. When finetuning\nLlama2-7B with LoRA, compared to the peak memory consumption of 33.9GB of\nbackpropagation, Spry only consumes 6.2GB of peak memory. For OPT13B, the\nreduction is from 76.5GB to 10.8GB. Spry makes feasible previously impossible\nFL deployments on commodity edge devices. Our source code is available at\nhttps://github.com/Astuary/Spry.\n","authors":["Kunjal Panchal","Nisarg Parikh","Sunav Choudhary","Lijun Zhang","Yuriy Brun","Hui Guan"],"pdf_url":"https://arxiv.org/pdf/2405.15551v2.pdf","comment":"Accepted to NeurIPS 2024"},{"id":"http://arxiv.org/abs/2406.12142v2","updated":"2024-10-22T13:32:34Z","published":"2024-06-17T23:08:46Z","title":"Slicing Through Bias: Explaining Performance Gaps in Medical Image\n  Analysis using Slice Discovery Methods","summary":"  Machine learning models have achieved high overall accuracy in medical image\nanalysis. However, performance disparities on specific patient groups pose\nchallenges to their clinical utility, safety, and fairness. This can affect\nknown patient groups - such as those based on sex, age, or disease subtype - as\nwell as previously unknown and unlabeled groups. Furthermore, the root cause of\nsuch observed performance disparities is often challenging to uncover,\nhindering mitigation efforts. In this paper, to address these issues, we\nleverage Slice Discovery Methods (SDMs) to identify interpretable\nunderperforming subsets of data and formulate hypotheses regarding the cause of\nobserved performance disparities. We introduce a novel SDM and apply it in a\ncase study on the classification of pneumothorax and atelectasis from chest\nx-rays. Our study demonstrates the effectiveness of SDMs in hypothesis\nformulation and yields an explanation of previously observed but unexplained\nperformance disparities between male and female patients in widely used chest\nX-ray datasets and models. Our findings indicate shortcut learning in both\nclassification tasks, through the presence of chest drains and ECG wires,\nrespectively. Sex-based differences in the prevalence of these shortcut\nfeatures appear to cause the observed classification performance gap,\nrepresenting a previously underappreciated interaction between shortcut\nlearning and model fairness analyses.\n","authors":["Vincent Olesen","Nina Weng","Aasa Feragen","Eike Petersen"],"pdf_url":"https://arxiv.org/pdf/2406.12142v2.pdf","comment":"MICCAI 2024 Workshop on Fairness of AI in Medical Imaging"},{"id":"http://arxiv.org/abs/2302.05765v3","updated":"2024-10-22T13:31:16Z","published":"2023-02-11T19:30:55Z","title":"Adversarial Online Collaborative Filtering","summary":"  We investigate the problem of online collaborative filtering under\nno-repetition constraints, whereby users need to be served content in an online\nfashion and a given user cannot be recommended the same content item more than\nonce. We start by designing and analyzing an algorithm that works under\nbiclustering assumptions on the user-item preference matrix, and show that this\nalgorithm exhibits an optimal regret guarantee, while being fully adaptive, in\nthat it is oblivious to any prior knowledge about the sequence of users, the\nuniverse of items, as well as the biclustering parameters of the preference\nmatrix. We then propose a more robust version of this algorithm which operates\nwith general matrices. Also this algorithm is parameter free, and we prove\nregret guarantees that scale with the amount by which the preference matrix\ndeviates from a biclustered structure. To our knowledge, these are the first\nresults on online collaborative filtering that hold at this level of generality\nand adaptivity under no-repetition constraints. Finally, we complement our\ntheoretical findings with simple experiments on real-world datasets aimed at\nboth validating the theory and empirically comparing to standard baselines.\nThis comparison shows the competitive advantage of our approach over these\nbaselines.\n","authors":["Stephen Pasteris","Fabio Vitale","Mark Herbster","Claudio Gentile","Andre' Panisson"],"pdf_url":"https://arxiv.org/pdf/2302.05765v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2402.17704v2","updated":"2024-10-22T13:19:36Z","published":"2024-02-27T17:30:33Z","title":"Transfer Learning Bayesian Optimization to Design Competitor DNA\n  Molecules for Use in Diagnostic Assays","summary":"  With the rise in engineered biomolecular devices, there is an increased need\nfor tailor-made biological sequences. Often, many similar biological sequences\nneed to be made for a specific application meaning numerous, sometimes\nprohibitively expensive, lab experiments are necessary for their optimization.\nThis paper presents a transfer learning design of experiments workflow to make\nthis development feasible. By combining a transfer learning surrogate model\nwith Bayesian optimization, we show how the total number of experiments can be\nreduced by sharing information between optimization tasks. We demonstrate the\nreduction in the number of experiments using data from the development of DNA\ncompetitors for use in an amplification-based diagnostic assay. We use\ncross-validation to compare the predictive accuracy of different transfer\nlearning models, and then compare the performance of the models for both single\nobjective and penalized optimization tasks.\n","authors":["Ruby Sedgwick","John P. Goertz","Molly M. Stevens","Ruth Misener","Mark van der Wilk"],"pdf_url":"https://arxiv.org/pdf/2402.17704v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.10851v2","updated":"2024-10-22T13:08:02Z","published":"2024-10-06T12:53:07Z","title":"LLM Gesticulator: Leveraging Large Language Models for Scalable and\n  Controllable Co-Speech Gesture Synthesis","summary":"  In this work, we present LLM Gesticulator, an LLM-based audio-driven\nco-speech gesture generation framework that synthesizes full-body animations\nthat are rhythmically aligned with the input audio while exhibiting natural\nmovements and editability. Compared to previous work, our model demonstrates\nsubstantial scalability. As the size of the backbone LLM model increases, our\nframework shows proportional improvements in evaluation metrics (a.k.a. scaling\nlaw). Our method also exhibits strong controllability where the content, style\nof the generated gestures can be controlled by text prompt. To the best of our\nknowledge, LLM gesticulator is the first work that use LLM on the co-speech\ngeneration task. Evaluation with existing objective metrics and user studies\nindicate that our framework outperforms prior works.\n","authors":["Haozhou Pang","Tianwei Ding","Lanshan He","Ming Tao","Lu Zhang","Qi Gan"],"pdf_url":"https://arxiv.org/pdf/2410.10851v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.16982v1","updated":"2024-10-22T13:02:12Z","published":"2024-10-22T13:02:12Z","title":"Sample-Efficient Geometry Reconstruction from Euclidean Distances using\n  Non-Convex Optimization","summary":"  The problem of finding suitable point embedding or geometric configurations\ngiven only Euclidean distance information of point pairs arises both as a core\ntask and as a sub-problem in a variety of machine learning applications. In\nthis paper, we aim to solve this problem given a minimal number of distance\nsamples. To this end, we leverage continuous and non-convex rank minimization\nformulations of the problem and establish a local convergence guarantee for a\nvariant of iteratively reweighted least squares (IRLS), which applies if a\nminimal random set of observed distances is provided. As a technical tool, we\nestablish a restricted isometry property (RIP) restricted to a tangent space of\nthe manifold of symmetric rank-$r$ matrices given random Euclidean distance\nmeasurements, which might be of independent interest for the analysis of other\nnon-convex approaches. Furthermore, we assess data efficiency, scalability and\ngeneralizability of different reconstruction algorithms through numerical\nexperiments with simulated data as well as real-world data, demonstrating the\nproposed algorithm's ability to identify the underlying geometry from fewer\ndistance samples compared to the state-of-the-art.\n","authors":["Ipsita Ghosh","Abiy Tasissa","Christian Kümmerle"],"pdf_url":"https://arxiv.org/pdf/2410.16982v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.16975v1","updated":"2024-10-22T12:55:02Z","published":"2024-10-22T12:55:02Z","title":"Publishing Neural Networks in Drug Discovery Might Compromise Training\n  Data Privacy","summary":"  This study investigates the risks of exposing confidential chemical\nstructures when machine learning models trained on these structures are made\npublicly available. We use membership inference attacks, a common method to\nassess privacy that is largely unexplored in the context of drug discovery, to\nexamine neural networks for molecular property prediction in a black-box\nsetting. Our results reveal significant privacy risks across all evaluated\ndatasets and neural network architectures. Combining multiple attacks increases\nthese risks. Molecules from minority classes, often the most valuable in drug\ndiscovery, are particularly vulnerable. We also found that representing\nmolecules as graphs and using message-passing neural networks may mitigate\nthese risks. We provide a framework to assess privacy risks of classification\nmodels and molecular representations. Our findings highlight the need for\ncareful consideration when sharing neural networks trained on proprietary\nchemical structures, informing organisations and researchers about the\ntrade-offs between data confidentiality and model openness.\n","authors":["Fabian P. Krüger","Johan Östman","Lewis Mervin","Igor V. Tetko","Ola Engkvist"],"pdf_url":"https://arxiv.org/pdf/2410.16975v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.16973v1","updated":"2024-10-22T12:51:51Z","published":"2024-10-22T12:51:51Z","title":"Learning Mathematical Rules with Large Language Models","summary":"  In this paper, we study the ability of large language models to learn\nspecific mathematical rules such as distributivity or simplifying equations. We\npresent an empirical analysis of their ability to generalize these rules, as\nwell as to reuse them in the context of word problems. For this purpose, we\nprovide a rigorous methodology to build synthetic data incorporating such\nrules, and perform fine-tuning of large language models on such data. Our\nexperiments show that our model can learn and generalize these rules to some\nextent, as well as suitably reuse them in the context of word problems.\n","authors":["Antoine Gorceix","Bastien Le Chenadec","Ahmad Rammal","Nelson Vadori","Manuela Veloso"],"pdf_url":"https://arxiv.org/pdf/2410.16973v1.pdf","comment":"4th MATH-AI Workshop at NeurIPS'24"},{"id":"http://arxiv.org/abs/2410.16972v1","updated":"2024-10-22T12:51:46Z","published":"2024-10-22T12:51:46Z","title":"Sample-efficient Bayesian Optimisation Using Known Invariances","summary":"  Bayesian optimisation (BO) is a powerful framework for global optimisation of\ncostly functions, using predictions from Gaussian process models (GPs). In this\nwork, we apply BO to functions that exhibit invariance to a known group of\ntransformations. We show that vanilla and constrained BO algorithms are\ninefficient when optimising such invariant objectives, and provide a method for\nincorporating group invariances into the kernel of the GP to produce\ninvariance-aware algorithms that achieve significant improvements in sample\nefficiency. We derive a bound on the maximum information gain of these\ninvariant kernels, and provide novel upper and lower bounds on the number of\nobservations required for invariance-aware BO algorithms to achieve\n$\\epsilon$-optimality. We demonstrate our method's improved performance on a\nrange of synthetic invariant and quasi-invariant functions. We also apply our\nmethod in the case where only some of the invariance is incorporated into the\nkernel, and find that these kernels achieve similar gains in sample efficiency\nat significantly reduced computational cost. Finally, we use invariant BO to\ndesign a current drive system for a nuclear fusion reactor, finding a\nhigh-performance solution where non-invariant methods failed.\n","authors":["Theodore Brown","Alexandru Cioba","Ilija Bogunovic"],"pdf_url":"https://arxiv.org/pdf/2410.16972v1.pdf","comment":"Accepted as a poster at NeurIPS 2024"},{"id":"http://arxiv.org/abs/2202.08967v2","updated":"2024-10-22T12:46:44Z","published":"2022-02-12T21:39:29Z","title":"Beyond Trading Data: The Hidden Influence of Public Awareness and\n  Interest on Cryptocurrency Volatility","summary":"  Since Bitcoin first appeared on the scene in 2009, cryptocurrencies have\nbecome a worldwide phenomenon as important decentralized financial assets.\nTheir decentralized nature, however, leads to notable volatility against\ntraditional fiat currencies, making the task of accurately forecasting the\ncrypto-fiat exchange rate complex. This study examines the various independent\nfactors that affect the volatility of the Bitcoin-Dollar exchange rate. To this\nend, we propose CoMForE, a multimodal AdaBoost-LSTM ensemble model, which not\nonly utilizes historical trading data but also incorporates public sentiments\nfrom related tweets, public interest demonstrated by search volumes, and\nblockchain hash-rate data. Our developed model goes a step further by\npredicting fluctuations in the overall cryptocurrency value distribution, thus\nincreasing its value for investment decision-making. We have subjected this\nmethod to extensive testing via comprehensive experiments, thereby validating\nthe importance of multimodal combination over exclusive reliance on trading\ndata. Further experiments show that our method significantly surpasses existing\nforecasting tools and methodologies, demonstrating a 19.29% improvement. This\nresult underscores the influence of external independent factors on\ncryptocurrency volatility.\n","authors":["Zeyd Boukhers","Azeddine Bouabdallah","Cong Yang","Jan Jürjens"],"pdf_url":"https://arxiv.org/pdf/2202.08967v2.pdf","comment":"Published at the 32nd ACM International Conference on Information and\n  Knowledge Management (CIKM 2023)"},{"id":"http://arxiv.org/abs/2402.02017v2","updated":"2024-10-22T12:46:09Z","published":"2024-02-03T04:17:09Z","title":"Adaptive $Q$-Aid for Conditional Supervised Learning in Offline\n  Reinforcement Learning","summary":"  Offline reinforcement learning (RL) has progressed with return-conditioned\nsupervised learning (RCSL), but its lack of stitching ability remains a\nlimitation. We introduce $Q$-Aided Conditional Supervised Learning (QCS), which\neffectively combines the stability of RCSL with the stitching capability of\n$Q$-functions. By analyzing $Q$-function over-generalization, which impairs\nstable stitching, QCS adaptively integrates $Q$-aid into RCSL's loss function\nbased on trajectory return. Empirical results show that QCS significantly\noutperforms RCSL and value-based methods, consistently achieving or exceeding\nthe maximum trajectory returns across diverse offline RL benchmarks.\n","authors":["Jeonghye Kim","Suyoung Lee","Woojun Kim","Youngchul Sung"],"pdf_url":"https://arxiv.org/pdf/2402.02017v2.pdf","comment":"Accepted to NeurIPS2024. The project page is available at\n  https://beanie00.com/publications/qcs"},{"id":"http://arxiv.org/abs/2209.12835v4","updated":"2024-10-22T12:38:35Z","published":"2022-09-26T16:41:16Z","title":"Targeted Separation and Convergence with Kernel Discrepancies","summary":"  Maximum mean discrepancies (MMDs) like the kernel Stein discrepancy (KSD)\nhave grown central to a wide range of applications, including hypothesis\ntesting, sampler selection, distribution approximation, and variational\ninference. In each setting, these kernel-based discrepancy measures are\nrequired to (i) separate a target P from other probability measures or even\n(ii) control weak convergence to P. In this article we derive new sufficient\nand necessary conditions to ensure (i) and (ii). For MMDs on separable metric\nspaces, we characterize those kernels that separate Bochner embeddable measures\nand introduce simple conditions for separating all measures with unbounded\nkernels and for controlling convergence with bounded kernels. We use these\nresults on $\\mathbb{R}^d$ to substantially broaden the known conditions for KSD\nseparation and convergence control and to develop the first KSDs known to\nexactly metrize weak convergence to P. Along the way, we highlight the\nimplications of our results for hypothesis testing, measuring and improving\nsample quality, and sampling with Stein variational gradient descent.\n","authors":["Alessandro Barp","Carl-Johann Simon-Gabriel","Mark Girolami","Lester Mackey"],"pdf_url":"https://arxiv.org/pdf/2209.12835v4.pdf","comment":null},{"id":"http://arxiv.org/abs/2304.07063v4","updated":"2024-10-22T12:28:13Z","published":"2023-04-14T11:35:35Z","title":"Rethinking Complex Queries on Knowledge Graphs with Neural Link\n  Predictors","summary":"  Reasoning on knowledge graphs is a challenging task because it utilizes\nobserved information to predict the missing one. Particularly, answering\ncomplex queries based on first-order logic is one of the crucial tasks to\nverify learning to reason abilities for generalization and composition.\nRecently, the prevailing method is query embedding which learns the embedding\nof a set of entities and treats logic operations as set operations and has\nshown great empirical success. Though there has been much research following\nthe same formulation, many of its claims lack a formal and systematic\ninspection. In this paper, we rethink this formulation and justify many of the\nprevious claims by characterizing the scope of queries investigated previously\nand precisely identifying the gap between its formulation and its goal, as well\nas providing complexity analysis for the currently investigated queries.\nMoreover, we develop a new dataset containing ten new types of queries with\nfeatures that have never been considered and therefore can provide a thorough\ninvestigation of complex queries. Finally, we propose a new neural-symbolic\nmethod, Fuzzy Inference with Truth value (FIT), where we equip the neural link\npredictors with fuzzy logic theory to support end-to-end learning using complex\nqueries with provable reasoning capability. Empirical results show that our\nmethod outperforms previous methods significantly in the new dataset and also\nsurpasses previous methods in the existing dataset at the same time.\n","authors":["Hang Yin","Zihao Wang","Yangqiu Song"],"pdf_url":"https://arxiv.org/pdf/2304.07063v4.pdf","comment":"Received in ICLR 2024"},{"id":"http://arxiv.org/abs/2410.16947v1","updated":"2024-10-22T12:21:39Z","published":"2024-10-22T12:21:39Z","title":"ISImed: A Framework for Self-Supervised Learning using Intrinsic Spatial\n  Information in Medical Images","summary":"  This paper demonstrates that spatial information can be used to learn\ninterpretable representations in medical images using Self-Supervised Learning\n(SSL). Our proposed method, ISImed, is based on the observation that medical\nimages exhibit a much lower variability among different images compared to\nclassic data vision benchmarks. By leveraging this resemblance of human body\nstructures across multiple images, we establish a self-supervised objective\nthat creates a latent representation capable of capturing its location in the\nphysical realm. More specifically, our method involves sampling image crops and\ncreating a distance matrix that compares the learned representation vectors of\nall possible combinations of these crops to the true distance between them. The\nintuition is, that the learned latent space is a positional encoding for a\ngiven image crop. We hypothesize, that by learning these positional encodings,\ncomprehensive image representations have to be generated. To test this\nhypothesis and evaluate our method, we compare our learned representation with\ntwo state-of-the-art SSL benchmarking methods on two publicly available medical\nimaging datasets. We show that our method can efficiently learn representations\nthat capture the underlying structure of the data and can be used to transfer\nto a downstream classification task.\n","authors":["Nabil Jabareen","Dongsheng Yuan","Sören Lukassen"],"pdf_url":"https://arxiv.org/pdf/2410.16947v1.pdf","comment":"11 pages, 4 figures"},{"id":"http://arxiv.org/abs/2410.16941v1","updated":"2024-10-22T12:16:11Z","published":"2024-10-22T12:16:11Z","title":"Business Process Simulation: Probabilistic Modeling of Intermittent\n  Resource Availability and Multitasking Behavior","summary":"  In business process simulation, resource availability is typically modeled by\nassigning a calendar to each resource, e.g., Monday-Friday, 9:00-18:00.\nResources are assumed to be always available during each time slot in their\navailability calendar. This assumption often becomes invalid due to\ninterruptions, breaks, or time-sharing across processes. In other words,\nexisting approaches fail to capture intermittent availability. Another\nlimitation of existing approaches is that they either do not consider\nmultitasking behavior, or if they do, they assume that resources always\nmultitask (up to a maximum capacity) whenever available. However, studies have\nshown that the multitasking patterns vary across days. This paper introduces a\nprobabilistic approach to model resource availability and multitasking behavior\nfor business process simulation. In this approach, each time slot in a resource\ncalendar has an associated availability probability and a multitasking\nprobability per multitasking level. For example, a resource may be available on\nFridays between 14:00-15:00 with 90\\% probability, and given that they are\nperforming one task during this slot, they may take on a second concurrent task\nwith 60\\% probability. We propose algorithms to discover probabilistic\ncalendars and probabilistic multitasking capacities from event logs. An\nevaluation shows that, with these enhancements, simulation models discovered\nfrom event logs better replicate the distribution of activities and cycle\ntimes, relative to approaches with crisp calendars and monotasking assumptions.\n","authors":["Orlenys López-Pintado","Marlon Dumas"],"pdf_url":"https://arxiv.org/pdf/2410.16941v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.16935v1","updated":"2024-10-22T12:12:43Z","published":"2024-10-22T12:12:43Z","title":"Graph Neural Networks for Edge Signals: Orientation Equivariance and\n  Invariance","summary":"  Many applications in traffic, civil engineering, or electrical engineering\nrevolve around edge-level signals. Such signals can be categorized as\ninherently directed, for example, the water flow in a pipe network, and\nundirected, like the diameter of a pipe. Topological methods model edge signals\nwith inherent direction by representing them relative to a so-called\norientation assigned to each edge. These approaches can neither model\nundirected edge signals nor distinguish if an edge itself is directed or\nundirected. We address these shortcomings by (i) revising the notion of\norientation equivariance to enable edge direction-aware topological models,\n(ii) proposing orientation invariance as an additional requirement to describe\nsignals without inherent direction, and (iii) developing EIGN, an architecture\ncomposed of novel direction-aware edge-level graph shift operators, that\nprovably fulfills the aforementioned desiderata. It is the first\ngeneral-purpose topological GNN for edge-level signals that can model directed\nand undirected signals while distinguishing between directed and undirected\nedges. A comprehensive evaluation shows that EIGN outperforms prior work in\nedge-level tasks, for example, improving in RMSE on flow simulation tasks by up\nto 43.5%.\n","authors":["Dominik Fuchsgruber","Tim Poštuvan","Stephan Günnemann","Simon Geisler"],"pdf_url":"https://arxiv.org/pdf/2410.16935v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2407.04157v2","updated":"2024-10-22T12:04:49Z","published":"2024-07-04T21:23:12Z","title":"Finite Operator Learning: Bridging Neural Operators and Numerical\n  Methods for Efficient Parametric Solution and Optimization of PDEs","summary":"  We introduce a method that combines neural operators, physics-informed\nmachine learning, and standard numerical methods for solving PDEs. The proposed\napproach extends each of the aforementioned methods and unifies them within a\nsingle framework. We can parametrically solve partial differential equations in\na data-free manner and provide accurate sensitivities, meaning the derivatives\nof the solution space with respect to the design space. These capabilities\nenable gradient-based optimization without the typical sensitivity analysis\ncosts, unlike adjoint methods that scale directly with the number of response\nfunctions. Our Finite Operator Learning (FOL) approach uses an uncomplicated\nfeed-forward neural network model to directly map the discrete design space\n(i.e. parametric input space) to the discrete solution space (i.e. finite\nnumber of sensor points in the arbitrary shape domain) ensuring compliance with\nphysical laws by designing them into loss functions. The discretized governing\nequations, as well as the design and solution spaces, can be derived from any\nwell-established numerical techniques. In this work, we employ the Finite\nElement Method (FEM) to approximate fields and their spatial derivatives.\nSubsequently, we conduct Sobolev training to minimize a multi-objective loss\nfunction, which includes the discretized weak form of the energy functional,\nboundary conditions violations, and the stationarity of the residuals with\nrespect to the design variables. Our study focuses on the steady-state heat\nequation within heterogeneous materials that exhibits significant phase\ncontrast and possibly temperature-dependent conductivity. The network's tangent\nmatrix is directly used for gradient-based optimization to improve the\nmicrostructure's heat transfer characteristics. ...\n","authors":["Shahed Rezaei","Reza Najian Asl","Kianoosh Taghikhani","Ahmad Moeineddin","Michael Kaliske","Markus Apel"],"pdf_url":"https://arxiv.org/pdf/2407.04157v2.pdf","comment":"arXiv admin note: text overlap with arXiv:2401.02363"},{"id":"http://arxiv.org/abs/2405.15330v2","updated":"2024-10-22T12:01:45Z","published":"2024-05-24T08:12:41Z","title":"Towards Understanding the Working Mechanism of Text-to-Image Diffusion\n  Model","summary":"  Recently, the strong latent Diffusion Probabilistic Model (DPM) has been\napplied to high-quality Text-to-Image (T2I) generation (e.g., Stable\nDiffusion), by injecting the encoded target text prompt into the gradually\ndenoised diffusion image generator. Despite the success of DPM in practice, the\nmechanism behind it remains to be explored. To fill this blank, we begin by\nexamining the intermediate statuses during the gradual denoising generation\nprocess in DPM. The empirical observations indicate, the shape of image is\nreconstructed after the first few denoising steps, and then the image is filled\nwith details (e.g., texture). The phenomenon is because the low-frequency\nsignal (shape relevant) of the noisy image is not corrupted until the final\nstage in the forward process (initial stage of generation) of adding noise in\nDPM. Inspired by the observations, we proceed to explore the influence of each\ntoken in the text prompt during the two stages. After a series of experiments\nof T2I generations conditioned on a set of text prompts. We conclude that in\nthe earlier generation stage, the image is mostly decided by the special token\n[\\texttt{EOS}] in the text prompt, and the information in the text prompt is\nalready conveyed in this stage. After that, the diffusion model completes the\ndetails of generated images by information from themselves. Finally, we propose\nto apply this observation to accelerate the process of T2I generation by\nproperly removing text guidance, which finally accelerates the sampling up to\n25\\%+.\n","authors":["Mingyang Yi","Aoxue Li","Yi Xin","Zhenguo Li"],"pdf_url":"https://arxiv.org/pdf/2405.15330v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.16928v1","updated":"2024-10-22T11:59:36Z","published":"2024-10-22T11:59:36Z","title":"xLSTM-Mixer: Multivariate Time Series Forecasting by Mixing via Scalar\n  Memories","summary":"  Time series data is prevalent across numerous fields, necessitating the\ndevelopment of robust and accurate forecasting models. Capturing patterns both\nwithin and between temporal and multivariate components is crucial for reliable\npredictions. We introduce xLSTM-Mixer, a model designed to effectively\nintegrate temporal sequences, joint time-variate information, and multiple\nperspectives for robust forecasting. Our approach begins with a linear forecast\nshared across variates, which is then refined by xLSTM blocks. These blocks\nserve as key elements for modeling the complex dynamics of challenging time\nseries data. xLSTM-Mixer ultimately reconciles two distinct views to produce\nthe final forecast. Our extensive evaluations demonstrate xLSTM-Mixer's\nsuperior long-term forecasting performance compared to recent state-of-the-art\nmethods. A thorough model analysis provides further insights into its key\ncomponents and confirms its robustness and effectiveness. This work contributes\nto the resurgence of recurrent models in time series forecasting.\n","authors":["Maurice Kraus","Felix Divo","Devendra Singh Dhami","Kristian Kersting"],"pdf_url":"https://arxiv.org/pdf/2410.16928v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.16926v1","updated":"2024-10-22T11:57:32Z","published":"2024-10-22T11:57:32Z","title":"Pyramid Vector Quantization for LLMs","summary":"  Recent works on compression of large language models (LLM) using quantization\nconsidered reparameterizing the architecture such that weights are distributed\non the sphere. This demonstratively improves the ability to quantize by\nincreasing the mathematical notion of coherence, resulting in fewer weight\noutliers without affecting the network output. In this work, we aim to further\nexploit this spherical geometry of the weights when performing quantization by\nconsidering Pyramid Vector Quantization (PVQ) for large language models.\nArranging points evenly on the sphere is notoriously difficult, especially in\nhigh dimensions, and in case approximate solutions exists, representing points\nexplicitly in a codebook is typically not feasible due to its additional memory\ncost. Instead, PVQ uses a fixed integer lattice on the sphere by projecting\npoints onto the 1-sphere, which allows for efficient encoding and decoding\nwithout requiring an explicit codebook in memory. To obtain a practical\nalgorithm, we propose to combine PVQ with scale quantization for which we\nderive theoretically optimal quantizations, under empirically verified\nassumptions. Further, we extend pyramid vector quantization to use Hessian\ninformation to minimize quantization error under expected feature activations,\ninstead of only relying on weight magnitudes. Experimentally, we achieves\nstate-of-the-art quantization performance with pareto-optimal trade-off between\nperformance and bits per weight and bits per activation, compared to compared\nmethods. On weight-only, we find that we can quantize a Llama-3 70B model to\n3.25 bits per weight and retain 98\\% accuracy on downstream tasks.\n","authors":["Tycho F. A. van der Ouderaa","Maximilian L. Croci","Agrin Hilmkil","James Hensman"],"pdf_url":"https://arxiv.org/pdf/2410.16926v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2405.16747v2","updated":"2024-10-22T11:53:58Z","published":"2024-05-27T01:31:40Z","title":"Understanding Linear Probing then Fine-tuning Language Models from NTK\n  Perspective","summary":"  The two-stage fine-tuning (FT) method, linear probing (LP) then fine-tuning\n(LP-FT), outperforms linear probing and FT alone. This holds true for both\nin-distribution (ID) and out-of-distribution (OOD) data. One key reason for its\nsuccess is the preservation of pre-trained features, achieved by obtaining a\nnear-optimal linear head during LP. However, despite the widespread use of\nlarge language models, there has been limited exploration of more complex\narchitectures such as Transformers. In this paper, we analyze the training\ndynamics of LP-FT for classification tasks on the basis of the neural tangent\nkernel (NTK) theory. Our analysis decomposes the NTK matrix into two\ncomponents. This decomposition highlights the importance of the linear head\nnorm alongside the prediction accuracy at the start of the FT stage. We also\nobserve a significant increase in the linear head norm during LP, which stems\nfrom training with the cross-entropy (CE) loss. This increase in the linear\nhead norm effectively reduces changes in learned features. Furthermore, we find\nthat this increased norm can adversely affect model calibration, which can be\ncorrected using temperature scaling. Additionally, we extend our analysis with\nthe NTK to the low-rank adaptation (LoRA) method and validate its\neffectiveness. Our experiments using a Transformer-based model on multiple\nnatural language processing datasets confirm our theoretical analysis. Our\nstudy demonstrates the effectiveness of LP-FT for fine-tuning language models.\nCode is available at https://github.com/tom4649/lp-ft_ntk.\n","authors":["Akiyoshi Tomihari","Issei Sato"],"pdf_url":"https://arxiv.org/pdf/2405.16747v2.pdf","comment":"Accepted at NeurIPS 2024"},{"id":"http://arxiv.org/abs/2410.16919v1","updated":"2024-10-22T11:52:22Z","published":"2024-10-22T11:52:22Z","title":"EnvBridge: Bridging Diverse Environments with Cross-Environment\n  Knowledge Transfer for Embodied AI","summary":"  In recent years, Large Language Models (LLMs) have demonstrated high\nreasoning capabilities, drawing attention for their applications as agents in\nvarious decision-making processes. One notably promising application of LLM\nagents is robotic manipulation. Recent research has shown that LLMs can\ngenerate text planning or control code for robots, providing substantial\nflexibility and interaction capabilities. However, these methods still face\nchallenges in terms of flexibility and applicability across different\nenvironments, limiting their ability to adapt autonomously. Current approaches\ntypically fall into two categories: those relying on environment-specific\npolicy training, which restricts their transferability, and those generating\ncode actions based on fixed prompts, which leads to diminished performance when\nconfronted with new environments. These limitations significantly constrain the\ngeneralizability of agents in robotic manipulation. To address these\nlimitations, we propose a novel method called EnvBridge. This approach involves\nthe retention and transfer of successful robot control codes from source\nenvironments to target environments. EnvBridge enhances the agent's\nadaptability and performance across diverse settings by leveraging insights\nfrom multiple environments. Notably, our approach alleviates environmental\nconstraints, offering a more flexible and generalizable solution for robotic\nmanipulation tasks. We validated the effectiveness of our method using robotic\nmanipulation benchmarks: RLBench, MetaWorld, and CALVIN. Our experiments\ndemonstrate that LLM agents can successfully leverage diverse knowledge sources\nto solve complex tasks. Consequently, our approach significantly enhances the\nadaptability and robustness of robotic manipulation agents in planning across\ndiverse environments.\n","authors":["Tomoyuki Kagaya","Yuxuan Lou","Thong Jing Yuan","Subramanian Lakshmi","Jayashree Karlekar","Sugiri Pranata","Natsuki Murakami","Akira Kinose","Koki Oguri","Felix Wick","Yang You"],"pdf_url":"https://arxiv.org/pdf/2410.16919v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.16917v1","updated":"2024-10-22T11:51:09Z","published":"2024-10-22T11:51:09Z","title":"DNAHLM -- DNA sequence and Human Language mixed large language Model","summary":"  There are already many DNA large language models, but most of them still\nfollow traditional uses, such as extracting sequence features for\nclassification tasks. More innovative applications of large language models,\nsuch as prompt engineering, RAG, and zero-shot or few-shot prediction, remain\nchallenging for DNA-based models. The key issue lies in the fact that DNA\nmodels and human natural language models are entirely separate; however,\ntechniques like prompt engineering require the use of natural language, thereby\nsignificantly limiting the application of DNA large language models. This paper\nintroduces a hybrid model trained on the GPT-2 network, combining DNA sequences\nand English text to explore the potential of using prompts and fine-tuning in\nDNA models. The model has demonstrated its effectiveness in DNA related\nzero-shot prediction and multitask application.\n","authors":["Wang Liang"],"pdf_url":"https://arxiv.org/pdf/2410.16917v1.pdf","comment":"10 pages, 7 figures"},{"id":"http://arxiv.org/abs/2306.09805v3","updated":"2024-10-22T11:33:36Z","published":"2023-06-16T12:43:47Z","title":"Mimicking Better by Matching the Approximate Action Distribution","summary":"  In this paper, we introduce MAAD, a novel, sample-efficient on-policy\nalgorithm for Imitation Learning from Observations. MAAD utilizes a surrogate\nreward signal, which can be derived from various sources such as adversarial\ngames, trajectory matching objectives, or optimal transport criteria. To\ncompensate for the non-availability of expert actions, we rely on an inverse\ndynamics model that infers plausible actions distribution given the expert's\nstate-state transitions; we regularize the imitator's policy by aligning it to\nthe inferred action distribution. MAAD leads to significantly improved sample\nefficiency and stability. We demonstrate its effectiveness in a number of\nMuJoCo environments, both int the OpenAI Gym and the DeepMind Control Suite. We\nshow that it requires considerable fewer interactions to achieve expert\nperformance, outperforming current state-of-the-art on-policy methods.\nRemarkably, MAAD often stands out as the sole method capable of attaining\nexpert performance levels, underscoring its simplicity and efficacy.\n","authors":["João A. Cândido Ramos","Lionel Blondé","Naoya Takeishi","Alexandros Kalousis"],"pdf_url":"https://arxiv.org/pdf/2306.09805v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2409.13467v2","updated":"2024-10-22T11:32:23Z","published":"2024-09-20T12:55:43Z","title":"Higher-Order Message Passing for Glycan Representation Learning","summary":"  Glycans are the most complex biological sequence, with monosaccharides\nforming extended, non-linear sequences. As post-translational modifications,\nthey modulate protein structure, function, and interactions. Due to their\ndiversity and complexity, predictive models of glycan properties and functions\nare still insufficient. Graph Neural Networks (GNNs) are deep learning models\ndesigned to process and analyze graph-structured data. These architectures\nleverage the connectivity and relational information in graphs to learn\neffective representations of nodes, edges, and entire graphs. Iteratively\naggregating information from neighboring nodes, GNNs capture complex patterns\nwithin graph data, making them particularly well-suited for tasks such as link\nprediction or graph classification across domains. This work presents a new\nmodel architecture based on combinatorial complexes and higher-order message\npassing to extract features from glycan structures into a latent space\nrepresentation. The architecture is evaluated on an improved GlycanML benchmark\nsuite, establishing a new state-of-the-art performance. We envision that these\nimprovements will spur further advances in computational glycosciences and\nreveal the roles of glycans in biology.\n","authors":["Roman Joeres","Daniel Bojar"],"pdf_url":"https://arxiv.org/pdf/2409.13467v2.pdf","comment":"Accepted to MLSB Workshop at NeurIPS 2024"},{"id":"http://arxiv.org/abs/2410.11488v2","updated":"2024-10-22T11:18:29Z","published":"2024-10-15T10:46:03Z","title":"Advancing Training Efficiency of Deep Spiking Neural Networks through\n  Rate-based Backpropagation","summary":"  Recent insights have revealed that rate-coding is a primary form of\ninformation representation captured by surrogate-gradient-based Backpropagation\nThrough Time (BPTT) in training deep Spiking Neural Networks (SNNs). Motivated\nby these findings, we propose rate-based backpropagation, a training strategy\nspecifically designed to exploit rate-based representations to reduce the\ncomplexity of BPTT. Our method minimizes reliance on detailed temporal\nderivatives by focusing on averaged dynamics, streamlining the computational\ngraph to reduce memory and computational demands of SNNs training. We\nsubstantiate the rationality of the gradient approximation between BPTT and the\nproposed method through both theoretical analysis and empirical observations.\nComprehensive experiments on CIFAR-10, CIFAR-100, ImageNet, and CIFAR10-DVS\nvalidate that our method achieves comparable performance to BPTT counterparts,\nand surpasses state-of-the-art efficient training techniques. By leveraging the\ninherent benefits of rate-coding, this work sets the stage for more scalable\nand efficient SNNs training within resource-constrained environments. Our code\nis available at https://github.com/Tab-ct/rate-based-backpropagation.\n","authors":["Chengting Yu","Lei Liu","Gaoang Wang","Erping Li","Aili Wang"],"pdf_url":"https://arxiv.org/pdf/2410.11488v2.pdf","comment":"Accepted by NeurIPS 2024"},{"id":"http://arxiv.org/abs/2410.16901v1","updated":"2024-10-22T11:15:07Z","published":"2024-10-22T11:15:07Z","title":"Bayes without Underfitting: Fully Correlated Deep Learning Posteriors\n  via Alternating Projections","summary":"  Bayesian deep learning all too often underfits so that the Bayesian\nprediction is less accurate than a simple point estimate. Uncertainty\nquantification then comes at the cost of accuracy. For linearized models, the\nnull space of the generalized Gauss-Newton matrix corresponds to parameters\nthat preserve the training predictions of the point estimate. We propose to\nbuild Bayesian approximations in this null space, thereby guaranteeing that the\nBayesian predictive does not underfit. We suggest a matrix-free algorithm for\nprojecting onto this null space, which scales linearly with the number of\nparameters and quadratically with the number of output dimensions. We further\npropose an approximation that only scales linearly with parameters to make the\nmethod applicable to generative models. An extensive empirical evaluation shows\nthat the approach scales to large models, including vision transformers with 28\nmillion parameters.\n","authors":["Marco Miani","Hrittik Roy","Søren Hauberg"],"pdf_url":"https://arxiv.org/pdf/2410.16901v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.16898v1","updated":"2024-10-22T11:03:06Z","published":"2024-10-22T11:03:06Z","title":"MBD: Multi b-value Denoising of Diffusion Magnetic Resonance Images","summary":"  We propose a novel approach to denoising diffusion magnetic resonance images\n(dMRI) using convolutional neural networks, that exploits the benefits of data\nacquired at multiple b-values to offset the need for many redundant\nobservations. Denoising is especially relevant in dMRI since noise can have a\ndeleterious impact on both quantification accuracy and image preprocessing. The\nmost successful methods proposed to date, like Marchenko-Pastur Principal\nComponent Analysis (MPPCA) denoising, are tailored to diffusion-weighting\nrepeated for many encoding directions. They exploit high redundancy of the\ndataset that oversamples the diffusion-encoding direction space, since many\ndirections have collinear components.\n  However, there are many dMRI techniques that do not entail a large number of\nencoding directions or repetitions, and are therefore less suited to this\napproach. For example, clinical dMRI exams may include as few as three encoding\ndirections, with low or negligible data redundancy across directions. Moreover,\npromising new dMRI approaches, like spherical b-tensor encoding (STE), benefit\nfrom high b-values while sensitizing the signal to diffusion along all\ndirections in just a single shot.\n  We introduce a convolutional neural network approach that we call\nmulti-b-value-based denoising (MBD). MBD exploits the similarity in\ndiffusion-weighted images (DWI) across different b-values but along the same\ndiffusion encoding direction. It allows denoising of diffusion images with high\nnoise variance while avoiding blurring, and using just a small number input\nimages.\n","authors":["Jakub Jurek","Andrzej Materka","Kamil Ludwisiak","Agata Majos","Filip Szczepankiewicz"],"pdf_url":"https://arxiv.org/pdf/2410.16898v1.pdf","comment":"this is a biomedical engineering work using machine learning to\n  enhance medical images"},{"id":"http://arxiv.org/abs/2410.16893v1","updated":"2024-10-22T10:56:52Z","published":"2024-10-22T10:56:52Z","title":"Global Optimization of Gaussian Process Acquisition Functions Using a\n  Piecewise-Linear Kernel Approximation","summary":"  Bayesian optimization relies on iteratively constructing and optimizing an\nacquisition function. The latter turns out to be a challenging, non-convex\noptimization problem itself. Despite the relative importance of this step, most\nalgorithms employ sampling- or gradient-based methods, which do not provably\nconverge to global optima. This work investigates mixed-integer programming\n(MIP) as a paradigm for \\textit{global} acquisition function optimization.\nSpecifically, our Piecewise-linear Kernel Mixed Integer Quadratic Programming\n(PK-MIQP) formulation introduces a piecewise-linear approximation for Gaussian\nprocess kernels and admits a corresponding MIQP representation for acquisition\nfunctions. We analyze the theoretical regret bounds of the proposed\napproximation, and empirically demonstrate the framework on synthetic\nfunctions, constrained benchmarks, and a hyperparameter tuning task.\n","authors":["Yilin Xie","Shiqiang Zhang","Joel Paulson","Calvin Tsay"],"pdf_url":"https://arxiv.org/pdf/2410.16893v1.pdf","comment":"16 pages, 3 figures, 2 tables"},{"id":"http://arxiv.org/abs/2407.07457v3","updated":"2024-10-22T10:54:15Z","published":"2024-07-10T08:20:47Z","title":"GLBench: A Comprehensive Benchmark for Graph with Large Language Models","summary":"  The emergence of large language models (LLMs) has revolutionized the way we\ninteract with graphs, leading to a new paradigm called GraphLLM. Despite the\nrapid development of GraphLLM methods in recent years, the progress and\nunderstanding of this field remain unclear due to the lack of a benchmark with\nconsistent experimental protocols. To bridge this gap, we introduce GLBench,\nthe first comprehensive benchmark for evaluating GraphLLM methods in both\nsupervised and zero-shot scenarios. GLBench provides a fair and thorough\nevaluation of different categories of GraphLLM methods, along with traditional\nbaselines such as graph neural networks. Through extensive experiments on a\ncollection of real-world datasets with consistent data processing and splitting\nstrategies, we have uncovered several key findings. Firstly, GraphLLM methods\noutperform traditional baselines in supervised settings, with LLM-as-enhancers\nshowing the most robust performance. However, using LLMs as predictors is less\neffective and often leads to uncontrollable output issues. We also notice that\nno clear scaling laws exist for current GraphLLM methods. In addition, both\nstructures and semantics are crucial for effective zero-shot transfer, and our\nproposed simple baseline can even outperform several models tailored for\nzero-shot scenarios. The data and code of the benchmark can be found at\nhttps://github.com/NineAbyss/GLBench.\n","authors":["Yuhan Li","Peisong Wang","Xiao Zhu","Aochuan Chen","Haiyun Jiang","Deng Cai","Victor Wai Kin Chan","Jia Li"],"pdf_url":"https://arxiv.org/pdf/2407.07457v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.16888v1","updated":"2024-10-22T10:46:36Z","published":"2024-10-22T10:46:36Z","title":"Unsupervised Time Series Anomaly Prediction with Importance-based\n  Generative Contrastive Learning","summary":"  Time series anomaly prediction plays an essential role in many real-world\nscenarios, such as environmental prevention and prompt maintenance of\ncyber-physical systems. However, existing time series anomaly prediction\nmethods mainly require supervised training with plenty of manually labeled\ndata, which are difficult to obtain in practice. Besides, unseen anomalies can\noccur during inference, which could differ from the labeled training data and\nmake these models fail to predict such new anomalies. In this paper, we study a\nnovel problem of unsupervised time series anomaly prediction. We provide a\ntheoretical analysis and propose Importance-based Generative Contrastive\nLearning (IGCL) to address the aforementioned problems. IGCL distinguishes\nbetween normal and anomaly precursors, which are generated by our anomaly\nprecursor pattern generation module. To address the efficiency issues caused by\nthe potential complex anomaly precursor combinations, we propose a memory bank\nwith importance-based scores to adaptively store representative anomaly\nprecursors and generate more complicated anomaly precursors. Extensive\nexperiments on seven benchmark datasets show our method outperforms\nstate-of-the-art baselines on unsupervised time series anomaly prediction\nproblems.\n","authors":["Kai Zhao","Zhihao Zhuang","Chenjuan Guo","Hao Miao","Yunyao Cheng","Bin Yang"],"pdf_url":"https://arxiv.org/pdf/2410.16888v1.pdf","comment":"16 pages"},{"id":"http://arxiv.org/abs/2409.15955v4","updated":"2024-10-22T10:41:58Z","published":"2024-09-24T10:36:40Z","title":"A Historical Trajectory Assisted Optimization Method for Zeroth-Order\n  Federated Learning","summary":"  Federated learning heavily relies on distributed gradient descent techniques.\nIn the situation where gradient information is not available, the gradients\nneed to be estimated from zeroth-order information, which typically involves\ncomputing finite-differences along isotropic random directions. This method\nsuffers from high estimation errors, as the geometric features of the objective\nlandscape may be overlooked during the isotropic sampling. In this work, we\npropose a non-isotropic sampling method to improve the gradient estimation\nprocedure. Gradients in our method are estimated in a subspace spanned by\nhistorical trajectories of solutions, aiming to encourage the exploration of\npromising regions and hence improve the convergence. The proposed method uses a\ncovariance matrix for sampling which is a convex combination of two parts. The\nfirst part is a thin projection matrix containing the basis of the subspace\nwhich is designed to improve the exploitation ability. The second part is the\nhistorical trajectories. We implement this method in zeroth-order federated\nsettings, and show that the convergence rate aligns with existing ones while\nintroducing no significant overheads in communication or local computation. The\neffectiveness of our proposal is verified on several numerical experiments in\ncomparison to several commonly-used zeroth-order federated optimization\nalgorithms.\n","authors":["Chenlin Wu","Xiaoyu He","Zike Li","Jing Gong","Zibin Zheng"],"pdf_url":"https://arxiv.org/pdf/2409.15955v4.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.16882v1","updated":"2024-10-22T10:36:15Z","published":"2024-10-22T10:36:15Z","title":"Large Language Model-based Augmentation for Imbalanced Node\n  Classification on Text-Attributed Graphs","summary":"  Node classification on graphs frequently encounters the challenge of class\nimbalance, leading to biased performance and posing significant risks in\nreal-world applications. Although several data-centric solutions have been\nproposed, none of them focus on Text-Attributed Graphs (TAGs), and therefore\noverlook the potential of leveraging the rich semantics encoded in textual\nfeatures for boosting the classification of minority nodes. Given this crucial\ngap, we investigate the possibility of augmenting graph data in the text space,\nleveraging the textual generation power of Large Language Models (LLMs) to\nhandle imbalanced node classification on TAGs. Specifically, we propose a novel\napproach called LA-TAG (LLM-based Augmentation on Text-Attributed Graphs),\nwhich prompts LLMs to generate synthetic texts based on existing node texts in\nthe graph. Furthermore, to integrate these synthetic text-attributed nodes into\nthe graph, we introduce a text-based link predictor to connect the synthesized\nnodes with the existing nodes. Our experiments across multiple datasets and\nevaluation metrics show that our framework significantly outperforms\ntraditional non-textual-based data augmentation strategies and specific node\nimbalance solutions. This highlights the promise of using LLMs to resolve\nimbalance issues on TAGs.\n","authors":["Leyao Wang","Yu Wang","Bo Ni","Yuying Zhao","Tyler Derr"],"pdf_url":"https://arxiv.org/pdf/2410.16882v1.pdf","comment":"11 pages, 4 figures"},{"id":"http://arxiv.org/abs/2410.16881v1","updated":"2024-10-22T10:33:00Z","published":"2024-10-22T10:33:00Z","title":"Just In Time Transformers","summary":"  Precise energy load forecasting in residential households is crucial for\nmitigating carbon emissions and enhancing energy efficiency; indeed, accurate\nforecasting enables utility companies and policymakers, who advocate\nsustainable energy practices, to optimize resource utilization. Moreover, smart\nmeters provide valuable information by allowing for granular insights into\nconsumption patterns. Building upon available smart meter data, our study aims\nto cluster consumers into distinct groups according to their energy usage\nbehaviours, effectively capturing a diverse spectrum of consumption patterns.\nNext, we design JITtrans (Just In Time transformer), a novel transformer deep\nlearning model that significantly improves energy consumption forecasting\naccuracy, with respect to traditional forecasting methods. Extensive\nexperimental results validate our claims using proprietary smart meter data.\nOur findings highlight the potential of advanced predictive technologies to\nrevolutionize energy management and advance sustainable power systems: the\ndevelopment of efficient and eco-friendly energy solutions critically depends\non such technologies.\n","authors":["Ahmed Ala Eddine Benali","Massimo Cafaro","Italo Epicoco","Marco Pulimeno","Enrico Junior Schioppa"],"pdf_url":"https://arxiv.org/pdf/2410.16881v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.16879v1","updated":"2024-10-22T10:31:23Z","published":"2024-10-22T10:31:23Z","title":"Contrasting Attitudes Towards Current and Future AI Applications for\n  Computerised Interpretation of ECG: A Clinical Stakeholder Interview Study","summary":"  Objectives: To investigate clinicians' attitudes towards current automated\ninterpretation of ECG and novel AI technologies and their perception of\ncomputer-assisted interpretation. Materials and Methods: We conducted a series\nof interviews with clinicians in the UK. Our study: (i) explores the potential\nfor AI, specifically future 'human-like' computing approaches, to facilitate\nECG interpretation and support clinical decision making, and (ii) elicits their\nopinions about the importance of explainability and trustworthiness of AI\nalgorithms. Results: We performed inductive thematic analysis on interview\ntranscriptions from 23 clinicians and identified the following themes: (i) a\nlack of trust in current systems, (ii) positive attitudes towards future AI\napplications and requirements for these, (iii) the relationship between the\naccuracy and explainability of algorithms, and (iv) opinions on education,\npossible deskilling, and the impact of AI on clinical competencies. Discussion:\nClinicians do not trust current computerised methods, but welcome future 'AI'\ntechnologies. Where clinicians trust future AI interpretation to be accurate,\nthey are less concerned that it is explainable. They also preferred ECG\ninterpretation that demonstrated the results of the algorithm visually. Whilst\nclinicians do not fear job losses, they are concerned about deskilling and the\nneed to educate the workforce to use AI responsibly. Conclusion: Clinicians are\npositive about the future application of AI in clinical decision-making.\nAccuracy is a key factor of uptake and visualisations are preferred over\ncurrent computerised methods. This is viewed as a potential means of training\nand upskilling, in contrast to the deskilling that automation might be\nperceived to bring.\n","authors":["Lukas Hughes-Noehrer","Leda Channer","Gabriel Strain","Gregory Yates","Richard Body","Caroline Jay"],"pdf_url":"https://arxiv.org/pdf/2410.16879v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.16872v1","updated":"2024-10-22T10:20:20Z","published":"2024-10-22T10:20:20Z","title":"CK4Gen: A Knowledge Distillation Framework for Generating High-Utility\n  Synthetic Survival Datasets in Healthcare","summary":"  Access to real clinical data is heavily restricted by privacy regulations,\nhindering both healthcare research and education. These constraints slow\nprogress in developing new treatments and data-driven healthcare solutions,\nwhile also limiting students' access to real-world datasets, leaving them\nwithout essential practical skills. High-utility synthetic datasets are\ntherefore critical for advancing research and providing meaningful training\nmaterial. However, current generative models -- such as Variational\nAutoencoders (VAEs) and Generative Adversarial Networks (GANs) -- produce\nsurface-level realism at the expense of healthcare utility, blending distinct\npatient profiles and producing synthetic data of limited practical relevance.\nTo overcome these limitations, we introduce CK4Gen (Cox Knowledge for\nGeneration), a novel framework that leverages knowledge distillation from Cox\nProportional Hazards (CoxPH) models to create synthetic survival datasets that\npreserve key clinical characteristics, including hazard ratios and survival\ncurves. CK4Gen avoids the interpolation issues seen in VAEs and GANs by\nmaintaining distinct patient risk profiles, ensuring realistic and reliable\noutputs for research and educational use. Validated across four benchmark\ndatasets -- GBSG2, ACTG320, WHAS500, and FLChain -- CK4Gen outperforms\ncompeting techniques by better aligning real and synthetic data, enhancing\nsurvival model performance in both discrimination and calibration via data\naugmentation. As CK4Gen is scalable across clinical conditions, and with code\nto be made publicly available, future researchers can apply it to their own\ndatasets to generate synthetic versions suitable for open sharing.\n","authors":["Nicholas I-Hsien Kuo","Blanca Gallego","Louisa Jorm"],"pdf_url":"https://arxiv.org/pdf/2410.16872v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.16871v1","updated":"2024-10-22T10:19:27Z","published":"2024-10-22T10:19:27Z","title":"Error Feedback under $(L_0,L_1)$-Smoothness: Normalization and Momentum","summary":"  We provide the first proof of convergence for normalized error feedback\nalgorithms across a wide range of machine learning problems. Despite their\npopularity and efficiency in training deep neural networks, traditional\nanalyses of error feedback algorithms rely on the smoothness assumption that\ndoes not capture the properties of objective functions in these problems.\nRather, these problems have recently been shown to satisfy generalized\nsmoothness assumptions, and the theoretical understanding of error feedback\nalgorithms under these assumptions remains largely unexplored. Moreover, to the\nbest of our knowledge, all existing analyses under generalized smoothness\neither i) focus on single-node settings or ii) make unrealistically strong\nassumptions for distributed settings, such as requiring data heterogeneity, and\nalmost surely bounded stochastic gradient noise variance. In this paper, we\npropose distributed error feedback algorithms that utilize normalization to\nachieve the $O(1/\\sqrt{K})$ convergence rate for nonconvex problems under\ngeneralized smoothness. Our analyses apply for distributed settings without\ndata heterogeneity conditions, and enable stepsize tuning that is independent\nof problem parameters. Additionally, we provide strong convergence guarantees\nof normalized error feedback algorithms for stochastic settings. Finally, we\nshow that due to their larger allowable stepsizes, our new normalized error\nfeedback algorithms outperform their non-normalized counterparts on various\ntasks, including the minimization of polynomial functions, logistic regression,\nand ResNet-20 training.\n","authors":["Sarit Khirirat","Abdurakhmon Sadiev","Artem Riabinin","Eduard Gorbunov","Peter Richtárik"],"pdf_url":"https://arxiv.org/pdf/2410.16871v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.16870v1","updated":"2024-10-22T10:19:17Z","published":"2024-10-22T10:19:17Z","title":"Federated Causal Inference: Multi-Centric ATE Estimation beyond\n  Meta-Analysis","summary":"  We study Federated Causal Inference, an approach to estimate treatment\neffects from decentralized data across centers. We compare three classes of\nAverage Treatment Effect (ATE) estimators derived from the Plug-in G-Formula,\nranging from simple meta-analysis to one-shot and multi-shot federated\nlearning, the latter leveraging the full data to learn the outcome model\n(albeit requiring more communication). Focusing on Randomized Controlled Trials\n(RCTs), we derive the asymptotic variance of these estimators for linear\nmodels. Our results provide practical guidance on selecting the appropriate\nestimator for various scenarios, including heterogeneity in sample sizes,\ncovariate distributions, treatment assignment schemes, and center effects. We\nvalidate these findings with a simulation study.\n","authors":["Rémi Khellaf","Aurélien Bellet","Julie Josse"],"pdf_url":"https://arxiv.org/pdf/2410.16870v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.16868v1","updated":"2024-10-22T10:12:57Z","published":"2024-10-22T10:12:57Z","title":"Rethinking generalization of classifiers in separable classes scenarios\n  and over-parameterized regimes","summary":"  We investigate the learning dynamics of classifiers in scenarios where\nclasses are separable or classifiers are over-parameterized. In both cases,\nEmpirical Risk Minimization (ERM) results in zero training error. However,\nthere are many global minima with a training error of zero, some of which\ngeneralize well and some of which do not. We show that in separable classes\nscenarios the proportion of \"bad\" global minima diminishes exponentially with\nthe number of training data n. Our analysis provides bounds and learning curves\ndependent solely on the density distribution of the true error for the given\nclassifier function set, irrespective of the set's size or complexity (e.g.,\nnumber of parameters). This observation may shed light on the unexpectedly good\ngeneralization of over-parameterized Neural Networks. For the\nover-parameterized scenario, we propose a model for the density distribution of\nthe true error, yielding learning curves that align with experiments on MNIST\nand CIFAR-10.\n","authors":["Julius Martinetz","Christoph Linse","Thomas Martinetz"],"pdf_url":"https://arxiv.org/pdf/2410.16868v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.16858v1","updated":"2024-10-22T09:52:15Z","published":"2024-10-22T09:52:15Z","title":"Dynamic graph neural networks for enhanced volatility prediction in\n  financial markets","summary":"  Volatility forecasting is essential for risk management and decision-making\nin financial markets. Traditional models like Generalized Autoregressive\nConditional Heteroskedasticity (GARCH) effectively capture volatility\nclustering but often fail to model complex, non-linear interdependencies\nbetween multiple indices. This paper proposes a novel approach using Graph\nNeural Networks (GNNs) to represent global financial markets as dynamic graphs.\nThe Temporal Graph Attention Network (Temporal GAT) combines Graph\nConvolutional Networks (GCNs) and Graph Attention Networks (GATs) to capture\nthe temporal and structural dynamics of volatility spillovers. By utilizing\ncorrelation-based and volatility spillover indices, the Temporal GAT constructs\ndirected graphs that enhance the accuracy of volatility predictions. Empirical\nresults from a 15-year study of eight major global indices show that the\nTemporal GAT outperforms traditional GARCH models and other machine learning\nmethods, particularly in short- to mid-term forecasts. The sensitivity and\nscenario-based analysis over a range of parameters and hyperparameters further\ndemonstrate the significance of the proposed technique. Hence, this work\nhighlights the potential of GNNs in modeling complex market behaviors,\nproviding valuable insights for financial analysts and investors.\n","authors":["Pulikandala Nithish Kumar","Nneka Umeorah","Alex Alochukwu"],"pdf_url":"https://arxiv.org/pdf/2410.16858v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2402.02500v3","updated":"2024-10-22T09:42:39Z","published":"2024-02-04T14:18:45Z","title":"Point Cloud Matters: Rethinking the Impact of Different Observation\n  Spaces on Robot Learning","summary":"  In robot learning, the observation space is crucial due to the distinct\ncharacteristics of different modalities, which can potentially become a\nbottleneck alongside policy design. In this study, we explore the influence of\nvarious observation spaces on robot learning, focusing on three predominant\nmodalities: RGB, RGB-D, and point cloud. We introduce OBSBench, a benchmark\ncomprising two simulators and 125 tasks, along with standardized pipelines for\nvarious encoders and policy baselines. Extensive experiments on diverse\ncontact-rich manipulation tasks reveal a notable trend: point cloud-based\nmethods, even those with the simplest designs, frequently outperform their RGB\nand RGB-D counterparts. This trend persists in both scenarios: training from\nscratch and utilizing pre-training. Furthermore, our findings demonstrate that\npoint cloud observations often yield better policy performance and\nsignificantly stronger generalization capabilities across various geometric and\nvisual conditions. These outcomes suggest that the 3D point cloud is a valuable\nobservation modality for intricate robotic tasks. We also suggest that\nincorporating both appearance and coordinate information can enhance the\nperformance of point cloud methods. We hope our work provides valuable insights\nand guidance for designing more generalizable and robust robotic models. Codes\nare available at https://github.com/HaoyiZhu/PointCloudMatters.\n","authors":["Haoyi Zhu","Yating Wang","Di Huang","Weicai Ye","Wanli Ouyang","Tong He"],"pdf_url":"https://arxiv.org/pdf/2402.02500v3.pdf","comment":"38th Conference on Neural Information Processing Systems (NeurIPS\n  2024) Track on Datasets and Benchmarks"},{"id":"http://arxiv.org/abs/2410.16849v1","updated":"2024-10-22T09:35:47Z","published":"2024-10-22T09:35:47Z","title":"Polyak's Heavy Ball Method Achieves Accelerated Local Rate of\n  Convergence under Polyak-Lojasiewicz Inequality","summary":"  In this work, we consider the convergence of Polyak's heavy ball method, both\nin continuous and discrete time, on a non-convex objective function. We recover\nthe convergence rates derived in [Polyak, U.S.S.R. Comput. Math. and Math.\nPhys., 1964] for strongly convex objective functions, assuming only validity of\nthe Polyak-Lojasiewicz inequality. In continuous time our result holds for all\ninitializations, whereas in the discrete time setting we conduct a local\nanalysis around the global minima. Our results demonstrate that the heavy ball\nmethod does, in fact, accelerate on the class of objective functions satisfying\nthe Polyak-Lojasiewicz inequality. This holds even in the discrete time\nsetting, provided the method reaches a neighborhood of the global minima.\nInstead of the usually employed Lyapunov-type arguments, our approach leverages\na new differential geometric perspective of the Polyak-Lojasiewicz inequality\nproposed in [Rebjock and Boumal, Math. Program., 2024].\n","authors":["Sebastian Kassing","Simon Weissmann"],"pdf_url":"https://arxiv.org/pdf/2410.16849v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.16846v1","updated":"2024-10-22T09:34:22Z","published":"2024-10-22T09:34:22Z","title":"Safe Load Balancing in Software-Defined-Networking","summary":"  High performance, reliability and safety are crucial properties of any\nSoftware-Defined-Networking (SDN) system. Although the use of Deep\nReinforcement Learning (DRL) algorithms has been widely studied to improve\nperformance, their practical applications are still limited as they fail to\nensure safe operations in exploration and decision-making. To fill this gap, we\nexplore the design of a Control Barrier Function (CBF) on top of Deep\nReinforcement Learning (DRL) algorithms for load-balancing. We show that our\nDRL-CBF approach is capable of meeting safety requirements during training and\ntesting while achieving near-optimal performance in testing. We provide results\nusing two simulators: a flow-based simulator, which is used for\nproof-of-concept and benchmarking, and a packet-based simulator that implements\nreal protocols and scheduling. Thanks to the flow-based simulator, we compared\nthe performance against the optimal policy, solving a Non Linear Programming\n(NLP) problem with the SCIP solver. Furthermore, we showed that pre-trained\nmodels in the flow-based simulator, which is faster, can be transferred to the\npacket simulator, which is slower but more accurate, with some fine-tuning.\nOverall, the results suggest that near-optimal Quality-of-Service (QoS)\nperformance in terms of end-to-end delay can be achieved while safety\nrequirements related to link capacity constraints are guaranteed. In the\npacket-based simulator, we also show that our DRL-CBF algorithms outperform\nnon-RL baseline algorithms. When the models are fine-tuned over a few episodes,\nwe achieved smoother QoS and safety in training, and similar performance in\ntesting compared to the case where models have been trained from scratch.\n","authors":["Lam Dinh","Pham Tran Anh Quang","Jérémie Leguay"],"pdf_url":"https://arxiv.org/pdf/2410.16846v1.pdf","comment":"Accepted to Computer Communications 2024. arXiv admin note: text\n  overlap with arXiv:2401.05525"},{"id":"http://arxiv.org/abs/2410.16845v1","updated":"2024-10-22T09:33:29Z","published":"2024-10-22T09:33:29Z","title":"Fast Graph Sharpness-Aware Minimization for Enhancing and Accelerating\n  Few-Shot Node Classification","summary":"  Graph Neural Networks (GNNs) have shown superior performance in node\nclassification. However, GNNs perform poorly in the Few-Shot Node\nClassification (FSNC) task that requires robust generalization to make accurate\npredictions for unseen classes with limited labels. To tackle the challenge, we\npropose the integration of Sharpness-Aware Minimization (SAM)--a technique\ndesigned to enhance model generalization by finding a flat minimum of the loss\nlandscape--into GNN training. The standard SAM approach, however, consists of\ntwo forward-backward steps in each training iteration, doubling the\ncomputational cost compared to the base optimizer (e.g., Adam). To mitigate\nthis drawback, we introduce a novel algorithm, Fast Graph Sharpness-Aware\nMinimization (FGSAM), that integrates the rapid training of Multi-Layer\nPerceptrons (MLPs) with the superior performance of GNNs. Specifically, we\nutilize GNNs for parameter perturbation while employing MLPs to minimize the\nperturbed loss so that we can find a flat minimum with good generalization more\nefficiently. Moreover, our method reutilizes the gradient from the perturbation\nphase to incorporate graph topology into the minimization process at almost\nzero additional cost. To further enhance training efficiency, we develop FGSAM+\nthat executes exact perturbations periodically. Extensive experiments\ndemonstrate that our proposed algorithm outperforms the standard SAM with lower\ncomputational costs in FSNC tasks. In particular, our FGSAM+ as a SAM variant\noffers a faster optimization than the base optimizer in most cases. In addition\nto FSNC, our proposed methods also demonstrate competitive performance in the\nstandard node classification task for heterophilic graphs, highlighting the\nbroad applicability. The code is available at\nhttps://github.com/draym28/FGSAM_NeurIPS24.\n","authors":["Yihong Luo","Yuhan Chen","Siya Qiu","Yiwei Wang","Chen Zhang","Yan Zhou","Xiaochun Cao","Jing Tang"],"pdf_url":"https://arxiv.org/pdf/2410.16845v1.pdf","comment":"NeurIPS24; The first two authors contributed equally to this work"},{"id":"http://arxiv.org/abs/2406.05335v2","updated":"2024-10-22T09:32:17Z","published":"2024-06-08T03:37:05Z","title":"Critical Phase Transition in Large Language Models","summary":"  Large Language Models (LLMs) have demonstrated impressive performance. To\nunderstand their behaviors, we need to consider the fact that LLMs sometimes\nshow qualitative changes. The natural world also presents such changes called\nphase transitions, which are defined by singular, divergent statistical\nquantities. Therefore, an intriguing question is whether qualitative changes in\nLLMs are phase transitions. In this work, we have conducted extensive analysis\non texts generated by LLMs and suggested that a phase transition occurs in LLMs\nwhen varying the temperature parameter. Specifically, statistical quantities\nhave divergent properties just at the point between the low-temperature regime,\nwhere LLMs generate sentences with clear repetitive structures, and the\nhigh-temperature regime, where generated sentences are often incomprehensible.\nIn addition, critical behaviors near the phase transition point, such as a\npower-law decay of correlation and slow convergence toward the stationary\nstate, are similar to those in natural languages. Our results suggest a\nmeaningful analogy between LLMs and natural phenomena.\n","authors":["Kai Nakaishi","Yoshihiko Nishikawa","Koji Hukushima"],"pdf_url":"https://arxiv.org/pdf/2406.05335v2.pdf","comment":"10 pages, 6 figures"},{"id":"http://arxiv.org/abs/2404.03348v2","updated":"2024-10-22T09:31:49Z","published":"2024-04-04T10:28:55Z","title":"Knowledge Distillation-Based Model Extraction Attack using GAN-based\n  Private Counterfactual Explanations","summary":"  In recent years, there has been a notable increase in the deployment of\nmachine learning (ML) models as services (MLaaS) across diverse production\nsoftware applications. In parallel, explainable AI (XAI) continues to evolve,\naddressing the necessity for transparency and trustworthiness in ML models. XAI\ntechniques aim to enhance the transparency of ML models by providing insights,\nin terms of model's explanations, into their decision-making process.\nSimultaneously, some MLaaS platforms now offer explanations alongside the ML\nprediction outputs. This setup has elevated concerns regarding vulnerabilities\nin MLaaS, particularly in relation to privacy leakage attacks such as model\nextraction attacks (MEA). This is due to the fact that explanations can unveil\ninsights about the inner workings of the model which could be exploited by\nmalicious users. In this work, we focus on investigating how model\nexplanations, particularly counterfactual explanations (CFs), can be exploited\nfor performing MEA within the MLaaS platform. We also delve into assessing the\neffectiveness of incorporating differential privacy (DP) as a mitigation\nstrategy. To this end, we first propose a novel approach for MEA based on\nKnowledge Distillation (KD) to enhance the efficiency of extracting a\nsubstitute model of a target model exploiting CFs, without any knowledge about\nthe training data distribution by the attacker. Then, we advise an approach for\ntraining CF generators incorporating DP to generate private CFs. We conduct\nthorough experimental evaluations on real-world datasets and demonstrate that\nour proposed KD-based MEA can yield a high-fidelity substitute model with a\nreduced number of queries with respect to baseline approaches. Furthermore, our\nfindings reveal that including a privacy layer can allow mitigating the MEA.\nHowever, on the account of the quality of CFs, impacts the performance of the\nexplanations.\n","authors":["Fatima Ezzeddine","Omran Ayoub","Silvia Giordano"],"pdf_url":"https://arxiv.org/pdf/2404.03348v2.pdf","comment":"19 pages"},{"id":"http://arxiv.org/abs/2404.16656v2","updated":"2024-10-22T09:30:36Z","published":"2024-04-25T14:48:29Z","title":"A Self-Organizing Clustering System for Unsupervised Distribution Shift\n  Detection","summary":"  Modeling non-stationary data is a challenging problem in the field of\ncontinual learning, and data distribution shifts may result in negative\nconsequences on the performance of a machine learning model. Classic learning\ntools are often vulnerable to perturbations of the input covariates, and are\nsensitive to outliers and noise, and some tools are based on rigid algebraic\nassumptions. Distribution shifts are frequently occurring due to changes in raw\nmaterials for production, seasonality, a different user base, or even\nadversarial attacks. Therefore, there is a need for more effective distribution\nshift detection techniques. In this work, we propose a continual learning\nframework for monitoring and detecting distribution changes. We explore the\nproblem in a latent space generated by a bio-inspired self-organizing\nclustering and statistical aspects of the latent space. In particular, we\ninvestigate the projections made by two topology-preserving maps: the\nSelf-Organizing Map and the Scale Invariant Map. Our method can be applied in\nboth a supervised and an unsupervised context. We construct the assessment of\nchanges in the data distribution as a comparison of Gaussian signals, making\nthe proposed method fast and robust. We compare it to other unsupervised\ntechniques, specifically Principal Component Analysis (PCA) and Kernel-PCA. Our\ncomparison involves conducting experiments using sequences of images (based on\nMNIST and injected shifts with adversarial samples), chemical sensor\nmeasurements, and the environmental variable related to ozone levels. The\nempirical study reveals the potential of the proposed approach.\n","authors":["Sebastián Basterrech","Line Clemmensen","Gerardo Rubino"],"pdf_url":"https://arxiv.org/pdf/2404.16656v2.pdf","comment":"Revised version of the accepted manuscript to IJCNN'2024. Main\n  corrections were in Section 2.2 and Section 3.3. In Section 2.2 was corrected\n  expression (3), and in Section 3.3 in the definition of the elements of the\n  matrix $D$ it was a typo where $\\phi(x)$ was written instead of $x$"},{"id":"http://arxiv.org/abs/2402.08180v3","updated":"2024-10-22T09:23:43Z","published":"2024-02-13T02:36:41Z","title":"Online Structured Prediction with Fenchel--Young Losses and Improved\n  Surrogate Regret for Online Multiclass Classification with Logistic Loss","summary":"  This paper studies online structured prediction with full-information\nfeedback. For online multiclass classification, Van der Hoeven (2020)\nestablished \\emph{finite} surrogate regret bounds, which are independent of the\ntime horizon, by introducing an elegant \\emph{exploit-the-surrogate-gap}\nframework. However, this framework has been limited to multiclass\nclassification primarily because it relies on a classification-specific\nprocedure for converting estimated scores to outputs. We extend the\nexploit-the-surrogate-gap framework to online structured prediction with\n\\emph{Fenchel--Young losses}, a large family of surrogate losses that includes\nthe logistic loss for multiclass classification as a special case, obtaining\nfinite surrogate regret bounds in various structured prediction problems. To\nthis end, we propose and analyze \\emph{randomized decoding}, which converts\nestimated scores to general structured outputs. Moreover, by applying our\ndecoding to online multiclass classification with the logistic loss, we obtain\na surrogate regret bound of $O(\\| \\mathbf{U} \\|_\\mathrm{F}^2)$, where\n$\\mathbf{U}$ is the best offline linear estimator and $\\| \\cdot \\|_\\mathrm{F}$\ndenotes the Frobenius norm. This bound is tight up to logarithmic factors and\nimproves the previous bound of $O(d\\| \\mathbf{U} \\|_\\mathrm{F}^2)$ due to Van\nder Hoeven (2020) by a factor of $d$, the number of classes.\n","authors":["Shinsaku Sakaue","Han Bao","Taira Tsuchiya","Taihei Oki"],"pdf_url":"https://arxiv.org/pdf/2402.08180v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2312.01344v2","updated":"2024-10-22T09:22:33Z","published":"2023-12-03T10:40:07Z","title":"Enhancing Algorithm Performance Understanding through tsMorph:\n  Generating Semi-Synthetic Time Series for Robust Forecasting Evaluation","summary":"  Time series forecasting is a subject of significant scientific and industrial\nimportance. Despite the widespread utilization of forecasting methods, there is\na dearth of research aimed at comprehending the conditions under which these\nmethods yield favorable or unfavorable performances. Empirical studies,\nalthough common, are challenged by the limited availability of time series\ndatasets, restricting the extraction of reliable insights. To address this\nlimitation, we present tsMorph, a tool for generating semi-synthetic time\nseries through dataset morphing. tsMorph works by creating a sequence of\ndatasets from two original datasets. The characteristics of the generated\ndatasets progressively depart from those of one of the datasets and converge\ntoward the attributes of the other dataset. This method provides a valuable\nalternative for obtaining substantial datasets. In this paper, we show the\nbenefits of tsMorph by assessing the predictive performance of the Long\nShort-Term Memory Network and DeepAR forecasting algorithms. The time series\nused for the experiments comes from the NN5 Competition. The experimental\nresults provide important insights. Notably, the performances of the two\nalgorithms improve proportionally with the frequency of the time series. These\nexperiments confirm that tsMorph can be an effective tool for better\nunderstanding the behavior of forecasting algorithms, delivering a pathway to\novercoming the limitations posed by empirical studies and enabling more\nextensive and reliable experiments.\n","authors":["Moisés Santos","André de Carvalho","Carlos Soares"],"pdf_url":"https://arxiv.org/pdf/2312.01344v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.07563v2","updated":"2024-10-22T09:06:38Z","published":"2024-10-10T02:59:36Z","title":"PLaMo-100B: A Ground-Up Language Model Designed for Japanese Proficiency","summary":"  We introduce PLaMo-100B, a large-scale language model designed for Japanese\nproficiency. The model was trained from scratch using 2 trillion tokens, with\narchitecture such as QK Normalization and Z-Loss to ensure training stability\nduring the training process. Post-training techniques, including Supervised\nFine-Tuning and Direct Preference Optimization, were applied to refine the\nmodel's performance. Benchmark evaluations suggest that PLaMo-100B performs\nwell, particularly in Japanese-specific tasks, achieving results that are\ncompetitive with frontier models like GPT-4. The base model is available at\nhttps://huggingface.co/pfnet/plamo-100b.\n","authors":["Preferred Elements"," :","Kenshin Abe","Kaizaburo Chubachi","Yasuhiro Fujita","Yuta Hirokawa","Kentaro Imajo","Toshiki Kataoka","Hiroyoshi Komatsu","Hiroaki Mikami","Tsuguo Mogami","Shogo Murai","Kosuke Nakago","Daisuke Nishino","Toru Ogawa","Daisuke Okanohara","Yoshihiko Ozaki","Shotaro Sano","Shuji Suzuki","Tianqi Xu","Toshihiko Yanase"],"pdf_url":"https://arxiv.org/pdf/2410.07563v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.16826v1","updated":"2024-10-22T08:58:44Z","published":"2024-10-22T08:58:44Z","title":"Guarantees of a Preconditioned Subgradient Algorithm for\n  Overparameterized Asymmetric Low-rank Matrix Recovery","summary":"  In this paper, we focus on a matrix factorization-based approach for robust\nlow-rank and asymmetric matrix recovery from corrupted measurements. We address\nthe challenging scenario where the rank of the sought matrix is unknown and\nemploy an overparameterized approach using the variational form of the nuclear\nnorm as a regularizer. We propose a subgradient algorithm that inherits the\nmerits of preconditioned algorithms, whose rate of convergence does not depend\non the condition number of the sought matrix, and addresses their current\nlimitation, i.e., the lack of convergence guarantees in the case of asymmetric\nmatrices with unknown rank. In this setting, we provide, for the first time in\nthe literature, linear convergence guarantees for the derived overparameterized\npreconditioned subgradient algorithm in the presence of gross corruptions.\nAdditionally, by applying our approach to matrix sensing, we highlight its\nmerits when the measurement operator satisfies the mixed-norm restricted\nisometry properties. Lastly, we present numerical experiments that validate our\ntheoretical results and demonstrate the effectiveness of our approach.\n","authors":["Paris Giampouras","HanQin Cai","Rene Vidal"],"pdf_url":"https://arxiv.org/pdf/2410.16826v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.16813v1","updated":"2024-10-22T08:40:05Z","published":"2024-10-22T08:40:05Z","title":"Klein Model for Hyperbolic Neural Networks","summary":"  Hyperbolic neural networks (HNNs) have been proved effective in modeling\ncomplex data structures. However, previous works mainly focused on the\nPoincar\\'e ball model and the hyperboloid model as coordinate representations\nof the hyperbolic space, often neglecting the Klein model. Despite this, the\nKlein model offers its distinct advantages thanks to its straight-line\ngeodesics, which facilitates the well-known Einstein midpoint construction,\npreviously leveraged to accompany HNNs in other models. In this work, we\nintroduce a framework for hyperbolic neural networks based on the Klein model.\nWe provide detailed formulation for representing useful operations using the\nKlein model. We further study the Klein linear layer and prove that the\n\"tangent space construction\" of the scalar multiplication and parallel\ntransport are exactly the Einstein scalar multiplication and the Einstein\naddition, analogous to the M\\\"obius operations used in the Poincar\\'e ball\nmodel. We show numerically that the Klein HNN performs on par with the\nPoincar\\'e ball model, providing a third option for HNN that works as a\nbuilding block for more complicated architectures.\n","authors":["Yidan Mao","Jing Gu","Marcus C. Werner","Dongmian Zou"],"pdf_url":"https://arxiv.org/pdf/2410.16813v1.pdf","comment":"Accepted to NeurIPS 2024 Symmetry and Geometry in Neural\n  Representations Workshop"},{"id":"http://arxiv.org/abs/2410.16811v1","updated":"2024-10-22T08:38:46Z","published":"2024-10-22T08:38:46Z","title":"Masked Clinical Modelling: A Framework for Synthetic and Augmented\n  Survival Data Generation","summary":"  Access to real clinical data is often restricted due to privacy obligations,\ncreating significant barriers for healthcare research. Synthetic datasets\nprovide a promising solution, enabling secure data sharing and model\ndevelopment. However, most existing approaches focus on data realism rather\nthan utility -- ensuring that models trained on synthetic data yield clinically\nmeaningful insights comparable to those trained on real data. In this paper, we\npresent Masked Clinical Modelling (MCM), a framework inspired by masked\nlanguage modelling, designed for both data synthesis and conditional data\naugmentation. We evaluate this prototype on the WHAS500 dataset using Cox\nProportional Hazards models, focusing on the preservation of hazard ratios as\nkey clinical metrics. Our results show that data generated using the MCM\nframework improves both discrimination and calibration in survival analysis,\noutperforming existing methods. MCM demonstrates strong potential to support\nsurvival data analysis and broader healthcare applications.\n","authors":["Nicholas I-Hsien Kuo","Blanca Gallego","Louisa Jorm"],"pdf_url":"https://arxiv.org/pdf/2410.16811v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.16805v1","updated":"2024-10-22T08:32:17Z","published":"2024-10-22T08:32:17Z","title":"Test-time Adversarial Defense with Opposite Adversarial Path and High\n  Attack Time Cost","summary":"  Deep learning models are known to be vulnerable to adversarial attacks by\ninjecting sophisticated designed perturbations to input data. Training-time\ndefenses still exhibit a significant performance gap between natural accuracy\nand robust accuracy. In this paper, we investigate a new test-time adversarial\ndefense method via diffusion-based recovery along opposite adversarial paths\n(OAPs). We present a purifier that can be plugged into a pre-trained model to\nresist adversarial attacks. Different from prior arts, the key idea is\nexcessive denoising or purification by integrating the opposite adversarial\ndirection with reverse diffusion to push the input image further toward the\nopposite adversarial direction. For the first time, we also exemplify the\npitfall of conducting AutoAttack (Rand) for diffusion-based defense methods.\nThrough the lens of time complexity, we examine the trade-off between the\neffectiveness of adaptive attack and its computation complexity against our\ndefense. Experimental evaluation along with time cost analysis verifies the\neffectiveness of the proposed method.\n","authors":["Cheng-Han Yeh","Kuanchun Yu","Chun-Shien Lu"],"pdf_url":"https://arxiv.org/pdf/2410.16805v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.16802v1","updated":"2024-10-22T08:27:43Z","published":"2024-10-22T08:27:43Z","title":"Evaluating the Effectiveness of Attack-Agnostic Features for Morphing\n  Attack Detection","summary":"  Morphing attacks have diversified significantly over the past years, with new\nmethods based on generative adversarial networks (GANs) and diffusion models\nposing substantial threats to face recognition systems. Recent research has\ndemonstrated the effectiveness of features extracted from large vision models\npretrained on bonafide data only (attack-agnostic features) for detecting deep\ngenerative images. Building on this, we investigate the potential of these\nimage representations for morphing attack detection (MAD). We develop\nsupervised detectors by training a simple binary linear SVM on the extracted\nfeatures and one-class detectors by modeling the distribution of bonafide\nfeatures with a Gaussian Mixture Model (GMM). Our method is evaluated across a\ncomprehensive set of attacks and various scenarios, including generalization to\nunseen attacks, different source datasets, and print-scan data. Our results\nindicate that attack-agnostic features can effectively detect morphing attacks,\noutperforming traditional supervised and one-class detectors from the\nliterature in most scenarios. Additionally, we provide insights into the\nstrengths and limitations of each considered representation and discuss\npotential future research directions to further enhance the robustness and\ngeneralizability of our approach.\n","authors":["Laurent Colbois","Sébastien Marcel"],"pdf_url":"https://arxiv.org/pdf/2410.16802v1.pdf","comment":"Published in the 2024 IEEE International Joint Conference on\n  Biometrics (IJCB)"},{"id":"http://arxiv.org/abs/2207.09185v3","updated":"2024-10-22T08:17:21Z","published":"2022-07-19T10:46:02Z","title":"Multimodal hierarchical Variational AutoEncoders with Factor Analysis\n  latent space","summary":"  Purpose: Handling heterogeneous and mixed data types has become increasingly\ncritical with the exponential growth in real-world databases. While deep\ngenerative models attempt to merge diverse data views into a common latent\nspace, they often sacrifice interpretability, flexibility, and modularity. This\nstudy proposes a novel method to address these limitations by combining\nVariational AutoEncoders (VAEs) with a Factor Analysis latent space (FA-VAE).\n  Methods: The proposed FA-VAE method employs multiple VAEs to learn a private\nrepresentation for each heterogeneous data view in a continuous latent space.\nInformation is shared between views using a low-dimensional latent space,\ngenerated via a linear projection matrix. This modular design creates a\nhierarchical dependency between private and shared latent spaces, allowing for\nthe flexible addition of new views and conditioning of pre-trained models.\n  Results: The FA-VAE approach facilitates cross-generation of data from\ndifferent domains and enables transfer learning between generative models. This\nallows for effective integration of information across diverse data views while\npreserving their distinct characteristics.\n  Conclusions: By overcoming the limitations of existing methods, the FA-VAE\nprovides a more interpretable, flexible, and modular solution for managing\nheterogeneous data types. It offers a pathway to more efficient and scalable\ndata-handling strategies, enhancing the potential for cross-domain data\nsynthesis and model transferability.\n","authors":["Alejandro Guerrero-López","Carlos Sevilla-Salcedo","Vanessa Gómez-Verdejo","Pablo M. Olmos"],"pdf_url":"https://arxiv.org/pdf/2207.09185v3.pdf","comment":"21 pages main work, 2 pages supplementary, 14 figures"},{"id":"http://arxiv.org/abs/2410.16794v1","updated":"2024-10-22T08:17:20Z","published":"2024-10-22T08:17:20Z","title":"One-Step Diffusion Distillation through Score Implicit Matching","summary":"  Despite their strong performances on many generative tasks, diffusion models\nrequire a large number of sampling steps in order to generate realistic\nsamples. This has motivated the community to develop effective methods to\ndistill pre-trained diffusion models into more efficient models, but these\nmethods still typically require few-step inference or perform substantially\nworse than the underlying model. In this paper, we present Score Implicit\nMatching (SIM) a new approach to distilling pre-trained diffusion models into\nsingle-step generator models, while maintaining almost the same sample\ngeneration ability as the original model as well as being data-free with no\nneed of training samples for distillation. The method rests upon the fact that,\nalthough the traditional score-based loss is intractable to minimize for\ngenerator models, under certain conditions we can efficiently compute the\ngradients for a wide class of score-based divergences between a diffusion model\nand a generator. SIM shows strong empirical performances for one-step\ngenerators: on the CIFAR10 dataset, it achieves an FID of 2.06 for\nunconditional generation and 1.96 for class-conditional generation. Moreover,\nby applying SIM to a leading transformer-based diffusion model, we distill a\nsingle-step generator for text-to-image (T2I) generation that attains an\naesthetic score of 6.42 with no performance decline over the original\nmulti-step counterpart, clearly outperforming the other one-step generators\nincluding SDXL-TURBO of 5.33, SDXL-LIGHTNING of 5.34 and HYPER-SDXL of 5.85. We\nwill release this industry-ready one-step transformer-based T2I generator along\nwith this paper.\n","authors":["Weijian Luo","Zemin Huang","Zhengyang Geng","J. Zico Kolter","Guo-jun Qi"],"pdf_url":"https://arxiv.org/pdf/2410.16794v1.pdf","comment":"Accepted by NeurIPS 2024"},{"id":"http://arxiv.org/abs/2410.16790v1","updated":"2024-10-22T08:07:44Z","published":"2024-10-22T08:07:44Z","title":"Sample-Efficient Curriculum Reinforcement Learning for Complex Reward\n  Functions","summary":"  Reinforcement learning (RL) shows promise in control problems, but its\npractical application is often hindered by the complexity arising from\nintricate reward functions with constraints. While the reward hypothesis\nsuggests these competing demands can be encapsulated in a single scalar reward\nfunction, designing such functions remains challenging. Building on existing\nwork, we start by formulating preferences over trajectories to derive a\nrealistic reward function that balances goal achievement with constraint\nsatisfaction in the application of mobile robotics with dynamic obstacles. To\nmitigate reward exploitation in such complex settings, we propose a novel\ntwo-stage reward curriculum combined with a flexible replay buffer that\nadaptively samples experiences. Our approach first learns on a subset of\nrewards before transitioning to the full reward, allowing the agent to learn\ntrade-offs between objectives and constraints. After transitioning to a new\nstage, our method continues to make use of past experiences by updating their\nrewards for sample-efficient learning. We investigate the efficacy of our\napproach in robot navigation tasks and demonstrate superior performance\ncompared to baselines in terms of true reward achievement and task completion,\nunderlining its effectiveness.\n","authors":["Kilian Freitag","Kristian Ceder","Rita Laezza","Knut Åkesson","Morteza Haghir Chehreghani"],"pdf_url":"https://arxiv.org/pdf/2410.16790v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.16780v1","updated":"2024-10-22T07:53:41Z","published":"2024-10-22T07:53:41Z","title":"Beyond Retrieval: Generating Narratives in Conversational Recommender\n  Systems","summary":"  The recent advances in Large Language Model's generation and reasoning\ncapabilities present an opportunity to develop truly conversational\nrecommendation systems. However, effectively integrating recommender system\nknowledge into LLMs for natural language generation which is tailored towards\nrecommendation tasks remains a challenge. This paper addresses this challenge\nby making two key contributions.\n  First, we introduce a new dataset (REGEN) for natural language generation\ntasks in conversational recommendations. REGEN (Reviews Enhanced with\nGEnerative Narratives) extends the Amazon Product Reviews dataset with rich\nuser narratives, including personalized explanations of product preferences,\nproduct endorsements for recommended items, and summaries of user purchase\nhistory. REGEN is made publicly available to facilitate further research.\nFurthermore, we establish benchmarks using well-known generative metrics, and\nperform an automated evaluation of the new dataset using a rater LLM. Second,\nthe paper introduces a fusion architecture (CF model with an LLM) which serves\nas a baseline for REGEN. And to the best of our knowledge, represents the first\nattempt to analyze the capabilities of LLMs in understanding recommender\nsignals and generating rich narratives. We demonstrate that LLMs can\neffectively learn from simple fusion architectures utilizing interaction-based\nCF embeddings, and this can be further enhanced using the metadata and\npersonalization data associated with items. Our experiments show that combining\nCF and content embeddings leads to improvements of 4-12% in key language\nmetrics compared to using either type of embedding individually. We also\nprovide an analysis to interpret how CF and content embeddings contribute to\nthis new generative task.\n","authors":["Krishna Sayana","Raghavendra Vasudeva","Yuri Vasilevski","Kun Su","Liam Hebert","Hubert Pham","Ambarish Jash","Sukhdeep Sodhi"],"pdf_url":"https://arxiv.org/pdf/2410.16780v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.10787v3","updated":"2024-10-22T07:51:43Z","published":"2024-08-20T12:27:53Z","title":"A Lightweight Modular Framework for Low-Cost Open-Vocabulary Object\n  Detection Training","summary":"  Object detection is a fundamental challenge in computer vision, centered on\nrecognizing objects within images, with diverse applications in areas like\nimage analysis, robotics, and autonomous vehicles. Although existing methods\nhave achieved great success, they are often constrained by a fixed vocabulary\nof objects. To overcome this limitation, approaches like MDETR have redefined\nobject detection by incorporating region-level vision-language pre-training,\nenabling open-vocabulary object detectors. However, these methods are\ncomputationally heavy due to the simultaneous training of large models for both\nvision and language representations. To address this, we introduce a\nlightweight framework that significantly reduces the number of parameters while\npreserving, or even improving, performance. Our solution is applied to MDETR,\nresulting in the development of Lightweight MDETR (LightMDETR), an optimized\nversion of MDETR designed to enhance computational efficiency without\nsacrificing accuracy. The core of our approach involves freezing the MDETR\nbackbone and training only the Universal Projection module (UP), which bridges\nvision and language representations. A learnable modality token parameter\nallows the UP to seamlessly switch between modalities. Evaluations on tasks\nlike phrase grounding, referring expression comprehension, and segmentation\nshow that LightMDETR not only reduces computational costs but also outperforms\nseveral state-of-the-art methods in terms of accuracy.\n","authors":["Bilal Faye","Binta Sow","Hanane Azzag","Mustapha Lebbah"],"pdf_url":"https://arxiv.org/pdf/2408.10787v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2004.04454v2","updated":"2024-10-22T07:40:17Z","published":"2020-04-09T09:52:49Z","title":"TensorProjection Layer: A Tensor-Based Dimension Reduction Method in\n  Deep Neural Networks","summary":"  In this paper, we propose a dimension reduction method specifically designed\nfor tensor-structured feature data in deep neural networks. The method is\nimplemented as a hidden layer, called the TensorProjection layer, which\ntransforms input tensors into output tensors with reduced dimensions through\nmode-wise projections. The projection directions are treated as model\nparameters of the layer and are optimized during model training. Our method can\nserve as an alternative to pooling layers for summarizing image data, or to\nconvolutional layers as a technique for reducing the number of channels. We\nconduct experiments on tasks such as medical image classification and\nsegmentation, integrating the TensorProjection layer into commonly used\nbaseline architectures to evaluate its effectiveness. Numerical experiments\nindicate that the proposed method can outperform traditional downsampling\nmethods, such as pooling layers, in our tasks, suggesting it as a promising\nalternative for feature summarization.\n","authors":["Toshinari Morimoto","Su-Yun Huang"],"pdf_url":"https://arxiv.org/pdf/2004.04454v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.16765v1","updated":"2024-10-22T07:33:34Z","published":"2024-10-22T07:33:34Z","title":"Survival Models: Proper Scoring Rule and Stochastic Optimization with\n  Competing Risks","summary":"  When dealing with right-censored data, where some outcomes are missing due to\na limited observation period, survival analysis -- known as time-to-event\nanalysis -- focuses on predicting the time until an event of interest occurs.\nMultiple classes of outcomes lead to a classification variant: predicting the\nmost likely event, a less explored area known as competing risks. Classic\ncompeting risks models couple architecture and loss, limiting scalability.To\naddress these issues, we design a strictly proper censoring-adjusted separable\nscoring rule, allowing optimization on a subset of the data as each observation\nis evaluated independently. The loss estimates outcome probabilities and\nenables stochastic optimization for competing risks, which we use for efficient\ngradient boosting trees. SurvivalBoost not only outperforms 12 state-of-the-art\nmodels across several metrics on 4 real-life datasets, both in competing risks\nand survival settings, but also provides great calibration, the ability to\npredict across any time horizon, and computation times faster than existing\nmethods.\n","authors":["Julie Alberge","Vincent Maladière","Olivier Grisel","Judith Abécassis","Gaël Varoquaux"],"pdf_url":"https://arxiv.org/pdf/2410.16765v1.pdf","comment":"arXiv admin note: substantial text overlap with arXiv:2406.14085"},{"id":"http://arxiv.org/abs/2410.16760v1","updated":"2024-10-22T07:27:20Z","published":"2024-10-22T07:27:20Z","title":"Efficient Frequency Selective Surface Analysis via End-to-End\n  Model-Based Learning","summary":"  This paper introduces an innovative end-to-end model-based deep learning\napproach for efficient electromagnetic analysis of high-dimensional frequency\nselective surfaces (FSS). Unlike traditional data-driven methods that require\nlarge datasets, this approach combines physical insights from equivalent\ncircuit models with deep learning techniques to significantly reduce model\ncomplexity and enhance prediction accuracy. Compared to previously introduced\nmodel-based learning approaches, the proposed method is trained end-to-end from\nthe physical structure of the FSS (geometric parameters) to its electromagnetic\nresponse (S-parameters). Additionally, an improvement in phase prediction\naccuracy through a modified loss function is presented. Comparisons with direct\nmodels, including deep neural networks (DNN) and radial basis function networks\n(RBFN), demonstrate the superiority of the model-based approach in terms of\ncomputational efficiency, model size, and generalization capability.\n","authors":["Cheima Hammami","Lucas Polo-López","Luc Le Magoarou"],"pdf_url":"https://arxiv.org/pdf/2410.16760v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.04183v2","updated":"2024-10-22T07:24:05Z","published":"2024-10-05T14:57:52Z","title":"Unsupervised Assessment of Landscape Shifts Based on Persistent Entropy\n  and Topological Preservation","summary":"  In Continual Learning (CL) contexts, concept drift typically refers to the\nanalysis of changes in data distribution. A drift in the input data can have\nnegative consequences on a learning predictor and the system's stability. The\nmajority of concept drift methods emphasize the analysis of statistical changes\nin non-stationary data over time. In this context, we consider another\nperspective, where the concept drift also integrates substantial changes in the\ntopological characteristics of the data stream. In this article, we introduce a\nnovel framework for monitoring changes in multi-dimensional data streams. We\nexplore variations in the topological structures of the data, presenting\nanother angle on the standard concept drift. Our developed approach is based on\npersistent entropy and topology-preserving projections in a continual learning\nscenario. The framework operates in both unsupervised and supervised\nenvironments. To show the utility of the proposed framework, we analyze the\nmodel across three scenarios using data streams generated with MNIST samples.\nThe obtained results reveal the potential of applying topological data analysis\nfor shift detection and encourage further research in this area.\n","authors":["Sebastian Basterrech"],"pdf_url":"https://arxiv.org/pdf/2410.04183v2.pdf","comment":"KDD'2024. Workshop on Drift Detection and Landscape Shifts"},{"id":"http://arxiv.org/abs/2410.16750v1","updated":"2024-10-22T07:12:38Z","published":"2024-10-22T07:12:38Z","title":"Theoretical Convergence Guarantees for Variational Autoencoders","summary":"  Variational Autoencoders (VAE) are popular generative models used to sample\nfrom complex data distributions. Despite their empirical success in various\nmachine learning tasks, significant gaps remain in understanding their\ntheoretical properties, particularly regarding convergence guarantees. This\npaper aims to bridge that gap by providing non-asymptotic convergence\nguarantees for VAE trained using both Stochastic Gradient Descent and Adam\nalgorithms.We derive a convergence rate of $\\mathcal{O}(\\log n / \\sqrt{n})$,\nwhere $n$ is the number of iterations of the optimization algorithm, with\nexplicit dependencies on the batch size, the number of variational samples, and\nother key hyperparameters. Our theoretical analysis applies to both Linear VAE\nand Deep Gaussian VAE, as well as several VAE variants, including $\\beta$-VAE\nand IWAE. Additionally, we empirically illustrate the impact of hyperparameters\non convergence, offering new insights into the theoretical understanding of VAE\ntraining.\n","authors":["Sobihan Surendran","Antoine Godichon-Baggioni","Sylvain Le Corff"],"pdf_url":"https://arxiv.org/pdf/2410.16750v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2405.16726v2","updated":"2024-10-22T07:05:57Z","published":"2024-05-26T23:48:30Z","title":"Exploring Edge Probability Graph Models Beyond Edge Independency:\n  Concepts, Analyses, and Algorithms","summary":"  Desirable random graph models (RGMs) should (i) generate realistic structures\nsuch as high clustering (i.e., high subgraph densities), (ii) generate variable\n(i.e., not overly similar) graphs, and (iii) remain tractable to compute and\ncontrol graph statistics. A common class of RGMs (e.g., Erd\\H{o}s-R'{e}nyi and\nstochastic Kronecker) outputs edge probabilities, and we need to realize (i.e.,\nsample from) the edge probabilities to generate graphs. Typically, each edge's\nexistence is assumed to be determined independently for simplicity and\ntractability. However, with edge independency, RGMs theoretically cannot\nproduce high subgraph densities and high output variability simultaneously. In\nthis work, we explore realization beyond edge independence that can produce\nmore realistic structures while maintaining high traceability and variability.\nTheoretically, we propose an edge-dependent realization framework called\nbinding that provably preserves output variability, and derive closed-form\ntractability results on subgraph (e.g., triangle) densities in generated\ngraphs. Practically, we propose algorithms for graph generation with binding\nand parameter fitting of binding. Our empirical results demonstrate that\nbinding exhibits high tractability and generates realistic graphs with high\nclustering, significantly improving upon existing RGMs assuming edge\nindependency.\n","authors":["Fanchen Bu","Ruochen Yang","Paul Bogdan","Kijung Shin"],"pdf_url":"https://arxiv.org/pdf/2405.16726v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.16739v1","updated":"2024-10-22T06:46:28Z","published":"2024-10-22T06:46:28Z","title":"Corrected Soft Actor Critic for Continuous Control","summary":"  The Soft Actor-Critic (SAC) algorithm is known for its stability and high\nsample efficiency in deep reinforcement learning. However, the tanh\ntransformation applied to sampled actions in SAC distorts the action\ndistribution, hindering the selection of the most probable actions. This paper\npresents a novel action sampling method that directly identifies and selects\nthe most probable actions within the transformed distribution, thereby\naddressing this issue. Extensive experiments on standard continuous control\nbenchmarks demonstrate that the proposed method significantly enhances SAC's\nperformance, resulting in faster convergence and higher cumulative rewards\ncompared to the original algorithm.\n","authors":["Yanjun Chen","Xinming Zhang","Xianghui Wang","Zhiqiang Xu","Xiaoyu Shen","Wei Zhang"],"pdf_url":"https://arxiv.org/pdf/2410.16739v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.16738v1","updated":"2024-10-22T06:46:09Z","published":"2024-10-22T06:46:09Z","title":"LLM-Assisted Red Teaming of Diffusion Models through \"Failures Are\n  Fated, But Can Be Faded\"","summary":"  In large deep neural networks that seem to perform surprisingly well on many\ntasks, we also observe a few failures related to accuracy, social biases, and\nalignment with human values, among others. Therefore, before deploying these\nmodels, it is crucial to characterize this failure landscape for engineers to\ndebug or audit models. Nevertheless, it is infeasible to exhaustively test for\nall possible combinations of factors that could lead to a model's failure. In\nthis paper, we improve the \"Failures are fated, but can be faded\" framework\n(arXiv:2406.07145)--a post-hoc method to explore and construct the failure\nlandscape in pre-trained generative models--with a variety of deep\nreinforcement learning algorithms, screening tests, and LLM-based rewards and\nstate generation. With the aid of limited human feedback, we then demonstrate\nhow to restructure the failure landscape to be more desirable by moving away\nfrom the discovered failure modes. We empirically demonstrate the effectiveness\nof the proposed method on diffusion models. We also highlight the strengths and\nweaknesses of each algorithm in identifying failure modes.\n","authors":["Som Sagar","Aditya Taparia","Ransalu Senanayake"],"pdf_url":"https://arxiv.org/pdf/2410.16738v1.pdf","comment":"13 pages, 11 figures. arXiv admin note: substantial text overlap with\n  arXiv:2406.07145"},{"id":"http://arxiv.org/abs/2410.16737v1","updated":"2024-10-22T06:46:05Z","published":"2024-10-22T06:46:05Z","title":"Interactive Residual Domain Adaptation Networks for Partial Transfer\n  Industrial Fault Diagnosis","summary":"  The partial domain adaptation (PDA) challenge is a prevalent issue in\nindustrial fault diagnosis. Current PDA approaches primarily rely on\nadversarial learning for domain adaptation and use reweighting strategies to\nexclude source samples deemed outliers. However, the transferability of\nfeatures diminishes from general feature extraction layers to higher\ntask-specific layers in adversarial learning-based adaptation modules, leading\nto significant negative transfer in PDA settings. We term this issue the\nadaptation-discrimination paradox (ADP). Furthermore, reweighting strategies\noften suffer from unreliable pseudo-labels, compromising their effectiveness.\nDrawing inspiration from traditional classification settings where such partial\nchallenge is not a concern, we propose a novel PDA framework called Interactive\nResidual Domain Adaptation Networks (IRDAN), which introduces domain-wise\nmodels for each domain to provide a new perspective for the PDA challenge. Each\ndomain-wise model is equipped with a residual domain adaptation (RDA) block to\nmitigate the ADP problem. Additionally, we introduce a confident information\nflow via an interactive learning strategy, training the modules of IRDAN\nsequentially to avoid cross-interference. We also establish a reliable stopping\ncriterion for selecting the best-performing model, ensuring practical usability\nin real-world applications. Experiments have demonstrated the superior\nperformance of the proposed IRDAN.\n","authors":["Gecheng Chen","Chengwen Luo","Jianqiang Li","Xinkai Chen"],"pdf_url":"https://arxiv.org/pdf/2410.16737v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2312.03876v2","updated":"2024-10-22T06:36:46Z","published":"2023-12-06T19:46:06Z","title":"Scaling transformer neural networks for skillful and reliable\n  medium-range weather forecasting","summary":"  Weather forecasting is a fundamental problem for anticipating and mitigating\nthe impacts of climate change. Recently, data-driven approaches for weather\nforecasting based on deep learning have shown great promise, achieving\naccuracies that are competitive with operational systems. However, those\nmethods often employ complex, customized architectures without sufficient\nablation analysis, making it difficult to understand what truly contributes to\ntheir success. Here we introduce Stormer, a simple transformer model that\nachieves state-of-the-art performance on weather forecasting with minimal\nchanges to the standard transformer backbone. We identify the key components of\nStormer through careful empirical analyses, including weather-specific\nembedding, randomized dynamics forecast, and pressure-weighted loss. At the\ncore of Stormer is a randomized forecasting objective that trains the model to\nforecast the weather dynamics over varying time intervals. During inference,\nthis allows us to produce multiple forecasts for a target lead time and combine\nthem to obtain better forecast accuracy. On WeatherBench 2, Stormer performs\ncompetitively at short to medium-range forecasts and outperforms current\nmethods beyond 7 days, while requiring orders-of-magnitude less training data\nand compute. Additionally, we demonstrate Stormer's favorable scaling\nproperties, showing consistent improvements in forecast accuracy with increases\nin model size and training tokens. Code and checkpoints are available at\nhttps://github.com/tung-nd/stormer.\n","authors":["Tung Nguyen","Rohan Shah","Hritik Bansal","Troy Arcomano","Romit Maulik","Veerabhadra Kotamarthi","Ian Foster","Sandeep Madireddy","Aditya Grover"],"pdf_url":"https://arxiv.org/pdf/2312.03876v2.pdf","comment":"Neural Information Processing Systems (NeurIPS 2024)"},{"id":"http://arxiv.org/abs/2401.16635v3","updated":"2024-10-22T06:19:20Z","published":"2024-01-30T00:17:37Z","title":"Improving Reinforcement Learning from Human Feedback with Efficient\n  Reward Model Ensemble","summary":"  Reinforcement Learning from Human Feedback (RLHF) is a widely adopted\napproach for aligning large language models with human values. However, RLHF\nrelies on a reward model that is trained with a limited amount of human\npreference data, which could lead to inaccurate predictions. As a result, RLHF\nmay produce outputs that are misaligned with human values. To mitigate this\nissue, we contribute a reward ensemble method that allows the reward model to\nmake more accurate predictions. As using an ensemble of large language\nmodel-based reward models can be computationally and resource-expensive, we\nexplore efficient ensemble methods including linear-layer ensemble and\nLoRA-based ensemble. Empirically, we run Best-of-$n$ and Proximal Policy\nOptimization with our ensembled reward models, and verify that our ensemble\nmethods help improve the alignment performance of RLHF outputs.\n","authors":["Shun Zhang","Zhenfang Chen","Sunli Chen","Yikang Shen","Zhiqing Sun","Chuang Gan"],"pdf_url":"https://arxiv.org/pdf/2401.16635v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.16719v1","updated":"2024-10-22T05:59:29Z","published":"2024-10-22T05:59:29Z","title":"Progressive Compositionality In Text-to-Image Generative Models","summary":"  Despite the impressive text-to-image (T2I) synthesis capabilities of\ndiffusion models, they often struggle to understand compositional relationships\nbetween objects and attributes, especially in complex settings. Existing\nsolutions have tackled these challenges by optimizing the cross-attention\nmechanism or learning from the caption pairs with minimal semantic changes.\nHowever, can we generate high-quality complex contrastive images that diffusion\nmodels can directly discriminate based on visual representations? In this work,\nwe leverage large-language models (LLMs) to compose realistic, complex\nscenarios and harness Visual-Question Answering (VQA) systems alongside\ndiffusion models to automatically curate a contrastive dataset, ConPair,\nconsisting of 15k pairs of high-quality contrastive images. These pairs feature\nminimal visual discrepancies and cover a wide range of attribute categories,\nespecially complex and natural scenarios. To learn effectively from these error\ncases, i.e., hard negative images, we propose EvoGen, a new multi-stage\ncurriculum for contrastive learning of diffusion models. Through extensive\nexperiments across a wide range of compositional scenarios, we showcase the\neffectiveness of our proposed framework on compositional T2I benchmarks.\n","authors":["Xu Han","Linghao Jin","Xiaofeng Liu","Paul Pu Liang"],"pdf_url":"https://arxiv.org/pdf/2410.16719v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.16718v1","updated":"2024-10-22T05:56:57Z","published":"2024-10-22T05:56:57Z","title":"Optimal Partial Graph Matching","summary":"  Partial graph matching addresses the limitations of traditional graph\nmatching by allowing some nodes to remain unmatched, making it applicable to\nmore complex scenarios. However, this flexibility introduces additional\ncomplexity, as both the subset of nodes to match and the optimal mapping must\nbe determined. While recent studies have explored deep learning techniques for\npartial graph matching, a significant limitation remains: the absence of an\noptimization objective that fully captures the problem's intrinsic nature while\nenabling efficient solutions. In this paper, we propose a novel optimization\nframework for partial graph matching, inspired by optimal partial transport.\nOur approach formulates an objective that enables partial assignments while\nincorporating matching biases, using weighted total variation as the divergence\nfunction to guarantee optimal partial assignments. We employ the Hungarian\nalgorithm to achieve efficient, exact solutions with cubic time complexity. Our\ncontributions are threefold: (i) we introduce a robust optimization objective\nthat balances matched and unmatched nodes; (ii) we establish a connection\nbetween partial graph matching and the linear sum assignment problem, enabling\nefficient solutions; (iii) we propose a deep graph matching architecture with a\nnovel partial matching loss, providing an end-to-end solution. The empirical\nevaluations on standard graph matching benchmarks demonstrate the efficacy of\nthe proposed approach.\n","authors":["Gathika Ratnayaka","James Nichols","Qing Wang"],"pdf_url":"https://arxiv.org/pdf/2410.16718v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.16713v1","updated":"2024-10-22T05:49:24Z","published":"2024-10-22T05:49:24Z","title":"Collapse or Thrive? Perils and Promises of Synthetic Data in a\n  Self-Generating World","summary":"  The increasing presence of AI-generated content on the internet raises a\ncritical question: What happens when generative machine learning models are\npretrained on web-scale datasets containing data created by earlier models?\nSome authors prophesy $\\textit{model collapse}$ under a \"$\\textit{replace}$\"\nscenario: a sequence of models, the first trained with real data and each later\none trained only on synthetic data from its preceding model. In this scenario,\nmodels successively degrade. Others see collapse as easily avoidable; in an\n\"$\\textit{accumulate}$' scenario, a sequence of models is trained, but each\ntraining uses all real and synthetic data generated so far. In this work, we\ndeepen and extend the study of these contrasting scenarios. First, collapse\nversus avoidance of collapse is studied by comparing the replace and accumulate\nscenarios on each of three prominent generative modeling settings; we find the\nsame contrast emerges in all three settings. Second, we study a compromise\nscenario; the available data remains the same as in the accumulate scenario --\nbut unlike $\\textit{accumulate}$ and like $\\textit{replace}$, each model is\ntrained using a fixed compute budget; we demonstrate that model test loss on\nreal data is larger than in the $\\textit{accumulate}$ scenario, but apparently\nplateaus, unlike the divergence seen with $\\textit{replace}$. Third, we study\nthe relative importance of cardinality and proportion of real data for avoiding\nmodel collapse. Surprisingly, we find a non-trivial interaction between real\nand synthetic data, where the value of synthetic data for reducing test loss\ndepends on the absolute quantity of real data. Our insights are particularly\nimportant when forecasting whether future frontier generative models will\ncollapse or thrive, and our results open avenues for empirically and\nmathematically studying the context-dependent value of synthetic data.\n","authors":["Joshua Kazdan","Rylan Schaeffer","Apratim Dey","Matthias Gerstgrasser","Rafael Rafailov","David L. Donoho","Sanmi Koyejo"],"pdf_url":"https://arxiv.org/pdf/2410.16713v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2404.11216v2","updated":"2024-10-22T05:45:46Z","published":"2024-04-17T10:00:56Z","title":"Position Engineering: Boosting Large Language Models through Positional\n  Information Manipulation","summary":"  The performance of large language models (LLMs) is significantly influenced\nby the quality of the prompts provided. In response, researchers have developed\nenormous prompt engineering strategies aimed at modifying the prompt text to\nenhance task performance. In this paper, we introduce a novel technique termed\nposition engineering, which offers a more efficient way to guide large language\nmodels. Unlike prompt engineering, which requires substantial effort to modify\nthe text provided to LLMs, position engineering merely involves altering the\npositional information in the prompt without modifying the text itself. We have\nevaluated position engineering in two widely-used LLM scenarios:\nretrieval-augmented generation (RAG) and in-context learning (ICL). Our\nfindings show that position engineering substantially improves upon the\nbaseline in both cases. Position engineering thus represents a promising new\nstrategy for exploiting the capabilities of large language models.\n","authors":["Zhiyuan He","Huiqiang Jiang","Zilong Wang","Yuqing Yang","Luna Qiu","Lili Qiu"],"pdf_url":"https://arxiv.org/pdf/2404.11216v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.16710v1","updated":"2024-10-22T05:32:40Z","published":"2024-10-22T05:32:40Z","title":"Influential Language Data Selection via Gradient Trajectory Pursuit","summary":"  Curating a desirable dataset for training has been the core of building\nhighly capable large language models (Touvron et al., 2023; Achiam et al.,\n2023; Team et al.,2024). Gradient influence scores (Pruthi et al., 2020; Xia et\nal., 2024) are shown to be correlated with model performance and are commonly\nused as the criterion for data selection. However, existing methods are built\nupon either individual sample rankings or inefficient matching process, leading\nto suboptimal performance or scaling up issues.In this paper, we propose\nGradient Trajectory Pursuit (GTP), an algorithm that performs pursuit of\ngradient trajectories via jointly selecting data points under an L0-norm\nregularized objective. The proposed algorithm highlights: (1) joint selection\ninstead of independent top-k selection, which automatically de-duplicates\nsamples; (2) higher efficiency with compressive sampling processes, which can\nbe further sped up using a distributed framework. In the experiments, we\ndemonstrate the algorithm in both in-domain and target-domain selection\nbenchmarks and show that it outperforms top-k selection and competitive\nalgorithms consistently, for example, our algorithm chooses as low as 0.5% data\nto achieve full performance on the targeted instruction tuning tasks\n","authors":["Zhiwei Deng","Tao Li","Yang Li"],"pdf_url":"https://arxiv.org/pdf/2410.16710v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.16709v1","updated":"2024-10-22T05:27:01Z","published":"2024-10-22T05:27:01Z","title":"Universal approximation property of ODENet and ResNet with a single\n  activation function","summary":"  We study a universal approximation property of ODENet and ResNet. The ODENet\nis a map from an initial value to the final value of an ODE system in a finite\ninterval. It is considered a mathematical model of a ResNet-type deep learning\nsystem. We consider dynamical systems with vector fields given by a single\ncomposition of the activation function and an affine mapping, which is the most\ncommon choice of the ODENet or ResNet vector field in actual machine learning\nsystems. We show that such an ODENet and ResNet with a restricted vector field\ncan uniformly approximate ODENet with a general vector field.\n","authors":["Masato Kimura","Kazunori Matsui","Yosuke Mizuno"],"pdf_url":"https://arxiv.org/pdf/2410.16709v1.pdf","comment":"14 pages"},{"id":"http://arxiv.org/abs/2410.16705v1","updated":"2024-10-22T05:20:21Z","published":"2024-10-22T05:20:21Z","title":"Privacy-hardened and hallucination-resistant synthetic data generation\n  with logic-solvers","summary":"  Machine-generated data is a valuable resource for training Artificial\nIntelligence algorithms, evaluating rare workflows, and sharing data under\nstricter data legislations. The challenge is to generate data that is accurate\nand private. Current statistical and deep learning methods struggle with large\ndata volumes, are prone to hallucinating scenarios incompatible with reality,\nand seldom quantify privacy meaningfully. Here we introduce Genomator, a logic\nsolving approach (SAT solving), which efficiently produces private and\nrealistic representations of the original data. We demonstrate the method on\ngenomic data, which arguably is the most complex and private information.\nSynthetic genomes hold great potential for balancing underrepresented\npopulations in medical research and advancing global data exchange. We\nbenchmark Genomator against state-of-the-art methodologies (Markov generation,\nRestricted Boltzmann Machine, Generative Adversarial Network and Conditional\nRestricted Boltzmann Machines), demonstrating an 84-93% accuracy improvement\nand 95-98% higher privacy. Genomator is also 1000-1600 times more efficient,\nmaking it the only tested method that scales to whole genomes. We show the\nuniversal trade-off between privacy and accuracy, and use Genomator's tuning\ncapability to cater to all applications along the spectrum, from provable\nprivate representations of sensitive cohorts, to datasets with\nindistinguishable pharmacogenomic profiles. Demonstrating the production-scale\ngeneration of tuneable synthetic data can increase trust and pave the way into\nthe clinic.\n","authors":["Mark A. Burgess","Brendan Hosking","Roc Reguant","Anubhav Kaphle","Mitchell J. O'Brien","Letitia M. F. Sng","Yatish Jain","Denis C. Bauer"],"pdf_url":"https://arxiv.org/pdf/2410.16705v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2312.06682v2","updated":"2024-10-22T05:12:24Z","published":"2023-12-09T07:08:00Z","title":"Learning to Denoise Biomedical Knowledge Graph for Robust Molecular\n  Interaction Prediction","summary":"  Molecular interaction prediction plays a crucial role in forecasting unknown\ninteractions between molecules, such as drug-target interaction (DTI) and\ndrug-drug interaction (DDI), which are essential in the field of drug discovery\nand therapeutics. Although previous prediction methods have yielded promising\nresults by leveraging the rich semantics and topological structure of\nbiomedical knowledge graphs (KGs), they have primarily focused on enhancing\npredictive performance without addressing the presence of inevitable noise and\ninconsistent semantics. This limitation has hindered the advancement of\nKG-based prediction methods. To address this limitation, we propose BioKDN\n(Biomedical Knowledge Graph Denoising Network) for robust molecular interaction\nprediction. BioKDN refines the reliable structure of local subgraphs by\ndenoising noisy links in a learnable manner, providing a general module for\nextracting task-relevant interactions. To enhance the reliability of the\nrefined structure, BioKDN maintains consistent and robust semantics by\nsmoothing relations around the target interaction. By maximizing the mutual\ninformation between reliable structure and smoothed relations, BioKDN\nemphasizes informative semantics to enable precise predictions. Experimental\nresults on real-world datasets show that BioKDN surpasses state-of-the-art\nmodels in DTI and DDI prediction tasks, confirming the effectiveness and\nrobustness of BioKDN in denoising unreliable interactions within contaminated\nKGs\n","authors":["Tengfei Ma","Yujie Chen","Wen Tao","Dashun Zheng","Xuan Lin","Patrick Cheong-lao Pang","Yiping Liu","Yijun Wang","Longyue Wang","Bosheng Song","Xiangxiang Zeng","Philip S. Yu"],"pdf_url":"https://arxiv.org/pdf/2312.06682v2.pdf","comment":"13 pages, Accepted at TKDE"},{"id":"http://arxiv.org/abs/2410.16701v1","updated":"2024-10-22T05:12:19Z","published":"2024-10-22T05:12:19Z","title":"ClimaQA: An Automated Evaluation Framework for Climate Foundation Models","summary":"  The use of foundation models in climate science has recently gained\nsignificant attention. However, a critical issue remains: the lack of a\ncomprehensive evaluation framework capable of assessing the quality and\nscientific validity of model outputs. To address this issue, we develop\nClimaGen (Climate QA Generator), an automated algorithmic framework that\ngenerates question-answer pairs from graduate textbooks with climate scientists\nin the loop. As a result, we present ClimaQA-Gold, an expert-annotated\nbenchmark dataset alongside ClimaQA-Silver, a large-scale, comprehensive\nsynthetic QA dataset for climate science. Finally, we develop evaluation\nstrategies and compare different Large Language Models (LLMs) on our\nbenchmarks. Our results offer novel insights into various approaches used to\nenhance climate foundation models.\n","authors":["Veeramakali Vignesh Manivannan","Yasaman Jafari","Srikar Eranky","Spencer Ho","Rose Yu","Duncan Watson-Parris","Yian Ma","Leon Bergen","Taylor Berg-Kirkpatrick"],"pdf_url":"https://arxiv.org/pdf/2410.16701v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.16699v1","updated":"2024-10-22T05:11:45Z","published":"2024-10-22T05:11:45Z","title":"Graph Transformers Dream of Electric Flow","summary":"  We show theoretically and empirically that the linear Transformer, when\napplied to graph data, can implement algorithms that solve canonical problems\nsuch as electric flow and eigenvector decomposition. The input to the\nTransformer is simply the graph incidence matrix; no other explicit positional\nencoding information is provided. We present explicit weight configurations for\nimplementing each such graph algorithm, and we bound the errors of the\nconstructed Transformers by the errors of the underlying algorithms. Our\ntheoretical findings are corroborated by experiments on synthetic data.\nAdditionally, on a real-world molecular regression task, we observe that the\nlinear Transformer is capable of learning a more effective positional encoding\nthan the default one based on Laplacian eigenvectors. Our work is an initial\nstep towards elucidating the inner-workings of the Transformer for graph data.\n","authors":["Xiang Cheng","Lawrence Carin","Suvrit Sra"],"pdf_url":"https://arxiv.org/pdf/2410.16699v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.16698v1","updated":"2024-10-22T05:07:30Z","published":"2024-10-22T05:07:30Z","title":"Hyperboloid GPLVM for Discovering Continuous Hierarchies via\n  Nonparametric Estimation","summary":"  Dimensionality reduction (DR) offers a useful representation of complex\nhigh-dimensional data. Recent DR methods focus on hyperbolic geometry to derive\na faithful low-dimensional representation of hierarchical data. However,\nexisting methods are based on neighbor embedding, frequently ruining the\ncontinual relation of the hierarchies. This paper presents hyperboloid Gaussian\nprocess (GP) latent variable models (hGP-LVMs) to embed high-dimensional\nhierarchical data with implicit continuity via nonparametric estimation. We\nadopt generative modeling using the GP, which brings effective hierarchical\nembedding and executes ill-posed hyperparameter tuning. This paper presents\nthree variants that employ original point, sparse point, and Bayesian\nestimations. We establish their learning algorithms by incorporating the\nRiemannian optimization and active approximation scheme of GP-LVM. For Bayesian\ninference, we further introduce the reparameterization trick to realize\nBayesian latent variable learning. In the last part of this paper, we apply\nhGP-LVMs to several datasets and show their ability to represent\nhigh-dimensional hierarchies in low-dimensional spaces.\n","authors":["Koshi Watanabe","Keisuke Maeda","Takahiro Ogawa","Miki Haseyama"],"pdf_url":"https://arxiv.org/pdf/2410.16698v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.13253v2","updated":"2024-10-22T04:58:21Z","published":"2024-10-17T06:20:43Z","title":"FDF: Flexible Decoupled Framework for Time Series Forecasting with\n  Conditional Denoising and Polynomial Modeling","summary":"  Time series forecasting is vital in numerous web applications, influencing\ncritical decision-making across industries. While diffusion models have\nrecently gained increasing popularity for this task, we argue they suffer from\na significant drawback: indiscriminate noise addition to the original time\nseries followed by denoising, which can obscure underlying dynamic evolving\ntrend and complicate forecasting. To address this limitation, we propose a\nnovel flexible decoupled framework (FDF) that learns high-quality time series\nrepresentations for enhanced forecasting performance. A key characteristic of\nour approach leverages the inherent inductive bias of time series data by\ndecomposing it into trend and seasonal components, each modeled separately to\nenable decoupled analysis and modeling. Specifically, we propose an innovative\nConditional Denoising Seasonal Module (CDSM) within the diffusion model, which\nleverages statistical information from the historical window to conditionally\nmodel the complex seasonal component. Notably, we incorporate a Polynomial\nTrend Module (PTM) to effectively capture the smooth trend component, thereby\nenhancing the model's ability to represent temporal dependencies. Extensive\nexperiments validate the effectiveness of our framework, demonstrating superior\nperformance over existing methods and higlighting its flexibility in time\nseries forecasting. We hope our work can bring a new perspective for time\nseries forecasting. We intend to make our code publicly available as\nopen-source in the future.\n","authors":["Jintao Zhang","Mingyue Cheng","Xiaoyu Tao","Zhiding Liu","Daoyu Wang"],"pdf_url":"https://arxiv.org/pdf/2410.13253v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.16694v1","updated":"2024-10-22T04:55:12Z","published":"2024-10-22T04:55:12Z","title":"Governing equation discovery of a complex system from snapshots","summary":"  Complex systems in physics, chemistry, and biology that evolve over time with\ninherent randomness are typically described by stochastic differential\nequations (SDEs). A fundamental challenge in science and engineering is to\ndetermine the governing equations of a complex system from snapshot data.\nTraditional equation discovery methods often rely on stringent assumptions,\nsuch as the availability of the trajectory information or time-series data, and\nthe presumption that the underlying system is deterministic. In this work, we\nintroduce a data-driven, simulation-free framework, called Sparse\nIdentification of Differential Equations from Snapshots (SpIDES), that\ndiscovers the governing equations of a complex system from snapshots by\nutilizing the advanced machine learning techniques to perform three essential\nsteps: probability flow reconstruction, probability density estimation, and\nBayesian sparse identification. We validate the effectiveness and robustness of\nSpIDES by successfully identifying the governing equation of an over-damped\nLangevin system confined within two potential wells. By extracting\ninterpretable drift and diffusion terms from the SDEs, our framework provides\ndeeper insights into system dynamics, enhances predictive accuracy, and\nfacilitates more effective strategies for managing and simulating stochastic\nsystems.\n","authors":["Qunxi Zhu","Bolin Zhao","Jingdong Zhang","Peiyang Li","Wei Lin"],"pdf_url":"https://arxiv.org/pdf/2410.16694v1.pdf","comment":null}]},"2024-10-23T00:00:00Z":{"Computation and Language":[{"id":"http://arxiv.org/abs/2410.17195v2","updated":"2024-10-23T07:02:09Z","published":"2024-10-22T17:13:38Z","title":"Non-myopic Generation of Language Model for Reasoning and Planning","summary":"  Large Language Models have demonstrated remarkable abilities in reasoning and\nplanning by breaking down complex problems into sequential steps. Despite their\nsuccess in various domains like mathematical problem-solving and coding, LLMs\nface challenges in ensuring reliable and optimal planning due to their inherent\nmyopic nature of autoregressive decoding. This paper revisits LLM reasoning\nfrom an optimal-control perspective, proposing a novel method,\nPredictive-Decoding, that leverages Model Predictive Control to enhance\nplanning accuracy. By re-weighting LLM distributions based on foresight\ntrajectories, Predictive-Decoding aims to mitigate early errors and promote\nnon-myopic planning. Our experiments show significant improvements in a wide\nrange of tasks for math, coding, and agents. Furthermore, Predictive-Decoding\ndemonstrates computational efficiency, outperforming search baselines with\nreduced computational resources. This study provides insights into optimizing\nLLM planning capabilities.\n","authors":["Chang Ma","Haiteng Zhao","Junlei Zhang","Junxian He","Lingpeng Kong"],"pdf_url":"https://arxiv.org/pdf/2410.17195v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.16638v2","updated":"2024-10-23T03:41:49Z","published":"2024-10-22T02:27:57Z","title":"LLMScan: Causal Scan for LLM Misbehavior Detection","summary":"  Despite the success of Large Language Models (LLMs) across various fields,\ntheir potential to generate untruthful, biased and harmful responses poses\nsignificant risks, particularly in critical applications. This highlights the\nurgent need for systematic methods to detect and prevent such misbehavior.\nWhile existing approaches target specific issues such as harmful responses,\nthis work introduces LLMScan, an innovative LLM monitoring technique based on\ncausality analysis, offering a comprehensive solution. LLMScan systematically\nmonitors the inner workings of an LLM through the lens of causal inference,\noperating on the premise that the LLM's `brain' behaves differently when\nmisbehaving. By analyzing the causal contributions of the LLM's input tokens\nand transformer layers, LLMScan effectively detects misbehavior. Extensive\nexperiments across various tasks and models reveal clear distinctions in the\ncausal distributions between normal behavior and misbehavior, enabling the\ndevelopment of accurate, lightweight detectors for a variety of misbehavior\ndetection tasks.\n","authors":["Mengdi Zhang","Kai Kiat Goh","Peixin Zhang","Jun Sun"],"pdf_url":"https://arxiv.org/pdf/2410.16638v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.16451v2","updated":"2024-10-23T01:56:15Z","published":"2024-10-21T19:25:31Z","title":"Susu Box or Piggy Bank: Assessing Cultural Commonsense Knowledge between\n  Ghana and the U.S","summary":"  Recent work has highlighted the culturally-contingent nature of commonsense\nknowledge. We introduce AMAMMER${\\epsilon}$, a test set of 525 multiple-choice\nquestions designed to evaluate the commonsense knowledge of English LLMs,\nrelative to the cultural contexts of Ghana and the United States. To create\nAMAMMER${\\epsilon}$, we select a set of multiple-choice questions (MCQs) from\nexisting commonsense datasets and rewrite them in a multi-stage process\ninvolving surveys of Ghanaian and U.S. participants. In three rounds of\nsurveys, participants from both pools are solicited to (1) write correct and\nincorrect answer choices, (2) rate individual answer choices on a 5-point\nLikert scale, and (3) select the best answer choice from the newly-constructed\nMCQ items, in a final validation step. By engaging participants at multiple\nstages, our procedure ensures that participant perspectives are incorporated\nboth in the creation and validation of test items, resulting in high levels of\nagreement within each pool. We evaluate several off-the-shelf English LLMs on\nAMAMMER${\\epsilon}$. Uniformly, models prefer answers choices that align with\nthe preferences of U.S. annotators over Ghanaian annotators. Additionally, when\ntest items specify a cultural context (Ghana or the U.S.), models exhibit some\nability to adapt, but performance is consistently better in U.S. contexts than\nGhanaian. As large resources are devoted to the advancement of English LLMs,\nour findings underscore the need for culturally adaptable models and\nevaluations to meet the needs of diverse English-speaking populations around\nthe world.\n","authors":["Christabel Acquaye","Haozhe An","Rachel Rudinger"],"pdf_url":"https://arxiv.org/pdf/2410.16451v2.pdf","comment":"Accepted to EMNLP 2024"},{"id":"http://arxiv.org/abs/2410.18077v1","updated":"2024-10-23T17:58:49Z","published":"2024-10-23T17:58:49Z","title":"ALTA: Compiler-Based Analysis of Transformers","summary":"  We propose a new programming language called ALTA and a compiler that can map\nALTA programs to Transformer weights. ALTA is inspired by RASP, a language\nproposed by Weiss et al. (2021), and Tracr (Lindner et al., 2023), a compiler\nfrom RASP programs to Transformer weights. ALTA complements and extends this\nprior work, offering the ability to express loops and to compile programs to\nUniversal Transformers, among other advantages. ALTA allows us to\nconstructively show how Transformers can represent length-invariant algorithms\nfor computing parity and addition, as well as a solution to the SCAN benchmark\nof compositional generalization tasks, without requiring intermediate\nscratchpad decoding steps. We also propose tools to analyze cases where the\nexpressibility of an algorithm is established, but end-to-end training on a\ngiven training set fails to induce behavior consistent with the desired\nalgorithm. To this end, we explore training from ALTA execution traces as a\nmore fine-grained supervision signal. This enables additional experiments and\ntheoretical analyses relating the learnability of various algorithms to data\navailability and modeling decisions, such as positional encodings. We make the\nALTA framework -- language specification, symbolic interpreter, and weight\ncompiler -- available to the community to enable further applications and\ninsights.\n","authors":["Peter Shaw","James Cohan","Jacob Eisenstein","Kenton Lee","Jonathan Berant","Kristina Toutanova"],"pdf_url":"https://arxiv.org/pdf/2410.18077v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.18071v1","updated":"2024-10-23T17:54:43Z","published":"2024-10-23T17:54:43Z","title":"TP-Eval: Tap Multimodal LLMs' Potential in Evaluation by Customizing\n  Prompts","summary":"  Recently, multimodal large language models (MLLMs) have received much\nattention for their impressive capabilities. The evaluation of MLLMs is\nbecoming critical to analyzing attributes of MLLMs and providing valuable\ninsights. However, current benchmarks overlook the problem of prompt\nsensitivity - minor prompt variations may lead to significant performance\nfluctuations. Thus, inappropriate prompts may obscure the models' capabilities,\nunderestimating the models' performance. Moreover, different models have\ndifferent preferences for different prompts, and thus, using the same prompt\nfor all models will cause evaluation bias. This paper analyzes this deficiency\nin existing benchmarks and further introduces a new evaluation framework named\nTP-Eval, which introduces a prompt customization method to reduce evaluation\nbiases and tap models' potential. TP-Eval will rewrite the original prompts to\ndifferent customized prompts for different models. In particular, we propose\nsome well-designed modules for prompt customization tailored to the scenario of\nMLLM evaluation. Extensive experiments demonstrate the effectiveness of our\napproach to uncovering models' capabilities, and TP-Eval should benefit the\ncommunity in developing more comprehensive and convincing MLLM evaluation\nbenchmarks.\n","authors":["Yuxuan Xie","Tianhua Li","Wenqi Shao","Kaipeng Zhang"],"pdf_url":"https://arxiv.org/pdf/2410.18071v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2409.15240v2","updated":"2024-10-23T17:47:58Z","published":"2024-09-23T17:38:41Z","title":"MADial-Bench: Towards Real-world Evaluation of Memory-Augmented Dialogue\n  Generation","summary":"  Long-term memory is important for chatbots and dialogue systems (DS) to\ncreate consistent and human-like conversations, evidenced by numerous developed\nmemory-augmented DS (MADS). To evaluate the effectiveness of such MADS,\nexisting commonly used evaluation metrics, like retrieval accuracy and\nperplexity (PPL), mainly focus on query-oriented factualness and language\nquality assessment. However, these metrics often lack practical value.\nMoreover, the evaluation dimensions are insufficient for human-like assessment\nin DS. Regarding memory-recalling paradigms, current evaluation schemes only\nconsider passive memory retrieval while ignoring diverse memory recall with\nrich triggering factors, e.g., emotions and surroundings, which can be\nessential in emotional support scenarios. To bridge the gap, we construct a\nnovel Memory-Augmented Dialogue Benchmark (MADail-Bench) covering various\nmemory-recalling paradigms based on cognitive science and psychology theories.\nThe benchmark assesses two tasks separately: memory retrieval and memory\nrecognition with the incorporation of both passive and proactive memory recall\ndata. We introduce new scoring criteria to the evaluation, including memory\ninjection, emotion support (ES) proficiency, and intimacy, to comprehensively\nassess generated responses. Results from cutting-edge embedding models and\nlarge language models on this benchmark indicate the potential for further\nadvancement. Extensive testing further reveals correlations between memory\ninjection, ES proficiency, and intimacy.\n","authors":["Junqing He","Liang Zhu","Rui Wang","Xi Wang","Reza Haffari","Jiaxing Zhang"],"pdf_url":"https://arxiv.org/pdf/2409.15240v2.pdf","comment":"Submitted to NAACL 2025"},{"id":"http://arxiv.org/abs/2404.19442v2","updated":"2024-10-23T17:46:13Z","published":"2024-04-30T10:45:40Z","title":"Does Generative AI speak Nigerian-Pidgin?: Issues about\n  Representativeness and Bias for Multilingualism in LLMs","summary":"  Nigeria is a multilingual country with 500+ languages. Naija is a\nNigerian-Pidgin spoken by approx. 120M speakers in Nigeria and it is a mixed\nlanguage (e.g., English, Portuguese, Yoruba, Hausa and Igbo). Although it has\nmainly been a spoken language until recently, there are now various platforms\npublishing exclusively in Naija such as Naija Wikipedia. However, it is hard to\ndistinguish by non-native from a larger pidgin languages spoken across West\nAfrica known as West African Pidgin English (WAPE) -- which is more simplied\nand understandable by wider audience in Ghana, Nigeria, and Cameroon. BBC news\nplatform publishes exclusively in WAPE to cater for several countries in West\nAfrica. In our paper, we show through statistical analyses and Machine\nTranslation experiments that these two creole varieties do not represent each\nother (i.e., there are linguistic differences in word order and vocabulary) and\nGenerative AI operates only based on WAPE. In other words, Naija is\nunder-represented in Generative AI, and it is hard to teach LLMs with few\nexamples.\n","authors":["David Ifeoluwa Adelani","A. Seza Doğruöz","Iyanuoluwa Shode","Anuoluwapo Aremu"],"pdf_url":"https://arxiv.org/pdf/2404.19442v2.pdf","comment":"under review"},{"id":"http://arxiv.org/abs/2407.15762v2","updated":"2024-10-23T17:42:39Z","published":"2024-07-22T16:13:38Z","title":"Conditional Language Policy: A General Framework for Steerable\n  Multi-Objective Finetuning","summary":"  Reward-based finetuning is crucial for aligning language policies with\nintended behaviors (e.g., creativity and safety). A key challenge is to develop\nsteerable language models that trade-off multiple (conflicting) objectives in a\nflexible and efficient manner. This paper presents Conditional Language Policy\n(CLP), a general framework for finetuning language models on multiple\nobjectives. Building on techniques from multi-task training and\nparameter-efficient finetuning, CLP learn steerable models that effectively\ntrade-off conflicting objectives at inference time. Notably, this does not\nrequire training or maintaining multiple models to achieve different trade-offs\nbetween the objectives. Through extensive experiments and ablations on two\nsummarization datasets, we show that CLP learns steerable language models that\noutperform and Pareto-dominate the existing approaches for multi-objective\nfinetuning.\n","authors":["Kaiwen Wang","Rahul Kidambi","Ryan Sullivan","Alekh Agarwal","Christoph Dann","Andrea Michi","Marco Gelmi","Yunxuan Li","Raghav Gupta","Avinava Dubey","Alexandre Ramé","Johan Ferret","Geoffrey Cideron","Le Hou","Hongkun Yu","Amr Ahmed","Aranyak Mehta","Léonard Hussenot","Olivier Bachem","Edouard Leurent"],"pdf_url":"https://arxiv.org/pdf/2407.15762v2.pdf","comment":"40 pages. Findings of EMNLP 2024"},{"id":"http://arxiv.org/abs/2410.18057v1","updated":"2024-10-23T17:30:50Z","published":"2024-10-23T17:30:50Z","title":"CLEAR: Character Unlearning in Textual and Visual Modalities","summary":"  Machine Unlearning (MU) is critical for enhancing privacy and security in\ndeep learning models, particularly in large multimodal language models (MLLMs),\nby removing specific private or hazardous information. While MU has made\nsignificant progress in textual and visual modalities, multimodal unlearning\n(MMU) remains significantly underexplored, partially due to the absence of a\nsuitable open-source benchmark. To address this, we introduce CLEAR, a new\nbenchmark designed to evaluate MMU methods. CLEAR contains 200 fictitious\nindividuals and 3,700 images linked with corresponding question-answer pairs,\nenabling a thorough evaluation across modalities. We assess 10 MU methods,\nadapting them for MMU, and highlight new challenges specific to multimodal\nforgetting. We also demonstrate that simple $\\ell_1$ regularization on LoRA\nweights significantly mitigates catastrophic forgetting, preserving model\nperformance on retained data. The dataset is available at\nhttps://huggingface.co/datasets/therem/CLEAR\n","authors":["Alexey Dontsov","Dmitrii Korzh","Alexey Zhavoronkin","Boris Mikheev","Denis Bobkov","Aibek Alanov","Oleg Y. Rogov","Ivan Oseledets","Elena Tutubalina"],"pdf_url":"https://arxiv.org/pdf/2410.18057v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.18050v1","updated":"2024-10-23T17:24:58Z","published":"2024-10-23T17:24:58Z","title":"LongRAG: A Dual-Perspective Retrieval-Augmented Generation Paradigm for\n  Long-Context Question Answering","summary":"  Long-Context Question Answering (LCQA), a challenging task, aims to reason\nover long-context documents to yield accurate answers to questions. Existing\nlong-context Large Language Models (LLMs) for LCQA often struggle with the\n\"lost in the middle\" issue. Retrieval-Augmented Generation (RAG) mitigates this\nissue by providing external factual evidence. However, its chunking strategy\ndisrupts the global long-context information, and its low-quality retrieval in\nlong contexts hinders LLMs from identifying effective factual details due to\nsubstantial noise. To this end, we propose LongRAG, a general,\ndual-perspective, and robust LLM-based RAG system paradigm for LCQA to enhance\nRAG's understanding of complex long-context knowledge (i.e., global information\nand factual details). We design LongRAG as a plug-and-play paradigm,\nfacilitating adaptation to various domains and LLMs. Extensive experiments on\nthree multi-hop datasets demonstrate that LongRAG significantly outperforms\nlong-context LLMs (up by 6.94%), advanced RAG (up by 6.16%), and Vanilla RAG\n(up by 17.25%). Furthermore, we conduct quantitative ablation studies and\nmulti-dimensional analyses, highlighting the effectiveness of the system's\ncomponents and fine-tuning strategies. Data and code are available at\nhttps://github.com/QingFei1/LongRAG.\n","authors":["Qingfei Zhao","Ruobing Wang","Yukuo Cen","Daren Zha","Shicheng Tan","Yuxiao Dong","Jie Tang"],"pdf_url":"https://arxiv.org/pdf/2410.18050v1.pdf","comment":"EMNLP 2024 Main"},{"id":"http://arxiv.org/abs/2410.18040v1","updated":"2024-10-23T17:07:32Z","published":"2024-10-23T17:07:32Z","title":"Key Algorithms for Keyphrase Generation: Instruction-Based LLMs for\n  Russian Scientific Keyphrases","summary":"  Keyphrase selection is a challenging task in natural language processing that\nhas a wide range of applications. Adapting existing supervised and unsupervised\nsolutions for the Russian language faces several limitations due to the rich\nmorphology of Russian and the limited number of training datasets available.\nRecent studies conducted on English texts show that large language models\n(LLMs) successfully address the task of generating keyphrases. LLMs allow\nachieving impressive results without task-specific fine-tuning, using text\nprompts instead. In this work, we access the performance of prompt-based\nmethods for generating keyphrases for Russian scientific abstracts. First, we\ncompare the performance of zero-shot and few-shot prompt-based methods,\nfine-tuned models, and unsupervised methods. Then we assess strategies for\nselecting keyphrase examples in a few-shot setting. We present the outcomes of\nhuman evaluation of the generated keyphrases and analyze the strengths and\nweaknesses of the models through expert assessment. Our results suggest that\nprompt-based methods can outperform common baselines even using simple text\nprompts.\n","authors":["Anna Glazkova","Dmitry Morozov","Timur Garipov"],"pdf_url":"https://arxiv.org/pdf/2410.18040v1.pdf","comment":"The 12th International Conference on Analysis of Images, Social\n  Networks and Texts (AIST'2024)"},{"id":"http://arxiv.org/abs/2410.18035v1","updated":"2024-10-23T17:04:40Z","published":"2024-10-23T17:04:40Z","title":"MiLoRA: Efficient Mixture of Low-Rank Adaptation for Large Language\n  Models Fine-tuning","summary":"  Low-rank adaptation (LoRA) and its mixture-of-experts (MOE) variants are\nhighly effective parameter-efficient fine-tuning (PEFT) methods. However, they\nintroduce significant latency in multi-tenant settings due to the LoRA modules\nand MOE routers added to multiple linear modules in the Transformer layer. To\naddress this issue, we propose Mixture of Low-Rank Adaptation (MiLoRA), a novel\nand efficient LoRA variant. MiLoRA differs from previous MOE-style LoRA methods\nby considering each LoRA module as an expert and employing a prompt-aware\nrouting mechanism. This mechanism calculates expert routing results once before\ngenerating the first new token and reuses these results for subsequent tokens,\nreducing latency. Extensive experiments and analysis on commonsense reasoning\ntasks, math reasoning tasks, and widely used LLM evaluation benchmarks\ndemonstrate that MiLoRA consistently outperforms strong PEFT baselines with\ncomparable tunable parameter budgets. Additionally, MiLoRA significantly\nreduces latency in multi-tenant settings compared to previous LoRA-based\nmethods.\n","authors":["Jingfan Zhang","Yi Zhao","Dan Chen","Xing Tian","Huanran Zheng","Wei Zhu"],"pdf_url":"https://arxiv.org/pdf/2410.18035v1.pdf","comment":"Accepted by EMNLP 2024 Findings. arXiv admin note: substantial text\n  overlap with arXiv:2405.18203"},{"id":"http://arxiv.org/abs/2410.18032v1","updated":"2024-10-23T17:02:59Z","published":"2024-10-23T17:02:59Z","title":"GraphTeam: Facilitating Large Language Model-based Graph Analysis via\n  Multi-Agent Collaboration","summary":"  Graphs are widely used for modeling relational data in real-world scenarios,\nsuch as social networks and urban computing. Existing LLM-based graph analysis\napproaches either integrate graph neural networks (GNNs) for specific machine\nlearning tasks, limiting their transferability, or rely solely on LLMs'\ninternal reasoning ability, resulting in suboptimal performance. To address\nthese limitations, we take advantage of recent advances in LLM-based agents,\nwhich have shown capabilities of utilizing external knowledge or tools for\nproblem solving. By simulating human problem-solving strategies such as analogy\nand collaboration, we propose a multi-agent system based on LLMs named\nGraphTeam, for graph analysis. GraphTeam consists of five LLM-based agents from\nthree modules, and the agents with different specialities can collaborate with\neach other to address complex problems. Specifically, (1) input-output\nnormalization module: the question agent extracts and refines four key\narguments from the original question, facilitating the problem understanding,\nand the answer agent organizes the results to meet the output requirement; (2)\nexternal knowledge retrieval module: we first build a knowledge base consisting\nof relevant documentation and experience information, and then the search agent\nretrieves the most relevant entries for each question. (3) problem-solving\nmodule: given the retrieved information from search agent, the coding agent\nuses established algorithms via programming to generate solutions, and in case\nthe coding agent does not work, the reasoning agent will directly compute the\nresults without programming. Extensive experiments on six graph analysis\nbenchmarks demonstrate that GraphTeam achieves state-of-the-art performance\nwith an average 25.85% improvement over the best baseline in terms of accuracy.\nThe code and data are available at https://github.com/BUPT-GAMMA/GraphTeam.\n","authors":["Xin Li","Qizhi Chu","Yubin Chen","Yang Liu","Yaoqi Liu","Zekai Yu","Weize Chen","Chen Qian","Chuan Shi","Cheng Yang"],"pdf_url":"https://arxiv.org/pdf/2410.18032v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.18027v1","updated":"2024-10-23T17:00:13Z","published":"2024-10-23T17:00:13Z","title":"Cross-lingual Transfer of Reward Models in Multilingual Alignment","summary":"  Reinforcement learning with human feedback (RLHF) is shown to largely benefit\nfrom precise reward models (RMs). However, recent studies in reward modeling\nschemes are skewed towards English, limiting the applicability of RLHF in\nmultilingual alignments. In this work, we investigate the cross-lingual\ntransfer of RMs trained in diverse languages, primarily from English. Our\nexperimental results demonstrate the strong cross-lingual transfer of English\nRMs, exceeding target language RMs by 3~4% average increase in Multilingual\nRewardBench. Furthermore, we analyze the cross-lingual transfer of RMs through\nthe representation shifts. Finally, we perform multilingual alignment to\nexemplify how cross-lingual transfer in RM propagates to enhanced multilingual\ninstruction-following capability, along with extensive analyses on\noff-the-shelf RMs. We release the code, model, and data.\n","authors":["Jiwoo Hong","Noah Lee","Rodrigo Martínez-Castaño","César Rodríguez","James Thorne"],"pdf_url":"https://arxiv.org/pdf/2410.18027v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.11757v4","updated":"2024-10-23T16:41:45Z","published":"2024-06-17T17:16:45Z","title":"STAR: SocioTechnical Approach to Red Teaming Language Models","summary":"  This research introduces STAR, a sociotechnical framework that improves on\ncurrent best practices for red teaming safety of large language models. STAR\nmakes two key contributions: it enhances steerability by generating\nparameterised instructions for human red teamers, leading to improved coverage\nof the risk surface. Parameterised instructions also provide more detailed\ninsights into model failures at no increased cost. Second, STAR improves signal\nquality by matching demographics to assess harms for specific groups, resulting\nin more sensitive annotations. STAR further employs a novel step of arbitration\nto leverage diverse viewpoints and improve label reliability, treating\ndisagreement not as noise but as a valuable contribution to signal quality.\n","authors":["Laura Weidinger","John Mellor","Bernat Guillen Pegueroles","Nahema Marchal","Ravin Kumar","Kristian Lum","Canfer Akbulut","Mark Diaz","Stevie Bergman","Mikel Rodriguez","Verena Rieser","William Isaac"],"pdf_url":"https://arxiv.org/pdf/2406.11757v4.pdf","comment":"8 pages, 5 figures, 5 pages appendix. * denotes equal contribution"},{"id":"http://arxiv.org/abs/2409.17270v2","updated":"2024-10-23T16:27:20Z","published":"2024-09-25T18:35:45Z","title":"Proof of Thought : Neurosymbolic Program Synthesis allows Robust and\n  Interpretable Reasoning","summary":"  Large Language Models (LLMs) have revolutionized natural language processing,\nyet they struggle with inconsistent reasoning, particularly in novel domains\nand complex logical sequences. This research introduces Proof of Thought, a\nframework that enhances the reliability and transparency of LLM outputs. Our\napproach bridges LLM-generated ideas with formal logic verification, employing\na custom interpreter to convert LLM outputs into First Order Logic constructs\nfor theorem prover scrutiny. Central to our method is an intermediary\nJSON-based Domain-Specific Language, which by design balances precise logical\nstructures with intuitive human concepts. This hybrid representation enables\nboth rigorous validation and accessible human comprehension of LLM reasoning\nprocesses. Key contributions include a robust type system with sort management\nfor enhanced logical integrity, explicit representation of rules for clear\ndistinction between factual and inferential knowledge, and a flexible\narchitecture that allows for easy extension to various domain-specific\napplications. We demonstrate Proof of Thought's effectiveness through\nbenchmarking on StrategyQA and a novel multimodal reasoning task, showing\nimproved performance in open-ended scenarios. By providing verifiable and\ninterpretable results, our technique addresses critical needs for AI system\naccountability and sets a foundation for human-in-the-loop oversight in\nhigh-stakes domains.\n","authors":["Debargha Ganguly","Srinivasan Iyengar","Vipin Chaudhary","Shivkumar Kalyanaraman"],"pdf_url":"https://arxiv.org/pdf/2409.17270v2.pdf","comment":"38th Conference on Neural Information Processing Systems (NeurIPS\n  2024) System 2 Reasoning At Scale Workshop"},{"id":"http://arxiv.org/abs/2407.10992v2","updated":"2024-10-23T16:19:06Z","published":"2024-06-24T09:29:14Z","title":"AlleNoise: large-scale text classification benchmark dataset with\n  real-world label noise","summary":"  Label noise remains a challenge for training robust classification models.\nMost methods for mitigating label noise have been benchmarked using primarily\ndatasets with synthetic noise. While the need for datasets with realistic noise\ndistribution has partially been addressed by web-scraped benchmarks such as\nWebVision and Clothing1M, those benchmarks are restricted to the computer\nvision domain. With the growing importance of Transformer-based models, it is\ncrucial to establish text classification benchmarks for learning with noisy\nlabels. In this paper, we present AlleNoise, a new curated text classification\nbenchmark dataset with real-world instance-dependent label noise, containing\nover 500,000 examples across approximately 5,600 classes, complemented with a\nmeaningful, hierarchical taxonomy of categories. The noise distribution comes\nfrom actual users of a major e-commerce marketplace, so it realistically\nreflects the semantics of human mistakes. In addition to the noisy labels, we\nprovide human-verified clean labels, which help to get a deeper insight into\nthe noise distribution, unlike web-scraped datasets typically used in the\nfield. We demonstrate that a representative selection of established methods\nfor learning with noisy labels is inadequate to handle such real-world noise.\nIn addition, we show evidence that these algorithms do not alleviate excessive\nmemorization. As such, with AlleNoise, we set the bar high for the development\nof label noise methods that can handle real-world label noise in text\nclassification tasks. The code and dataset are available for download at\nhttps://github.com/allegro/AlleNoise.\n","authors":["Alicja Rączkowska","Aleksandra Osowska-Kurczab","Jacek Szczerbiński","Kalina Jasinska-Kobus","Klaudia Nazarko"],"pdf_url":"https://arxiv.org/pdf/2407.10992v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2404.15720v4","updated":"2024-10-23T16:12:39Z","published":"2024-04-24T08:13:02Z","title":"Annotator-Centric Active Learning for Subjective NLP Tasks","summary":"  Active Learning (AL) addresses the high costs of collecting human annotations\nby strategically annotating the most informative samples. However, for\nsubjective NLP tasks, incorporating a wide range of perspectives in the\nannotation process is crucial to capture the variability in human judgments. We\nintroduce Annotator-Centric Active Learning (ACAL), which incorporates an\nannotator selection strategy following data sampling. Our objective is\ntwo-fold: 1) to efficiently approximate the full diversity of human judgments,\nand 2) to assess model performance using annotator-centric metrics, which value\nminority and majority perspectives equally. We experiment with multiple\nannotator selection strategies across seven subjective NLP tasks, employing\nboth traditional and novel, human-centered evaluation metrics. Our findings\nindicate that ACAL improves data efficiency and excels in annotator-centric\nperformance evaluations. However, its success depends on the availability of a\nsufficiently large and diverse pool of annotators to sample from.\n","authors":["Michiel van der Meer","Neele Falk","Pradeep K. Murukannaiah","Enrico Liscio"],"pdf_url":"https://arxiv.org/pdf/2404.15720v4.pdf","comment":"Accepted at EMNLP2024"},{"id":"http://arxiv.org/abs/2410.14979v2","updated":"2024-10-23T15:43:28Z","published":"2024-10-19T05:01:56Z","title":"Do Large Language Models Truly Grasp Mathematics? An Empirical\n  Exploration","summary":"  Despite their proficiency in math tasks, the mechanisms underlying LLMs'\nmathematical reasoning abilities remain a subject of debate. Recent studies\nsuggest that chain-of-thought (CoT) prompts can bolster mathematical reasoning\nby encouraging LLMs to employ human-like logical reasoning (System 2), enabling\nthem to excel on the Cognitive Reflection Test (CRT). To assess whether LLMs\ngenuinely possess System 2-like logical reasoning, we introduced targeted\nmodifications to CRT problems. Our findings reveal that, despite the use of CoT\nprompts, mainstream LLMs, including the latest o1-preview model, continue to\nexhibit a significant error rate. Further analysis indicates that they\npredominantly rely on System 1-like intuitive reasoning and pattern matching\nderived from training data, rather than demonstrating mastery of mathematical\nthinking. This discovery challenges the prevailing notion that LLMs possess\ngenuine logical reasoning abilities and that CoT can enhance them.\nConsequently, this work may temper overly optimistic projections regarding\nLLMs' advancement toward artificial general intelligence.\n","authors":["Wei Xie","Shuoyoucheng Ma","Zhenhua Wang","Enze Wang","Baosheng Wang","Jinshu Su"],"pdf_url":"https://arxiv.org/pdf/2410.14979v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.17973v1","updated":"2024-10-23T15:37:08Z","published":"2024-10-23T15:37:08Z","title":"Together We Can: Multilingual Automatic Post-Editing for Low-Resource\n  Languages","summary":"  This exploratory study investigates the potential of multilingual Automatic\nPost-Editing (APE) systems to enhance the quality of machine translations for\nlow-resource Indo-Aryan languages. Focusing on two closely related language\npairs, English-Marathi and English-Hindi, we exploit the linguistic\nsimilarities to develop a robust multilingual APE model. To facilitate\ncross-linguistic transfer, we generate synthetic Hindi-Marathi and\nMarathi-Hindi APE triplets. Additionally, we incorporate a Quality Estimation\n(QE)-APE multi-task learning framework. While the experimental results\nunderline the complementary nature of APE and QE, we also observe that QE-APE\nmultitask learning facilitates effective domain adaptation. Our experiments\ndemonstrate that the multilingual APE models outperform their corresponding\nEnglish-Hindi and English-Marathi single-pair models by $2.5$ and $2.39$ TER\npoints, respectively, with further notable improvements over the multilingual\nAPE model observed through multi-task learning ($+1.29$ and $+1.44$ TER\npoints), data augmentation ($+0.53$ and $+0.45$ TER points) and domain\nadaptation ($+0.35$ and $+0.45$ TER points). We release the synthetic data,\ncode, and models accrued during this study publicly at\nhttps://github.com/cfiltnlp/Multilingual-APE.\n","authors":["Sourabh Deoghare","Diptesh Kanojia","Pushpak Bhattacharyya"],"pdf_url":"https://arxiv.org/pdf/2410.17973v1.pdf","comment":"Accepted at Findings of EMNLP 2024"},{"id":"http://arxiv.org/abs/2410.17972v1","updated":"2024-10-23T15:37:02Z","published":"2024-10-23T15:37:02Z","title":"Dependency Graph Parsing as Sequence Labeling","summary":"  Various linearizations have been proposed to cast syntactic dependency\nparsing as sequence labeling. However, these approaches do not support more\ncomplex graph-based representations, such as semantic dependencies or enhanced\nuniversal dependencies, as they cannot handle reentrancy or cycles. By\nextending them, we define a range of unbounded and bounded linearizations that\ncan be used to cast graph parsing as a tagging task, enlarging the toolbox of\nproblems that can be solved under this paradigm. Experimental results on\nsemantic dependency and enhanced UD parsing show that with a good choice of\nencoding, sequence-labeling dependency graph parsers combine high efficiency\nwith accuracies close to the state of the art, in spite of their simplicity.\n","authors":["Ana Ezquerro","David Vilares","Carlos Gómez-Rodríguez"],"pdf_url":"https://arxiv.org/pdf/2410.17972v1.pdf","comment":"Accepted at EMNLP-2024"},{"id":"http://arxiv.org/abs/2410.17963v1","updated":"2024-10-23T15:30:37Z","published":"2024-10-23T15:30:37Z","title":"A Time-Aware Approach to Early Detection of Anorexia: UNSL at eRisk 2024","summary":"  The eRisk laboratory aims to address issues related to early risk detection\non the Web. In this year's edition, three tasks were proposed, where Task 2 was\nabout early detection of signs of anorexia. Early risk detection is a problem\nwhere precision and speed are two crucial objectives. Our research group solved\nTask 2 by defining a CPI+DMC approach, addressing both objectives\nindependently, and a time-aware approach, where precision and speed are\nconsidered a combined single-objective. We implemented the last approach by\nexplicitly integrating time during the learning process, considering the\nERDE{\\theta} metric as the training objective. It also allowed us to\nincorporate temporal metrics to validate and select the optimal models. We\nachieved outstanding results for the ERDE50 metric and ranking-based metrics,\ndemonstrating consistency in solving ERD problems.\n","authors":["Horacio Thompson","Marcelo Errecalde"],"pdf_url":"https://arxiv.org/pdf/2410.17963v1.pdf","comment":"In Conference and Labs of the Evaluation Forum (CLEF 2024), Grenoble,\n  France"},{"id":"http://arxiv.org/abs/2410.17960v1","updated":"2024-10-23T15:28:53Z","published":"2024-10-23T15:28:53Z","title":"Zeitenwenden: Detecting changes in the German political discourse","summary":"  From a monarchy to a democracy, to a dictatorship and back to a democracy --\nthe German political landscape has been constantly changing ever since the\nfirst German national state was formed in 1871. After World War II, the Federal\nRepublic of Germany was formed in 1949. Since then every plenary session of the\nGerman Bundestag was logged and even has been digitized over the course of the\nlast few years. We analyze these texts using a time series variant of the topic\nmodel LDA to investigate which events had a lasting effect on the political\ndiscourse and how the political topics changed over time. This allows us to\ndetect changes in word frequency (and thus key discussion points) in political\ndiscourse.\n","authors":["Kai-Robin Lange","Jonas Rieger","Niklas Benner","Carsten Jentsch"],"pdf_url":"https://arxiv.org/pdf/2410.17960v1.pdf","comment":"7 pages, 6 figures"},{"id":"http://arxiv.org/abs/2201.12091v5","updated":"2024-10-23T15:28:38Z","published":"2022-01-28T13:00:17Z","title":"Linear Adversarial Concept Erasure","summary":"  Modern neural models trained on textual data rely on pre-trained\nrepresentations that emerge without direct supervision. As these\nrepresentations are increasingly being used in real-world applications, the\ninability to \\emph{control} their content becomes an increasingly important\nproblem. We formulate the problem of identifying and erasing a linear subspace\nthat corresponds to a given concept, in order to prevent linear predictors from\nrecovering the concept. We model this problem as a constrained, linear maximin\ngame, and show that existing solutions are generally not optimal for this task.\nWe derive a closed-form solution for certain objectives, and propose a convex\nrelaxation, \\method, that works well for others. When evaluated in the context\nof binary gender removal, the method recovers a low-dimensional subspace whose\nremoval mitigates bias by intrinsic and extrinsic evaluation. We show that the\nmethod is highly expressive, effectively mitigating bias in deep nonlinear\nclassifiers while maintaining tractability and interpretability.\n","authors":["Shauli Ravfogel","Michael Twiton","Yoav Goldberg","Ryan Cotterell"],"pdf_url":"https://arxiv.org/pdf/2201.12091v5.pdf","comment":"Accepted in ICML 2022; a revised version"},{"id":"http://arxiv.org/abs/2410.17954v1","updated":"2024-10-23T15:24:54Z","published":"2024-10-23T15:24:54Z","title":"ExpertFlow: Optimized Expert Activation and Token Allocation for\n  Efficient Mixture-of-Experts Inference","summary":"  Sparse Mixture of Experts (MoE) models, while outperforming dense Large\nLanguage Models (LLMs) in terms of performance, face significant deployment\nchallenges during inference due to their high memory demands. Existing\noffloading techniques, which involve swapping activated and idle experts\nbetween the GPU and CPU, often suffer from rigid expert caching mechanisms.\nThese mechanisms fail to adapt to dynamic routing, leading to inefficient cache\nutilization, or incur prohibitive costs for prediction training. To tackle\nthese inference-specific challenges, we introduce ExpertFlow, a comprehensive\nsystem specifically designed to enhance inference efficiency by accommodating\nflexible routing and enabling efficient expert scheduling between CPU and GPU.\nThis reduces overhead and boosts system performance. Central to our approach is\na predictive routing path-based offloading mechanism that utilizes a\nlightweight predictor to accurately forecast routing paths before computation\nbegins. This proactive strategy allows for real-time error correction in expert\ncaching, significantly increasing cache hit ratios and reducing the frequency\nof expert transfers, thereby minimizing I/O overhead. Additionally, we\nimplement a dynamic token scheduling strategy that optimizes MoE inference by\nrearranging input tokens across different batches. This method not only reduces\nthe number of activated experts per batch but also improves computational\nefficiency. Our extensive experiments demonstrate that ExpertFlow achieves up\nto 93.72\\% GPU memory savings and enhances inference speed by 2 to 10 times\ncompared to baseline methods, highlighting its effectiveness and utility as a\nrobust solution for resource-constrained inference scenarios.\n","authors":["Xin He","Shunkang Zhang","Yuxin Wang","Haiyan Yin","Zihao Zeng","Shaohuai Shi","Zhenheng Tang","Xiaowen Chu","Ivor Tsang","Ong Yew Soon"],"pdf_url":"https://arxiv.org/pdf/2410.17954v1.pdf","comment":"Mixture-of-Experts, Inference, Offloading"},{"id":"http://arxiv.org/abs/2410.17952v1","updated":"2024-10-23T15:24:16Z","published":"2024-10-23T15:24:16Z","title":"SimRAG: Self-Improving Retrieval-Augmented Generation for Adapting Large\n  Language Models to Specialized Domains","summary":"  Retrieval-augmented generation (RAG) enhances the question-answering (QA)\nabilities of large language models (LLMs) by integrating external knowledge.\nHowever, adapting general-purpose RAG systems to specialized fields such as\nscience and medicine poses unique challenges due to distribution shifts and\nlimited access to domain-specific data. To tackle this, we propose SimRAG, a\nself-training approach that equips the LLM with joint capabilities of question\nanswering and question generation for domain adaptation. Our method first\nfine-tunes the LLM on instruction-following, question-answering, and\nsearch-related data. Then, it prompts the same LLM to generate diverse\ndomain-relevant questions from unlabeled corpora, with an additional filtering\nstrategy to retain high-quality synthetic examples. By leveraging these\nsynthetic examples, the LLM can improve their performance on domain-specific\nRAG tasks. Experiments on 11 datasets, spanning two backbone sizes and three\ndomains, demonstrate that SimRAG outperforms baselines by 1.2\\%--8.6\\%.\n","authors":["Ran Xu","Hui Liu","Sreyashi Nag","Zhenwei Dai","Yaochen Xie","Xianfeng Tang","Chen Luo","Yang Li","Joyce C. Ho","Carl Yang","Qi He"],"pdf_url":"https://arxiv.org/pdf/2410.17952v1.pdf","comment":"Work in Progress"},{"id":"http://arxiv.org/abs/2406.12295v2","updated":"2024-10-23T15:23:00Z","published":"2024-06-18T05:59:28Z","title":"Fast and Slow Generating: An Empirical Study on Large and Small Language\n  Models Collaborative Decoding","summary":"  Large Language Models (LLMs) exhibit impressive capabilities across various\napplications but encounter substantial challenges such as high inference\nlatency, considerable training costs, and the generation of hallucinations.\nCollaborative decoding between large and small language models (SLMs) presents\na promising strategy to mitigate these issues through methods including\nspeculative decoding, contrastive decoding, and emulator or proxy fine-tuning.\nHowever, the specifics of such collaborations, particularly from a unified\nperspective, remain largely unexplored. Inspired by dual-process cognitive\ntheory, we propose a unified framework in this paper, termed Fast and Slow\nGenerating (FS-GEN). Within this framework, LLMs (sometimes along with SLMs)\nare categorized as System 2 (slow and deliberate), while independent SLMs are\ndesignated as System 1 (fast and intuitive). We provide a comprehensive\nanalysis of these collaborative methodologies, elucidating their common\nproperties and shedding light on the differential knowledge capabilities of\nSystem 2 versus System 1 through the FS-GEN framework. Our findings indicate\nthat only a small proportion of collaborative interactions (approximately less\nthan 20\\% in most instances) are necessary across various methods. These\ninteractions between System 1 and System 2 conform to a scaling law related to\nthe parameter ratios, enabling predictable collaboration. Furthermore, we\nexplore the specific conditions under which collaboration proves most\neffective, particularly from an uncertainty perspective, offering novel\ninsights that may guide future optimization efforts. Our research underscores\nthat the fundamental distinction between System 1 and System 2 lies in the\nuncertainty of next token predictions, where interventions by System 2 are\ncrucial to support System 1. Code for Reproduction:\nhttps://github.com/TsinghuaC3I/FS-GEN\n","authors":["Kaiyan Zhang","Jianyu Wang","Ning Ding","Biqing Qi","Ermo Hua","Xingtai Lv","Bowen Zhou"],"pdf_url":"https://arxiv.org/pdf/2406.12295v2.pdf","comment":"update figures and results on Pythia Series"},{"id":"http://arxiv.org/abs/2410.12018v2","updated":"2024-10-23T15:21:54Z","published":"2024-10-15T19:33:57Z","title":"LocoMotion: Learning Motion-Focused Video-Language Representations","summary":"  This paper strives for motion-focused video-language representations.\nExisting methods to learn video-language representations use spatial-focused\ndata, where identifying the objects and scene is often enough to distinguish\nthe relevant caption. We instead propose LocoMotion to learn from\nmotion-focused captions that describe the movement and temporal progression of\nlocal object motions. We achieve this by adding synthetic motions to videos and\nusing the parameters of these motions to generate corresponding captions.\nFurthermore, we propose verb-variation paraphrasing to increase the caption\nvariety and learn the link between primitive motions and high-level verbs. With\nthis, we are able to learn a motion-focused video-language representation.\nExperiments demonstrate our approach is effective for a variety of downstream\ntasks, particularly when limited data is available for fine-tuning. Code is\navailable: https://hazeldoughty.github.io/Papers/LocoMotion/\n","authors":["Hazel Doughty","Fida Mohammad Thoker","Cees G. M. Snoek"],"pdf_url":"https://arxiv.org/pdf/2410.12018v2.pdf","comment":"ACCV 2024 Oral"},{"id":"http://arxiv.org/abs/2402.04957v3","updated":"2024-10-23T15:08:57Z","published":"2024-02-07T15:40:22Z","title":"Reconfidencing LLMs from the Grouping Loss Perspective","summary":"  Large Language Models (LLMs), including ChatGPT and LLaMA, are susceptible to\ngenerating hallucinated answers in a confident tone. While efforts to elicit\nand calibrate confidence scores have proven useful, recent findings show that\ncontrolling uncertainty must go beyond calibration: predicted scores may\ndeviate significantly from the actual posterior probabilities due to the impact\nof grouping loss. In this work, we construct a new evaluation dataset derived\nfrom a knowledge base to assess confidence scores given to answers of Mistral\nand LLaMA. Experiments show that they tend to be overconfident. Further, we\nshow that they are more overconfident on some answers than others, \\emph{eg}\ndepending on the nationality of the person in the query. In\nuncertainty-quantification theory, this is grouping loss. To address this, we\npropose a solution to reconfidence LLMs, canceling not only calibration but\nalso grouping loss. The LLMs, after the reconfidencing process, indicate\nimproved confidence alignment with the accuracy of their responses.\n","authors":["Lihu Chen","Alexandre Perez-Lebel","Fabian M. Suchanek","Gaël Varoquaux"],"pdf_url":"https://arxiv.org/pdf/2402.04957v3.pdf","comment":"EMNLP 2024 Findings"},{"id":"http://arxiv.org/abs/2402.01622v4","updated":"2024-10-23T15:02:57Z","published":"2024-02-02T18:39:51Z","title":"TravelPlanner: A Benchmark for Real-World Planning with Language Agents","summary":"  Planning has been part of the core pursuit for artificial intelligence since\nits conception, but earlier AI agents mostly focused on constrained settings\nbecause many of the cognitive substrates necessary for human-level planning\nhave been lacking. Recently, language agents powered by large language models\n(LLMs) have shown interesting capabilities such as tool use and reasoning. Are\nthese language agents capable of planning in more complex settings that are out\nof the reach of prior AI agents? To advance this investigation, we propose\nTravelPlanner, a new planning benchmark that focuses on travel planning, a\ncommon real-world planning scenario. It provides a rich sandbox environment,\nvarious tools for accessing nearly four million data records, and 1,225\nmeticulously curated planning intents and reference plans. Comprehensive\nevaluations show that the current language agents are not yet capable of\nhandling such complex planning tasks-even GPT-4 only achieves a success rate of\n0.6%. Language agents struggle to stay on task, use the right tools to collect\ninformation, or keep track of multiple constraints. However, we note that the\nmere possibility for language agents to tackle such a complex problem is in\nitself non-trivial progress. TravelPlanner provides a challenging yet\nmeaningful testbed for future language agents.\n","authors":["Jian Xie","Kai Zhang","Jiangjie Chen","Tinghui Zhu","Renze Lou","Yuandong Tian","Yanghua Xiao","Yu Su"],"pdf_url":"https://arxiv.org/pdf/2402.01622v4.pdf","comment":"ICML 2024 (Spotlight)"},{"id":"http://arxiv.org/abs/2311.05876v3","updated":"2024-10-23T14:48:20Z","published":"2023-11-10T05:24:04Z","title":"Trends in Integration of Knowledge and Large Language Models: A Survey\n  and Taxonomy of Methods, Benchmarks, and Applications","summary":"  Large language models (LLMs) exhibit superior performance on various natural\nlanguage tasks, but they are susceptible to issues stemming from outdated data\nand domain-specific limitations. In order to address these challenges,\nresearchers have pursued two primary strategies, knowledge editing and\nretrieval augmentation, to enhance LLMs by incorporating external information\nfrom different aspects. Nevertheless, there is still a notable absence of a\ncomprehensive survey. In this paper, we propose a review to discuss the trends\nin integration of knowledge and large language models, including taxonomy of\nmethods, benchmarks, and applications. In addition, we conduct an in-depth\nanalysis of different methods and point out potential research directions in\nthe future. We hope this survey offers the community quick access and a\ncomprehensive overview of this research area, with the intention of inspiring\nfuture research endeavors.\n","authors":["Zhangyin Feng","Weitao Ma","Weijiang Yu","Lei Huang","Haotian Wang","Qianglong Chen","Weihua Peng","Xiaocheng Feng","Bing Qin","Ting liu"],"pdf_url":"https://arxiv.org/pdf/2311.05876v3.pdf","comment":"Work in progress; 22 pages. This work has been submitted to the IEEE\n  for possible publication"},{"id":"http://arxiv.org/abs/2408.01119v2","updated":"2024-10-23T14:37:50Z","published":"2024-08-02T09:00:03Z","title":"Task Prompt Vectors: Effective Initialization through Multi-Task\n  Soft-Prompt Transfer","summary":"  Prompt tuning is an efficient solution for training large language models\n(LLMs). However, current soft-prompt-based methods often sacrifice multi-task\nmodularity, requiring the training process to be fully or partially repeated\nfor each newly added task. While recent work on task vectors applied arithmetic\noperations on full model weights to achieve the desired multi-task performance,\na similar approach for soft-prompts is still missing. To this end, we introduce\nTask Prompt Vectors, created by element-wise difference between weights of\ntuned soft-prompts and their random initialization. Experimental results on 12\nNLU datasets show that task prompt vectors can be used in low-resource settings\nto effectively initialize prompt tuning on similar tasks. In addition, we show\nthat task prompt vectors are independent of the random initialization of prompt\ntuning on 2 different language model architectures. This allows prompt\narithmetics with the pre-trained vectors from different tasks. In this way, we\nprovide a competitive alternative to state-of-the-art baselines by arithmetic\naddition of task prompt vectors from multiple tasks.\n","authors":["Robert Belanec","Simon Ostermann","Ivan Srba","Maria Bielikova"],"pdf_url":"https://arxiv.org/pdf/2408.01119v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2307.00279v3","updated":"2024-10-23T14:33:44Z","published":"2023-07-01T09:18:24Z","title":"Let Me Teach You: Pedagogical Foundations of Feedback for Language\n  Models","summary":"  Natural Language Feedback (NLF) is an increasingly popular mechanism for\naligning Large Language Models (LLMs) to human preferences. Despite the\ndiversity of the information it can convey, NLF methods are often hand-designed\nand arbitrary, with little systematic grounding. At the same time, research in\nlearning sciences has long established several effective feedback models. In\nthis opinion piece, we compile ideas from pedagogy to introduce FELT, a\nfeedback framework for LLMs that outlines various characteristics of the\nfeedback space, and a feedback content taxonomy based on these variables,\nproviding a general mapping of the feedback space. In addition to streamlining\nNLF designs, FELT also brings out new, unexplored directions for research in\nNLF. We make our taxonomy available to the community, providing guides and\nexamples for mapping our categorizations to future research.\n","authors":["Beatriz Borges","Niket Tandon","Tanja Käser","Antoine Bosselut"],"pdf_url":"https://arxiv.org/pdf/2307.00279v3.pdf","comment":"EMNLP 2024; 9 pages, 3 figures"},{"id":"http://arxiv.org/abs/2410.17901v1","updated":"2024-10-23T14:18:25Z","published":"2024-10-23T14:18:25Z","title":"ELAICHI: Enhancing Low-resource TTS by Addressing Infrequent and\n  Low-frequency Character Bigrams","summary":"  Recent advancements in Text-to-Speech (TTS) technology have led to\nnatural-sounding speech for English, primarily due to the availability of\nlarge-scale, high-quality web data. However, many other languages lack access\nto such resources, relying instead on limited studio-quality data. This\nscarcity results in synthesized speech that often suffers from intelligibility\nissues, particularly with low-frequency character bigrams. In this paper, we\npropose three solutions to address this challenge. First, we leverage\nhigh-quality data from linguistically or geographically related languages to\nimprove TTS for the target language. Second, we utilize low-quality Automatic\nSpeech Recognition (ASR) data recorded in non-studio environments, which is\nrefined using denoising and speech enhancement models. Third, we apply\nknowledge distillation from large-scale models using synthetic data to generate\nmore robust outputs. Our experiments with Hindi demonstrate significant\nreductions in intelligibility issues, as validated by human evaluators. We\npropose this methodology as a viable alternative for languages with limited\naccess to high-quality data, enabling them to collectively benefit from shared\nresources.\n","authors":["Srija Anand","Praveen Srinivasa Varadhan","Mehak Singal","Mitesh M. Khapra"],"pdf_url":"https://arxiv.org/pdf/2410.17901v1.pdf","comment":"11 pages, 1 figure, 3 tables"},{"id":"http://arxiv.org/abs/2410.17897v1","updated":"2024-10-23T14:15:07Z","published":"2024-10-23T14:15:07Z","title":"Value Residual Learning For Alleviating Attention Concentration In\n  Transformers","summary":"  Transformers can capture long-range dependencies using self-attention,\nallowing tokens to attend to all others directly. However, stacking multiple\nattention layers leads to attention concentration. One natural way to address\nthis issue is to use cross-layer attention, allowing information from earlier\nlayers to be directly accessible to later layers. However, this approach is\ncomputationally expensive. To address this problem, we propose Transformer with\nresidual value (ResFormer) which approximates cross-layer attention through\nadding a residual connection from the values of the the first layer to all\nsubsequent layers. Based on this method, one variant is the Transformer with\nsingle layer value (SVFormer), where all layers share the same value embedding\nfrom first layer, reducing the KV cache by nearly 50%. Comprehensive empirical\nevidence demonstrates that ResFormer mitigates attention concentration problem\nin deeper layers and enhances representation across most layers, outperforming\nthe vanilla Transformer, DenseFormer, and NeuTRENO in training error as well as\ndownstream tasks. SVFormer trains significantly faster than the vanilla\nTransformer and performs better than other methods like GQA and CLA, with\nperformance influenced by sequence length and cumulative learning rate.\n","authors":["Zhanchao Zhou","Tianyi Wu","Zhiyun Jiang","Zhenzhong Lan"],"pdf_url":"https://arxiv.org/pdf/2410.17897v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.15592v2","updated":"2024-10-23T14:08:10Z","published":"2024-10-21T02:21:56Z","title":"CPE-Pro: A Structure-Sensitive Deep Learning Method for Protein\n  Representation and Origin Evaluation","summary":"  Protein structures are important for understanding their functions and\ninteractions. Currently, many protein structure prediction methods are\nenriching the structure database. Discriminating the origin of structures is\ncrucial for distinguishing between experimentally resolved and computationally\npredicted structures, evaluating the reliability of prediction methods, and\nguiding downstream biological studies. Building on works in structure\nprediction, We developed a structure-sensitive supervised deep learning model,\nCrystal vs Predicted Evaluator for Protein Structure (CPE-Pro), to represent\nand discriminate the origin of protein structures. CPE-Pro learns the\nstructural information of proteins and captures inter-structural differences to\nachieve accurate traceability on four data classes, and is expected to be\nextended to more. Simultaneously, we utilized Foldseek to encode protein\nstructures into \"structure-sequences\" and trained a protein Structural Sequence\nLanguage Model, SSLM. Preliminary experiments demonstrated that, compared to\nlarge-scale protein language models pre-trained on vast amounts of amino acid\nsequences, the \"structure-sequence\" enables the language model to learn more\ninformative protein features, enhancing and optimizing structural\nrepresentations. We have provided the code, model weights, and all related\nmaterials on https://github.com/GouWenrui/CPE-Pro-main.git.\n","authors":["Wenrui Gou","Wenhui Ge","Yang Tan","Mingchen Li","Guisheng Fan","Huiqun Yu"],"pdf_url":"https://arxiv.org/pdf/2410.15592v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.17891v1","updated":"2024-10-23T14:04:22Z","published":"2024-10-23T14:04:22Z","title":"Scaling Diffusion Language Models via Adaptation from Autoregressive\n  Models","summary":"  Diffusion Language Models (DLMs) have emerged as a promising new paradigm for\ntext generative modeling, potentially addressing limitations of autoregressive\n(AR) models. However, current DLMs have been studied at a smaller scale\ncompared to their AR counterparts and lack fair comparison on language modeling\nbenchmarks. Additionally, training diffusion models from scratch at scale\nremains challenging. Given the prevalence of open-source AR language models, we\npropose adapting these models to build text diffusion models. We demonstrate\nconnections between AR and diffusion modeling objectives and introduce a simple\ncontinual pre-training approach for training diffusion models. Through\nsystematic evaluation on language modeling, reasoning, and commonsense\nbenchmarks, we show that we can convert AR models ranging from 127M to 7B\nparameters (GPT2 and LLaMA) into diffusion models DiffuGPT and DiffuLLaMA,\nusing less than 200B tokens for training. Our experimental results reveal that\nthese models outperform earlier DLMs and are competitive with their AR\ncounterparts. We release a suite of DLMs (with 127M, 355M, and 7B parameters)\ncapable of generating fluent text, performing in-context learning, filling in\nthe middle without prompt re-ordering, and following instructions\n\\url{https://github.com/HKUNLP/DiffuLLaMA}.\n","authors":["Shansan Gong","Shivam Agarwal","Yizhe Zhang","Jiacheng Ye","Lin Zheng","Mukai Li","Chenxin An","Peilin Zhao","Wei Bi","Jiawei Han","Hao Peng","Lingpeng Kong"],"pdf_url":"https://arxiv.org/pdf/2410.17891v1.pdf","comment":"25 pages. Code: https://github.com/HKUNLP/DiffuLLaMA"},{"id":"http://arxiv.org/abs/2406.14703v2","updated":"2024-10-23T14:01:14Z","published":"2024-06-20T19:50:56Z","title":"Do LLMs Have Distinct and Consistent Personality? TRAIT: Personality\n  Testset designed for LLMs with Psychometrics","summary":"  Recent advancements in Large Language Models (LLMs) have led to their\nadaptation in various domains as conversational agents. We wonder: can\npersonality tests be applied to these agents to analyze their behavior, similar\nto humans? We introduce TRAIT, a new benchmark consisting of 8K multi-choice\nquestions designed to assess the personality of LLMs. TRAIT is built on two\npsychometrically validated small human questionnaires, Big Five Inventory (BFI)\nand Short Dark Triad (SD-3), enhanced with the ATOMIC-10X knowledge graph to a\nvariety of real-world scenarios. TRAIT also outperforms existing personality\ntests for LLMs in terms of reliability and validity, achieving the highest\nscores across four key metrics: Content Validity, Internal Validity, Refusal\nRate, and Reliability. Using TRAIT, we reveal two notable insights into\npersonalities of LLMs: 1) LLMs exhibit distinct and consistent personality,\nwhich is highly influenced by their training data (e.g., data used for\nalignment tuning), and 2) current prompting techniques have limited\neffectiveness in eliciting certain traits, such as high psychopathy or low\nconscientiousness, suggesting the need for further research in this direction.\n","authors":["Seungbeen Lee","Seungwon Lim","Seungju Han","Giyeong Oh","Hyungjoo Chae","Jiwan Chung","Minju Kim","Beong-woo Kwak","Yeonsoo Lee","Dongha Lee","Jinyoung Yeo","Youngjae Yu"],"pdf_url":"https://arxiv.org/pdf/2406.14703v2.pdf","comment":"Preprint; Under review"},{"id":"http://arxiv.org/abs/2410.17886v1","updated":"2024-10-23T14:00:48Z","published":"2024-10-23T14:00:48Z","title":"SpeakGer: A meta-data enriched speech corpus of German state and federal\n  parliaments","summary":"  The application of natural language processing on political texts as well as\nspeeches has become increasingly relevant in political sciences due to the\nability to analyze large text corpora which cannot be read by a single person.\nBut such text corpora often lack critical meta information, detailing for\ninstance the party, age or constituency of the speaker, that can be used to\nprovide an analysis tailored to more fine-grained research questions. To enable\nresearchers to answer such questions with quantitative approaches such as\nnatural language processing, we provide the SpeakGer data set, consisting of\nGerman parliament debates from all 16 federal states of Germany as well as the\nGerman Bundestag from 1947-2023, split into a total of 10,806,105 speeches.\nThis data set includes rich meta data in form of information on both reactions\nfrom the audience towards the speech as well as information about the speaker's\nparty, their age, their constituency and their party's political alignment,\nwhich enables a deeper analysis. We further provide three exploratory analyses,\ndetailing topic shares of different parties throughout time, a descriptive\nanalysis of the development of the age of an average speaker as well as a\nsentiment analysis of speeches of different parties with regards to the\nCOVID-19 pandemic.\n","authors":["Kai-Robin Lange","Carsten Jentsch"],"pdf_url":"https://arxiv.org/pdf/2410.17886v1.pdf","comment":"10 pages, 3 figures"},{"id":"http://arxiv.org/abs/2407.07799v2","updated":"2024-10-23T14:00:40Z","published":"2024-07-10T16:16:02Z","title":"Attribute or Abstain: Large Language Models as Long Document Assistants","summary":"  LLMs can help humans working with long documents, but are known to\nhallucinate. Attribution can increase trust in LLM responses: The LLM provides\nevidence that supports its response, which enhances verifiability. Existing\napproaches to attribution have only been evaluated in RAG settings, where the\ninitial retrieval confounds LLM performance. This is crucially different from\nthe long document setting, where retrieval is not needed, but could help. Thus,\na long document specific evaluation of attribution is missing. To fill this\ngap, we present LAB, a benchmark of 6 diverse long document tasks with\nattribution, and experiments with different approaches to attribution on 5 LLMs\nof different sizes.\n  We find that citation, i.e. response generation and evidence extraction in\none step, performs best for large and fine-tuned models, while additional\nretrieval can help for small, prompted models. We investigate whether the \"Lost\nin the Middle'' phenomenon exists for attribution, but do not find this. We\nalso find that evidence quality can predict response quality on datasets with\nsimple responses, but not so for complex responses, as models struggle with\nproviding evidence for complex claims.\n","authors":["Jan Buchmann","Xiao Liu","Iryna Gurevych"],"pdf_url":"https://arxiv.org/pdf/2407.07799v2.pdf","comment":"Accepted at EMNLP 2024. Code and data:\n  https://github.com/UKPLab/arxiv2024-attribute-or-abstain"},{"id":"http://arxiv.org/abs/2407.12819v2","updated":"2024-10-23T14:00:36Z","published":"2024-07-01T10:33:46Z","title":"I've Got 99 Problems But FLOPS Ain't One","summary":"  Hyperscalers dominate the landscape of large network deployments, yet they\nrarely share data or insights about the challenges they face. In light of this\nsupremacy, what problems can we find to solve in this space? We take an\nunconventional approach to find relevant research directions, starting from\npublic plans to build a $100 billion datacenter for machine learning\napplications. Leveraging the language models scaling laws, we discover what\nworkloads such a datacenter might carry and explore the challenges one may\nencounter in doing so, with a focus on networking research. We conclude that\nbuilding the datacenter and training such models is technically possible, but\nthis requires novel wide-area transports for inter-DC communication, a\nmultipath transport and novel datacenter topologies for intra-datacenter\ncommunication, high speed scale-up networks and transports, outlining a rich\nresearch agenda for the networking community.\n","authors":["Alexandru M. Gherghescu","Vlad-Andrei Bădoiu","Alexandru Agache","Mihai-Valentin Dumitru","Iuliu Vasilescu","Radu Mantu","Costin Raiciu"],"pdf_url":"https://arxiv.org/pdf/2407.12819v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.17875v1","updated":"2024-10-23T13:47:05Z","published":"2024-10-23T13:47:05Z","title":"Understanding Layer Significance in LLM Alignment","summary":"  Aligning large language models (LLMs) through fine-tuning is essential for\ntailoring them to specific applications. Therefore, understanding what LLMs\nlearn during the alignment process is crucial. Recent studies suggest that\nalignment primarily adjusts a model's presentation style rather than its\nfoundational knowledge, indicating that only certain components of the model\nare significantly impacted. To delve deeper into LLM alignment, we propose to\nidentify which layers within LLMs are most critical to the alignment process,\nthereby uncovering how alignment influences model behavior at a granular level.\nWe propose a novel approach to identify the important layers for LLM alignment\n(ILA). It involves learning a binary mask for each incremental weight matrix in\nthe LoRA algorithm, indicating the significance of each layer. ILA consistently\nidentifies important layers across various alignment datasets, with nearly 90%\noverlap even with substantial dataset differences, highlighting fundamental\npatterns in LLM alignment. Experimental results indicate that freezing\nnon-essential layers improves overall model performance, while selectively\ntuning the most critical layers significantly enhances fine-tuning efficiency\nwith minimal performance loss.\n","authors":["Guangyuan Shi","Zexin Lu","Xiaoyu Dong","Wenlong Zhang","Xuanyu Zhang","Yujie Feng","Xiao-Ming Wu"],"pdf_url":"https://arxiv.org/pdf/2410.17875v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2402.15055v2","updated":"2024-10-23T13:20:15Z","published":"2024-02-23T02:15:47Z","title":"Interpreting Context Look-ups in Transformers: Investigating\n  Attention-MLP Interactions","summary":"  Understanding the inner workings of large language models (LLMs) is crucial\nfor advancing their theoretical foundations and real-world applications. While\nthe attention mechanism and multi-layer perceptrons (MLPs) have been studied\nindependently, their interactions remain largely unexplored. This study\ninvestigates how attention heads and next-token neurons interact in LLMs to\npredict new words. We propose a methodology to identify next-token neurons,\nfind prompts that highly activate them, and determine the upstream attention\nheads responsible. We then generate and evaluate explanations for the activity\nof these attention heads in an automated manner. Our findings reveal that some\nattention heads recognize specific contexts relevant to predicting a token and\nactivate a downstream token-predicting neuron accordingly. This mechanism\nprovides a deeper understanding of how attention heads work with MLP neurons to\nperform next-token prediction. Our approach offers a foundation for further\nresearch into the intricate workings of LLMs and their impact on text\ngeneration and understanding.\n","authors":["Clement Neo","Shay B. Cohen","Fazl Barez"],"pdf_url":"https://arxiv.org/pdf/2402.15055v2.pdf","comment":"Accepted to EMNLP 2024 Main Conference"},{"id":"http://arxiv.org/abs/2403.14774v2","updated":"2024-10-23T13:01:14Z","published":"2024-03-21T18:28:43Z","title":"Few-Shot Adversarial Prompt Learning on Vision-Language Models","summary":"  The vulnerability of deep neural networks to imperceptible adversarial\nperturbations has attracted widespread attention. Inspired by the success of\nvision-language foundation models, previous efforts achieved zero-shot\nadversarial robustness by aligning adversarial visual features with text\nsupervision. However, in practice, they are still unsatisfactory due to several\nissues, including heavy adaptation cost, suboptimal text supervision, and\nuncontrolled natural generalization capacity. In this paper, to address these\nissues, we propose a few-shot adversarial prompt framework where adapting input\nsequences with limited data makes significant adversarial robustness\nimprovement. Specifically, we achieve this by providing adversarially\ncorrelated text supervision that is end-to-end learned from adversarial\nexamples. We also propose a novel training objective that enhances the\nconsistency of multi-modal features while encourages differentiated uni-modal\nfeatures between natural and adversarial examples. The proposed framework gives\naccess to learn adversarial text supervision, which provides superior\ncross-modal adversarial alignment and matches state-of-the-art zero-shot\nadversarial robustness with only 1% training data. Code is available at:\nhttps://github.com/lionel-w2/FAP.\n","authors":["Yiwei Zhou","Xiaobo Xia","Zhiwei Lin","Bo Han","Tongliang Liu"],"pdf_url":"https://arxiv.org/pdf/2403.14774v2.pdf","comment":"NeurIPS 2024"},{"id":"http://arxiv.org/abs/2410.15956v2","updated":"2024-10-23T13:00:27Z","published":"2024-10-21T12:34:17Z","title":"Do Large Language Models Have an English Accent? Evaluating and\n  Improving the Naturalness of Multilingual LLMs","summary":"  Current Large Language Models (LLMs) are predominantly designed with English\nas the primary language, and even the few that are multilingual tend to exhibit\nstrong English-centric biases. Much like speakers who might produce awkward\nexpressions when learning a second language, LLMs often generate unnatural\noutputs in non-English languages, reflecting English-centric patterns in both\nvocabulary and grammar. Despite the importance of this issue, the naturalness\nof multilingual LLM outputs has received limited attention. In this paper, we\naddress this gap by introducing novel automatic corpus-level metrics to assess\nthe lexical and syntactic naturalness of LLM outputs in a multilingual context.\nUsing our new metrics, we evaluate state-of-the-art LLMs on a curated benchmark\nin French and Chinese, revealing a tendency towards English-influenced\npatterns. To mitigate this issue, we also propose a simple and effective\nalignment method to improve the naturalness of an LLM in a target language and\ndomain, achieving consistent improvements in naturalness without compromising\nthe performance on general-purpose benchmarks. Our work highlights the\nimportance of developing multilingual metrics, resources and methods for the\nnew wave of multilingual LLMs.\n","authors":["Yanzhu Guo","Simone Conia","Zelin Zhou","Min Li","Saloni Potdar","Henry Xiao"],"pdf_url":"https://arxiv.org/pdf/2410.15956v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.16845v2","updated":"2024-10-23T12:53:00Z","published":"2024-06-24T17:49:28Z","title":"RaTEScore: A Metric for Radiology Report Generation","summary":"  This paper introduces a novel, entity-aware metric, termed as Radiological\nReport (Text) Evaluation (RaTEScore), to assess the quality of medical reports\ngenerated by AI models. RaTEScore emphasizes crucial medical entities such as\ndiagnostic outcomes and anatomical details, and is robust against complex\nmedical synonyms and sensitive to negation expressions. Technically, we\ndeveloped a comprehensive medical NER dataset, RaTE-NER, and trained an NER\nmodel specifically for this purpose. This model enables the decomposition of\ncomplex radiological reports into constituent medical entities. The metric\nitself is derived by comparing the similarity of entity embeddings, obtained\nfrom a language model, based on their types and relevance to clinical\nsignificance. Our evaluations demonstrate that RaTEScore aligns more closely\nwith human preference than existing metrics, validated both on established\npublic benchmarks and our newly proposed RaTE-Eval benchmark.\n","authors":["Weike Zhao","Chaoyi Wu","Xiaoman Zhang","Ya Zhang","Yanfeng Wang","Weidi Xie"],"pdf_url":"https://arxiv.org/pdf/2406.16845v2.pdf","comment":"EMNLP 2024"},{"id":"http://arxiv.org/abs/2410.06022v2","updated":"2024-10-23T12:49:32Z","published":"2024-10-08T13:23:58Z","title":"Can Language Models Induce Grammatical Knowledge from Indirect Evidence?","summary":"  What kinds of and how much data is necessary for language models to induce\ngrammatical knowledge to judge sentence acceptability? Recent language models\nstill have much room for improvement in their data efficiency compared to\nhumans. This paper investigates whether language models efficiently use\nindirect data (indirect evidence), from which they infer sentence\nacceptability. In contrast, humans use indirect evidence efficiently, which is\nconsidered one of the inductive biases contributing to efficient language\nacquisition. To explore this question, we introduce the Wug InDirect Evidence\nTest (WIDET), a dataset consisting of training instances inserted into the\npre-training data and evaluation instances. We inject synthetic instances with\nnewly coined wug words into pretraining data and explore the model's behavior\non evaluation data that assesses grammatical acceptability regarding those\nwords. We prepare the injected instances by varying their levels of\nindirectness and quantity. Our experiments surprisingly show that language\nmodels do not induce grammatical knowledge even after repeated exposure to\ninstances with the same structure but differing only in lexical items from\nevaluation instances in certain language phenomena. Our findings suggest a\npotential direction for future research: developing models that use latent\nindirect evidence to induce grammatical knowledge.\n","authors":["Miyu Oba","Yohei Oseki","Akiyo Fukatsu","Akari Haga","Hiroki Ouchi","Taro Watanabe","Saku Sugawara"],"pdf_url":"https://arxiv.org/pdf/2410.06022v2.pdf","comment":"This paper is accepted at EMNLP 2024 Main"},{"id":"http://arxiv.org/abs/2410.17820v1","updated":"2024-10-23T12:26:10Z","published":"2024-10-23T12:26:10Z","title":"Understanding When Tree of Thoughts Succeeds: Larger Models Excel in\n  Generation, Not Discrimination","summary":"  Tree of Thoughts (ToT) is a reasoning strategy for Large Language Models\n(LLMs) that employs a generator to suggest reasoning steps and a discriminator\nto decide which steps to implement. ToT demonstrates strong performance on\nreasoning tasks, often surpassing simple methods such as Input-Output (IO)\nprompting and Chain-of-Thought (CoT) reasoning. However, ToT does not\nconsistently outperform such simpler methods across all models, leaving large\nknowledge gaps on the conditions under which ToT is most beneficial. In this\npaper, we analyze the roles of the generator and discriminator separately to\nbetter understand the conditions when ToT is beneficial. We find that the\ngenerator plays a more critical role than the discriminator in driving the\nsuccess of ToT. While using even a smaller model as the discriminator, scaling\nthe generator leads to notable improvements in ToT performance, whereas scaling\nthe discriminator with a fixed generator yields only marginal gains. Our\nresults show that models across different scales exhibit comparable\ndiscrimination capabilities, yet differ significantly in their generative\nperformance for ToT.\n","authors":["Qiqi Chen","Xinpeng Wang","Philipp Mondorf","Michael A. Hedderich","Barbara Plank"],"pdf_url":"https://arxiv.org/pdf/2410.17820v1.pdf","comment":"Code: github.com/mainlp/tot-eval"},{"id":"http://arxiv.org/abs/2410.17799v1","updated":"2024-10-23T11:58:58Z","published":"2024-10-23T11:58:58Z","title":"OmniFlatten: An End-to-end GPT Model for Seamless Voice Conversation","summary":"  Full-duplex spoken dialogue systems significantly advance over traditional\nturn-based dialogue systems, as they allow simultaneous bidirectional\ncommunication, closely mirroring human-human interactions. However, achieving\nlow latency and natural interactions in full-duplex dialogue systems remains a\nsignificant challenge, especially considering human conversation dynamics such\nas interruptions, backchannels, and overlapping speech. In this paper, we\nintroduce a novel End-to-End GPT-based model OmniFlatten for full-duplex\nconversation, capable of effectively modeling the complex behaviors inherent to\nnatural conversations with low latency. To achieve full-duplex communication\ncapabilities, we propose a multi-stage post-training scheme that progressively\nadapts a text-based large language model (LLM) backbone into a speech-text\ndialogue LLM, capable of generating text and speech in real time, without\nmodifying the architecture of the backbone LLM. The training process comprises\nthree stages: modality alignment, half-duplex dialogue learning, and\nfull-duplex dialogue learning. Throughout all training stages, we standardize\nthe data using a flattening operation, which allows us to unify the training\nmethods and the model architecture across different modalities and tasks. Our\napproach offers a straightforward modeling technique and a promising research\ndirection for developing efficient and natural end-to-end full-duplex spoken\ndialogue systems. Audio samples of dialogues generated by OmniFlatten can be\nfound at this web site (https://omniflatten.github.io/).\n","authors":["Qinglin Zhang","Luyao Cheng","Chong Deng","Qian Chen","Wen Wang","Siqi Zheng","Jiaqing Liu","Hai Yu","Chaohong Tan"],"pdf_url":"https://arxiv.org/pdf/2410.17799v1.pdf","comment":"Work in progress"},{"id":"http://arxiv.org/abs/2406.05804v4","updated":"2024-10-23T11:36:57Z","published":"2024-06-09T14:42:55Z","title":"A Review of Prominent Paradigms for LLM-Based Agents: Tool Use\n  (Including RAG), Planning, and Feedback Learning","summary":"  Tool use, planning, and feedback learning are currently three prominent\nparadigms for developing Large Language Model (LLM)-based agents across various\ntasks. Although numerous frameworks have been devised for each paradigm, their\nintricate workflows and inconsistent taxonomy create challenges in\nunderstanding and reviewing the frameworks across different paradigms. This\nsurvey introduces a unified taxonomy to systematically review and discuss these\nframeworks. Specifically, 1) the taxonomy defines environments/tasks, common\nLLM-profiled roles or LMPRs (policy models, evaluators, and dynamic models),\nand universally applicable workflows found in prior work, and 2) it enables a\ncomparison of key perspectives on the implementations of LMPRs and workflow\ndesigns across different agent paradigms and frameworks. 3) Finally, we\nidentify three limitations in existing workflow designs and systematically\ndiscuss the future work.\n","authors":["Xinzhe Li"],"pdf_url":"https://arxiv.org/pdf/2406.05804v4.pdf","comment":"Under Review"},{"id":"http://arxiv.org/abs/2410.17783v1","updated":"2024-10-23T11:32:46Z","published":"2024-10-23T11:32:46Z","title":"Leveraging the Domain Adaptation of Retrieval Augmented Generation\n  Models for Question Answering and Reducing Hallucination","summary":"  While ongoing advancements in Large Language Models have demonstrated\nremarkable success across various NLP tasks, Retrieval Augmented Generation\nModel stands out to be highly effective on downstream applications like\nQuestion Answering. Recently, RAG-end2end model further optimized the\narchitecture and achieved notable performance improvements on domain\nadaptation. However, the effectiveness of these RAG-based architectures remains\nrelatively unexplored when fine-tuned on specialized domains such as customer\nservice for building a reliable conversational AI system. Furthermore, a\ncritical challenge persists in reducing the occurrence of hallucinations while\nmaintaining high domain-specific accuracy. In this paper, we investigated the\nperformance of diverse RAG and RAG-like architectures through domain adaptation\nand evaluated their ability to generate accurate and relevant response grounded\nin the contextual knowledge base. To facilitate the evaluation of the models,\nwe constructed a novel dataset HotelConvQA, sourced from wide range of\nhotel-related conversations and fine-tuned all the models on our domain\nspecific dataset. We also addressed a critical research gap on determining the\nimpact of domain adaptation on reducing hallucinations across different RAG\narchitectures, an aspect that was not properly measured in prior work. Our\nevaluation shows positive results in all metrics by employing domain\nadaptation, demonstrating strong performance on QA tasks and providing insights\ninto their efficacy in reducing hallucinations. Our findings clearly indicate\nthat domain adaptation not only enhances the models' performance on QA tasks\nbut also significantly reduces hallucination across all evaluated RAG\narchitectures.\n","authors":["Salman Rakin","Md. A. R. Shibly","Zahin M. Hossain","Zeeshan Khan","Md. Mostofa Akbar"],"pdf_url":"https://arxiv.org/pdf/2410.17783v1.pdf","comment":"Initial Version fine-tuned on HotelConvQA"},{"id":"http://arxiv.org/abs/2404.19232v7","updated":"2024-10-23T11:19:02Z","published":"2024-04-30T03:29:30Z","title":"GRAMMAR: Grounded and Modular Methodology for Assessment of\n  Closed-Domain Retrieval-Augmented Language Model","summary":"  Retrieval-Augmented Generation (RAG) systems are widely used across various\nindustries for querying closed-domain and in-house knowledge bases. However,\nevaluating these systems presents significant challenges due to the private\nnature of closed-domain data and a scarcity of queries with verifiable ground\ntruths. Moreover, there is a lack of analytical methods to diagnose problematic\nmodules and identify types of failure, such as those caused by knowledge\ndeficits or issues with robustness. To address these challenges, we introduce\nGRAMMAR (GRounded And Modular Methodology for Assessment of RAG), an evaluation\nframework comprising a grounded data generation process and an evaluation\nprotocol that effectively pinpoints defective modules. Our validation\nexperiments reveal that GRAMMAR provides a reliable approach for identifying\nvulnerable modules and supports hypothesis testing for textual form\nvulnerabilities. An open-source tool accompanying this framework is available\nin our GitHub repository (see https://github.com/xinzhel/grammar), allowing for\neasy reproduction of our results and enabling reliable and modular evaluation\nin closed-domain settings.\n","authors":["Xinzhe Li","Ming Liu","Shang Gao"],"pdf_url":"https://arxiv.org/pdf/2404.19232v7.pdf","comment":"Under Review"},{"id":"http://arxiv.org/abs/2410.16144v2","updated":"2024-10-23T11:17:42Z","published":"2024-10-21T16:14:57Z","title":"1-bit AI Infra: Part 1.1, Fast and Lossless BitNet b1.58 Inference on\n  CPUs","summary":"  Recent advances in 1-bit Large Language Models (LLMs), such as BitNet and\nBitNet b1.58, present a promising approach to enhancing the efficiency of LLMs\nin terms of speed and energy consumption. These developments also enable local\nLLM deployment across a broad range of devices. In this work, we introduce\nbitnet.cpp, a tailored software stack designed to unlock the full potential of\n1-bit LLMs. Specifically, we develop a set of kernels to support fast and\nlossless inference of ternary BitNet b1.58 LLMs on CPUs. Extensive experiments\ndemonstrate that bitnet.cpp achieves significant speedups, ranging from 2.37x\nto 6.17x on x86 CPUs and from 1.37x to 5.07x on ARM CPUs, across various model\nsizes. The code is available at https://github.com/microsoft/BitNet.\n","authors":["Jinheng Wang","Hansong Zhou","Ting Song","Shaoguang Mao","Shuming Ma","Hongyu Wang","Yan Xia","Furu Wei"],"pdf_url":"https://arxiv.org/pdf/2410.16144v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.17759v1","updated":"2024-10-23T10:50:40Z","published":"2024-10-23T10:50:40Z","title":"Latent Structures of Intertextuality in French Fiction","summary":"  Intertextuality is a key concept in literary theory that challenges\ntraditional notions of text, signification or authorship. It views texts as\npart of a vast intertextual network that is constantly evolving and being\nreconfigured. This paper argues that the field of computational literary\nstudies is the ideal place to conduct a study of intertextuality since we have\nnow the ability to systematically compare texts with each others. Specifically,\nwe present a work on a corpus of more than 12.000 French fictions from the\n18th, 19th and early 20th century. We focus on evaluating the underlying roles\nof two literary notions, sub-genres and the literary canon in the framing of\ntextuality. The article attempts to operationalize intertextuality using\nstate-of-the-art contextual language models to encode novels and capture\nfeatures that go beyond simple lexical or thematic approaches. Previous\nresearch (Hughes, 2012) supports the existence of a literary \"style of a time\",\nand our findings further reinforce this concept. Our findings also suggest that\nboth subgenres and canonicity play a significant role in shaping textual\nsimilarities within French fiction. These discoveries point to the importance\nof considering genre and canon as dynamic forces that influence the evolution\nand intertextual connections of literary works within specific historical\ncontexts.\n","authors":["Jean Barré"],"pdf_url":"https://arxiv.org/pdf/2410.17759v1.pdf","comment":"13 pages, 6 figures. Computational Humanities Research Conference\n  2024"},{"id":"http://arxiv.org/abs/2410.17739v1","updated":"2024-10-23T10:12:35Z","published":"2024-10-23T10:12:35Z","title":"Local Contrastive Editing of Gender Stereotypes","summary":"  Stereotypical bias encoded in language models (LMs) poses a threat to safe\nlanguage technology, yet our understanding of how bias manifests in the\nparameters of LMs remains incomplete. We introduce local contrastive editing\nthat enables the localization and editing of a subset of weights in a target\nmodel in relation to a reference model. We deploy this approach to identify and\nmodify subsets of weights that are associated with gender stereotypes in LMs.\nThrough a series of experiments, we demonstrate that local contrastive editing\ncan precisely localize and control a small subset (< 0.5%) of weights that\nencode gender bias. Our work (i) advances our understanding of how\nstereotypical biases can manifest in the parameter space of LMs and (ii) opens\nup new avenues for developing parameter-efficient strategies for controlling\nmodel properties in a contrastive manner.\n","authors":["Marlene Lutz","Rochelle Choenni","Markus Strohmaier","Anne Lauscher"],"pdf_url":"https://arxiv.org/pdf/2410.17739v1.pdf","comment":"Accepted at EMNLP 2024"},{"id":"http://arxiv.org/abs/2410.17736v1","updated":"2024-10-23T10:11:40Z","published":"2024-10-23T10:11:40Z","title":"MojoBench: Language Modeling and Benchmarks for Mojo","summary":"  The recently introduced Mojo programming language (PL) by Modular, has\nreceived significant attention in the scientific community due to its claimed\nsignificant speed boost over Python. Despite advancements in code Large\nLanguage Models (LLMs) across various PLs, Mojo remains unexplored in this\ncontext. To address this gap, we introduce MojoBench, the first framework for\nMojo code generation. MojoBench includes HumanEval-Mojo, a benchmark dataset\ndesigned for evaluating code LLMs on Mojo, and Mojo-Coder, the first LLM\npretrained and finetuned for Mojo code generation, which supports instructions\nin 5 natural languages (NLs). Our results show that Mojo-Coder achieves a\n30-35% performance improvement over leading models like GPT-4o and\nClaude-3.5-Sonnet. Furthermore, we provide insights into LLM behavior with\nunderrepresented and unseen PLs, offering potential strategies for enhancing\nmodel adaptability. MojoBench contributes to our understanding of LLM\ncapabilities and limitations in emerging programming paradigms fostering more\nrobust code generation systems.\n","authors":["Nishat Raihan","Joanna C. S. Santos","Marcos Zampieri"],"pdf_url":"https://arxiv.org/pdf/2410.17736v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2402.14622v2","updated":"2024-10-23T10:06:10Z","published":"2024-02-22T15:10:45Z","title":"From Keywords to Structured Summaries: Streamlining Scholarly\n  Information Access","summary":"  This paper highlights the growing importance of information retrieval (IR)\nengines in the scientific community, addressing the inefficiency of traditional\nkeyword-based search engines due to the rising volume of publications. The\nproposed solution involves structured records, underpinning advanced\ninformation technology (IT) tools, including visualization dashboards, to\nrevolutionize how researchers access and filter articles, replacing the\ntraditional text-heavy approach. This vision is exemplified through a proof of\nconcept centered on the \"reproductive number estimate of infectious diseases\"\nresearch theme, using a fine-tuned large language model (LLM) to automate the\ncreation of structured records to populate a backend database that now goes\nbeyond keywords. The result is a next-generation information access system as\nan IR method accessible at https://orkg.org/usecases/r0-estimates.\n","authors":["Mahsa Shamsabadi","Jennifer D'Souza"],"pdf_url":"https://arxiv.org/pdf/2402.14622v2.pdf","comment":"8 pages, 3 figures | Accepted for publication as a poster paper at\n  the International Semantic Web Conference (ISWC 2024)"},{"id":"http://arxiv.org/abs/2410.17728v1","updated":"2024-10-23T10:00:23Z","published":"2024-10-23T10:00:23Z","title":"Dialectal and Low Resource Machine Translation for Aromanian","summary":"  We present a neural machine translation system that can translate between\nRomanian, English, and Aromanian (an endangered Eastern Romance language); the\nfirst of its kind. BLEU scores range from 17 to 32 depending on the direction\nand genre of the text. Alongside, we release the biggest known\nAromanian-Romanian bilingual corpus, consisting of 79k cleaned sentence pairs.\nAdditional tools such as an agnostic sentence embedder (used for both text\nmining and automatic evaluation) and a diacritics converter are also presented.\nWe publicly release our findings and models. Finally, we describe the\ndeployment of our quantized model at https://arotranslate.com.\n","authors":["Alexandru-Iulius Jerpelea","Alina-Ştefania Rădoi","Sergiu Nisioi"],"pdf_url":"https://arxiv.org/pdf/2410.17728v1.pdf","comment":"16 pages, 3 figures, 6 tables, submitted to COLING 2025"},{"id":"http://arxiv.org/abs/2406.14282v3","updated":"2024-10-23T09:42:59Z","published":"2024-06-20T13:07:38Z","title":"Learning to Plan for Retrieval-Augmented Large Language Models from\n  Knowledge Graphs","summary":"  Improving the performance of large language models (LLMs) in complex\nquestion-answering (QA) scenarios has always been a research focal point.\nRecent studies have attempted to enhance LLMs' performance by combining\nstep-wise planning with external retrieval. While effective for advanced models\nlike GPT-3.5, smaller LLMs face challenges in decomposing complex questions,\nnecessitating supervised fine-tuning. Previous work has relied on manual\nannotation and knowledge distillation from teacher LLMs, which are\ntime-consuming and not accurate enough. In this paper, we introduce a novel\nframework for enhancing LLMs' planning capabilities by using planning data\nderived from knowledge graphs (KGs). LLMs fine-tuned with this data have\nimproved planning capabilities, better equipping them to handle complex QA\ntasks that involve retrieval. Evaluations on multiple datasets, including our\nnewly proposed benchmark, highlight the effectiveness of our framework and the\nbenefits of KG-derived planning data.\n","authors":["Junjie Wang","Mingyang Chen","Binbin Hu","Dan Yang","Ziqi Liu","Yue Shen","Peng Wei","Zhiqiang Zhang","Jinjie Gu","Jun Zhou","Jeff Z. Pan","Wen Zhang","Huajun Chen"],"pdf_url":"https://arxiv.org/pdf/2406.14282v3.pdf","comment":"EMNLP2024 Findings"},{"id":"http://arxiv.org/abs/2410.17714v1","updated":"2024-10-23T09:40:15Z","published":"2024-10-23T09:40:15Z","title":"CogSteer: Cognition-Inspired Selective Layer Intervention for Efficient\n  Semantic Steering in Large Language Models","summary":"  Despite their impressive capabilities, large language models (LLMs) often\nlack interpretability and can generate toxic content. While using LLMs as\nfoundation models and applying semantic steering methods are widely practiced,\nwe believe that efficient methods should be based on a thorough understanding\nof LLM behavior. To this end, we propose using eye movement measures to\ninterpret LLM behavior across layers. We find that LLMs exhibit patterns\nsimilar to human gaze across layers and different layers function differently.\nInspired by these findings, we introduce a heuristic steering layer selection\nand apply it to layer intervention methods via fine-tuning and inference. Using\nlanguage toxification and detoxification as test beds, we demonstrate that our\nproposed CogSteer methods achieve better results in terms of toxicity scores\nwhile efficiently saving 97% of the computational resources and 60% of the\ntraining time. Our model-agnostic approach can be adopted into various LLMs,\ncontributing to their interpretability and promoting trustworthiness for safe\ndeployment.\n","authors":["Xintong Wang","Jingheng Pan","Longqin Jiang","Liang Ding","Xingshan Li","Chris Biemann"],"pdf_url":"https://arxiv.org/pdf/2410.17714v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.17711v1","updated":"2024-10-23T09:36:21Z","published":"2024-10-23T09:36:21Z","title":"Beware of Calibration Data for Pruning Large Language Models","summary":"  As large language models (LLMs) are widely applied across various fields,\nmodel compression has become increasingly crucial for reducing costs and\nimproving inference efficiency. Post-training pruning is a promising method\nthat does not require resource-intensive iterative training and only needs a\nsmall amount of calibration data to assess the importance of parameters.\nPrevious research has primarily focused on designing advanced pruning methods,\nwhile different calibration data's impact on pruning performance still lacks\nsystematical exploration. We fill this blank and surprisingly observe that the\neffects of calibration data even value more than designing advanced pruning\nstrategies, especially for high sparsity. Our preliminary exploration also\ndiscloses that using calibration data similar to the training data can yield\nbetter performance. As pre-training data is usually inaccessible for advanced\nLLMs, we further provide a self-generating calibration data synthesis strategy\nto construct feasible calibration data. We conduct experiments on the recent\nstrong open-source LLMs (e.g., DCLM, and LLaMA-3), and the results show that\nthe proposed method outperforms commonly used calibration data and can\neffectively enhance strong pruning methods (e.g., Wanda, OWL).\n","authors":["Yixin Ji","Yang Xiang","Juntao Li","Qingrong Xia","Ping Li","Xinyu Duan","Zhefeng Wang","Min Zhang"],"pdf_url":"https://arxiv.org/pdf/2410.17711v1.pdf","comment":"under review"},{"id":"http://arxiv.org/abs/2410.17694v1","updated":"2024-10-23T09:14:57Z","published":"2024-10-23T09:14:57Z","title":"An Adaptive Framework for Generating Systematic Explanatory Answer in\n  Online Q&A Platforms","summary":"  Question Answering (QA) systems face challenges in handling complex questions\nthat require multi-domain knowledge synthesis. The naive RAG models, although\neffective in information retrieval, struggle with complex questions that\nrequire comprehensive and in-depth answers. The pioneering task is defined as\nexplanatory answer generation, which entails handling identified challenges\nsuch as the requirement for comprehensive information and logical coherence\nwithin the generated context. To address these issues, we refer to systematic\nthinking theory and propose SynthRAG, an innovative framework designed to\nenhance QA performance. SynthRAG improves on conventional models by employing\nadaptive outlines for dynamic content structuring, generating systematic\ninformation to ensure detailed coverage, and producing customized answers\ntailored to specific user inquiries. This structured approach guarantees\nlogical coherence and thorough integration of information, yielding responses\nthat are both insightful and methodically organized. Empirical evaluations\nunderscore SynthRAG's effectiveness, demonstrating its superiority in handling\ncomplex questions, overcoming the limitations of naive RAG models, and\nsignificantly improving answer quality and depth. Furthermore, an online\ndeployment on the Zhihu platform revealed that SynthRAG's answers achieved\nnotable user engagement, with each response averaging 5.73 upvotes and\nsurpassing the performance of 79.8% of human contributors, highlighting the\npractical relevance and impact of the proposed framework. Our code is available\nat https://github.com/czy1999/SynthRAG .\n","authors":["Ziyang Chen","Xiaobin Wang","Yong Jiang","Jinzhi Liao","Pengjun Xie","Fei Huang","Xiang Zhao"],"pdf_url":"https://arxiv.org/pdf/2410.17694v1.pdf","comment":"10 pages, 6 figures"},{"id":"http://arxiv.org/abs/2410.17676v1","updated":"2024-10-23T08:49:51Z","published":"2024-10-23T08:49:51Z","title":"Towards a Similarity-adjusted Surprisal Theory","summary":"  Surprisal theory posits that the cognitive effort required to comprehend a\nword is determined by its contextual predictability, quantified as surprisal.\nTraditionally, surprisal theory treats words as distinct entities, overlooking\nany potential similarity between them. Giulianelli et al. (2023) address this\nlimitation by introducing information value, a measure of predictability\ndesigned to account for similarities between communicative units. Our work\nleverages Ricotta and Szeidl's (2006) diversity index to extend surprisal into\na metric that we term similarity-adjusted surprisal, exposing a mathematical\nrelationship between surprisal and information value. Similarity-adjusted\nsurprisal aligns with information value when considering graded similarities\nand reduces to standard surprisal when words are treated as distinct.\nExperimental results with reading time data indicate that similarity-adjusted\nsurprisal adds predictive power beyond standard surprisal for certain datasets,\nsuggesting it serves as a complementary measure of comprehension effort.\n","authors":["Clara Meister","Mario Giulianelli","Tiago Pimentel"],"pdf_url":"https://arxiv.org/pdf/2410.17676v1.pdf","comment":"EMNLP 2024 main conference proceedings"},{"id":"http://arxiv.org/abs/2410.17670v1","updated":"2024-10-23T08:42:36Z","published":"2024-10-23T08:42:36Z","title":"Quantifying the Risks of Tool-assisted Rephrasing to Linguistic\n  Diversity","summary":"  Writing assistants and large language models see widespread use in the\ncreation of text content. While their effectiveness for individual users has\nbeen evaluated in the literature, little is known about their proclivity to\nchange language or reduce its richness when adopted by a large user base. In\nthis paper, we take a first step towards quantifying this risk by measuring the\nsemantic and vocabulary change enacted by the use of rephrasing tools on a\nmulti-domain corpus of human-generated text.\n","authors":["Mengying Wang","Andreas Spitz"],"pdf_url":"https://arxiv.org/pdf/2410.17670v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2404.15993v4","updated":"2024-10-23T08:33:54Z","published":"2024-04-24T17:10:35Z","title":"Uncertainty Estimation and Quantification for LLMs: A Simple Supervised\n  Approach","summary":"  In this paper, we study the problem of uncertainty estimation and calibration\nfor LLMs. We begin by formulating the uncertainty estimation problem, a\nrelevant yet underexplored area in existing literature. We then propose a\nsupervised approach that leverages labeled datasets to estimate the uncertainty\nin LLMs' responses. Based on the formulation, we illustrate the difference\nbetween the uncertainty estimation for LLMs and that for standard ML models and\nexplain why the hidden neurons of the LLMs may contain uncertainty information.\nOur designed approach demonstrates the benefits of utilizing hidden activations\nto enhance uncertainty estimation across various tasks and shows robust\ntransferability in out-of-distribution settings. We distinguish the uncertainty\nestimation task from the uncertainty calibration task and show that better\nuncertainty estimation leads to better calibration performance. Furthermore,\nour method is easy to implement and adaptable to different levels of model\naccessibility including black box, grey box, and white box.\n","authors":["Linyu Liu","Yu Pan","Xiaocheng Li","Guanting Chen"],"pdf_url":"https://arxiv.org/pdf/2404.15993v4.pdf","comment":"29 pages, 14 figures"},{"id":"http://arxiv.org/abs/2406.10216v2","updated":"2024-10-23T08:22:44Z","published":"2024-06-14T17:49:59Z","title":"Regularizing Hidden States Enables Learning Generalizable Reward Model\n  for LLMs","summary":"  Reward models trained on human preference data have been proven to\neffectively align Large Language Models (LLMs) with human intent within the\nframework of reinforcement learning from human feedback (RLHF). However,\ncurrent reward models have limited generalization capabilities to unseen\nprompts and responses, which can lead to an unexpected phenomenon known as\nreward over-optimization, resulting in a decline in actual performance due to\nexcessive optimization of rewards. While previous research has advocated for\nconstraining policy optimization, our study introduces a novel approach to\nenhance the reward model's generalization ability against distribution shifts\nby regularizing the hidden states. Specifically, we retain the base model's\nlanguage model head and incorporate a suite of text-generation losses to\npreserve the hidden states' text-generation capabilities, while concurrently\nlearning a reward head behind the same hidden states. Our experimental results\ndemonstrate that the introduced regularization technique markedly improves the\naccuracy of learned reward models across a variety of out-of-distribution (OOD)\ntasks and effectively alleviates the over-optimization issue in RLHF, offering\na more reliable and robust preference learning paradigm.\n","authors":["Rui Yang","Ruomeng Ding","Yong Lin","Huan Zhang","Tong Zhang"],"pdf_url":"https://arxiv.org/pdf/2406.10216v2.pdf","comment":"NeurIPS 2024"},{"id":"http://arxiv.org/abs/2410.17657v1","updated":"2024-10-23T08:19:18Z","published":"2024-10-23T08:19:18Z","title":"ReflecTool: Towards Reflection-Aware Tool-Augmented Clinical Agents","summary":"  Large Language Models (LLMs) have shown promising potential in the medical\ndomain, assisting with tasks like clinical note generation and patient\ncommunication. However, current LLMs are limited to text-based communication,\nhindering their ability to interact with diverse forms of information in\nclinical environments. Despite clinical agents succeeding in diverse signal\ninteraction, they are oriented to a single clinical scenario and hence fail for\nbroader applications. To evaluate clinical agents holistically, we propose\nClinicalAgent Bench~(CAB), a comprehensive medical agent benchmark consisting\nof 18 tasks across five key realistic clinical dimensions. Building on this, we\nintroduce ReflecTool, a novel framework that excels at utilizing\ndomain-specific tools within two stages. The first optimization stage\nprogressively enlarges a long-term memory by saving successful solving\nprocesses and tool-wise experience of agents in a tiny pre-defined training\nset. In the following inference stage, ReflecTool can search for supportive\nsuccessful demonstrations from already built long-term memory to guide the tool\nselection strategy, and a verifier improves the tool usage according to the\ntool-wise experience with two verification methods--iterative refinement and\ncandidate selection. Extensive experiments on ClinicalAgent Benchmark\ndemonstrate that ReflecTool surpasses the pure LLMs with more than 10 points\nand the well-established agent-based methods with 3 points, highlighting its\nadaptability and effectiveness in solving complex clinical tasks.\n","authors":["Yusheng Liao","Shuyang Jiang","Yanfeng Wang","Yu Wang"],"pdf_url":"https://arxiv.org/pdf/2410.17657v1.pdf","comment":"20 pages"},{"id":"http://arxiv.org/abs/2410.17635v1","updated":"2024-10-23T07:53:29Z","published":"2024-10-23T07:53:29Z","title":"Markov Chain of Thought for Efficient Mathematical Reasoning","summary":"  Chain of Thought (CoT) of multi-step benefits from the logical structure of\nthe reasoning steps and task-specific actions, significantly enhancing the\nmathematical reasoning capabilities of large language models. As the prevalence\nof long CoT, the number of reasoning steps exceeds manageable token limits and\nleads to higher computational demands. Inspired by the fundamental logic of\nhuman cognition, ``derive, then reduce'', we conceptualize the standard\nmulti-step CoT as a novel Markov Chain of Thought (MCoT). In this study, we\nconsider the mathematical reasoning task, defining each reasoning step as text\naccompanied by a Python code snippet. To facilitate a longer reasoning path,\nself-correction is enabled through interactions with the code interpreter. Our\nMCoT aims to compress previous reasoning steps into a simplified question,\nenabling efficient next-step inference without relying on a lengthy KV cache.\nIn our experiments, we curate the \\texttt{MCoTInstruct} dataset, and the\nempirical results indicate that MCoT not only significantly enhances efficiency\nbut also maintains comparable accuracy. While much remains to be explored, this\nwork paves the way for exploring the long CoT reasoning abilities of LLMs.\n","authors":["Wen Yang","Kai Fan","Minpeng Liao"],"pdf_url":"https://arxiv.org/pdf/2410.17635v1.pdf","comment":"Work in progress"},{"id":"http://arxiv.org/abs/2410.17632v1","updated":"2024-10-23T07:48:51Z","published":"2024-10-23T07:48:51Z","title":"LMLPA: Language Model Linguistic Personality Assessment","summary":"  Large Language Models (LLMs) are increasingly used in everyday life and\nresearch. One of the most common use cases is conversational interactions,\nenabled by the language generation capabilities of LLMs. Just as between two\nhumans, a conversation between an LLM-powered entity and a human depends on the\npersonality of the conversants. However, measuring the personality of a given\nLLM is currently a challenge. This paper introduces the Language Model\nLinguistic Personality Assessment (LMLPA), a system designed to evaluate the\nlinguistic personalities of LLMs. Our system helps to understand LLMs' language\ngeneration capabilities by quantitatively assessing the distinct personality\ntraits reflected in their linguistic outputs. Unlike traditional human-centric\npsychometrics, the LMLPA adapts a personality assessment questionnaire,\nspecifically the Big Five Inventory, to align with the operational capabilities\nof LLMs, and also incorporates the findings from previous language-based\npersonality measurement literature. To mitigate sensitivity to the order of\noptions, our questionnaire is designed to be open-ended, resulting in textual\nanswers. Thus, the AI rater is needed to transform ambiguous personality\ninformation from text responses into clear numerical indicators of personality\ntraits. Utilising Principal Component Analysis and reliability validations, our\nfindings demonstrate that LLMs possess distinct personality traits that can be\neffectively quantified by the LMLPA. This research contributes to\nHuman-Computer Interaction and Human-Centered AI, providing a robust framework\nfor future studies to refine AI personality assessments and expand their\napplications in multiple areas, including education and manufacturing.\n","authors":["Jingyao Zheng","Xian Wang","Simo Hosio","Xiaoxian Xu","Lik-Hang Lee"],"pdf_url":"https://arxiv.org/pdf/2410.17632v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2404.03622v3","updated":"2024-10-23T07:20:26Z","published":"2024-04-04T17:45:08Z","title":"Mind's Eye of LLMs: Visualization-of-Thought Elicits Spatial Reasoning\n  in Large Language Models","summary":"  Large language models (LLMs) have exhibited impressive performance in\nlanguage comprehension and various reasoning tasks. However, their abilities in\nspatial reasoning, a crucial aspect of human cognition, remain relatively\nunexplored. Human possess a remarkable ability to create mental images of\nunseen objects and actions through a process known as the Mind's Eye, enabling\nthe imagination of the unseen world. Inspired by this cognitive capacity, we\npropose Visualization-of-Thought (VoT) prompting. VoT aims to elicit spatial\nreasoning of LLMs by visualizing their reasoning traces, thereby guiding\nsubsequent reasoning steps. We employed VoT for multi-hop spatial reasoning\ntasks, including natural language navigation, visual navigation, and visual\ntiling in 2D grid worlds. Experimental results demonstrated that VoT\nsignificantly enhances the spatial reasoning abilities of LLMs. Notably, VoT\noutperformed existing multimodal large language models (MLLMs) in these tasks.\nWhile VoT works surprisingly well on LLMs, the ability to generate mental\nimages to facilitate spatial reasoning resembles the mind's eye process,\nsuggesting its potential viability in MLLMs. Please find the dataset and codes\nat https://microsoft.github.io/visualization-of-thought\n","authors":["Wenshan Wu","Shaoguang Mao","Yadong Zhang","Yan Xia","Li Dong","Lei Cui","Furu Wei"],"pdf_url":"https://arxiv.org/pdf/2404.03622v3.pdf","comment":"38th Conference on Neural Information Processing Systems (NeurIPS\n  2024)"},{"id":"http://arxiv.org/abs/2305.12987v3","updated":"2024-10-23T07:13:49Z","published":"2023-05-22T12:47:48Z","title":"GPT-SW3: An Autoregressive Language Model for the Nordic Languages","summary":"  This paper details the process of developing the first native large\ngenerative language model for the Nordic languages, GPT-SW3. We cover all parts\nof the development process, from data collection and processing, training\nconfiguration and instruction finetuning, to evaluation and considerations for\nrelease strategies. We hope that this paper can serve as a guide and reference\nfor other researchers that undertake the development of large generative models\nfor smaller languages.\n","authors":["Ariel Ekgren","Amaru Cuba Gyllensten","Felix Stollenwerk","Joey Öhman","Tim Isbister","Evangelia Gogoulou","Fredrik Carlsson","Alice Heiman","Judit Casademont","Magnus Sahlgren"],"pdf_url":"https://arxiv.org/pdf/2305.12987v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.17600v1","updated":"2024-10-23T06:54:03Z","published":"2024-10-23T06:54:03Z","title":"Graphusion: A RAG Framework for Knowledge Graph Construction with a\n  Global Perspective","summary":"  Knowledge Graphs (KGs) are crucial in the field of artificial intelligence\nand are widely used in downstream tasks, such as question-answering (QA). The\nconstruction of KGs typically requires significant effort from domain experts.\nLarge Language Models (LLMs) have recently been used for Knowledge Graph\nConstruction (KGC). However, most existing approaches focus on a local\nperspective, extracting knowledge triplets from individual sentences or\ndocuments, missing a fusion process to combine the knowledge in a global KG.\nThis work introduces Graphusion, a zero-shot KGC framework from free text. It\ncontains three steps: in Step 1, we extract a list of seed entities using topic\nmodeling to guide the final KG includes the most relevant entities; in Step 2,\nwe conduct candidate triplet extraction using LLMs; in Step 3, we design the\nnovel fusion module that provides a global view of the extracted knowledge,\nincorporating entity merging, conflict resolution, and novel triplet discovery.\nResults show that Graphusion achieves scores of 2.92 and 2.37 out of 3 for\nentity extraction and relation recognition, respectively. Moreover, we showcase\nhow Graphusion could be applied to the Natural Language Processing (NLP) domain\nand validate it in an educational scenario. Specifically, we introduce TutorQA,\na new expert-verified benchmark for QA, comprising six tasks and a total of\n1,200 QA pairs. Using the Graphusion-constructed KG, we achieve a significant\nimprovement on the benchmark, for example, a 9.2% accuracy improvement on\nsub-graph completion.\n","authors":["Rui Yang","Boming Yang","Aosong Feng","Sixun Ouyang","Moritz Blum","Tianwei She","Yuang Jiang","Freddy Lecue","Jinghui Lu","Irene Li"],"pdf_url":"https://arxiv.org/pdf/2410.17600v1.pdf","comment":"arXiv admin note: substantial text overlap with arXiv:2407.10794"},{"id":"http://arxiv.org/abs/2410.17599v1","updated":"2024-10-23T06:52:09Z","published":"2024-10-23T06:52:09Z","title":"Cross-model Control: Improving Multiple Large Language Models in\n  One-time Training","summary":"  The number of large language models (LLMs) with varying parameter scales and\nvocabularies is increasing. While they deliver powerful performance, they also\nface a set of common optimization needs to meet specific requirements or\nstandards, such as instruction following or avoiding the output of sensitive\ninformation from the real world. However, how to reuse the fine-tuning outcomes\nof one model to other models to reduce training costs remains a challenge. To\nbridge this gap, we introduce Cross-model Control (CMC), a method that improves\nmultiple LLMs in one-time training with a portable tiny language model.\nSpecifically, we have observed that the logit shift before and after\nfine-tuning is remarkably similar across different models. Based on this\ninsight, we incorporate a tiny language model with a minimal number of\nparameters. By training alongside a frozen template LLM, the tiny model gains\nthe capability to alter the logits output by the LLMs. To make this tiny\nlanguage model applicable to models with different vocabularies, we propose a\nnovel token mapping strategy named PM-MinED. We have conducted extensive\nexperiments on instruction tuning and unlearning tasks, demonstrating the\neffectiveness of CMC. Our code is available at https://github.com/wujwyi/CMC.\n","authors":["Jiayi Wu","Hao Sun","Hengyi Cai","Lixin Su","Shuaiqiang Wang","Dawei Yin","Xiang Li","Ming Gao"],"pdf_url":"https://arxiv.org/pdf/2410.17599v1.pdf","comment":"Accepted by NeurIPS 2024"},{"id":"http://arxiv.org/abs/2402.12617v2","updated":"2024-10-23T06:28:19Z","published":"2024-02-20T00:51:05Z","title":"Generative AI Security: Challenges and Countermeasures","summary":"  Generative AI's expanding footprint across numerous industries has led to\nboth excitement and increased scrutiny. This paper delves into the unique\nsecurity challenges posed by Generative AI, and outlines potential research\ndirections for managing these risks.\n","authors":["Banghua Zhu","Norman Mu","Jiantao Jiao","David Wagner"],"pdf_url":"https://arxiv.org/pdf/2402.12617v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.15573v2","updated":"2024-10-23T06:21:09Z","published":"2024-10-21T01:36:42Z","title":"OpenMU: Your Swiss Army Knife for Music Understanding","summary":"  We present OpenMU-Bench, a large-scale benchmark suite for addressing the\ndata scarcity issue in training multimodal language models to understand music.\nTo construct OpenMU-Bench, we leveraged existing datasets and bootstrapped new\nannotations. OpenMU-Bench also broadens the scope of music understanding by\nincluding lyrics understanding and music tool usage. Using OpenMU-Bench, we\ntrained our music understanding model, OpenMU, with extensive ablations,\ndemonstrating that OpenMU outperforms baseline models such as MU-Llama. Both\nOpenMU and OpenMU-Bench are open-sourced to facilitate future research in music\nunderstanding and to enhance creative music production efficiency.\n","authors":["Mengjie Zhao","Zhi Zhong","Zhuoyuan Mao","Shiqi Yang","Wei-Hsiang Liao","Shusuke Takahashi","Hiromi Wakaki","Yuki Mitsufuji"],"pdf_url":"https://arxiv.org/pdf/2410.15573v2.pdf","comment":"Resources: https://github.com/mzhaojp22/openmu"},{"id":"http://arxiv.org/abs/2410.17578v1","updated":"2024-10-23T06:04:55Z","published":"2024-10-23T06:04:55Z","title":"MM-Eval: A Multilingual Meta-Evaluation Benchmark for LLM-as-a-Judge and\n  Reward Models","summary":"  Large language models (LLMs) are commonly used as evaluators in tasks (e.g.,\nreward modeling, LLM-as-a-judge), where they act as proxies for human\npreferences or judgments. This leads to the need for meta-evaluation:\nevaluating the credibility of LLMs as evaluators. However, existing benchmarks\nprimarily focus on English, offering limited insight into LLMs' effectiveness\nas evaluators in non-English contexts. To address this, we introduce MM-Eval, a\nmultilingual meta-evaluation benchmark that covers 18 languages across six\ncategories. MM-Eval evaluates various dimensions, including language-specific\nchallenges like linguistics and language hallucinations. Evaluation results\nshow that both proprietary and open-source language models have considerable\nroom for improvement. Further analysis reveals a tendency for these models to\nassign middle-ground scores to low-resource languages. We publicly release our\nbenchmark and code.\n","authors":["Guijin Son","Dongkeun Yoon","Juyoung Suk","Javier Aula-Blasco","Mano Aslan","Vu Trong Kim","Shayekh Bin Islam","Jaume Prats-Cristià","Lucía Tormo-Bañuelos","Seungone Kim"],"pdf_url":"https://arxiv.org/pdf/2410.17578v1.pdf","comment":"work in progress"},{"id":"http://arxiv.org/abs/2410.17566v1","updated":"2024-10-23T05:19:51Z","published":"2024-10-23T05:19:51Z","title":"Differentially Private Learning Needs Better Model Initialization and\n  Self-Distillation","summary":"  Differentially private SGD (DPSGD) enables privacy-preserving training of\nlanguage models, but often reduces utility, diversity, and linguistic quality.\nWe introduce DPRefine, a three-phase method that initializes a model using data\nsynthesis from a small pre-trained LM with rigorous filtering, applies DP\nfinetuning on private data, and performs self-distillation to refine outputs.\nThis approach significantly outperforms vanilla DPSGD, with AlpacaEval\npreferring DPRefine's generations in 78.4% of cases across all datasets. Our\nanalysis reveals that DPRefine reduces linguistic errors in generated text by\n84.0%, mitigating grammar and spelling errors, commonly associated with DPSGD.\nIt also reduces inconsistencies of non-private models, such as hallucinated\ndetails and misattributed quotes. We find that small models like GPT-2 can be\neffective for initialization and distillation, highlighting their potential in\nenabling scalable and efficient deployment of privacy-preserving language.\n","authors":["Ivoline C. Ngong","Joseph P. Near","Niloofar Mireshghallah"],"pdf_url":"https://arxiv.org/pdf/2410.17566v1.pdf","comment":"18 pages"},{"id":"http://arxiv.org/abs/2402.14146v2","updated":"2024-10-23T04:39:25Z","published":"2024-02-21T22:02:37Z","title":"Reinforcement Learning with Dynamic Multi-Reward Weighting for\n  Multi-Style Controllable Generation","summary":"  Textual style expresses a diverse set of information, including interpersonal\ndynamics (e.g., formality) and the author's emotions or attitudes (e.g.,\ndisgust). An open question is how language models can be explicitly controlled\nso that they weave together target styles when generating text: for example, to\nproduce text that is both negative and non-toxic. One approach to such\ncontrolled generation is multi-objective reinforcement learning (RL), but how\nbest to combine multiple objectives in a reward function is an open question.\nIn this paper, we investigate various formulations of multi-style rewards,\nincluding calibrated outputs from discriminators and dynamic weighting by\ndiscriminator gradient magnitudes. We find that our proposed dynamic weighting\noutperforms static weighting approaches with respect to style control while\nmaintaining linguistic quality, and we explore its effectiveness in 2- and\n3-style control.\n","authors":["Karin de Langis","Ryan Koo","Dongyeop Kang"],"pdf_url":"https://arxiv.org/pdf/2402.14146v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.17552v1","updated":"2024-10-23T04:34:49Z","published":"2024-10-23T04:34:49Z","title":"ESpeW: Robust Copyright Protection for LLM-based EaaS via\n  Embedding-Specific Watermark","summary":"  Embeddings as a Service (EaaS) is emerging as a crucial role in AI\napplications. Unfortunately, EaaS is vulnerable to model extraction attacks,\nhighlighting the urgent need for copyright protection.Although some preliminary\nworks propose applying embedding watermarks to protect EaaS, recent research\nreveals that these watermarks can be easily removed. Hence, it is crucial to\ninject robust watermarks resistant to watermark removal attacks.Existing\nwatermarking methods typically inject a target embedding into embeddings\nthrough linear interpolation when the text contains triggers. However, this\nmechanism results in each watermarked embedding having the same component,\nwhich makes the watermark easy to identify and eliminate.Motivated by this, in\nthis paper, we propose a novel embedding-specific watermarking (ESpeW)\nmechanism to offer robust copyright protection for EaaS. Our approach involves\ninjecting unique, yet readily identifiable watermarks into each embedding.\nWatermarks inserted by ESpeW are designed to maintain a significant distance\nfrom one another and to avoid sharing common components, thus making it\nsignificantly more challenging to remove the watermarks.Extensive experiments\non four popular datasets demonstrate that ESpeW can even watermark successfully\nagainst a highly aggressive removal strategy without sacrificing the quality of\nembeddings.\n","authors":["Zongqi Wang","Baoyuan Wu","Jingyuan Deng","Yujiu Yang"],"pdf_url":"https://arxiv.org/pdf/2410.17552v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.17546v1","updated":"2024-10-23T03:53:46Z","published":"2024-10-23T03:53:46Z","title":"ProtoLens: Advancing Prototype Learning for Fine-Grained\n  Interpretability in Text Classification","summary":"  Deep neural networks have achieved remarkable performance in various\ntext-based tasks but often lack interpretability, making them less suitable for\napplications where transparency is critical. To address this, we propose\nProtoLens, a novel prototype-based model that provides fine-grained,\nsub-sentence level interpretability for text classification. ProtoLens uses a\nPrototype-aware Span Extraction module to identify relevant text spans\nassociated with learned prototypes and a Prototype Alignment mechanism to\nensure prototypes are semantically meaningful throughout training. By aligning\nthe prototype embeddings with human-understandable examples, ProtoLens provides\ninterpretable predictions while maintaining competitive accuracy. Extensive\nexperiments demonstrate that ProtoLens outperforms both prototype-based and\nnon-interpretable baselines on multiple text classification benchmarks. Code\nand data are available at\n\\url{https://anonymous.4open.science/r/ProtoLens-CE0B/}.\n","authors":["Bowen Wei","Ziwei Zhu"],"pdf_url":"https://arxiv.org/pdf/2410.17546v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.17532v1","updated":"2024-10-23T03:19:15Z","published":"2024-10-23T03:19:15Z","title":"Responsible Multilingual Large Language Models: A Survey of Development,\n  Applications, and Societal Impact","summary":"  Multilingual Large Language Models (MLLMs) represent a pivotal advancement in\ndemocratizing artificial intelligence across linguistic boundaries. While\ntheoretical foundations are well-established, practical implementation\nguidelines remain scattered. This work bridges this gap by providing a\ncomprehensive end-to-end framework for developing and deploying MLLMs in\nproduction environments. We make three distinctive contributions: First, we\npresent an actionable pipeline from data pre-processing through deployment,\nintegrating insights from academic research and industrial applications.\nSecond, using Llama2 as a case study, we provide detailed optimization\nstrategies for enhancing multilingual capabilities, including curriculum\nlearning approaches for balancing high-resource and low-resource languages,\ntokenization strategies, and effective sampling methods. Third, we offer an\ninterdisciplinary analysis that considers technical, linguistic, and cultural\nperspectives in MLLM development. Our findings reveal critical challenges in\nsupporting linguistic diversity, with 88.38% of world languages categorized as\nlow-resource, affecting over a billion speakers. We examine practical solutions\nthrough real-world applications in customer service, search engines, and\nmachine translation. By synthesizing theoretical frameworks with\nproduction-ready implementation strategies, this survey provides essential\nguidance for practitioners and researchers working to develop more inclusive\nand effective multilingual AI systems.\n","authors":["Junhua Liu","Bin Fu"],"pdf_url":"https://arxiv.org/pdf/2410.17532v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.17529v1","updated":"2024-10-23T03:14:07Z","published":"2024-10-23T03:14:07Z","title":"Navigate Complex Physical Worlds via Geometrically Constrained LLM","summary":"  This study investigates the potential of Large Language Models (LLMs) for\nreconstructing and constructing the physical world solely based on textual\nknowledge. It explores the impact of model performance on spatial understanding\nabilities. To enhance the comprehension of geometric and spatial relationships\nin the complex physical world, the study introduces a set of geometric\nconventions and develops a workflow based on multi-layer graphs and multi-agent\nsystem frameworks. It examines how LLMs achieve multi-step and multi-objective\ngeometric inference in a spatial environment using multi-layer graphs under\nunified geometric conventions. Additionally, the study employs a genetic\nalgorithm, inspired by large-scale model knowledge, to solve geometric\nconstraint problems. In summary, this work innovatively explores the\nfeasibility of using text-based LLMs as physical world builders and designs a\nworkflow to enhance their capabilities.\n","authors":["Yongqiang Huang","Wentao Ye","Liyao Li","Junbo Zhao"],"pdf_url":"https://arxiv.org/pdf/2410.17529v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.14687v2","updated":"2024-10-23T03:05:37Z","published":"2024-10-03T14:17:43Z","title":"BrainTransformers: SNN-LLM","summary":"  This study introduces BrainTransformers, an innovative Large Language Model\n(LLM) implemented using Spiking Neural Networks (SNN). Our key contributions\ninclude: (1) designing SNN-compatible Transformer components such as SNNMatmul,\nSNNSoftmax, and SNNSiLU; (2) implementing an SNN approximation of the SiLU\nactivation function; and (3) developing a Synapsis module to simulate synaptic\nplasticity. Our 3-billion parameter model, BrainTransformers-3B-Chat,\ndemonstrates competitive performance across various benchmarks, including MMLU\n(63.2), BBH (54.1), ARC-C (54.3), and GSM8K (76.3), while potentially offering\nimproved energy efficiency and biological plausibility. The model employs a\nthree-stage training approach, including SNN-specific neuronal synaptic\nplasticity training. This research opens new avenues for brain-like AI systems\nin natural language processing and neuromorphic computing. Future work will\nfocus on hardware optimization, developing specialized SNN fine-tuning tools,\nand exploring practical applications in energy-efficient computing\nenvironments.\n","authors":["Zhengzheng Tang","Eva Zhu"],"pdf_url":"https://arxiv.org/pdf/2410.14687v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.11303v2","updated":"2024-10-23T03:00:41Z","published":"2024-10-15T05:54:17Z","title":"TSDS: Data Selection for Task-Specific Model Finetuning","summary":"  Finetuning foundation models for specific tasks is an emerging paradigm in\nmodern machine learning. The efficacy of task-specific finetuning largely\ndepends on the selection of appropriate training data. We present TSDS\n(Task-Specific Data Selection), a framework to select data for task-specific\nmodel finetuning, guided by a small but representative set of examples from the\ntarget task. To do so, we formulate data selection for task-specific finetuning\nas an optimization problem with a distribution alignment loss based on optimal\ntransport to capture the discrepancy between the selected data and the target\ndistribution. In addition, we add a regularizer to encourage the diversity of\nthe selected data and incorporate kernel density estimation into the\nregularizer to reduce the negative effects of near-duplicates among the\ncandidate data. We connect our optimization problem to nearest neighbor search\nand design efficient algorithms to compute the optimal solution based on\napproximate nearest neighbor search techniques. We evaluate our method on data\nselection for both continued pretraining and instruction tuning of language\nmodels. We show that instruction tuning using data selected by our method with\na 1% selection ratio often outperforms using the full dataset and beats the\nbaseline selection methods by 1.5 points in F1 score on average.\n","authors":["Zifan Liu","Amin Karbasi","Theodoros Rekatsinas"],"pdf_url":"https://arxiv.org/pdf/2410.11303v2.pdf","comment":"31 pages, 1 figure"},{"id":"http://arxiv.org/abs/2406.18925v3","updated":"2024-10-23T02:57:31Z","published":"2024-06-27T06:32:56Z","title":"Selective Vision is the Challenge for Visual Reasoning: A Benchmark for\n  Visual Argument Understanding","summary":"  Visual arguments, often used in advertising or social causes, rely on images\nto persuade viewers to do or believe something. Understanding these arguments\nrequires selective vision: only specific visual stimuli within an image are\nrelevant to the argument, and relevance can only be understood within the\ncontext of a broader argumentative structure. While visual arguments are\nreadily appreciated by human audiences, we ask: are today's AI capable of\nsimilar understanding? We present VisArgs, a dataset of 1,611 images annotated\nwith 5,112 visual premises (with regions), 5,574 commonsense premises, and\nreasoning trees connecting them into structured arguments. We propose three\ntasks for evaluating visual argument understanding: premise localization,\npremise identification, and conclusion deduction. Experiments show that 1)\nmachines struggle to capture visual cues: GPT-4-O achieved 78.5% accuracy,\nwhile humans reached 98.0%. Models also performed 19.5% worse when\ndistinguishing between irrelevant objects within the image compared to external\nobjects. 2) Providing relevant visual premises improved model performance\nsignificantly.\n","authors":["Jiwan Chung","Sungjae Lee","Minseo Kim","Seungju Han","Ashkan Yousefpour","Jack Hessel","Youngjae Yu"],"pdf_url":"https://arxiv.org/pdf/2406.18925v3.pdf","comment":"12 pages, 6 figures. Accepted as main paper in EMNLP 2024"},{"id":"http://arxiv.org/abs/2410.17520v1","updated":"2024-10-23T02:51:43Z","published":"2024-10-23T02:51:43Z","title":"MobileSafetyBench: Evaluating Safety of Autonomous Agents in Mobile\n  Device Control","summary":"  Autonomous agents powered by large language models (LLMs) show promising\npotential in assistive tasks across various domains, including mobile device\ncontrol. As these agents interact directly with personal information and device\nsettings, ensuring their safe and reliable behavior is crucial to prevent\nundesirable outcomes. However, no benchmark exists for standardized evaluation\nof the safety of mobile device-control agents. In this work, we introduce\nMobileSafetyBench, a benchmark designed to evaluate the safety of\ndevice-control agents within a realistic mobile environment based on Android\nemulators. We develop a diverse set of tasks involving interactions with\nvarious mobile applications, including messaging and banking applications. To\nclearly evaluate safety apart from general capabilities, we design separate\ntasks measuring safety and tasks evaluating helpfulness. The safety tasks\nchallenge agents with managing potential risks prevalent in daily life and\ninclude tests to evaluate robustness against indirect prompt injections. Our\nexperiments demonstrate that while baseline agents, based on state-of-the-art\nLLMs, perform well in executing helpful tasks, they show poor performance in\nsafety tasks. To mitigate these safety concerns, we propose a prompting method\nthat encourages agents to prioritize safety considerations. While this method\nshows promise in promoting safer behaviors, there is still considerable room\nfor improvement to fully earn user trust. This highlights the urgent need for\ncontinued research to develop more robust safety mechanisms in mobile\nenvironments. We open-source our benchmark at:\nhttps://mobilesafetybench.github.io/.\n","authors":["Juyong Lee","Dongyoon Hahm","June Suk Choi","W. Bradley Knox","Kimin Lee"],"pdf_url":"https://arxiv.org/pdf/2410.17520v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.17519v1","updated":"2024-10-23T02:51:33Z","published":"2024-10-23T02:51:33Z","title":"Large Language Models Still Exhibit Bias in Long Text","summary":"  Existing fairness benchmarks for large language models (LLMs) primarily focus\non simple tasks, such as multiple-choice questions, overlooking biases that may\narise in more complex scenarios like long-text generation. To address this gap,\nwe introduce the Long Text Fairness Test (LTF-TEST), a framework that evaluates\nbiases in LLMs through essay-style prompts. LTF-TEST covers 14 topics and 10\ndemographic axes, including gender and race, resulting in 11,948 samples. By\nassessing both model responses and the reasoning behind them, LTF-TEST uncovers\nsubtle biases that are difficult to detect in simple responses. In our\nevaluation of five recent LLMs, including GPT-4o and LLaMa3, we identify two\nkey patterns of bias. First, these models frequently favor certain demographic\ngroups in their responses. Second, they show excessive sensitivity toward\ntraditionally disadvantaged groups, often providing overly protective responses\nwhile neglecting others. To mitigate these biases, we propose FT-REGARD, a\nfinetuning approach that pairs biased prompts with neutral responses. FT-REGARD\nreduces gender bias by 34.6% and improves performance by 1.4 percentage points\non the BBQ benchmark, offering a promising approach to addressing biases in\nlong-text generation tasks.\n","authors":["Wonje Jeung","Dongjae Jeon","Ashkan Yousefpour","Jonghyun Choi"],"pdf_url":"https://arxiv.org/pdf/2410.17519v1.pdf","comment":"22 page, 38 figures, Neurips (SoLaR Workshop)"},{"id":"http://arxiv.org/abs/2410.13334v2","updated":"2024-10-23T02:15:52Z","published":"2024-10-17T08:46:09Z","title":"Do LLMs Have Political Correctness? Analyzing Ethical Biases and\n  Jailbreak Vulnerabilities in AI Systems","summary":"  Although large language models (LLMs) demonstrate impressive proficiency in\nvarious tasks, they present potential safety risks, such as `jailbreaks', where\nmalicious inputs can coerce LLMs into generating harmful content. To address\nthese issues, many LLM developers have implemented various safety measures to\nalign these models. This alignment involves several techniques, including data\nfiltering during pre-training, supervised fine-tuning, reinforcement learning\nfrom human feedback, and red-teaming exercises. These methods often introduce\ndeliberate and intentional biases similar to Political Correctness (PC) to\nensure the ethical behavior of LLMs. In this paper, we delve into the\nintentional biases injected into LLMs for safety purposes and examine methods\nto circumvent these safety alignment techniques. Notably, these intentional\nbiases result in a jailbreaking success rate in GPT-4o models that differs by\n20% between non-binary and cisgender keywords and by 16% between white and\nblack keywords, even when the other parts of the prompts are identical. We\nintroduce the concept of PCJailbreak, highlighting the inherent risks posed by\nthese safety-induced biases. Additionally, we propose an efficient defense\nmethod PCDefense, which prevents jailbreak attempts by injecting defense\nprompts prior to generation. PCDefense stands as an appealing alternative to\nGuard Models, such as Llama-Guard, that require additional inference cost after\ntext generation. Our findings emphasize the urgent need for LLM developers to\nadopt a more responsible approach when designing and implementing safety\nmeasures.\n","authors":["Isack Lee","Haebin Seong"],"pdf_url":"https://arxiv.org/pdf/2410.13334v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2404.03881v4","updated":"2024-10-23T01:39:31Z","published":"2024-04-05T04:04:23Z","title":"A Bi-consolidating Model for Joint Relational Triple Extraction","summary":"  Current methods to extract relational triples directly make a prediction\nbased on a possible entity pair in a raw sentence without depending on entity\nrecognition. The task suffers from a serious semantic overlapping problem, in\nwhich several relation triples may share one or two entities in a sentence. In\nthis paper, based on a two-dimensional sentence representation, a\nbi-consolidating model is proposed to address this problem by simultaneously\nreinforcing the local and global semantic features relevant to a relation\ntriple. This model consists of a local consolidation component and a global\nconsolidation component. The first component uses a pixel difference\nconvolution to enhance semantic information of a possible triple representation\nfrom adjacent regions and mitigate noise in neighbouring neighbours. The second\ncomponent strengthens the triple representation based a channel attention and a\nspatial attention, which has the advantage to learn remote semantic\ndependencies in a sentence. They are helpful to improve the performance of both\nentity identification and relation type classification in relation triple\nextraction. After evaluated on several publish datasets, the bi-consolidating\nmodel achieves competitive performance. Analytical experiments demonstrate the\neffectiveness of our model for relational triple extraction and give motivation\nfor other natural language processing tasks.\n","authors":["Xiaocheng Luo","Yanping Chen","Ruixue Tang","Caiwei Yang","Ruizhang Huang","Yongbin Qin"],"pdf_url":"https://arxiv.org/pdf/2404.03881v4.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.17498v1","updated":"2024-10-23T01:38:10Z","published":"2024-10-23T01:38:10Z","title":"Mechanisms of Symbol Processing for In-Context Learning in Transformer\n  Networks","summary":"  Large Language Models (LLMs) have demonstrated impressive abilities in symbol\nprocessing through in-context learning (ICL). This success flies in the face of\ndecades of predictions that artificial neural networks cannot master abstract\nsymbol manipulation. We seek to understand the mechanisms that can enable\nrobust symbol processing in transformer networks, illuminating both the\nunanticipated success, and the significant limitations, of transformers in\nsymbol processing. Borrowing insights from symbolic AI on the power of\nProduction System architectures, we develop a high-level language, PSL, that\nallows us to write symbolic programs to do complex, abstract symbol processing,\nand create compilers that precisely implement PSL programs in transformer\nnetworks which are, by construction, 100% mechanistically interpretable. We\ndemonstrate that PSL is Turing Universal, so the work can inform the\nunderstanding of transformer ICL in general. The type of transformer\narchitecture that we compile from PSL programs suggests a number of paths for\nenhancing transformers' capabilities at symbol processing. (Note: The first\nsection of the paper gives an extended synopsis of the entire paper.)\n","authors":["Paul Smolensky","Roland Fernandez","Zhenghao Herbert Zhou","Mattia Opper","Jianfeng Gao"],"pdf_url":"https://arxiv.org/pdf/2410.17498v1.pdf","comment":"101 pages (including 30 pages of Appendices), 18 figures"},{"id":"http://arxiv.org/abs/2410.17492v1","updated":"2024-10-23T01:14:54Z","published":"2024-10-23T01:14:54Z","title":"BadFair: Backdoored Fairness Attacks with Group-conditioned Triggers","summary":"  Attacking fairness is crucial because compromised models can introduce biased\noutcomes, undermining trust and amplifying inequalities in sensitive\napplications like hiring, healthcare, and law enforcement. This highlights the\nurgent need to understand how fairness mechanisms can be exploited and to\ndevelop defenses that ensure both fairness and robustness. We introduce\nBadFair, a novel backdoored fairness attack methodology. BadFair stealthily\ncrafts a model that operates with accuracy and fairness under regular\nconditions but, when activated by certain triggers, discriminates and produces\nincorrect results for specific groups. This type of attack is particularly\nstealthy and dangerous, as it circumvents existing fairness detection methods,\nmaintaining an appearance of fairness in normal use. Our findings reveal that\nBadFair achieves a more than 85% attack success rate in attacks aimed at target\ngroups on average while only incurring a minimal accuracy loss. Moreover, it\nconsistently exhibits a significant discrimination score, distinguishing\nbetween pre-defined target and non-target attacked groups across various\ndatasets and models.\n","authors":["Jiaqi Xue","Qian Lou","Mengxin Zheng"],"pdf_url":"https://arxiv.org/pdf/2410.17492v1.pdf","comment":"Accepted by EMNLP 2024"},{"id":"http://arxiv.org/abs/2402.10601v2","updated":"2024-10-23T00:38:14Z","published":"2024-02-16T11:37:05Z","title":"When \"Competency\" in Reasoning Opens the Door to Vulnerability:\n  Jailbreaking LLMs via Novel Complex Ciphers","summary":"  Recent advancements in the safety of Large Language Models (LLMs) have\nprimarily focused on mitigating attacks crafted in natural language or in\ncommon encryption techniques like Base64. However, new models which often\npossess better reasoning capabilities, open the door to new attack vectors that\nwere previously non-existent in older models. This seems counter-intuitive at\nfirst glance, but these advanced models can decipher more complex cryptic\nqueries that previous models could not, making them susceptible to attacks\nusing such prompts. To exploit this vulnerability, we propose Attacks using\nCustom Encryptions (ACE), a novel method to jailbreak LLMs by leveraging custom\nencryption schemes. We evaluate the effectiveness of ACE on four\nstate-of-the-art LLMs, achieving Attack Success Rates (ASR) of up to 66% on\nclose-source models and 88% on open-source models. Building upon this, we\nintroduce Layered Attacks using Custom Encryptions (LACE), which employs\nmultiple layers of encryption through our custom ciphers to further enhance the\nASR. Our findings demonstrate that LACE significantly enhances the ability to\njailbreak LLMs, increasing the ASR of GPT-4o from 40% to 78%, a 38%\nimprovement. Our results highlight that the advanced capabilities of LLMs\nintroduce unforeseen vulnerabilities to complex attacks. Specifically complex\nand layered ciphers increase the chance of jailbreaking.\n","authors":["Divij Handa","Zehua Zhang","Amir Saeidi","Chitta Baral"],"pdf_url":"https://arxiv.org/pdf/2402.10601v2.pdf","comment":"14 pages, 7 figures"},{"id":"http://arxiv.org/abs/2410.17485v1","updated":"2024-10-23T00:36:06Z","published":"2024-10-23T00:36:06Z","title":"VoiceTextBlender: Augmenting Large Language Models with Speech\n  Capabilities via Single-Stage Joint Speech-Text Supervised Fine-Tuning","summary":"  Recent studies have augmented large language models (LLMs) with speech\ncapabilities, leading to the development of speech language models (SpeechLMs).\nEarlier SpeechLMs focused on single-turn speech-based question answering (QA),\nwhere user input comprised a speech context and a text question. More recent\nstudies have extended this to multi-turn conversations, though they often\nrequire complex, multi-stage supervised fine-tuning (SFT) with diverse data.\nAnother critical challenge with SpeechLMs is catastrophic forgetting-where\nmodels optimized for speech tasks suffer significant degradation in text-only\nperformance. To mitigate these issues, we propose a novel single-stage joint\nspeech-text SFT approach on the low-rank adaptation (LoRA) of the LLM backbone.\nOur joint SFT combines text-only SFT data with three types of speech-related\ndata: speech recognition and translation, speech-based QA, and mixed-modal SFT.\nCompared to previous SpeechLMs with 7B or 13B parameters, our 3B model\ndemonstrates superior performance across various speech benchmarks while\npreserving the original capabilities on text-only tasks. Furthermore, our model\nshows emergent abilities of effectively handling previously unseen prompts and\ntasks, including multi-turn, mixed-modal inputs.\n","authors":["Yifan Peng","Krishna C. Puvvada","Zhehuai Chen","Piotr Zelasko","He Huang","Kunal Dhawan","Ke Hu","Shinji Watanabe","Jagadeesh Balam","Boris Ginsburg"],"pdf_url":"https://arxiv.org/pdf/2410.17485v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.17484v1","updated":"2024-10-23T00:31:17Z","published":"2024-10-23T00:31:17Z","title":"Which Client is Reliable?: A Reliable and Personalized Prompt-based\n  Federated Learning for Medical Image Question Answering","summary":"  Conventional medical artificial intelligence (AI) models face barriers in\nclinical application and ethical issues owing to their inability to handle the\nprivacy-sensitive characteristics of medical data. We present a novel\npersonalized federated learning (pFL) method for medical visual question\nanswering (VQA) models, addressing privacy reliability challenges in the\nmedical domain. Our method introduces learnable prompts into a Transformer\narchitecture to efficiently train it on diverse medical datasets without\nmassive computational costs. Then we introduce a reliable client VQA model that\nincorporates Dempster-Shafer evidence theory to quantify uncertainty in\npredictions, enhancing the model's reliability. Furthermore, we propose a novel\ninter-client communication mechanism that uses maximum likelihood estimation to\nbalance accuracy and uncertainty, fostering efficient integration of insights\nacross clients.\n","authors":["He Zhu","Ren Togo","Takahiro Ogawa","Miki Haseyama"],"pdf_url":"https://arxiv.org/pdf/2410.17484v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.17482v1","updated":"2024-10-23T00:05:57Z","published":"2024-10-23T00:05:57Z","title":"Is artificial intelligence still intelligence? LLMs generalize to novel\n  adjective-noun pairs, but don't mimic the full human distribution","summary":"  Inferences from adjective-noun combinations like \"Is artificial intelligence\nstill intelligence?\" provide a good test bed for LLMs' understanding of meaning\nand compositional generalization capability, since there are many combinations\nwhich are novel to both humans and LLMs but nevertheless elicit convergent\nhuman judgments. We study a range of LLMs and find that the largest models we\ntested are able to draw human-like inferences when the inference is determined\nby context and can generalize to unseen adjective-noun combinations. We also\npropose three methods to evaluate LLMs on these inferences out of context,\nwhere there is a distribution of human-like answers rather than a single\ncorrect answer. We find that LLMs show a human-like distribution on at most\n75\\% of our dataset, which is promising but still leaves room for improvement.\n","authors":["Hayley Ross","Kathryn Davidson","Najoung Kim"],"pdf_url":"https://arxiv.org/pdf/2410.17482v1.pdf","comment":"9 pages (23 pages with appendix). Accepted to GenBench 2024"}],"Computer Vision and Pattern Recognition":[{"id":"http://arxiv.org/abs/2406.16592v3","updated":"2024-10-23T06:45:20Z","published":"2024-06-24T12:33:21Z","title":"Toward Fairer Face Recognition Datasets","summary":"  Face recognition and verification are two computer vision tasks whose\nperformance has progressed with the introduction of deep representations.\nHowever, ethical, legal, and technical challenges due to the sensitive\ncharacter of face data and biases in real training datasets hinder their\ndevelopment. Generative AI addresses privacy by creating fictitious identities,\nbut fairness problems persist. We promote fairness by introducing a demographic\nattributes balancing mechanism in generated training datasets. We experiment\nwith an existing real dataset, three generated training datasets, and the\nbalanced versions of a diffusion-based dataset. We propose a comprehensive\nevaluation that considers accuracy and fairness equally and includes a rigorous\nregression-based statistical analysis of attributes. The analysis shows that\nbalancing reduces demographic unfairness. Also, a performance gap persists\ndespite generation becoming more accurate with time. The proposed balancing\nmethod and comprehensive verification evaluation promote fairer and transparent\nface recognition and verification.\n","authors":["Alexandre Fournier-Montgieux","Michael Soumm","Adrian Popescu","Bertrand Luvison","Hervé Le Borgne"],"pdf_url":"https://arxiv.org/pdf/2406.16592v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2405.15574v4","updated":"2024-10-23T10:54:16Z","published":"2024-05-24T14:04:03Z","title":"Meteor: Mamba-based Traversal of Rationale for Large Language and Vision\n  Models","summary":"  The rapid development of large language and vision models (LLVMs) has been\ndriven by advances in visual instruction tuning. Recently, open-source LLVMs\nhave curated high-quality visual instruction tuning datasets and utilized\nadditional vision encoders or multiple computer vision models in order to\nnarrow the performance gap with powerful closed-source LLVMs. These\nadvancements are attributed to multifaceted information required for diverse\ncapabilities, including fundamental image understanding, real-world knowledge\nabout common-sense and non-object concepts (e.g., charts, diagrams, symbols,\nsigns, and math problems), and step-by-step procedures for solving complex\nquestions. Drawing from the multifaceted information, we present a new\nefficient LLVM, Mamba-based traversal of rationales (Meteor), which leverages\nmultifaceted rationale to enhance understanding and answering capabilities. To\nembed lengthy rationales containing abundant information, we employ the Mamba\narchitecture, capable of processing sequential data with linear time\ncomplexity. We introduce a new concept of traversal of rationale that\nfacilitates efficient embedding of rationale. Subsequently, the backbone\nmultimodal language model (MLM) is trained to generate answers with the aid of\nrationale. Through these steps, Meteor achieves significant improvements in\nvision language performances across multiple evaluation benchmarks requiring\ndiverse capabilities, without scaling up the model size or employing additional\nvision encoders and computer vision models.\n","authors":["Byung-Kwan Lee","Chae Won Kim","Beomchan Park","Yong Man Ro"],"pdf_url":"https://arxiv.org/pdf/2405.15574v4.pdf","comment":"Code is available in https://github.com/ByungKwanLee/Meteor"},{"id":"http://arxiv.org/abs/2410.18084v1","updated":"2024-10-23T17:59:58Z","published":"2024-10-23T17:59:58Z","title":"DynamicCity: Large-Scale LiDAR Generation from Dynamic Scenes","summary":"  LiDAR scene generation has been developing rapidly recently. However,\nexisting methods primarily focus on generating static and single-frame scenes,\noverlooking the inherently dynamic nature of real-world driving environments.\nIn this work, we introduce DynamicCity, a novel 4D LiDAR generation framework\ncapable of generating large-scale, high-quality LiDAR scenes that capture the\ntemporal evolution of dynamic environments. DynamicCity mainly consists of two\nkey models. 1) A VAE model for learning HexPlane as the compact 4D\nrepresentation. Instead of using naive averaging operations, DynamicCity\nemploys a novel Projection Module to effectively compress 4D LiDAR features\ninto six 2D feature maps for HexPlane construction, which significantly\nenhances HexPlane fitting quality (up to 12.56 mIoU gain). Furthermore, we\nutilize an Expansion & Squeeze Strategy to reconstruct 3D feature volumes in\nparallel, which improves both network training efficiency and reconstruction\naccuracy than naively querying each 3D point (up to 7.05 mIoU gain, 2.06x\ntraining speedup, and 70.84% memory reduction). 2) A DiT-based diffusion model\nfor HexPlane generation. To make HexPlane feasible for DiT generation, a Padded\nRollout Operation is proposed to reorganize all six feature planes of the\nHexPlane as a squared 2D feature map. In particular, various conditions could\nbe introduced in the diffusion or sampling process, supporting versatile 4D\ngeneration applications, such as trajectory- and command-driven generation,\ninpainting, and layout-conditioned generation. Extensive experiments on the\nCarlaSC and Waymo datasets demonstrate that DynamicCity significantly\noutperforms existing state-of-the-art 4D LiDAR generation methods across\nmultiple metrics. The code will be released to facilitate future research.\n","authors":["Hengwei Bian","Lingdong Kong","Haozhe Xie","Liang Pan","Yu Qiao","Ziwei Liu"],"pdf_url":"https://arxiv.org/pdf/2410.18084v1.pdf","comment":"Preprint; 29 pages, 15 figures, 7 tables; Project Page at\n  https://dynamic-city.github.io/"},{"id":"http://arxiv.org/abs/2410.18083v1","updated":"2024-10-23T17:59:57Z","published":"2024-10-23T17:59:57Z","title":"FIPER: Generalizable Factorized Fields for Joint Image Compression and\n  Super-Resolution","summary":"  In this work, we propose a unified representation for Super-Resolution (SR)\nand Image Compression, termed **Factorized Fields**, motivated by the shared\nprinciples between these two tasks. Both SISR and Image Compression require\nrecovering and preserving fine image details--whether by enhancing resolution\nor reconstructing compressed data. Unlike previous methods that mainly focus on\nnetwork architecture, our proposed approach utilizes a basis-coefficient\ndecomposition to explicitly capture multi-scale visual features and structural\ncomponents in images, addressing the core challenges of both tasks. We first\nderive our SR model, which includes a Coefficient Backbone and Basis Swin\nTransformer for generalizable Factorized Fields. Then, to further unify these\ntwo tasks, we leverage the strong information-recovery capabilities of the\ntrained SR modules as priors in the compression pipeline, improving both\ncompression efficiency and detail reconstruction. Additionally, we introduce a\nmerged-basis compression branch that consolidates shared structures, further\noptimizing the compression process. Extensive experiments show that our unified\nrepresentation delivers state-of-the-art performance, achieving an average\nrelative improvement of 204.4% in PSNR over the baseline in Super-Resolution\n(SR) and 9.35% BD-rate reduction in Image Compression compared to the previous\nSOTA.\n","authors":["Yang-Che Sun","Cheng Yu Yeo","Ernie Chu","Jun-Cheng Chen","Yu-Lun Liu"],"pdf_url":"https://arxiv.org/pdf/2410.18083v1.pdf","comment":"Project page: https://jayisaking.github.io/FIPER/"},{"id":"http://arxiv.org/abs/2410.18079v1","updated":"2024-10-23T17:59:11Z","published":"2024-10-23T17:59:11Z","title":"FreeVS: Generative View Synthesis on Free Driving Trajectory","summary":"  Existing reconstruction-based novel view synthesis methods for driving scenes\nfocus on synthesizing camera views along the recorded trajectory of the ego\nvehicle. Their image rendering performance will severely degrade on viewpoints\nfalling out of the recorded trajectory, where camera rays are untrained. We\npropose FreeVS, a novel fully generative approach that can synthesize camera\nviews on free new trajectories in real driving scenes. To control the\ngeneration results to be 3D consistent with the real scenes and accurate in\nviewpoint pose, we propose the pseudo-image representation of view priors to\ncontrol the generation process. Viewpoint transformation simulation is applied\non pseudo-images to simulate camera movement in each direction. Once trained,\nFreeVS can be applied to any validation sequences without reconstruction\nprocess and synthesis views on novel trajectories. Moreover, we propose two new\nchallenging benchmarks tailored to driving scenes, which are novel camera\nsynthesis and novel trajectory synthesis, emphasizing the freedom of\nviewpoints. Given that no ground truth images are available on novel\ntrajectories, we also propose to evaluate the consistency of images synthesized\non novel trajectories with 3D perception models. Experiments on the Waymo Open\nDataset show that FreeVS has a strong image synthesis performance on both the\nrecorded trajectories and novel trajectories. Project Page:\nhttps://freevs24.github.io/\n","authors":["Qitai Wang","Lue Fan","Yuqi Wang","Yuntao Chen","Zhaoxiang Zhang"],"pdf_url":"https://arxiv.org/pdf/2410.18079v1.pdf","comment":"Project Page: https://freevs24.github.io/"},{"id":"http://arxiv.org/abs/2410.18074v1","updated":"2024-10-23T17:56:33Z","published":"2024-10-23T17:56:33Z","title":"UnCLe: Unsupervised Continual Learning of Depth Completion","summary":"  We propose UnCLe, a standardized benchmark for Unsupervised Continual\nLearning of a multimodal depth estimation task: Depth completion aims to infer\na dense depth map from a pair of synchronized RGB image and sparse depth map.\nWe benchmark depth completion models under the practical scenario of\nunsupervised learning over continuous streams of data. Existing methods are\ntypically trained on a static, or stationary, dataset. However, when adapting\nto novel non-stationary distributions, they \"catastrophically forget\"\npreviously learned information. UnCLe simulates these non-stationary\ndistributions by adapting depth completion models to sequences of datasets\ncontaining diverse scenes captured from distinct domains using different visual\nand range sensors. We adopt representative methods from continual learning\nparadigms and translate them to enable unsupervised continual learning of depth\ncompletion. We benchmark these models for indoor and outdoor and investigate\nthe degree of catastrophic forgetting through standard quantitative metrics.\nFurthermore, we introduce model inversion quality as an additional measure of\nforgetting. We find that unsupervised continual learning of depth completion is\nan open problem, and we invite researchers to leverage UnCLe as a development\nplatform.\n","authors":["Suchisrit Gangopadhyay","Xien Chen","Michael Chu","Patrick Rim","Hyoungseob Park","Alex Wong"],"pdf_url":"https://arxiv.org/pdf/2410.18074v1.pdf","comment":"Preprint"},{"id":"http://arxiv.org/abs/2410.18072v1","updated":"2024-10-23T17:56:11Z","published":"2024-10-23T17:56:11Z","title":"WorldSimBench: Towards Video Generation Models as World Simulators","summary":"  Recent advancements in predictive models have demonstrated exceptional\ncapabilities in predicting the future state of objects and scenes. However, the\nlack of categorization based on inherent characteristics continues to hinder\nthe progress of predictive model development. Additionally, existing benchmarks\nare unable to effectively evaluate higher-capability, highly embodied\npredictive models from an embodied perspective. In this work, we classify the\nfunctionalities of predictive models into a hierarchy and take the first step\nin evaluating World Simulators by proposing a dual evaluation framework called\nWorldSimBench. WorldSimBench includes Explicit Perceptual Evaluation and\nImplicit Manipulative Evaluation, encompassing human preference assessments\nfrom the visual perspective and action-level evaluations in embodied tasks,\ncovering three representative embodied scenarios: Open-Ended Embodied\nEnvironment, Autonomous, Driving, and Robot Manipulation. In the Explicit\nPerceptual Evaluation, we introduce the HF-Embodied Dataset, a video assessment\ndataset based on fine-grained human feedback, which we use to train a Human\nPreference Evaluator that aligns with human perception and explicitly assesses\nthe visual fidelity of World Simulators. In the Implicit Manipulative\nEvaluation, we assess the video-action consistency of World Simulators by\nevaluating whether the generated situation-aware video can be accurately\ntranslated into the correct control signals in dynamic environments. Our\ncomprehensive evaluation offers key insights that can drive further innovation\nin video generation models, positioning World Simulators as a pivotal\nadvancement toward embodied artificial intelligence.\n","authors":["Yiran Qin","Zhelun Shi","Jiwen Yu","Xijun Wang","Enshen Zhou","Lijun Li","Zhenfei Yin","Xihui Liu","Lu Sheng","Jing Shao","Lei Bai","Wanli Ouyang","Ruimao Zhang"],"pdf_url":"https://arxiv.org/pdf/2410.18072v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.18071v1","updated":"2024-10-23T17:54:43Z","published":"2024-10-23T17:54:43Z","title":"TP-Eval: Tap Multimodal LLMs' Potential in Evaluation by Customizing\n  Prompts","summary":"  Recently, multimodal large language models (MLLMs) have received much\nattention for their impressive capabilities. The evaluation of MLLMs is\nbecoming critical to analyzing attributes of MLLMs and providing valuable\ninsights. However, current benchmarks overlook the problem of prompt\nsensitivity - minor prompt variations may lead to significant performance\nfluctuations. Thus, inappropriate prompts may obscure the models' capabilities,\nunderestimating the models' performance. Moreover, different models have\ndifferent preferences for different prompts, and thus, using the same prompt\nfor all models will cause evaluation bias. This paper analyzes this deficiency\nin existing benchmarks and further introduces a new evaluation framework named\nTP-Eval, which introduces a prompt customization method to reduce evaluation\nbiases and tap models' potential. TP-Eval will rewrite the original prompts to\ndifferent customized prompts for different models. In particular, we propose\nsome well-designed modules for prompt customization tailored to the scenario of\nMLLM evaluation. Extensive experiments demonstrate the effectiveness of our\napproach to uncovering models' capabilities, and TP-Eval should benefit the\ncommunity in developing more comprehensive and convincing MLLM evaluation\nbenchmarks.\n","authors":["Yuxuan Xie","Tianhua Li","Wenqi Shao","Kaipeng Zhang"],"pdf_url":"https://arxiv.org/pdf/2410.18071v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.12568v2","updated":"2024-10-23T17:53:24Z","published":"2024-08-22T17:35:18Z","title":"Pruning By Explaining Revisited: Optimizing Attribution Methods to Prune\n  CNNs and Transformers","summary":"  To solve ever more complex problems, Deep Neural Networks are scaled to\nbillions of parameters, leading to huge computational costs. An effective\napproach to reduce computational requirements and increase efficiency is to\nprune unnecessary components of these often over-parameterized networks.\nPrevious work has shown that attribution methods from the field of eXplainable\nAI serve as effective means to extract and prune the least relevant network\ncomponents in a few-shot fashion. We extend the current state by proposing to\nexplicitly optimize hyperparameters of attribution methods for the task of\npruning, and further include transformer-based networks in our analysis. Our\napproach yields higher model compression rates of large transformer- and\nconvolutional architectures (VGG, ResNet, ViT) compared to previous works,\nwhile still attaining high performance on ImageNet classification tasks. Here,\nour experiments indicate that transformers have a higher degree of\nover-parameterization compared to convolutional neural networks. Code is\navailable at https://github.com/erfanhatefi/Pruning-by-eXplaining-in-PyTorch.\n","authors":["Sayed Mohammad Vakilzadeh Hatefi","Maximilian Dreyer","Reduan Achtibat","Thomas Wiegand","Wojciech Samek","Sebastian Lapuschkin"],"pdf_url":"https://arxiv.org/pdf/2408.12568v2.pdf","comment":"Accepted as a workshop paper at ECCV 2024, 26 pages (11 pages\n  manuscript, 3 pages references, 12 pages appendix)"},{"id":"http://arxiv.org/abs/2410.18065v1","updated":"2024-10-23T17:42:07Z","published":"2024-10-23T17:42:07Z","title":"SPIRE: Synergistic Planning, Imitation, and Reinforcement Learning for\n  Long-Horizon Manipulation","summary":"  Robot learning has proven to be a general and effective technique for\nprogramming manipulators. Imitation learning is able to teach robots solely\nfrom human demonstrations but is bottlenecked by the capabilities of the\ndemonstrations. Reinforcement learning uses exploration to discover better\nbehaviors; however, the space of possible improvements can be too large to\nstart from scratch. And for both techniques, the learning difficulty increases\nproportional to the length of the manipulation task. Accounting for this, we\npropose SPIRE, a system that first uses Task and Motion Planning (TAMP) to\ndecompose tasks into smaller learning subproblems and second combines imitation\nand reinforcement learning to maximize their strengths. We develop novel\nstrategies to train learning agents when deployed in the context of a planning\nsystem. We evaluate SPIRE on a suite of long-horizon and contact-rich robot\nmanipulation problems. We find that SPIRE outperforms prior approaches that\nintegrate imitation learning, reinforcement learning, and planning by 35% to\n50% in average task performance, is 6 times more data efficient in the number\nof human demonstrations needed to train proficient agents, and learns to\ncomplete tasks nearly twice as efficiently. View\nhttps://sites.google.com/view/spire-corl-2024 for more details.\n","authors":["Zihan Zhou","Animesh Garg","Dieter Fox","Caelan Garrett","Ajay Mandlekar"],"pdf_url":"https://arxiv.org/pdf/2410.18065v1.pdf","comment":"Conference on Robot Learning (CoRL) 2024"},{"id":"http://arxiv.org/abs/2410.18057v1","updated":"2024-10-23T17:30:50Z","published":"2024-10-23T17:30:50Z","title":"CLEAR: Character Unlearning in Textual and Visual Modalities","summary":"  Machine Unlearning (MU) is critical for enhancing privacy and security in\ndeep learning models, particularly in large multimodal language models (MLLMs),\nby removing specific private or hazardous information. While MU has made\nsignificant progress in textual and visual modalities, multimodal unlearning\n(MMU) remains significantly underexplored, partially due to the absence of a\nsuitable open-source benchmark. To address this, we introduce CLEAR, a new\nbenchmark designed to evaluate MMU methods. CLEAR contains 200 fictitious\nindividuals and 3,700 images linked with corresponding question-answer pairs,\nenabling a thorough evaluation across modalities. We assess 10 MU methods,\nadapting them for MMU, and highlight new challenges specific to multimodal\nforgetting. We also demonstrate that simple $\\ell_1$ regularization on LoRA\nweights significantly mitigates catastrophic forgetting, preserving model\nperformance on retained data. The dataset is available at\nhttps://huggingface.co/datasets/therem/CLEAR\n","authors":["Alexey Dontsov","Dmitrii Korzh","Alexey Zhavoronkin","Boris Mikheev","Denis Bobkov","Aibek Alanov","Oleg Y. Rogov","Ivan Oseledets","Elena Tutubalina"],"pdf_url":"https://arxiv.org/pdf/2410.18057v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.18052v1","updated":"2024-10-23T17:26:22Z","published":"2024-10-23T17:26:22Z","title":"In-Pixel Foreground and Contrast Enhancement Circuits with Customizable\n  Mapping","summary":"  This paper presents an innovative in-pixel contrast enhancement circuit that\nperforms image processing directly within the pixel circuit. The circuit can be\ntuned for different modes of operation. In foreground enhancement mode, it\nsuppresses low-intensity background pixels to nearly zero, isolating the\nforeground for better object visibility. In contrast enhancement mode, it\nimproves overall image contrast. The contrast enhancement function is\ncustomizable both during the design phase and in real-time, allowing the\ncircuit to adapt to specific applications and varying lighting conditions. A\nmodel of the designed pixel circuit is developed and applied to a full pixel\narray, demonstrating significant improvements in image quality. Simulations\nperformed in HSPICE show a nearly 6x increase in Michelson Contrast Ratio (CR)\nin the foreground enhancement mode. The simulation results indicate its\npotential for real-time, adaptive contrast enhancement across various imaging\nenvironments.\n","authors":["Md Rahatul Islam Udoy","Md Mazharul Islam","Elijah Johnson","Ahmedullah Aziz"],"pdf_url":"https://arxiv.org/pdf/2410.18052v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.18051v1","updated":"2024-10-23T17:25:26Z","published":"2024-10-23T17:25:26Z","title":"Real time anomalies detection on video","summary":"  Nowadays, many places use security cameras. Unfortunately, when an incident\noccurs, these technologies are used to show past events. So it can be\nconsidered as a deterrence tool than a detection tool. In this article, we will\npropose a deep learning approach trying to solve this problematic. This\napproach uses convolutional models (CNN) to extract relevant characteristics\nlinked to the video images, theses characteristics will form times series to be\nanalyzed by LSTM / GRU models.\n","authors":["Fabien Poirier"],"pdf_url":"https://arxiv.org/pdf/2410.18051v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.18013v1","updated":"2024-10-23T16:42:56Z","published":"2024-10-23T16:42:56Z","title":"Scalable Ranked Preference Optimization for Text-to-Image Generation","summary":"  Direct Preference Optimization (DPO) has emerged as a powerful approach to\nalign text-to-image (T2I) models with human feedback. Unfortunately, successful\napplication of DPO to T2I models requires a huge amount of resources to collect\nand label large-scale datasets, e.g., millions of generated paired images\nannotated with human preferences. In addition, these human preference datasets\ncan get outdated quickly as the rapid improvements of T2I models lead to higher\nquality images. In this work, we investigate a scalable approach for collecting\nlarge-scale and fully synthetic datasets for DPO training. Specifically, the\npreferences for paired images are generated using a pre-trained reward\nfunction, eliminating the need for involving humans in the annotation process,\ngreatly improving the dataset collection efficiency. Moreover, we demonstrate\nthat such datasets allow averaging predictions across multiple models and\ncollecting ranked preferences as opposed to pairwise preferences. Furthermore,\nwe introduce RankDPO to enhance DPO-based methods using the ranking feedback.\nApplying RankDPO on SDXL and SD3-Medium models with our synthetically generated\npreference dataset ``Syn-Pic'' improves both prompt-following (on benchmarks\nlike T2I-Compbench, GenEval, and DPG-Bench) and visual quality (through user\nstudies). This pipeline presents a practical and scalable solution to develop\nbetter preference datasets to enhance the performance of text-to-image models.\n","authors":["Shyamgopal Karthik","Huseyin Coskun","Zeynep Akata","Sergey Tulyakov","Jian Ren","Anil Kag"],"pdf_url":"https://arxiv.org/pdf/2410.18013v1.pdf","comment":"Project Page: https://snap-research.github.io/RankDPO/"},{"id":"http://arxiv.org/abs/2409.04429v2","updated":"2024-10-23T16:42:06Z","published":"2024-09-06T17:49:56Z","title":"VILA-U: a Unified Foundation Model Integrating Visual Understanding and\n  Generation","summary":"  VILA-U is a Unified foundation model that integrates Video, Image, Language\nunderstanding and generation. Traditional visual language models (VLMs) use\nseparate modules for understanding and generating visual content, which can\nlead to misalignment and increased complexity. In contrast, VILA-U employs a\nsingle autoregressive next-token prediction framework for both tasks,\neliminating the need for additional components like diffusion models. This\napproach not only simplifies the model but also achieves near state-of-the-art\nperformance in visual language understanding and generation. The success of\nVILA-U is attributed to two main factors: the unified vision tower that aligns\ndiscrete visual tokens with textual inputs during pretraining, which enhances\nvisual perception, and autoregressive image generation can achieve similar\nquality as diffusion models with high-quality dataset. This allows VILA-U to\nperform comparably to more complex models using a fully token-based\nautoregressive framework.\n","authors":["Yecheng Wu","Zhuoyang Zhang","Junyu Chen","Haotian Tang","Dacheng Li","Yunhao Fang","Ligeng Zhu","Enze Xie","Hongxu Yin","Li Yi","Song Han","Yao Lu"],"pdf_url":"https://arxiv.org/pdf/2409.04429v2.pdf","comment":"Code: https://github.com/mit-han-lab/vila-u. The first two authors\n  contributed equally to this work"},{"id":"http://arxiv.org/abs/2403.05489v2","updated":"2024-10-23T16:39:15Z","published":"2024-03-08T17:54:38Z","title":"JointMotion: Joint Self-Supervision for Joint Motion Prediction","summary":"  We present JointMotion, a self-supervised pre-training method for joint\nmotion prediction in self-driving vehicles. Our method jointly optimizes a\nscene-level objective connecting motion and environments, and an instance-level\nobjective to refine learned representations. Scene-level representations are\nlearned via non-contrastive similarity learning of past motion sequences and\nenvironment context. At the instance level, we use masked autoencoding to\nrefine multimodal polyline representations. We complement this with an adaptive\npre-training decoder that enables JointMotion to generalize across different\nenvironment representations, fusion mechanisms, and dataset characteristics.\nNotably, our method reduces the joint final displacement error of Wayformer,\nHPTR, and Scene Transformer models by 3\\%, 8\\%, and 12\\%, respectively; and\nenables transfer learning between the Waymo Open Motion and the Argoverse 2\nMotion Forecasting datasets. Code: https://github.com/kit-mrt/future-motion\n","authors":["Royden Wagner","Omer Sahin Tas","Marvin Klemp","Carlos Fernandez"],"pdf_url":"https://arxiv.org/pdf/2403.05489v2.pdf","comment":"CoRL'24 camera-ready"},{"id":"http://arxiv.org/abs/2309.17327v2","updated":"2024-10-23T16:25:17Z","published":"2023-09-29T15:34:39Z","title":"Telling Stories for Common Sense Zero-Shot Action Recognition","summary":"  Video understanding has long suffered from reliance on large labeled\ndatasets, motivating research into zero-shot learning. Recent progress in\nlanguage modeling presents opportunities to advance zero-shot video analysis,\nbut constructing an effective semantic space relating action classes remains\nchallenging. We address this by introducing a novel dataset, Stories, which\ncontains rich textual descriptions for diverse action classes extracted from\nWikiHow articles. For each class, we extract multi-sentence narratives\ndetailing the necessary steps, scenes, objects, and verbs that characterize the\naction. This contextual data enables modeling of nuanced relationships between\nactions, paving the way for zero-shot transfer. We also propose an approach\nthat harnesses Stories to improve feature generation for training zero-shot\nclassification. Without any target dataset fine-tuning, our method achieves new\nstate-of-the-art on multiple benchmarks, improving top-1 accuracy by up to\n6.1%. We believe Stories provides a valuable resource that can catalyze\nprogress in zero-shot action recognition. The textual narratives forge\nconnections between seen and unseen classes, overcoming the bottleneck of\nlabeled data that has long impeded advancements in this exciting domain. The\ndata can be found here: https://github.com/kini5gowda/Stories .\n","authors":["Shreyank N Gowda","Laura Sevilla-Lara"],"pdf_url":"https://arxiv.org/pdf/2309.17327v2.pdf","comment":"Accepted in ACCV 2024!"},{"id":"http://arxiv.org/abs/2410.03189v2","updated":"2024-10-23T16:22:59Z","published":"2024-10-04T07:02:13Z","title":"Generalizable Prompt Tuning for Vision-Language Models","summary":"  Prompt tuning for vision-language models such as CLIP involves optimizing the\ntext prompts used to generate image-text pairs for specific downstream tasks.\nWhile hand-crafted or template-based prompts are generally applicable to a\nwider range of unseen classes, they tend to perform poorly in downstream tasks\n(i.e., seen classes). Learnable soft prompts, on the other hand, often perform\nwell in downstream tasks but lack generalizability. Additionally, prior\nresearch has predominantly concentrated on the textual modality, with very few\nstudies attempting to explore the prompt's generalization potential from the\nvisual modality. Keeping these limitations in mind, we investigate how to\nprompt tuning to obtain both a competitive downstream performance and\ngeneralization. The study shows that by treating soft and hand-crafted prompts\nas dual views of the textual modality, and maximizing their mutual information,\nwe can better ensemble task-specific and general semantic information.\nMoreover, to generate more expressive prompts, the study introduces a\nclass-wise augmentation from the visual modality, resulting in significant\nrobustness to a wider range of unseen classes. Extensive evaluations on several\nbenchmarks report that the proposed approach achieves competitive results in\nterms of both task-specific performance and general abilities.\n","authors":["Qian Zhang"],"pdf_url":"https://arxiv.org/pdf/2410.03189v2.pdf","comment":"in progress"},{"id":"http://arxiv.org/abs/2410.17997v1","updated":"2024-10-23T16:12:03Z","published":"2024-10-23T16:12:03Z","title":"Characterization of the multiplicity of solutions for camera pose given\n  two vertically-aligned landmarks and accelerometer","summary":"  We consider the problem of recovering the position and orientation of a\ncamera equipped with an accelerometer from sensor images of two labeled\nlandmarks whose positions in a coordinate system aligned in a known way with\ngravity are known. This a variant on the much studied P$n$P problem of\nrecovering camera position and orientation from $n$ points without any\ngravitational data. It is proved that in three types of singular cases there\nare infinitely many solutions, in another type of case there is one, and in a\nfinal type of case there are two. A precise characterization of each type of\ncase. In particular, there is always a unique solution in the practically\ninteresting case where the two landmarks are at the same altitude and the\ncamera is at a different altitude. This case is studied by numerical simulation\nand an implementation on a consumer cellphone. It is also proved that if the\ntwo landmarks are unlabeled, then apart from the same singular cases, there are\nstill always one or two solutions.\n","authors":["Alexander R. Pruss"],"pdf_url":"https://arxiv.org/pdf/2410.17997v1.pdf","comment":"32 pages, 8 figures"},{"id":"http://arxiv.org/abs/2407.19553v2","updated":"2024-10-23T16:06:32Z","published":"2024-07-28T18:20:08Z","title":"Exploring the Adversarial Robustness of CLIP for AI-generated Image\n  Detection","summary":"  In recent years, many forensic detectors have been proposed to detect\nAI-generated images and prevent their use for malicious purposes. Convolutional\nneural networks (CNNs) have long been the dominant architecture in this field\nand have been the subject of intense study. However, recently proposed\nTransformer-based detectors have been shown to match or even outperform\nCNN-based detectors, especially in terms of generalization. In this paper, we\nstudy the adversarial robustness of AI-generated image detectors, focusing on\nContrastive Language-Image Pretraining (CLIP)-based methods that rely on Visual\nTransformer (ViT) backbones and comparing their performance with CNN-based\nmethods. We study the robustness to different adversarial attacks under a\nvariety of conditions and analyze both numerical results and frequency-domain\npatterns. CLIP-based detectors are found to be vulnerable to white-box attacks\njust like CNN-based detectors. However, attacks do not easily transfer between\nCNN-based and CLIP-based methods. This is also confirmed by the different\ndistribution of the adversarial noise patterns in the frequency domain.\nOverall, this analysis provides new insights into the properties of forensic\ndetectors that can help to develop more effective strategies.\n","authors":["Vincenzo De Rosa","Fabrizio Guillaro","Giovanni Poggi","Davide Cozzolino","Luisa Verdoliva"],"pdf_url":"https://arxiv.org/pdf/2407.19553v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.17988v1","updated":"2024-10-23T16:01:31Z","published":"2024-10-23T16:01:31Z","title":"A Pipeline for Segmenting and Structuring RGB-D Data for Robotics\n  Applications","summary":"  We introduce a novel pipeline for segmenting and structuring color and depth\n(RGB-D) data. Existing processing pipelines for RGB-D data have focused on\nextracting geometric information alone. This approach precludes the development\nof more advanced robotic navigation and manipulation algorithms, which benefit\nfrom a semantic understanding of their environment. Our pipeline can segment\nRGB-D data into accurate semantic masks. These masks are then used to fuse raw\ncaptured point clouds into semantically separated point clouds. We store this\ninformation using the Universal Scene Description (USD) file format, a format\nsuitable for easy querying by downstream robotics algorithms, human-friendly\nvisualization, and robotics simulation.\n","authors":["Zhiwu Zheng","Lauren Mentzer","Berk Iskender","Michael Price","Colm Prendergast","Audren Cloitre"],"pdf_url":"https://arxiv.org/pdf/2410.17988v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.17983v1","updated":"2024-10-23T15:51:33Z","published":"2024-10-23T15:51:33Z","title":"Robust Two-View Geometry Estimation with Implicit Differentiation","summary":"  We present a novel two-view geometry estimation framework which is based on a\ndifferentiable robust loss function fitting. We propose to treat the robust\nfundamental matrix estimation as an implicit layer, which allows us to avoid\nbackpropagation through time and significantly improves the numerical\nstability. To take full advantage of the information from the feature matching\nstage we incorporate learnable weights that depend on the matching confidences.\nIn this way our solution brings together feature extraction, matching and\ntwo-view geometry estimation in a unified end-to-end trainable pipeline. We\nevaluate our approach on the camera pose estimation task in both outdoor and\nindoor scenarios. The experiments on several datasets show that the proposed\nmethod outperforms both classic and learning-based state-of-the-art methods by\na large margin. The project webpage is available at:\nhttps://github.com/VladPyatov/ihls\n","authors":["Vladislav Pyatov","Iaroslav Koshelev","Stamatis Lefkimmiatis"],"pdf_url":"https://arxiv.org/pdf/2410.17983v1.pdf","comment":"IROS 2024 Accepted"},{"id":"http://arxiv.org/abs/2410.17966v1","updated":"2024-10-23T15:34:06Z","published":"2024-10-23T15:34:06Z","title":"A Wavelet Diffusion GAN for Image Super-Resolution","summary":"  In recent years, diffusion models have emerged as a superior alternative to\ngenerative adversarial networks (GANs) for high-fidelity image generation, with\nwide applications in text-to-image generation, image-to-image translation, and\nsuper-resolution. However, their real-time feasibility is hindered by slow\ntraining and inference speeds. This study addresses this challenge by proposing\na wavelet-based conditional Diffusion GAN scheme for Single-Image\nSuper-Resolution (SISR). Our approach utilizes the diffusion GAN paradigm to\nreduce the timesteps required by the reverse diffusion process and the Discrete\nWavelet Transform (DWT) to achieve dimensionality reduction, decreasing\ntraining and inference times significantly. The results of an experimental\nvalidation on the CelebA-HQ dataset confirm the effectiveness of our proposed\nscheme. Our approach outperforms other state-of-the-art methodologies\nsuccessfully ensuring high-fidelity output while overcoming inherent drawbacks\nassociated with diffusion models in time-sensitive applications.\n","authors":["Lorenzo Aloisi","Luigi Sigillo","Aurelio Uncini","Danilo Comminiello"],"pdf_url":"https://arxiv.org/pdf/2410.17966v1.pdf","comment":"The paper has been accepted at Italian Workshop on Neural Networks\n  (WIRN) 2024"},{"id":"http://arxiv.org/abs/2408.15205v2","updated":"2024-10-23T15:33:47Z","published":"2024-08-27T17:06:22Z","title":"Leveraging Hallucinations to Reduce Manual Prompt Dependency in\n  Promptable Segmentation","summary":"  Promptable segmentation typically requires instance-specific manual prompts\nto guide the segmentation of each desired object. To minimize such a need,\ntask-generic promptable segmentation has been introduced, which employs a\nsingle task-generic prompt to segment various images of different objects in\nthe same task. Current methods use Multimodal Large Language Models (MLLMs) to\nreason detailed instance-specific prompts from a task-generic prompt for\nimproving segmentation accuracy. The effectiveness of this segmentation heavily\ndepends on the precision of these derived prompts. However, MLLMs often suffer\nhallucinations during reasoning, resulting in inaccurate prompting. While\nexisting methods focus on eliminating hallucinations to improve a model, we\nargue that MLLM hallucinations can reveal valuable contextual insights when\nleveraged correctly, as they represent pre-trained large-scale knowledge beyond\nindividual images. In this paper, we utilize hallucinations to mine\ntask-related information from images and verify its accuracy for enhancing\nprecision of the generated prompts. Specifically, we introduce an iterative\nPrompt-Mask Cycle generation framework (ProMaC) with a prompt generator and a\nmask generator.The prompt generator uses a multi-scale chain of thought\nprompting, initially exploring hallucinations for extracting extended\ncontextual knowledge on a test image.These hallucinations are then reduced to\nformulate precise instance-specific prompts, directing the mask generator to\nproduce masks that are consistent with task semantics by mask semantic\nalignment. The generated masks iteratively induce the prompt generator to focus\nmore on task-relevant image areas and reduce irrelevant hallucinations,\nresulting jointly in better prompts and masks. Experiments on 5 benchmarks\ndemonstrate the effectiveness of ProMaC. Code given in\nhttps://lwpyh.github.io/ProMaC/.\n","authors":["Jian Hu","Jiayi Lin","Junchi Yan","Shaogang Gong"],"pdf_url":"https://arxiv.org/pdf/2408.15205v2.pdf","comment":"NeurIPS 2024"},{"id":"http://arxiv.org/abs/2410.17959v1","updated":"2024-10-23T15:28:25Z","published":"2024-10-23T15:28:25Z","title":"Medical Imaging Complexity and its Effects on GAN Performance","summary":"  The proliferation of machine learning models in diverse clinical applications\nhas led to a growing need for high-fidelity, medical image training data. Such\ndata is often scarce due to cost constraints and privacy concerns. Alleviating\nthis burden, medical image synthesis via generative adversarial networks (GANs)\nemerged as a powerful method for synthetically generating photo-realistic\nimages based on existing sets of real medical images. However, the exact image\nset size required to efficiently train such a GAN is unclear. In this work, we\nexperimentally establish benchmarks that measure the relationship between a\nsample dataset size and the fidelity of the generated images, given the\ndataset's distribution of image complexities. We analyze statistical metrics\nbased on delentropy, an image complexity measure rooted in Shannon's entropy in\ninformation theory. For our pipeline, we conduct experiments with two\nstate-of-the-art GANs, StyleGAN 3 and SPADE-GAN, trained on multiple medical\nimaging datasets with variable sample sizes. Across both GANs, general\nperformance improved with increasing training set size but suffered with\nincreasing complexity.\n","authors":["William Cagas","Chan Ko","Blake Hsiao","Shryuk Grandhi","Rishi Bhattacharya","Kevin Zhu","Michael Lam"],"pdf_url":"https://arxiv.org/pdf/2410.17959v1.pdf","comment":"Accepted to ACCV, Workshop on Generative AI for Synthetic Medical\n  Data"},{"id":"http://arxiv.org/abs/2410.12018v2","updated":"2024-10-23T15:21:54Z","published":"2024-10-15T19:33:57Z","title":"LocoMotion: Learning Motion-Focused Video-Language Representations","summary":"  This paper strives for motion-focused video-language representations.\nExisting methods to learn video-language representations use spatial-focused\ndata, where identifying the objects and scene is often enough to distinguish\nthe relevant caption. We instead propose LocoMotion to learn from\nmotion-focused captions that describe the movement and temporal progression of\nlocal object motions. We achieve this by adding synthetic motions to videos and\nusing the parameters of these motions to generate corresponding captions.\nFurthermore, we propose verb-variation paraphrasing to increase the caption\nvariety and learn the link between primitive motions and high-level verbs. With\nthis, we are able to learn a motion-focused video-language representation.\nExperiments demonstrate our approach is effective for a variety of downstream\ntasks, particularly when limited data is available for fine-tuning. Code is\navailable: https://hazeldoughty.github.io/Papers/LocoMotion/\n","authors":["Hazel Doughty","Fida Mohammad Thoker","Cees G. M. Snoek"],"pdf_url":"https://arxiv.org/pdf/2410.12018v2.pdf","comment":"ACCV 2024 Oral"},{"id":"http://arxiv.org/abs/2406.14856v2","updated":"2024-10-23T15:08:59Z","published":"2024-06-21T04:02:19Z","title":"Accessible, At-Home Detection of Parkinson's Disease via Multi-task\n  Video Analysis","summary":"  Limited accessibility to neurological care leads to underdiagnosed\nParkinson's Disease (PD), preventing early intervention. Existing AI-based PD\ndetection methods primarily focus on unimodal analysis of motor or speech\ntasks, overlooking the multifaceted nature of the disease. To address this, we\nintroduce a large-scale, multi-task video dataset consisting of 1102 sessions\n(each containing videos of finger tapping, facial expression, and speech tasks\ncaptured via webcam) from 845 participants (272 with PD). We propose a novel\nUncertainty-calibrated Fusion Network (UFNet) that leverages this multimodal\ndata to enhance diagnostic accuracy. UFNet employs independent task-specific\nnetworks, trained with Monte Carlo Dropout for uncertainty quantification,\nfollowed by self-attended fusion of features, with attention weights\ndynamically adjusted based on task-specific uncertainties. To ensure\npatient-centered evaluation, the participants were randomly split into three\nsets: 60% for training, 20% for model selection, and 20% for final performance\nevaluation. UFNet significantly outperformed single-task models in terms of\naccuracy, area under the ROC curve (AUROC), and sensitivity while maintaining\nnon-inferior specificity. Withholding uncertain predictions further boosted the\nperformance, achieving 88.0+-0.3%$ accuracy, 93.0+-0.2% AUROC, 79.3+-0.9%\nsensitivity, and 92.6+-0.3% specificity, at the expense of not being able to\npredict for 2.3+-0.3% data (+- denotes 95% confidence interval). Further\nanalysis suggests that the trained model does not exhibit any detectable bias\nacross sex and ethnic subgroups and is most effective for individuals aged\nbetween 50 and 80. Requiring only a webcam and microphone, our approach\nfacilitates accessible home-based PD screening, especially in regions with\nlimited healthcare resources.\n","authors":["Md Saiful Islam","Tariq Adnan","Jan Freyberg","Sangwu Lee","Abdelrahman Abdelkader","Meghan Pawlik","Cathe Schwartz","Karen Jaffe","Ruth B. Schneider","E Ray Dorsey","Ehsan Hoque"],"pdf_url":"https://arxiv.org/pdf/2406.14856v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.17932v1","updated":"2024-10-23T14:54:48Z","published":"2024-10-23T14:54:48Z","title":"VR-Splatting: Foveated Radiance Field Rendering via 3D Gaussian\n  Splatting and Neural Points","summary":"  Recent advances in novel view synthesis (NVS), particularly neural radiance\nfields (NeRF) and Gaussian splatting (3DGS), have demonstrated impressive\nresults in photorealistic scene rendering. These techniques hold great\npotential for applications in virtual tourism and teleportation, where\nimmersive realism is crucial. However, the high-performance demands of virtual\nreality (VR) systems present challenges in directly utilizing even such\nfast-to-render scene representations like 3DGS due to latency and computational\nconstraints.\n  In this paper, we propose foveated rendering as a promising solution to these\nobstacles. We analyze state-of-the-art NVS methods with respect to their\nrendering performance and compatibility with the human visual system. Our\napproach introduces a novel foveated rendering approach for Virtual Reality,\nthat leverages the sharp, detailed output of neural point rendering for the\nfoveal region, fused with a smooth rendering of 3DGS for the peripheral vision.\n  Our evaluation confirms that perceived sharpness and detail-richness are\nincreased by our approach compared to a standard VR-ready 3DGS configuration.\nOur system meets the necessary performance requirements for real-time VR\ninteractions, ultimately enhancing the user's immersive experience.\n  Project page: https://lfranke.github.io/vr_splatting\n","authors":["Linus Franke","Laura Fink","Marc Stamminger"],"pdf_url":"https://arxiv.org/pdf/2410.17932v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.02240v4","updated":"2024-10-23T14:53:38Z","published":"2024-10-03T06:25:53Z","title":"SCA: Highly Efficient Semantic-Consistent Unrestricted Adversarial\n  Attack","summary":"  Deep neural network based systems deployed in sensitive environments are\nvulnerable to adversarial attacks. Unrestricted adversarial attacks typically\nmanipulate the semantic content of an image (e.g., color or texture) to create\nadversarial examples that are both effective and photorealistic. Recent works\nhave utilized the diffusion inversion process to map images into a latent\nspace, where high-level semantics are manipulated by introducing perturbations.\nHowever, they often results in substantial semantic distortions in the denoised\noutput and suffers from low efficiency. In this study, we propose a novel\nframework called Semantic-Consistent Unrestricted Adversarial Attacks (SCA),\nwhich employs an inversion method to extract edit-friendly noise maps and\nutilizes Multimodal Large Language Model (MLLM) to provide semantic guidance\nthroughout the process. Under the condition of rich semantic information\nprovided by MLLM, we perform the DDPM denoising process of each step using a\nseries of edit-friendly noise maps, and leverage DPM Solver++ to accelerate\nthis process, enabling efficient sampling with semantic consistency. Compared\nto existing methods, our framework enables the efficient generation of\nadversarial examples that exhibit minimal discernible semantic changes.\nConsequently, we for the first time introduce Semantic-Consistent Adversarial\nExamples (SCAE). Extensive experiments and visualizations have demonstrated the\nhigh efficiency of SCA, particularly in being on average 12 times faster than\nthe state-of-the-art attacks. Our research can further draw attention to the\nsecurity of multimedia information.\n","authors":["Zihao Pan","Weibin Wu","Yuhang Cao","Zibin Zheng"],"pdf_url":"https://arxiv.org/pdf/2410.02240v4.pdf","comment":null},{"id":"http://arxiv.org/abs/2404.08401v3","updated":"2024-10-23T14:48:44Z","published":"2024-04-12T11:15:15Z","title":"PnLCalib: Sports Field Registration via Points and Lines Optimization","summary":"  Camera calibration in broadcast sports videos presents numerous challenges\nfor accurate sports field registration due to multiple camera angles, varying\ncamera parameters, and frequent occlusions of the field. Traditional\nsearch-based methods depend on initial camera pose estimates, which can\nstruggle in non-standard positions and dynamic environments. In response, we\npropose an optimization-based calibration pipeline that leverages a 3D soccer\nfield model and a predefined set of keypoints to overcome these limitations.\nOur method also introduces a novel refinement module that improves initial\ncalibration by using detected field lines in a non-linear optimization process.\nThis approach outperforms existing techniques in both multi-view and\nsingle-view 3D camera calibration tasks, while maintaining competitive\nperformance in homography estimation. Extensive experimentation on real-world\nsoccer datasets, including SoccerNet-Calibration, WorldCup 2014, and\nTS-WorldCup, highlights the robustness and accuracy of our method across\ndiverse broadcast scenarios. Our approach offers significant improvements in\ncamera calibration precision and reliability.\n","authors":["Marc Gutiérrez-Pérez","Antonio Agudo"],"pdf_url":"https://arxiv.org/pdf/2404.08401v3.pdf","comment":"Extended version of \"No Bells, Just Whistles: Sports Field\n  Registration Leveraging Geometric Properties\""},{"id":"http://arxiv.org/abs/2312.05349v3","updated":"2024-10-23T14:47:10Z","published":"2023-12-08T20:12:26Z","title":"PixLore: A Dataset-driven Approach to Rich Image Captioning","summary":"  In the domain of vision-language integration, generating detailed image\ncaptions poses a significant challenge due to the lack of curated and rich\ndatasets. This study introduces PixLore, a novel method that leverages Querying\nTransformers through the fine-tuning of the BLIP-2 model using the LoRa method\non a standard commercial GPU. The followed approach, which involves training on\na carefully assembled dataset from state-of-the-art Computer Vision models\ncombined and augmented by ChatGPT, addresses the question of whether intricate\nimage understanding can be achieved with an ensemble of smaller-scale models,\nreferred to as Knowledge Stitching. Comparative evaluations against major\nmodels such as GPT-4 and Google Bard demonstrate that PixLore-2.7B, despite\nhaving considerably fewer parameters, is rated higher than the existing\nState-of-the-Art models in over half of the assessments. Precisely, PixLore\noutperform Bard and BLIP-2, which score approximately 35.18% and 27.98% lower\nthan PixLore in the task of image captioning. This research not only presents a\ngroundbreaking approach but also highlights the importance of well-curated\ndatasets in enhancing the performance of smaller models.\n","authors":["Diego Bonilla-Salvador","Marcelino Martínez-Sober","Joan Vila-Francés","Antonio José Serrano-López","Pablo Rodríguez-Belenguer","Fernando Mateo"],"pdf_url":"https://arxiv.org/pdf/2312.05349v3.pdf","comment":"Paper in preprint pending of publication"},{"id":"http://arxiv.org/abs/2402.17307v2","updated":"2024-10-23T14:42:07Z","published":"2024-02-27T08:31:39Z","title":"Denoising Diffusion Models for Inpainting of Healthy Brain Tissue","summary":"  This paper is a contribution to the \"BraTS 2023 Local Synthesis of Healthy\nBrain Tissue via Inpainting Challenge\". The task of this challenge is to\ntransform tumor tissue into healthy tissue in brain magnetic resonance (MR)\nimages. This idea originates from the problem that MR images can be evaluated\nusing automatic processing tools, however, many of these tools are optimized\nfor the analysis of healthy tissue. By solving the given inpainting task, we\nenable the automatic analysis of images featuring lesions, and further\ndownstream tasks. Our approach builds on denoising diffusion probabilistic\nmodels. We use a 2D model that is trained using slices in which healthy tissue\nwas cropped out and is learned to be inpainted again. This allows us to use the\nground truth healthy tissue during training. In the sampling stage, we replace\nthe slices containing diseased tissue in the original 3D volume with the slices\ncontaining the healthy tissue inpainting. With our approach, we achieve\ncomparable results to the competing methods. On the validation set our model\nachieves a mean SSIM of 0.7804, a PSNR of 20.3525 and a MSE of 0.0113. In\nfuture we plan to extend our 2D model to a 3D model, allowing to inpaint the\nregion of interest as a whole without losing context information of neighboring\nslices.\n","authors":["Alicia Durrer","Philippe C. Cattin","Julia Wolleb"],"pdf_url":"https://arxiv.org/pdf/2402.17307v2.pdf","comment":"12 pages, 5 figures, MICCAI challenge submission"},{"id":"http://arxiv.org/abs/2410.17920v1","updated":"2024-10-23T14:38:57Z","published":"2024-10-23T14:38:57Z","title":"Gaze-Assisted Medical Image Segmentation","summary":"  The annotation of patient organs is a crucial part of various diagnostic and\ntreatment procedures, such as radiotherapy planning. Manual annotation is\nextremely time-consuming, while its automation using modern image analysis\ntechniques has not yet reached levels sufficient for clinical adoption. This\npaper investigates the idea of semi-supervised medical image segmentation using\nhuman gaze as interactive input for segmentation correction. In particular, we\nfine-tuned the Segment Anything Model in Medical Images (MedSAM), a public\nsolution that uses various prompt types as additional input for semi-automated\nsegmentation correction. We used human gaze data from reading abdominal images\nas a prompt for fine-tuning MedSAM. The model was validated on a public WORD\ndatabase, which consists of 120 CT scans of 16 abdominal organs. The results of\nthe gaze-assisted MedSAM were shown to be superior to the results of the\nstate-of-the-art segmentation models. In particular, the average Dice\ncoefficient for 16 abdominal organs was 85.8%, 86.7%, 81.7%, and 90.5% for\nnnUNetV2, ResUNet, original MedSAM, and our gaze-assisted MedSAM model,\nrespectively.\n","authors":["Leila Khaertdinova","Ilya Pershin","Tatiana Shmykova","Bulat Ibragimov"],"pdf_url":"https://arxiv.org/pdf/2410.17920v1.pdf","comment":"16 pages, 4 figures, Accepted to AIM-FM Workshop @ NeurIPS'24"},{"id":"http://arxiv.org/abs/2410.17918v1","updated":"2024-10-23T14:34:39Z","published":"2024-10-23T14:34:39Z","title":"Addressing Asynchronicity in Clinical Multimodal Fusion via\n  Individualized Chest X-ray Generation","summary":"  Integrating multi-modal clinical data, such as electronic health records\n(EHR) and chest X-ray images (CXR), is particularly beneficial for clinical\nprediction tasks. However, in a temporal setting, multi-modal data are often\ninherently asynchronous. EHR can be continuously collected but CXR is generally\ntaken with a much longer interval due to its high cost and radiation dose. When\nclinical prediction is needed, the last available CXR image might have been\noutdated, leading to suboptimal predictions. To address this challenge, we\npropose DDL-CXR, a method that dynamically generates an up-to-date latent\nrepresentation of the individualized CXR images. Our approach leverages latent\ndiffusion models for patient-specific generation strategically conditioned on a\nprevious CXR image and EHR time series, providing information regarding\nanatomical structures and disease progressions, respectively. In this way, the\ninteraction across modalities could be better captured by the latent CXR\ngeneration process, ultimately improving the prediction performance.\nExperiments using MIMIC datasets show that the proposed model could effectively\naddress asynchronicity in multimodal fusion and consistently outperform\nexisting methods.\n","authors":["Wenfang Yao","Chen Liu","Kejing Yin","William K. Cheung","Jing Qin"],"pdf_url":"https://arxiv.org/pdf/2410.17918v1.pdf","comment":"Accepted by NeurIPS-24"},{"id":"http://arxiv.org/abs/2403.08511v3","updated":"2024-10-23T14:21:40Z","published":"2024-03-13T13:16:26Z","title":"A Multimodal Fusion Network For Student Emotion Recognition Based on\n  Transformer and Tensor Product","summary":"  This paper introduces a new multi-modal model based on the Transformer\narchitecture and tensor product fusion strategy, combining BERT's text vectors\nand ViT's image vectors to classify students' psychological conditions, with an\naccuracy of 93.65%. The purpose of the study is to accurately analyze the\nmental health status of students from various data sources. This paper\ndiscusses modal fusion methods, including early, late and intermediate fusion,\nto overcome the challenges of integrating multi-modal information. Ablation\nstudies compare the performance of different models and fusion techniques,\nshowing that the proposed model outperforms existing methods such as CLIP and\nViLBERT in terms of accuracy and inference speed. Conclusions indicate that\nwhile this model has significant advantages in emotion recognition, its\npotential to incorporate other data modalities provides areas for future\nresearch.\n","authors":["Ao Xiang","Zongqing Qi","Han Wang","Qin Yang","Danqing Ma"],"pdf_url":"https://arxiv.org/pdf/2403.08511v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2409.19472v2","updated":"2024-10-23T14:02:12Z","published":"2024-09-28T22:41:49Z","title":"Towards Croppable Implicit Neural Representations","summary":"  Implicit Neural Representations (INRs) have peaked interest in recent years\ndue to their ability to encode natural signals using neural networks. While\nINRs allow for useful applications such as interpolating new coordinates and\nsignal compression, their black-box nature makes it difficult to modify them\npost-training. In this paper we explore the idea of editable INRs, and\nspecifically focus on the widely used cropping operation. To this end, we\npresent Local-Global SIRENs -- a novel INR architecture that supports cropping\nby design. Local-Global SIRENs are based on combining local and global feature\nextraction for signal encoding. What makes their design unique is the ability\nto effortlessly remove specific portions of an encoded signal, with a\nproportional weight decrease. This is achieved by eliminating the corresponding\nweights from the network, without the need for retraining. We further show how\nthis architecture can be used to support the straightforward extension of\npreviously encoded signals. Beyond signal editing, we examine how the\nLocal-Global approach can accelerate training, enhance encoding of various\nsignals, improve downstream performance, and be applied to modern INRs such as\nINCODE, highlighting its potential and flexibility. Code is available at\nhttps://github.com/maorash/Local-Global-INRs.\n","authors":["Maor Ashkenazi","Eran Treister"],"pdf_url":"https://arxiv.org/pdf/2409.19472v2.pdf","comment":"Accepted to NeurIPS 2024"},{"id":"http://arxiv.org/abs/2408.06927v2","updated":"2024-10-23T14:01:27Z","published":"2024-08-13T14:29:00Z","title":"Breaking Class Barriers: Efficient Dataset Distillation via Inter-Class\n  Feature Compensator","summary":"  Dataset distillation has emerged as a technique aiming to condense\ninformative features from large, natural datasets into a compact and synthetic\nform. While recent advancements have refined this technique, its performance is\nbottlenecked by the prevailing class-specific synthesis paradigm. Under this\nparadigm, synthetic data is optimized exclusively for a pre-assigned one-hot\nlabel, creating an implicit class barrier in feature condensation. This leads\nto inefficient utilization of the distillation budget and oversight of\ninter-class feature distributions, which ultimately limits the effectiveness\nand efficiency, as demonstrated in our analysis. To overcome these constraints,\nthis paper presents the Inter-class Feature Compensator (INFER), an innovative\ndistillation approach that transcends the class-specific data-label framework\nwidely utilized in current dataset distillation methods. Specifically, INFER\nleverages a Universal Feature Compensator (UFC) to enhance feature integration\nacross classes, enabling the generation of multiple additional synthetic\ninstances from a single UFC input. This significantly improves the efficiency\nof the distillation budget. Moreover, INFER enriches inter-class interactions\nduring the distillation, thereby enhancing the effectiveness and\ngeneralizability of the distilled data. By allowing for the linear\ninterpolation of labels similar to those in the original dataset, INFER\nmeticulously optimizes the synthetic data and dramatically reduces the size of\nsoft labels in the synthetic dataset to almost zero, establishing a new\nbenchmark for efficiency and effectiveness in dataset distillation.\n","authors":["Xin Zhang","Jiawei Du","Ping Liu","Joey Tianyi Zhou"],"pdf_url":"https://arxiv.org/pdf/2408.06927v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.17885v1","updated":"2024-10-23T13:58:39Z","published":"2024-10-23T13:58:39Z","title":"R-CoT: Reverse Chain-of-Thought Problem Generation for Geometric\n  Reasoning in Large Multimodal Models","summary":"  Existing Large Multimodal Models (LMMs) struggle with mathematical geometric\nreasoning due to a lack of high-quality image-text paired data. Current\ngeometric data generation approaches, which apply preset templates to generate\ngeometric data or use Large Language Models (LLMs) to rephrase questions and\nanswers (Q&A), unavoidably limit data accuracy and diversity. To synthesize\nhigher-quality data, we propose a two-stage Reverse Chain-of-Thought (R-CoT)\ngeometry problem generation pipeline. First, we introduce GeoChain to produce\nhigh-fidelity geometric images and corresponding descriptions highlighting\nrelations among geometric elements. We then design a Reverse A&Q method that\nreasons step-by-step based on the descriptions and generates questions in\nreverse from the reasoning results. Experiments demonstrate that the proposed\nmethod brings significant and consistent improvements on multiple LMM\nbaselines, achieving new performance records in the 2B, 7B, and 8B settings.\nNotably, R-CoT-8B significantly outperforms previous state-of-the-art\nopen-source mathematical models by 16.6% on MathVista and 9.2% on GeoQA, while\nalso surpassing the closed-source model GPT-4o by an average of 13% across both\ndatasets. The code is available at https://github.com/dle666/R-CoT.\n","authors":["Linger Deng","Yuliang Liu","Bohan Li","Dongliang Luo","Liang Wu","Chengquan Zhang","Pengyuan Lyu","Ziyang Zhang","Gang Zhang","Errui Ding","Yingying Zhu","Xiang Bai"],"pdf_url":"https://arxiv.org/pdf/2410.17885v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.17880v1","updated":"2024-10-23T13:52:22Z","published":"2024-10-23T13:52:22Z","title":"A utility-based spatial analysis of residential street-level conditions;\n  A case study of Rotterdam","summary":"  Residential location choices are traditionally modelled using factors related\nto accessibility and socioeconomic environments, neglecting the importance of\nlocal street-level conditions. Arguably, this neglect is due to data practices.\nToday, however, street-level images -- which are highly effective at encoding\nstreet-level conditions -- are widely available. Additionally, recent advances\nin discrete choice models incorporating computer vision capabilities offer\nopportunities to integrate street-level conditions into residential location\nchoice analysis. This study leverages these developments to investigate the\nspatial distribution of utility derived from street-level conditions in\nresidential location choices on a city-wide scale. In our case study of\nRotterdam, the Netherlands, we find that the utility derived from street-level\nconditions varies significantly on a highly localised scale, with conditions\nrapidly changing even within neighbourhoods. Our results also reveal that the\nhigh real-estate prices in the city centre cannot be attributed to attractive\nstreet-level conditions. Furthermore, whereas the city centre is characterised\nby relatively unattractive residential street-level conditions, neighbourhoods\nin the southern part of the city -- often perceived as problematic -- exhibit\nsurprisingly appealing street-level environments. The methodological\ncontribution of this paper is that it advances the discrete choice models\nincorporating computer vision capabilities by introducing a semantic\nregularisation layer to the model. Thereby, it adds explainability and\neliminates the need for a separate pipeline to extract information from images,\nstreamlining the analysis. As such, this paper's findings and methodological\nadvancements pave the way for further studies to explore integrating\nstreet-level conditions in urban planning.\n","authors":["Sander van Cranenburgh","Francisco Garrido-Valenzuela"],"pdf_url":"https://arxiv.org/pdf/2410.17880v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.17863v1","updated":"2024-10-23T13:35:18Z","published":"2024-10-23T13:35:18Z","title":"CASCRNet: An Atrous Spatial Pyramid Pooling and Shared Channel Residual\n  based Network for Capsule Endoscopy","summary":"  This manuscript summarizes work on the Capsule Vision Challenge 2024 by\nMISAHUB. To address the multi-class disease classification task, which is\nchallenging due to the complexity and imbalance in the Capsule Vision challenge\ndataset, this paper proposes CASCRNet (Capsule endoscopy-Aspp-SCR-Network), a\nparameter-efficient and novel model that uses Shared Channel Residual (SCR)\nblocks and Atrous Spatial Pyramid Pooling (ASPP) blocks. Further, the\nperformance of the proposed model is compared with other well-known approaches.\nThe experimental results yield that proposed model provides better disease\nclassification results. The proposed model was successful in classifying\ndiseases with an F1 Score of 78.5% and a Mean AUC of 98.3%, which is promising\ngiven its compact architecture.\n","authors":["K V Srinanda","M Manvith Prabhu","Shyam Lal"],"pdf_url":"https://arxiv.org/pdf/2410.17863v1.pdf","comment":"8 pages, 4 figures"},{"id":"http://arxiv.org/abs/2410.17858v1","updated":"2024-10-23T13:29:02Z","published":"2024-10-23T13:29:02Z","title":"Blendify -- Python rendering framework for Blender","summary":"  With the rapid growth of the volume of research fields like computer vision\nand computer graphics, researchers require effective and user-friendly\nrendering tools to visualize results. While advanced tools like Blender offer\npowerful capabilities, they also require a significant effort to master. This\ntechnical report introduces Blendify, a lightweight Python-based framework that\nseamlessly integrates with Blender, providing a high-level API for scene\ncreation and rendering. Blendify reduces the complexity of working with\nBlender's native API by automating object creation, handling the colors and\nmaterial linking, and implementing features such as shadow-catcher objects\nwhile maintaining support for high-quality ray-tracing rendering output. With a\nfocus on usability Blendify enables efficient and flexible rendering workflow\nfor rendering in common computer vision and computer graphics use cases. The\ncode is available at https://github.com/ptrvilya/blendify\n","authors":["Vladimir Guzov","Ilya A. Petrov","Gerard Pons-Moll"],"pdf_url":"https://arxiv.org/pdf/2410.17858v1.pdf","comment":"Project page: https://virtualhumans.mpi-inf.mpg.de/blendify/"},{"id":"http://arxiv.org/abs/2410.17856v1","updated":"2024-10-23T13:26:59Z","published":"2024-10-23T13:26:59Z","title":"ROCKET-1: Master Open-World Interaction with Visual-Temporal Context\n  Prompting","summary":"  Vision-language models (VLMs) have excelled in multimodal tasks, but adapting\nthem to embodied decision-making in open-world environments presents\nchallenges. A key issue is the difficulty in smoothly connecting individual\nentities in low-level observations with abstract concepts required for\nplanning. A common approach to address this problem is through the use of\nhierarchical agents, where VLMs serve as high-level reasoners that break down\ntasks into executable sub-tasks, typically specified using language and\nimagined observations. However, language often fails to effectively convey\nspatial information, while generating future images with sufficient accuracy\nremains challenging. To address these limitations, we propose visual-temporal\ncontext prompting, a novel communication protocol between VLMs and policy\nmodels. This protocol leverages object segmentation from both past and present\nobservations to guide policy-environment interactions. Using this approach, we\ntrain ROCKET-1, a low-level policy that predicts actions based on concatenated\nvisual observations and segmentation masks, with real-time object tracking\nprovided by SAM-2. Our method unlocks the full potential of VLMs\nvisual-language reasoning abilities, enabling them to solve complex creative\ntasks, especially those heavily reliant on spatial understanding. Experiments\nin Minecraft demonstrate that our approach allows agents to accomplish\npreviously unattainable tasks, highlighting the effectiveness of\nvisual-temporal context prompting in embodied decision-making. Codes and demos\nwill be available on the project page: https://craftjarvis.github.io/ROCKET-1.\n","authors":["Shaofei Cai","Zihao Wang","Kewei Lian","Zhancun Mu","Xiaojian Ma","Anji Liu","Yitao Liang"],"pdf_url":"https://arxiv.org/pdf/2410.17856v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.17855v1","updated":"2024-10-23T13:26:19Z","published":"2024-10-23T13:26:19Z","title":"TAGE: Trustworthy Attribute Group Editing for Stable Few-shot Image\n  Generation","summary":"  Generative Adversarial Networks (GANs) have emerged as a prominent research\nfocus for image editing tasks, leveraging the powerful image generation\ncapabilities of the GAN framework to produce remarkable results.However,\nprevailing approaches are contingent upon extensive training datasets and\nexplicit supervision, presenting a significant challenge in manipulating the\ndiverse attributes of new image classes with limited sample availability. To\nsurmount this hurdle, we introduce TAGE, an innovative image generation network\ncomprising three integral modules: the Codebook Learning Module (CLM), the Code\nPrediction Module (CPM) and the Prompt-driven Semantic Module (PSM). The CPM\nmodule delves into the semantic dimensions of category-agnostic attributes,\nencapsulating them within a discrete codebook. This module is predicated on the\nconcept that images are assemblages of attributes, and thus, by editing these\ncategory-independent attributes, it is theoretically possible to generate\nimages from unseen categories. Subsequently, the CPM module facilitates\nnaturalistic image editing by predicting indices of category-independent\nattribute vectors within the codebook. Additionally, the PSM module generates\nsemantic cues that are seamlessly integrated into the Transformer architecture\nof the CPM, enhancing the model's comprehension of the targeted attributes for\nediting. With these semantic cues, the model can generate images that\naccentuate desired attributes more prominently while maintaining the integrity\nof the original category, even with a limited number of samples. We have\nconducted extensive experiments utilizing the Animal Faces, Flowers, and\nVGGFaces datasets. The results of these experiments demonstrate that our\nproposed method not only achieves superior performance but also exhibits a high\ndegree of stability when compared to other few-shot image generation\ntechniques.\n","authors":["Ruicheng Zhang","Guoheng Huang","Yejing Huo","Xiaochen Yuan","Zhizhen Zhou","Xuhang Chen","Guo Zhong"],"pdf_url":"https://arxiv.org/pdf/2410.17855v1.pdf","comment":"Accepted by International Conference on Signal Processing Systems\n  Conference"},{"id":"http://arxiv.org/abs/2410.15613v2","updated":"2024-10-23T13:07:41Z","published":"2024-10-21T03:17:25Z","title":"Exploring Stronger Transformer Representation Learning for Occluded\n  Person Re-Identification","summary":"  Due to some complex factors (e.g., occlusion, pose variation and diverse\ncamera perspectives), extracting stronger feature representation in person\nre-identification remains a challenging task. In this paper, we proposed a\nnovel self-supervision and supervision combining transformer-based person\nre-identification framework, namely SSSC-TransReID. Different from the general\ntransformer-based person re-identification models, we designed a\nself-supervised contrastive learning branch, which can enhance the feature\nrepresentation for person re-identification without negative samples or\nadditional pre-training. In order to train the contrastive learning branch, we\nalso proposed a novel random rectangle mask strategy to simulate the occlusion\nin real scenes, so as to enhance the feature representation for occlusion.\nFinally, we utilized the joint-training loss function to integrate the\nadvantages of supervised learning with ID tags and self-supervised contrastive\nlearning without negative samples, which can reinforce the ability of our model\nto excavate stronger discriminative features, especially for occlusion.\nExtensive experimental results on several benchmark datasets show our proposed\nmodel obtains superior Re-ID performance consistently and outperforms the\nstate-of-the-art ReID methods by large margins on the mean average accuracy\n(mAP) and Rank-1 accuracy.\n","authors":["Zhangjian Ji","Donglin Cheng","Kai Feng"],"pdf_url":"https://arxiv.org/pdf/2410.15613v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.17839v1","updated":"2024-10-23T13:05:26Z","published":"2024-10-23T13:05:26Z","title":"Few-shot NeRF by Adaptive Rendering Loss Regularization","summary":"  Novel view synthesis with sparse inputs poses great challenges to Neural\nRadiance Field (NeRF). Recent works demonstrate that the frequency\nregularization of Positional Encoding (PE) can achieve promising results for\nfew-shot NeRF. In this work, we reveal that there exists an inconsistency\nbetween the frequency regularization of PE and rendering loss. This prevents\nfew-shot NeRF from synthesizing higher-quality novel views. To mitigate this\ninconsistency, we propose Adaptive Rendering loss regularization for few-shot\nNeRF, dubbed AR-NeRF. Specifically, we present a two-phase rendering\nsupervision and an adaptive rendering loss weight learning strategy to align\nthe frequency relationship between PE and 2D-pixel supervision. In this way,\nAR-NeRF can learn global structures better in the early training phase and\nadaptively learn local details throughout the training process. Extensive\nexperiments show that our AR-NeRF achieves state-of-the-art performance on\ndifferent datasets, including object-level and complex scenes.\n","authors":["Qingshan Xu","Xuanyu Yi","Jianyao Xu","Wenbing Tao","Yew-Soon Ong","Hanwang Zhang"],"pdf_url":"https://arxiv.org/pdf/2410.17839v1.pdf","comment":"Accepted by ECCV2024"},{"id":"http://arxiv.org/abs/2410.13896v2","updated":"2024-10-23T13:01:22Z","published":"2024-10-15T02:41:52Z","title":"From Real Artifacts to Virtual Reference: A Robust Framework for\n  Translating Endoscopic Images","summary":"  Domain adaptation, which bridges the distributions across different\nmodalities, plays a crucial role in multimodal medical image analysis. In\nendoscopic imaging, combining pre-operative data with intra-operative imaging\nis important for surgical planning and navigation. However, existing domain\nadaptation methods are hampered by distribution shift caused by in vivo\nartifacts, necessitating robust techniques for aligning noisy and artifact\nabundant patient endoscopic videos with clean virtual images reconstructed from\npre-operative tomographic data for pose estimation during intraoperative\nguidance. This paper presents an artifact-resilient image translation method\nand an associated benchmark for this purpose. The method incorporates a novel\n``local-global'' translation framework and a noise-resilient feature extraction\nstrategy. For the former, it decouples the image translation process into a\nlocal step for feature denoising, and a global step for global style transfer.\nFor feature extraction, a new contrastive learning strategy is proposed, which\ncan extract noise-resilient features for establishing robust correspondence\nacross domains. Detailed validation on both public and in-house clinical\ndatasets has been conducted, demonstrating significantly improved performance\ncompared to the current state-of-the-art.\n","authors":["Junyang Wu","Fangfang Xie","Jiayuan Sun","Yun Gu","Guang-Zhong Yang"],"pdf_url":"https://arxiv.org/pdf/2410.13896v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.14774v2","updated":"2024-10-23T13:01:14Z","published":"2024-03-21T18:28:43Z","title":"Few-Shot Adversarial Prompt Learning on Vision-Language Models","summary":"  The vulnerability of deep neural networks to imperceptible adversarial\nperturbations has attracted widespread attention. Inspired by the success of\nvision-language foundation models, previous efforts achieved zero-shot\nadversarial robustness by aligning adversarial visual features with text\nsupervision. However, in practice, they are still unsatisfactory due to several\nissues, including heavy adaptation cost, suboptimal text supervision, and\nuncontrolled natural generalization capacity. In this paper, to address these\nissues, we propose a few-shot adversarial prompt framework where adapting input\nsequences with limited data makes significant adversarial robustness\nimprovement. Specifically, we achieve this by providing adversarially\ncorrelated text supervision that is end-to-end learned from adversarial\nexamples. We also propose a novel training objective that enhances the\nconsistency of multi-modal features while encourages differentiated uni-modal\nfeatures between natural and adversarial examples. The proposed framework gives\naccess to learn adversarial text supervision, which provides superior\ncross-modal adversarial alignment and matches state-of-the-art zero-shot\nadversarial robustness with only 1% training data. Code is available at:\nhttps://github.com/lionel-w2/FAP.\n","authors":["Yiwei Zhou","Xiaobo Xia","Zhiwei Lin","Bo Han","Tongliang Liu"],"pdf_url":"https://arxiv.org/pdf/2403.14774v2.pdf","comment":"NeurIPS 2024"},{"id":"http://arxiv.org/abs/2405.13152v3","updated":"2024-10-23T12:56:05Z","published":"2024-05-21T18:45:18Z","title":"Enhancing Interaction Modeling with Agent Selection and Physical\n  Coefficient for Trajectory Prediction","summary":"  A thorough understanding of the interaction between the target agent and\nsurrounding agents is a prerequisite for accurate trajectory prediction.\nAlthough many methods have been explored, they all assign correlation\ncoefficients to surrounding agents in a purely learning-based manner. In this\nstudy, we present ASPILin, which manually selects interacting agents and\ncalculates their correlations instead of attention scores. Surprisingly, these\nsimple modifications can significantly improve prediction performance and\nsubstantially reduce computational costs. Additionally, ASPILin models the\ninteracting agents at each past time step separately, rather than only modeling\nthe interacting agents at the current time step. This clarifies the causal\nchain of the target agent's historical trajectory and helps the model better\nunderstand dynamic interactions. We intentionally simplified our model in other\naspects, such as map encoding. Remarkably, experiments conducted on the\nINTERACTION, highD, and CitySim datasets demonstrate that our method is\nefficient and straightforward, outperforming other state-of-the-art methods.\n","authors":["Shiji Huang","Lei Ye","Min Chen","Wenhai Luo","Dihong Wang","Chenqi Xu","Deyuan Liang"],"pdf_url":"https://arxiv.org/pdf/2405.13152v3.pdf","comment":"code:https://github.com/kkk00714/ASPILin"},{"id":"http://arxiv.org/abs/2410.17832v1","updated":"2024-10-23T12:51:07Z","published":"2024-10-23T12:51:07Z","title":"Exploiting Text-Image Latent Spaces for the Description of Visual\n  Concepts","summary":"  Concept Activation Vectors (CAVs) offer insights into neural network\ndecision-making by linking human friendly concepts to the model's internal\nfeature extraction process. However, when a new set of CAVs is discovered, they\nmust still be translated into a human understandable description. For\nimage-based neural networks, this is typically done by visualizing the most\nrelevant images of a CAV, while the determination of the concept is left to\nhumans. In this work, we introduce an approach to aid the interpretation of\nnewly discovered concept sets by suggesting textual descriptions for each CAV.\nThis is done by mapping the most relevant images representing a CAV into a\ntext-image embedding where a joint description of these relevant images can be\ncomputed. We propose utilizing the most relevant receptive fields instead of\nfull images encoded. We demonstrate the capabilities of this approach in\nmultiple experiments with and without given CAV labels, showing that the\nproposed approach provides accurate descriptions for the CAVs and reduces the\nchallenge of concept interpretation.\n","authors":["Laines Schmalwasser","Jakob Gawlikowski","Joachim Denzler","Julia Niebling"],"pdf_url":"https://arxiv.org/pdf/2410.17832v1.pdf","comment":"19 pages, 7 figures, to be published in ICPR"},{"id":"http://arxiv.org/abs/2210.01708v4","updated":"2024-10-23T12:50:18Z","published":"2022-10-04T16:08:54Z","title":"Conquering the Communication Constraints to Enable Large Pre-Trained\n  Models in Federated Learning","summary":"  Federated learning (FL) has emerged as a promising paradigm for enabling the\ncollaborative training of models without centralized access to the raw data on\nlocal devices. In the typical FL paradigm (e.g., FedAvg), model weights are\nsent to and from the server each round to participating clients. Recently, the\nuse of small pre-trained models has been shown effective in federated learning\noptimization and improving convergence. However, recent state-of-the-art\npre-trained models are getting more capable but also have more parameters. In\nconventional FL, sharing the enormous model weights can quickly put a massive\ncommunication burden on the system, especially if more capable models are\nemployed. Can we find a solution to enable those strong and readily-available\npre-trained models in FL to achieve excellent performance while simultaneously\nreducing the communication burden? To this end, we investigate the use of\nparameter-efficient fine-tuning in federated learning and thus introduce a new\nframework: FedPEFT. Specifically, we systemically evaluate the performance of\nFedPEFT across a variety of client stability, data distribution, and\ndifferential privacy settings. By only locally tuning and globally sharing a\nsmall portion of the model weights, significant reductions in the total\ncommunication overhead can be achieved while maintaining competitive or even\nbetter performance in a wide range of federated learning scenarios, providing\ninsight into a new paradigm for practical and effective federated systems.\n","authors":["Guangyu Sun","Umar Khalid","Matias Mendieta","Taojiannan Yang","Pu Wang","Minwoo Lee","Chen Chen"],"pdf_url":"https://arxiv.org/pdf/2210.01708v4.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.17823v1","updated":"2024-10-23T12:32:21Z","published":"2024-10-23T12:32:21Z","title":"Att2CPC: Attention-Guided Lossy Attribute Compression of Point Clouds","summary":"  With the great progress of 3D sensing and acquisition technology, the volume\nof point cloud data has grown dramatically, which urges the development of\nefficient point cloud compression methods. In this paper, we focus on the task\nof learned lossy point cloud attribute compression (PCAC). We propose an\nefficient attention-based method for lossy compression of point cloud\nattributes leveraging on an autoencoder architecture. Specifically, at the\nencoding side, we conduct multiple downsampling to best exploit the local\nattribute patterns, in which effective External Cross Attention (ECA) is\ndevised to hierarchically aggregate features by intergrating attributes and\ngeometry contexts. At the decoding side, the attributes of the point cloud are\nprogressively reconstructed based on the multi-scale representation and the\nzero-padding upsampling tactic. To the best of our knowledge, this is the first\napproach to introduce attention mechanism to point-based lossy PCAC task. We\nverify the compression efficiency of our model on various sequences, including\nhuman body frames, sparse objects, and large-scale point cloud scenes.\nExperiments show that our method achieves an average improvement of 1.15 dB and\n2.13 dB in BD-PSNR of Y channel and YUV channel, respectively, when comparing\nwith the state-of-the-art point-based method Deep-PCAC. Codes of this paper are\navailable at https://github.com/I2-Multimedia-Lab/Att2CPC.\n","authors":["Kai Liu","Kang You","Pan Gao","Manoranjan Paul"],"pdf_url":"https://arxiv.org/pdf/2410.17823v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.17822v1","updated":"2024-10-23T12:32:20Z","published":"2024-10-23T12:32:20Z","title":"DREB-Net: Dual-stream Restoration Embedding Blur-feature Fusion Network\n  for High-mobility UAV Object Detection","summary":"  Object detection algorithms are pivotal components of unmanned aerial vehicle\n(UAV) imaging systems, extensively employed in complex fields. However, images\ncaptured by high-mobility UAVs often suffer from motion blur cases, which\nsignificantly impedes the performance of advanced object detection algorithms.\nTo address these challenges, we propose an innovative object detection\nalgorithm specifically designed for blurry images, named DREB-Net (Dual-stream\nRestoration Embedding Blur-feature Fusion Network). First, DREB-Net addresses\nthe particularities of blurry image object detection problem by incorporating a\nBlurry image Restoration Auxiliary Branch (BRAB) during the training phase.\nSecond, it fuses the extracted shallow features via Multi-level\nAttention-Guided Feature Fusion (MAGFF) module, to extract richer features.\nHere, the MAGFF module comprises local attention modules and global attention\nmodules, which assign different weights to the branches. Then, during the\ninference phase, the deep feature extraction of the BRAB can be removed to\nreduce computational complexity and improve detection speed. In loss function,\na combined loss of MSE and SSIM is added to the BRAB to restore blurry images.\nFinally, DREB-Net introduces Fast Fourier Transform in the early stages of\nfeature extraction, via a Learnable Frequency domain Amplitude Modulation\nModule (LFAMM), to adjust feature amplitude and enhance feature processing\ncapability. Experimental results indicate that DREB-Net can still effectively\nperform object detection tasks under motion blur in captured images, showcasing\nexcellent performance and broad application prospects. Our source code will be\navailable at https://github.com/EEIC-Lab/DREB-Net.git.\n","authors":["Qingpeng Li","Yuxin Zhang","Leyuan Fang","Yuhan Kang","Shutao Li","Xiao Xiang Zhu"],"pdf_url":"https://arxiv.org/pdf/2410.17822v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.17816v1","updated":"2024-10-23T12:19:12Z","published":"2024-10-23T12:19:12Z","title":"Deep Learning for Active Region Classification: A Systematic Study from\n  Convolutional Neural Networks to Vision Transformers","summary":"  A solar active region can significantly disrupt the Sun Earth space\nenvironment, often leading to severe space weather events such as solar flares\nand coronal mass ejections. As a consequence, the automatic classification of\nactive region groups is the crucial starting point for accurately and promptly\npredicting solar activity. This study presents our results concerned with the\napplication of deep learning techniques to the classification of active region\ncutouts based on the Mount Wilson classification scheme. Specifically, we have\nexplored the latest advancements in image classification architectures, from\nConvolutional Neural Networks to Vision Transformers, and reported on their\nperformances for the active region classification task, showing that the\ncrucial point for their effectiveness consists in a robust training process\nbased on the latest advances in the field.\n","authors":["Edoardo Legnaro","Sabrina Guastavino","Michele Piana","Anna Maria Massone"],"pdf_url":"https://arxiv.org/pdf/2410.17816v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.17814v1","updated":"2024-10-23T12:18:36Z","published":"2024-10-23T12:18:36Z","title":"Learning Lossless Compression for High Bit-Depth Volumetric Medical\n  Image","summary":"  Recent advances in learning-based methods have markedly enhanced the\ncapabilities of image compression. However, these methods struggle with high\nbit-depth volumetric medical images, facing issues such as degraded\nperformance, increased memory demand, and reduced processing speed. To address\nthese challenges, this paper presents the Bit-Division based Lossless\nVolumetric Image Compression (BD-LVIC) framework, which is tailored for high\nbit-depth medical volume compression. The BD-LVIC framework skillfully divides\nthe high bit-depth volume into two lower bit-depth segments: the Most\nSignificant Bit-Volume (MSBV) and the Least Significant Bit-Volume (LSBV). The\nMSBV concentrates on the most significant bits of the volumetric medical image,\ncapturing vital structural details in a compact manner. This reduction in\ncomplexity greatly improves compression efficiency using traditional codecs.\nConversely, the LSBV deals with the least significant bits, which encapsulate\nintricate texture details. To compress this detailed information effectively,\nwe introduce an effective learning-based compression model equipped with a\nTransformer-Based Feature Alignment Module, which exploits both intra-slice and\ninter-slice redundancies to accurately align features. Subsequently, a Parallel\nAutoregressive Coding Module merges these features to precisely estimate the\nprobability distribution of the least significant bit-planes. Our extensive\ntesting demonstrates that the BD-LVIC framework not only sets new performance\nbenchmarks across various datasets but also maintains a competitive coding\nspeed, highlighting its significant potential and practical utility in the\nrealm of volumetric medical image compression.\n","authors":["Kai Wang","Yuanchao Bai","Daxin Li","Deming Zhai","Junjun Jiang","Xianming Liu"],"pdf_url":"https://arxiv.org/pdf/2410.17814v1.pdf","comment":"13 pages"},{"id":"http://arxiv.org/abs/2410.17812v1","updated":"2024-10-23T12:17:03Z","published":"2024-10-23T12:17:03Z","title":"PGDiffSeg: Prior-Guided Denoising Diffusion Model with Parameter-Shared\n  Attention for Breast Cancer Segmentation","summary":"  Early detection through imaging and accurate diagnosis is crucial in\nmitigating the high mortality rate associated with breast cancer. However,\nlocating tumors from low-resolution and high-noise medical images is extremely\nchallenging. Therefore, this paper proposes a novel PGDiffSeg (Prior-Guided\nDiffusion Denoising Model with Parameter-Shared Attention) that applies\ndiffusion denoising methods to breast cancer medical image segmentation,\naccurately recovering the affected areas from Gaussian noise. Firstly, we\ndesign a parallel pipeline for noise processing and semantic information\nprocessing and propose a parameter-shared attention module (PSA) in multi-layer\nthat seamlessly integrates these two pipelines. This integration empowers\nPGDiffSeg to incorporate semantic details at multiple levels during the\ndenoising process, producing highly accurate segmentation maps. Secondly, we\nintroduce a guided strategy that leverages prior knowledge to simulate the\ndecision-making process of medical professionals, thereby enhancing the model's\nability to locate tumor positions precisely. Finally, we provide the first-ever\ndiscussion on the interpretability of the generative diffusion model in the\ncontext of breast cancer segmentation. Extensive experiments have demonstrated\nthe superiority of our model over the current state-of-the-art approaches,\nconfirming its effectiveness as a flexible diffusion denoising method suitable\nfor medical image research. Our code will be publicly available later.\n","authors":["Feiyan Feng","Tianyu Liu","Hong Wang","Jun Zhao","Wei Li","Yanshen Sun"],"pdf_url":"https://arxiv.org/pdf/2410.17812v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.17810v1","updated":"2024-10-23T12:12:56Z","published":"2024-10-23T12:12:56Z","title":"EntityCLIP: Entity-Centric Image-Text Matching via Multimodal Attentive\n  Contrastive Learning","summary":"  Recent advancements in image-text matching have been notable, yet prevailing\nmodels predominantly cater to broad queries and struggle with accommodating\nfine-grained query intention. In this paper, we work towards the\n\\textbf{E}ntity-centric \\textbf{I}mage-\\textbf{T}ext \\textbf{M}atching (EITM),\na task that the text and image involve specific entity-related information. The\nchallenge of this task mainly lies in the larger semantic gap in entity\nassociation modeling, comparing with the general image-text matching problem.To\nnarrow the huge semantic gap between the entity-centric text and the images, we\ntake the fundamental CLIP as the backbone and devise a multimodal attentive\ncontrastive learning framework to tam CLIP to adapt EITM problem, developing a\nmodel named EntityCLIP. The key of our multimodal attentive contrastive\nlearning is to generate interpretive explanation text using Large Language\nModels (LLMs) as the bridge clues. In specific, we proceed by extracting\nexplanatory text from off-the-shelf LLMs. This explanation text, coupled with\nthe image and text, is then input into our specially crafted Multimodal\nAttentive Experts (MMAE) module, which effectively integrates explanation texts\nto narrow the gap of the entity-related text and image in a shared semantic\nspace. Building on the enriched features derived from MMAE, we further design\nan effective Gated Integrative Image-text Matching (GI-ITM) strategy. The\nGI-ITM employs an adaptive gating mechanism to aggregate MMAE's features,\nsubsequently applying image-text matching constraints to steer the alignment\nbetween the text and the image. Extensive experiments are conducted on three\nsocial media news benchmarks including N24News, VisualNews, and GoodNews, the\nresults shows that our method surpasses the competition methods with a clear\nmargin.\n","authors":["Yaxiong Wang","Yaxiong Wang","Lianwei Wu","Lechao Cheng","Zhun Zhong","Meng Wang"],"pdf_url":"https://arxiv.org/pdf/2410.17810v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.17809v1","updated":"2024-10-23T12:11:26Z","published":"2024-10-23T12:11:26Z","title":"An Intelligent Agentic System for Complex Image Restoration Problems","summary":"  Real-world image restoration (IR) is inherently complex and often requires\ncombining multiple specialized models to address diverse degradations. Inspired\nby human problem-solving, we propose AgenticIR, an agentic system that mimics\nthe human approach to image processing by following five key stages:\nPerception, Scheduling, Execution, Reflection, and Rescheduling. AgenticIR\nleverages large language models (LLMs) and vision-language models (VLMs) that\ninteract via text generation to dynamically operate a toolbox of IR models. We\nfine-tune VLMs for image quality analysis and employ LLMs for reasoning,\nguiding the system step by step. To compensate for LLMs' lack of specific IR\nknowledge and experience, we introduce a self-exploration method, allowing the\nLLM to observe and summarize restoration results into referenceable documents.\nExperiments demonstrate AgenticIR's potential in handling complex IR tasks,\nrepresenting a promising path toward achieving general intelligence in visual\nprocessing.\n","authors":["Kaiwen Zhu","Jinjin Gu","Zhiyuan You","Yu Qiao","Chao Dong"],"pdf_url":"https://arxiv.org/pdf/2410.17809v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.17802v1","updated":"2024-10-23T11:59:49Z","published":"2024-10-23T11:59:49Z","title":"GenUDC: High Quality 3D Mesh Generation with Unsigned Dual Contouring\n  Representation","summary":"  Generating high-quality meshes with complex structures and realistic surfaces\nis the primary goal of 3D generative models. Existing methods typically employ\nsequence data or deformable tetrahedral grids for mesh generation. However,\nsequence-based methods have difficulty producing complex structures with many\nfaces due to memory limits. The deformable tetrahedral grid-based method\nMeshDiffusion fails to recover realistic surfaces due to the inherent ambiguity\nin deformable grids. We propose the GenUDC framework to address these\nchallenges by leveraging the Unsigned Dual Contouring (UDC) as the mesh\nrepresentation. UDC discretizes a mesh in a regular grid and divides it into\nthe face and vertex parts, recovering both complex structures and fine details.\nAs a result, the one-to-one mapping between UDC and mesh resolves the ambiguity\nproblem. In addition, GenUDC adopts a two-stage, coarse-to-fine generative\nprocess for 3D mesh generation. It first generates the face part as a rough\nshape and then the vertex part to craft a detailed shape. Extensive evaluations\ndemonstrate the superiority of UDC as a mesh representation and the favorable\nperformance of GenUDC in mesh generation. The code and trained models are\navailable at https://github.com/TrepangCat/GenUDC.\n","authors":["Ruowei Wang","Jiaqi Li","Dan Zeng","Xueqi Ma","Zixiang Xu","Jianwei Zhang","Qijun Zhao"],"pdf_url":"https://arxiv.org/pdf/2410.17802v1.pdf","comment":"ACMMM 2024, code:https://github.com/TrepangCat/GenUDC"},{"id":"http://arxiv.org/abs/2309.16515v3","updated":"2024-10-23T11:56:02Z","published":"2023-09-28T15:22:02Z","title":"Latent Noise Segmentation: How Neural Noise Leads to the Emergence of\n  Segmentation and Grouping","summary":"  Humans are able to segment images effortlessly without supervision using\nperceptual grouping. Here, we propose a counter-intuitive computational\napproach to solving unsupervised perceptual grouping and segmentation: that\nthey arise because of neural noise, rather than in spite of it. We (1)\nmathematically demonstrate that under realistic assumptions, neural noise can\nbe used to separate objects from each other; (2) that adding noise in a DNN\nenables the network to segment images even though it was never trained on any\nsegmentation labels; and (3) that segmenting objects using noise results in\nsegmentation performance that aligns with the perceptual grouping phenomena\nobserved in humans, and is sample-efficient. We introduce the Good Gestalt (GG)\ndatasets -- six datasets designed to specifically test perceptual grouping, and\nshow that our DNN models reproduce many important phenomena in human\nperception, such as illusory contours, closure, continuity, proximity, and\nocclusion. Finally, we (4) show that our model improves performance on our GG\ndatasets compared to other tested unsupervised models by $24.9\\%$. Together,\nour results suggest a novel unsupervised segmentation method requiring few\nassumptions, a new explanation for the formation of perceptual grouping, and a\nnovel potential benefit of neural noise.\n","authors":["Ben Lonnqvist","Zhengqing Wu","Michael H. Herzog"],"pdf_url":"https://arxiv.org/pdf/2309.16515v3.pdf","comment":"ICML 2024 camera ready version"},{"id":"http://arxiv.org/abs/2410.17785v1","updated":"2024-10-23T11:35:44Z","published":"2024-10-23T11:35:44Z","title":"TranSPORTmer: A Holistic Approach to Trajectory Understanding in\n  Multi-Agent Sports","summary":"  Understanding trajectories in multi-agent scenarios requires addressing\nvarious tasks, including predicting future movements, imputing missing\nobservations, inferring the status of unseen agents, and classifying different\nglobal states. Traditional data-driven approaches often handle these tasks\nseparately with specialized models. We introduce TranSPORTmer, a unified\ntransformer-based framework capable of addressing all these tasks, showcasing\nits application to the intricate dynamics of multi-agent sports scenarios like\nsoccer and basketball. Using Set Attention Blocks, TranSPORTmer effectively\ncaptures temporal dynamics and social interactions in an equivariant manner.\nThe model's tasks are guided by an input mask that conceals missing or\nyet-to-be-predicted observations. Additionally, we introduce a CLS extra agent\nto classify states along soccer trajectories, including passes, possessions,\nuncontrolled states, and out-of-play intervals, contributing to an enhancement\nin modeling trajectories. Evaluations on soccer and basketball datasets show\nthat TranSPORTmer outperforms state-of-the-art task-specific models in player\nforecasting, player forecasting-imputation, ball inference, and ball\nimputation. https://youtu.be/8VtSRm8oGoE\n","authors":["Guillem Capellera","Luis Ferraz","Antonio Rubio","Antonio Agudo","Francesc Moreno-Noguer"],"pdf_url":"https://arxiv.org/pdf/2410.17785v1.pdf","comment":"Accepted to ACCV 2024"},{"id":"http://arxiv.org/abs/2410.17779v1","updated":"2024-10-23T11:31:06Z","published":"2024-10-23T11:31:06Z","title":"ADEM-VL: Adaptive and Embedded Fusion for Efficient Vision-Language\n  Tuning","summary":"  Recent advancements in multimodal fusion have witnessed the remarkable\nsuccess of vision-language (VL) models, which excel in various multimodal\napplications such as image captioning and visual question answering. However,\nbuilding VL models requires substantial hardware resources, where efficiency is\nrestricted by two key factors: the extended input sequence of the language\nmodel with vision features demands more computational operations, and a large\nnumber of additional learnable parameters increase memory complexity. These\nchallenges significantly restrict the broader applicability of such models. To\nbridge this gap, we propose ADEM-VL, an efficient vision-language method that\ntunes VL models based on pretrained large language models (LLMs) by adopting a\nparameter-free cross-attention mechanism for similarity measurements in\nmultimodal fusion. This approach only requires embedding vision features into\nthe language space, significantly reducing the number of trainable parameters\nand accelerating both training and inference speeds. To enhance representation\nlearning in fusion module, we introduce an efficient multiscale feature\ngeneration scheme that requires only a single forward pass through the vision\nencoder. Moreover, we propose an adaptive fusion scheme that dynamically\ndiscards less relevant visual information for each text token based on its\nattention score. This ensures that the fusion process prioritizes the most\npertinent visual features. With experiments on various tasks including visual\nquestion answering, image captioning, and instruction-following, we demonstrate\nthat our framework outperforms existing approaches. Specifically, our method\nsurpasses existing methods by an average accuracy of 0.77% on ScienceQA\ndataset, with reduced training and inference latency, demonstrating the\nsuperiority of our framework. The code is available at\nhttps://github.com/Hao840/ADEM-VL.\n","authors":["Zhiwei Hao","Jianyuan Guo","Li Shen","Yong Luo","Han Hu","Yonggang Wen"],"pdf_url":"https://arxiv.org/pdf/2410.17779v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.17774v1","updated":"2024-10-23T11:23:05Z","published":"2024-10-23T11:23:05Z","title":"Quasi-Medial Distance Field (Q-MDF): A Robust Method for Approximating\n  and Discretizing Neural Medial Axis","summary":"  The medial axis, a lower-dimensional shape descriptor, plays an important\nrole in the field of digital geometry processing. Despite its importance,\nrobust computation of the medial axis transform from diverse inputs, especially\npoint clouds with defects, remains a significant challenge. In this paper, we\ntackle the challenge by proposing a new implicit method that diverges from\nmainstream explicit medial axis computation techniques. Our key technical\ninsight is the difference between the signed distance field (SDF) and the\nmedial field (MF) of a solid shape is the unsigned distance field (UDF) of the\nshape's medial axis. This allows for formulating medial axis computation as an\nimplicit reconstruction problem. Utilizing a modified double covering method,\nwe extract the medial axis as the zero level-set of the UDF. Extensive\nexperiments show that our method has enhanced accuracy and robustness in\nlearning compact medial axis transform from thorny meshes and point clouds\ncompared to existing methods.\n","authors":["Jiayi Kong","Chen Zong","Jun Luo","Shiqing Xin","Fei Hou","Hanqing Jiang","Chen Qian","Ying He"],"pdf_url":"https://arxiv.org/pdf/2410.17774v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.17772v1","updated":"2024-10-23T11:19:48Z","published":"2024-10-23T11:19:48Z","title":"Scaling Robot Policy Learning via Zero-Shot Labeling with Foundation\n  Models","summary":"  A central challenge towards developing robots that can relate human language\nto their perception and actions is the scarcity of natural language annotations\nin diverse robot datasets. Moreover, robot policies that follow natural\nlanguage instructions are typically trained on either templated language or\nexpensive human-labeled instructions, hindering their scalability. To this end,\nwe introduce NILS: Natural language Instruction Labeling for Scalability. NILS\nautomatically labels uncurated, long-horizon robot data at scale in a zero-shot\nmanner without any human intervention. NILS combines pretrained vision-language\nfoundation models in order to detect objects in a scene, detect object-centric\nchanges, segment tasks from large datasets of unlabelled interaction data and\nultimately label behavior datasets. Evaluations on BridgeV2, Fractal, and a\nkitchen play dataset show that NILS can autonomously annotate diverse robot\ndemonstrations of unlabeled and unstructured datasets while alleviating several\nshortcomings of crowdsourced human annotations, such as low data quality and\ndiversity. We use NILS to label over 115k trajectories obtained from over 430\nhours of robot data. We open-source our auto-labeling code and generated\nannotations on our website: http://robottasklabeling.github.io.\n","authors":["Nils Blank","Moritz Reuss","Marcel Rühle","Ömer Erdinç Yağmurlu","Fabian Wenzel","Oier Mees","Rudolf Lioutikov"],"pdf_url":"https://arxiv.org/pdf/2410.17772v1.pdf","comment":"Project Website at https://robottasklabeling.github.io/"},{"id":"http://arxiv.org/abs/2404.00362v2","updated":"2024-10-23T11:06:02Z","published":"2024-03-30T13:28:53Z","title":"STBA: Towards Evaluating the Robustness of DNNs for Query-Limited\n  Black-box Scenario","summary":"  Many attack techniques have been proposed to explore the vulnerability of\nDNNs and further help to improve their robustness. Despite the significant\nprogress made recently, existing black-box attack methods still suffer from\nunsatisfactory performance due to the vast number of queries needed to optimize\ndesired perturbations. Besides, the other critical challenge is that\nadversarial examples built in a noise-adding manner are abnormal and struggle\nto successfully attack robust models, whose robustness is enhanced by\nadversarial training against small perturbations. There is no doubt that these\ntwo issues mentioned above will significantly increase the risk of exposure and\nresult in a failure to dig deeply into the vulnerability of DNNs. Hence, it is\nnecessary to evaluate DNNs' fragility sufficiently under query-limited settings\nin a non-additional way. In this paper, we propose the Spatial Transform\nBlack-box Attack (STBA), a novel framework to craft formidable adversarial\nexamples in the query-limited scenario. Specifically, STBA introduces a flow\nfield to the high-frequency part of clean images to generate adversarial\nexamples and adopts the following two processes to enhance their naturalness\nand significantly improve the query efficiency: a) we apply an estimated flow\nfield to the high-frequency part of clean images to generate adversarial\nexamples instead of introducing external noise to the benign image, and b) we\nleverage an efficient gradient estimation method based on a batch of samples to\noptimize such an ideal flow field under query-limited settings. Compared to\nexisting score-based black-box baselines, extensive experiments indicated that\nSTBA could effectively improve the imperceptibility of the adversarial examples\nand remarkably boost the attack success rate under query-limited settings.\n","authors":["Renyang Liu","Kwok-Yan Lam","Wei Zhou","Sixing Wu","Jun Zhao","Dongting Hu","Mingming Gong"],"pdf_url":"https://arxiv.org/pdf/2404.00362v2.pdf","comment":"Accepted by T-MM"},{"id":"http://arxiv.org/abs/2403.14626v2","updated":"2024-10-23T11:05:01Z","published":"2024-03-21T17:59:55Z","title":"ODTFormer: Efficient Obstacle Detection and Tracking with Stereo Cameras\n  Based on Transformer","summary":"  Obstacle detection and tracking represent a critical component in robot\nautonomous navigation. In this paper, we propose ODTFormer, a Transformer-based\nmodel to address both obstacle detection and tracking problems. For the\ndetection task, our approach leverages deformable attention to construct a 3D\ncost volume, which is decoded progressively in the form of voxel occupancy\ngrids. We further track the obstacles by matching the voxels between\nconsecutive frames. The entire model can be optimized in an end-to-end manner.\nThrough extensive experiments on DrivingStereo and KITTI benchmarks, our model\nachieves state-of-the-art performance in the obstacle detection task. We also\nreport comparable accuracy to state-of-the-art obstacle tracking models while\nrequiring only a fraction of their computation cost, typically ten-fold to\ntwenty-fold less. The code and model weights will be publicly released.\n","authors":["Tianye Ding","Hongyu Li","Huaizu Jiang"],"pdf_url":"https://arxiv.org/pdf/2403.14626v2.pdf","comment":"8 pages. Accepted by IROS 2024"},{"id":"http://arxiv.org/abs/2410.17752v1","updated":"2024-10-23T10:29:18Z","published":"2024-10-23T10:29:18Z","title":"AdaDiffSR: Adaptive Region-aware Dynamic Acceleration Diffusion Model\n  for Real-World Image Super-Resolution","summary":"  Diffusion models (DMs) have shown promising results on single-image\nsuper-resolution and other image-to-image translation tasks. Benefiting from\nmore computational resources and longer inference times, they are able to yield\nmore realistic images. Existing DMs-based super-resolution methods try to\nachieve an overall average recovery over all regions via iterative refinement,\nignoring the consideration that different input image regions require different\ntimesteps to reconstruct. In this work, we notice that previous DMs-based\nsuper-resolution methods suffer from wasting computational resources to\nreconstruct invisible details. To further improve the utilization of\ncomputational resources, we propose AdaDiffSR, a DMs-based SR pipeline with\ndynamic timesteps sampling strategy (DTSS). Specifically, by introducing the\nmulti-metrics latent entropy module (MMLE), we can achieve dynamic perception\nof the latent spatial information gain during the denoising process, thereby\nguiding the dynamic selection of the timesteps. In addition, we adopt a\nprogressive feature injection module (PFJ), which dynamically injects the\noriginal image features into the denoising process based on the current\ninformation gain, so as to generate images with both fidelity and realism.\nExperiments show that our AdaDiffSR achieves comparable performance over\ncurrent state-of-the-art DMs-based SR methods while consuming less\ncomputational resources and inference time on both synthetic and real-world\ndatasets.\n","authors":["Yuanting Fan","Chengxu Liu","Nengzhong Yin","Changlong Gao","Xueming Qian"],"pdf_url":"https://arxiv.org/pdf/2410.17752v1.pdf","comment":"18 pages, 6 figures, ECCV2024 accepted"},{"id":"http://arxiv.org/abs/2410.17751v1","updated":"2024-10-23T10:28:17Z","published":"2024-10-23T10:28:17Z","title":"VISAGE: Video Synthesis using Action Graphs for Surgery","summary":"  Surgical data science (SDS) is a field that analyzes patient data before,\nduring, and after surgery to improve surgical outcomes and skills. However,\nsurgical data is scarce, heterogeneous, and complex, which limits the\napplicability of existing machine learning methods. In this work, we introduce\nthe novel task of future video generation in laparoscopic surgery. This task\ncan augment and enrich the existing surgical data and enable various\napplications, such as simulation, analysis, and robot-aided surgery.\nUltimately, it involves not only understanding the current state of the\noperation but also accurately predicting the dynamic and often unpredictable\nnature of surgical procedures. Our proposed method, VISAGE (VIdeo Synthesis\nusing Action Graphs for Surgery), leverages the power of action scene graphs to\ncapture the sequential nature of laparoscopic procedures and utilizes diffusion\nmodels to synthesize temporally coherent video sequences. VISAGE predicts the\nfuture frames given only a single initial frame, and the action graph triplets.\nBy incorporating domain-specific knowledge through the action graph, VISAGE\nensures the generated videos adhere to the expected visual and motion patterns\nobserved in real laparoscopic procedures. The results of our experiments\ndemonstrate high-fidelity video generation for laparoscopy procedures, which\nenables various applications in SDS.\n","authors":["Yousef Yeganeh","Rachmadio Lazuardi","Amir Shamseddin","Emine Dari","Yash Thirani","Nassir Navab Azade Farshad"],"pdf_url":"https://arxiv.org/pdf/2410.17751v1.pdf","comment":"Accepted at MICCAI 2024 Embodied AI and Robotics for HealTHcare\n  (EARTH) Workshop"},{"id":"http://arxiv.org/abs/2410.17741v1","updated":"2024-10-23T10:16:01Z","published":"2024-10-23T10:16:01Z","title":"Efficient Neural Implicit Representation for 3D Human Reconstruction","summary":"  High-fidelity digital human representations are increasingly in demand in the\ndigital world, particularly for interactive telepresence, AR/VR, 3D graphics,\nand the rapidly evolving metaverse. Even though they work well in small spaces,\nconventional methods for reconstructing 3D human motion frequently require the\nuse of expensive hardware and have high processing costs. This study presents\nHumanAvatar, an innovative approach that efficiently reconstructs precise human\navatars from monocular video sources. At the core of our methodology, we\nintegrate the pre-trained HuMoR, a model celebrated for its proficiency in\nhuman motion estimation. This is adeptly fused with the cutting-edge neural\nradiance field technology, Instant-NGP, and the state-of-the-art articulated\nmodel, Fast-SNARF, to enhance the reconstruction fidelity and speed. By\ncombining these two technologies, a system is created that can render quickly\nand effectively while also providing estimation of human pose parameters that\nare unmatched in accuracy. We have enhanced our system with an advanced\nposture-sensitive space reduction technique, which optimally balances rendering\nquality with computational efficiency. In our detailed experimental analysis\nusing both artificial and real-world monocular videos, we establish the\nadvanced performance of our approach. HumanAvatar consistently equals or\nsurpasses contemporary leading-edge reconstruction techniques in quality.\nFurthermore, it achieves these complex reconstructions in minutes, a fraction\nof the time typically required by existing methods. Our models achieve a\ntraining speed that is 110X faster than that of State-of-The-Art (SoTA)\nNeRF-based models. Our technique performs noticeably better than SoTA dynamic\nhuman NeRF methods if given an identical runtime limit. HumanAvatar can provide\neffective visuals after only 30 seconds of training.\n","authors":["Zexu Huang","Sarah Monazam Erfani","Siying Lu","Mingming Gong"],"pdf_url":"https://arxiv.org/pdf/2410.17741v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.17740v1","updated":"2024-10-23T10:14:37Z","published":"2024-10-23T10:14:37Z","title":"Emotion Recognition with Facial Attention and Objective Activation\n  Functions","summary":"  In this paper, we study the effect of introducing channel and spatial\nattention mechanisms, namely SEN-Net, ECA-Net, and CBAM, to existing CNN\nvision-based models such as VGGNet, ResNet, and ResNetV2 to perform the Facial\nEmotion Recognition task. We show that not only attention can significantly\nimprove the performance of these models but also that combining them with a\ndifferent activation function can further help increase the performance of\nthese models.\n","authors":["Andrzej Miskow","Abdulrahman Altahhan"],"pdf_url":"https://arxiv.org/pdf/2410.17740v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.17735v1","updated":"2024-10-23T10:11:39Z","published":"2024-10-23T10:11:39Z","title":"New Insight in Cervical Cancer Diagnosis Using Convolution Neural\n  Network Architecture","summary":"  The Pap smear is a screening method for early cervical cancer diagnosis. The\nselection of the right optimizer in the convolutional neural network (CNN)\nmodel is key to the success of the CNN in image classification, including the\nclassification of cervical cancer Pap smear images. In this study, stochastic\ngradient descent (SGD), RMSprop, Adam, AdaGrad, AdaDelta, Adamax, and Nadam\noptimizers were used to classify cervical cancer Pap smear images from the\nSipakMed dataset. Resnet-18, Resnet-34, and VGG-16 are the CNN architectures\nused in this study, and each architecture uses a transfer-learning model. Based\non the test results, we conclude that the transfer learning model performs\nbetter on all CNNs and optimization techniques and that in the transfer\nlearning model, the optimization has little influence on the training of the\nmodel. Adamax, with accuracy values of 72.8% and 66.8%, had the best accuracy\nfor the VGG-16 and Resnet-18 architectures, respectively. Resnet-34 had 54.0%.\nThis is 0.034% lower than Nadam. Overall, Adamax is a suitable optimizer for\nCNN in cervical cancer classification on Resnet-18, Resnet-34, and VGG-16\narchitectures. This study provides new insights into the configuration of CNN\nmodels for Pap smear image analysis.\n","authors":["Ach. Khozaimi","Wayan Firdaus Mahmudy"],"pdf_url":"https://arxiv.org/pdf/2410.17735v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.17734v1","updated":"2024-10-23T10:07:13Z","published":"2024-10-23T10:07:13Z","title":"YOLO-Vehicle-Pro: A Cloud-Edge Collaborative Framework for Object\n  Detection in Autonomous Driving under Adverse Weather Conditions","summary":"  With the rapid advancement of autonomous driving technology, efficient and\naccurate object detection capabilities have become crucial factors in ensuring\nthe safety and reliability of autonomous driving systems. However, in\nlow-visibility environments such as hazy conditions, the performance of\ntraditional object detection algorithms often degrades significantly, failing\nto meet the demands of autonomous driving. To address this challenge, this\npaper proposes two innovative deep learning models: YOLO-Vehicle and\nYOLO-Vehicle-Pro. YOLO-Vehicle is an object detection model tailored\nspecifically for autonomous driving scenarios, employing multimodal fusion\ntechniques to combine image and textual information for object detection.\nYOLO-Vehicle-Pro builds upon this foundation by introducing an improved image\ndehazing algorithm, enhancing detection performance in low-visibility\nenvironments. In addition to model innovation, this paper also designs and\nimplements a cloud-edge collaborative object detection system, deploying models\non edge devices and offloading partial computational tasks to the cloud in\ncomplex situations. Experimental results demonstrate that on the KITTI dataset,\nthe YOLO-Vehicle-v1s model achieved 92.1% accuracy while maintaining a\ndetection speed of 226 FPS and an inference time of 12ms, meeting the real-time\nrequirements of autonomous driving. When processing hazy images, the\nYOLO-Vehicle-Pro model achieved a high accuracy of 82.3% mAP@50 on the Foggy\nCityscapes dataset while maintaining a detection speed of 43 FPS.\n","authors":["Xiguang Li","Jiafu Chen","Yunhe Sun","Na Lin","Ammar Hawbani","Liang Zhao"],"pdf_url":"https://arxiv.org/pdf/2410.17734v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.17725v1","updated":"2024-10-23T09:55:22Z","published":"2024-10-23T09:55:22Z","title":"YOLOv11: An Overview of the Key Architectural Enhancements","summary":"  This study presents an architectural analysis of YOLOv11, the latest\niteration in the YOLO (You Only Look Once) series of object detection models.\nWe examine the models architectural innovations, including the introduction of\nthe C3k2 (Cross Stage Partial with kernel size 2) block, SPPF (Spatial Pyramid\nPooling - Fast), and C2PSA (Convolutional block with Parallel Spatial\nAttention) components, which contribute in improving the models performance in\nseveral ways such as enhanced feature extraction. The paper explores YOLOv11's\nexpanded capabilities across various computer vision tasks, including object\ndetection, instance segmentation, pose estimation, and oriented object\ndetection (OBB). We review the model's performance improvements in terms of\nmean Average Precision (mAP) and computational efficiency compared to its\npredecessors, with a focus on the trade-off between parameter count and\naccuracy. Additionally, the study discusses YOLOv11's versatility across\ndifferent model sizes, from nano to extra-large, catering to diverse\napplication needs from edge devices to high-performance computing environments.\nOur research provides insights into YOLOv11's position within the broader\nlandscape of object detection and its potential impact on real-time computer\nvision applications.\n","authors":["Rahima Khanam","Muhammad Hussain"],"pdf_url":"https://arxiv.org/pdf/2410.17725v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.15881v3","updated":"2024-10-23T09:52:23Z","published":"2024-08-28T15:52:23Z","title":"LLaVA-MoD: Making LLaVA Tiny via MoE Knowledge Distillation","summary":"  We introduce LLaVA-MoD, a novel framework designed to enable the efficient\ntraining of small-scale Multimodal Language Models (s-MLLM) by distilling\nknowledge from large-scale MLLM (l-MLLM). Our approach tackles two fundamental\nchallenges in MLLM distillation. First, we optimize the network structure of\ns-MLLM by integrating a sparse Mixture of Experts (MoE) architecture into the\nlanguage model, striking a balance between computational efficiency and model\nexpressiveness. Second, we propose a progressive knowledge transfer strategy to\nensure comprehensive knowledge migration. This strategy begins with mimic\ndistillation, where we minimize the Kullback-Leibler (KL) divergence between\noutput distributions to enable the student model to emulate the teacher\nnetwork's understanding. Following this, we introduce preference distillation\nvia Direct Preference Optimization (DPO), where the key lies in treating l-MLLM\nas the reference model. During this phase, the s-MLLM's ability to discriminate\nbetween superior and inferior examples is significantly enhanced beyond l-MLLM,\nleading to a better student that surpasses its teacher, particularly in\nhallucination benchmarks. Extensive experiments demonstrate that LLaVA-MoD\noutperforms existing models across various multimodal benchmarks while\nmaintaining a minimal number of activated parameters and low computational\ncosts. Remarkably, LLaVA-MoD, with only 2B activated parameters, surpasses\nQwen-VL-Chat-7B by an average of 8.8% across benchmarks, using merely 0.3% of\nthe training data and 23% trainable parameters. These results underscore\nLLaVA-MoD's ability to effectively distill comprehensive knowledge from its\nteacher model, paving the way for the development of more efficient MLLMs. The\ncode will be available on: https://github.com/shufangxun/LLaVA-MoD.\n","authors":["Fangxun Shu","Yue Liao","Le Zhuo","Chenning Xu","Lei Zhang","Guanghao Zhang","Haonan Shi","Long Chen","Tao Zhong","Wanggui He","Siming Fu","Haoyuan Li","Bolin Li","Zhelun Yu","Si Liu","Hongsheng Li","Hao Jiang"],"pdf_url":"https://arxiv.org/pdf/2408.15881v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2404.14693v2","updated":"2024-10-23T09:42:29Z","published":"2024-04-23T02:50:38Z","title":"DIP-Watermark: A Double Identity Protection Method Based on Robust\n  Adversarial Watermark","summary":"  The wide deployment of Face Recognition (FR) systems poses privacy risks. One\ncountermeasure is adversarial attack, deceiving unauthorized malicious FR, but\nit also disrupts regular identity verification of trusted authorizers,\nexacerbating the potential threat of identity impersonation. To address this,\nwe propose the first double identity protection scheme based on traceable\nadversarial watermarking, termed DIP-Watermark. DIP-Watermark employs a\none-time watermark embedding to deceive unauthorized FR models and allows\nauthorizers to perform identity verification by extracting the watermark.\nSpecifically, we propose an information-guided adversarial attack against FR\nmodels. The encoder embeds an identity-specific watermark into the deep feature\nspace of the carrier, guiding recognizable features of the image to deviate\nfrom the source identity. We further adopt a collaborative meta-optimization\nstrategy compatible with sub-tasks, which regularizes the joint optimization\ndirection of the encoder and decoder. This strategy enhances the representation\nof universal carrier features, mitigating multi-objective optimization\nconflicts in watermarking. Experiments confirm that DIP-Watermark achieves\nsignificant attack success rates and traceability accuracy on state-of-the-art\nFR models, exhibiting remarkable robustness that outperforms the existing\nprivacy protection methods using adversarial attacks and deep watermarking, or\nsimple combinations of the two. Our work potentially opens up new insights into\nproactive protection for FR privacy.\n","authors":["Yunming Zhang","Dengpan Ye","Caiyun Xie","Sipeng Shen","Ziyi Liu","Jiacheng Deng","Long Tang"],"pdf_url":"https://arxiv.org/pdf/2404.14693v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.17715v1","updated":"2024-10-23T09:42:17Z","published":"2024-10-23T09:42:17Z","title":"Continual Learning on a Data Diet","summary":"  Continual Learning (CL) methods usually learn from all available data.\nHowever, this is not the case in human cognition which efficiently focuses on\nkey experiences while disregarding the redundant information. Similarly, not\nall data points in a dataset have equal potential; some can be more informative\nthan others. This disparity may significantly impact the performance, as both\nthe quality and quantity of samples directly influence the model's\ngeneralizability and efficiency. Drawing inspiration from this, we explore the\npotential of learning from important samples and present an empirical study for\nevaluating coreset selection techniques in the context of CL to stimulate\nresearch in this unexplored area. We train different continual learners on\nincreasing amounts of selected samples and investigate the learning-forgetting\ndynamics by shedding light on the underlying mechanisms driving their improved\nstability-plasticity balance. We present several significant observations:\nlearning from selectively chosen samples (i) enhances incremental accuracy,\n(ii) improves knowledge retention of previous tasks, and (iii) refines learned\nrepresentations. This analysis contributes to a deeper understanding of\nselective learning strategies in CL scenarios.\n","authors":["Elif Ceren Gok Yildirim","Murat Onur Yildirim","Joaquin Vanschoren"],"pdf_url":"https://arxiv.org/pdf/2410.17715v1.pdf","comment":"18 pages, 6 figures"},{"id":"http://arxiv.org/abs/2403.17678v2","updated":"2024-10-23T09:15:32Z","published":"2024-03-26T13:05:49Z","title":"Hierarchical Light Transformer Ensembles for Multimodal Trajectory\n  Forecasting","summary":"  Accurate trajectory forecasting is crucial for the performance of various\nsystems, such as advanced driver-assistance systems and self-driving vehicles.\nThese forecasts allow to anticipate events leading to collisions and,\ntherefore, to mitigate them. Deep Neural Networks have excelled in motion\nforecasting, but issues like overconfidence and uncertainty quantification\npersist. Deep Ensembles address these concerns, yet applying them to multimodal\ndistributions remains challenging. In this paper, we propose a novel approach\nnamed Hierarchical Light Transformer Ensembles (HLT-Ens), aimed at efficiently\ntraining an ensemble of Transformer architectures using a novel hierarchical\nloss function. HLT-Ens leverages grouped fully connected layers, inspired by\ngrouped convolution techniques, to capture multimodal distributions,\neffectively. Through extensive experimentation, we demonstrate that HLT-Ens\nachieves state-of-the-art performance levels, offering a promising avenue for\nimproving trajectory forecasting techniques.\n","authors":["Adrien Lafage","Mathieu Barbier","Gianni Franchi","David Filliat"],"pdf_url":"https://arxiv.org/pdf/2403.17678v2.pdf","comment":"acknowledgement added"},{"id":"http://arxiv.org/abs/2410.17691v1","updated":"2024-10-23T09:13:11Z","published":"2024-10-23T09:13:11Z","title":"Longitudinal Causal Image Synthesis","summary":"  Clinical decision-making relies heavily on causal reasoning and longitudinal\nanalysis. For example, for a patient with Alzheimer's disease (AD), how will\nthe brain grey matter atrophy in a year if intervened on the A-beta level in\ncerebrospinal fluid? The answer is fundamental to diagnosis and follow-up\ntreatment. However, this kind of inquiry involves counterfactual medical images\nwhich can not be acquired by instrumental or correlation-based image synthesis\nmodels. Yet, such queries require counterfactual medical images, not obtainable\nthrough standard image synthesis models. Hence, a causal longitudinal image\nsynthesis (CLIS) method, enabling the synthesis of such images, is highly\nvaluable. However, building a CLIS model confronts three primary yet unmet\nchallenges: mismatched dimensionality between high-dimensional images and\nlow-dimensional tabular variables, inconsistent collection intervals of\nfollow-up data, and inadequate causal modeling capability of existing causal\ngraph methods for image data. In this paper, we established a tabular-visual\ncausal graph (TVCG) for CLIS overcoming these challenges through a novel\nintegration of generative imaging, continuous-time modeling, and structural\ncausal models combined with a neural network. We train our CLIS based on the\nADNI dataset and evaluate it on two other AD datasets, which illustrate the\noutstanding yet controllable quality of the synthesized images and the\ncontributions of synthesized MRI to the characterization of AD progression,\nsubstantiating the reliability and utility in clinics.\n","authors":["Yujia Li","Han Li","ans S. Kevin Zhou"],"pdf_url":"https://arxiv.org/pdf/2410.17691v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2305.13752v2","updated":"2024-10-23T08:53:05Z","published":"2023-05-23T07:09:09Z","title":"Pulling Target to Source: A New Perspective on Domain Adaptive Semantic\n  Segmentation","summary":"  Domain adaptive semantic segmentation aims to transfer knowledge from a\nlabeled source domain to an unlabeled target domain. However, existing methods\nprimarily focus on directly learning qualified target features, making it\nchallenging to guarantee their discrimination in the absence of target labels.\nThis work provides a new perspective. We observe that the features learned with\nsource data manage to keep categorically discriminative during training,\nthereby enabling us to implicitly learn adequate target representations by\nsimply \\textbf{pulling target features close to source features for each\ncategory}. To this end, we propose T2S-DA, which we interpret as a form of\npulling Target to Source for Domain Adaptation, encouraging the model in\nlearning similar cross-domain features. Also, considering the pixel categories\nare heavily imbalanced for segmentation datasets, we come up with a dynamic\nre-weighting strategy to help the model concentrate on those underperforming\nclasses. Extensive experiments confirm that T2S-DA learns a more discriminative\nand generalizable representation, significantly surpassing the\nstate-of-the-art. We further show that our method is quite qualified for the\ndomain generalization task, verifying its domain-invariant property.\n","authors":["Haochen Wang","Yujun Shen","Jingjing Fei","Wei Li","Liwei Wu","Yuxi Wang","Zhaoxiang Zhang"],"pdf_url":"https://arxiv.org/pdf/2305.13752v2.pdf","comment":"Accepted by IJCV"},{"id":"http://arxiv.org/abs/2410.17664v1","updated":"2024-10-23T08:33:23Z","published":"2024-10-23T08:33:23Z","title":"Deep Generative Models for 3D Medical Image Synthesis","summary":"  Deep generative modeling has emerged as a powerful tool for synthesizing\nrealistic medical images, driving advances in medical image analysis, disease\ndiagnosis, and treatment planning. This chapter explores various deep\ngenerative models for 3D medical image synthesis, with a focus on Variational\nAutoencoders (VAEs), Generative Adversarial Networks (GANs), and Denoising\nDiffusion Models (DDMs). We discuss the fundamental principles, recent\nadvances, as well as strengths and weaknesses of these models and examine their\napplications in clinically relevant problems, including unconditional and\nconditional generation tasks like image-to-image translation and image\nreconstruction. We additionally review commonly used evaluation metrics for\nassessing image fidelity, diversity, utility, and privacy and provide an\noverview of current challenges in the field.\n","authors":["Paul Friedrich","Yannik Frisch","Philippe C. Cattin"],"pdf_url":"https://arxiv.org/pdf/2410.17664v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.00505v2","updated":"2024-10-23T08:28:53Z","published":"2024-06-01T17:27:34Z","title":"Improving Text Generation on Images with Synthetic Captions","summary":"  The recent emergence of latent diffusion models such as SDXL and SD 1.5 has\nshown significant capability in generating highly detailed and realistic\nimages. Despite their remarkable ability to produce images, generating accurate\ntext within images still remains a challenging task. In this paper, we examine\nthe validity of fine-tuning approaches in generating legible text within the\nimage. We propose a low-cost approach by leveraging SDXL without any\ntime-consuming training on large-scale datasets. The proposed strategy employs\na fine-tuning technique that examines the effects of data refinement levels and\nsynthetic captions. Moreover, our results demonstrate how our small scale\nfine-tuning approach can improve the accuracy of text generation in different\nscenarios without the need of additional multimodal encoders. Our experiments\nshow that with the addition of random letters to our raw dataset, our model's\nperformance improves in producing well-formed visual text.\n","authors":["Jun Young Koh","Sang Hyun Park","Joy Song"],"pdf_url":"https://arxiv.org/pdf/2406.00505v2.pdf","comment":"2024 16th IIAI International Congress on Advanced Applied Informatics\n  (IIAI-AAI)"},{"id":"http://arxiv.org/abs/2407.16364v2","updated":"2024-10-23T08:27:23Z","published":"2024-07-23T10:11:56Z","title":"Harmonizing Visual Text Comprehension and Generation","summary":"  In this work, we present TextHarmony, a unified and versatile multimodal\ngenerative model proficient in comprehending and generating visual text.\nSimultaneously generating images and texts typically results in performance\ndegradation due to the inherent inconsistency between vision and language\nmodalities. To overcome this challenge, existing approaches resort to\nmodality-specific data for supervised fine-tuning, necessitating distinct model\ninstances. We propose Slide-LoRA, which dynamically aggregates\nmodality-specific and modality-agnostic LoRA experts, partially decoupling the\nmultimodal generation space. Slide-LoRA harmonizes the generation of vision and\nlanguage within a singular model instance, thereby facilitating a more unified\ngenerative process. Additionally, we develop a high-quality image caption\ndataset, DetailedTextCaps-100K, synthesized with a sophisticated closed-source\nMLLM to enhance visual text generation capabilities further. Comprehensive\nexperiments across various benchmarks demonstrate the effectiveness of the\nproposed approach. Empowered by Slide-LoRA, TextHarmony achieves comparable\nperformance to modality-specific fine-tuning results with only a 2% increase in\nparameters and shows an average improvement of 2.5% in visual text\ncomprehension tasks and 4.0% in visual text generation tasks. Our work\ndelineates the viability of an integrated approach to multimodal generation\nwithin the visual text domain, setting a foundation for subsequent inquiries.\nCode is available at https://github.com/bytedance/TextHarmony.\n","authors":["Zhen Zhao","Jingqun Tang","Binghong Wu","Chunhui Lin","Shu Wei","Hao Liu","Xin Tan","Zhizhong Zhang","Can Huang","Yuan Xie"],"pdf_url":"https://arxiv.org/pdf/2407.16364v2.pdf","comment":"accepted by NeurIPS 2024"},{"id":"http://arxiv.org/abs/2312.12540v4","updated":"2024-10-23T08:20:12Z","published":"2023-12-19T19:19:19Z","title":"Lightning-Fast Image Inversion and Editing for Text-to-Image Diffusion\n  Models","summary":"  Diffusion inversion is the problem of taking an image and a text prompt that\ndescribes it and finding a noise latent that would generate the exact same\nimage. Most current deterministic inversion techniques operate by approximately\nsolving an implicit equation and may converge slowly or yield poor\nreconstructed images. We formulate the problem by finding the roots of an\nimplicit equation and devlop a method to solve it efficiently. Our solution is\nbased on Newton-Raphson (NR), a well-known technique in numerical analysis. We\nshow that a vanilla application of NR is computationally infeasible while\nnaively transforming it to a computationally tractable alternative tends to\nconverge to out-of-distribution solutions, resulting in poor reconstruction and\nediting. We therefore derive an efficient guided formulation that fastly\nconverges and provides high-quality reconstructions and editing. We showcase\nour method on real image editing with three popular open-sourced diffusion\nmodels: Stable Diffusion, SDXL-Turbo, and Flux with different deterministic\nschedulers. Our solution, Guided Newton-Raphson Inversion, inverts an image\nwithin 0.4 sec (on an A100 GPU) for few-step models (SDXL-Turbo and Flux.1),\nopening the door for interactive image editing. We further show improved\nresults in image interpolation and generation of rare objects.\n","authors":["Dvir Samuel","Barak Meiri","Haggai Maron","Yoad Tewel","Nir Darshan","Shai Avidan","Gal Chechik","Rami Ben-Ari"],"pdf_url":"https://arxiv.org/pdf/2312.12540v4.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.17642v1","updated":"2024-10-23T07:58:47Z","published":"2024-10-23T07:58:47Z","title":"Surgical Scene Segmentation by Transformer With Asymmetric Feature\n  Enhancement","summary":"  Surgical scene segmentation is a fundamental task for robotic-assisted\nlaparoscopic surgery understanding. It often contains various anatomical\nstructures and surgical instruments, where similar local textures and\nfine-grained structures make the segmentation a difficult task. Vision-specific\ntransformer method is a promising way for surgical scene understanding.\nHowever, there are still two main challenges. Firstly, the absence of\ninner-patch information fusion leads to poor segmentation performance.\nSecondly, the specific characteristics of anatomy and instruments are not\nspecifically modeled. To tackle the above challenges, we propose a novel\nTransformer-based framework with an Asymmetric Feature Enhancement module\n(TAFE), which enhances local information and then actively fuses the improved\nfeature pyramid into the embeddings from transformer encoders by a multi-scale\ninteraction attention strategy. The proposed method outperforms the SOTA\nmethods in several different surgical segmentation tasks and additionally\nproves its ability of fine-grained structure recognition. Code is available at\nhttps://github.com/cyuan-sjtu/ViT-asym.\n","authors":["Cheng Yuan","Yutong Ban"],"pdf_url":"https://arxiv.org/pdf/2410.17642v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.17637v1","updated":"2024-10-23T07:56:48Z","published":"2024-10-23T07:56:48Z","title":"MIA-DPO: Multi-Image Augmented Direct Preference Optimization For Large\n  Vision-Language Models","summary":"  Visual preference alignment involves training Large Vision-Language Models\n(LVLMs) to predict human preferences between visual inputs. This is typically\nachieved by using labeled datasets of chosen/rejected pairs and employing\noptimization algorithms like direct preference optimization (DPO). Existing\nvisual alignment methods, primarily designed for single-image scenarios,\nstruggle to effectively handle the complexity of multi-image tasks due to the\nscarcity of diverse training data and the high cost of annotating\nchosen/rejected pairs. We present Multi-Image Augmented Direct Preference\nOptimization (MIA-DPO), a visual preference alignment approach that effectively\nhandles multi-image inputs. MIA-DPO mitigates the scarcity of diverse\nmulti-image training data by extending single-image data with unrelated images\narranged in grid collages or pic-in-pic formats, significantly reducing the\ncosts associated with multi-image data annotations. Our observation reveals\nthat attention values of LVLMs vary considerably across different images. We\nuse attention values to identify and filter out rejected responses the model\nmay have mistakenly focused on. Our attention-aware selection for constructing\nthe chosen/rejected pairs without relying on (i) human annotation, (ii) extra\ndata, and (iii) external models or APIs. MIA-DPO is compatible with various\narchitectures and outperforms existing methods on five multi-image benchmarks,\nachieving an average performance boost of 3.0% on LLaVA-v1.5 and 4.3% on the\nrecent InternLM-XC2.5. Moreover, MIA-DPO has a minimal effect on the model's\nability to understand single images.\n","authors":["Ziyu Liu","Yuhang Zang","Xiaoyi Dong","Pan Zhang","Yuhang Cao","Haodong Duan","Conghui He","Yuanjun Xiong","Dahua Lin","Jiaqi Wang"],"pdf_url":"https://arxiv.org/pdf/2410.17637v1.pdf","comment":"Project URL: https://github.com/Liuziyu77/MIA-DPO"},{"id":"http://arxiv.org/abs/2410.15767v2","updated":"2024-10-23T07:55:10Z","published":"2024-10-21T08:27:13Z","title":"Improving Instance Optimization in Deformable Image Registration with\n  Gradient Projection","summary":"  Deformable image registration is inherently a multi-objective optimization\n(MOO) problem, requiring a delicate balance between image similarity and\ndeformation regularity. These conflicting objectives often lead to poor\noptimization outcomes, such as being trapped in unsatisfactory local minima or\nexperiencing slow convergence. Deep learning methods have recently gained\npopularity in this domain due to their efficiency in processing large datasets\nand achieving high accuracy. However, they often underperform during test time\ncompared to traditional optimization techniques, which further explore\niterative, instance-specific gradient-based optimization. This performance gap\nis more pronounced when a distribution shift between training and test data\nexists. To address this issue, we focus on the instance optimization (IO)\nparadigm, which involves additional optimization for test-time instances based\non a pre-trained model. IO effectively combines the generalization capabilities\nof deep learning with the fine-tuning advantages of instance-specific\noptimization. Within this framework, we emphasize the use of gradient\nprojection to mitigate conflicting updates in MOO. This technique projects\nconflicting gradients into a common space, better aligning the dual objectives\nand enhancing optimization stability. We validate our method using a\nstate-of-the-art foundation model on the 3D Brain inter-subject registration\ntask (LUMIR) from the Learn2Reg 2024 Challenge. Our results show significant\nimprovements over standard gradient descent, leading to more accurate and\nreliable registration results.\n","authors":["Yi Zhang","Yidong Zhao","Qian Tao"],"pdf_url":"https://arxiv.org/pdf/2410.15767v2.pdf","comment":"Learn2Reg Challenge at MICCAI 2024"},{"id":"http://arxiv.org/abs/2410.17622v1","updated":"2024-10-23T07:26:19Z","published":"2024-10-23T07:26:19Z","title":"Bridging the Gaps: Utilizing Unlabeled Face Recognition Datasets to\n  Boost Semi-Supervised Facial Expression Recognition","summary":"  In recent years, Facial Expression Recognition (FER) has gained increasing\nattention. Most current work focuses on supervised learning, which requires a\nlarge amount of labeled and diverse images, while FER suffers from the scarcity\nof large, diverse datasets and annotation difficulty. To address these\nproblems, we focus on utilizing large unlabeled Face Recognition (FR) datasets\nto boost semi-supervised FER. Specifically, we first perform face\nreconstruction pre-training on large-scale facial images without annotations to\nlearn features of facial geometry and expression regions, followed by two-stage\nfine-tuning on FER datasets with limited labels. In addition, to further\nalleviate the scarcity of labeled and diverse images, we propose a Mixup-based\ndata augmentation strategy tailored for facial images, and the loss weights of\nreal and virtual images are determined according to the intersection-over-union\n(IoU) of the faces in the two images. Experiments on RAF-DB, AffectNet, and\nFERPlus show that our method outperforms existing semi-supervised FER methods\nand achieves new state-of-the-art performance. Remarkably, with only 5%, 25%\ntraining sets,our method achieves 64.02% on AffectNet,and 88.23% on RAF-DB,\nwhich is comparable to fully supervised state-of-the-art methods. Codes will be\nmade publicly available at https://github.com/zhelishisongjie/SSFER.\n","authors":["Jie Song","Mengqiao He","Jinhua Feng","Bairong Shen"],"pdf_url":"https://arxiv.org/pdf/2410.17622v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.14947v2","updated":"2024-10-23T07:18:51Z","published":"2024-08-27T10:44:34Z","title":"ERX: A Fast Real-Time Anomaly Detection Algorithm for Hyperspectral Line\n  Scanning","summary":"  Detecting unexpected objects (anomalies) in real time has great potential for\nmonitoring, managing, and protecting the environment. Hyperspectral line-scan\ncameras are a low-cost solution that enhance confidence in anomaly detection\nover RGB and multispectral imagery. However, existing line-scan algorithms are\ntoo slow when using small computers (e.g. those onboard a drone or small\nsatellite), do not adapt to changing scenery, or lack robustness against\ngeometric distortions. This paper introduces the Exponentially moving RX\nalgorithm (ERX) to address these issues, and compares it with existing RX-based\nanomaly detection methods for hyperspectral line scanning. Three large and more\ncomplex datasets are also introduced to better assess the practical challenges\nwhen using line-scan cameras (two hyperspectral and one multispectral). ERX is\nevaluated using a Jetson Xavier NX compute module, achieving the best\ncombination of speed and detection performance. This research paves the way for\nfuture studies in grouping and locating anomalous objects, adaptive and\nautomatic threshold selection, and real-time field tests. The datasets and the\nPython code are available at: https://github.com/WiseGamgee/HyperAD.\n","authors":["Samuel Garske","Bradley Evans","Christopher Artlett","KC Wong"],"pdf_url":"https://arxiv.org/pdf/2408.14947v2.pdf","comment":"17 pages, 13 figures, 4 tables, code and datasets accessible at\n  https://github.com/WiseGamgee/HyperAD"},{"id":"http://arxiv.org/abs/2404.07554v2","updated":"2024-10-23T07:16:42Z","published":"2024-04-11T08:36:13Z","title":"CAT: Contrastive Adapter Training for Personalized Image Generation","summary":"  The emergence of various adapters, including Low-Rank Adaptation (LoRA)\napplied from the field of natural language processing, has allowed diffusion\nmodels to personalize image generation at a low cost. However, due to the\nvarious challenges including limited datasets and shortage of regularization\nand computation resources, adapter training often results in unsatisfactory\noutcomes, leading to the corruption of the backbone model's prior knowledge.\nOne of the well known phenomena is the loss of diversity in object generation,\nespecially within the same class which leads to generating almost identical\nobjects with minor variations. This poses challenges in generation\ncapabilities. To solve this issue, we present Contrastive Adapter Training\n(CAT), a simple yet effective strategy to enhance adapter training through the\napplication of CAT loss. Our approach facilitates the preservation of the base\nmodel's original knowledge when the model initiates adapters. Furthermore, we\nintroduce the Knowledge Preservation Score (KPS) to evaluate CAT's ability to\nkeep the former information. We qualitatively and quantitatively compare CAT's\nimprovement. Finally, we mention the possibility of CAT in the aspects of\nmulti-concept adapter and optimization.\n","authors":["Jae Wan Park","Sang Hyun Park","Jun Young Koh","Junha Lee","Min Song"],"pdf_url":"https://arxiv.org/pdf/2404.07554v2.pdf","comment":"CVPRW 2024"},{"id":"http://arxiv.org/abs/2410.17610v1","updated":"2024-10-23T07:06:08Z","published":"2024-10-23T07:06:08Z","title":"ImDy: Human Inverse Dynamics from Imitated Observations","summary":"  Inverse dynamics (ID), which aims at reproducing the driven torques from\nhuman kinematic observations, has been a critical tool for gait analysis.\nHowever, it is hindered from wider application to general motion due to its\nlimited scalability. Conventional optimization-based ID requires expensive\nlaboratory setups, restricting its availability. To alleviate this problem, we\npropose to exploit the recently progressive human motion imitation algorithms\nto learn human inverse dynamics in a data-driven manner. The key insight is\nthat the human ID knowledge is implicitly possessed by motion imitators, though\nnot directly applicable. In light of this, we devise an efficient data\ncollection pipeline with state-of-the-art motion imitation algorithms and\nphysics simulators, resulting in a large-scale human inverse dynamics benchmark\nas Imitated Dynamics (ImDy). ImDy contains over 150 hours of motion with joint\ntorque and full-body ground reaction force data. With ImDy, we train a\ndata-driven human inverse dynamics solver ImDyS(olver) in a fully supervised\nmanner, which conducts ID and ground reaction force estimation simultaneously.\nExperiments on ImDy and real-world data demonstrate the impressive competency\nof ImDyS in human inverse dynamics and ground reaction force estimation.\nMoreover, the potential of ImDy(-S) as a fundamental motion analysis tool is\nexhibited with downstream applications. The project page is\nhttps://foruck.github.io/ImDy/.\n","authors":["Xinpeng Liu","Junxuan Liang","Zili Lin","Haowen Hou","Yong-Lu Li","Cewu Lu"],"pdf_url":"https://arxiv.org/pdf/2410.17610v1.pdf","comment":"Yong-Lu Li and Cewu Lu are the corresponding authors"},{"id":"http://arxiv.org/abs/2406.14927v2","updated":"2024-10-23T07:01:34Z","published":"2024-06-21T07:37:17Z","title":"Gaussian-Informed Continuum for Physical Property Identification and\n  Simulation","summary":"  This paper studies the problem of estimating physical properties (system\nidentification) through visual observations. To facilitate geometry-aware\nguidance in physical property estimation, we introduce a novel hybrid framework\nthat leverages 3D Gaussian representation to not only capture explicit shapes\nbut also enable the simulated continuum to render object masks as 2D shape\nsurrogates during training.\n  We propose a new dynamic 3D Gaussian framework based on motion factorization\nto recover the object as 3D Gaussian point sets across different time states.\n  Furthermore, we develop a coarse-to-fine filling strategy to generate the\ndensity fields of the object from the Gaussian reconstruction, allowing for the\nextraction of object continuums along with their surfaces and the integration\nof Gaussian attributes into these continuums.\n  In addition to the extracted object surfaces, the Gaussian-informed continuum\nalso enables the rendering of object masks during simulations, serving as\n2D-shape guidance for physical property estimation.\n  Extensive experimental evaluations demonstrate that our pipeline achieves\nstate-of-the-art performance across multiple benchmarks and metrics.\nAdditionally, we illustrate the effectiveness of the proposed method through\nreal-world demonstrations, showcasing its practical utility.\n  Our project page is at https://jukgei.github.io/project/gic.\n","authors":["Junhao Cai","Yuji Yang","Weihao Yuan","Yisheng He","Zilong Dong","Liefeng Bo","Hui Cheng","Qifeng Chen"],"pdf_url":"https://arxiv.org/pdf/2406.14927v2.pdf","comment":"21 pages, 8 figures, NeurIPS 2024"},{"id":"http://arxiv.org/abs/2410.17606v1","updated":"2024-10-23T07:01:16Z","published":"2024-10-23T07:01:16Z","title":"Towards Effective Data-Free Knowledge Distillation via Diverse Diffusion\n  Augmentation","summary":"  Data-free knowledge distillation (DFKD) has emerged as a pivotal technique in\nthe domain of model compression, substantially reducing the dependency on the\noriginal training data. Nonetheless, conventional DFKD methods that employ\nsynthesized training data are prone to the limitations of inadequate diversity\nand discrepancies in distribution between the synthesized and original\ndatasets. To address these challenges, this paper introduces an innovative\napproach to DFKD through diverse diffusion augmentation (DDA). Specifically, we\nrevise the paradigm of common data synthesis in DFKD to a composite process\nthrough leveraging diffusion models subsequent to data synthesis for\nself-supervised augmentation, which generates a spectrum of data samples with\nsimilar distributions while retaining controlled variations. Furthermore, to\nmitigate excessive deviation in the embedding space, we introduce an image\nfiltering technique grounded in cosine similarity to maintain fidelity during\nthe knowledge distillation process. Comprehensive experiments conducted on\nCIFAR-10, CIFAR-100, and Tiny-ImageNet datasets showcase the superior\nperformance of our method across various teacher-student network\nconfigurations, outperforming the contemporary state-of-the-art DFKD methods.\nCode will be available at:https://github.com/SLGSP/DDA.\n","authors":["Muquan Li","Dongyang Zhang","Tao He","Xiurui Xie","Yuan-Fang Li","Ke Qin"],"pdf_url":"https://arxiv.org/pdf/2410.17606v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.17598v1","updated":"2024-10-23T06:51:59Z","published":"2024-10-23T06:51:59Z","title":"PlantCamo: Plant Camouflage Detection","summary":"  Camouflaged Object Detection (COD) aims to detect objects with camouflaged\nproperties. Although previous studies have focused on natural (animals and\ninsects) and unnatural (artistic and synthetic) camouflage detection, plant\ncamouflage has been neglected. However, plant camouflage plays a vital role in\nnatural camouflage. Therefore, this paper introduces a new challenging problem\nof Plant Camouflage Detection (PCD). To address this problem, we introduce the\nPlantCamo dataset, which comprises 1,250 images with camouflaged plants\nrepresenting 58 object categories in various natural scenes. To investigate the\ncurrent status of plant camouflage detection, we conduct a large-scale\nbenchmark study using 20+ cutting-edge COD models on the proposed dataset. Due\nto the unique characteristics of plant camouflage, including holes and\nirregular borders, we developed a new framework, named PCNet, dedicated to PCD.\nOur PCNet surpasses performance thanks to its multi-scale global feature\nenhancement and refinement. Finally, we discuss the potential applications and\ninsights, hoping this work fills the gap in fine-grained COD research and\nfacilitates further intelligent ecology research. All resources will be\navailable on https://github.com/yjybuaa/PlantCamo.\n","authors":["Jinyu Yang","Qingwei Wang","Feng Zheng","Peng Chen","Aleš Leonardis","Deng-Ping Fan"],"pdf_url":"https://arxiv.org/pdf/2410.17598v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.17594v1","updated":"2024-10-23T06:47:29Z","published":"2024-10-23T06:47:29Z","title":"How to Continually Adapt Text-to-Image Diffusion Models for Flexible\n  Customization?","summary":"  Custom diffusion models (CDMs) have attracted widespread attention due to\ntheir astonishing generative ability for personalized concepts. However, most\nexisting CDMs unreasonably assume that personalized concepts are fixed and\ncannot change over time. Moreover, they heavily suffer from catastrophic\nforgetting and concept neglect on old personalized concepts when continually\nlearning a series of new concepts. To address these challenges, we propose a\nnovel Concept-Incremental text-to-image Diffusion Model (CIDM), which can\nresolve catastrophic forgetting and concept neglect to learn new customization\ntasks in a concept-incremental manner. Specifically, to surmount the\ncatastrophic forgetting of old concepts, we develop a concept consolidation\nloss and an elastic weight aggregation module. They can explore task-specific\nand task-shared knowledge during training, and aggregate all low-rank weights\nof old concepts based on their contributions during inference. Moreover, in\norder to address concept neglect, we devise a context-controllable synthesis\nstrategy that leverages expressive region features and noise estimation to\ncontrol the contexts of generated images according to user conditions.\nExperiments validate that our CIDM surpasses existing custom diffusion models.\nThe source codes are available at https://github.com/JiahuaDong/CIFC.\n","authors":["Jiahua Dong","Wenqi Liang","Hongliu Li","Duzhen Zhang","Meng Cao","Henghui Ding","Salman Khan","Fahad Shahbaz Khan"],"pdf_url":"https://arxiv.org/pdf/2410.17594v1.pdf","comment":"Accepted to NeurIPS2024"},{"id":"http://arxiv.org/abs/2406.08035v2","updated":"2024-10-23T06:37:01Z","published":"2024-06-12T09:36:52Z","title":"LVBench: An Extreme Long Video Understanding Benchmark","summary":"  Recent progress in multimodal large language models has markedly enhanced the\nunderstanding of short videos (typically under one minute), and several\nevaluation datasets have emerged accordingly. However, these advancements fall\nshort of meeting the demands of real-world applications such as embodied\nintelligence for long-term decision-making, in-depth movie reviews and\ndiscussions, and live sports commentary, all of which require comprehension of\nlong videos spanning several hours. To address this gap, we introduce LVBench,\na benchmark specifically designed for long video understanding. Our dataset\ncomprises publicly sourced videos and encompasses a diverse set of tasks aimed\nat long video comprehension and information extraction. LVBench is designed to\nchallenge multimodal models to demonstrate long-term memory and extended\ncomprehension capabilities. Our extensive evaluations reveal that current\nmultimodal models still underperform on these demanding long video\nunderstanding tasks. Through LVBench, we aim to spur the development of more\nadvanced models capable of tackling the complexities of long video\ncomprehension. Our data and code are publicly available at:\nhttps://lvbench.github.io.\n","authors":["Weihan Wang","Zehai He","Wenyi Hong","Yean Cheng","Xiaohan Zhang","Ji Qi","Xiaotao Gu","Shiyu Huang","Bin Xu","Yuxiao Dong","Ming Ding","Jie Tang"],"pdf_url":"https://arxiv.org/pdf/2406.08035v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2409.17555v2","updated":"2024-10-23T05:49:00Z","published":"2024-09-26T05:57:35Z","title":"Advancing Open-Set Domain Generalization Using Evidential Bi-Level\n  Hardest Domain Scheduler","summary":"  In Open-Set Domain Generalization (OSDG), the model is exposed to both new\nvariations of data appearance (domains) and open-set conditions, where both\nknown and novel categories are present at test time. The challenges of this\ntask arise from the dual need to generalize across diverse domains and\naccurately quantify category novelty, which is critical for applications in\ndynamic environments. Recently, meta-learning techniques have demonstrated\nsuperior results in OSDG, effectively orchestrating the meta-train and -test\ntasks by employing varied random categories and predefined domain partition\nstrategies. These approaches prioritize a well-designed training schedule over\ntraditional methods that focus primarily on data augmentation and the\nenhancement of discriminative feature learning. The prevailing meta-learning\nmodels in OSDG typically utilize a predefined sequential domain scheduler to\nstructure data partitions. However, a crucial aspect that remains inadequately\nexplored is the influence brought by strategies of domain schedulers during\ntraining. In this paper, we observe that an adaptive domain scheduler benefits\nmore in OSDG compared with prefixed sequential and random domain schedulers. We\npropose the Evidential Bi-Level Hardest Domain Scheduler (EBiL-HaDS) to achieve\nan adaptive domain scheduler. This method strategically sequences domains by\nassessing their reliabilities in utilizing a follower network, trained with\nconfidence scores learned in an evidential manner, regularized by max rebiasing\ndiscrepancy, and optimized in a bi-level manner. The results show that our\nmethod substantially improves OSDG performance and achieves more discriminative\nembeddings for both the seen and unseen categories. The source code is publicly\navailable at https://github.com/KPeng9510/EBiL-HaDS.\n","authors":["Kunyu Peng","Di Wen","Kailun Yang","Ao Luo","Yufan Chen","Jia Fu","M. Saquib Sarfraz","Alina Roitberg","Rainer Stiefelhagen"],"pdf_url":"https://arxiv.org/pdf/2409.17555v2.pdf","comment":"Accepted to NeurIPS 2024. The source code is publicly available at\n  https://github.com/KPeng9510/EBiL-HaDS"},{"id":"http://arxiv.org/abs/2407.15815v2","updated":"2024-10-23T05:32:34Z","published":"2024-07-22T17:29:02Z","title":"Learning to Manipulate Anywhere: A Visual Generalizable Framework For\n  Reinforcement Learning","summary":"  Can we endow visuomotor robots with generalization capabilities to operate in\ndiverse open-world scenarios? In this paper, we propose \\textbf{Maniwhere}, a\ngeneralizable framework tailored for visual reinforcement learning, enabling\nthe trained robot policies to generalize across a combination of multiple\nvisual disturbance types. Specifically, we introduce a multi-view\nrepresentation learning approach fused with Spatial Transformer Network (STN)\nmodule to capture shared semantic information and correspondences among\ndifferent viewpoints. In addition, we employ a curriculum-based randomization\nand augmentation approach to stabilize the RL training process and strengthen\nthe visual generalization ability. To exhibit the effectiveness of Maniwhere,\nwe meticulously design 8 tasks encompassing articulate objects, bi-manual, and\ndexterous hand manipulation tasks, demonstrating Maniwhere's strong visual\ngeneralization and sim2real transfer abilities across 3 hardware platforms. Our\nexperiments show that Maniwhere significantly outperforms existing\nstate-of-the-art methods. Videos are provided at\nhttps://gemcollector.github.io/maniwhere/.\n","authors":["Zhecheng Yuan","Tianming Wei","Shuiqi Cheng","Gu Zhang","Yuanpei Chen","Huazhe Xu"],"pdf_url":"https://arxiv.org/pdf/2407.15815v2.pdf","comment":"Webpage: https://gemcollector.github.io/maniwhere/"},{"id":"http://arxiv.org/abs/2312.11309v2","updated":"2024-10-23T05:30:24Z","published":"2023-12-18T16:02:43Z","title":"The Ultimate Combo: Boosting Adversarial Example Transferability by\n  Composing Data Augmentations","summary":"  To help adversarial examples generalize from surrogate machine-learning (ML)\nmodels to targets, certain transferability-based black-box evasion attacks\nincorporate data augmentations (e.g., random resizing). Yet, prior work has\nexplored limited augmentations and their composition. To fill the gap, we\nsystematically studied how data augmentation affects transferability.\nSpecifically, we explored 46 augmentation techniques originally proposed to\nhelp ML models generalize to unseen benign samples, and assessed how they\nimpact transferability, when applied individually or composed. Performing\nexhaustive search on a small subset of augmentation techniques and genetic\nsearch on all techniques, we identified augmentation combinations that help\npromote transferability. Extensive experiments with the ImageNet and CIFAR-10\ndatasets and 18 models showed that simple color-space augmentations (e.g.,\ncolor to greyscale) attain high transferability when combined with standard\naugmentations. Furthermore, we discovered that composing augmentations impacts\ntransferability mostly monotonically (i.e., more augmentations $\\rightarrow$\n$\\ge$transferability). We also found that the best composition significantly\noutperformed the state of the art (e.g., 91.8% vs. $\\le$82.5% average\ntransferability to adversarially trained targets on ImageNet). Lastly, our\ntheoretical analysis, backed by empirical evidence, intuitively explains why\ncertain augmentations promote transferability.\n","authors":["Zebin Yun","Achi-Or Weingarten","Eyal Ronen","Mahmood Sharif"],"pdf_url":"https://arxiv.org/pdf/2312.11309v2.pdf","comment":"Accepted by AISec'24"},{"id":"http://arxiv.org/abs/2402.02316v3","updated":"2024-10-23T05:26:10Z","published":"2024-02-04T02:09:18Z","title":"Diffusion Models are Certifiably Robust Classifiers","summary":"  Generative learning, recognized for its effective modeling of data\ndistributions, offers inherent advantages in handling out-of-distribution\ninstances, especially for enhancing robustness to adversarial attacks. Among\nthese, diffusion classifiers, utilizing powerful diffusion models, have\ndemonstrated superior empirical robustness. However, a comprehensive\ntheoretical understanding of their robustness is still lacking, raising\nconcerns about their vulnerability to stronger future attacks. In this study,\nwe prove that diffusion classifiers possess $O(1)$ Lipschitzness, and establish\ntheir certified robustness, demonstrating their inherent resilience. To achieve\nnon-constant Lipschitzness, thereby obtaining much tighter certified\nrobustness, we generalize diffusion classifiers to classify Gaussian-corrupted\ndata. This involves deriving the evidence lower bounds (ELBOs) for these\ndistributions, approximating the likelihood using the ELBO, and calculating\nclassification probabilities via Bayes' theorem. Experimental results show the\nsuperior certified robustness of these Noised Diffusion Classifiers (NDCs).\nNotably, we achieve over 80% and 70% certified robustness on CIFAR-10 under\nadversarial perturbations with \\(\\ell_2\\) norms less than 0.25 and 0.5,\nrespectively, using a single off-the-shelf diffusion model without any\nadditional data.\n","authors":["Huanran Chen","Yinpeng Dong","Shitong Shao","Zhongkai Hao","Xiao Yang","Hang Su","Jun Zhu"],"pdf_url":"https://arxiv.org/pdf/2402.02316v3.pdf","comment":"Accepted by NeurIPS 2024"},{"id":"http://arxiv.org/abs/2410.17565v1","updated":"2024-10-23T05:19:20Z","published":"2024-10-23T05:19:20Z","title":"Double Banking on Knowledge: Customized Modulation and Prototypes for\n  Multi-Modality Semi-supervised Medical Image Segmentation","summary":"  Multi-modality (MM) semi-supervised learning (SSL) based medical image\nsegmentation has recently gained increasing attention for its ability to\nutilize MM data and reduce reliance on labeled images. However, current methods\nface several challenges: (1) Complex network designs hinder scalability to\nscenarios with more than two modalities. (2) Focusing solely on\nmodality-invariant representation while neglecting modality-specific features,\nleads to incomplete MM learning. (3) Leveraging unlabeled data with generative\nmethods can be unreliable for SSL. To address these problems, we propose Double\nBank Dual Consistency (DBDC), a novel MM-SSL approach for medical image\nsegmentation. To address challenge (1), we propose a modality all-in-one\nsegmentation network that accommodates data from any number of modalities,\nremoving the limitation on modality count. To address challenge (2), we design\ntwo learnable plug-in banks, Modality-Level Modulation bank (MLMB) and\nModality-Level Prototype (MLPB) bank, to capture both modality-invariant and\nmodality-specific knowledge. These banks are updated using our proposed\nModality Prototype Contrastive Learning (MPCL). Additionally, we design\nModality Adaptive Weighting (MAW) to dynamically adjust learning weights for\neach modality, ensuring balanced MM learning as different modalities learn at\ndifferent rates. Finally, to address challenge (3), we introduce a Dual\nConsistency (DC) strategy that enforces consistency at both the image and\nfeature levels without relying on generative methods. We evaluate our method on\na 2-to-4 modality segmentation task using three open-source datasets, and\nextensive experiments show that our method outperforms state-of-the-art\napproaches.\n","authors":["Yingyu Chen","Ziyuan Yang","Ming Yan","Zhongzhou Zhang","Hui Yu","Yan Liu","Yi Zhang"],"pdf_url":"https://arxiv.org/pdf/2410.17565v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2312.06316v2","updated":"2024-10-23T05:14:19Z","published":"2023-12-11T12:03:30Z","title":"SemiSAM: Enhancing Semi-Supervised Medical Image Segmentation via\n  SAM-Assisted Consistency Regularization","summary":"  Semi-supervised learning has attracted much attention due to its less\ndependence on acquiring abundant annotations from experts compared to fully\nsupervised methods, which is especially important for medical image\nsegmentation which typically requires intensive pixel/voxel-wise labeling by\ndomain experts. Although semi-supervised methods can improve the performance by\nutilizing unlabeled data, there are still gaps between fully supervised methods\nunder extremely limited annotation scenarios. In this paper, we propose a\nsimple yet efficient strategy to explore the usage of the Segment Anything\nModel (SAM) for enhancing semi-supervised medical image segmentation.\nConcretely, the segmentation model trained with domain knowledge provides\ninformation for localization and generating input prompts to the SAM. Then the\ngenerated pseudo-labels of SAM are utilized as additional supervision to assist\nin the learning procedure of the semi-supervised framework. Extensive\nexperiments demonstrate that SemiSAM significantly improves the performance of\nexisting semi-supervised frameworks when only one or a few labeled images are\navailable and shows strong efficiency as a plug-and-play strategy for\nsemi-supervised medical image segmentation.\n","authors":["Yichi Zhang","Jin Yang","Yuchen Liu","Yuan Cheng","Yuan Qi"],"pdf_url":"https://arxiv.org/pdf/2312.06316v2.pdf","comment":"Accept for BIBM 2024"},{"id":"http://arxiv.org/abs/2410.17557v1","updated":"2024-10-23T04:46:36Z","published":"2024-10-23T04:46:36Z","title":"BlurryScope: a cost-effective and compact scanning microscope for\n  automated HER2 scoring using deep learning on blurry image data","summary":"  We developed a rapid scanning optical microscope, termed \"BlurryScope\", that\nleverages continuous image acquisition and deep learning to provide a\ncost-effective and compact solution for automated inspection and analysis of\ntissue sections. BlurryScope integrates specialized hardware with a neural\nnetwork-based model to quickly process motion-blurred histological images and\nperform automated pathology classification. This device offers comparable speed\nto commercial digital pathology scanners, but at a significantly lower price\npoint and smaller size/weight, making it ideal for fast triaging in small\nclinics, as well as for resource-limited settings. To demonstrate the\nproof-of-concept of BlurryScope, we implemented automated classification of\nhuman epidermal growth factor receptor 2 (HER2) scores on immunohistochemically\n(IHC) stained breast tissue sections, achieving concordant results with those\nobtained from a high-end digital scanning microscope. We evaluated this\napproach by scanning HER2-stained tissue microarrays (TMAs) at a continuous\nspeed of 5 mm/s, which introduces bidirectional motion blur artifacts. These\ncompromised images were then used to train our network models. Using a test set\nof 284 unique patient cores, we achieved blind testing accuracies of 79.3% and\n89.7% for 4-class (0, 1+, 2+, 3+) and 2-class (0/1+ , 2+/3+) HER2 score\nclassification, respectively. BlurryScope automates the entire workflow, from\nimage scanning to stitching and cropping of regions of interest, as well as\nHER2 score classification. We believe BlurryScope has the potential to enhance\nthe current pathology infrastructure in resource-scarce environments, save\ndiagnostician time and bolster cancer identification and classification across\nvarious clinical environments.\n","authors":["Michael John Fanous","Christopher Michael Seybold","Hanlong Chen","Nir Pillar","Aydogan Ozcan"],"pdf_url":"https://arxiv.org/pdf/2410.17557v1.pdf","comment":"18 Pages, 6 Figures"},{"id":"http://arxiv.org/abs/2409.05280v2","updated":"2024-10-23T04:41:51Z","published":"2024-09-09T02:18:50Z","title":"RotCAtt-TransUNet++: Novel Deep Neural Network for Sophisticated Cardiac\n  Segmentation","summary":"  Cardiovascular disease remains a predominant global health concern,\nresponsible for a significant portion of mortality worldwide. Accurate\nsegmentation of cardiac medical imaging data is pivotal in mitigating fatality\nrates associated with cardiovascular conditions. However, existing\nstate-of-the-art (SOTA) neural networks, including both CNN-based and\nTransformer-based approaches, exhibit limitations in practical applicability\ndue to their inability to effectively capture inter-slice connections alongside\nintra-slice information. This deficiency is particularly evident in datasets\nfeaturing intricate, long-range details along the z-axis, such as coronary\narteries in axial views. Additionally, SOTA methods fail to differentiate\nnon-cardiac components from myocardium in segmentation, leading to the\n\"spraying\" phenomenon. To address these challenges, we present\nRotCAtt-TransUNet++, a novel architecture tailored for robust segmentation of\ncomplex cardiac structures. Our approach emphasizes modeling global contexts by\naggregating multiscale features with nested skip connections in the encoder. It\nintegrates transformer layers to capture interactions between patches and\nemploys a rotatory attention mechanism to capture connectivity between multiple\nslices (inter-slice information). Additionally, a channel-wise cross-attention\ngate guides the fused multi-scale channel-wise information and features from\ndecoder stages to bridge semantic gaps. Experimental results demonstrate that\nour proposed model outperforms existing SOTA approaches across four cardiac\ndatasets and one abdominal dataset. Importantly, coronary arteries and\nmyocardium are annotated with near-perfect accuracy during inference. An\nablation study shows that the rotatory attention mechanism effectively\ntransforms embedded vectorized patches in the semantic dimensional space,\nenhancing segmentation accuracy.\n","authors":["Quoc-Bao Nguyen-Le","Tuan-Hy Le","Anh-Triet Do","Quoc-Huy Trinh"],"pdf_url":"https://arxiv.org/pdf/2409.05280v2.pdf","comment":"11 pages, 11 figures"},{"id":"http://arxiv.org/abs/2309.12029v2","updated":"2024-10-23T04:36:26Z","published":"2023-09-21T12:51:11Z","title":"Exploring Self-Supervised Skeleton-Based Human Action Recognition under\n  Occlusions","summary":"  To integrate self-supervised skeleton-based action recognition methods into\nautonomous robotic systems, it is crucial to consider adverse situations\ninvolving target occlusions. Such a scenario, despite its practical relevance,\nis rarely addressed in existing self-supervised skeleton-based action\nrecognition methods. To empower models with the capacity to address occlusion,\nwe propose a simple and effective method. We first pre-train using occluded\nskeleton sequences, then use k-means clustering (KMeans) on sequence embeddings\nto group semantically similar samples. Next, we propose KNN-Imputation to fill\nin missing skeleton data based on the closest sample neighbors. Imputing\nincomplete skeleton sequences to create relatively complete sequences as input\nprovides significant benefits to existing skeleton-based self-supervised\nmethods. Meanwhile, building on the state-of-the-art Partial Spatio-Temporal\nLearning (PSTL), we introduce an Occluded Partial Spatio-Temporal Learning\n(OPSTL) framework. This enhancement utilizes Adaptive Spatial Masking (ASM) for\nbetter use of high-quality, intact skeletons. The new proposed method is\nverified on the challenging occluded versions of the NTURGB+D 60 and NTURGB+D\n120. The source code is publicly available at https://github.com/cyfml/OPSTL.\n","authors":["Yifei Chen","Kunyu Peng","Alina Roitberg","David Schneider","Jiaming Zhang","Junwei Zheng","Ruiping Liu","Yufan Chen","Kailun Yang","Rainer Stiefelhagen"],"pdf_url":"https://arxiv.org/pdf/2309.12029v2.pdf","comment":"The source code is publicly available at\n  https://github.com/cyfml/OPSTL"},{"id":"http://arxiv.org/abs/2305.19599v4","updated":"2024-10-23T03:59:05Z","published":"2023-05-31T06:59:21Z","title":"RealignDiff: Boosting Text-to-Image Diffusion Model with Coarse-to-fine\n  Semantic Re-alignment","summary":"  Recent advances in text-to-image diffusion models have achieved remarkable\nsuccess in generating high-quality, realistic images from textual descriptions.\nHowever, these approaches have faced challenges in precisely aligning the\ngenerated visual content with the textual concepts described in the prompts. In\nthis paper, we propose a two-stage coarse-to-fine semantic re-alignment method,\nnamed RealignDiff, aimed at improving the alignment between text and images in\ntext-to-image diffusion models. In the coarse semantic re-alignment phase, a\nnovel caption reward, leveraging the BLIP-2 model, is proposed to evaluate the\nsemantic discrepancy between the generated image caption and the given text\nprompt. Subsequently, the fine semantic re-alignment stage employs a local\ndense caption generation module and a re-weighting attention modulation module\nto refine the previously generated images from a local semantic view.\nExperimental results on the MS-COCO and ViLG-300 datasets demonstrate that the\nproposed two-stage coarse-to-fine semantic re-alignment method outperforms\nother baseline re-alignment techniques by a substantial margin in both visual\nquality and semantic similarity with the input prompt.\n","authors":["Guian Fang","Zutao Jiang","Jianhua Han","Guansong Lu","Hang Xu","Shengcai Liao","Xiaojun Chang","Xiaodan Liang"],"pdf_url":"https://arxiv.org/pdf/2305.19599v4.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.17543v1","updated":"2024-10-23T03:47:29Z","published":"2024-10-23T03:47:29Z","title":"Unsupervised Low-dose CT Reconstruction with One-way Conditional\n  Normalizing Flows","summary":"  Deep-learning methods have shown promising performance for low-dose computed\ntomography (LDCT) reconstruction. However, supervised methods face the problem\nof lacking labeled data in clinical scenarios, and the CNN-based unsupervised\ndenoising methods would cause excessive smoothing in the reconstructed image.\nRecently, the normalizing flows (NFs) based methods have shown advantages in\nproducing detail-rich images and avoiding over-smoothing, however, there are\nstill issues: (1) Although the alternating optimization in the data and latent\nspace can well utilize the regularization and generation capabilities of NFs,\nthe current two-way transformation strategy of noisy images and latent\nvariables would cause detail loss and secondary artifacts; and (2) Training NFs\non high-resolution CT images is hard due to huge computation. Though using\nconditional normalizing flows (CNFs) to learn conditional probability can\nreduce the computational burden, current methods require labeled data for\nconditionalization, and the unsupervised CNFs-based LDCT reconstruction remains\na problem. To tackle these problems, we propose a novel CNFs-based unsupervised\nLDCT iterative reconstruction algorithm. It employs strict one-way\ntransformation when performing alternating optimization in the dual spaces,\nthus effectively avoiding the problems of detail loss and secondary artifacts.\nBy proposing a novel unsupervised conditionalization strategy, we train CNFs on\nhigh-resolution CT images, thus achieving fast and high-quality unsupervised\nreconstruction. Experiments on different datasets suggest that the performance\nof the proposed algorithm could surpass some state-of-the-art unsupervised and\neven supervised methods.\n","authors":["Ran An","Ke Chen","Hongwei Li"],"pdf_url":"https://arxiv.org/pdf/2410.17543v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2402.05741v2","updated":"2024-10-23T03:39:00Z","published":"2024-02-08T15:19:50Z","title":"Real-World Robot Applications of Foundation Models: A Review","summary":"  Recent developments in foundation models, like Large Language Models (LLMs)\nand Vision-Language Models (VLMs), trained on extensive data, facilitate\nflexible application across different tasks and modalities. Their impact spans\nvarious fields, including healthcare, education, and robotics. This paper\nprovides an overview of the practical application of foundation models in\nreal-world robotics, with a primary emphasis on the replacement of specific\ncomponents within existing robot systems. The summary encompasses the\nperspective of input-output relationships in foundation models, as well as\ntheir role in perception, motion planning, and control within the field of\nrobotics. This paper concludes with a discussion of future challenges and\nimplications for practical robot applications.\n","authors":["Kento Kawaharazuka","Tatsuya Matsushima","Andrew Gambardella","Jiaxian Guo","Chris Paxton","Andy Zeng"],"pdf_url":"https://arxiv.org/pdf/2402.05741v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.17534v1","updated":"2024-10-23T03:28:46Z","published":"2024-10-23T03:28:46Z","title":"OVT-B: A New Large-Scale Benchmark for Open-Vocabulary Multi-Object\n  Tracking","summary":"  Open-vocabulary object perception has become an important topic in artificial\nintelligence, which aims to identify objects with novel classes that have not\nbeen seen during training. Under this setting, open-vocabulary object detection\n(OVD) in a single image has been studied in many literature. However,\nopen-vocabulary object tracking (OVT) from a video has been studied less, and\none reason is the shortage of benchmarks. In this work, we have built a new\nlarge-scale benchmark for open-vocabulary multi-object tracking namely OVT-B.\nOVT-B contains 1,048 categories of objects and 1,973 videos with 637,608\nbounding box annotations, which is much larger than the sole open-vocabulary\ntracking dataset, i.e., OVTAO-val dataset (200+ categories, 900+ videos). The\nproposed OVT-B can be used as a new benchmark to pave the way for OVT research.\nWe also develop a simple yet effective baseline method for OVT. It integrates\nthe motion features for object tracking, which is an important feature for MOT\nbut is ignored in previous OVT methods. Experimental results have verified the\nusefulness of the proposed benchmark and the effectiveness of our method. We\nhave released the benchmark to the public at\nhttps://github.com/Coo1Sea/OVT-B-Dataset.\n","authors":["Haiji Liang","Ruize Han"],"pdf_url":"https://arxiv.org/pdf/2410.17534v1.pdf","comment":"15 pages, 6 figures, accepted at NeurIPS 2024 Dataset and Benchmark\n  Track"},{"id":"http://arxiv.org/abs/2406.14515v2","updated":"2024-10-23T03:09:54Z","published":"2024-06-20T17:26:01Z","title":"MMBench-Video: A Long-Form Multi-Shot Benchmark for Holistic Video\n  Understanding","summary":"  The advent of large vision-language models (LVLMs) has spurred research into\ntheir applications in multi-modal contexts, particularly in video\nunderstanding. Traditional VideoQA benchmarks, despite providing quantitative\nmetrics, often fail to encompass the full spectrum of video content and\ninadequately assess models' temporal comprehension. To address these\nlimitations, we introduce MMBench-Video, a quantitative benchmark designed to\nrigorously evaluate LVLMs' proficiency in video understanding. MMBench-Video\nincorporates lengthy videos from YouTube and employs free-form questions,\nmirroring practical use cases. The benchmark is meticulously crafted to probe\nthe models' temporal reasoning skills, with all questions human-annotated\naccording to a carefully constructed ability taxonomy. We employ GPT-4 for\nautomated assessment, demonstrating superior accuracy and robustness over\nearlier LLM-based evaluations. Utilizing MMBench-Video, we have conducted\ncomprehensive evaluations that include both proprietary and open-source LVLMs\nfor images and videos. MMBench-Video stands as a valuable resource for the\nresearch community, facilitating improved evaluation of LVLMs and catalyzing\nprogress in the field of video understanding. The evalutation code of\nMMBench-Video will be integrated into VLMEvalKit:\nhttps://github.com/open-compass/VLMEvalKit.\n","authors":["Xinyu Fang","Kangrui Mao","Haodong Duan","Xiangyu Zhao","Yining Li","Dahua Lin","Kai Chen"],"pdf_url":"https://arxiv.org/pdf/2406.14515v2.pdf","comment":"Accepted in NeurIPS 2024 Datasets and Benchmarks Track"},{"id":"http://arxiv.org/abs/2406.18925v3","updated":"2024-10-23T02:57:31Z","published":"2024-06-27T06:32:56Z","title":"Selective Vision is the Challenge for Visual Reasoning: A Benchmark for\n  Visual Argument Understanding","summary":"  Visual arguments, often used in advertising or social causes, rely on images\nto persuade viewers to do or believe something. Understanding these arguments\nrequires selective vision: only specific visual stimuli within an image are\nrelevant to the argument, and relevance can only be understood within the\ncontext of a broader argumentative structure. While visual arguments are\nreadily appreciated by human audiences, we ask: are today's AI capable of\nsimilar understanding? We present VisArgs, a dataset of 1,611 images annotated\nwith 5,112 visual premises (with regions), 5,574 commonsense premises, and\nreasoning trees connecting them into structured arguments. We propose three\ntasks for evaluating visual argument understanding: premise localization,\npremise identification, and conclusion deduction. Experiments show that 1)\nmachines struggle to capture visual cues: GPT-4-O achieved 78.5% accuracy,\nwhile humans reached 98.0%. Models also performed 19.5% worse when\ndistinguishing between irrelevant objects within the image compared to external\nobjects. 2) Providing relevant visual premises improved model performance\nsignificantly.\n","authors":["Jiwan Chung","Sungjae Lee","Minseo Kim","Seungju Han","Ashkan Yousefpour","Jack Hessel","Youngjae Yu"],"pdf_url":"https://arxiv.org/pdf/2406.18925v3.pdf","comment":"12 pages, 6 figures. Accepted as main paper in EMNLP 2024"},{"id":"http://arxiv.org/abs/2410.01023v2","updated":"2024-10-23T02:55:20Z","published":"2024-10-01T19:32:57Z","title":"Can visual language models resolve textual ambiguity with visual cues?\n  Let visual puns tell you!","summary":"  Humans possess multimodal literacy, allowing them to actively integrate\ninformation from various modalities to form reasoning. Faced with challenges\nlike lexical ambiguity in text, we supplement this with other modalities, such\nas thumbnail images or textbook illustrations. Is it possible for machines to\nachieve a similar multimodal understanding capability? In response, we present\nUnderstanding Pun with Image Explanations (UNPIE), a novel benchmark designed\nto assess the impact of multimodal inputs in resolving lexical ambiguities.\nPuns serve as the ideal subject for this evaluation due to their intrinsic\nambiguity. Our dataset includes 1,000 puns, each accompanied by an image that\nexplains both meanings. We pose three multimodal challenges with the\nannotations to assess different aspects of multimodal literacy; Pun Grounding,\nDisambiguation, and Reconstruction. The results indicate that various Socratic\nModels and Visual-Language Models improve over the text-only models when given\nvisual context, particularly as the complexity of the tasks increases.\n","authors":["Jiwan Chung","Seungwon Lim","Jaehyun Jeon","Seungbeen Lee","Youngjae Yu"],"pdf_url":"https://arxiv.org/pdf/2410.01023v2.pdf","comment":"Accepted as main paper in EMNLP 2024"},{"id":"http://arxiv.org/abs/2410.17521v1","updated":"2024-10-23T02:52:53Z","published":"2024-10-23T02:52:53Z","title":"Diffusion Priors for Variational Likelihood Estimation and Image\n  Denoising","summary":"  Real-world noise removal is crucial in low-level computer vision. Due to the\nremarkable generation capabilities of diffusion models, recent attention has\nshifted towards leveraging diffusion priors for image restoration tasks.\nHowever, existing diffusion priors-based methods either consider simple noise\ntypes or rely on approximate posterior estimation, limiting their effectiveness\nin addressing structured and signal-dependent noise commonly found in\nreal-world images. In this paper, we build upon diffusion priors and propose\nadaptive likelihood estimation and MAP inference during the reverse diffusion\nprocess to tackle real-world noise. We introduce an independent,\nnon-identically distributed likelihood combined with the noise precision\n(inverse variance) prior and dynamically infer the precision posterior using\nvariational Bayes during the generation process. Meanwhile, we rectify the\nestimated noise variance through local Gaussian convolution. The final denoised\nimage is obtained by propagating intermediate MAP solutions that balance the\nupdated likelihood and diffusion prior. Additionally, we explore the local\ndiffusion prior inherent in low-resolution diffusion models, enabling direct\nhandling of high-resolution noisy images. Extensive experiments and analyses on\ndiverse real-world datasets demonstrate the effectiveness of our method. Code\nis available at https://github.com/HUST-Tan/DiffusionVI.\n","authors":["Jun Cheng","Shan Tan"],"pdf_url":"https://arxiv.org/pdf/2410.17521v1.pdf","comment":"Accepted by NeurIPS2024 as Spotlight"},{"id":"http://arxiv.org/abs/2405.20279v2","updated":"2024-10-23T02:38:44Z","published":"2024-05-30T17:33:10Z","title":"CV-VAE: A Compatible Video VAE for Latent Generative Video Models","summary":"  Spatio-temporal compression of videos, utilizing networks such as Variational\nAutoencoders (VAE), plays a crucial role in OpenAI's SORA and numerous other\nvideo generative models. For instance, many LLM-like video models learn the\ndistribution of discrete tokens derived from 3D VAEs within the VQVAE\nframework, while most diffusion-based video models capture the distribution of\ncontinuous latent extracted by 2D VAEs without quantization. The temporal\ncompression is simply realized by uniform frame sampling which results in\nunsmooth motion between consecutive frames. Currently, there lacks of a\ncommonly used continuous video (3D) VAE for latent diffusion-based video models\nin the research community. Moreover, since current diffusion-based approaches\nare often implemented using pre-trained text-to-image (T2I) models, directly\ntraining a video VAE without considering the compatibility with existing T2I\nmodels will result in a latent space gap between them, which will take huge\ncomputational resources for training to bridge the gap even with the T2I models\nas initialization. To address this issue, we propose a method for training a\nvideo VAE of latent video models, namely CV-VAE, whose latent space is\ncompatible with that of a given image VAE, e.g., image VAE of Stable Diffusion\n(SD). The compatibility is achieved by the proposed novel latent space\nregularization, which involves formulating a regularization loss using the\nimage VAE. Benefiting from the latent space compatibility, video models can be\ntrained seamlessly from pre-trained T2I or video models in a truly\nspatio-temporally compressed latent space, rather than simply sampling video\nframes at equal intervals. With our CV-VAE, existing video models can generate\nfour times more frames with minimal finetuning. Extensive experiments are\nconducted to demonstrate the effectiveness of the proposed video VAE.\n","authors":["Sijie Zhao","Yong Zhang","Xiaodong Cun","Shaoshu Yang","Muyao Niu","Xiaoyu Li","Wenbo Hu","Ying Shan"],"pdf_url":"https://arxiv.org/pdf/2405.20279v2.pdf","comment":"Project Page: https://ailab-cvc.github.io/cvvae/index.html"},{"id":"http://arxiv.org/abs/2410.17514v1","updated":"2024-10-23T02:38:12Z","published":"2024-10-23T02:38:12Z","title":"PathMoCo: A Novel Framework to Improve Feature Embedding in\n  Self-supervised Contrastive Learning for Histopathological Images","summary":"  Self-supervised contrastive learning has become a cornerstone in various\nareas, particularly histopathological image analysis. Image augmentation plays\na crucial role in self-supervised contrastive learning, as it generates\nvariations in image samples. However, traditional image augmentation techniques\noften overlook the unique characteristics of histopathological images. In this\npaper, we propose a new histopathology-specific image augmentation method\ncalled stain reconstruction augmentation (SRA). We integrate our SRA with MoCo\nv3, a leading model in self-supervised contrastive learning, along with our\nadditional contrastive loss terms, and call the new model PathMoCo. We\ndemonstrate that our PathMoCo always outperforms the standard MoCo v3 across\nvarious downstream tasks and achieves comparable or superior performance to\nother foundation models pre-trained on significantly larger histopathology\ndatasets.\n","authors":["Hamid Manoochehri","Bodong Zhang","Beatrice S. Knudsen","Tolga Tasdizen"],"pdf_url":"https://arxiv.org/pdf/2410.17514v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.17513v1","updated":"2024-10-23T02:36:47Z","published":"2024-10-23T02:36:47Z","title":"HCDN: A Change Detection Network for Construction Housekeeping Using\n  Feature Fusion and Large Vision Models","summary":"  Workplace safety has received increasing attention as millions of workers\nworldwide suffer from work-related accidents. Despite poor housekeeping is a\nsignificant contributor to construction accidents, there remains a significant\nlack of technological research focused on improving housekeeping practices in\nconstruction sites. Recognizing and locating poor housekeeping in a dynamic\nconstruction site is an important task that can be improved through computer\nvision approaches. Despite advances in AI and computer vision, existing methods\nfor detecting poor housekeeping conditions face many challenges, including\nlimited explanations, lack of locating of poor housekeeping, and lack of\nannotated datasets. On the other hand, change detection which aims to detect\nthe changed environmental conditions (e.g., changing from good to poor\nhousekeeping) and 'where' the change has occurred (e.g., location of objects\ncausing poor housekeeping), has not been explored to the problem of\nhousekeeping management. To address these challenges, we propose the\nHousekeeping Change Detection Network (HCDN), an advanced change detection\nneural network that integrates a feature fusion module and a large vision\nmodel, achieving state-of-the-art performance. Additionally, we introduce the\napproach to establish a novel change detection dataset (named Housekeeping-CCD)\nfocused on housekeeping in construction sites, along with a housekeeping\nsegmentation dataset. Our contributions include significant performance\nimprovements compared to existing methods, providing an effective tool for\nenhancing construction housekeeping and safety. To promote further development,\nwe share our source code and trained models for global researchers:\nhttps://github.com/NUS-DBE/Housekeeping-CD.\n","authors":["Kailai Sun","Zherui Shao","Yang Miang Goh","Jing Tian","Vincent J. L. Gan"],"pdf_url":"https://arxiv.org/pdf/2410.17513v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2407.15070v2","updated":"2024-10-23T02:35:58Z","published":"2024-07-21T06:03:11Z","title":"GPHM: Gaussian Parametric Head Model for Monocular Head Avatar\n  Reconstruction","summary":"  Creating high-fidelity 3D human head avatars is crucial for applications in\nVR/AR, digital human, and film production. Recent advances have leveraged\nmorphable face models to generate animated head avatars from easily accessible\ndata, representing varying identities and expressions within a low-dimensional\nparametric space. However, existing methods often struggle with modeling\ncomplex appearance details, e.g., hairstyles, and suffer from low rendering\nquality and efficiency. In this paper we introduce a novel approach, 3D\nGaussian Parametric Head Model, which employs 3D Gaussians to accurately\nrepresent the complexities of the human head, allowing precise control over\nboth identity and expression. The Gaussian model can handle intricate details,\nenabling realistic representations of varying appearances and complex\nexpressions. Furthermore, we presents a well-designed training framework to\nensure smooth convergence, providing a robust guarantee for learning the rich\ncontent. Our method achieves high-quality, photo-realistic rendering with\nreal-time efficiency, making it a valuable contribution to the field of\nparametric head models. Finally, we apply the 3D Gaussian Parametric Head Model\nto monocular video or few-shot head avatar reconstruction tasks, which enables\ninstant reconstruction of high-quality 3D head avatars even when input data is\nextremely limited, surpassing previous methods in terms of reconstruction\nquality and training speed.\n","authors":["Yuelang Xu","Zhaoqi Su","Qingyao Wu","Yebin Liu"],"pdf_url":"https://arxiv.org/pdf/2407.15070v2.pdf","comment":"Project page: https://yuelangx.github.io/gphmv2/"},{"id":"http://arxiv.org/abs/2403.08350v2","updated":"2024-10-23T02:16:37Z","published":"2024-03-13T08:54:31Z","title":"CoIN: A Benchmark of Continual Instruction tuNing for Multimodel Large\n  Language Model","summary":"  Instruction tuning represents a prevalent strategy employed by Multimodal\nLarge Language Models (MLLMs) to align with human instructions and adapt to new\ntasks. Nevertheless, MLLMs encounter the challenge of adapting to users'\nevolving knowledge and demands. Therefore, how to retain existing skills while\nacquiring new knowledge needs to be investigated. In this paper, we present a\ncomprehensive benchmark, namely Continual Instruction tuNing (CoIN), to assess\nexisting MLLMs in the sequential instruction tuning paradigm. CoIN comprises 10\ncommonly used datasets spanning 8 task categories, ensuring a diverse range of\ninstructions and tasks. Besides, the trained model is evaluated from two\naspects: Instruction Following and General Knowledge, which assess the\nalignment with human intention and knowledge preserved for reasoning,\nrespectively. Experiments on CoIN demonstrate that current powerful MLLMs still\nsuffer catastrophic forgetting, and the failure in intention alignment assumes\nthe main responsibility, instead of the knowledge forgetting. To this end, we\nintroduce MoELoRA to MLLMs which is effective to retain the previous\ninstruction alignment. Experimental results consistently illustrate the\nforgetting decreased from this method on CoIN.\n","authors":["Cheng Chen","Junchen Zhu","Xu Luo","Hengtao Shen","Lianli Gao","Jingkuan Song"],"pdf_url":"https://arxiv.org/pdf/2403.08350v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2409.05166v4","updated":"2024-10-23T02:10:29Z","published":"2024-09-08T17:35:48Z","title":"CD-NGP: A Fast Scalable Continual Representation for Dynamic Scenes","summary":"  Current methodologies for novel view synthesis (NVS) in dynamic scenes\nencounter significant challenges in harmonizing memory consumption, model\ncomplexity, training efficiency, and rendering fidelity. Existing offline\ntechniques, while delivering high-quality results, are often characterized by\nsubstantial memory demands and limited scalability. In contrast, online methods\ngrapple with the challenge of balancing rapid convergence with model\ncompactness. To address these issues, we propose continual dynamic neural\ngraphics primitives (CD-NGP). Our approach synergizes features from both\ntemporal and spatial hash encodings to achieve high rendering quality, employs\nparameter reuse to enhance scalability, and leverages a continual learning\nframework to mitigate memory overhead. Furthermore, we introduce a novel\ndataset comprising multi-view, exceptionally long video sequences with\nsubstantial rigid and non-rigid motion, thereby substantiating the scalability\nof our method.\n","authors":["Zhenhuan Liu","Shuai Liu","Zhiwei Ning","Jie Yang","Wei Liu"],"pdf_url":"https://arxiv.org/pdf/2409.05166v4.pdf","comment":"new template, editing"},{"id":"http://arxiv.org/abs/2410.17505v1","updated":"2024-10-23T02:05:05Z","published":"2024-10-23T02:05:05Z","title":"PLGS: Robust Panoptic Lifting with 3D Gaussian Splatting","summary":"  Previous methods utilize the Neural Radiance Field (NeRF) for panoptic\nlifting, while their training and rendering speed are unsatisfactory. In\ncontrast, 3D Gaussian Splatting (3DGS) has emerged as a prominent technique due\nto its rapid training and rendering speed. However, unlike NeRF, the\nconventional 3DGS may not satisfy the basic smoothness assumption as it does\nnot rely on any parameterized structures to render (e.g., MLPs). Consequently,\nthe conventional 3DGS is, in nature, more susceptible to noisy 2D mask\nsupervision. In this paper, we propose a new method called PLGS that enables\n3DGS to generate consistent panoptic segmentation masks from noisy 2D\nsegmentation masks while maintaining superior efficiency compared to NeRF-based\nmethods. Specifically, we build a panoptic-aware structured 3D Gaussian model\nto introduce smoothness and design effective noise reduction strategies. For\nthe semantic field, instead of initialization with structure from motion, we\nconstruct reliable semantic anchor points to initialize the 3D Gaussians. We\nthen use these anchor points as smooth regularization during training.\nAdditionally, we present a self-training approach using pseudo labels generated\nby merging the rendered masks with the noisy masks to enhance the robustness of\nPLGS. For the instance field, we project the 2D instance masks into 3D space\nand match them with oriented bounding boxes to generate cross-view consistent\ninstance masks for supervision. Experiments on various benchmarks demonstrate\nthat our method outperforms previous state-of-the-art methods in terms of both\nsegmentation quality and speed.\n","authors":["Yu Wang","Xiaobao Wei","Ming Lu","Guoliang Kang"],"pdf_url":"https://arxiv.org/pdf/2410.17505v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.17502v1","updated":"2024-10-23T02:00:07Z","published":"2024-10-23T02:00:07Z","title":"Bilateral Hippocampi Segmentation in Low Field MRIs Using Mutual Feature\n  Learning via Dual-Views","summary":"  Accurate hippocampus segmentation in brain MRI is critical for studying\ncognitive and memory functions and diagnosing neurodevelopmental disorders.\nWhile high-field MRIs provide detailed imaging, low-field MRIs are more\naccessible and cost-effective, which eliminates the need for sedation in\nchildren, though they often suffer from lower image quality. In this paper, we\npresent a novel deep-learning approach for the automatic segmentation of\nbilateral hippocampi in low-field MRIs. Extending recent advancements in infant\nbrain segmentation to underserved communities through the use of low-field MRIs\nensures broader access to essential diagnostic tools, thereby supporting better\nhealthcare outcomes for all children. Inspired by our previous work, Co-BioNet,\nthe proposed model employs a dual-view structure to enable mutual feature\nlearning via high-frequency masking, enhancing segmentation accuracy by\nleveraging complementary information from different perspectives. Extensive\nexperiments demonstrate that our method provides reliable segmentation outcomes\nfor hippocampal analysis in low-resource settings. The code is publicly\navailable at: https://github.com/himashi92/LoFiHippSeg.\n","authors":["Himashi Peiris","Zhaolin Chen"],"pdf_url":"https://arxiv.org/pdf/2410.17502v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.17494v1","updated":"2024-10-23T01:25:25Z","published":"2024-10-23T01:25:25Z","title":"Enhancing Multimodal Medical Image Classification using Cross-Graph\n  Modal Contrastive Learning","summary":"  The classification of medical images is a pivotal aspect of disease\ndiagnosis, often enhanced by deep learning techniques. However, traditional\napproaches typically focus on unimodal medical image data, neglecting the\nintegration of diverse non-image patient data. This paper proposes a novel\nCross-Graph Modal Contrastive Learning (CGMCL) framework for multimodal medical\nimage classification. The model effectively integrates both image and non-image\ndata by constructing cross-modality graphs and leveraging contrastive learning\nto align multimodal features in a shared latent space. An inter-modality\nfeature scaling module further optimizes the representation learning process by\nreducing the gap between heterogeneous modalities. The proposed approach is\nevaluated on two datasets: a Parkinson's disease (PD) dataset and a public\nmelanoma dataset. Results demonstrate that CGMCL outperforms conventional\nunimodal methods in accuracy, interpretability, and early disease prediction.\nAdditionally, the method shows superior performance in multi-class melanoma\nclassification. The CGMCL framework provides valuable insights into medical\nimage classification while offering improved disease interpretability and\npredictive capabilities.\n","authors":["Jun-En Ding","Chien-Chin Hsu","Feng Liu"],"pdf_url":"https://arxiv.org/pdf/2410.17494v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.10937v2","updated":"2024-10-23T01:13:24Z","published":"2024-10-14T17:59:58Z","title":"Hybrid Spatial Representations for Species Distribution Modeling","summary":"  We address an important problem in ecology called Species Distribution\nModeling (SDM), whose goal is to predict whether a species exists at a certain\nposition on Earth. In particular, we tackle a challenging version of this task,\nwhere we learn from presence-only data in a community-sourced dataset, model a\nlarge number of species simultaneously, and do not use any additional\nenvironmental information. Previous work has used neural implicit\nrepresentations to construct models that achieve promising results. However,\nimplicit representations often generate predictions of limited spatial\nprecision. We attribute this limitation to their inherently global formulation\nand inability to effectively capture local feature variations. This issue is\nespecially pronounced with presence-only data and a large number of species. To\naddress this, we propose a hybrid embedding scheme that combines both implicit\nand explicit embeddings. Specifically, the explicit embedding is implemented\nwith a multiresolution hashgrid, enabling our models to better capture local\ninformation. Experiments demonstrate that our results exceed other works by a\nlarge margin on various standard benchmarks, and that the hybrid representation\nis better than both purely implicit and explicit ones. Qualitative\nvisualizations and comprehensive ablation studies reveal that our hybrid\nrepresentation successfully addresses the two main challenges. Our code is\nopen-sourced at https://github.com/Shiran-Yuan/HSR-SDM.\n","authors":["Shiran Yuan","Hao Zhao"],"pdf_url":"https://arxiv.org/pdf/2410.10937v2.pdf","comment":"Project codebase https://github.com/Shiran-Yuan/HSR-SDM"},{"id":"http://arxiv.org/abs/2410.17489v1","updated":"2024-10-23T00:59:27Z","published":"2024-10-23T00:59:27Z","title":"Unsupervised Domain Adaptation for Action Recognition via\n  Self-Ensembling and Conditional Embedding Alignment","summary":"  Recent advancements in deep learning-based wearable human action recognition\n(wHAR) have improved the capture and classification of complex motions, but\nadoption remains limited due to the lack of expert annotations and domain\ndiscrepancies from user variations. Limited annotations hinder the model's\nability to generalize to out-of-distribution samples. While data augmentation\ncan improve generalizability, unsupervised augmentation techniques must be\napplied carefully to avoid introducing noise. Unsupervised domain adaptation\n(UDA) addresses domain discrepancies by aligning conditional distributions with\nlabeled target samples, but vanilla pseudo-labeling can lead to error\npropagation. To address these challenges, we propose $\\mu$DAR, a novel joint\noptimization architecture comprised of three functions: (i) consistency\nregularizer between augmented samples to improve model classification\ngeneralizability, (ii) temporal ensemble for robust pseudo-label generation and\n(iii) conditional distribution alignment to improve domain generalizability.\nThe temporal ensemble works by aggregating predictions from past epochs to\nsmooth out noisy pseudo-label predictions, which are then used in the\nconditional distribution alignment module to minimize kernel-based class-wise\nconditional maximum mean discrepancy ($k$CMMD) between the source and target\nfeature space to learn a domain invariant embedding. The\nconsistency-regularized augmentations ensure that multiple augmentations of the\nsame sample share the same labels; this results in (a) strong generalization\nwith limited source domain samples and (b) consistent pseudo-label generation\nin target samples. The novel integration of these three modules in $\\mu$DAR\nresults in a range of $\\approx$ 4-12% average macro-F1 score improvement over\nsix state-of-the-art UDA methods in four benchmark wHAR datasets\n","authors":["Indrajeet Ghosh","Garvit Chugh","Abu Zaher Md Faridee","Nirmalya Roy"],"pdf_url":"https://arxiv.org/pdf/2410.17489v1.pdf","comment":"This work has been accepted to the Proceedings of the IEEE\n  International Conference on Data Mining, 2024"},{"id":"http://arxiv.org/abs/2410.17488v1","updated":"2024-10-23T00:51:47Z","published":"2024-10-23T00:51:47Z","title":"GenDP: 3D Semantic Fields for Category-Level Generalizable Diffusion\n  Policy","summary":"  Diffusion-based policies have shown remarkable capability in executing\ncomplex robotic manipulation tasks but lack explicit characterization of\ngeometry and semantics, which often limits their ability to generalize to\nunseen objects and layouts. To enhance the generalization capabilities of\nDiffusion Policy, we introduce a novel framework that incorporates explicit\nspatial and semantic information via 3D semantic fields. We generate 3D\ndescriptor fields from multi-view RGBD observations with large foundational\nvision models, then compare these descriptor fields against reference\ndescriptors to obtain semantic fields. The proposed method explicitly considers\ngeometry and semantics, enabling strong generalization capabilities in tasks\nrequiring category-level generalization, resolving geometric ambiguities, and\nattention to subtle geometric details. We evaluate our method across eight\ntasks involving articulated objects and instances with varying shapes and\ntextures from multiple object categories. Our method demonstrates its\neffectiveness by increasing Diffusion Policy's average success rate on unseen\ninstances from 20% to 93%. Additionally, we provide a detailed analysis and\nvisualization to interpret the sources of performance gain and explain how our\nmethod can generalize to novel instances.\n","authors":["Yixuan Wang","Guang Yin","Binghao Huang","Tarik Kelestemur","Jiuguang Wang","Yunzhu Li"],"pdf_url":"https://arxiv.org/pdf/2410.17488v1.pdf","comment":"Accepted to Conference on Robot Learning (CoRL 2024). Project Page:\n  https://robopil.github.io/GenDP/"},{"id":"http://arxiv.org/abs/2410.17484v1","updated":"2024-10-23T00:31:17Z","published":"2024-10-23T00:31:17Z","title":"Which Client is Reliable?: A Reliable and Personalized Prompt-based\n  Federated Learning for Medical Image Question Answering","summary":"  Conventional medical artificial intelligence (AI) models face barriers in\nclinical application and ethical issues owing to their inability to handle the\nprivacy-sensitive characteristics of medical data. We present a novel\npersonalized federated learning (pFL) method for medical visual question\nanswering (VQA) models, addressing privacy reliability challenges in the\nmedical domain. Our method introduces learnable prompts into a Transformer\narchitecture to efficiently train it on diverse medical datasets without\nmassive computational costs. Then we introduce a reliable client VQA model that\nincorporates Dempster-Shafer evidence theory to quantify uncertainty in\npredictions, enhancing the model's reliability. Furthermore, we propose a novel\ninter-client communication mechanism that uses maximum likelihood estimation to\nbalance accuracy and uncertainty, fostering efficient integration of insights\nacross clients.\n","authors":["He Zhu","Ren Togo","Takahiro Ogawa","Miki Haseyama"],"pdf_url":"https://arxiv.org/pdf/2410.17484v1.pdf","comment":null}],"Machine Learning":[{"id":"http://arxiv.org/abs/2410.17128v2","updated":"2024-10-23T06:51:54Z","published":"2024-10-22T16:00:44Z","title":"Understanding Transfer Learning via Mean-field Analysis","summary":"  We propose a novel framework for exploring generalization errors of transfer\nlearning through the lens of differential calculus on the space of probability\nmeasures. In particular, we consider two main transfer learning scenarios,\n$\\alpha$-ERM and fine-tuning with the KL-regularized empirical risk\nminimization and establish generic conditions under which the generalization\nerror and the population risk convergence rates for these scenarios are\nstudied. Based on our theoretical results, we show the benefits of transfer\nlearning with a one-hidden-layer neural network in the mean-field regime under\nsome suitable integrability and regularity assumptions on the loss and\nactivation functions.\n","authors":["Gholamali Aminian","Łukasz Szpruch","Samuel N. Cohen"],"pdf_url":"https://arxiv.org/pdf/2410.17128v2.pdf","comment":"Under review"},{"id":"http://arxiv.org/abs/2410.17055v2","updated":"2024-10-23T12:55:39Z","published":"2024-10-22T14:36:44Z","title":"Optimal Design for Reward Modeling in RLHF","summary":"  Reinforcement Learning from Human Feedback (RLHF) has become a popular\napproach to align language models (LMs) with human preferences. This method\ninvolves collecting a large dataset of human pairwise preferences across\nvarious text generations and using it to infer (implicitly or explicitly) a\nreward model. Numerous methods have been proposed to learn the reward model and\nalign a LM with it. However, the costly process of collecting human preferences\nhas received little attention and could benefit from theoretical insights. This\npaper addresses this issue and aims to formalize the reward training model in\nRLHF. We frame the selection of an effective dataset as a simple regret\nminimization task, using a linear contextual dueling bandit method. Given the\npotentially large number of arms, this approach is more coherent than the\nbest-arm identification setting. We then propose an offline framework for\nsolving this problem. Under appropriate assumptions - linearity of the reward\nmodel in the embedding space, and boundedness of the reward parameter - we\nderive bounds on the simple regret. Finally, we provide a lower bound that\nmatches our upper bound up to constant and logarithmic terms. To our knowledge,\nthis is the first theoretical contribution in this area to provide an offline\napproach as well as worst-case guarantees.\n","authors":["Antoine Scheid","Etienne Boursier","Alain Durmus","Michael I. Jordan","Pierre Ménard","Eric Moulines","Michal Valko"],"pdf_url":"https://arxiv.org/pdf/2410.17055v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.16928v2","updated":"2024-10-23T08:13:11Z","published":"2024-10-22T11:59:36Z","title":"xLSTM-Mixer: Multivariate Time Series Forecasting by Mixing via Scalar\n  Memories","summary":"  Time series data is prevalent across numerous fields, necessitating the\ndevelopment of robust and accurate forecasting models. Capturing patterns both\nwithin and between temporal and multivariate components is crucial for reliable\npredictions. We introduce xLSTM-Mixer, a model designed to effectively\nintegrate temporal sequences, joint time-variate information, and multiple\nperspectives for robust forecasting. Our approach begins with a linear forecast\nshared across variates, which is then refined by xLSTM blocks. These blocks\nserve as key elements for modeling the complex dynamics of challenging time\nseries data. xLSTM-Mixer ultimately reconciles two distinct views to produce\nthe final forecast. Our extensive evaluations demonstrate xLSTM-Mixer's\nsuperior long-term forecasting performance compared to recent state-of-the-art\nmethods. A thorough model analysis provides further insights into its key\ncomponents and confirms its robustness and effectiveness. This work contributes\nto the resurgence of recurrent models in time series forecasting.\n","authors":["Maurice Kraus","Felix Divo","Devendra Singh Dhami","Kristian Kersting"],"pdf_url":"https://arxiv.org/pdf/2410.16928v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.16811v2","updated":"2024-10-23T05:57:12Z","published":"2024-10-22T08:38:46Z","title":"Masked Clinical Modelling: A Framework for Synthetic and Augmented\n  Survival Data Generation","summary":"  Access to real clinical data is often restricted due to privacy obligations,\ncreating significant barriers for healthcare research. Synthetic datasets\nprovide a promising solution, enabling secure data sharing and model\ndevelopment. However, most existing approaches focus on data realism rather\nthan utility -- ensuring that models trained on synthetic data yield clinically\nmeaningful insights comparable to those trained on real data. In this paper, we\npresent Masked Clinical Modelling (MCM), a framework inspired by masked\nlanguage modelling, designed for both data synthesis and conditional data\naugmentation. We evaluate this prototype on the WHAS500 dataset using Cox\nProportional Hazards models, focusing on the preservation of hazard ratios as\nkey clinical metrics. Our results show that data generated using the MCM\nframework improves both discrimination and calibration in survival analysis,\noutperforming existing methods. MCM demonstrates strong potential to support\nsurvival data analysis and broader healthcare applications.\n","authors":["Nicholas I-Hsien Kuo","Blanca Gallego","Louisa Jorm"],"pdf_url":"https://arxiv.org/pdf/2410.16811v2.pdf","comment":"Re-archived due to incorrect ORCiD. Last edited: 2024-10-23"},{"id":"http://arxiv.org/abs/2410.18082v1","updated":"2024-10-23T17:59:52Z","published":"2024-10-23T17:59:52Z","title":"Prioritized Generative Replay","summary":"  Sample-efficient online reinforcement learning often uses replay buffers to\nstore experience for reuse when updating the value function. However, uniform\nreplay is inefficient, since certain classes of transitions can be more\nrelevant to learning. While prioritization of more useful samples is helpful,\nthis strategy can also lead to overfitting, as useful samples are likely to be\nmore rare. In this work, we instead propose a prioritized, parametric version\nof an agent's memory, using generative models to capture online experience.\nThis paradigm enables (1) densification of past experience, with new\ngenerations that benefit from the generative model's generalization capacity\nand (2) guidance via a family of \"relevance functions\" that push these\ngenerations towards more useful parts of an agent's acquired history. We show\nthis recipe can be instantiated using conditional diffusion models and simple\nrelevance functions such as curiosity- or value-based metrics. Our approach\nconsistently improves performance and sample efficiency in both state- and\npixel-based domains. We expose the mechanisms underlying these gains, showing\nhow guidance promotes diversity in our generated transitions and reduces\noverfitting. We also showcase how our approach can train policies with even\nhigher update-to-data ratios than before, opening up avenues to better scale\nonline RL agents.\n","authors":["Renhao Wang","Kevin Frans","Pieter Abbeel","Sergey Levine","Alexei A. Efros"],"pdf_url":"https://arxiv.org/pdf/2410.18082v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.18077v1","updated":"2024-10-23T17:58:49Z","published":"2024-10-23T17:58:49Z","title":"ALTA: Compiler-Based Analysis of Transformers","summary":"  We propose a new programming language called ALTA and a compiler that can map\nALTA programs to Transformer weights. ALTA is inspired by RASP, a language\nproposed by Weiss et al. (2021), and Tracr (Lindner et al., 2023), a compiler\nfrom RASP programs to Transformer weights. ALTA complements and extends this\nprior work, offering the ability to express loops and to compile programs to\nUniversal Transformers, among other advantages. ALTA allows us to\nconstructively show how Transformers can represent length-invariant algorithms\nfor computing parity and addition, as well as a solution to the SCAN benchmark\nof compositional generalization tasks, without requiring intermediate\nscratchpad decoding steps. We also propose tools to analyze cases where the\nexpressibility of an algorithm is established, but end-to-end training on a\ngiven training set fails to induce behavior consistent with the desired\nalgorithm. To this end, we explore training from ALTA execution traces as a\nmore fine-grained supervision signal. This enables additional experiments and\ntheoretical analyses relating the learnability of various algorithms to data\navailability and modeling decisions, such as positional encodings. We make the\nALTA framework -- language specification, symbolic interpreter, and weight\ncompiler -- available to the community to enable further applications and\ninsights.\n","authors":["Peter Shaw","James Cohan","Jacob Eisenstein","Kenton Lee","Jonathan Berant","Kristina Toutanova"],"pdf_url":"https://arxiv.org/pdf/2410.18077v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.18076v1","updated":"2024-10-23T17:58:45Z","published":"2024-10-23T17:58:45Z","title":"Leveraging Skills from Unlabeled Prior Data for Efficient Online\n  Exploration","summary":"  Unsupervised pretraining has been transformative in many supervised domains.\nHowever, applying such ideas to reinforcement learning (RL) presents a unique\nchallenge in that fine-tuning does not involve mimicking task-specific data,\nbut rather exploring and locating the solution through iterative\nself-improvement. In this work, we study how unlabeled prior trajectory data\ncan be leveraged to learn efficient exploration strategies. While prior data\ncan be used to pretrain a set of low-level skills, or as additional off-policy\ndata for online RL, it has been unclear how to combine these ideas effectively\nfor online exploration. Our method SUPE (Skills from Unlabeled Prior data for\nExploration) demonstrates that a careful combination of these ideas compounds\ntheir benefits. Our method first extracts low-level skills using a variational\nautoencoder (VAE), and then pseudo-relabels unlabeled trajectories using an\noptimistic reward model, transforming prior data into high-level, task-relevant\nexamples. Finally, SUPE uses these transformed examples as additional\noff-policy data for online RL to learn a high-level policy that composes\npretrained low-level skills to explore efficiently. We empirically show that\nSUPE reliably outperforms prior strategies, successfully solving a suite of\nlong-horizon, sparse-reward tasks. Code: https://github.com/rail-berkeley/supe.\n","authors":["Max Wilcoxson","Qiyang Li","Kevin Frans","Sergey Levine"],"pdf_url":"https://arxiv.org/pdf/2410.18076v1.pdf","comment":"23 pages, 10 figures"},{"id":"http://arxiv.org/abs/2410.18075v1","updated":"2024-10-23T17:57:14Z","published":"2024-10-23T17:57:14Z","title":"ProFL: Performative Robust Optimal Federated Learning","summary":"  Performative prediction (PP) is a framework that captures distribution shifts\nthat occur during the training of machine learning models due to their\ndeployment. As the trained model is used, its generated data could cause the\nmodel to evolve, leading to deviations from the original data distribution. The\nimpact of such model-induced distribution shifts in the federated learning (FL)\nsetup remains unexplored despite being increasingly likely to transpire in\nreal-life use cases. Although Jin et al. (2024) recently extended PP to FL in a\nstraightforward manner, the resulting model only converges to a performative\nstable point, which may be far from optimal. The methods in Izzo et al. (2021);\nMiller et al. (2021) can find a performative optimal point in centralized\nsettings, but they require the performative risk to be convex and the training\ndata to be noiseless, assumptions often violated in realistic FL systems. This\npaper overcomes all of these shortcomings and proposes Performative robust\noptimal Federated Learning (ProFL), an algorithm that finds performative\noptimal points in FL from noisy and contaminated data. We present the\nconvergence analysis under the Polyak-Lojasiewicz condition, which applies to\nnon-convex objectives. Extensive experiments on multiple datasets validate our\nproposed algorithms' efficiency.\n","authors":["Xue Zheng","Tian Xie","Xuwei Tan","Aylin Yener","Xueru Zhang","Ali Payani","Myungjin Lee"],"pdf_url":"https://arxiv.org/pdf/2410.18075v1.pdf","comment":"27 pages with Appendix, 18 figures. The paper has been submitted and\n  is currently under review"},{"id":"http://arxiv.org/abs/2410.18074v1","updated":"2024-10-23T17:56:33Z","published":"2024-10-23T17:56:33Z","title":"UnCLe: Unsupervised Continual Learning of Depth Completion","summary":"  We propose UnCLe, a standardized benchmark for Unsupervised Continual\nLearning of a multimodal depth estimation task: Depth completion aims to infer\na dense depth map from a pair of synchronized RGB image and sparse depth map.\nWe benchmark depth completion models under the practical scenario of\nunsupervised learning over continuous streams of data. Existing methods are\ntypically trained on a static, or stationary, dataset. However, when adapting\nto novel non-stationary distributions, they \"catastrophically forget\"\npreviously learned information. UnCLe simulates these non-stationary\ndistributions by adapting depth completion models to sequences of datasets\ncontaining diverse scenes captured from distinct domains using different visual\nand range sensors. We adopt representative methods from continual learning\nparadigms and translate them to enable unsupervised continual learning of depth\ncompletion. We benchmark these models for indoor and outdoor and investigate\nthe degree of catastrophic forgetting through standard quantitative metrics.\nFurthermore, we introduce model inversion quality as an additional measure of\nforgetting. We find that unsupervised continual learning of depth completion is\nan open problem, and we invite researchers to leverage UnCLe as a development\nplatform.\n","authors":["Suchisrit Gangopadhyay","Xien Chen","Michael Chu","Patrick Rim","Hyoungseob Park","Alex Wong"],"pdf_url":"https://arxiv.org/pdf/2410.18074v1.pdf","comment":"Preprint"},{"id":"http://arxiv.org/abs/2408.12568v2","updated":"2024-10-23T17:53:24Z","published":"2024-08-22T17:35:18Z","title":"Pruning By Explaining Revisited: Optimizing Attribution Methods to Prune\n  CNNs and Transformers","summary":"  To solve ever more complex problems, Deep Neural Networks are scaled to\nbillions of parameters, leading to huge computational costs. An effective\napproach to reduce computational requirements and increase efficiency is to\nprune unnecessary components of these often over-parameterized networks.\nPrevious work has shown that attribution methods from the field of eXplainable\nAI serve as effective means to extract and prune the least relevant network\ncomponents in a few-shot fashion. We extend the current state by proposing to\nexplicitly optimize hyperparameters of attribution methods for the task of\npruning, and further include transformer-based networks in our analysis. Our\napproach yields higher model compression rates of large transformer- and\nconvolutional architectures (VGG, ResNet, ViT) compared to previous works,\nwhile still attaining high performance on ImageNet classification tasks. Here,\nour experiments indicate that transformers have a higher degree of\nover-parameterization compared to convolutional neural networks. Code is\navailable at https://github.com/erfanhatefi/Pruning-by-eXplaining-in-PyTorch.\n","authors":["Sayed Mohammad Vakilzadeh Hatefi","Maximilian Dreyer","Reduan Achtibat","Thomas Wiegand","Wojciech Samek","Sebastian Lapuschkin"],"pdf_url":"https://arxiv.org/pdf/2408.12568v2.pdf","comment":"Accepted as a workshop paper at ECCV 2024, 26 pages (11 pages\n  manuscript, 3 pages references, 12 pages appendix)"},{"id":"http://arxiv.org/abs/2410.18070v1","updated":"2024-10-23T17:53:11Z","published":"2024-10-23T17:53:11Z","title":"Training Free Guided Flow Matching with Optimal Control","summary":"  Controlled generation with pre-trained Diffusion and Flow Matching models has\nvast applications. One strategy for guiding ODE-based generative models is\nthrough optimizing a target loss $R(x_1)$ while staying close to the prior\ndistribution. Along this line, some recent work showed the effectiveness of\nguiding flow model by differentiating through its ODE sampling process. Despite\nthe superior performance, the theoretical understanding of this line of methods\nis still preliminary, leaving space for algorithm improvement. Moreover,\nexisting methods predominately focus on Euclidean data manifold, and there is a\ncompelling need for guided flow methods on complex geometries such as SO(3),\nwhich prevails in high-stake scientific applications like protein design. We\npresent OC-Flow, a general and theoretically grounded training-free framework\nfor guided flow matching using optimal control. Building upon advances in\noptimal control theory, we develop effective and practical algorithms for\nsolving optimal control in guided ODE-based generation and provide a systematic\ntheoretical analysis of the convergence guarantee in both Euclidean and SO(3).\nWe show that existing backprop-through-ODE methods can be interpreted as\nspecial cases of Euclidean OC-Flow. OC-Flow achieved superior performance in\nextensive experiments on text-guided image manipulation, conditional molecule\ngeneration, and all-atom peptide design.\n","authors":["Luran Wang","Chaoran Cheng","Yizhen Liao","Yanru Qu","Ge Liu"],"pdf_url":"https://arxiv.org/pdf/2410.18070v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.03185v2","updated":"2024-10-23T17:52:57Z","published":"2024-03-05T18:22:15Z","title":"Correlated Proxies: A New Definition and Improved Mitigation for Reward\n  Hacking","summary":"  Because it is difficult to precisely specify complex objectives,\nreinforcement learning policies are often optimized using flawed proxy rewards\nthat seem to capture the true objective. However, optimizing proxy rewards\nfrequently leads to reward hacking: the optimized reward function ceases to be\na good proxy, and the resulting policy performs poorly with respect to the\nunspecified true reward. Principled solutions to reward hacking have been\nimpeded by the lack of a good definition for the problem. To address this, we\nintroduce a definition of reward hacking based on the correlation between proxy\nand true rewards for states and actions seen by a \"base policy\" that breaks\ndown under optimization. We show that this definition captures reward hacking\nbehavior across several realistic settings, including in reinforcement learning\nfrom human feedback (RLHF). We then show theoretically that regularization to\nthe base policy can effectively prevent reward hacking. While current RLHF\napproaches apply a KL penalty between the action distributions of policies, our\ntheory suggests that it is more effective to regularize using the $\\chi^2$\ndivergence between the policies' occupancy measures. We intuitively show why\nthis type of regularization is superior and demonstrate that it better\nmitigates reward hacking in practice across four realistic domains, including\nRLHF for LLMs. Our code is available at https://github.com/cassidylaidlaw/orpo.\n","authors":["Cassidy Laidlaw","Shivam Singhal","Anca Dragan"],"pdf_url":"https://arxiv.org/pdf/2403.03185v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.18067v1","updated":"2024-10-23T17:48:28Z","published":"2024-10-23T17:48:28Z","title":"Beyond position: how rotary embeddings shape representations and memory\n  in autoregressive transfomers","summary":"  Rotary Positional Embeddings (RoPE) enhance positional encoding in\nTransformer models, yet their full impact on model dynamics remains\nunderexplored. This paper studies how RoPE introduces position-dependent\nrotations, causing phase shifts in token embeddings that influence\nhigher-frequency components within the model's internal representations.\nThrough spectral analysis, we demonstrate that RoPE's rotation matrices induce\noscillatory behaviors in embeddings, affecting information retention across\nlayers and shaping temporal modeling capabilities. We show that activation\nfunctions in feed-forward networks interact with RoPE-modulated embeddings to\ngenerate harmonics, leading to constructive or destructive interference based\non phase alignment. Our findings reveal that phase alignment amplifies\nactivations and sharpens attention, while misalignment weakens activations and\ndisrupts focus on positional patterns. This study underscores the importance of\nfrequency components as intrinsic elements of model behavior, offering new\ninsights beyond traditional analyses.\n","authors":["Valeria Ruscio","Fabrizio Silvestri"],"pdf_url":"https://arxiv.org/pdf/2410.18067v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.18066v1","updated":"2024-10-23T17:42:54Z","published":"2024-10-23T17:42:54Z","title":"The Double-Edged Sword of Behavioral Responses in Strategic\n  Classification: Theory and User Studies","summary":"  When humans are subject to an algorithmic decision system, they can\nstrategically adjust their behavior accordingly (``game'' the system). While a\ngrowing line of literature on strategic classification has used game-theoretic\nmodeling to understand and mitigate such gaming, these existing works consider\nstandard models of fully rational agents. In this paper, we propose a strategic\nclassification model that considers behavioral biases in human responses to\nalgorithms. We show how misperceptions of a classifier (specifically, of its\nfeature weights) can lead to different types of discrepancies between biased\nand rational agents' responses, and identify when behavioral agents over- or\nunder-invest in different features. We also show that strategic agents with\nbehavioral biases can benefit or (perhaps, unexpectedly) harm the firm compared\nto fully rational strategic agents. We complement our analytical results with\nuser studies, which support our hypothesis of behavioral biases in human\nresponses to the algorithm. Together, our findings highlight the need to\naccount for human (cognitive) biases when designing AI systems, and providing\nexplanations of them, to strategic human in the loop.\n","authors":["Raman Ebrahimi","Kristen Vaccaro","Parinaz Naghizadeh"],"pdf_url":"https://arxiv.org/pdf/2410.18066v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2407.15762v2","updated":"2024-10-23T17:42:39Z","published":"2024-07-22T16:13:38Z","title":"Conditional Language Policy: A General Framework for Steerable\n  Multi-Objective Finetuning","summary":"  Reward-based finetuning is crucial for aligning language policies with\nintended behaviors (e.g., creativity and safety). A key challenge is to develop\nsteerable language models that trade-off multiple (conflicting) objectives in a\nflexible and efficient manner. This paper presents Conditional Language Policy\n(CLP), a general framework for finetuning language models on multiple\nobjectives. Building on techniques from multi-task training and\nparameter-efficient finetuning, CLP learn steerable models that effectively\ntrade-off conflicting objectives at inference time. Notably, this does not\nrequire training or maintaining multiple models to achieve different trade-offs\nbetween the objectives. Through extensive experiments and ablations on two\nsummarization datasets, we show that CLP learns steerable language models that\noutperform and Pareto-dominate the existing approaches for multi-objective\nfinetuning.\n","authors":["Kaiwen Wang","Rahul Kidambi","Ryan Sullivan","Alekh Agarwal","Christoph Dann","Andrea Michi","Marco Gelmi","Yunxuan Li","Raghav Gupta","Avinava Dubey","Alexandre Ramé","Johan Ferret","Geoffrey Cideron","Le Hou","Hongkun Yu","Amr Ahmed","Aranyak Mehta","Léonard Hussenot","Olivier Bachem","Edouard Leurent"],"pdf_url":"https://arxiv.org/pdf/2407.15762v2.pdf","comment":"40 pages. Findings of EMNLP 2024"},{"id":"http://arxiv.org/abs/2410.18065v1","updated":"2024-10-23T17:42:07Z","published":"2024-10-23T17:42:07Z","title":"SPIRE: Synergistic Planning, Imitation, and Reinforcement Learning for\n  Long-Horizon Manipulation","summary":"  Robot learning has proven to be a general and effective technique for\nprogramming manipulators. Imitation learning is able to teach robots solely\nfrom human demonstrations but is bottlenecked by the capabilities of the\ndemonstrations. Reinforcement learning uses exploration to discover better\nbehaviors; however, the space of possible improvements can be too large to\nstart from scratch. And for both techniques, the learning difficulty increases\nproportional to the length of the manipulation task. Accounting for this, we\npropose SPIRE, a system that first uses Task and Motion Planning (TAMP) to\ndecompose tasks into smaller learning subproblems and second combines imitation\nand reinforcement learning to maximize their strengths. We develop novel\nstrategies to train learning agents when deployed in the context of a planning\nsystem. We evaluate SPIRE on a suite of long-horizon and contact-rich robot\nmanipulation problems. We find that SPIRE outperforms prior approaches that\nintegrate imitation learning, reinforcement learning, and planning by 35% to\n50% in average task performance, is 6 times more data efficient in the number\nof human demonstrations needed to train proficient agents, and learns to\ncomplete tasks nearly twice as efficiently. View\nhttps://sites.google.com/view/spire-corl-2024 for more details.\n","authors":["Zihan Zhou","Animesh Garg","Dieter Fox","Caelan Garrett","Ajay Mandlekar"],"pdf_url":"https://arxiv.org/pdf/2410.18065v1.pdf","comment":"Conference on Robot Learning (CoRL) 2024"},{"id":"http://arxiv.org/abs/2410.18038v1","updated":"2024-10-23T17:06:56Z","published":"2024-10-23T17:06:56Z","title":"POD-Attention: Unlocking Full Prefill-Decode Overlap for Faster LLM\n  Inference","summary":"  Each request in LLM inference goes through two phases: compute-bound prefill\nand memory-bandwidth-bound decode. To improve GPU utilization, recent systems\nuse hybrid batching that combines the prefill and decode phases of different\nrequests into the same batch. Hybrid batching works well for linear operations\nas it amortizes the cost of loading model weights from HBM. However, attention\ncomputation in hybrid batches remains inefficient because existing attention\nkernels are optimized for either prefill or decode.\n  In this paper, we present POD-Attention -- the first GPU kernel that\nefficiently computes attention for hybrid batches. POD-Attention aims to\nmaximize the utilization of both compute and memory bandwidth by carefully\nallocating the GPU's resources such that prefill and decode operations happen\nconcurrently on the same multiprocessor. We integrate POD-Attention in a\nstate-of-the-art LLM inference scheduler Sarathi-Serve. POD-Attention speeds up\nattention computation by up to 75% (mean 28%) and increases LLM serving\nthroughput by up to 22% in offline inference. In online inference,\nPOD-Attention enables lower time-to-first-token (TTFT), time-between-tokens\n(TBT), and request execution latency versus Sarathi-Serve.\n","authors":["Aditya K Kamath","Ramya Prabhu","Jayashree Mohan","Simon Peter","Ramachandran Ramjee","Ashish Panwar"],"pdf_url":"https://arxiv.org/pdf/2410.18038v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2409.04429v2","updated":"2024-10-23T16:42:06Z","published":"2024-09-06T17:49:56Z","title":"VILA-U: a Unified Foundation Model Integrating Visual Understanding and\n  Generation","summary":"  VILA-U is a Unified foundation model that integrates Video, Image, Language\nunderstanding and generation. Traditional visual language models (VLMs) use\nseparate modules for understanding and generating visual content, which can\nlead to misalignment and increased complexity. In contrast, VILA-U employs a\nsingle autoregressive next-token prediction framework for both tasks,\neliminating the need for additional components like diffusion models. This\napproach not only simplifies the model but also achieves near state-of-the-art\nperformance in visual language understanding and generation. The success of\nVILA-U is attributed to two main factors: the unified vision tower that aligns\ndiscrete visual tokens with textual inputs during pretraining, which enhances\nvisual perception, and autoregressive image generation can achieve similar\nquality as diffusion models with high-quality dataset. This allows VILA-U to\nperform comparably to more complex models using a fully token-based\nautoregressive framework.\n","authors":["Yecheng Wu","Zhuoyang Zhang","Junyu Chen","Haotian Tang","Dacheng Li","Yunhao Fang","Ligeng Zhu","Enze Xie","Hongxu Yin","Li Yi","Song Han","Yao Lu"],"pdf_url":"https://arxiv.org/pdf/2409.04429v2.pdf","comment":"Code: https://github.com/mit-han-lab/vila-u. The first two authors\n  contributed equally to this work"},{"id":"http://arxiv.org/abs/2409.19841v2","updated":"2024-10-23T16:27:27Z","published":"2024-09-30T00:47:13Z","title":"Counter-Current Learning: A Biologically Plausible Dual Network Approach\n  for Deep Learning","summary":"  Despite its widespread use in neural networks, error backpropagation has\nfaced criticism for its lack of biological plausibility, suffering from issues\nsuch as the backward locking problem and the weight transport problem. These\nlimitations have motivated researchers to explore more biologically plausible\nlearning algorithms that could potentially shed light on how biological neural\nsystems adapt and learn. Inspired by the counter-current exchange mechanisms\nobserved in biological systems, we propose counter-current learning (CCL), a\nbiologically plausible framework for credit assignment in neural networks. This\nframework employs a feedforward network to process input data and a feedback\nnetwork to process targets, with each network enhancing the other through\nanti-parallel signal propagation. By leveraging the more informative signals\nfrom the bottom layer of the feedback network to guide the updates of the top\nlayer of the feedforward network and vice versa, CCL enables the simultaneous\ntransformation of source inputs to target outputs and the dynamic mutual\ninfluence of these transformations. Experimental results on MNIST,\nFashionMNIST, CIFAR10, and CIFAR100 datasets using multi-layer perceptrons and\nconvolutional neural networks demonstrate that CCL achieves comparable\nperformance to other biologically plausible algorithms while offering a more\nbiologically realistic learning mechanism. Furthermore, we showcase the\napplicability of our approach to an autoencoder task, underscoring its\npotential for unsupervised representation learning. Our work presents a\ndirection for biologically inspired and plausible learning algorithms, offering\nan alternative mechanism of learning and adaptation in neural networks.\n","authors":["Chia-Hsiang Kao","Bharath Hariharan"],"pdf_url":"https://arxiv.org/pdf/2409.19841v2.pdf","comment":"Accepted at NeurIPS 2024. Code available at\n  https://github.com/IandRover/CCL-NeurIPS24"},{"id":"http://arxiv.org/abs/2409.17270v2","updated":"2024-10-23T16:27:20Z","published":"2024-09-25T18:35:45Z","title":"Proof of Thought : Neurosymbolic Program Synthesis allows Robust and\n  Interpretable Reasoning","summary":"  Large Language Models (LLMs) have revolutionized natural language processing,\nyet they struggle with inconsistent reasoning, particularly in novel domains\nand complex logical sequences. This research introduces Proof of Thought, a\nframework that enhances the reliability and transparency of LLM outputs. Our\napproach bridges LLM-generated ideas with formal logic verification, employing\na custom interpreter to convert LLM outputs into First Order Logic constructs\nfor theorem prover scrutiny. Central to our method is an intermediary\nJSON-based Domain-Specific Language, which by design balances precise logical\nstructures with intuitive human concepts. This hybrid representation enables\nboth rigorous validation and accessible human comprehension of LLM reasoning\nprocesses. Key contributions include a robust type system with sort management\nfor enhanced logical integrity, explicit representation of rules for clear\ndistinction between factual and inferential knowledge, and a flexible\narchitecture that allows for easy extension to various domain-specific\napplications. We demonstrate Proof of Thought's effectiveness through\nbenchmarking on StrategyQA and a novel multimodal reasoning task, showing\nimproved performance in open-ended scenarios. By providing verifiable and\ninterpretable results, our technique addresses critical needs for AI system\naccountability and sets a foundation for human-in-the-loop oversight in\nhigh-stakes domains.\n","authors":["Debargha Ganguly","Srinivasan Iyengar","Vipin Chaudhary","Shivkumar Kalyanaraman"],"pdf_url":"https://arxiv.org/pdf/2409.17270v2.pdf","comment":"38th Conference on Neural Information Processing Systems (NeurIPS\n  2024) System 2 Reasoning At Scale Workshop"},{"id":"http://arxiv.org/abs/2410.18003v1","updated":"2024-10-23T16:25:36Z","published":"2024-10-23T16:25:36Z","title":"Inferring stability properties of chaotic systems on autoencoders'\n  latent spaces","summary":"  The data-driven learning of solutions of partial differential equations can\nbe based on a divide-and-conquer strategy. First, the high dimensional data is\ncompressed to a latent space with an autoencoder; and, second, the temporal\ndynamics are inferred on the latent space with a form of recurrent neural\nnetwork. In chaotic systems and turbulence, convolutional autoencoders and echo\nstate networks (CAE-ESN) successfully forecast the dynamics, but little is\nknown about whether the stability properties can also be inferred. We show that\nthe CAE-ESN model infers the invariant stability properties and the geometry of\nthe tangent space in the low-dimensional manifold (i.e. the latent space)\nthrough Lyapunov exponents and covariant Lyapunov vectors. This work opens up\nnew opportunities for inferring the stability of high-dimensional chaotic\nsystems in latent spaces.\n","authors":["Elise Özalp","Luca Magri"],"pdf_url":"https://arxiv.org/pdf/2410.18003v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2407.10992v2","updated":"2024-10-23T16:19:06Z","published":"2024-06-24T09:29:14Z","title":"AlleNoise: large-scale text classification benchmark dataset with\n  real-world label noise","summary":"  Label noise remains a challenge for training robust classification models.\nMost methods for mitigating label noise have been benchmarked using primarily\ndatasets with synthetic noise. While the need for datasets with realistic noise\ndistribution has partially been addressed by web-scraped benchmarks such as\nWebVision and Clothing1M, those benchmarks are restricted to the computer\nvision domain. With the growing importance of Transformer-based models, it is\ncrucial to establish text classification benchmarks for learning with noisy\nlabels. In this paper, we present AlleNoise, a new curated text classification\nbenchmark dataset with real-world instance-dependent label noise, containing\nover 500,000 examples across approximately 5,600 classes, complemented with a\nmeaningful, hierarchical taxonomy of categories. The noise distribution comes\nfrom actual users of a major e-commerce marketplace, so it realistically\nreflects the semantics of human mistakes. In addition to the noisy labels, we\nprovide human-verified clean labels, which help to get a deeper insight into\nthe noise distribution, unlike web-scraped datasets typically used in the\nfield. We demonstrate that a representative selection of established methods\nfor learning with noisy labels is inadequate to handle such real-world noise.\nIn addition, we show evidence that these algorithms do not alleviate excessive\nmemorization. As such, with AlleNoise, we set the bar high for the development\nof label noise methods that can handle real-world label noise in text\nclassification tasks. The code and dataset are available for download at\nhttps://github.com/allegro/AlleNoise.\n","authors":["Alicja Rączkowska","Aleksandra Osowska-Kurczab","Jacek Szczerbiński","Kalina Jasinska-Kobus","Klaudia Nazarko"],"pdf_url":"https://arxiv.org/pdf/2407.10992v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.17998v1","updated":"2024-10-23T16:12:59Z","published":"2024-10-23T16:12:59Z","title":"Estimating the Spectral Moments of the Kernel Integral Operator from\n  Finite Sample Matrices","summary":"  Analyzing the structure of sampled features from an input data distribution\nis challenging when constrained by limited measurements in both the number of\ninputs and features. Traditional approaches often rely on the eigenvalue\nspectrum of the sample covariance matrix derived from finite measurement\nmatrices; however, these spectra are sensitive to the size of the measurement\nmatrix, leading to biased insights. In this paper, we introduce a novel\nalgorithm that provides unbiased estimates of the spectral moments of the\nkernel integral operator in the limit of infinite inputs and features from\nfinitely sampled measurement matrices. Our method, based upon dynamic\nprogramming, is efficient and capable of estimating the moments of the operator\nspectrum. We demonstrate the accuracy of our estimator on radial basis function\n(RBF) kernels, highlighting its consistency with the theoretical spectra.\nFurthermore, we showcase the practical utility and robustness of our method in\nunderstanding the geometry of learned representations in neural networks.\n","authors":["Chanwoo Chun","SueYeon Chung","Daniel D. Lee"],"pdf_url":"https://arxiv.org/pdf/2410.17998v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.02131v4","updated":"2024-10-23T16:05:11Z","published":"2024-06-04T09:18:20Z","title":"CondTSF: One-line Plugin of Dataset Condensation for Time Series\n  Forecasting","summary":"  Dataset condensation is a newborn technique that generates a small dataset\nthat can be used in training deep neural networks to lower training costs. The\nobjective of dataset condensation is to ensure that the model trained with the\nsynthetic dataset can perform comparably to the model trained with full\ndatasets. However, existing methods predominantly concentrate on classification\ntasks, posing challenges in their adaptation to time series forecasting\n(TS-forecasting). This challenge arises from disparities in the evaluation of\nsynthetic data. In classification, the synthetic data is considered\nwell-distilled if the model trained with the full dataset and the model trained\nwith the synthetic dataset yield identical labels for the same input,\nregardless of variations in output logits distribution. Conversely, in\nTS-forecasting, the effectiveness of synthetic data distillation is determined\nby the distance between predictions of the two models. The synthetic data is\ndeemed well-distilled only when all data points within the predictions are\nsimilar. Consequently, TS-forecasting has a more rigorous evaluation\nmethodology compared to classification. To mitigate this gap, we theoretically\nanalyze the optimization objective of dataset condensation for TS-forecasting\nand propose a new one-line plugin of dataset condensation designated as Dataset\nCondensation for Time Series Forecasting (CondTSF) based on our analysis.\nPlugging CondTSF into previous dataset condensation methods facilitates a\nreduction in the distance between the predictions of the model trained with the\nfull dataset and the model trained with the synthetic dataset, thereby\nenhancing performance. We conduct extensive experiments on eight commonly used\ntime series datasets. CondTSF consistently improves the performance of all\nprevious dataset condensation methods across all datasets, particularly at low\ncondensing ratios.\n","authors":["Jianrong Ding","Zhanyu Liu","Guanjie Zheng","Haiming Jin","Linghe Kong"],"pdf_url":"https://arxiv.org/pdf/2406.02131v4.pdf","comment":"Accepted by NeurIPS 2024, the project can be found at\n  https://github.com/RafaDD/CondTSF"},{"id":"http://arxiv.org/abs/2304.10650v2","updated":"2024-10-23T16:03:19Z","published":"2023-04-20T21:25:33Z","title":"Learning a quantum computer's capability","summary":"  Accurately predicting a quantum computer's capability -- which circuits it\ncan run and how well it can run them -- is a foundational goal of quantum\ncharacterization and benchmarking. As modern quantum computers become\nincreasingly hard to simulate, we must develop accurate and scalable predictive\ncapability models to help researchers and stakeholders decide which quantum\ncomputers to build and use. In this work, we propose a hardware-agnostic method\nto efficiently construct scalable predictive models of a quantum computer's\ncapability for almost any class of circuits, and demonstrate our method using\nconvolutional neural networks (CNNs). Our CNN-based approach works by\nefficiently representing a circuit as a three-dimensional tensor and then using\na CNN to predict its success rate. Our CNN capability models obtain\napproximately a $1\\%$ average absolute prediction error when modeling\nprocessors experiencing both Markovian and non-Markovian stochastic Pauli\nerrors. We also apply our CNNs to model the capabilities of cloud-access\nquantum computing systems, obtaining moderate prediction accuracy (average\nabsolute error around $2-5\\%$), and we highlight the challenges to building\nbetter neural network capability models.\n","authors":["Daniel Hothem","Kevin Young","Tommie Catanach","Timothy Proctor"],"pdf_url":"https://arxiv.org/pdf/2304.10650v2.pdf","comment":"20 pages, 11 figures, plus appendices"},{"id":"http://arxiv.org/abs/2410.17986v1","updated":"2024-10-23T16:00:14Z","published":"2024-10-23T16:00:14Z","title":"Federated Transformer: Multi-Party Vertical Federated Learning on\n  Practical Fuzzily Linked Data","summary":"  Federated Learning (FL) is an evolving paradigm that enables multiple parties\nto collaboratively train models without sharing raw data. Among its variants,\nVertical Federated Learning (VFL) is particularly relevant in real-world,\ncross-organizational collaborations, where distinct features of a shared\ninstance group are contributed by different parties. In these scenarios,\nparties are often linked using fuzzy identifiers, leading to a common practice\ntermed as multi-party fuzzy VFL. Existing models generally address either\nmulti-party VFL or fuzzy VFL between two parties. Extending these models to\npractical multi-party fuzzy VFL typically results in significant performance\ndegradation and increased costs for maintaining privacy. To overcome these\nlimitations, we introduce the Federated Transformer (FeT), a novel framework\nthat supports multi-party VFL with fuzzy identifiers. FeT innovatively encodes\nthese identifiers into data representations and employs a transformer\narchitecture distributed across different parties, incorporating three new\ntechniques to enhance performance. Furthermore, we have developed a multi-party\nprivacy framework for VFL that integrates differential privacy with secure\nmulti-party computation, effectively protecting local representations while\nminimizing associated utility costs. Our experiments demonstrate that the FeT\nsurpasses the baseline models by up to 46\\% in terms of accuracy when scaled to\n50 parties. Additionally, in two-party fuzzy VFL settings, FeT also shows\nimproved performance and privacy over cutting-edge VFL models.\n","authors":["Zhaomin Wu","Junyi Hou","Yiqun Diao","Bingsheng He"],"pdf_url":"https://arxiv.org/pdf/2410.17986v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.17980v1","updated":"2024-10-23T15:51:13Z","published":"2024-10-23T15:51:13Z","title":"Stick-breaking Attention","summary":"  The self-attention mechanism traditionally relies on the softmax operator,\nnecessitating positional embeddings like RoPE, or position biases to account\nfor token order. But current methods using still face length generalisation\nchallenges. We propose an alternative attention mechanism based on the\nstick-breaking process: For each token before the current, we determine a break\npoint $\\beta_{i,j}$, which represents the proportion of the remaining stick to\nallocate to the current token. We repeat the process until the stick is fully\nallocated, resulting in a sequence of attention weights. This process naturally\nincorporates recency bias, which has linguistic motivations for grammar parsing\n(Shen et. al., 2017). We study the implications of replacing the conventional\nsoftmax-based attention mechanism with stick-breaking attention. We then\ndiscuss implementation of numerically stable stick-breaking attention and adapt\nFlash Attention to accommodate this mechanism. When used as a drop-in\nreplacement for current softmax+RoPE attention systems, we find that\nstick-breaking attention performs competitively with current methods on length\ngeneralisation and downstream tasks. Stick-breaking also performs well at\nlength generalisation, allowing a model trained with $2^{11}$ context window to\nperform well at $2^{14}$ with perplexity improvements.\n","authors":["Shawn Tan","Yikang Shen","Songlin Yang","Aaron Courville","Rameswar Panda"],"pdf_url":"https://arxiv.org/pdf/2410.17980v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.02447v3","updated":"2024-10-23T15:48:45Z","published":"2024-06-04T16:12:27Z","title":"Federated Class-Incremental Learning with Hierarchical Generative\n  Prototypes","summary":"  Federated Learning (FL) aims at unburdening the training of deep models by\ndistributing computation across multiple devices (clients) while safeguarding\ndata privacy. On top of that, Federated Continual Learning (FCL) also accounts\nfor data distribution evolving over time, mirroring the dynamic nature of\nreal-world environments. While previous studies have identified Catastrophic\nForgetting and Client Drift as primary causes of performance degradation in\nFCL, we shed light on the importance of Incremental Bias and Federated Bias,\nwhich cause models to prioritize classes that are recently introduced or\nlocally predominant, respectively. Our proposal constrains both biases in the\nlast layer by efficiently finetuning a pre-trained backbone using learnable\nprompts, resulting in clients that produce less biased representations and more\nbiased classifiers. Therefore, instead of solely relying on parameter\naggregation, we leverage generative prototypes to effectively balance the\npredictions of the global model. Our method significantly improves the current\nState Of The Art, providing an average increase of +7.8% in accuracy. Code to\nreproduce the results is provided in the suppl. material.\n","authors":["Riccardo Salami","Pietro Buzzega","Matteo Mosconi","Mattia Verasani","Simone Calderara"],"pdf_url":"https://arxiv.org/pdf/2406.02447v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.14979v2","updated":"2024-10-23T15:43:28Z","published":"2024-10-19T05:01:56Z","title":"Do Large Language Models Truly Grasp Mathematics? An Empirical\n  Exploration","summary":"  Despite their proficiency in math tasks, the mechanisms underlying LLMs'\nmathematical reasoning abilities remain a subject of debate. Recent studies\nsuggest that chain-of-thought (CoT) prompts can bolster mathematical reasoning\nby encouraging LLMs to employ human-like logical reasoning (System 2), enabling\nthem to excel on the Cognitive Reflection Test (CRT). To assess whether LLMs\ngenuinely possess System 2-like logical reasoning, we introduced targeted\nmodifications to CRT problems. Our findings reveal that, despite the use of CoT\nprompts, mainstream LLMs, including the latest o1-preview model, continue to\nexhibit a significant error rate. Further analysis indicates that they\npredominantly rely on System 1-like intuitive reasoning and pattern matching\nderived from training data, rather than demonstrating mastery of mathematical\nthinking. This discovery challenges the prevailing notion that LLMs possess\ngenuine logical reasoning abilities and that CoT can enhance them.\nConsequently, this work may temper overly optimistic projections regarding\nLLMs' advancement toward artificial general intelligence.\n","authors":["Wei Xie","Shuoyoucheng Ma","Zhenhua Wang","Enze Wang","Baosheng Wang","Jinshu Su"],"pdf_url":"https://arxiv.org/pdf/2410.14979v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.17976v1","updated":"2024-10-23T15:39:08Z","published":"2024-10-23T15:39:08Z","title":"metasnf: Meta Clustering with Similarity Network Fusion in R","summary":"  metasnf is an R package that enables users to apply meta clustering, a method\nfor efficiently searching a broad space of cluster solutions by clustering the\nsolutions themselves, to clustering workflows based on similarity network\nfusion (SNF). SNF is a multi-modal data integration algorithm commonly used for\nbiomedical subtype discovery. The package also contains functions to assist\nwith cluster visualization, characterization, and validation. This package can\nhelp researchers identify SNF-derived cluster solutions that are guided by\ncontext-specific utility over context-agnostic measures of quality.\n","authors":["Prashanth S Velayudhan","Xiaoqiao Xu","Prajkta Kallurkar","Ana Patricia Balbon","Maria T Secara","Adam Taback","Denise Sabac","Nicholas Chan","Shihao Ma","Bo Wang","Daniel Felsky","Stephanie H Ameis","Brian Cox","Colin Hawco","Lauren Erdman","Anne L Wheeler"],"pdf_url":"https://arxiv.org/pdf/2410.17976v1.pdf","comment":"72 pages, 22 figures, submitted to Journal of Statistical Software"},{"id":"http://arxiv.org/abs/2410.17970v1","updated":"2024-10-23T15:36:08Z","published":"2024-10-23T15:36:08Z","title":"Optical Generative Models","summary":"  Generative models cover various application areas, including image, video and\nmusic synthesis, natural language processing, and molecular design, among many\nothers. As digital generative models become larger, scalable inference in a\nfast and energy-efficient manner becomes a challenge. Here, we present optical\ngenerative models inspired by diffusion models, where a shallow and fast\ndigital encoder first maps random noise into phase patterns that serve as\noptical generative seeds for a desired data distribution; a jointly-trained\nfree-space-based reconfigurable decoder all-optically processes these\ngenerative seeds to create novel images (never seen before) following the\ntarget data distribution. Except for the illumination power and the random seed\ngeneration through a shallow encoder, these optical generative models do not\nconsume computing power during the synthesis of novel images. We report the\noptical generation of monochrome and multi-color novel images of handwritten\ndigits, fashion products, butterflies, and human faces, following the data\ndistributions of MNIST, Fashion MNIST, Butterflies-100, and Celeb-A datasets,\nrespectively, achieving an overall performance comparable to digital neural\nnetwork-based generative models. To experimentally demonstrate optical\ngenerative models, we used visible light to generate, in a snapshot, novel\nimages of handwritten digits and fashion products. These optical generative\nmodels might pave the way for energy-efficient, scalable and rapid inference\ntasks, further exploiting the potentials of optics and photonics for artificial\nintelligence-generated content.\n","authors":["Shiqi Chen","Yuhang Li","Hanlong Chen","Aydogan Ozcan"],"pdf_url":"https://arxiv.org/pdf/2410.17970v1.pdf","comment":"24 Pages, 9 Figures"},{"id":"http://arxiv.org/abs/2410.11709v2","updated":"2024-10-23T15:35:57Z","published":"2024-10-15T15:46:03Z","title":"On the potential of Optimal Transport in Geospatial Data Science","summary":"  Prediction problems in geographic information science and transportation are\noften motivated by the possibility to enhance operational efficiency and\nthereby reduce emissions. Examples range from predicting car sharing demand for\nrelocation planning to forecasting traffic congestion for navigation purposes.\nHowever, conventional accuracy metrics ignore the spatial distribution of the\nerrors, despite its relevance for operations. Here, we put forward a spatially\naware evaluation metric and loss function based on Optimal Transport (OT). Our\nframework leverages partial OT and can minimize relocation costs in any spatial\nprediction problem. We showcase the advantages of OT-based evaluation over\nconventional metrics and further demonstrate the application of an OT loss\nfunction for improving forecasts of bike sharing demand and charging station\noccupancy. Thus, our framework not only aligns with operational considerations,\nbut also signifies a step forward in refining predictions within geospatial\napplications. All code is available at https://github.com/mie-lab/geospatialOT.\n","authors":["Nina Wiedemann","Théo Uscidda","Martin Raubal"],"pdf_url":"https://arxiv.org/pdf/2410.11709v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.17967v1","updated":"2024-10-23T15:34:11Z","published":"2024-10-23T15:34:11Z","title":"POMDP-Driven Cognitive Massive MIMO Radar: Joint Target\n  Detection-Tracking In Unknown Disturbances","summary":"  The joint detection and tracking of a moving target embedded in an unknown\ndisturbance represents a key feature that motivates the development of the\ncognitive radar paradigm. Building upon recent advancements in robust target\ndetection with multiple-input multiple-output (MIMO) radars, this work explores\nthe application of a Partially Observable Markov Decision Process (POMDP)\nframework to enhance the tracking and detection tasks in a statistically\nunknown environment. In the POMDP setup, the radar system is considered as an\nintelligent agent that continuously senses the surrounding environment,\noptimizing its actions to maximize the probability of detection $(P_D)$ and\nimprove the target position and velocity estimation, all this while keeping a\nconstant probability of false alarm $(P_{FA})$. The proposed approach employs\nan online algorithm that does not require any apriori knowledge of the noise\nstatistics, and it relies on a much more general observation model than the\ntraditional range-azimuth-elevation model employed by conventional tracking\nalgorithms. Simulation results clearly show substantial performance improvement\nof the POMDP-based algorithm compared to the State-Action-Reward-State-Action\n(SARSA)-based one that has been recently investigated in the context of massive\nMIMO (MMIMO) radar systems.\n","authors":["Imad Bouhou","Stefano Fortunati","Leila Gharsalli","Alexandre Renaux"],"pdf_url":"https://arxiv.org/pdf/2410.17967v1.pdf","comment":"The paper has been submitted to ieee Transactions on radar systems"},{"id":"http://arxiv.org/abs/2401.11576v3","updated":"2024-10-23T15:30:50Z","published":"2024-01-21T19:53:17Z","title":"Quantum Architecture Search with Unsupervised Representation Learning","summary":"  Unsupervised representation learning presents new opportunities for advancing\nQuantum Architecture Search (QAS) on Noisy Intermediate-Scale Quantum (NISQ)\ndevices. QAS is designed to optimize quantum circuits for Variational Quantum\nAlgorithms (VQAs). Most QAS algorithms tightly couple the search space and\nsearch algorithm, typically requiring the evaluation of numerous quantum\ncircuits, resulting in high computational costs and limiting scalability to\nlarger quantum circuits. Predictor-based QAS algorithms mitigate this issue by\nestimating circuit performance based on structure or embedding. However, these\nmethods often demand time-intensive labeling to optimize gate parameters across\nmany circuits, which is crucial for training accurate predictors. Inspired by\nthe classical neural architecture search algorithm Arch2vec, we investigate the\npotential of unsupervised representation learning for QAS without relying on\npredictors. Our framework decouples unsupervised architecture representation\nlearning from the search process, enabling the learned representations to be\napplied across various downstream tasks. Additionally, it integrates an\nimproved quantum circuit graph encoding scheme, addressing the limitations of\nexisting representations and enhancing search efficiency. This predictor-free\napproach removes the need for large labeled datasets. During the search, we\nemploy REINFORCE and Bayesian Optimization to explore the latent representation\nspace and compare their performance against baseline methods. Our results\ndemonstrate that the framework efficiently identifies high-performing quantum\ncircuits with fewer search iterations.\n","authors":["Yize Sun","Zixin Wu","Yunpu Ma","Volker Tresp"],"pdf_url":"https://arxiv.org/pdf/2401.11576v3.pdf","comment":"9 Pages, quantum architecture search, unsupervised representation\n  learning"},{"id":"http://arxiv.org/abs/2410.17963v1","updated":"2024-10-23T15:30:37Z","published":"2024-10-23T15:30:37Z","title":"A Time-Aware Approach to Early Detection of Anorexia: UNSL at eRisk 2024","summary":"  The eRisk laboratory aims to address issues related to early risk detection\non the Web. In this year's edition, three tasks were proposed, where Task 2 was\nabout early detection of signs of anorexia. Early risk detection is a problem\nwhere precision and speed are two crucial objectives. Our research group solved\nTask 2 by defining a CPI+DMC approach, addressing both objectives\nindependently, and a time-aware approach, where precision and speed are\nconsidered a combined single-objective. We implemented the last approach by\nexplicitly integrating time during the learning process, considering the\nERDE{\\theta} metric as the training objective. It also allowed us to\nincorporate temporal metrics to validate and select the optimal models. We\nachieved outstanding results for the ERDE50 metric and ranking-based metrics,\ndemonstrating consistency in solving ERD problems.\n","authors":["Horacio Thompson","Marcelo Errecalde"],"pdf_url":"https://arxiv.org/pdf/2410.17963v1.pdf","comment":"In Conference and Labs of the Evaluation Forum (CLEF 2024), Grenoble,\n  France"},{"id":"http://arxiv.org/abs/2410.17961v1","updated":"2024-10-23T15:30:13Z","published":"2024-10-23T15:30:13Z","title":"Closed-form merging of parameter-efficient modules for Federated\n  Continual Learning","summary":"  Model merging has emerged as a crucial technique in Deep Learning, enabling\nthe integration of multiple models into a unified system while preserving\nperformance and scalability. In this respect, the compositional properties of\nlow-rank adaptation techniques (e.g., LoRA) have proven beneficial, as simple\naveraging LoRA modules yields a single model that mostly integrates the\ncapabilities of all individual modules. Building on LoRA, we take a step\nfurther by imposing that the merged model matches the responses of all learned\nmodules. Solving this objective in closed form yields an indeterminate system\nwith A and B as unknown variables, indicating the existence of infinitely many\nclosed-form solutions. To address this challenge, we introduce LoRM, an\nalternating optimization strategy that trains one LoRA matrix at a time. This\nallows solving for each unknown variable individually, thus finding a unique\nsolution. We apply our proposed methodology to Federated Class-Incremental\nLearning (FCIL), ensuring alignment of model responses both between clients and\nacross tasks. Our method demonstrates state-of-the-art performance across a\nrange of FCIL scenarios.\n","authors":["Riccardo Salami","Pietro Buzzega","Matteo Mosconi","Jacopo Bonato","Luigi Sabetta","Simone Calderara"],"pdf_url":"https://arxiv.org/pdf/2410.17961v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.08649v2","updated":"2024-10-23T15:29:28Z","published":"2024-06-12T21:18:14Z","title":"MOTIVE: A Drug-Target Interaction Graph For Inductive Link Prediction","summary":"  Drug-target interaction (DTI) prediction is crucial for identifying new\ntherapeutics and detecting mechanisms of action. While structure-based methods\naccurately model physical interactions between a drug and its protein target,\ncell-based assays such as Cell Painting can better capture complex DTI\ninteractions. This paper introduces MOTIVE, a Morphological cOmpound Target\nInteraction Graph dataset comprising Cell Painting features for 11,000 genes\nand 3,600 compounds, along with their relationships extracted from seven\npublicly available databases. We provide random, cold-source (new drugs), and\ncold-target (new genes) data splits to enable rigorous evaluation under\nrealistic use cases. Our benchmark results show that graph neural networks that\nuse Cell Painting features consistently outperform those that learn from graph\nstructure alone, feature-based models, and topological heuristics. MOTIVE\naccelerates both graph ML research and drug discovery by promoting the\ndevelopment of more reliable DTI prediction models. MOTIVE resources are\navailable at https://github.com/carpenter-singh-lab/motive.\n","authors":["John Arevalo","Ellen Su","Anne E Carpenter","Shantanu Singh"],"pdf_url":"https://arxiv.org/pdf/2406.08649v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2305.09063v3","updated":"2024-10-23T15:28:59Z","published":"2023-05-15T23:12:15Z","title":"Bounded KRnet and its applications to density estimation and\n  approximation","summary":"  In this paper, we develop an invertible mapping, called B-KRnet, on a bounded\ndomain and apply it to density estimation/approximation for data or the\nsolutions of PDEs such as the Fokker-Planck equation and the Keller-Segel\nequation. Similar to KRnet, the structure of B-KRnet adapts the\npseudo-triangular structure into a normalizing flow model. The main difference\nbetween B-KRnet and KRnet is that B-KRnet is defined on a hypercube while KRnet\nis defined on the whole space, in other words, a new mechanism is introduced in\nB-KRnet to maintain the exact invertibility. Using B-KRnet as a transport map,\nwe obtain an explicit probability density function (PDF) model that corresponds\nto the pushforward of a prior (uniform) distribution on the hypercube. It can\nbe directly applied to density estimation when only data are available. By\ncoupling KRnet and B-KRnet, we define a deep generative model on a\nhigh-dimensional domain where some dimensions are bounded and other dimensions\nare unbounded. A typical case is the solution of the stationary kinetic\nFokker-Planck equation, which is a PDF of position and momentum. Based on\nB-KRnet, we develop an adaptive learning approach to approximate partial\ndifferential equations whose solutions are PDFs or can be treated as PDFs. A\nvariety of numerical experiments is presented to demonstrate the effectiveness\nof B-KRnet.\n","authors":["Li Zeng","Xiaoliang Wan","Tao Zhou"],"pdf_url":"https://arxiv.org/pdf/2305.09063v3.pdf","comment":"26 pages, 13 figures"},{"id":"http://arxiv.org/abs/2201.12091v5","updated":"2024-10-23T15:28:38Z","published":"2022-01-28T13:00:17Z","title":"Linear Adversarial Concept Erasure","summary":"  Modern neural models trained on textual data rely on pre-trained\nrepresentations that emerge without direct supervision. As these\nrepresentations are increasingly being used in real-world applications, the\ninability to \\emph{control} their content becomes an increasingly important\nproblem. We formulate the problem of identifying and erasing a linear subspace\nthat corresponds to a given concept, in order to prevent linear predictors from\nrecovering the concept. We model this problem as a constrained, linear maximin\ngame, and show that existing solutions are generally not optimal for this task.\nWe derive a closed-form solution for certain objectives, and propose a convex\nrelaxation, \\method, that works well for others. When evaluated in the context\nof binary gender removal, the method recovers a low-dimensional subspace whose\nremoval mitigates bias by intrinsic and extrinsic evaluation. We show that the\nmethod is highly expressive, effectively mitigating bias in deep nonlinear\nclassifiers while maintaining tractability and interpretability.\n","authors":["Shauli Ravfogel","Michael Twiton","Yoav Goldberg","Ryan Cotterell"],"pdf_url":"https://arxiv.org/pdf/2201.12091v5.pdf","comment":"Accepted in ICML 2022; a revised version"},{"id":"http://arxiv.org/abs/2410.17959v1","updated":"2024-10-23T15:28:25Z","published":"2024-10-23T15:28:25Z","title":"Medical Imaging Complexity and its Effects on GAN Performance","summary":"  The proliferation of machine learning models in diverse clinical applications\nhas led to a growing need for high-fidelity, medical image training data. Such\ndata is often scarce due to cost constraints and privacy concerns. Alleviating\nthis burden, medical image synthesis via generative adversarial networks (GANs)\nemerged as a powerful method for synthetically generating photo-realistic\nimages based on existing sets of real medical images. However, the exact image\nset size required to efficiently train such a GAN is unclear. In this work, we\nexperimentally establish benchmarks that measure the relationship between a\nsample dataset size and the fidelity of the generated images, given the\ndataset's distribution of image complexities. We analyze statistical metrics\nbased on delentropy, an image complexity measure rooted in Shannon's entropy in\ninformation theory. For our pipeline, we conduct experiments with two\nstate-of-the-art GANs, StyleGAN 3 and SPADE-GAN, trained on multiple medical\nimaging datasets with variable sample sizes. Across both GANs, general\nperformance improved with increasing training set size but suffered with\nincreasing complexity.\n","authors":["William Cagas","Chan Ko","Blake Hsiao","Shryuk Grandhi","Rishi Bhattacharya","Kevin Zhu","Michael Lam"],"pdf_url":"https://arxiv.org/pdf/2410.17959v1.pdf","comment":"Accepted to ACCV, Workshop on Generative AI for Synthetic Medical\n  Data"},{"id":"http://arxiv.org/abs/2410.17957v1","updated":"2024-10-23T15:27:37Z","published":"2024-10-23T15:27:37Z","title":"MCUBERT: Memory-Efficient BERT Inference on Commodity Microcontrollers","summary":"  In this paper, we propose MCUBERT to enable language models like BERT on tiny\nmicrocontroller units (MCUs) through network and scheduling co-optimization. We\nobserve the embedding table contributes to the major storage bottleneck for\ntiny BERT models. Hence, at the network level, we propose an MCU-aware\ntwo-stage neural architecture search algorithm based on clustered low-rank\napproximation for embedding compression. To reduce the inference memory\nrequirements, we further propose a novel fine-grained MCU-friendly scheduling\nstrategy. Through careful computation tiling and re-ordering as well as kernel\ndesign, we drastically increase the input sequence lengths supported on MCUs\nwithout any latency or accuracy penalty. MCUBERT reduces the parameter size of\nBERT-tiny and BERT-mini by 5.7$\\times$ and 3.0$\\times$ and the execution memory\nby 3.5$\\times$ and 4.3$\\times$, respectively. MCUBERT also achieves 1.5$\\times$\nlatency reduction. For the first time, MCUBERT enables lightweight BERT models\non commodity MCUs and processing more than 512 tokens with less than 256KB of\nmemory.\n","authors":["Zebin Yang","Renze Chen","Taiqiang Wu","Ngai Wong","Yun Liang","Runsheng Wang","Ru Huang","Meng Li"],"pdf_url":"https://arxiv.org/pdf/2410.17957v1.pdf","comment":"ICCAD 2024"},{"id":"http://arxiv.org/abs/2410.17952v1","updated":"2024-10-23T15:24:16Z","published":"2024-10-23T15:24:16Z","title":"SimRAG: Self-Improving Retrieval-Augmented Generation for Adapting Large\n  Language Models to Specialized Domains","summary":"  Retrieval-augmented generation (RAG) enhances the question-answering (QA)\nabilities of large language models (LLMs) by integrating external knowledge.\nHowever, adapting general-purpose RAG systems to specialized fields such as\nscience and medicine poses unique challenges due to distribution shifts and\nlimited access to domain-specific data. To tackle this, we propose SimRAG, a\nself-training approach that equips the LLM with joint capabilities of question\nanswering and question generation for domain adaptation. Our method first\nfine-tunes the LLM on instruction-following, question-answering, and\nsearch-related data. Then, it prompts the same LLM to generate diverse\ndomain-relevant questions from unlabeled corpora, with an additional filtering\nstrategy to retain high-quality synthetic examples. By leveraging these\nsynthetic examples, the LLM can improve their performance on domain-specific\nRAG tasks. Experiments on 11 datasets, spanning two backbone sizes and three\ndomains, demonstrate that SimRAG outperforms baselines by 1.2\\%--8.6\\%.\n","authors":["Ran Xu","Hui Liu","Sreyashi Nag","Zhenwei Dai","Yaochen Xie","Xianfeng Tang","Chen Luo","Yang Li","Joyce C. Ho","Carl Yang","Qi He"],"pdf_url":"https://arxiv.org/pdf/2410.17952v1.pdf","comment":"Work in Progress"},{"id":"http://arxiv.org/abs/2410.17948v1","updated":"2024-10-23T15:22:21Z","published":"2024-10-23T15:22:21Z","title":"Generalized Resubstitution for Regression Error Estimation","summary":"  We propose generalized resubstitution error estimators for regression, a\nbroad family of estimators, each corresponding to a choice of empirical\nprobability measures and loss function. The usual sum of squares criterion is a\nspecial case corresponding to the standard empirical probability measure and\nthe quadratic loss. Other choices of empirical probability measure lead to more\ngeneral estimators with superior bias and variance properties. We prove that\nthese error estimators are consistent under broad assumptions. In addition,\nprocedures for choosing the empirical measure based on the method of moments\nand maximum pseudo-likelihood are proposed and investigated. Detailed\nexperimental results using polynomial regression demonstrate empirically the\nsuperior finite-sample bias and variance properties of the proposed estimators.\nThe R code for the experiments is provided.\n","authors":["Diego Marcondes","Ulisses Braga-Neto"],"pdf_url":"https://arxiv.org/pdf/2410.17948v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.17945v1","updated":"2024-10-23T15:18:07Z","published":"2024-10-23T15:18:07Z","title":"Theoretically Grounded Pruning of Large Ground Sets for Constrained,\n  Discrete Optimization","summary":"  Modern instances of combinatorial optimization problems often exhibit\nbillion-scale ground sets, which have many uninformative or redundant elements.\nIn this work, we develop light-weight pruning algorithms to quickly discard\nelements that are unlikely to be part of an optimal solution. Under mild\nassumptions on the instance, we prove theoretical guarantees on the fraction of\nthe optimal value retained and the size of the resulting pruned ground set.\nThrough extensive experiments on real-world datasets for various applications,\nwe demonstrate that our algorithm, QuickPrune, efficiently prunes over 90% of\nthe ground set and outperforms state-of-the-art classical and machine learning\nheuristics for pruning.\n","authors":["Ankur Nath","Alan Kuhnle"],"pdf_url":"https://arxiv.org/pdf/2410.17945v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.17943v1","updated":"2024-10-23T15:15:56Z","published":"2024-10-23T15:15:56Z","title":"Optimizing Travel Itineraries with AI Algorithms in a Microservices\n  Architecture: Balancing Cost, Time, Preferences, and Sustainability","summary":"  The objective of this research is how an implementation of AI algorithms in\nthe microservices architecture enhances travel itineraries by cost, time, user\npreferences, and environmental sustainability. It uses machine learning models\nfor both cost forecasting and personalization, genetic algorithm for\noptimization of the itinerary, and heuristics for sustainability checking.\nPrimary evaluated parameters consist of latency, ability to satisfy user\npreferences, cost and environmental concern. The experimental results\ndemonstrate an average of 4.5 seconds of response time on 1000 concurrent users\nand 92% of user preferences accuracy. The cost efficiency is proved, with 95%\nof provided trips being within the limits of the budget declared by the user.\nThe system also implements some measures to alleviate negative externalities\nrelated to travel and 60% of offered travel plans had green options\nincorporated, resulting in the average 15% lower carbon emissions than the\ntraditional travel plans offered. The genetic algorithm with time complexity\nO(g.p.f) provides the optimal solution in 100 generations. Every iteration\nimproves the quality of the solution by 5%, thus enabling its effective use in\noptimization problems where time is measured in seconds. Finally, the system is\ndesigned to be fault-tolerant with functional 99.9% availability which allows\nthe provision of services even when requirements are exceeded. Travel\noptimization platform is turned dynamic and efficient by this microservices\nbased architecture which provides enhanced scaling, allows asynchronous\ncommunication and real time changes. Because of the incorporation of Ai, cost\ncontrol and eco-friendliness approaches, the system addresses the different\nuser needs in the present days travel business.\n","authors":["Biman Barua","M. Shamim Kaiser"],"pdf_url":"https://arxiv.org/pdf/2410.17943v1.pdf","comment":"18 pages, 6 figures"},{"id":"http://arxiv.org/abs/2410.17941v1","updated":"2024-10-23T15:09:02Z","published":"2024-10-23T15:09:02Z","title":"Spiking Graph Neural Network on Riemannian Manifolds","summary":"  Graph neural networks (GNNs) have become the dominant solution for learning\non graphs, the typical non-Euclidean structures. Conventional GNNs, constructed\nwith the Artificial Neuron Network (ANN), have achieved impressive performance\nat the cost of high computation and energy consumption. In parallel, spiking\nGNNs with brain-like spiking neurons are drawing increasing research attention\nowing to the energy efficiency. So far, existing spiking GNNs consider graphs\nin Euclidean space, ignoring the structural geometry, and suffer from the high\nlatency issue due to Back-Propagation-Through-Time (BPTT) with the surrogate\ngradient. In light of the aforementioned issues, we are devoted to exploring\nspiking GNN on Riemannian manifolds, and present a Manifold-valued Spiking GNN\n(MSG). In particular, we design a new spiking neuron on geodesically complete\nmanifolds with the diffeomorphism, so that BPTT regarding the spikes is\nreplaced by the proposed differentiation via manifold. Theoretically, we show\nthat MSG approximates a solver of the manifold ordinary differential equation.\nExtensive experiments on common graphs show the proposed MSG achieves superior\nperformance to previous spiking GNNs and energy efficiency to conventional\nGNNs.\n","authors":["Li Sun","Zhenhao Huang","Qiqi Wan","Hao Peng","Philip S. Yu"],"pdf_url":"https://arxiv.org/pdf/2410.17941v1.pdf","comment":"Accepted by NeurIPS 2024, 30 pages"},{"id":"http://arxiv.org/abs/2406.14856v2","updated":"2024-10-23T15:08:59Z","published":"2024-06-21T04:02:19Z","title":"Accessible, At-Home Detection of Parkinson's Disease via Multi-task\n  Video Analysis","summary":"  Limited accessibility to neurological care leads to underdiagnosed\nParkinson's Disease (PD), preventing early intervention. Existing AI-based PD\ndetection methods primarily focus on unimodal analysis of motor or speech\ntasks, overlooking the multifaceted nature of the disease. To address this, we\nintroduce a large-scale, multi-task video dataset consisting of 1102 sessions\n(each containing videos of finger tapping, facial expression, and speech tasks\ncaptured via webcam) from 845 participants (272 with PD). We propose a novel\nUncertainty-calibrated Fusion Network (UFNet) that leverages this multimodal\ndata to enhance diagnostic accuracy. UFNet employs independent task-specific\nnetworks, trained with Monte Carlo Dropout for uncertainty quantification,\nfollowed by self-attended fusion of features, with attention weights\ndynamically adjusted based on task-specific uncertainties. To ensure\npatient-centered evaluation, the participants were randomly split into three\nsets: 60% for training, 20% for model selection, and 20% for final performance\nevaluation. UFNet significantly outperformed single-task models in terms of\naccuracy, area under the ROC curve (AUROC), and sensitivity while maintaining\nnon-inferior specificity. Withholding uncertain predictions further boosted the\nperformance, achieving 88.0+-0.3%$ accuracy, 93.0+-0.2% AUROC, 79.3+-0.9%\nsensitivity, and 92.6+-0.3% specificity, at the expense of not being able to\npredict for 2.3+-0.3% data (+- denotes 95% confidence interval). Further\nanalysis suggests that the trained model does not exhibit any detectable bias\nacross sex and ethnic subgroups and is most effective for individuals aged\nbetween 50 and 80. Requiring only a webcam and microphone, our approach\nfacilitates accessible home-based PD screening, especially in regions with\nlimited healthcare resources.\n","authors":["Md Saiful Islam","Tariq Adnan","Jan Freyberg","Sangwu Lee","Abdelrahman Abdelkader","Meghan Pawlik","Cathe Schwartz","Karen Jaffe","Ruth B. Schneider","E Ray Dorsey","Ehsan Hoque"],"pdf_url":"https://arxiv.org/pdf/2406.14856v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.03093v2","updated":"2024-10-23T15:01:34Z","published":"2024-08-06T10:48:15Z","title":"Certifiably Robust Policies for Uncertain Parametric Environments","summary":"  We present a data-driven approach for producing policies that are provably\nrobust across unknown stochastic environments. Existing approaches can learn\nmodels of a single environment as an interval Markov decision processes (IMDP)\nand produce a robust policy with a probably approximately correct (PAC)\nguarantee on its performance. However these are unable to reason about the\nimpact of environmental parameters underlying the uncertainty. We propose a\nframework based on parametric Markov decision processes (MDPs) with unknown\ndistributions over parameters. We learn and analyse IMDPs for a set of unknown\nsample environments induced by parameters. The key challenge is then to produce\nmeaningful performance guarantees that combine the two layers of uncertainty:\n(1) multiple environments induced by parameters with an unknown distribution;\n(2) unknown induced environments which are approximated by IMDPs. We present a\nnovel approach based on scenario optimisation that yields a single PAC\nguarantee quantifying the risk level for which a specified performance level\ncan be assured in unseen environments, plus a means to trade-off risk and\nperformance. We implement and evaluate our framework using multiple robust\npolicy generation methods on a range of benchmarks. We show that our approach\nproduces tight bounds on a policy's performance with high confidence.\n","authors":["Yannik Schnitzer","Alessandro Abate","David Parker"],"pdf_url":"https://arxiv.org/pdf/2408.03093v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.17935v1","updated":"2024-10-23T15:00:30Z","published":"2024-10-23T15:00:30Z","title":"Semi-Implicit Functional Gradient Flow","summary":"  Particle-based variational inference methods (ParVIs) use non-parametric\nvariational families represented by particles to approximate the target\ndistribution according to the kernelized Wasserstein gradient flow for the\nKullback-Leibler (KL) divergence. Recent works introduce functional gradient\nflows to substitute the kernel for better flexibility. However, the\ndeterministic updating mechanism may suffer from limited exploration and\nrequire expensive repetitive runs for new samples. In this paper, we propose\nSemi-Implicit Functional Gradient flow (SIFG), a functional gradient ParVI\nmethod that uses perturbed particles as the approximation family. The\ncorresponding functional gradient flow, which can be estimated via denoising\nscore matching, exhibits strong theoretical convergence guarantee. We also\npresent an adaptive version of our method to automatically choose the suitable\nnoise magnitude. Extensive experiments demonstrate the effectiveness and\nefficiency of the proposed framework on both simulated and real data problems.\n","authors":["Shiyue Zhang","Ziheng Cheng","Cheng Zhang"],"pdf_url":"https://arxiv.org/pdf/2410.17935v1.pdf","comment":"31 pages, 12 figures"},{"id":"http://arxiv.org/abs/2410.17934v1","updated":"2024-10-23T14:59:06Z","published":"2024-10-23T14:59:06Z","title":"Retrieving snow depth distribution by downscaling ERA5 Reanalysis with\n  ICESat-2 laser altimetry","summary":"  Estimating the variability of seasonal snow cover, in particular snow depth\nin remote areas, poses significant challenges due to limited spatial and\ntemporal data availability. This study uses snow depth measurements from the\nICESat-2 satellite laser altimeter, which are sparse in both space and time,\nand incorporates them with climate reanalysis data into a\ndownscaling-calibration scheme to produce monthly gridded snow depth maps at\nmicroscale (10 m). Snow surface elevation measurements from ICESat-2 along\nprofiles are compared to a digital elevation model to determine snow depth at\neach point. To efficiently turn sparse measurements into snow depth maps, a\nregression model is fitted to establish a relationship between the retrieved\nsnow depth and the corresponding ERA5 Land snow depth. This relationship,\nreferred to as subgrid variability, is then applied to downscale the monthly\nERA5 Land snow depth data. The method can provide timeseries of monthly snow\ndepth maps for the entire ERA5 time range (since 1950). The validation of\ndownscaled snow depth data was performed at an intermediate scale (100 m x 500\nm) using datasets from airborne laser scanning (ALS) in the Hardangervidda\nregion of southern Norway. Results show that snow depth prediction achieved R2\nvalues ranging from 0.74 to 0.88 (post-calibration). The method relies on\nglobally available data and is applicable to other snow regions above the\ntreeline. Though requiring area-specific calibration, our approach has the\npotential to provide snow depth maps in areas where no such data exist and can\nbe used to extrapolate existing snow surveys in time and over larger areas.\nWith this, it can offer valuable input data for hydrological, ecological or\npermafrost modeling tasks.\n","authors":["Zhihao Liu","Simon Filhol","Désirée Treichler"],"pdf_url":"https://arxiv.org/pdf/2410.17934v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.17933v1","updated":"2024-10-23T14:55:53Z","published":"2024-10-23T14:55:53Z","title":"Multi-Continental Healthcare Modelling Using Blockchain-Enabled\n  Federated Learning","summary":"  One of the biggest challenges of building artificial intelligence (AI) model\nin healthcare area is the data sharing. Since healthcare data is private,\nsensitive, and heterogeneous, collecting sufficient data for modelling is\nexhausted, costly, and sometimes impossible. In this paper, we propose a\nframework for global healthcare modelling using datasets from multi-continents\n(Europe, North America and Asia) while without sharing the local datasets, and\nchoose glucose management as a study model to verify its effectiveness.\nTechnically, blockchain-enabled federated learning is implemented with adaption\nto make it meet with the privacy and safety requirements of healthcare data,\nmeanwhile rewards honest participation and penalize malicious activities using\nits on-chain incentive mechanism. Experimental results show that the proposed\nframework is effective, efficient, and privacy preserved. Its prediction\naccuracy is much better than the models trained from limited personal data and\nis similar to, and even slightly better than, the results from a centralized\ndataset. This work paves the way for international collaborations on healthcare\nprojects, where additional data is crucial for reducing bias and providing\nbenefits to humanity.\n","authors":["Rui Sun","Zhipeng Wang","Hengrui Zhang","Ming Jiang","Yizhe Wen","Jiqun Zhang","Jiahao Sun","Shuoying Zhang","Erwu Liu","Kezhi Li"],"pdf_url":"https://arxiv.org/pdf/2410.17933v1.pdf","comment":"Accepted by IEEE Global Blockchain Conference"},{"id":"http://arxiv.org/abs/2402.04033v3","updated":"2024-10-23T14:50:51Z","published":"2024-02-06T14:26:22Z","title":"On provable privacy vulnerabilities of graph representations","summary":"  Graph representation learning (GRL) is critical for extracting insights from\ncomplex network structures, but it also raises security concerns due to\npotential privacy vulnerabilities in these representations. This paper\ninvestigates the structural vulnerabilities in graph neural models where\nsensitive topological information can be inferred through edge reconstruction\nattacks. Our research primarily addresses the theoretical underpinnings of\nsimilarity-based edge reconstruction attacks (SERA), furnishing a\nnon-asymptotic analysis of their reconstruction capacities. Moreover, we\npresent empirical corroboration indicating that such attacks can perfectly\nreconstruct sparse graphs as graph size increases. Conversely, we establish\nthat sparsity is a critical factor for SERA's effectiveness, as demonstrated\nthrough analysis and experiments on (dense) stochastic block models. Finally,\nwe explore the resilience of private graph representations produced via noisy\naggregation (NAG) mechanism against SERA. Through theoretical analysis and\nempirical assessments, we affirm the mitigation of SERA using NAG . In\nparallel, we also empirically delineate instances wherein SERA demonstrates\nboth efficacy and deficiency in its capacity to function as an instrument for\nelucidating the trade-off between privacy and utility.\n","authors":["Ruofan Wu","Guanhua Fang","Qiying Pan","Mingyang Zhang","Tengfei Liu","Weiqiang Wang"],"pdf_url":"https://arxiv.org/pdf/2402.04033v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.01959v2","updated":"2024-10-23T14:49:39Z","published":"2024-06-04T04:39:51Z","title":"Adaptive Variance Reduction for Stochastic Optimization under Weaker\n  Assumptions","summary":"  This paper explores adaptive variance reduction methods for stochastic\noptimization based on the STORM technique. Existing adaptive extensions of\nSTORM rely on strong assumptions like bounded gradients and bounded function\nvalues, or suffer an additional $\\mathcal{O}(\\log T)$ term in the convergence\nrate. To address these limitations, we introduce a novel adaptive STORM method\nthat achieves an optimal convergence rate of $\\mathcal{O}(T^{-1/3})$ for\nnon-convex functions with our newly designed learning rate strategy. Compared\nwith existing approaches, our method requires weaker assumptions and attains\nthe optimal convergence rate without the additional $\\mathcal{O}(\\log T)$ term.\nWe also extend the proposed technique to stochastic compositional optimization,\nobtaining the same optimal rate of $\\mathcal{O}(T^{-1/3})$. Furthermore, we\ninvestigate the non-convex finite-sum problem and develop another innovative\nadaptive variance reduction method that achieves an optimal convergence rate of\n$\\mathcal{O}(n^{1/4} T^{-1/2} )$, where $n$ represents the number of component\nfunctions. Numerical experiments across various tasks validate the\neffectiveness of our method.\n","authors":["Wei Jiang","Sifan Yang","Yibo Wang","Lijun Zhang"],"pdf_url":"https://arxiv.org/pdf/2406.01959v2.pdf","comment":"arXiv admin note: substantial text overlap with arXiv:2406.00489"},{"id":"http://arxiv.org/abs/2310.10107v4","updated":"2024-10-23T14:47:42Z","published":"2023-10-16T06:41:13Z","title":"Posterior Sampling-based Online Learning for Episodic POMDPs","summary":"  Learning in POMDPs is known to be significantly harder than in MDPs. In this\npaper, we consider the online learning problem for episodic POMDPs with unknown\ntransition and observation models. We propose a Posterior Sampling-based\nreinforcement learning algorithm for POMDPs (PS4POMDPs), which is much simpler\nand more implementable compared to state-of-the-art optimism-based online\nlearning algorithms for POMDPs. We show that the Bayesian regret of the\nproposed algorithm scales as the square root of the number of episodes and is\npolynomial in the other parameters. In a general setting, the regret scales\nexponentially in the horizon length $H$, and we show that this is inevitable by\nproviding a lower bound. However, when the POMDP is undercomplete and weakly\nrevealing (a common assumption in the recent literature), we establish a\npolynomial Bayesian regret bound. We finally propose a posterior sampling\nalgorithm for multi-agent POMDPs, and show it too has sublinear regret.\n","authors":["Dengwang Tang","Dongze Ye","Rahul Jain","Ashutosh Nayyar","Pierluigi Nuzzo"],"pdf_url":"https://arxiv.org/pdf/2310.10107v4.pdf","comment":"41 pages, 9 figures"},{"id":"http://arxiv.org/abs/2406.00489v2","updated":"2024-10-23T14:42:35Z","published":"2024-06-01T16:38:43Z","title":"Efficient Sign-Based Optimization: Accelerating Convergence via Variance\n  Reduction","summary":"  Sign stochastic gradient descent (signSGD) is a communication-efficient\nmethod that transmits only the sign of stochastic gradients for parameter\nupdating. Existing literature has demonstrated that signSGD can achieve a\nconvergence rate of $\\mathcal{O}(d^{1/2}T^{-1/4})$, where $d$ represents the\ndimension and $T$ is the iteration number. In this paper, we improve this\nconvergence rate to $\\mathcal{O}(d^{1/2}T^{-1/3})$ by introducing the\nSign-based Stochastic Variance Reduction (SSVR) method, which employs variance\nreduction estimators to track gradients and leverages their signs to update.\nFor finite-sum problems, our method can be further enhanced to achieve a\nconvergence rate of $\\mathcal{O}(m^{1/4}d^{1/2}T^{-1/2})$, where $m$ denotes\nthe number of component functions. Furthermore, we investigate the\nheterogeneous majority vote in distributed settings and introduce two novel\nalgorithms that attain improved convergence rates of\n$\\mathcal{O}(d^{1/2}T^{-1/2} + dn^{-1/2})$ and $\\mathcal{O}(d^{1/4}T^{-1/4})$\nrespectively, outperforming the previous results of $\\mathcal{O}(dT^{-1/4} +\ndn^{-1/2})$ and $\\mathcal{O}(d^{3/8}T^{-1/8})$, where $n$ represents the number\nof nodes. Numerical experiments across different tasks validate the\neffectiveness of our proposed methods.\n","authors":["Wei Jiang","Sifan Yang","Wenhao Yang","Lijun Zhang"],"pdf_url":"https://arxiv.org/pdf/2406.00489v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.17918v1","updated":"2024-10-23T14:34:39Z","published":"2024-10-23T14:34:39Z","title":"Addressing Asynchronicity in Clinical Multimodal Fusion via\n  Individualized Chest X-ray Generation","summary":"  Integrating multi-modal clinical data, such as electronic health records\n(EHR) and chest X-ray images (CXR), is particularly beneficial for clinical\nprediction tasks. However, in a temporal setting, multi-modal data are often\ninherently asynchronous. EHR can be continuously collected but CXR is generally\ntaken with a much longer interval due to its high cost and radiation dose. When\nclinical prediction is needed, the last available CXR image might have been\noutdated, leading to suboptimal predictions. To address this challenge, we\npropose DDL-CXR, a method that dynamically generates an up-to-date latent\nrepresentation of the individualized CXR images. Our approach leverages latent\ndiffusion models for patient-specific generation strategically conditioned on a\nprevious CXR image and EHR time series, providing information regarding\nanatomical structures and disease progressions, respectively. In this way, the\ninteraction across modalities could be better captured by the latent CXR\ngeneration process, ultimately improving the prediction performance.\nExperiments using MIMIC datasets show that the proposed model could effectively\naddress asynchronicity in multimodal fusion and consistently outperform\nexisting methods.\n","authors":["Wenfang Yao","Chen Liu","Kejing Yin","William K. Cheung","Jing Qin"],"pdf_url":"https://arxiv.org/pdf/2410.17918v1.pdf","comment":"Accepted by NeurIPS-24"},{"id":"http://arxiv.org/abs/2410.17917v1","updated":"2024-10-23T14:34:36Z","published":"2024-10-23T14:34:36Z","title":"regAL: Python Package for Active Learning of Regression Problems","summary":"  Increasingly more research areas rely on machine learning methods to\naccelerate discovery while saving resources. Machine learning models, however,\nusually require large datasets of experimental or computational results, which\nin certain fields, such as (bio)chemistry, materials science, or medicine, are\nrarely given and often prohibitively expensive to obtain. To bypass that\nobstacle, active learning methods are employed to develop machine learning\nmodels with a desired performance while requiring the least possible number of\ncomputational or experimental results from the domain of application. For this\npurpose, the model's knowledge about certain regions of the application domain\nis estimated to guide the choice of the model's training set. Although active\nlearning is widely studied for classification problems (discrete outcomes),\ncomparatively few works handle this method for regression problems (continuous\noutcomes). In this work, we present our Python package regAL, which allows\nusers to evaluate different active learning strategies for regression problems.\nWith a minimal input of just the dataset in question, but many additional\ncustomization and insight options, this package is intended for anyone who aims\nto perform and understand active learning in their problem-specific scope.\n","authors":["Elizaveta Surzhikova","Jonny Proppe"],"pdf_url":"https://arxiv.org/pdf/2410.17917v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.17913v1","updated":"2024-10-23T14:33:11Z","published":"2024-10-23T14:33:11Z","title":"Deep learning for model correction of dynamical systems with data\n  scarcity","summary":"  We present a deep learning framework for correcting existing dynamical system\nmodels utilizing only a scarce high-fidelity data set. In many practical\nsituations, one has a low-fidelity model that can capture the dynamics\nreasonably well but lacks high resolution, due to the inherent limitation of\nthe model and the complexity of the underlying physics. When high resolution\ndata become available, it is natural to seek model correction to improve the\nresolution of the model predictions. We focus on the case when the amount of\nhigh-fidelity data is so small that most of the existing data driven modeling\nmethods cannot be applied. In this paper, we address these challenges with a\nmodel-correction method which only requires a scarce high-fidelity data set.\nOur method first seeks a deep neural network (DNN) model to approximate the\nexisting low-fidelity model. By using the scarce high-fidelity data, the method\nthen corrects the DNN model via transfer learning (TL). After TL, an improved\nDNN model with high prediction accuracy to the underlying dynamics is obtained.\nOne distinct feature of the propose method is that it does not assume a\nspecific form of the model correction terms. Instead, it offers an inherent\ncorrection to the low-fidelity model via TL. A set of numerical examples are\npresented to demonstrate the effectiveness of the proposed method.\n","authors":["Caroline Tatsuoka","Dongbin Xiu"],"pdf_url":"https://arxiv.org/pdf/2410.17913v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.04377v3","updated":"2024-10-23T14:29:56Z","published":"2024-08-08T11:22:52Z","title":"Anomaly Prediction: A Novel Approach with Explicit Delay and Horizon","summary":"  Anomaly detection in time series data is a critical challenge across various\ndomains. Traditional methods typically focus on identifying anomalies in\nimmediate subsequent steps, often underestimating the significance of temporal\ndynamics such as delay time and horizons of anomalies, which generally require\nextensive post-analysis. This paper introduces a novel approach for time series\nanomaly prediction, incorporating temporal information directly into the\nprediction results. We propose a new dataset specifically designed to evaluate\nthis approach and conduct comprehensive experiments using several\nstate-of-the-art methods. Our results demonstrate the efficacy of our approach\nin providing timely and accurate anomaly predictions, setting a new benchmark\nfor future research in this field.\n","authors":["Jiang You","Arben Cela","René Natowicz","Jacob Ouanounou","Patrick Siarry"],"pdf_url":"https://arxiv.org/pdf/2408.04377v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2405.16164v3","updated":"2024-10-23T14:24:50Z","published":"2024-05-25T10:15:51Z","title":"Acquiring Better Load Estimates by Combining Anomaly and Change Point\n  Detection in Power Grid Time-series Measurements","summary":"  In this paper we present novel methodology for automatic anomaly and switch\nevent filtering to improve load estimation in power grid systems. By leveraging\nunsupervised methods with supervised optimization, our approach prioritizes\ninterpretability while ensuring robust and generalizable performance on unseen\ndata. Through experimentation, a combination of binary segmentation for change\npoint detection and statistical process control for anomaly detection emerges\nas the most effective strategy, specifically when ensembled in a novel\nsequential manner. Results indicate the clear wasted potential when filtering\nis not applied. The automatic load estimation is also fairly accurate, with\napproximately 90% of estimates falling within a 10% error margin, with only a\nsingle significant failure in both the minimum and maximum load estimates\nacross 60 measurements in the test set. Our methodology's interpretability\nmakes it particularly suitable for critical infrastructure planning, thereby\nenhancing decision-making processes.\n","authors":["Roel Bouman","Linda Schmeitz","Luco Buise","Jacco Heres","Yuliya Shapovalova","Tom Heskes"],"pdf_url":"https://arxiv.org/pdf/2405.16164v3.pdf","comment":"All code can be found at: https://github.com/RoelBouman/StormPhase2"},{"id":"http://arxiv.org/abs/2410.17904v1","updated":"2024-10-23T14:22:49Z","published":"2024-10-23T14:22:49Z","title":"Reinforcement Learning under Latent Dynamics: Toward Statistical and\n  Algorithmic Modularity","summary":"  Real-world applications of reinforcement learning often involve environments\nwhere agents operate on complex, high-dimensional observations, but the\nunderlying (''latent'') dynamics are comparatively simple. However, outside of\nrestrictive settings such as small latent spaces, the fundamental statistical\nrequirements and algorithmic principles for reinforcement learning under latent\ndynamics are poorly understood.\n  This paper addresses the question of reinforcement learning under\n$\\textit{general}$ latent dynamics from a statistical and algorithmic\nperspective. On the statistical side, our main negative result shows that most\nwell-studied settings for reinforcement learning with function approximation\nbecome intractable when composed with rich observations; we complement this\nwith a positive result, identifying latent pushforward coverability as a\ngeneral condition that enables statistical tractability. Algorithmically, we\ndevelop provably efficient observable-to-latent reductions -- that is,\nreductions that transform an arbitrary algorithm for the latent MDP into an\nalgorithm that can operate on rich observations -- in two settings: one where\nthe agent has access to hindsight observations of the latent dynamics [LADZ23],\nand one where the agent can estimate self-predictive latent models [SAGHCB20].\nTogether, our results serve as a first step toward a unified statistical and\nalgorithmic theory for reinforcement learning under latent dynamics.\n","authors":["Philip Amortila","Dylan J. Foster","Nan Jiang","Akshay Krishnamurthy","Zakaria Mhammedi"],"pdf_url":"https://arxiv.org/pdf/2410.17904v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.17898v1","updated":"2024-10-23T14:16:34Z","published":"2024-10-23T14:16:34Z","title":"Scalable Offline Reinforcement Learning for Mean Field Games","summary":"  Reinforcement learning algorithms for mean-field games offer a scalable\nframework for optimizing policies in large populations of interacting agents.\nExisting methods often depend on online interactions or access to system\ndynamics, limiting their practicality in real-world scenarios where such\ninteractions are infeasible or difficult to model. In this paper, we present\nOffline Munchausen Mirror Descent (Off-MMD), a novel mean-field RL algorithm\nthat approximates equilibrium policies in mean-field games using purely offline\ndata. By leveraging iterative mirror descent and importance sampling\ntechniques, Off-MMD estimates the mean-field distribution from static datasets\nwithout relying on simulation or environment dynamics. Additionally, we\nincorporate techniques from offline reinforcement learning to address common\nissues like Q-value overestimation, ensuring robust policy learning even with\nlimited data coverage. Our algorithm scales to complex environments and\ndemonstrates strong performance on benchmark tasks like crowd exploration or\nnavigation, highlighting its applicability to real-world multi-agent systems\nwhere online experimentation is infeasible. We empirically demonstrate the\nrobustness of Off-MMD to low-quality datasets and conduct experiments to\ninvestigate its sensitivity to hyperparameter choices.\n","authors":["Axel Brunnbauer","Julian Lemmel","Zahra Babaiee","Sophie Neubauer","Radu Grosu"],"pdf_url":"https://arxiv.org/pdf/2410.17898v1.pdf","comment":"Submitted to AAMAS"},{"id":"http://arxiv.org/abs/2407.19353v2","updated":"2024-10-23T14:11:34Z","published":"2024-07-28T00:07:20Z","title":"A spring-block theory of feature learning in deep neural networks","summary":"  Feature-learning deep nets progressively collapse data to a regular\nlow-dimensional geometry. How this phenomenon emerges from collective action of\nnonlinearity, noise, learning rate, and other choices that shape the dynamics,\nhas eluded first-principles theories built from microscopic neuronal dynamics.\nWe exhibit a noise-nonlinearity phase diagram that identifies regimes where\nshallow or deep layers learn more effectively. We then propose a macroscopic\nmechanical theory that reproduces the diagram, explaining why some DNNs are\nlazy and some active, and linking feature learning across layers to\ngeneralization.\n","authors":["Cheng Shi","Liming Pan","Ivan Dokmanić"],"pdf_url":"https://arxiv.org/pdf/2407.19353v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.15592v2","updated":"2024-10-23T14:08:10Z","published":"2024-10-21T02:21:56Z","title":"CPE-Pro: A Structure-Sensitive Deep Learning Method for Protein\n  Representation and Origin Evaluation","summary":"  Protein structures are important for understanding their functions and\ninteractions. Currently, many protein structure prediction methods are\nenriching the structure database. Discriminating the origin of structures is\ncrucial for distinguishing between experimentally resolved and computationally\npredicted structures, evaluating the reliability of prediction methods, and\nguiding downstream biological studies. Building on works in structure\nprediction, We developed a structure-sensitive supervised deep learning model,\nCrystal vs Predicted Evaluator for Protein Structure (CPE-Pro), to represent\nand discriminate the origin of protein structures. CPE-Pro learns the\nstructural information of proteins and captures inter-structural differences to\nachieve accurate traceability on four data classes, and is expected to be\nextended to more. Simultaneously, we utilized Foldseek to encode protein\nstructures into \"structure-sequences\" and trained a protein Structural Sequence\nLanguage Model, SSLM. Preliminary experiments demonstrated that, compared to\nlarge-scale protein language models pre-trained on vast amounts of amino acid\nsequences, the \"structure-sequence\" enables the language model to learn more\ninformative protein features, enhancing and optimizing structural\nrepresentations. We have provided the code, model weights, and all related\nmaterials on https://github.com/GouWenrui/CPE-Pro-main.git.\n","authors":["Wenrui Gou","Wenhui Ge","Yang Tan","Mingchen Li","Guisheng Fan","Huiqun Yu"],"pdf_url":"https://arxiv.org/pdf/2410.15592v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2409.19472v2","updated":"2024-10-23T14:02:12Z","published":"2024-09-28T22:41:49Z","title":"Towards Croppable Implicit Neural Representations","summary":"  Implicit Neural Representations (INRs) have peaked interest in recent years\ndue to their ability to encode natural signals using neural networks. While\nINRs allow for useful applications such as interpolating new coordinates and\nsignal compression, their black-box nature makes it difficult to modify them\npost-training. In this paper we explore the idea of editable INRs, and\nspecifically focus on the widely used cropping operation. To this end, we\npresent Local-Global SIRENs -- a novel INR architecture that supports cropping\nby design. Local-Global SIRENs are based on combining local and global feature\nextraction for signal encoding. What makes their design unique is the ability\nto effortlessly remove specific portions of an encoded signal, with a\nproportional weight decrease. This is achieved by eliminating the corresponding\nweights from the network, without the need for retraining. We further show how\nthis architecture can be used to support the straightforward extension of\npreviously encoded signals. Beyond signal editing, we examine how the\nLocal-Global approach can accelerate training, enhance encoding of various\nsignals, improve downstream performance, and be applied to modern INRs such as\nINCODE, highlighting its potential and flexibility. Code is available at\nhttps://github.com/maorash/Local-Global-INRs.\n","authors":["Maor Ashkenazi","Eran Treister"],"pdf_url":"https://arxiv.org/pdf/2409.19472v2.pdf","comment":"Accepted to NeurIPS 2024"},{"id":"http://arxiv.org/abs/2408.06927v2","updated":"2024-10-23T14:01:27Z","published":"2024-08-13T14:29:00Z","title":"Breaking Class Barriers: Efficient Dataset Distillation via Inter-Class\n  Feature Compensator","summary":"  Dataset distillation has emerged as a technique aiming to condense\ninformative features from large, natural datasets into a compact and synthetic\nform. While recent advancements have refined this technique, its performance is\nbottlenecked by the prevailing class-specific synthesis paradigm. Under this\nparadigm, synthetic data is optimized exclusively for a pre-assigned one-hot\nlabel, creating an implicit class barrier in feature condensation. This leads\nto inefficient utilization of the distillation budget and oversight of\ninter-class feature distributions, which ultimately limits the effectiveness\nand efficiency, as demonstrated in our analysis. To overcome these constraints,\nthis paper presents the Inter-class Feature Compensator (INFER), an innovative\ndistillation approach that transcends the class-specific data-label framework\nwidely utilized in current dataset distillation methods. Specifically, INFER\nleverages a Universal Feature Compensator (UFC) to enhance feature integration\nacross classes, enabling the generation of multiple additional synthetic\ninstances from a single UFC input. This significantly improves the efficiency\nof the distillation budget. Moreover, INFER enriches inter-class interactions\nduring the distillation, thereby enhancing the effectiveness and\ngeneralizability of the distilled data. By allowing for the linear\ninterpolation of labels similar to those in the original dataset, INFER\nmeticulously optimizes the synthetic data and dramatically reduces the size of\nsoft labels in the synthetic dataset to almost zero, establishing a new\nbenchmark for efficiency and effectiveness in dataset distillation.\n","authors":["Xin Zhang","Jiawei Du","Ping Liu","Joey Tianyi Zhou"],"pdf_url":"https://arxiv.org/pdf/2408.06927v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2407.12819v2","updated":"2024-10-23T14:00:36Z","published":"2024-07-01T10:33:46Z","title":"I've Got 99 Problems But FLOPS Ain't One","summary":"  Hyperscalers dominate the landscape of large network deployments, yet they\nrarely share data or insights about the challenges they face. In light of this\nsupremacy, what problems can we find to solve in this space? We take an\nunconventional approach to find relevant research directions, starting from\npublic plans to build a $100 billion datacenter for machine learning\napplications. Leveraging the language models scaling laws, we discover what\nworkloads such a datacenter might carry and explore the challenges one may\nencounter in doing so, with a focus on networking research. We conclude that\nbuilding the datacenter and training such models is technically possible, but\nthis requires novel wide-area transports for inter-DC communication, a\nmultipath transport and novel datacenter topologies for intra-datacenter\ncommunication, high speed scale-up networks and transports, outlining a rich\nresearch agenda for the networking community.\n","authors":["Alexandru M. Gherghescu","Vlad-Andrei Bădoiu","Alexandru Agache","Mihai-Valentin Dumitru","Iuliu Vasilescu","Radu Mantu","Costin Raiciu"],"pdf_url":"https://arxiv.org/pdf/2407.12819v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.17882v1","updated":"2024-10-23T13:55:42Z","published":"2024-10-23T13:55:42Z","title":"Identifiable Representation and Model Learning for Latent Dynamic\n  Systems","summary":"  Learning identifiable representations and models from low-level observations\nis useful for an intelligent spacecraft to reliability finish downstream tasks.\nFor temporal observations, to ensure that the data generating process is\nprovably inverted, most existing works either assume the noise variables in the\ndynamic mechanisms are (conditionally) independent, or require interventions\nwhich can directly affect each latent variable. However, in practice, the\nrelationship between the exogenous inputs/interventions and the latent\nvariables may follow some complex deterministic mechanisms. In this work, we\nstudy the problem of identifiable representation and model learning for latent\ndynamic systems. The key idea is that we use an inductive bias inspired by\ncontrollable canonical forms, which is invariant, sparse, and input dependent\nby definition. We prove that, for linear or affine nonlinear latent dynamic\nsystems, it is possible to identify the representations up to scaling and\ndetermine the models up to some simple transformations. The results have\npotential to provide some theoretical guarantees for developing more\ntrustworthy decision-making and control methods for intelligent spacecrafts.\n","authors":["Congxi Zhang","Yongchun Xie"],"pdf_url":"https://arxiv.org/pdf/2410.17882v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.17881v1","updated":"2024-10-23T13:53:26Z","published":"2024-10-23T13:53:26Z","title":"AdaRankGrad: Adaptive Gradient-Rank and Moments for Memory-Efficient\n  LLMs Training and Fine-Tuning","summary":"  Training and fine-tuning large language models (LLMs) come with challenges\nrelated to memory and computational requirements due to the increasing size of\nthe model weights and the optimizer states. Various techniques have been\ndeveloped to tackle these challenges, such as low-rank adaptation (LoRA), which\ninvolves introducing a parallel trainable low-rank matrix to the fixed\npre-trained weights at each layer. However, these methods often fall short\ncompared to the full-rank weight training approach, as they restrict the\nparameter search to a low-rank subspace. This limitation can disrupt training\ndynamics and require a full-rank warm start to mitigate the impact. In this\npaper, we introduce a new method inspired by a phenomenon we formally prove: as\ntraining progresses, the rank of the estimated layer gradients gradually\ndecreases, and asymptotically approaches rank one. Leveraging this, our\napproach involves adaptively reducing the rank of the gradients during Adam\noptimization steps, using an efficient online-updating low-rank projections\nrule. We further present a randomized SVD scheme for efficiently finding the\nprojection matrix. Our technique enables full-parameter fine-tuning with\nadaptive low-rank gradient updates, significantly reducing overall memory\nrequirements during training compared to state-of-the-art methods while\nimproving model performance in both pretraining and fine-tuning. Finally, we\nprovide a convergence analysis of our method and demonstrate its merits for\ntraining and fine-tuning language and biological foundation models.\n","authors":["Yehonathan Refael","Jonathan Svirsky","Boris Shustin","Wasim Huleihel","Ofir Lindenbaum"],"pdf_url":"https://arxiv.org/pdf/2410.17881v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.17878v1","updated":"2024-10-23T13:50:27Z","published":"2024-10-23T13:50:27Z","title":"Relaxed Equivariance via Multitask Learning","summary":"  Incorporating equivariance as an inductive bias into deep learning\narchitectures to take advantage of the data symmetry has been successful in\nmultiple applications, such as chemistry and dynamical systems. In particular,\nroto-translations are crucial for effectively modeling geometric graphs and\nmolecules, where understanding the 3D structures enhances generalization.\nHowever, equivariant models often pose challenges due to their high\ncomputational complexity. In this paper, we introduce REMUL, a training\nprocedure for approximating equivariance with multitask learning. We show that\nunconstrained models (which do not build equivariance into the architecture)\ncan learn approximate symmetries by minimizing an additional simple\nequivariance loss. By formulating equivariance as a new learning objective, we\ncan control the level of approximate equivariance in the model. Our method\nachieves competitive performance compared to equivariant baselines while being\n$10 \\times$ faster at inference and $2.5 \\times$ at training.\n","authors":["Ahmed A. Elhag","T. Konstantin Rusch","Francesco Di Giovanni","Michael Bronstein"],"pdf_url":"https://arxiv.org/pdf/2410.17878v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.04953v3","updated":"2024-10-23T13:36:37Z","published":"2022-12-09T16:03:34Z","title":"TargetCall: Eliminating the Wasted Computation in Basecalling via\n  Pre-Basecalling Filtering","summary":"  Basecalling is an essential step in nanopore sequencing analysis where the\nraw signals of nanopore sequencers are converted into nucleotide sequences,\ni.e., reads. State-of-the-art basecallers employ complex deep learning models\nto achieve high basecalling accuracy. This makes basecalling computationally\ninefficient and memory-hungry, bottlenecking the entire genome analysis\npipeline. However, for many applications, the majority of reads do no match the\nreference genome of interest (i.e., target reference) and thus are discarded in\nlater steps in the genomics pipeline, wasting the basecalling computation. To\novercome this issue, we propose TargetCall, the first pre-basecalling filter to\neliminate the wasted computation in basecalling. TargetCall's key idea is to\ndiscard reads that will not match the target reference (i.e., off-target reads)\nprior to basecalling. TargetCall consists of two main components: (1)\nLightCall, a lightweight neural network basecaller that produces noisy reads;\nand (2) Similarity Check, which labels each of these noisy reads as on-target\nor off-target by matching them to the target reference. Our thorough\nexperimental evaluations show that TargetCall 1) improves the end-to-end\nbasecalling runtime performance of the state-of-the-art basecaller by 3.31x\nwhile maintaining high (98.88%) recall in keeping on-target reads, 2) maintains\nhigh accuracy in downstream analysis, and 3) achieves better runtime\nperformance, throughput, recall, precision, and generality compared to prior\nworks. TargetCall is available at https://github.com/CMU-SAFARI/TargetCall.\n","authors":["Meryem Banu Cavlak","Gagandeep Singh","Mohammed Alser","Can Firtina","Joël Lindegger","Mohammad Sadrosadati","Nika Mansouri Ghiasi","Can Alkan","Onur Mutlu"],"pdf_url":"https://arxiv.org/pdf/2212.04953v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.17865v1","updated":"2024-10-23T13:36:23Z","published":"2024-10-23T13:36:23Z","title":"Population stratification for prediction of mortality in post-AKI\n  patients","summary":"  Acute kidney injury (AKI) is a serious clinical condition that affects up to\n20% of hospitalised patients. AKI is associated with short term unplanned\nhospital readmission and post-discharge mortality risk. Patient risk and\nhealthcare expenditures can be minimised by followup planning grounded on\npredictive models and machine learning. Since AKI is multi-factorial,\npredictive models specialised in different categories of patients can increase\naccuracy of predictions. In the present article we present some results\nfollowing this approach.\n","authors":["Flavio S. Correa da Silva","Simon Sawhney"],"pdf_url":"https://arxiv.org/pdf/2410.17865v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.17863v1","updated":"2024-10-23T13:35:18Z","published":"2024-10-23T13:35:18Z","title":"CASCRNet: An Atrous Spatial Pyramid Pooling and Shared Channel Residual\n  based Network for Capsule Endoscopy","summary":"  This manuscript summarizes work on the Capsule Vision Challenge 2024 by\nMISAHUB. To address the multi-class disease classification task, which is\nchallenging due to the complexity and imbalance in the Capsule Vision challenge\ndataset, this paper proposes CASCRNet (Capsule endoscopy-Aspp-SCR-Network), a\nparameter-efficient and novel model that uses Shared Channel Residual (SCR)\nblocks and Atrous Spatial Pyramid Pooling (ASPP) blocks. Further, the\nperformance of the proposed model is compared with other well-known approaches.\nThe experimental results yield that proposed model provides better disease\nclassification results. The proposed model was successful in classifying\ndiseases with an F1 Score of 78.5% and a Mean AUC of 98.3%, which is promising\ngiven its compact architecture.\n","authors":["K V Srinanda","M Manvith Prabhu","Shyam Lal"],"pdf_url":"https://arxiv.org/pdf/2410.17863v1.pdf","comment":"8 pages, 4 figures"},{"id":"http://arxiv.org/abs/2410.17851v1","updated":"2024-10-23T13:20:42Z","published":"2024-10-23T13:20:42Z","title":"The Probabilistic Tsetlin Machine: A Novel Approach to Uncertainty\n  Quantification","summary":"  Tsetlin Machines (TMs) have emerged as a compelling alternative to\nconventional deep learning methods, offering notable advantages such as smaller\nmemory footprint, faster inference, fault-tolerant properties, and\ninterpretability. Although various adaptations of TMs have expanded their\napplicability across diverse domains, a fundamental gap remains in\nunderstanding how TMs quantify uncertainty in their predictions. In response,\nthis paper introduces the Probabilistic Tsetlin Machine (PTM) framework, aimed\nat providing a robust, reliable, and interpretable approach for uncertainty\nquantification. Unlike the original TM, the PTM learns the probability of\nstaying on each state of each Tsetlin Automaton (TA) across all clauses. These\nprobabilities are updated using the feedback tables that are part of the TM\nframework: Type I and Type II feedback. During inference, TAs decide their\nactions by sampling states based on learned probability distributions, akin to\nBayesian neural networks when generating weight values. In our experimental\nanalysis, we first illustrate the spread of the probabilities across TA states\nfor the noisy-XOR dataset. Then we evaluate the PTM alongside benchmark models\nusing both simulated and real-world datasets. The experiments on the simulated\ndataset reveal the PTM's effectiveness in uncertainty quantification,\nparticularly in delineating decision boundaries and identifying regions of high\nuncertainty. Moreover, when applied to multiclass classification tasks using\nthe Iris dataset, the PTM demonstrates competitive performance in terms of\npredictive entropy and expected calibration error, showcasing its potential as\na reliable tool for uncertainty estimation. Our findings underscore the\nimportance of selecting appropriate models for accurate uncertainty\nquantification in predictive tasks, with the PTM offering a particularly\ninterpretable and effective solution.\n","authors":["K. Darshana Abeyrathna","Sara El Mekkaoui","Andreas Hafver","Christian Agrell"],"pdf_url":"https://arxiv.org/pdf/2410.17851v1.pdf","comment":"12 pages, 5 figures, 6 tables, accepted and presented at ICAAI 2024,\n  London"},{"id":"http://arxiv.org/abs/2402.15055v2","updated":"2024-10-23T13:20:15Z","published":"2024-02-23T02:15:47Z","title":"Interpreting Context Look-ups in Transformers: Investigating\n  Attention-MLP Interactions","summary":"  Understanding the inner workings of large language models (LLMs) is crucial\nfor advancing their theoretical foundations and real-world applications. While\nthe attention mechanism and multi-layer perceptrons (MLPs) have been studied\nindependently, their interactions remain largely unexplored. This study\ninvestigates how attention heads and next-token neurons interact in LLMs to\npredict new words. We propose a methodology to identify next-token neurons,\nfind prompts that highly activate them, and determine the upstream attention\nheads responsible. We then generate and evaluate explanations for the activity\nof these attention heads in an automated manner. Our findings reveal that some\nattention heads recognize specific contexts relevant to predicting a token and\nactivate a downstream token-predicting neuron accordingly. This mechanism\nprovides a deeper understanding of how attention heads work with MLP neurons to\nperform next-token prediction. Our approach offers a foundation for further\nresearch into the intricate workings of LLMs and their impact on text\ngeneration and understanding.\n","authors":["Clement Neo","Shay B. Cohen","Fazl Barez"],"pdf_url":"https://arxiv.org/pdf/2402.15055v2.pdf","comment":"Accepted to EMNLP 2024 Main Conference"},{"id":"http://arxiv.org/abs/2410.13563v2","updated":"2024-10-23T13:19:26Z","published":"2024-10-17T14:00:18Z","title":"Ornstein-Uhlenbeck Adaptation as a Mechanism for Learning in Brains and\n  Machines","summary":"  Learning is a fundamental property of intelligent systems, observed across\nbiological organisms and engineered systems. While modern intelligent systems\ntypically rely on gradient descent for learning, the need for exact gradients\nand complex information flow makes its implementation in biological and\nneuromorphic systems challenging. This has motivated the exploration of\nalternative learning mechanisms that can operate locally and do not rely on\nexact gradients. In this work, we introduce a novel approach that leverages\nnoise in the parameters of the system and global reinforcement signals. Using\nan Ornstein-Uhlenbeck process with adaptive dynamics, our method balances\nexploration and exploitation during learning, driven by deviations from error\npredictions, akin to reward prediction error. Operating in continuous time,\nOrstein-Uhlenbeck adaptation (OUA) is proposed as a general mechanism for\nlearning dynamic, time-evolving environments. We validate our approach across\ndiverse tasks, including supervised learning and reinforcement learning in\nfeedforward and recurrent systems. Additionally, we demonstrate that it can\nperform meta-learning, adjusting hyper-parameters autonomously. Our results\nindicate that OUA provides a viable alternative to traditional gradient-based\nmethods, with potential applications in neuromorphic computing. It also hints\nat a possible mechanism for noise-driven learning in the brain, where\nstochastic neurotransmitter release may guide synaptic adjustments.\n","authors":["Jesus Garcia Fernandez","Nasir Ahmad","Marcel van Gerven"],"pdf_url":"https://arxiv.org/pdf/2410.13563v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.11397v2","updated":"2024-10-23T13:14:21Z","published":"2024-10-15T08:39:31Z","title":"FOOGD: Federated Collaboration for Both Out-of-distribution\n  Generalization and Detection","summary":"  Federated learning (FL) is a promising machine learning paradigm that\ncollaborates with client models to capture global knowledge. However, deploying\nFL models in real-world scenarios remains unreliable due to the coexistence of\nin-distribution data and unexpected out-of-distribution (OOD) data, such as\ncovariate-shift and semantic-shift data. Current FL researches typically\naddress either covariate-shift data through OOD generalization or\nsemantic-shift data via OOD detection, overlooking the simultaneous occurrence\nof various OOD shifts. In this work, we propose FOOGD, a method that estimates\nthe probability density of each client and obtains reliable global distribution\nas guidance for the subsequent FL process. Firstly, SM3D in FOOGD estimates\nscore model for arbitrary distributions without prior constraints, and detects\nsemantic-shift data powerfully. Then SAG in FOOGD provides invariant yet\ndiverse knowledge for both local covariate-shift generalization and client\nperformance generalization. In empirical validations, FOOGD significantly\nenjoys three main advantages: (1) reliably estimating non-normalized\ndecentralized distributions, (2) detecting semantic shift data via score\nvalues, and (3) generalizing to covariate-shift data by regularizing feature\nextractor. The prejoct is open in https://github.com/XeniaLLL/FOOGD-main.git.\n","authors":["Xinting Liao","Weiming Liu","Pengyang Zhou","Fengyuan Yu","Jiahe Xu","Jun Wang","Wenjie Wang","Chaochao Chen","Xiaolin Zheng"],"pdf_url":"https://arxiv.org/pdf/2410.11397v2.pdf","comment":"NeurIPS 2024"},{"id":"http://arxiv.org/abs/2410.17840v1","updated":"2024-10-23T13:05:46Z","published":"2024-10-23T13:05:46Z","title":"Is the GPU Half-Empty or Half-Full? Practical Scheduling Techniques for\n  LLMs","summary":"  Serving systems for Large Language Models (LLMs) improve throughput by\nprocessing several requests concurrently. However, multiplexing hardware\nresources between concurrent requests involves non-trivial scheduling\ndecisions. Practical serving systems typically implement these decisions at two\nlevels: First, a load balancer routes requests to different servers which each\nhold a replica of the LLM. Then, on each server, an engine-level scheduler\ndecides when to run a request, or when to queue or preempt it. Improved\nscheduling policies may benefit a wide range of LLM deployments and can often\nbe implemented as \"drop-in replacements\" to a system's current policy. In this\nwork, we survey scheduling techniques from the literature and from practical\nserving systems. We find that schedulers from the literature often achieve good\nperformance but introduce significant complexity. In contrast, schedulers in\npractical deployments often leave easy performance gains on the table but are\neasy to implement, deploy and configure. This finding motivates us to introduce\ntwo new scheduling techniques, which are both easy to implement, and outperform\ncurrent techniques on production workload traces.\n","authors":["Ferdi Kossmann","Bruce Fontaine","Daya Khudia","Michael Cafarella","Samuel Madden"],"pdf_url":"https://arxiv.org/pdf/2410.17840v1.pdf","comment":"12 pages, 11 figures"},{"id":"http://arxiv.org/abs/2403.14774v2","updated":"2024-10-23T13:01:14Z","published":"2024-03-21T18:28:43Z","title":"Few-Shot Adversarial Prompt Learning on Vision-Language Models","summary":"  The vulnerability of deep neural networks to imperceptible adversarial\nperturbations has attracted widespread attention. Inspired by the success of\nvision-language foundation models, previous efforts achieved zero-shot\nadversarial robustness by aligning adversarial visual features with text\nsupervision. However, in practice, they are still unsatisfactory due to several\nissues, including heavy adaptation cost, suboptimal text supervision, and\nuncontrolled natural generalization capacity. In this paper, to address these\nissues, we propose a few-shot adversarial prompt framework where adapting input\nsequences with limited data makes significant adversarial robustness\nimprovement. Specifically, we achieve this by providing adversarially\ncorrelated text supervision that is end-to-end learned from adversarial\nexamples. We also propose a novel training objective that enhances the\nconsistency of multi-modal features while encourages differentiated uni-modal\nfeatures between natural and adversarial examples. The proposed framework gives\naccess to learn adversarial text supervision, which provides superior\ncross-modal adversarial alignment and matches state-of-the-art zero-shot\nadversarial robustness with only 1% training data. Code is available at:\nhttps://github.com/lionel-w2/FAP.\n","authors":["Yiwei Zhou","Xiaobo Xia","Zhiwei Lin","Bo Han","Tongliang Liu"],"pdf_url":"https://arxiv.org/pdf/2403.14774v2.pdf","comment":"NeurIPS 2024"},{"id":"http://arxiv.org/abs/2410.17835v1","updated":"2024-10-23T12:54:04Z","published":"2024-10-23T12:54:04Z","title":"Optimal Streaming Algorithms for Multi-Armed Bandits","summary":"  This paper studies two variants of the best arm identification (BAI) problem\nunder the streaming model, where we have a stream of $n$ arms with reward\ndistributions supported on $[0,1]$ with unknown means. The arms in the stream\nare arriving one by one, and the algorithm cannot access an arm unless it is\nstored in a limited size memory.\n  We first study the streaming \\eps-$top$-$k$ arms identification problem,\nwhich asks for $k$ arms whose reward means are lower than that of the $k$-th\nbest arm by at most $\\eps$ with probability at least $1-\\delta$. For general\n$\\eps \\in (0,1)$, the existing solution for this problem assumes $k = 1$ and\nachieves the optimal sample complexity $O(\\frac{n}{\\eps^2} \\log\n\\frac{1}{\\delta})$ using $O(\\log^*(n))$ ($\\log^*(n)$ equals the number of times\nthat we need to apply the logarithm function on $n$ before the results is no\nmore than 1.) memory and a single pass of the stream. We propose an algorithm\nthat works for any $k$ and achieves the optimal sample complexity\n$O(\\frac{n}{\\eps^2} \\log\\frac{k}{\\delta})$ using a single-arm memory and a\nsingle pass of the stream.\n  Second, we study the streaming BAI problem, where the objective is to\nidentify the arm with the maximum reward mean with at least $1-\\delta$\nprobability, using a single-arm memory and as few passes of the input stream as\npossible. We present a single-arm-memory algorithm that achieves a near\ninstance-dependent optimal sample complexity within $O(\\log \\Delta_2^{-1})$\npasses, where $\\Delta_2$ is the gap between the mean of the best arm and that\nof the second best arm.\n","authors":["Tianyuan Jin","Keke Huang","Jing Tang","Xiaokui Xiao"],"pdf_url":"https://arxiv.org/pdf/2410.17835v1.pdf","comment":"24pages"},{"id":"http://arxiv.org/abs/2410.17834v1","updated":"2024-10-23T12:53:58Z","published":"2024-10-23T12:53:58Z","title":"Non-intrusive Speech Quality Assessment with Diffusion Models Trained on\n  Clean Speech","summary":"  Diffusion models have found great success in generating high quality, natural\nsamples of speech, but their potential for density estimation for speech has so\nfar remained largely unexplored. In this work, we leverage an unconditional\ndiffusion model trained only on clean speech for the assessment of speech\nquality. We show that the quality of a speech utterance can be assessed by\nestimating the likelihood of a corresponding sample in the terminating Gaussian\ndistribution, obtained via a deterministic noising process. The resulting\nmethod is purely unsupervised, trained only on clean speech, and therefore does\nnot rely on annotations. Our diffusion-based approach leverages clean speech\npriors to assess quality based on how the input relates to the learned\ndistribution of clean data. Our proposed log-likelihoods show promising\nresults, correlating well with intrusive speech quality metrics such as POLQA\nand SI-SDR.\n","authors":["Danilo de Oliveira","Julius Richter","Jean-Marie Lemercier","Simon Welker","Timo Gerkmann"],"pdf_url":"https://arxiv.org/pdf/2410.17834v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.01476v2","updated":"2024-10-23T12:53:49Z","published":"2024-10-02T12:30:05Z","title":"Reducing Variance in Meta-Learning via Laplace Approximation for\n  Regression Tasks","summary":"  Given a finite set of sample points, meta-learning algorithms aim to learn an\noptimal adaptation strategy for new, unseen tasks. Often, this data can be\nambiguous as it might belong to different tasks concurrently. This is\nparticularly the case in meta-regression tasks. In such cases, the estimated\nadaptation strategy is subject to high variance due to the limited amount of\nsupport data for each task, which often leads to sub-optimal generalization\nperformance. In this work, we address the problem of variance reduction in\ngradient-based meta-learning and formalize the class of problems prone to this,\na condition we refer to as \\emph{task overlap}. Specifically, we propose a\nnovel approach that reduces the variance of the gradient estimate by weighing\neach support point individually by the variance of its posterior over the\nparameters. To estimate the posterior, we utilize the Laplace approximation,\nwhich allows us to express the variance in terms of the curvature of the loss\nlandscape of our meta-learner. Experimental results demonstrate the\neffectiveness of the proposed method and highlight the importance of variance\nreduction in meta-learning.\n","authors":["Alfredo Reichlin","Gustaf Tegnér","Miguel Vasco","Hang Yin","Mårten Björkman","Danica Kragic"],"pdf_url":"https://arxiv.org/pdf/2410.01476v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2210.01708v4","updated":"2024-10-23T12:50:18Z","published":"2022-10-04T16:08:54Z","title":"Conquering the Communication Constraints to Enable Large Pre-Trained\n  Models in Federated Learning","summary":"  Federated learning (FL) has emerged as a promising paradigm for enabling the\ncollaborative training of models without centralized access to the raw data on\nlocal devices. In the typical FL paradigm (e.g., FedAvg), model weights are\nsent to and from the server each round to participating clients. Recently, the\nuse of small pre-trained models has been shown effective in federated learning\noptimization and improving convergence. However, recent state-of-the-art\npre-trained models are getting more capable but also have more parameters. In\nconventional FL, sharing the enormous model weights can quickly put a massive\ncommunication burden on the system, especially if more capable models are\nemployed. Can we find a solution to enable those strong and readily-available\npre-trained models in FL to achieve excellent performance while simultaneously\nreducing the communication burden? To this end, we investigate the use of\nparameter-efficient fine-tuning in federated learning and thus introduce a new\nframework: FedPEFT. Specifically, we systemically evaluate the performance of\nFedPEFT across a variety of client stability, data distribution, and\ndifferential privacy settings. By only locally tuning and globally sharing a\nsmall portion of the model weights, significant reductions in the total\ncommunication overhead can be achieved while maintaining competitive or even\nbetter performance in a wide range of federated learning scenarios, providing\ninsight into a new paradigm for practical and effective federated systems.\n","authors":["Guangyu Sun","Umar Khalid","Matias Mendieta","Taojiannan Yang","Pu Wang","Minwoo Lee","Chen Chen"],"pdf_url":"https://arxiv.org/pdf/2210.01708v4.pdf","comment":null},{"id":"http://arxiv.org/abs/2404.01335v2","updated":"2024-10-23T12:38:40Z","published":"2024-03-30T13:25:11Z","title":"Generative AI Models for Different Steps in Architectural Design: A\n  Literature Review","summary":"  Recent advances in generative artificial intelligence (AI) technologies have\nbeen significantly driven by models such as generative adversarial networks\n(GANs), variational autoencoders (VAEs), and denoising diffusion probabilistic\nmodels (DDPMs). Although architects recognize the potential of generative AI in\ndesign, personal barriers often restrict their access to the latest\ntechnological developments, thereby causing the application of generative AI in\narchitectural design to lag behind. Therefore, it is essential to comprehend\nthe principles and advancements of generative AI models and analyze their\nrelevance in architecture applications. This paper first provides an overview\nof generative AI technologies, with a focus on probabilistic diffusion models\n(DDPMs), 3D generative models, and foundation models, highlighting their recent\ndevelopments and main application scenarios. Then, the paper explains how the\nabovementioned models could be utilized in architecture. We subdivide the\narchitectural design process into six steps and review related research\nprojects in each step from 2020 to the present. Lastly, this paper discusses\npotential future directions for applying generative AI in the architectural\ndesign steps. This research can help architects quickly understand the\ndevelopment and latest progress of generative AI and contribute to the further\ndevelopment of intelligent architecture.\n","authors":["Chengyuan Li","Tianyu Zhang","Xusheng Du","Ye Zhang","Haoran Xie"],"pdf_url":"https://arxiv.org/pdf/2404.01335v2.pdf","comment":"34 pages, 14 figures, accepted by Frontiers of Architectural Research"},{"id":"http://arxiv.org/abs/2410.17823v1","updated":"2024-10-23T12:32:21Z","published":"2024-10-23T12:32:21Z","title":"Att2CPC: Attention-Guided Lossy Attribute Compression of Point Clouds","summary":"  With the great progress of 3D sensing and acquisition technology, the volume\nof point cloud data has grown dramatically, which urges the development of\nefficient point cloud compression methods. In this paper, we focus on the task\nof learned lossy point cloud attribute compression (PCAC). We propose an\nefficient attention-based method for lossy compression of point cloud\nattributes leveraging on an autoencoder architecture. Specifically, at the\nencoding side, we conduct multiple downsampling to best exploit the local\nattribute patterns, in which effective External Cross Attention (ECA) is\ndevised to hierarchically aggregate features by intergrating attributes and\ngeometry contexts. At the decoding side, the attributes of the point cloud are\nprogressively reconstructed based on the multi-scale representation and the\nzero-padding upsampling tactic. To the best of our knowledge, this is the first\napproach to introduce attention mechanism to point-based lossy PCAC task. We\nverify the compression efficiency of our model on various sequences, including\nhuman body frames, sparse objects, and large-scale point cloud scenes.\nExperiments show that our method achieves an average improvement of 1.15 dB and\n2.13 dB in BD-PSNR of Y channel and YUV channel, respectively, when comparing\nwith the state-of-the-art point-based method Deep-PCAC. Codes of this paper are\navailable at https://github.com/I2-Multimedia-Lab/Att2CPC.\n","authors":["Kai Liu","Kang You","Pan Gao","Manoranjan Paul"],"pdf_url":"https://arxiv.org/pdf/2410.17823v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2407.04811v2","updated":"2024-10-23T12:27:12Z","published":"2024-07-05T18:49:07Z","title":"Simplifying Deep Temporal Difference Learning","summary":"  Q-learning played a foundational role in the field reinforcement learning\n(RL). However, TD algorithms with off-policy data, such as Q-learning, or\nnonlinear function approximation like deep neural networks require several\nadditional tricks to stabilise training, primarily a replay buffer and target\nnetworks. Unfortunately, the delayed updating of frozen network parameters in\nthe target network harms the sample efficiency and, similarly, the replay\nbuffer introduces memory and implementation overheads. In this paper, we\ninvestigate whether it is possible to accelerate and simplify TD training while\nmaintaining its stability. Our key theoretical result demonstrates for the\nfirst time that regularisation techniques such as LayerNorm can yield provably\nconvergent TD algorithms without the need for a target network, even with\noff-policy data. Empirically, we find that online, parallelised sampling\nenabled by vectorised environments stabilises training without the need of a\nreplay buffer. Motivated by these findings, we propose PQN, our simplified deep\nonline Q-Learning algorithm. Surprisingly, this simple algorithm is competitive\nwith more complex methods like: Rainbow in Atari, R2D2 in Hanabi, QMix in Smax,\nPPO-RNN in Craftax, and can be up to 50x faster than traditional DQN without\nsacrificing sample efficiency. In an era where PPO has become the go-to RL\nalgorithm, PQN reestablishes Q-learning as a viable alternative.\n","authors":["Matteo Gallici","Mattie Fellows","Benjamin Ellis","Bartomeu Pou","Ivan Masmitja","Jakob Nicolaus Foerster","Mario Martin"],"pdf_url":"https://arxiv.org/pdf/2407.04811v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2401.04372v3","updated":"2024-10-23T12:19:16Z","published":"2024-01-09T06:15:45Z","title":"Stable generative modeling using Schrödinger bridges","summary":"  We consider the problem of sampling from an unknown distribution for which\nonly a sufficiently large number of training samples are available. Such\nsettings have recently drawn considerable interest in the context of generative\nmodelling and Bayesian inference. In this paper, we propose a generative model\ncombining Schr\\\"odinger bridges and Langevin dynamics. Schr\\\"odinger bridges\nover an appropriate reversible reference process are used to approximate the\nconditional transition probability from the available training samples, which\nis then implemented in a discrete-time reversible Langevin sampler to generate\nnew samples. By setting the kernel bandwidth in the reference process to match\nthe time step size used in the unadjusted Langevin algorithm, our method\neffectively circumvents any stability issues typically associated with the\ntime-stepping of stiff stochastic differential equations. Moreover, we\nintroduce a novel split-step scheme, ensuring that the generated samples remain\nwithin the convex hull of the training samples. Our framework can be naturally\nextended to generate conditional samples and to Bayesian inference problems. We\ndemonstrate the performance of our proposed scheme through experiments on\nsynthetic datasets with increasing dimensions and on a stochastic subgrid-scale\nparametrization conditional sampling problem as well as generating sample\ntrajectories of a dynamical system using conditional sampling.\n","authors":["Georg A. Gottwald","Fengyi Li","Youssef Marzouk","Sebastian Reich"],"pdf_url":"https://arxiv.org/pdf/2401.04372v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.11960v4","updated":"2024-10-23T12:18:49Z","published":"2024-03-18T16:57:16Z","title":"Causality-Aware Spatiotemporal Graph Neural Networks for Spatiotemporal\n  Time Series Imputation","summary":"  Spatiotemporal time series are usually collected via monitoring sensors\nplaced at different locations, which usually contain missing values due to\nvarious failures, such as mechanical damages and Internet outages. Imputing the\nmissing values is crucial for analyzing time series. When recovering a specific\ndata point, most existing methods consider all the information relevant to that\npoint regardless of the cause-and-effect relationship. During data collection,\nit is inevitable that some unknown confounders are included, e.g., background\nnoise in time series and non-causal shortcut edges in the constructed sensor\nnetwork. These confounders could open backdoor paths and establish non-causal\ncorrelations between the input and output. Over-exploiting these non-causal\ncorrelations could cause overfitting. In this paper, we first revisit\nspatiotemporal time series imputation from a causal perspective and show how to\nblock the confounders via the frontdoor adjustment. Based on the results of\nfrontdoor adjustment, we introduce a novel Causality-Aware Spatiotemporal Graph\nNeural Network (Casper), which contains a novel Prompt Based Decoder (PBD) and\na Spatiotemporal Causal Attention (SCA). PBD could reduce the impact of\nconfounders and SCA could discover the sparse causal relationships among\nembeddings. Theoretical analysis reveals that SCA discovers causal\nrelationships based on the values of gradients. We evaluate Casper on three\nreal-world datasets, and the experimental results show that Casper could\noutperform the baselines and could effectively discover causal relationships.\n","authors":["Baoyu Jing","Dawei Zhou","Kan Ren","Carl Yang"],"pdf_url":"https://arxiv.org/pdf/2403.11960v4.pdf","comment":"Accepted by CIKM'2024. Fixed typos"},{"id":"http://arxiv.org/abs/2410.17814v1","updated":"2024-10-23T12:18:36Z","published":"2024-10-23T12:18:36Z","title":"Learning Lossless Compression for High Bit-Depth Volumetric Medical\n  Image","summary":"  Recent advances in learning-based methods have markedly enhanced the\ncapabilities of image compression. However, these methods struggle with high\nbit-depth volumetric medical images, facing issues such as degraded\nperformance, increased memory demand, and reduced processing speed. To address\nthese challenges, this paper presents the Bit-Division based Lossless\nVolumetric Image Compression (BD-LVIC) framework, which is tailored for high\nbit-depth medical volume compression. The BD-LVIC framework skillfully divides\nthe high bit-depth volume into two lower bit-depth segments: the Most\nSignificant Bit-Volume (MSBV) and the Least Significant Bit-Volume (LSBV). The\nMSBV concentrates on the most significant bits of the volumetric medical image,\ncapturing vital structural details in a compact manner. This reduction in\ncomplexity greatly improves compression efficiency using traditional codecs.\nConversely, the LSBV deals with the least significant bits, which encapsulate\nintricate texture details. To compress this detailed information effectively,\nwe introduce an effective learning-based compression model equipped with a\nTransformer-Based Feature Alignment Module, which exploits both intra-slice and\ninter-slice redundancies to accurately align features. Subsequently, a Parallel\nAutoregressive Coding Module merges these features to precisely estimate the\nprobability distribution of the least significant bit-planes. Our extensive\ntesting demonstrates that the BD-LVIC framework not only sets new performance\nbenchmarks across various datasets but also maintains a competitive coding\nspeed, highlighting its significant potential and practical utility in the\nrealm of volumetric medical image compression.\n","authors":["Kai Wang","Yuanchao Bai","Daxin Li","Deming Zhai","Junjun Jiang","Xianming Liu"],"pdf_url":"https://arxiv.org/pdf/2410.17814v1.pdf","comment":"13 pages"},{"id":"http://arxiv.org/abs/2408.04307v2","updated":"2024-10-23T12:08:33Z","published":"2024-08-08T08:40:15Z","title":"MoC-System: Efficient Fault Tolerance for Sparse Mixture-of-Experts\n  Model Training","summary":"  As large language models continue to scale up, distributed training systems\nhave expanded beyond 10k nodes, intensifying the importance of fault tolerance.\nCheckpoint has emerged as the predominant fault tolerance strategy, with\nextensive studies dedicated to optimizing its efficiency. However, the advent\nof the sparse Mixture-of-Experts (MoE) model presents new challenges due to the\nsubstantial increase in model size, despite comparable computational demands to\ndense models.\n  In this work, we propose the Mixture-of-Checkpoint System (MoC-System) to\norchestrate the vast array of checkpoint shards produced in distributed\ntraining systems. MoC-System features a novel Partial Experts Checkpointing\n(PEC) mechanism, an algorithm-system co-design that strategically saves a\nselected subset of experts, effectively reducing the MoE checkpoint size to\nlevels comparable with dense models. Incorporating hybrid parallel strategies,\nMoC-System involves fully sharded checkpointing strategies to evenly distribute\nthe workload across distributed ranks. Furthermore, MoC-System introduces a\ntwo-level checkpointing management method that asynchronously handles in-memory\nsnapshots and persistence processes.\n  We build MoC-System upon the Megatron-DeepSpeed framework, achieving up to a\n98.9% reduction in overhead for each checkpointing process compared to the\noriginal method, during MoE model training with ZeRO-2 data parallelism and\nexpert parallelism. Additionally, extensive empirical analyses substantiate\nthat our methods enhance efficiency while maintaining comparable model\naccuracy, even achieving an average accuracy increase of 1.08% on downstream\ntasks.\n","authors":["Weilin Cai","Le Qin","Jiayi Huang"],"pdf_url":"https://arxiv.org/pdf/2408.04307v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.12641v3","updated":"2024-10-23T11:54:42Z","published":"2024-03-19T11:24:14Z","title":"Automated Contrastive Learning Strategy Search for Time Series","summary":"  In recent years, Contrastive Learning (CL) has become a predominant\nrepresentation learning paradigm for time series. Most existing methods\nmanually build specific CL Strategies (CLS) by human heuristics for certain\ndatasets and tasks. However, manually developing CLS usually requires excessive\nprior knowledge about the data, and massive experiments to determine the\ndetailed CL configurations. In this paper, we present an Automated Machine\nLearning (AutoML) practice at Microsoft, which automatically learns CLS for\ntime series datasets and tasks, namely Automated Contrastive Learning (AutoCL).\nWe first construct a principled search space of size over $3\\times10^{12}$,\ncovering data augmentation, embedding transformation, contrastive pair\nconstruction, and contrastive losses. Further, we introduce an efficient\nreinforcement learning algorithm, which optimizes CLS from the performance on\nthe validation tasks, to obtain effective CLS within the space. Experimental\nresults on various real-world datasets demonstrate that AutoCL could\nautomatically find the suitable CLS for the given dataset and task. From the\ncandidate CLS found by AutoCL on several public datasets/tasks, we compose a\ntransferable Generally Good Strategy (GGS), which has a strong performance for\nother datasets. We also provide empirical analysis as a guide for the future\ndesign of CLS.\n","authors":["Baoyu Jing","Yansen Wang","Guoxin Sui","Jing Hong","Jingrui He","Yuqing Yang","Dongsheng Li","Kan Ren"],"pdf_url":"https://arxiv.org/pdf/2403.12641v3.pdf","comment":"Accepted by CIKM'2024. Fixed typos"},{"id":"http://arxiv.org/abs/2410.17796v1","updated":"2024-10-23T11:52:52Z","published":"2024-10-23T11:52:52Z","title":"A Comprehensive Analysis on the Learning Curve in Kernel Ridge\n  Regression","summary":"  This paper conducts a comprehensive study of the learning curves of kernel\nridge regression (KRR) under minimal assumptions. Our contributions are\nthree-fold: 1) we analyze the role of key properties of the kernel, such as its\nspectral eigen-decay, the characteristics of the eigenfunctions, and the\nsmoothness of the kernel; 2) we demonstrate the validity of the Gaussian\nEquivalent Property (GEP), which states that the generalization performance of\nKRR remains the same when the whitened features are replaced by standard\nGaussian vectors, thereby shedding light on the success of previous analyzes\nunder the Gaussian Design Assumption; 3) we derive novel bounds that improve\nover existing bounds across a broad range of setting such as (in)dependent\nfeature vectors and various combinations of eigen-decay rates in the\nover/underparameterized regimes.\n","authors":["Tin Sum Cheng","Aurelien Lucchi","Anastasis Kratsios","David Belius"],"pdf_url":"https://arxiv.org/pdf/2410.17796v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.17792v1","updated":"2024-10-23T11:47:04Z","published":"2024-10-23T11:47:04Z","title":"Enhancing Federated Learning Convergence with Dynamic Data Queue and\n  Data Entropy-driven Participant Selection","summary":"  Federated Learning (FL) is a decentralized approach for collaborative model\ntraining on edge devices. This distributed method of model training offers\nadvantages in privacy, security, regulatory compliance, and cost-efficiency.\nOur emphasis in this research lies in addressing statistical complexity in FL,\nespecially when the data stored locally across devices is not identically and\nindependently distributed (non-IID). We have observed an accuracy reduction of\nup to approximately 10\\% to 30\\%, particularly in skewed scenarios where each\nedge device trains with only 1 class of data. This reduction is attributed to\nweight divergence, quantified using the Euclidean distance between device-level\nclass distributions and the population distribution, resulting in a bias term\n(\\(\\delta_k\\)). As a solution, we present a method to improve convergence in FL\nby creating a global subset of data on the server and dynamically distributing\nit across devices using a Dynamic Data queue-driven Federated Learning (DDFL).\nNext, we leverage Data Entropy metrics to observe the process during each\ntraining round and enable reasonable device selection for aggregation.\nFurthermore, we provide a convergence analysis of our proposed DDFL to justify\ntheir viability in practical FL scenarios, aiming for better device selection,\na non-sub-optimal global model, and faster convergence. We observe that our\napproach results in a substantial accuracy boost of approximately 5\\% for the\nMNIST dataset, around 18\\% for CIFAR-10, and 20\\% for CIFAR-100 with a 10\\%\nglobal subset of data, outperforming the state-of-the-art (SOTA) aggregation\nalgorithms.\n","authors":["Charuka Herath","Xiaolan Liu","Sangarapillai Lambotharan","Yogachandran Rahulamathavan"],"pdf_url":"https://arxiv.org/pdf/2410.17792v1.pdf","comment":"The Journal is submitted to IEEE Transactions in the Internet of\n  Things"},{"id":"http://arxiv.org/abs/2410.17787v1","updated":"2024-10-23T11:37:20Z","published":"2024-10-23T11:37:20Z","title":"Large Language Models Engineer Too Many Simple Features For Tabular Data","summary":"  Tabular machine learning problems often require time-consuming and\nlabor-intensive feature engineering. Recent efforts have focused on using large\nlanguage models (LLMs) to capitalize on their potential domain knowledge. At\nthe same time, researchers have observed ethically concerning negative biases\nin other LLM-related use cases, such as text generation. These developments\nmotivated us to investigate whether LLMs exhibit a bias that negatively impacts\nthe performance of feature engineering. While not ethically concerning, such a\nbias could hinder practitioners from fully utilizing LLMs for automated data\nscience. Therefore, we propose a method to detect potential biases by detecting\nanomalies in the frequency of operators (e.g., adding two features) suggested\nby LLMs when engineering new features. Our experiments evaluate the bias of\nfour LLMs, two big frontier and two small open-source models, across 27 tabular\ndatasets. Our results indicate that LLMs are biased toward simple operators,\nsuch as addition, and can fail to utilize more complex operators, such as\ngrouping followed by aggregations. Furthermore, the bias can negatively impact\nthe predictive performance when using LLM-generated features. Our results call\nfor mitigating bias when using LLMs for feature engineering.\n","authors":["Jaris Küken","Lennart Purucker","Frank Hutter"],"pdf_url":"https://arxiv.org/pdf/2410.17787v1.pdf","comment":"Preprint"},{"id":"http://arxiv.org/abs/2410.17772v1","updated":"2024-10-23T11:19:48Z","published":"2024-10-23T11:19:48Z","title":"Scaling Robot Policy Learning via Zero-Shot Labeling with Foundation\n  Models","summary":"  A central challenge towards developing robots that can relate human language\nto their perception and actions is the scarcity of natural language annotations\nin diverse robot datasets. Moreover, robot policies that follow natural\nlanguage instructions are typically trained on either templated language or\nexpensive human-labeled instructions, hindering their scalability. To this end,\nwe introduce NILS: Natural language Instruction Labeling for Scalability. NILS\nautomatically labels uncurated, long-horizon robot data at scale in a zero-shot\nmanner without any human intervention. NILS combines pretrained vision-language\nfoundation models in order to detect objects in a scene, detect object-centric\nchanges, segment tasks from large datasets of unlabelled interaction data and\nultimately label behavior datasets. Evaluations on BridgeV2, Fractal, and a\nkitchen play dataset show that NILS can autonomously annotate diverse robot\ndemonstrations of unlabeled and unstructured datasets while alleviating several\nshortcomings of crowdsourced human annotations, such as low data quality and\ndiversity. We use NILS to label over 115k trajectories obtained from over 430\nhours of robot data. We open-source our auto-labeling code and generated\nannotations on our website: http://robottasklabeling.github.io.\n","authors":["Nils Blank","Moritz Reuss","Marcel Rühle","Ömer Erdinç Yağmurlu","Fabian Wenzel","Oier Mees","Rudolf Lioutikov"],"pdf_url":"https://arxiv.org/pdf/2410.17772v1.pdf","comment":"Project Website at https://robottasklabeling.github.io/"},{"id":"http://arxiv.org/abs/2410.17770v1","updated":"2024-10-23T11:19:08Z","published":"2024-10-23T11:19:08Z","title":"Locating Information in Large Language Models via Random Matrix Theory","summary":"  As large language models (LLMs) become central to AI applications, gaining a\ndeeper understanding of their inner workings is increasingly important. In this\nwork, we analyze the weight matrices of pretrained transformer models --\nspecifically BERT and Llama -- using random matrix theory (RMT) as a\nzero-information hypothesis. While randomly initialized weights perfectly agree\nwith RMT predictions, deviations emerge after training, allowing us to locate\nlearned structures within the models. We identify layer-type specific behaviors\nthat are consistent across all blocks and architectures considered. By\npinpointing regions that deviate from RMT predictions, we highlight areas of\nfeature learning and confirm this through comparisons with the activation\ncovariance matrices of the corresponding layers. Our method provides a\ndiagnostic tool for identifying relevant regions in transformer weights using\nonly the trained matrices. Additionally, we address the ongoing debate\nregarding the significance of small singular values in the context of\nfine-tuning and alignment in LLMs. Our findings reveal that, after fine-tuning,\nsmall singular values play a crucial role in the models' capabilities,\nsuggesting that removing them in an already aligned transformer can be\ndetrimental, as it may compromise model alignment.\n","authors":["Max Staats","Matthias Thamm","Bernd Rosenow"],"pdf_url":"https://arxiv.org/pdf/2410.17770v1.pdf","comment":"17 pages, 14 figures"},{"id":"http://arxiv.org/abs/2410.17765v1","updated":"2024-10-23T11:06:36Z","published":"2024-10-23T11:06:36Z","title":"Faster Language Models with Better Multi-Token Prediction Using Tensor\n  Decomposition","summary":"  We propose a new model for multi-token prediction in transformers, aiming to\nenhance sampling efficiency without compromising accuracy. Motivated by recent\nwork that predicts the probabilities of subsequent tokens using multiple heads,\nwe connect this approach to rank-$1$ canonical tensor decomposition. By\ngeneralizing it to a rank-$r$ canonical probability decomposition, we develop\nan improved model that predicts multiple tokens simultaneously. This model can\nalso be interpreted as a mixture of experts, allowing us to leverage successful\ntechniques from that domain for efficient and robust training. Importantly, the\noverall overhead for training and sampling remains low. Our method demonstrates\nsignificant improvements in inference speed for both text and code generation\ntasks, proving particularly beneficial within the self-speculative decoding\nparadigm. It maintains its effectiveness across various model sizes and\ntraining epochs, highlighting its robustness and scalability.\n","authors":["Artem Basharin","Andrei Chertkov","Ivan Oseledets"],"pdf_url":"https://arxiv.org/pdf/2410.17765v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.17764v1","updated":"2024-10-23T11:02:59Z","published":"2024-10-23T11:02:59Z","title":"Beyond Backpropagation: Optimization with Multi-Tangent Forward\n  Gradients","summary":"  The gradients used to train neural networks are typically computed using\nbackpropagation. While an efficient way to obtain exact gradients,\nbackpropagation is computationally expensive, hinders parallelization, and is\nbiologically implausible. Forward gradients are an approach to approximate the\ngradients from directional derivatives along random tangents computed by\nforward-mode automatic differentiation. So far, research has focused on using a\nsingle tangent per step. This paper provides an in-depth analysis of\nmulti-tangent forward gradients and introduces an improved approach to\ncombining the forward gradients from multiple tangents based on orthogonal\nprojections. We demonstrate that increasing the number of tangents improves\nboth approximation quality and optimization performance across various tasks.\n","authors":["Katharina Flügel","Daniel Coquelin","Marie Weiel","Achim Streit","Markus Götz"],"pdf_url":"https://arxiv.org/pdf/2410.17764v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2312.12676v2","updated":"2024-10-23T11:01:45Z","published":"2023-12-20T00:31:43Z","title":"Bayesian Analysis of Combinatorial Gaussian Process Bandits","summary":"  We consider the combinatorial volatile Gaussian process (GP) semi-bandit\nproblem. Each round, an agent is provided a set of available base arms and must\nselect a subset of them to maximize the long-term cumulative reward. We study\nthe Bayesian setting and provide novel Bayesian cumulative regret bounds for\nthree GP-based algorithms: GP-UCB, GP-BayesUCB and GP-TS. Our bounds extend\nprevious results for GP-UCB and GP-TS to the infinite, volatile and\ncombinatorial setting, and to the best of our knowledge, we provide the first\nregret bound for GP-BayesUCB. Volatile arms encompass other widely considered\nbandit problems such as contextual bandits. Furthermore, we employ our\nframework to address the challenging real-world problem of online\nenergy-efficient navigation, where we demonstrate its effectiveness compared to\nthe alternatives.\n","authors":["Jack Sandberg","Niklas Åkerblom","Morteza Haghir Chehreghani"],"pdf_url":"https://arxiv.org/pdf/2312.12676v2.pdf","comment":"32 pages, 10 figures"},{"id":"http://arxiv.org/abs/2410.17762v1","updated":"2024-10-23T11:01:39Z","published":"2024-10-23T11:01:39Z","title":"Anomaly Resilient Temporal QoS Prediction using Hypergraph Convoluted\n  Transformer Network","summary":"  Quality-of-Service (QoS) prediction is a critical task in the service\nlifecycle, enabling precise and adaptive service recommendations by\nanticipating performance variations over time in response to evolving network\nuncertainties and user preferences. However, contemporary QoS prediction\nmethods frequently encounter data sparsity and cold-start issues, which hinder\naccurate QoS predictions and limit the ability to capture diverse user\npreferences. Additionally, these methods often assume QoS data reliability,\nneglecting potential credibility issues such as outliers and the presence of\ngreysheep users and services with atypical invocation patterns. Furthermore,\ntraditional approaches fail to leverage diverse features, including\ndomain-specific knowledge and complex higher-order patterns, essential for\naccurate QoS predictions. In this paper, we introduce a real-time, trust-aware\nframework for temporal QoS prediction to address the aforementioned challenges,\nfeaturing an end-to-end deep architecture called the Hypergraph Convoluted\nTransformer Network (HCTN). HCTN combines a hypergraph structure with graph\nconvolution over hyper-edges to effectively address high-sparsity issues by\ncapturing complex, high-order correlations. Complementing this, the transformer\nnetwork utilizes multi-head attention along with parallel 1D convolutional\nlayers and fully connected dense blocks to capture both fine-grained and\ncoarse-grained dynamic patterns. Additionally, our approach includes a\nsparsity-resilient solution for detecting greysheep users and services,\nincorporating their unique characteristics to improve prediction accuracy.\nTrained with a robust loss function resistant to outliers, HCTN demonstrated\nstate-of-the-art performance on the large-scale WSDREAM-2 datasets for response\ntime and throughput.\n","authors":["Suraj Kumar","Soumi Chattopadhyay","Chandranath Adak"],"pdf_url":"https://arxiv.org/pdf/2410.17762v1.pdf","comment":"16 pages, 12 figures"},{"id":"http://arxiv.org/abs/2410.17760v1","updated":"2024-10-23T10:56:05Z","published":"2024-10-23T10:56:05Z","title":"Topology meets Machine Learning: An Introduction using the Euler\n  Characteristic Transform","summary":"  This overview article makes the case for how topological concepts can enrich\nresearch in machine learning. Using the Euler Characteristic Transform (ECT), a\ngeometrical-topological invariant, as a running example, I present different\nuse cases that result in more efficient models for analyzing point clouds,\ngraphs, and meshes. Moreover, I outline a vision for how topological concepts\ncould be used in the future, comprising (1) the learning of functions on\ntopological spaces, (2) the building of hybrid models that imbue neural\nnetworks with knowledge about the topological information in data, and (3) the\nanalysis of qualitative properties of neural networks. With current research\nalready addressing some of these aspects, this article thus serves as an\nintroduction and invitation to this nascent area of research.\n","authors":["Bastian Rieck"],"pdf_url":"https://arxiv.org/pdf/2410.17760v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.17758v1","updated":"2024-10-23T10:50:07Z","published":"2024-10-23T10:50:07Z","title":"Escaping the Forest: Sparse Interpretable Neural Networks for Tabular\n  Data","summary":"  Tabular datasets are widely used in scientific disciplines such as biology.\nWhile these disciplines have already adopted AI methods to enhance their\nfindings and analysis, they mainly use tree-based methods due to their\ninterpretability. At the same time, artificial neural networks have been shown\nto offer superior flexibility and depth for rich and complex non-tabular\nproblems, but they are falling behind tree-based models for tabular data in\nterms of performance and interpretability. Although sparsity has been shown to\nimprove the interpretability and performance of ANN models for complex\nnon-tabular datasets, enforcing sparsity structurally and formatively for\ntabular data before training the model, remains an open question. To address\nthis question, we establish a method that infuses sparsity in neural networks\nby utilising attention mechanisms to capture the features' importance in\ntabular datasets. We show that our models, Sparse TABular NET or sTAB-Net with\nattention mechanisms, are more effective than tree-based models, reaching the\nstate-of-the-art on biological datasets. They further permit the extraction of\ninsights from these datasets and achieve better performance than post-hoc\nmethods like SHAP.\n","authors":["Salvatore Raieli","Abdulrahman Altahhan","Nathalie Jeanray","Stéphane Gerart","Sebastien Vachenc"],"pdf_url":"https://arxiv.org/pdf/2410.17758v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.05549v3","updated":"2024-10-23T10:31:03Z","published":"2023-01-12T18:46:28Z","title":"On the explainability of quantum neural networks based on variational\n  quantum circuits","summary":"  Ridge functions are used to describe and study the lower bound of the\napproximation done by the neural networks which can be written as a linear\ncombination of activation functions. If the activation functions are also ridge\nfunctions, these networks are called explainable neural networks.\n  In this brief paper, we first show that quantum neural networks which are\nbased on variational quantum circuits can be written as a linear combination of\nridge functions by following matrix notations. Consequently, we show that the\ninterpretability and explainability of such quantum neural networks can be\ndirectly considered and studied as an approximation with the linear combination\nof ridge functions.\n","authors":["Ammar Daskin"],"pdf_url":"https://arxiv.org/pdf/2301.05549v3.pdf","comment":"a brief paper,a few missing references have been added"},{"id":"http://arxiv.org/abs/2410.17751v1","updated":"2024-10-23T10:28:17Z","published":"2024-10-23T10:28:17Z","title":"VISAGE: Video Synthesis using Action Graphs for Surgery","summary":"  Surgical data science (SDS) is a field that analyzes patient data before,\nduring, and after surgery to improve surgical outcomes and skills. However,\nsurgical data is scarce, heterogeneous, and complex, which limits the\napplicability of existing machine learning methods. In this work, we introduce\nthe novel task of future video generation in laparoscopic surgery. This task\ncan augment and enrich the existing surgical data and enable various\napplications, such as simulation, analysis, and robot-aided surgery.\nUltimately, it involves not only understanding the current state of the\noperation but also accurately predicting the dynamic and often unpredictable\nnature of surgical procedures. Our proposed method, VISAGE (VIdeo Synthesis\nusing Action Graphs for Surgery), leverages the power of action scene graphs to\ncapture the sequential nature of laparoscopic procedures and utilizes diffusion\nmodels to synthesize temporally coherent video sequences. VISAGE predicts the\nfuture frames given only a single initial frame, and the action graph triplets.\nBy incorporating domain-specific knowledge through the action graph, VISAGE\nensures the generated videos adhere to the expected visual and motion patterns\nobserved in real laparoscopic procedures. The results of our experiments\ndemonstrate high-fidelity video generation for laparoscopy procedures, which\nenables various applications in SDS.\n","authors":["Yousef Yeganeh","Rachmadio Lazuardi","Amir Shamseddin","Emine Dari","Yash Thirani","Nassir Navab Azade Farshad"],"pdf_url":"https://arxiv.org/pdf/2410.17751v1.pdf","comment":"Accepted at MICCAI 2024 Embodied AI and Robotics for HealTHcare\n  (EARTH) Workshop"},{"id":"http://arxiv.org/abs/2410.17748v1","updated":"2024-10-23T10:23:53Z","published":"2024-10-23T10:23:53Z","title":"Can Uncertainty Quantification Enable Better Learning-based Index\n  Tuning?","summary":"  Index tuning is crucial for optimizing database performance by selecting\noptimal indexes based on workload. The key to this process lies in an accurate\nand efficient benefit estimator. Traditional methods relying on what-if tools\noften suffer from inefficiency and inaccuracy. In contrast, learning-based\nmodels provide a promising alternative but face challenges such as instability,\nlack of interpretability, and complex management. To overcome these\nlimitations, we adopt a novel approach: quantifying the uncertainty in\nlearning-based models' results, thereby combining the strengths of both\ntraditional and learning-based methods for reliable index tuning. We propose\nBeauty, the first uncertainty-aware framework that enhances learning-based\nmodels with uncertainty quantification and uses what-if tools as a\ncomplementary mechanism to improve reliability and reduce management\ncomplexity. Specifically, we introduce a novel method that combines AutoEncoder\nand Monte Carlo Dropout to jointly quantify uncertainty, tailored to the\ncharacteristics of benefit estimation tasks. In experiments involving sixteen\nmodels, our approach outperformed existing uncertainty quantification methods\nin the majority of cases. We also conducted index tuning tests on six datasets.\nBy applying the Beauty framework, we eliminated worst-case scenarios and more\nthan tripled the occurrence of best-case scenarios.\n","authors":["Tao Yu","Zhaonian Zou","Hao Xiong"],"pdf_url":"https://arxiv.org/pdf/2410.17748v1.pdf","comment":"14 pages, 11 figures"},{"id":"http://arxiv.org/abs/2410.17744v1","updated":"2024-10-23T10:17:13Z","published":"2024-10-23T10:17:13Z","title":"Learning Versatile Skills with Curriculum Masking","summary":"  Masked prediction has emerged as a promising pretraining paradigm in offline\nreinforcement learning (RL) due to its versatile masking schemes, enabling\nflexible inference across various downstream tasks with a unified model.\nDespite the versatility of masked prediction, it remains unclear how to balance\nthe learning of skills at different levels of complexity. To address this, we\npropose CurrMask, a curriculum masking pretraining paradigm for sequential\ndecision making. Motivated by how humans learn by organizing knowledge in a\ncurriculum, CurrMask adjusts its masking scheme during pretraining for learning\nversatile skills. Through extensive experiments, we show that CurrMask exhibits\nsuperior zero-shot performance on skill prompting tasks, goal-conditioned\nplanning tasks, and competitive finetuning performance on offline RL tasks.\nAdditionally, our analysis of training dynamics reveals that CurrMask gradually\nacquires skills of varying complexity by dynamically adjusting its masking\nscheme.\n","authors":["Yao Tang","Zhihui Xie","Zichuan Lin","Deheng Ye","Shuai Li"],"pdf_url":"https://arxiv.org/pdf/2410.17744v1.pdf","comment":"NeurIPS 2024 poster, 21 pages, 7 figures"},{"id":"http://arxiv.org/abs/2407.03094v2","updated":"2024-10-23T10:09:10Z","published":"2024-07-03T13:34:33Z","title":"Conformal Prediction for Causal Effects of Continuous Treatments","summary":"  Uncertainty quantification of causal effects is crucial for safety-critical\napplications such as personalized medicine. A powerful approach for this is\nconformal prediction, which has several practical benefits due to\nmodel-agnostic finite-sample guarantees. Yet, existing methods for conformal\nprediction of causal effects are limited to binary/discrete treatments and make\nhighly restrictive assumptions such as known propensity scores. In this work,\nwe provide a novel conformal prediction method for potential outcomes of\ncontinuous treatments. We account for the additional uncertainty introduced\nthrough propensity estimation so that our conformal prediction intervals are\nvalid even if the propensity score is unknown. Our contributions are\nthree-fold: (1) We derive finite-sample prediction intervals for potential\noutcomes of continuous treatments. (2) We provide an algorithm for calculating\nthe derived intervals. (3) We demonstrate the effectiveness of the conformal\nprediction intervals in experiments on synthetic and real-world datasets. To\nthe best of our knowledge, we are the first to propose conformal prediction for\ncontinuous treatments when the propensity score is unknown and must be\nestimated from data.\n","authors":["Maresa Schröder","Dennis Frauen","Jonas Schweisthal","Konstantin Heß","Valentyn Melnychuk","Stefan Feuerriegel"],"pdf_url":"https://arxiv.org/pdf/2407.03094v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.05354v3","updated":"2024-10-23T09:51:11Z","published":"2024-10-07T13:44:49Z","title":"Over-the-Air Federated Learning in Cell-Free MIMO with Long-term Power\n  Constraint","summary":"  Wireless networks supporting artificial intelligence have gained significant\nattention, with Over-the-Air Federated Learning emerging as a key application\ndue to its unique transmission and distributed computing characteristics. This\npaper derives error bounds for Over-the-Air Federated Learning in a Cell-free\nMIMO system and formulates an optimization problem to minimize optimality gap\nvia joint optimization of power control and beamforming. We introduce the\nMOP-LOFPC algorithm, which employs Lyapunov optimization to decouple long-term\nconstraints across rounds while requiring only causal channel state\ninformation. Experimental results demonstrate that MOP-LOFPC achieves a better\nand more flexible trade-off between the model's training loss and adherence to\nlong-term power constraints compared to existing baselines.\n","authors":["Yifan Wang","Cheng Zhang","Yuanndon Zhuang","Mingzeng Dai","Haiming Wang","Yongming Huang"],"pdf_url":"https://arxiv.org/pdf/2410.05354v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.11642v2","updated":"2024-10-23T09:43:03Z","published":"2024-10-15T14:31:54Z","title":"Improve Value Estimation of Q Function and Reshape Reward with Monte\n  Carlo Tree Search","summary":"  Reinforcement learning has achieved remarkable success in perfect information\ngames such as Go and Atari, enabling agents to compete at the highest levels\nagainst human players. However, research in reinforcement learning for\nimperfect information games has been relatively limited due to the more complex\ngame structures and randomness. Traditional methods face challenges in training\nand improving performance in imperfect information games due to issues like\ninaccurate Q value estimation and reward sparsity. In this paper, we focus on\nUno, an imperfect information game, and aim to address these problems by\nreducing Q value overestimation and reshaping reward function. We propose a\nnovel algorithm that utilizes Monte Carlo Tree Search to average the value\nestimations in Q function. Even though we choose Double Deep Q Learning as the\nfoundational framework in this paper, our method can be generalized and used in\nany algorithm which needs Q value estimation, such as the Actor-Critic.\nAdditionally, we employ Monte Carlo Tree Search to reshape the reward structure\nin the game environment. We compare our algorithm with several traditional\nmethods applied to games such as Double Deep Q Learning, Deep Monte Carlo and\nNeural Fictitious Self Play, and the experiments demonstrate that our algorithm\nconsistently outperforms these approaches, especially as the number of players\nin Uno increases, indicating a higher level of difficulty.\n","authors":["Jiamian Li"],"pdf_url":"https://arxiv.org/pdf/2410.11642v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.17715v1","updated":"2024-10-23T09:42:17Z","published":"2024-10-23T09:42:17Z","title":"Continual Learning on a Data Diet","summary":"  Continual Learning (CL) methods usually learn from all available data.\nHowever, this is not the case in human cognition which efficiently focuses on\nkey experiences while disregarding the redundant information. Similarly, not\nall data points in a dataset have equal potential; some can be more informative\nthan others. This disparity may significantly impact the performance, as both\nthe quality and quantity of samples directly influence the model's\ngeneralizability and efficiency. Drawing inspiration from this, we explore the\npotential of learning from important samples and present an empirical study for\nevaluating coreset selection techniques in the context of CL to stimulate\nresearch in this unexplored area. We train different continual learners on\nincreasing amounts of selected samples and investigate the learning-forgetting\ndynamics by shedding light on the underlying mechanisms driving their improved\nstability-plasticity balance. We present several significant observations:\nlearning from selectively chosen samples (i) enhances incremental accuracy,\n(ii) improves knowledge retention of previous tasks, and (iii) refines learned\nrepresentations. This analysis contributes to a deeper understanding of\nselective learning strategies in CL scenarios.\n","authors":["Elif Ceren Gok Yildirim","Murat Onur Yildirim","Joaquin Vanschoren"],"pdf_url":"https://arxiv.org/pdf/2410.17715v1.pdf","comment":"18 pages, 6 figures"},{"id":"http://arxiv.org/abs/2311.08745v5","updated":"2024-10-23T09:40:44Z","published":"2023-11-15T07:27:40Z","title":"Using Stochastic Gradient Descent to Smooth Nonconvex Functions:\n  Analysis of Implicit Graduated Optimization","summary":"  The graduated optimization approach is a heuristic method for finding global\noptimal solutions for nonconvex functions by using a function smoothing\noperation with stochastic noise. We show that stochastic noise in stochastic\ngradient descent (SGD) has the effect of smoothing the objective function, the\ndegree of which is determined by the learning rate, batch size, and variance of\nthe stochastic gradient. Using this finding, we propose and analyze a new\ngraduated optimization algorithm that varies the degree of smoothing by varying\nthe learning rate and batch size, and provide experimental results on image\nclassification tasks with ResNets that support our theoretical findings. We\nfurther show that there is an interesting correlation between the degree of\nsmoothing by SGD's stochastic noise, the well-studied ``sharpness'' indicator,\nand the generalization performance of the model.\n","authors":["Naoki Sato","Hideaki Iiduka"],"pdf_url":"https://arxiv.org/pdf/2311.08745v5.pdf","comment":"The latest version was updated in October 2024. Under review"},{"id":"http://arxiv.org/abs/2410.17711v1","updated":"2024-10-23T09:36:21Z","published":"2024-10-23T09:36:21Z","title":"Beware of Calibration Data for Pruning Large Language Models","summary":"  As large language models (LLMs) are widely applied across various fields,\nmodel compression has become increasingly crucial for reducing costs and\nimproving inference efficiency. Post-training pruning is a promising method\nthat does not require resource-intensive iterative training and only needs a\nsmall amount of calibration data to assess the importance of parameters.\nPrevious research has primarily focused on designing advanced pruning methods,\nwhile different calibration data's impact on pruning performance still lacks\nsystematical exploration. We fill this blank and surprisingly observe that the\neffects of calibration data even value more than designing advanced pruning\nstrategies, especially for high sparsity. Our preliminary exploration also\ndiscloses that using calibration data similar to the training data can yield\nbetter performance. As pre-training data is usually inaccessible for advanced\nLLMs, we further provide a self-generating calibration data synthesis strategy\nto construct feasible calibration data. We conduct experiments on the recent\nstrong open-source LLMs (e.g., DCLM, and LLaMA-3), and the results show that\nthe proposed method outperforms commonly used calibration data and can\neffectively enhance strong pruning methods (e.g., Wanda, OWL).\n","authors":["Yixin Ji","Yang Xiang","Juntao Li","Qingrong Xia","Ping Li","Xinyu Duan","Zhefeng Wang","Min Zhang"],"pdf_url":"https://arxiv.org/pdf/2410.17711v1.pdf","comment":"under review"},{"id":"http://arxiv.org/abs/2402.09891v2","updated":"2024-10-23T09:29:39Z","published":"2024-02-15T11:34:38Z","title":"Do causal predictors generalize better to new domains?","summary":"  We study how well machine learning models trained on causal features\ngeneralize across domains. We consider 16 prediction tasks on tabular datasets\ncovering applications in health, employment, education, social benefits, and\npolitics. Each dataset comes with multiple domains, allowing us to test how\nwell a model trained in one domain performs in another. For each prediction\ntask, we select features that have a causal influence on the target of\nprediction. Our goal is to test the hypothesis that models trained on causal\nfeatures generalize better across domains. Without exception, we find that\npredictors using all available features, regardless of causality, have better\nin-domain and out-of-domain accuracy than predictors using causal features.\nMoreover, even the absolute drop in accuracy from one domain to the other is no\nbetter for causal predictors than for models that use all features. In\naddition, we show that recent causal machine learning methods for domain\ngeneralization do not perform better in our evaluation than standard predictors\ntrained on the set of causal features. Likewise, causal discovery algorithms\neither fail to run or select causal variables that perform no better than our\nselection. Extensive robustness checks confirm that our findings are stable\nunder variable misclassification.\n","authors":["Vivian Y. Nastl","Moritz Hardt"],"pdf_url":"https://arxiv.org/pdf/2402.09891v2.pdf","comment":"118 pages, 55 figures, accepted at NeurIPS'24"},{"id":"http://arxiv.org/abs/2408.14762v4","updated":"2024-10-23T09:25:58Z","published":"2024-08-27T03:30:01Z","title":"Explainable Hierarchical Urban Representation Learning for Commuting\n  Flow Prediction","summary":"  Commuting flow prediction is an essential task for municipal operations in\nthe real world. Previous studies have revealed that it is feasible to estimate\nthe commuting origin-destination (OD) demand within a city using multiple\nauxiliary data. However, most existing methods are not suitable to deal with a\nsimilar task at a large scale, namely within a prefecture or the whole nation,\nowing to the increased number of geographical units that need to be maintained.\nIn addition, region representation learning is a universal approach for gaining\nurban knowledge for diverse metropolitan downstream tasks. Although many\nresearchers have developed comprehensive frameworks to describe urban units\nfrom multi-source data, they have not clarified the relationship between the\nselected geographical elements. Furthermore, metropolitan areas naturally\npreserve ranked structures, like cities and their inclusive districts, which\nmakes elucidating relations between cross-level urban units necessary.\nTherefore, we develop a heterogeneous graph-based model to generate meaningful\nregion embeddings at multiple spatial resolutions for predicting different\ntypes of inter-level OD flows. To demonstrate the effectiveness of the proposed\nmethod, extensive experiments were conducted using real-world aggregated mobile\nphone datasets collected from Shizuoka Prefecture, Japan. The results indicate\nthat our proposed model outperforms existing models in terms of a uniform urban\nstructure. We extend the understanding of predicted results using reasonable\nexplanations to enhance the credibility of the model.\n","authors":["Mingfei Cai","Yanbo Pang","Yoshihide Sekimoto"],"pdf_url":"https://arxiv.org/pdf/2408.14762v4.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.17700v1","updated":"2024-10-23T09:22:43Z","published":"2024-10-23T09:22:43Z","title":"Scalable Random Feature Latent Variable Models","summary":"  Random feature latent variable models (RFLVMs) represent the state-of-the-art\nin latent variable models, capable of handling non-Gaussian likelihoods and\neffectively uncovering patterns in high-dimensional data. However, their heavy\nreliance on Monte Carlo sampling results in scalability issues which makes it\ndifficult to use these models for datasets with a massive number of\nobservations. To scale up RFLVMs, we turn to the optimization-based variational\nBayesian inference (VBI) algorithm which is known for its scalability compared\nto sampling-based methods. However, implementing VBI for RFLVMs poses\nchallenges, such as the lack of explicit probability distribution functions\n(PDFs) for the Dirichlet process (DP) in the kernel learning component, and the\nincompatibility of existing VBI algorithms with RFLVMs. To address these\nissues, we introduce a stick-breaking construction for DP to obtain an explicit\nPDF and a novel VBI algorithm called ``block coordinate descent variational\ninference\" (BCD-VI). This enables the development of a scalable version of\nRFLVMs, or in short, SRFLVM. Our proposed method shows scalability,\ncomputational efficiency, superior performance in generating informative latent\nrepresentations and the ability of imputing missing data across various\nreal-world datasets, outperforming state-of-the-art competitors.\n","authors":["Ying Li","Zhidi Lin","Yuhao Liu","Michael Minyi Zhang","Pablo M. Olmos","Petar M. Djurić"],"pdf_url":"https://arxiv.org/pdf/2410.17700v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.17696v1","updated":"2024-10-23T09:16:22Z","published":"2024-10-23T09:16:22Z","title":"Optimizing Load Scheduling in Power Grids Using Reinforcement Learning\n  and Markov Decision Processes","summary":"  Power grid load scheduling is a critical task that ensures the balance\nbetween electricity generation and consumption while minimizing operational\ncosts and maintaining grid stability. Traditional optimization methods often\nstruggle with the dynamic and stochastic nature of power systems, especially\nwhen faced with renewable energy sources and fluctuating demand. This paper\nproposes a reinforcement learning (RL) approach using a Markov Decision Process\n(MDP) framework to address the challenges of dynamic load scheduling. The MDP\nis defined by a state space representing grid conditions, an action space\ncovering control operations like generator adjustments and storage management,\nand a reward function balancing economic efficiency and system reliability. We\ninvestigate the application of various RL algorithms, from basic Q-Learning to\nmore advanced Deep Q-Networks (DQN) and Actor-Critic methods, to determine\noptimal scheduling policies. The proposed approach is evaluated through a\nsimulated power grid environment, demonstrating its potential to improve\nscheduling efficiency and adapt to variable demand patterns. Our results show\nthat the RL-based method provides a robust and scalable solution for real-time\nload scheduling, contributing to the efficient management of modern power\ngrids.\n","authors":["Dongwen Luo"],"pdf_url":"https://arxiv.org/pdf/2410.17696v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2308.03648v2","updated":"2024-10-23T09:11:00Z","published":"2023-08-07T14:58:53Z","title":"Generative Forests","summary":"  We focus on generative AI for a type of data that still represent one of the\nmost prevalent form of data: tabular data. Our paper introduces two key\ncontributions: a new powerful class of forest-based models fit for such tasks\nand a simple training algorithm with strong convergence guarantees in a\nboosting model that parallels that of the original weak / strong supervised\nlearning setting. This algorithm can be implemented by a few tweaks to the most\npopular induction scheme for decision tree induction (i.e. supervised learning)\nwith two classes. Experiments on the quality of generated data display\nsubstantial improvements compared to the state of the art. The losses our\nalgorithm minimize and the structure of our models make them practical for\nrelated tasks that require fast estimation of a density given a generative\nmodel and an observation (even partially specified): such tasks include missing\ndata imputation and density estimation. Additional experiments on these tasks\nreveal that our models can be notably good contenders to diverse state of the\nart methods, relying on models as diverse as (or mixing elements of) trees,\nneural nets, kernels or graphical models.\n","authors":["Richard Nock","Mathieu Guillame-Bert"],"pdf_url":"https://arxiv.org/pdf/2308.03648v2.pdf","comment":"NeurIPS'24"},{"id":"http://arxiv.org/abs/2402.04892v2","updated":"2024-10-23T09:04:57Z","published":"2024-02-07T14:24:04Z","title":"Probabilistic ML Verification via Weighted Model Integration","summary":"  In machine learning (ML) verification, the majority of procedures are\nnon-quantitative and therefore cannot be used for verifying probabilistic\nmodels, or be applied in domains where hard guarantees are practically\nunachievable. The probabilistic formal verification (PFV) of ML models is in\nits infancy, with the existing approaches limited to specific ML models,\nproperties, or both. This contrasts with standard formal methods techniques,\nwhose successful adoption in real-world scenarios is also due to their support\nfor a wide range of properties and diverse systems. We propose a unifying\nframework for the PFV of ML systems based on Weighted Model Integration (WMI),\na relatively recent formalism for probabilistic inference with algebraic and\nlogical constraints. Crucially, reducing the PFV of ML models to WMI enables\nthe verification of many properties of interest over a wide range of systems,\naddressing multiple limitations of deterministic verification and ad-hoc\nalgorithms. We substantiate the generality of the approach on prototypical\ntasks involving the verification of group fairness, monotonicity, robustness to\nnoise, probabilistic local robustness and equivalence among predictors. We\ncharacterize the challenges related to the scalability of the approach and,\nthrough our WMI-based perspective, we show how successful scaling techniques in\nthe ML verification literature can be generalized beyond their original scope.\n","authors":["Paolo Morettin","Andrea Passerini","Roberto Sebastiani"],"pdf_url":"https://arxiv.org/pdf/2402.04892v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2402.10192v3","updated":"2024-10-23T08:39:00Z","published":"2024-02-15T18:48:32Z","title":"Multi-Excitation Projective Simulation with a Many-Body Physics Inspired\n  Inductive Bias","summary":"  With the impressive progress of deep learning, applications relying on\nmachine learning are increasingly being integrated into daily life. However,\nmost deep learning models have an opaque, oracle-like nature making it\ndifficult to interpret and understand their decisions. This problem led to the\ndevelopment of the field known as eXplainable Artificial Intelligence (XAI).\nOne method in this field known as Projective Simulation (PS) models a\nchain-of-thought as a random walk of a particle on a graph with vertices that\nhave concepts attached to them. While this description has various benefits,\nincluding the possibility of quantization, it cannot be naturally used to model\nthoughts that combine several concepts simultaneously. To overcome this\nlimitation, we introduce Multi-Excitation Projective Simulation (mePS), a\ngeneralization that considers a chain-of-thought to be a random walk of several\nparticles on a hypergraph. A definition for a dynamic hypergraph is put forward\nto describe the agent's training history along with applications to AI and\nhypergraph visualization. An inductive bias inspired by the remarkably\nsuccessful few-body interaction models used in quantum many-body physics is\nformalized for our classical mePS framework and employed to tackle the\nexponential complexity associated with naive implementations of hypergraphs. We\nprove that our inductive bias reduces the complexity from exponential to\npolynomial, with the exponent representing the cutoff on how many particles can\ninteract. We numerically apply our method to two toy environments and a more\ncomplex scenario modelling the diagnosis of a broken computer. These\nenvironments demonstrate the resource savings provided by an appropriate choice\nof inductive bias, as well as showcasing aspects of interpretability. A quantum\nmodel for mePS is also briefly outlined and some future directions for it are\ndiscussed.\n","authors":["Philip A. LeMaitre","Marius Krumm","Hans J. Briegel"],"pdf_url":"https://arxiv.org/pdf/2402.10192v3.pdf","comment":"26 pages, 8 figures; Code repository at\n  https://github.com/MariusKrumm/ManyBodyMEPS. Reorganized main text for better\n  readability"},{"id":"http://arxiv.org/abs/2404.15993v4","updated":"2024-10-23T08:33:54Z","published":"2024-04-24T17:10:35Z","title":"Uncertainty Estimation and Quantification for LLMs: A Simple Supervised\n  Approach","summary":"  In this paper, we study the problem of uncertainty estimation and calibration\nfor LLMs. We begin by formulating the uncertainty estimation problem, a\nrelevant yet underexplored area in existing literature. We then propose a\nsupervised approach that leverages labeled datasets to estimate the uncertainty\nin LLMs' responses. Based on the formulation, we illustrate the difference\nbetween the uncertainty estimation for LLMs and that for standard ML models and\nexplain why the hidden neurons of the LLMs may contain uncertainty information.\nOur designed approach demonstrates the benefits of utilizing hidden activations\nto enhance uncertainty estimation across various tasks and shows robust\ntransferability in out-of-distribution settings. We distinguish the uncertainty\nestimation task from the uncertainty calibration task and show that better\nuncertainty estimation leads to better calibration performance. Furthermore,\nour method is easy to implement and adaptable to different levels of model\naccessibility including black box, grey box, and white box.\n","authors":["Linyu Liu","Yu Pan","Xiaocheng Li","Guanting Chen"],"pdf_url":"https://arxiv.org/pdf/2404.15993v4.pdf","comment":"29 pages, 14 figures"},{"id":"http://arxiv.org/abs/2405.11752v2","updated":"2024-10-23T08:29:20Z","published":"2024-05-20T03:26:58Z","title":"Towards Foundation Model for Chemical Reactor Modeling: Meta-Learning\n  with Physics-Informed Adaptation","summary":"  In this work, we present a novel application of foundation models for\nchemical reactor modeling. Accurate modeling of real-world chemical reactors\nthrough first-principles is often challenging, and the process of rebuilding\nand retraining models for each new chemical process is inefficient. This raises\na critical question: can we develop a single, universal neural network (i.e., a\nfoundation model) that can rapidly adapt to any new chemical process in a\nreactor? To address this, we propose a foundation model for chemical reactor\nmodeling that employs a meta-learning approach, followed by physics-informed\nfine-tuning on new tasks with only a few data samples. Our model is designed to\ngeneralize across three classic reactor types: continuous stirred tank\nreactors, batch reactors, and plug flow reactors. Compared to conventional\nmethods such as data-driven learning, physics-informed learning, transfer\nlearning, and meta-learning, our approach demonstrates superior performance in\nfew-shot scenarios. Specifically, it shows rapid adaptation to unseen reactions\nwith varying integer orders across different reactor set-ups, requiring minimal\ndata for fine-tuning. Source code is available at\nhttps://github.com/killingbear999/chemical-reactor-foundation-model.\n","authors":["Zihao Wang","Zhe Wu"],"pdf_url":"https://arxiv.org/pdf/2405.11752v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.17661v1","updated":"2024-10-23T08:24:47Z","published":"2024-10-23T08:24:47Z","title":"PETAH: Parameter Efficient Task Adaptation for Hybrid Transformers in a\n  resource-limited Context","summary":"  Following their success in natural language processing (NLP), there has been\na shift towards transformer models in computer vision. While transformers\nperform well and offer promising multi-tasking performance, due to their high\ncompute requirements, many resource-constrained applications still rely on\nconvolutional or hybrid models that combine the benefits of convolution and\nattention layers and achieve the best results in the sub 100M parameter range.\nSimultaneously, task adaptation techniques that allow for the use of one shared\ntransformer backbone for multiple downstream tasks, resulting in great storage\nsavings at negligible cost in performance, have not yet been adopted for hybrid\ntransformers. In this work, we investigate how to achieve the best\ntask-adaptation performance and introduce PETAH: Parameter Efficient Task\nAdaptation for Hybrid Transformers. We further combine PETAH adaptation with\npruning to achieve highly performant and storage friendly models for\nmulti-tasking. In our extensive evaluation on classification and other vision\ntasks, we demonstrate that our PETAH-adapted hybrid models outperform\nestablished task-adaptation techniques for ViTs while requiring fewer\nparameters and being more efficient on mobile hardware.\n","authors":["Maximilian Augustin","Syed Shakib Sarwar","Mostafa Elhoushi","Sai Qian Zhang","Yuecheng Li","Barbara De Salvo"],"pdf_url":"https://arxiv.org/pdf/2410.17661v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.17655v1","updated":"2024-10-23T08:18:26Z","published":"2024-10-23T08:18:26Z","title":"Mapping the Media Landscape: Predicting Factual Reporting and Political\n  Bias Through Web Interactions","summary":"  Bias assessment of news sources is paramount for professionals,\norganizations, and researchers who rely on truthful evidence for information\ngathering and reporting. While certain bias indicators are discernible from\ncontent analysis, descriptors like political bias and fake news pose greater\nchallenges. In this paper, we propose an extension to a recently presented news\nmedia reliability estimation method that focuses on modeling outlets and their\nlongitudinal web interactions. Concretely, we assess the classification\nperformance of four reinforcement learning strategies on a large news media\nhyperlink graph. Our experiments, targeting two challenging bias descriptors,\nfactual reporting and political bias, showed a significant performance\nimprovement at the source media level. Additionally, we validate our methods on\nthe CLEF 2023 CheckThat! Lab challenge, outperforming the reported results in\nboth, F1-score and the official MAE metric. Furthermore, we contribute by\nreleasing the largest annotated dataset of news source media, categorized with\nfactual reporting and political bias labels. Our findings suggest that\nprofiling news media sources based on their hyperlink interactions over time is\nfeasible, offering a bird's-eye view of evolving media landscapes.\n","authors":["Dairazalia Sánchez-Cortés","Sergio Burdisso","Esaú Villatoro-Tello","Petr Motlicek"],"pdf_url":"https://arxiv.org/pdf/2410.17655v1.pdf","comment":"Accepted to CLEF 2024"},{"id":"http://arxiv.org/abs/2407.13432v3","updated":"2024-10-23T08:07:05Z","published":"2024-07-18T12:01:09Z","title":"The Art of Imitation: Learning Long-Horizon Manipulation Tasks from Few\n  Demonstrations","summary":"  Task Parametrized Gaussian Mixture Models (TP-GMM) are a sample-efficient\nmethod for learning object-centric robot manipulation tasks. However, there are\nseveral open challenges to applying TP-GMMs in the wild. In this work, we\ntackle three crucial challenges synergistically. First, end-effector velocities\nare non-Euclidean and thus hard to model using standard GMMs. We thus propose\nto factorize the robot's end-effector velocity into its direction and\nmagnitude, and model them using Riemannian GMMs. Second, we leverage the\nfactorized velocities to segment and sequence skills from complex demonstration\ntrajectories. Through the segmentation, we further align skill trajectories and\nhence leverage time as a powerful inductive bias. Third, we present a method to\nautomatically detect relevant task parameters per skill from visual\nobservations. Our approach enables learning complex manipulation tasks from\njust five demonstrations while using only RGB-D observations. Extensive\nexperimental evaluations on RLBench demonstrate that our approach achieves\nstate-of-the-art performance with 20-fold improved sample efficiency. Our\npolicies generalize across different environments, object instances, and object\npositions, while the learned skills are reusable.\n","authors":["Jan Ole von Hartz","Tim Welschehold","Abhinav Valada","Joschka Boedecker"],"pdf_url":"https://arxiv.org/pdf/2407.13432v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.17648v1","updated":"2024-10-23T08:07:00Z","published":"2024-10-23T08:07:00Z","title":"Towards Active Participant-Centric Vertical Federated Learning: Some\n  Representations May Be All You Need","summary":"  Vertical Federated Learning (VFL) enables collaborative model training across\ndifferent participants with distinct features and common samples, while\npreserving data privacy. Existing VFL methodologies often struggle with\nrealistic data partitions, typically incurring high communication costs and\nsignificant operational complexity. In this work, we introduce a novel\nsimplified approach to VFL, Active Participant-Centric VFL (APC-VFL), that, to\nthe best of our knowledge, is the first to require only a single communication\nround between participants, and allows the active participant to do inference\nin a non collaborative fashion. This method integrates unsupervised\nrepresentation learning with knowledge distillation to achieve comparable\naccuracy to traditional VFL methods based on vertical split learning in\nclassical settings, reducing required communication rounds by up to\n$4200\\times$, while being more flexible. Our approach also shows improvements\ncompared to non-federated local models, as well as a comparable VFL proposal,\nVFedTrans, offering an efficient and flexible solution for collaborative\nlearning.\n","authors":["Jon Irureta","Jon Imaz","Aizea Lojo","Marco González","Iñigo Perona"],"pdf_url":"https://arxiv.org/pdf/2410.17648v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2401.15294v3","updated":"2024-10-23T08:06:25Z","published":"2024-01-27T04:42:50Z","title":"Integral Operator Approaches for Scattered Data Fitting on Spheres","summary":"  This paper focuses on scattered data fitting problems on spheres. We study\nthe approximation performance of a class of weighted spectral filter\nalgorithms, including Tikhonov regularization, Landaweber iteration, spectral\ncut-off, and iterated Tikhonov, in fitting noisy data with possibly unbounded\nrandom noise. For the analysis, we develop an integral operator approach that\ncan be regarded as an extension of the widely used sampling inequality approach\nand norming set method in the community of scattered data fitting. After\nproviding an equivalence between the operator differences and quadrature rules,\nwe succeed in deriving optimal Sobolev-type error estimates of weighted\nspectral filter algorithms. Our derived error estimates do not suffer from the\nsaturation phenomenon for Tikhonov regularization in the literature,\nnative-space-barrier for existing error analysis and adapts to different\nembedding spaces. We also propose a divide-and-conquer scheme to equip weighted\nspectral filter algorithms to reduce their computational burden and present the\noptimal approximation error bounds.\n","authors":["Shao-Bo Lin"],"pdf_url":"https://arxiv.org/pdf/2401.15294v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.09079v2","updated":"2024-10-23T08:05:57Z","published":"2024-06-13T13:03:37Z","title":"Hadamard Representations: Augmenting Hyperbolic Tangents in RL","summary":"  Activation functions are one of the key components of a deep neural network.\nThe most commonly used activation functions can be classed into the category of\ncontinuously differentiable (e.g. tanh) and linear-unit functions (e.g. ReLU),\nboth having their own strengths and drawbacks with respect to downstream\nperformance and representation capacity through learning (e.g. measured by the\nnumber of dead neurons and the effective rank). In reinforcement learning, the\nperformance of continuously differentiable activations often falls short as\ncompared to linear-unit functions. We provide insights into the vanishing\ngradients associated with the former, and show that the dying neuron problem is\nnot exclusive to ReLU's. To alleviate vanishing gradients and the resulting\ndying neuron problem occurring with continuously differentiable activations, we\npropose a Hadamard representation. Using deep Q-networks and proximal policy\noptimization in the Atari domain, we show faster learning, a reduction in dead\nneurons and increased effective rank.\n","authors":["Jacob E. Kooi","Mark Hoogendoorn","Vincent François-Lavet"],"pdf_url":"https://arxiv.org/pdf/2406.09079v2.pdf","comment":"24 pages, 19 figures, 3 tables"},{"id":"http://arxiv.org/abs/2410.17647v1","updated":"2024-10-23T08:04:12Z","published":"2024-10-23T08:04:12Z","title":"Entity-based Reinforcement Learning for Autonomous Cyber Defence","summary":"  A significant challenge for autonomous cyber defence is ensuring a defensive\nagent's ability to generalise across diverse network topologies and\nconfigurations.\n  This capability is necessary for agents to remain effective when deployed in\ndynamically changing environments, such as an enterprise network where devices\nmay frequently join and leave.\n  Standard approaches to deep reinforcement learning, where policies are\nparameterised using a fixed-input multi-layer perceptron (MLP) expect\nfixed-size observation and action spaces. In autonomous cyber defence, this\nmakes it hard to develop agents that generalise to environments with network\ntopologies different from those trained on, as the number of nodes affects the\nnatural size of the observation and action spaces. To overcome this limitation,\nwe reframe the problem of autonomous network defence using entity-based\nreinforcement learning, where the observation and action space of an agent are\ndecomposed into a collection of discrete entities. This framework enables the\nuse of policy parameterisations specialised in compositional generalisation.\nNamely, we train a Transformer-based policy on the Yawning Titan cyber-security\nsimulation environment and test its generalisation capabilities across various\nnetwork topologies. We demonstrate that this approach significantly outperforms\nan MLP-based policy on fixed networks, and has the ability for zero-shot\ngeneralisation to networks of a different size to those seen in training.\n  These findings highlight the potential for entity-based reinforcement\nlearning to advance the field of autonomous cyber defence by providing more\ngeneralisable policies capable of handling variations in real-world network\nenvironments.\n","authors":["Isaac Symes Thompson","Alberto Caron","Chris Hicks","Vasilios Mavroudis"],"pdf_url":"https://arxiv.org/pdf/2410.17647v1.pdf","comment":"Material to appear in the proceedings of the 1st International\n  Workshop on Autonomous Cybersecurity at ACM CCS 2024"},{"id":"http://arxiv.org/abs/2405.04098v2","updated":"2024-10-23T07:57:41Z","published":"2024-05-07T08:05:20Z","title":"Binarized Simplicial Convolutional Neural Networks","summary":"  Graph Neural Networks have a limitation of solely processing features on\ngraph nodes, neglecting data on high-dimensional structures such as edges and\ntriangles. Simplicial Convolutional Neural Networks (SCNN) represent\nhigher-order structures using simplicial complexes to break this limitation\nalbeit still lacking time efficiency. In this paper, we propose a novel neural\nnetwork architecture on simplicial complexes named Binarized Simplicial\nConvolutional Neural Networks (Bi-SCNN) based on the combination of simplicial\nconvolution with a binary-sign forward propagation strategy. The usage of the\nHodge Laplacian on a binary-sign forward propagation enables Bi-SCNN to\nefficiently and effectively represent simplicial features that have\nhigher-order structures than traditional graph node representations. Compared\nto the previous Simplicial Convolutional Neural Networks, the reduced model\ncomplexity of Bi-SCNN shortens the execution time without sacrificing the\nprediction performance and is less prone to the over-smoothing effect.\nExperimenting with real-world citation and ocean-drifter data confirmed that\nour proposed Bi-SCNN is efficient and accurate.\n","authors":["Yi Yan","Ercan E. Kuruoglu"],"pdf_url":"https://arxiv.org/pdf/2405.04098v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.17631v1","updated":"2024-10-23T07:48:35Z","published":"2024-10-23T07:48:35Z","title":"Exploring structure diversity in atomic resolution microscopy with graph\n  neural networks","summary":"  The emergence of deep learning (DL) has provided great opportunities for the\nhigh-throughput analysis of atomic-resolution micrographs. However, the DL\nmodels trained by image patches in fixed size generally lack efficiency and\nflexibility when processing micrographs containing diversified atomic\nconfigurations. Herein, inspired by the similarity between the atomic\nstructures and graphs, we describe a few-shot learning framework based on an\nequivariant graph neural network (EGNN) to analyze a library of atomic\nstructures (e.g., vacancies, phases, grain boundaries, doping, etc.), showing\nsignificantly promoted robustness and three orders of magnitude reduced\ncomputing parameters compared to the image-driven DL models, which is\nespecially evident for those aggregated vacancy lines with flexible lattice\ndistortion. Besides, the intuitiveness of graphs enables quantitative and\nstraightforward extraction of the atomic-scale structural features in batches,\nthus statistically unveiling the self-assembly dynamics of vacancy lines under\nelectron beam irradiation. A versatile model toolkit is established by\nintegrating EGNN sub-models for single structure recognition to process images\ninvolving varied configurations in the form of a task chain, leading to the\ndiscovery of novel doping configurations with superior electrocatalytic\nproperties for hydrogen evolution reactions. This work provides a powerful tool\nto explore structure diversity in a fast, accurate, and intelligent manner.\n","authors":["Zheng Luo","Ming Feng","Zijian Gao","Jinyang Yu","Liang Hu","Tao Wang","Shenao Xue","Shen Zhou","Fangping Ouyang","Dawei Feng","Kele Xu","Shanshan Wang"],"pdf_url":"https://arxiv.org/pdf/2410.17631v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.17628v1","updated":"2024-10-23T07:44:14Z","published":"2024-10-23T07:44:14Z","title":"Feature Learning in Attention Mechanisms Is More Compact and Stable Than\n  in Convolution","summary":"  Attention and convolution are fundamental techniques in machine learning.\nWhile they use different approaches to learn features - attention mechanisms\ncapture both global and local data relathionships, while convolutional layers\nfocus on local patterns - both methods are effective for various tasks.\nAlthough the feature learning of both models is well-studied individually,\nthere has not been a direct comparison of their feature learning dynamics. In\nthis paper, we compare their Lipschitz continuity with respect to the\nWasserstein distance and covering numbers under similar settings. We\ndemonstrate that attention processes data in a more compact and stable manner.\nCompactness refers to the lower variance and intrinsic dimensionality of the\nactivation outputs, while stability refers to the changes between inputs and\noutputs. We validate our findings through experiments using topological data\nanalysis, measuring the 1-, 2-, and infinity-Wasserstein distances between the\noutputs of each layer from both models. Furthermore, we extend our comparison\nto Vision Transformers (ViTs) and ResNets, showing that while ViTs have higher\noutput variance, their feature learning is more stable than that of ResNets.\n","authors":["Baiyuan Chen"],"pdf_url":"https://arxiv.org/pdf/2410.17628v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.17624v1","updated":"2024-10-23T07:29:30Z","published":"2024-10-23T07:29:30Z","title":"Incremental Learning of Affordances using Markov Logic Networks","summary":"  Affordances enable robots to have a semantic understanding of their\nsurroundings. This allows them to have more acting flexibility when completing\na given task. Capturing object affordances in a machine learning model is a\ndifficult task, because of their dependence on contextual information. Markov\nLogic Networks (MLN) combine probabilistic reasoning with logic that is able to\ncapture such context. Mobile robots operate in partially known environments\nwherein unseen object affordances can be observed. This new information must be\nincorporated into the existing knowledge, without having to retrain the MLN\nfrom scratch. We introduce the MLN Cumulative Learning Algorithm (MLN-CLA).\nMLN-CLA learns new relations in various knowledge domains by retaining\nknowledge and only updating the changed knowledge, for which the MLN is\nretrained. We show that MLN-CLA is effective for accumulative learning and\nzero-shot affordance inference, outperforming strong baselines.\n","authors":["George Potter","Gertjan Burghouts","Joris Sijs"],"pdf_url":"https://arxiv.org/pdf/2410.17624v1.pdf","comment":"accepted at IEEE IRC 2024"},{"id":"http://arxiv.org/abs/2410.05623v2","updated":"2024-10-23T07:28:19Z","published":"2024-10-08T02:11:35Z","title":"Understanding Gradient Boosting Classifier: Training, Prediction, and\n  the Role of $γ_j$","summary":"  The Gradient Boosting Classifier (GBC) is a widely used machine learning\nalgorithm for binary classification, which builds decision trees iteratively to\nminimize prediction errors. This document explains the GBC's training and\nprediction processes, focusing on the computation of terminal node values\n$\\gamma_j$, which are crucial to optimizing the logistic loss function. We\nderive $\\gamma_j$ through a Taylor series approximation and provide a\nstep-by-step pseudocode for the algorithm's implementation. The guide explains\nthe theory of GBC and its practical application, demonstrating its\neffectiveness in binary classification tasks. We provide a step-by-step example\nin the appendix to help readers understand.\n","authors":["Hung-Hsuan Chen"],"pdf_url":"https://arxiv.org/pdf/2410.05623v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.05811v3","updated":"2024-10-23T07:26:07Z","published":"2024-03-09T06:19:53Z","title":"Statistical Efficiency of Distributional Temporal Difference Learning","summary":"  Distributional reinforcement learning (DRL) has achieved empirical success in\nvarious domains. One core task in the field of DRL is distributional policy\nevaluation, which involves estimating the return distribution $\\eta^\\pi$ for a\ngiven policy $\\pi$. The distributional temporal difference learning has been\naccordingly proposed, which is an extension of the temporal difference learning\n(TD) in the classic RL area. In the tabular case, \\citet{rowland2018analysis}\nand \\citet{rowland2023analysis} proved the asymptotic convergence of two\ninstances of distributional TD, namely categorical temporal difference learning\n(CTD) and quantile temporal difference learning (QTD), respectively. In this\npaper, we go a step further and analyze the finite-sample performance of\ndistributional TD. To facilitate theoretical analysis, we propose\nnon-parametric distributional TD learning (NTD). For a $\\gamma$-discounted\ninfinite-horizon tabular Markov decision process, we show that for NTD we need\n$\\tilde{O}\\left(\\frac{1}{\\varepsilon^{2p}(1-\\gamma)^{2p+1}}\\right)$ iterations\nto achieve an $\\varepsilon$-optimal estimator with high probability, when the\nestimation error is measured by the $p$-Wasserstein distance. This sample\ncomplexity bound is minimax optimal up to logarithmic factors in the case of\nthe $1$-Wasserstein distance. To achieve this, we establish a novel Freedman's\ninequality in Hilbert spaces, which would be of independent interest. In\naddition, we revisit CTD, showing that the same non-asymptotic convergence\nbounds hold for CTD in the case of the $p$-Wasserstein distance for $p\\geq 1$.\n","authors":["Yang Peng","Liangyu Zhang","Zhihua Zhang"],"pdf_url":"https://arxiv.org/pdf/2403.05811v3.pdf","comment":"NeurIPS 2024 (oral)"},{"id":"http://arxiv.org/abs/2410.17617v1","updated":"2024-10-23T07:14:37Z","published":"2024-10-23T07:14:37Z","title":"Self-Supervised Graph Neural Networks for Enhanced Feature Extraction in\n  Heterogeneous Information Networks","summary":"  This paper explores the applications and challenges of graph neural networks\n(GNNs) in processing complex graph data brought about by the rapid development\nof the Internet. Given the heterogeneity and redundancy problems that graph\ndata often have, traditional GNN methods may be overly dependent on the initial\nstructure and attribute information of the graph, which limits their ability to\naccurately simulate more complex relationships and patterns in the graph.\nTherefore, this study proposes a graph neural network model under a\nself-supervised learning framework, which can flexibly combine different types\nof additional information of the attribute graph and its nodes, so as to better\nmine the deep features in the graph data. By introducing a self-supervisory\nmechanism, it is expected to improve the adaptability of existing models to the\ndiversity and complexity of graph data and improve the overall performance of\nthe model.\n","authors":["Jianjun Wei","Yue Liu","Xin Huang","Xin Zhang","Wenyi Liu","Xu Yan"],"pdf_url":"https://arxiv.org/pdf/2410.17617v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.15899v2","updated":"2024-10-23T07:05:26Z","published":"2024-10-21T11:23:23Z","title":"On the Design and Performance of Machine Learning Based Error Correcting\n  Decoders","summary":"  This paper analyzes the design and competitiveness of four neural network\n(NN) architectures recently proposed as decoders for forward error correction\n(FEC) codes. We first consider the so-called single-label neural network (SLNN)\nand the multi-label neural network (MLNN) decoders which have been reported to\nachieve near maximum likelihood (ML) performance. Here, we show analytically\nthat SLNN and MLNN decoders can always achieve ML performance, regardless of\nthe code dimensions -- although at the cost of computational complexity -- and\nno training is in fact required. We then turn our attention to two\ntransformer-based decoders: the error correction code transformer (ECCT) and\nthe cross-attention message passing transformer (CrossMPT). We compare their\nperformance against traditional decoders, and show that ordered statistics\ndecoding outperforms these transformer-based decoders. The results in this\npaper cast serious doubts on the application of NN-based FEC decoders in the\nshort and medium block length regime.\n","authors":["Yuncheng Yuan","Péter Scheepers","Lydia Tasiou","Yunus Can Gültekin","Federico Corradi","Alex Alvarado"],"pdf_url":"https://arxiv.org/pdf/2410.15899v2.pdf","comment":"6 pages, 4 figures, submitted for possible presentation in a\n  conference (v2: Pre-FEC BER curves are corrected)"},{"id":"http://arxiv.org/abs/2311.00656v3","updated":"2024-10-23T06:53:57Z","published":"2023-11-01T17:02:41Z","title":"Adaptive Spatio-temporal Estimation on the Graph Edges via Line Graph\n  Transformation","summary":"  Spatio-temporal estimation of signals on graph edges is challenging because\nmost conventional Graph Signal Processing techniques are defined on the graph\nnodes. Leveraging the Line Graph transform, the Line Graph Least Mean Square\n(LGLMS) algorithm is proposed to conduct adaptive estimation of time-varying\nedge signals by projecting the edge signals from edge space to node space.\nLGLMS is an adaptive algorithm analogous to the classical LMS algorithm but\napplied to graph edges. Unlike edge-specific methods, LGLMS retains all GSP\nconcepts and techniques originally designed for graph nodes, without the need\nfor redefinition on the edges. Experimenting with transportation graphs and\nmeteorological graphs, with the signal observations having noisy and missing\nvalues, we confirmed that LGLMS is suitable for the online prediction of\ntime-varying edge signals.\n","authors":["Yi Yan","Ercan Engin Kuruoglu"],"pdf_url":"https://arxiv.org/pdf/2311.00656v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.14759v2","updated":"2024-10-23T06:51:05Z","published":"2024-10-18T09:53:20Z","title":"Universal approximation results for neural networks with non-polynomial\n  activation function over non-compact domains","summary":"  In this paper, we generalize the universal approximation property of\nsingle-hidden-layer feed-forward neural networks beyond the classical\nformulation over compact domains. More precisely, by assuming that the\nactivation function is non-polynomial, we derive universal approximation\nresults for neural networks within function spaces over non-compact subsets of\na Euclidean space, e.g., weighted spaces, $L^p$-spaces, and (weighted) Sobolev\nspaces over unbounded domains, where the latter includes the approximation of\nthe (weak) derivatives. Furthermore, we provide some dimension-independent\nrates for approximating a function with sufficiently regular and integrable\nFourier transform by neural networks with non-polynomial activation function.\n","authors":["Ariel Neufeld","Philipp Schmocker"],"pdf_url":"https://arxiv.org/pdf/2410.14759v2.pdf","comment":"arXiv admin note: text overlap with arXiv:2312.08410"},{"id":"http://arxiv.org/abs/2410.17592v1","updated":"2024-10-23T06:40:13Z","published":"2024-10-23T06:40:13Z","title":"A Kernel Perspective on Distillation-based Collaborative Learning","summary":"  Over the past decade, there is a growing interest in collaborative learning\nthat can enhance AI models of multiple parties. However, it is still\nchallenging to enhance performance them without sharing private data and models\nfrom individual parties. One recent promising approach is to develop\ndistillation-based algorithms that exploit unlabeled public data but the\nresults are still unsatisfactory in both theory and practice. To tackle this\nproblem, we rigorously analyze a representative distillation-based algorithm in\nthe view of kernel regression. This work provides the first theoretical results\nto prove the (nearly) minimax optimality of the nonparametric collaborative\nlearning algorithm that does not directly share local data or models in\nmassively distributed statistically heterogeneous environments. Inspired by our\ntheoretical results, we also propose a practical distillation-based\ncollaborative learning algorithm based on neural network architecture. Our\nalgorithm successfully bridges the gap between our theoretical assumptions and\npractical settings with neural networks through feature kernel matching. We\nsimulate various regression tasks to verify our theory and demonstrate the\npractical feasibility of our proposed algorithm.\n","authors":["Sejun Park","Kihun Hong","Ganguk Hwang"],"pdf_url":"https://arxiv.org/pdf/2410.17592v1.pdf","comment":"Accepted to NeurIPS 2024"},{"id":"http://arxiv.org/abs/2410.17589v1","updated":"2024-10-23T06:35:41Z","published":"2024-10-23T06:35:41Z","title":"Challenge on Sound Scene Synthesis: Evaluating Text-to-Audio Generation","summary":"  Despite significant advancements in neural text-to-audio generation,\nchallenges persist in controllability and evaluation. This paper addresses\nthese issues through the Sound Scene Synthesis challenge held as part of the\nDetection and Classification of Acoustic Scenes and Events 2024. We present an\nevaluation protocol combining objective metric, namely Fr\\'echet Audio\nDistance, with perceptual assessments, utilizing a structured prompt format to\nenable diverse captions and effective evaluation. Our analysis reveals varying\nperformance across sound categories and model architectures, with larger models\ngenerally excelling but innovative lightweight approaches also showing promise.\nThe strong correlation between objective metrics and human ratings validates\nour evaluation approach. We discuss outcomes in terms of audio quality,\ncontrollability, and architectural considerations for text-to-audio\nsynthesizers, providing direction for future research.\n","authors":["Junwon Lee","Modan Tailleur","Laurie M. Heller","Keunwoo Choi","Mathieu Lagrange","Brian McFee","Keisuke Imoto","Yuki Okamoto"],"pdf_url":"https://arxiv.org/pdf/2410.17589v1.pdf","comment":"accepted to NeurIPS 2024 Workshop: Audio Imagination"},{"id":"http://arxiv.org/abs/2410.17587v1","updated":"2024-10-23T06:30:20Z","published":"2024-10-23T06:30:20Z","title":"Predicting Company Growth by Econophysics informed Machine Learning","summary":"  Predicting company growth is crucial for strategic adjustment, operational\ndecision-making, risk assessment, and loan eligibility reviews. Traditional\nmodels for company growth often focus too much on theory, overlooking practical\nforecasting, or they rely solely on time series forecasting techniques,\nignoring interpretability and the inherent mechanisms of company growth. In\nthis paper, we propose a machine learning-based prediction framework that\nincorporates an econophysics model for company growth. Our model captures both\nthe intrinsic growth mechanisms of companies led by scaling laws and the\nfluctuations influenced by random factors and individual decisions,\ndemonstrating superior predictive performance compared with methods that use\ntime series techniques alone. Its advantages are more pronounced in long-range\nprediction tasks. By explicitly modeling the baseline growth and volatility\ncomponents, our model is more interpretable.\n","authors":["Ruyi Tao","Kaiwei Liu","Xu Jing","Jiang Zhang"],"pdf_url":"https://arxiv.org/pdf/2410.17587v1.pdf","comment":"18 pages, 12 figures"},{"id":"http://arxiv.org/abs/2402.12617v2","updated":"2024-10-23T06:28:19Z","published":"2024-02-20T00:51:05Z","title":"Generative AI Security: Challenges and Countermeasures","summary":"  Generative AI's expanding footprint across numerous industries has led to\nboth excitement and increased scrutiny. This paper delves into the unique\nsecurity challenges posed by Generative AI, and outlines potential research\ndirections for managing these risks.\n","authors":["Banghua Zhu","Norman Mu","Jiantao Jiao","David Wagner"],"pdf_url":"https://arxiv.org/pdf/2402.12617v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.15012v2","updated":"2024-10-23T06:27:26Z","published":"2024-03-22T07:56:31Z","title":"Empirical investigation of multi-source cross-validation in clinical ECG\n  classification","summary":"  Traditionally, machine learning-based clinical prediction models have been\ntrained and evaluated on patient data from a single source, such as a hospital.\nCross-validation methods can be used to estimate the accuracy of such models on\nnew patients originating from the same source, by repeated random splitting of\nthe data. However, such estimates tend to be highly overoptimistic when\ncompared to accuracy obtained from deploying models to sources not represented\nin the dataset, such as a new hospital. The increasing availability of\nmulti-source medical datasets provides new opportunities for obtaining more\ncomprehensive and realistic evaluations of expected accuracy through\nsource-level cross-validation designs.\n  In this study, we present a systematic empirical evaluation of standard\nK-fold cross-validation and leave-source-out cross-validation methods in a\nmulti-source setting. We consider the task of electrocardiogram based\ncardiovascular disease classification, combining and harmonizing the openly\navailable PhysioNet CinC Challenge 2021 and the Shandong Provincial Hospital\ndatasets for our study.\n  Our results show that K-fold cross-validation, both on single-source and\nmulti-source data, systemically overestimates prediction performance when the\nend goal is to generalize to new sources. Leave-source-out cross-validation\nprovides more reliable performance estimates, having close to zero bias though\nlarger variability. The evaluation highlights the dangers of obtaining\nmisleading cross-validation results on medical data and demonstrates how these\nissues can be mitigated when having access to multi-source data.\n","authors":["Tuija Leinonen","David Wong","Antti Vasankari","Ali Wahab","Ramesh Nadarajah","Matti Kaisti","Antti Airola"],"pdf_url":"https://arxiv.org/pdf/2403.15012v2.pdf","comment":"19 pages, 5 figures"},{"id":"http://arxiv.org/abs/2410.17579v1","updated":"2024-10-23T06:08:45Z","published":"2024-10-23T06:08:45Z","title":"Bonsai: Gradient-free Graph Distillation for Node Classification","summary":"  Graph distillation has emerged as a promising avenue to enable scalable\ntraining of GNNs by compressing the training dataset while preserving essential\ngraph characteristics. Our study uncovers significant shortcomings in current\ngraph distillation techniques. First, the majority of the algorithms\nparadoxically require training on the full dataset to perform distillation.\nSecond, due to their gradient-emulating approach, these methods require fresh\ndistillation for any change in hyperparameters or GNN architecture, limiting\ntheir flexibility and reusability. Finally, they fail to achieve substantial\nsize reduction due to synthesizing fully-connected, edge-weighted graphs. To\naddress these challenges, we present Bonsai, a novel graph distillation method\nempowered by the observation that \\textit{computation trees} form the\nfundamental processing units of message-passing GNNs. Bonsai distills datasets\nby encoding a careful selection of \\textit{exemplar} trees that maximize the\nrepresentation of all computation trees in the training set. This unique\napproach imparts Bonsai as the first linear-time, model-agnostic graph\ndistillation algorithm for node classification that outperforms existing\nbaselines across $6$ real-world datasets on accuracy, while being $22$ times\nfaster on average. Bonsai is grounded in rigorous mathematical guarantees on\nthe adopted approximation strategies making it robust to GNN architectures,\ndatasets, and parameters.\n","authors":["Mridul Gupta","Samyak Jain","Vansh Ramani","Hariprasad Kodamana","Sayan Ranu"],"pdf_url":"https://arxiv.org/pdf/2410.17579v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.03801v2","updated":"2024-10-23T06:05:11Z","published":"2024-10-04T08:14:24Z","title":"P1-KAN an effective Kolmogorov Arnold Network for function approximation","summary":"  A new Kolmogorov-Arnold network (KAN) is proposed to approximate potentially\nirregular functions in high dimension. We show that it outperforms multilayer\nperceptrons in terms of accuracy and converges faster. We also compare it with\nseveral proposed KAN networks: the original spline-based KAN network appears to\nbe more effective for smooth functions, while the P1-KAN network is more\neffective for irregular functions.\n","authors":["Xavier Warin"],"pdf_url":"https://arxiv.org/pdf/2410.03801v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.17574v1","updated":"2024-10-23T05:55:21Z","published":"2024-10-23T05:55:21Z","title":"Adversarial Domain Adaptation for Metal Cutting Sound Detection:\n  Leveraging Abundant Lab Data for Scarce Industry Data","summary":"  Cutting state monitoring in the milling process is crucial for improving\nmanufacturing efficiency and tool life. Cutting sound detection using machine\nlearning (ML) models, inspired by experienced machinists, can be employed as a\ncost-effective and non-intrusive monitoring method in a complex manufacturing\nenvironment. However, labeling industry data for training is costly and\ntime-consuming. Moreover, industry data is often scarce. In this study, we\npropose a novel adversarial domain adaptation (DA) approach to leverage\nabundant lab data to learn from scarce industry data, both labeled, for\ntraining a cutting-sound detection model. Rather than adapting the features\nfrom separate domains directly, we project them first into two separate latent\nspaces that jointly work as the feature space for learning domain-independent\nrepresentations. We also analyze two different mechanisms for adversarial\nlearning where the discriminator works as an adversary and a critic in separate\nsettings, enabling our model to learn expressive domain-invariant and\ndomain-ingrained features, respectively. We collected cutting sound data from\nmultiple sensors in different locations, prepared datasets from lab and\nindustry domain, and evaluated our learning models on them. Experiments showed\nthat our models outperformed the multi-layer perceptron based vanilla domain\nadaptation models in labeling tasks on the curated datasets, achieving near\n92%, 82% and 85% accuracy respectively for three different sensors installed in\nindustry settings.\n","authors":["Mir Imtiaz Mostafiz","Eunseob Kim","Adrian Shuai Li","Elisa Bertino","Martin Byung-Guk Jun","Ali Shakouri"],"pdf_url":"https://arxiv.org/pdf/2410.17574v1.pdf","comment":"8 pages, 3 figures, 3 tables, First two named Authors have equal\n  contribution (Co-first author)"},{"id":"http://arxiv.org/abs/2410.17573v1","updated":"2024-10-23T05:54:41Z","published":"2024-10-23T05:54:41Z","title":"Securing Federated Learning Against Novel and Classic Backdoor Threats\n  During Foundation Model Integration","summary":"  Federated learning (FL) enables decentralized model training while preserving\nprivacy. Recently, integrating Foundation Models (FMs) into FL has boosted\nperformance but also introduced a novel backdoor attack mechanism. Attackers\ncan exploit the FM's capabilities to embed backdoors into synthetic data\ngenerated by FMs used for model fusion, subsequently infecting all client\nmodels through knowledge sharing without involvement in the long-lasting FL\nprocess. These novel attacks render existing FL backdoor defenses ineffective,\nas they primarily detect anomalies among client updates, which may appear\nuniformly malicious under this attack. Our work proposes a novel data-free\ndefense strategy by constraining abnormal activations in the hidden feature\nspace during model aggregation on the server. The activation constraints,\noptimized using synthetic data alongside FL training, mitigate the attack while\nbarely affecting model performance, as the parameters remain untouched.\nExtensive experiments demonstrate its effectiveness against both novel and\nclassic backdoor attacks, outperforming existing defenses while maintaining\nmodel performance.\n","authors":["Xiaohuan Bi","Xi Li"],"pdf_url":"https://arxiv.org/pdf/2410.17573v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2409.17555v2","updated":"2024-10-23T05:49:00Z","published":"2024-09-26T05:57:35Z","title":"Advancing Open-Set Domain Generalization Using Evidential Bi-Level\n  Hardest Domain Scheduler","summary":"  In Open-Set Domain Generalization (OSDG), the model is exposed to both new\nvariations of data appearance (domains) and open-set conditions, where both\nknown and novel categories are present at test time. The challenges of this\ntask arise from the dual need to generalize across diverse domains and\naccurately quantify category novelty, which is critical for applications in\ndynamic environments. Recently, meta-learning techniques have demonstrated\nsuperior results in OSDG, effectively orchestrating the meta-train and -test\ntasks by employing varied random categories and predefined domain partition\nstrategies. These approaches prioritize a well-designed training schedule over\ntraditional methods that focus primarily on data augmentation and the\nenhancement of discriminative feature learning. The prevailing meta-learning\nmodels in OSDG typically utilize a predefined sequential domain scheduler to\nstructure data partitions. However, a crucial aspect that remains inadequately\nexplored is the influence brought by strategies of domain schedulers during\ntraining. In this paper, we observe that an adaptive domain scheduler benefits\nmore in OSDG compared with prefixed sequential and random domain schedulers. We\npropose the Evidential Bi-Level Hardest Domain Scheduler (EBiL-HaDS) to achieve\nan adaptive domain scheduler. This method strategically sequences domains by\nassessing their reliabilities in utilizing a follower network, trained with\nconfidence scores learned in an evidential manner, regularized by max rebiasing\ndiscrepancy, and optimized in a bi-level manner. The results show that our\nmethod substantially improves OSDG performance and achieves more discriminative\nembeddings for both the seen and unseen categories. The source code is publicly\navailable at https://github.com/KPeng9510/EBiL-HaDS.\n","authors":["Kunyu Peng","Di Wen","Kailun Yang","Ao Luo","Yufan Chen","Jia Fu","M. Saquib Sarfraz","Alina Roitberg","Rainer Stiefelhagen"],"pdf_url":"https://arxiv.org/pdf/2409.17555v2.pdf","comment":"Accepted to NeurIPS 2024. The source code is publicly available at\n  https://github.com/KPeng9510/EBiL-HaDS"},{"id":"http://arxiv.org/abs/2405.16194v3","updated":"2024-10-23T05:47:21Z","published":"2024-05-25T11:53:23Z","title":"Diffusion-Reward Adversarial Imitation Learning","summary":"  Imitation learning aims to learn a policy from observing expert\ndemonstrations without access to reward signals from environments. Generative\nadversarial imitation learning (GAIL) formulates imitation learning as\nadversarial learning, employing a generator policy learning to imitate expert\nbehaviors and discriminator learning to distinguish the expert demonstrations\nfrom agent trajectories. Despite its encouraging results, GAIL training is\noften brittle and unstable. Inspired by the recent dominance of diffusion\nmodels in generative modeling, we propose Diffusion-Reward Adversarial\nImitation Learning (DRAIL), which integrates a diffusion model into GAIL,\naiming to yield more robust and smoother rewards for policy learning.\nSpecifically, we propose a diffusion discriminative classifier to construct an\nenhanced discriminator, and design diffusion rewards based on the classifier's\noutput for policy learning. Extensive experiments are conducted in navigation,\nmanipulation, and locomotion, verifying DRAIL's effectiveness compared to prior\nimitation learning methods. Moreover, additional experimental results\ndemonstrate the generalizability and data efficiency of DRAIL. Visualized\nlearned reward functions of GAIL and DRAIL suggest that DRAIL can produce more\nrobust and smoother rewards. Project page:\nhttps://nturobotlearninglab.github.io/DRAIL/\n","authors":["Chun-Mao Lai","Hsiang-Chun Wang","Ping-Chun Hsieh","Yu-Chiang Frank Wang","Min-Hung Chen","Shao-Hua Sun"],"pdf_url":"https://arxiv.org/pdf/2405.16194v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.04869v3","updated":"2024-10-23T05:44:21Z","published":"2024-08-09T05:15:36Z","title":"UCB Exploration for Fixed-Budget Bayesian Best Arm Identification","summary":"  We study best-arm identification (BAI) in the fixed-budget setting. Adaptive\nallocations based on upper confidence bounds (UCBs), such as UCBE, are known to\nwork well in BAI. However, it is well-known that its optimal regret is\ntheoretically dependent on instances, which we show to be an artifact in many\nfixed-budget BAI problems. In this paper we propose an UCB exploration\nalgorithm that is both theoretically and empirically efficient for the fixed\nbudget BAI problem under a Bayesian setting. The key idea is to learn prior\ninformation, which can enhance the performance of UCB-based BAI algorithm as it\nhas done in the cumulative regret minimization problem. We establish bounds on\nthe failure probability and the simple regret for the Bayesian BAI problem,\nproviding upper bounds of order $\\tilde{O}(\\sqrt{K/n})$, up to logarithmic\nfactors, where $n$ represents the budget and $K$ denotes the number of arms.\nFurthermore, we demonstrate through empirical results that our approach\nconsistently outperforms state-of-the-art baselines.\n","authors":["Rong J. B. Zhu","Yanqi Qiu"],"pdf_url":"https://arxiv.org/pdf/2408.04869v3.pdf","comment":null}],"Information Retrieval":[{"id":"http://arxiv.org/abs/2402.16664v3","updated":"2024-10-23T16:27:48Z","published":"2024-02-26T15:35:24Z","title":"LLM-Assisted Multi-Teacher Continual Learning for Visual Question\n  Answering in Robotic Surgery","summary":"  Visual question answering (VQA) is crucial for promoting surgical education.\nIn practice, the needs of trainees are constantly evolving, such as learning\nmore surgical types, adapting to different robots, and learning new surgical\ninstruments and techniques for various surgeries. However, patient data privacy\noften restricts the availability of old data when updating the model,\nnecessitating an exemplar-free continual learning (CL) setup. Prior CL studies\noverlooked two vital problems in the surgical domain: 1) large domain shifts\nfrom diverse surgical operations collected from multiple sources, and 2) severe\ndata imbalance arising from the uneven presence of surgical instruments or\nactivities. This paper proposes addressing these problems with a multimodal\nlarge language model (LLM) and an adaptive weight assignment methodology. We\nfirst develop a new multi-teacher CL framework that leverages a multimodal LLM\nas the additional teacher. The strong generalization ability of the LLM can\nbridge the knowledge gap when domain shifts and data imbalances occur. We then\nput forth a novel data processing method that transforms complex LLM embeddings\ninto logits compatible with our CL framework. We further design an adaptive\nweight assignment approach that balances the generalization ability of the LLM\nand the domain expertise of the old CL model. Finally, to comprehensively test\nthe effectiveness of our proposed method, we have also constructed two new\nsurgical VQA datasets that are largely different from existing ones and could\nbe valuable resources for future research. Extensive experimental results on\nthe tested datasets demonstrate the superiority of our method to other advanced\nCL schemes.\n","authors":["Yuyang Du","Kexin Chen","Yue Zhan","Chang Han Low","Tao You","Mobarakol Islam","Ziyu Guo","Yueming Jin","Guangyong Chen","Pheng-Ann Heng"],"pdf_url":"https://arxiv.org/pdf/2402.16664v3.pdf","comment":"This paper has been accapted by 2024 IEEE International Conference on\n  Robotics and Automation (ICRA)"},{"id":"http://arxiv.org/abs/2410.17952v1","updated":"2024-10-23T15:24:16Z","published":"2024-10-23T15:24:16Z","title":"SimRAG: Self-Improving Retrieval-Augmented Generation for Adapting Large\n  Language Models to Specialized Domains","summary":"  Retrieval-augmented generation (RAG) enhances the question-answering (QA)\nabilities of large language models (LLMs) by integrating external knowledge.\nHowever, adapting general-purpose RAG systems to specialized fields such as\nscience and medicine poses unique challenges due to distribution shifts and\nlimited access to domain-specific data. To tackle this, we propose SimRAG, a\nself-training approach that equips the LLM with joint capabilities of question\nanswering and question generation for domain adaptation. Our method first\nfine-tunes the LLM on instruction-following, question-answering, and\nsearch-related data. Then, it prompts the same LLM to generate diverse\ndomain-relevant questions from unlabeled corpora, with an additional filtering\nstrategy to retain high-quality synthetic examples. By leveraging these\nsynthetic examples, the LLM can improve their performance on domain-specific\nRAG tasks. Experiments on 11 datasets, spanning two backbone sizes and three\ndomains, demonstrate that SimRAG outperforms baselines by 1.2\\%--8.6\\%.\n","authors":["Ran Xu","Hui Liu","Sreyashi Nag","Zhenwei Dai","Yaochen Xie","Xianfeng Tang","Chen Luo","Yang Li","Joyce C. Ho","Carl Yang","Qi He"],"pdf_url":"https://arxiv.org/pdf/2410.17952v1.pdf","comment":"Work in Progress"},{"id":"http://arxiv.org/abs/2410.17734v1","updated":"2024-10-23T10:07:13Z","published":"2024-10-23T10:07:13Z","title":"YOLO-Vehicle-Pro: A Cloud-Edge Collaborative Framework for Object\n  Detection in Autonomous Driving under Adverse Weather Conditions","summary":"  With the rapid advancement of autonomous driving technology, efficient and\naccurate object detection capabilities have become crucial factors in ensuring\nthe safety and reliability of autonomous driving systems. However, in\nlow-visibility environments such as hazy conditions, the performance of\ntraditional object detection algorithms often degrades significantly, failing\nto meet the demands of autonomous driving. To address this challenge, this\npaper proposes two innovative deep learning models: YOLO-Vehicle and\nYOLO-Vehicle-Pro. YOLO-Vehicle is an object detection model tailored\nspecifically for autonomous driving scenarios, employing multimodal fusion\ntechniques to combine image and textual information for object detection.\nYOLO-Vehicle-Pro builds upon this foundation by introducing an improved image\ndehazing algorithm, enhancing detection performance in low-visibility\nenvironments. In addition to model innovation, this paper also designs and\nimplements a cloud-edge collaborative object detection system, deploying models\non edge devices and offloading partial computational tasks to the cloud in\ncomplex situations. Experimental results demonstrate that on the KITTI dataset,\nthe YOLO-Vehicle-v1s model achieved 92.1% accuracy while maintaining a\ndetection speed of 226 FPS and an inference time of 12ms, meeting the real-time\nrequirements of autonomous driving. When processing hazy images, the\nYOLO-Vehicle-Pro model achieved a high accuracy of 82.3% mAP@50 on the Foggy\nCityscapes dataset while maintaining a detection speed of 43 FPS.\n","authors":["Xiguang Li","Jiafu Chen","Yunhe Sun","Na Lin","Ammar Hawbani","Liang Zhao"],"pdf_url":"https://arxiv.org/pdf/2410.17734v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2402.14622v2","updated":"2024-10-23T10:06:10Z","published":"2024-02-22T15:10:45Z","title":"From Keywords to Structured Summaries: Streamlining Scholarly\n  Information Access","summary":"  This paper highlights the growing importance of information retrieval (IR)\nengines in the scientific community, addressing the inefficiency of traditional\nkeyword-based search engines due to the rising volume of publications. The\nproposed solution involves structured records, underpinning advanced\ninformation technology (IT) tools, including visualization dashboards, to\nrevolutionize how researchers access and filter articles, replacing the\ntraditional text-heavy approach. This vision is exemplified through a proof of\nconcept centered on the \"reproductive number estimate of infectious diseases\"\nresearch theme, using a fine-tuned large language model (LLM) to automate the\ncreation of structured records to populate a backend database that now goes\nbeyond keywords. The result is a next-generation information access system as\nan IR method accessible at https://orkg.org/usecases/r0-estimates.\n","authors":["Mahsa Shamsabadi","Jennifer D'Souza"],"pdf_url":"https://arxiv.org/pdf/2402.14622v2.pdf","comment":"8 pages, 3 figures | Accepted for publication as a poster paper at\n  the International Semantic Web Conference (ISWC 2024)"},{"id":"http://arxiv.org/abs/2410.17651v1","updated":"2024-10-23T08:09:48Z","published":"2024-10-23T08:09:48Z","title":"Testing Deep Learning Recommender Systems Models on Synthetic\n  GAN-Generated Datasets","summary":"  The published method Generative Adversarial Networks for Recommender Systems\n(GANRS) allows generating data sets for collaborative filtering recommendation\nsystems. The GANRS source code is available along with a representative set of\ngenerated datasets. We have tested the GANRS method by creating multiple\nsynthetic datasets from three different real datasets taken as a source.\nExperiments include variations in the number of users in the synthetic\ndatasets, as well as a different number of samples. We have also selected six\nstate-of-the-art collaborative filtering deep learning models to test both\ntheir comparative performance and the GANRS method. The results show a\nconsistent behavior of the generated datasets compared to the source ones;\nparticularly, in the obtained values and trends of the precision and recall\nquality measures. The tested deep learning models have also performed as\nexpected on all synthetic datasets, making it possible to compare the results\nwith those obtained from the real source data. Future work is proposed,\nincluding different cold start scenarios, unbalanced data, and demographic\nfairness.\n","authors":["Jesús Bobadilla","Abraham Gutiérrez"],"pdf_url":"https://arxiv.org/pdf/2410.17651v1.pdf","comment":"10 pages, 7 figures, In press"},{"id":"http://arxiv.org/abs/2410.17644v1","updated":"2024-10-23T08:01:07Z","published":"2024-10-23T08:01:07Z","title":"Comprehensive Evaluation of Matrix Factorization Models for\n  Collaborative Filtering Recommender Systems","summary":"  Matrix factorization models are the core of current commercial collaborative\nfiltering Recommender Systems. This paper tested six representative matrix\nfactorization models, using four collaborative filtering datasets. Experiments\nhave tested a variety of accuracy and beyond accuracy quality measures,\nincluding prediction, recommendation of ordered and unordered lists, novelty,\nand diversity. Results show each convenient matrix factorization model\nattending to their simplicity, the required prediction quality, the necessary\nrecommendation quality, the desired recommendation novelty and diversity, the\nneed to explain recommendations, the adequacy of assigning semantic\ninterpretations to hidden factors, the advisability of recommending to groups\nof users, and the need to obtain reliability values. To ensure the\nreproducibility of the experiments, an open framework has been used, and the\nimplementation code is provided.\n","authors":["Jesús Bobadilla","Jorge Dueñas-Lerín","Fernando Ortega","Abraham Gutierrez"],"pdf_url":"https://arxiv.org/pdf/2410.17644v1.pdf","comment":"10 pages, 5 figures"},{"id":"http://arxiv.org/abs/2410.17614v1","updated":"2024-10-23T07:11:48Z","published":"2024-10-23T07:11:48Z","title":"Extending and Applying Automated HERMES Software Publication Workflows","summary":"  Research software is an import output of research and must be published\naccording to the FAIR Principles for Research Software. This can be achieved by\npublishing software with metadata under a persistent identifier. HERMES is a\ntool that leverages continuous integration to automate the publication of\nsoftware with rich metadata. In this work, we describe the HERMES workflow\nitself, and how to extend it to meet the needs of specific research software\nmetadata or infrastructure. We introduce the HERMES plugin architecture and\nprovide the example of creating a new HERMES plugin that harvests metadata from\na metadata source in source code repositories. We show how to use HERMES as an\nend user, both via the command line interface, and as a step in a continuous\nintegration pipeline. Finally, we report three informal case studies whose\nresults provide a preliminary evaluation of the feasibility and applicability\nof HERMES workflows, and the extensibility of the hermes software package.\n","authors":["Sophie Kernchen","Michael Meinel","Stephan Druskat","Michael Fritzsche","David Pape","Oliver Bertuch"],"pdf_url":"https://arxiv.org/pdf/2410.17614v1.pdf","comment":"17 pages, 2 figures, 2 tables, submitted to a special issue of\n  Electronic Communications of the EASST collecting submissions of deRSE24,\n  Conference for Research Software Engineers"},{"id":"http://arxiv.org/abs/2403.06737v2","updated":"2024-10-23T02:00:35Z","published":"2024-03-11T14:02:24Z","title":"Post-Training Attribute Unlearning in Recommender Systems","summary":"  With the growing privacy concerns in recommender systems, recommendation\nunlearning is getting increasing attention. Existing studies predominantly use\ntraining data, i.e., model inputs, as unlearning target. However, attackers can\nextract private information from the model even if it has not been explicitly\nencountered during training. We name this unseen information as\n\\textit{attribute} and treat it as unlearning target. To protect the sensitive\nattribute of users, Attribute Unlearning (AU) aims to make target attributes\nindistinguishable. In this paper, we focus on a strict but practical setting of\nAU, namely Post-Training Attribute Unlearning (PoT-AU), where unlearning can\nonly be performed after the training of the recommendation model is completed.\nTo address the PoT-AU problem in recommender systems, we propose a\ntwo-component loss function. The first component is distinguishability loss,\nwhere we design a distribution-based measurement to make attribute labels\nindistinguishable from attackers. We further extend this measurement to handle\nmulti-class attribute cases with efficient computational overhead. The second\ncomponent is regularization loss, where we explore a function-space measurement\nthat effectively maintains recommendation performance compared to\nparameter-space regularization. We use stochastic gradient descent algorithm to\noptimize our proposed loss. Extensive experiments on four real-world datasets\ndemonstrate the effectiveness of our proposed methods.\n","authors":["Chaochao Chen","Yizhao Zhang","Yuyuan Li","Dan Meng","Jun Wang","Xiaoli Zheng","Jianwei Yin"],"pdf_url":"https://arxiv.org/pdf/2403.06737v2.pdf","comment":"Accepted by TOIS. arXiv admin note: text overlap with\n  arXiv:2310.05847"},{"id":"http://arxiv.org/abs/2410.13707v2","updated":"2024-10-23T19:12:05Z","published":"2024-10-17T16:07:51Z","title":"Disjointness Violations in Wikidata","summary":"  Disjointness checks are among the most important constraint checks in a\nknowledge base and can be used to help detect and correct incorrect statements\nand internal contradictions. Wikidata is a very large, community-managed\nknowledge base. Because of both its size and construction, Wikidata contains\nmany incorrect statements and internal contradictions. We analyze the current\nmodeling of disjointness on Wikidata, identify patterns that cause these\ndisjointness violations and categorize them. We use SPARQL queries to identify\neach ``culprit'' causing a disjointness violation and lay out formulas to\nidentify and fix conflicting information. We finally discuss how disjointness\ninformation could be better modeled and expanded in Wikidata in the future.\n","authors":["Ege Atacan Doğan","Peter F. Patel-Schneider"],"pdf_url":"https://arxiv.org/pdf/2410.13707v2.pdf","comment":"Sixth International Knowledge Graph and Semantic Web Conference"}]},"2024-10-24T00:00:00Z":{"Computation and Language":[{"id":"http://arxiv.org/abs/2410.17820v2","updated":"2024-10-24T12:01:31Z","published":"2024-10-23T12:26:10Z","title":"Understanding When Tree of Thoughts Succeeds: Larger Models Excel in\n  Generation, Not Discrimination","summary":"  Tree of Thoughts (ToT) is a reasoning strategy for Large Language Models\n(LLMs) that employs a generator to suggest reasoning steps and a discriminator\nto decide which steps to implement. ToT demonstrates strong performance on\nreasoning tasks, often surpassing simple methods such as Input-Output (IO)\nprompting and Chain-of-Thought (CoT) reasoning. However, ToT does not\nconsistently outperform such simpler methods across all models, leaving large\nknowledge gaps on the conditions under which ToT is most beneficial. In this\npaper, we analyze the roles of the generator and discriminator separately to\nbetter understand the conditions when ToT is beneficial. We find that the\ngenerator plays a more critical role than the discriminator in driving the\nsuccess of ToT. Scaling the generator leads to notable improvements in ToT\nperformance, even when using a smaller model as the discriminator, whereas\nscaling the discriminator with a fixed generator yields only marginal gains.\nOur results show that models across different scales exhibit comparable\ndiscrimination capabilities, yet differ significantly in their generative\nperformance for ToT.\n","authors":["Qiqi Chen","Xinpeng Wang","Philipp Mondorf","Michael A. Hedderich","Barbara Plank"],"pdf_url":"https://arxiv.org/pdf/2410.17820v2.pdf","comment":"Code: github.com/mainlp/tot-eval"},{"id":"http://arxiv.org/abs/2406.05804v5","updated":"2024-10-24T07:07:43Z","published":"2024-06-09T14:42:55Z","title":"A Review of Prominent Paradigms for LLM-Based Agents: Tool Use\n  (Including RAG), Planning, and Feedback Learning","summary":"  Tool use, planning, and feedback learning are currently three prominent\nparadigms for developing Large Language Model (LLM)-based agents across various\ntasks. Although numerous frameworks have been devised for each paradigm, their\nintricate workflows and inconsistent taxonomy create challenges in\nunderstanding and reviewing the frameworks across different paradigms. This\nsurvey introduces a unified taxonomy to systematically review and discuss these\nframeworks. Specifically, 1) the taxonomy defines environments/tasks, common\nLLM-profiled roles or LMPRs (policy models, evaluators, and dynamic models),\nand universally applicable workflows found in prior work, and 2) it enables a\ncomparison of key perspectives on the implementations of LMPRs and workflow\ndesigns across different agent paradigms and frameworks. 3) Finally, we\nidentify three limitations in existing workflow designs and systematically\ndiscuss the future work. Resources have been made publicly available at in our\nGitHub repository https://github.com/xinzhel/LLM-Agent-Survey.\n","authors":["Xinzhe Li"],"pdf_url":"https://arxiv.org/pdf/2406.05804v5.pdf","comment":"Under Review"},{"id":"http://arxiv.org/abs/2410.17552v2","updated":"2024-10-24T02:35:09Z","published":"2024-10-23T04:34:49Z","title":"ESpeW: Robust Copyright Protection for LLM-based EaaS via\n  Embedding-Specific Watermark","summary":"  Embeddings as a Service (EaaS) is emerging as a crucial role in AI\napplications. Unfortunately, EaaS is vulnerable to model extraction attacks,\nhighlighting the urgent need for copyright protection. Although some\npreliminary works propose applying embedding watermarks to protect EaaS, recent\nresearch reveals that these watermarks can be easily removed. Hence, it is\ncrucial to inject robust watermarks resistant to watermark removal attacks.\nExisting watermarking methods typically inject a target embedding into\nembeddings through linear interpolation when the text contains triggers.\nHowever, this mechanism results in each watermarked embedding having the same\ncomponent, which makes the watermark easy to identify and eliminate. Motivated\nby this, in this paper, we propose a novel embedding-specific watermarking\n(ESpeW) mechanism to offer robust copyright protection for EaaS. Our approach\ninvolves injecting unique, yet readily identifiable watermarks into each\nembedding. Watermarks inserted by ESpeW are designed to maintain a significant\ndistance from one another and to avoid sharing common components, thus making\nit significantly more challenging to remove the watermarks. Extensive\nexperiments on four popular datasets demonstrate that ESpeW can even watermark\nsuccessfully against a highly aggressive removal strategy without sacrificing\nthe quality of embeddings. Code is available at\nhttps://github.com/liudan193/ESpeW.\n","authors":["Zongqi Wang","Baoyuan Wu","Jingyuan Deng","Yujiu Yang"],"pdf_url":"https://arxiv.org/pdf/2410.17552v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.17546v2","updated":"2024-10-24T04:21:54Z","published":"2024-10-23T03:53:46Z","title":"Advancing Interpretability in Text Classification through Prototype\n  Learning","summary":"  Deep neural networks have achieved remarkable performance in various\ntext-based tasks but often lack interpretability, making them less suitable for\napplications where transparency is critical. To address this, we propose\nProtoLens, a novel prototype-based model that provides fine-grained,\nsub-sentence level interpretability for text classification. ProtoLens uses a\nPrototype-aware Span Extraction module to identify relevant text spans\nassociated with learned prototypes and a Prototype Alignment mechanism to\nensure prototypes are semantically meaningful throughout training. By aligning\nthe prototype embeddings with human-understandable examples, ProtoLens provides\ninterpretable predictions while maintaining competitive accuracy. Extensive\nexperiments demonstrate that ProtoLens outperforms both prototype-based and\nnon-interpretable baselines on multiple text classification benchmarks. Code\nand data are available at\n\\url{https://anonymous.4open.science/r/ProtoLens-CE0B/}.\n","authors":["Bowen Wei","Ziwei Zhu"],"pdf_url":"https://arxiv.org/pdf/2410.17546v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.17450v2","updated":"2024-10-24T17:38:44Z","published":"2024-10-22T21:55:54Z","title":"Interação entre robôs humanoides: desenvolvendo a\n  colaboração e comunicação autônoma","summary":"  This study investigates the interaction between humanoid robots NAO and\nPepper, emphasizing their potential applications in educational settings. NAO,\nwidely used in education, and Pepper, designed for social interactions, of er\nnew opportunities for autonomous communication and collaboration. Through a\nseries of programmed interactions, the robots demonstrated their ability to\ncommunicate and coordinate actions autonomously, highlighting their potential\nas tools for enhancing learning environments. The research also explores the\nintegration of emerging technologies, such as artificial intelligence, into\nthese systems, allowing robots to learn from each other and adapt their\nbehavior. The findings suggest that NAO and Pepper can significantly contribute\nto both technical learning and the development of social and emotional skills\nin students, of ering innovative pedagogical approaches through the use of\nhumanoid robotics.\n","authors":["Moraes Pablo","Rodríguez Mónica","Peters Christopher","Sodre Hiago","Mazondo Ahilen","Sandin Vincent","Barcelona Sebastian","Moraes William","Fernández Santiago","Assunção Nathalie","de Vargas Bruna","Dörnbach Tobias","Kelbouscas André","Grando Ricardo"],"pdf_url":"https://arxiv.org/pdf/2410.17450v2.pdf","comment":"in Portuguese language"},{"id":"http://arxiv.org/abs/2410.17439v2","updated":"2024-10-24T13:34:47Z","published":"2024-10-22T21:30:58Z","title":"Evaluating AI-Generated Essays with GRE Analytical Writing Assessment","summary":"  The recent revolutionary advance in generative AI enables the generation of\nrealistic and coherent texts by large language models (LLMs). Despite many\nexisting evaluation metrics on the quality of the generated texts, there is\nstill a lack of rigorous assessment of how well LLMs perform in complex and\ndemanding writing assessments. This study examines essays generated by ten\nleading LLMs for the analytical writing assessment of the Graduate Record Exam\n(GRE). We assessed these essays using both human raters and the e-rater\nautomated scoring engine as used in the GRE scoring pipeline. Notably, the\ntop-performing Gemini and GPT-4o received an average score of 4.78 and 4.67,\nrespectively, falling between \"generally thoughtful, well-developed analysis of\nthe issue and conveys meaning clearly\" and \"presents a competent analysis of\nthe issue and conveys meaning with acceptable clarity\" according to the GRE\nscoring guideline. We also evaluated the detection accuracy of these essays,\nwith detectors trained on essays generated by the same and different LLMs.\n","authors":["Yang Zhong","Jiangang Hao","Michael Fauss","Chen Li","Yuan Wang"],"pdf_url":"https://arxiv.org/pdf/2410.17439v2.pdf","comment":"20 pages, 6 figures"},{"id":"http://arxiv.org/abs/2407.12883v3","updated":"2024-10-24T04:51:21Z","published":"2024-07-16T17:58:27Z","title":"BRIGHT: A Realistic and Challenging Benchmark for Reasoning-Intensive\n  Retrieval","summary":"  Existing retrieval benchmarks primarily consist of information-seeking\nqueries (e.g., aggregated questions from search engines) where keyword or\nsemantic-based retrieval is usually sufficient. However, many complex\nreal-world queries require in-depth reasoning to identify relevant documents\nthat go beyond surface form matching. For example, finding documentation for a\ncoding question requires understanding the logic and syntax of the functions\ninvolved. To better benchmark retrieval on such challenging queries, we\nintroduce BRIGHT, the first text retrieval benchmark that requires intensive\nreasoning to retrieve relevant documents. Our dataset consists of 1,384\nreal-world queries spanning diverse domains, such as economics, psychology,\nmathematics, and coding. These queries are drawn from naturally occurring and\ncarefully curated human data. Extensive evaluation reveals that even\nstate-of-the-art retrieval models perform poorly on BRIGHT. The leading model\non the MTEB leaderboard (Muennighoff et al., 2023), which achieves a score of\n59.0 nDCG@10, produces a score of nDCG@10 of 18.3 on BRIGHT. We show that\nincorporating explicit reasoning about the query improves retrieval performance\nby up to 12.2 points. Moreover, incorporating retrieved documents from the\ntop-performing retriever boosts question-answering performance by over 6.6\npoints. We believe that BRIGHT paves the way for future research on retrieval\nsystems in more realistic and challenging settings.\n","authors":["Hongjin Su","Howard Yen","Mengzhou Xia","Weijia Shi","Niklas Muennighoff","Han-yu Wang","Haisu Liu","Quan Shi","Zachary S. Siegel","Michael Tang","Ruoxi Sun","Jinsung Yoon","Sercan O. Arik","Danqi Chen","Tao Yu"],"pdf_url":"https://arxiv.org/pdf/2407.12883v3.pdf","comment":"48 pages"}],"Computer Vision and Pattern Recognition":[{"id":"http://arxiv.org/abs/2404.08401v4","updated":"2024-10-24T14:41:42Z","published":"2024-04-12T11:15:15Z","title":"PnLCalib: Sports Field Registration via Points and Lines Optimization","summary":"  Camera calibration in broadcast sports videos presents numerous challenges\nfor accurate sports field registration due to multiple camera angles, varying\ncamera parameters, and frequent occlusions of the field. Traditional\nsearch-based methods depend on initial camera pose estimates, which can\nstruggle in non-standard positions and dynamic environments. In response, we\npropose an optimization-based calibration pipeline that leverages a 3D soccer\nfield model and a predefined set of keypoints to overcome these limitations.\nOur method also introduces a novel refinement module that improves initial\ncalibration by using detected field lines in a non-linear optimization process.\nThis approach outperforms existing techniques in both multi-view and\nsingle-view 3D camera calibration tasks, while maintaining competitive\nperformance in homography estimation. Extensive experimentation on real-world\nsoccer datasets, including SoccerNet-Calibration, WorldCup 2014, and\nTS-WorldCup, highlights the robustness and accuracy of our method across\ndiverse broadcast scenarios. Our approach offers significant improvements in\ncamera calibration precision and reliability.\n","authors":["Marc Gutiérrez-Pérez","Antonio Agudo"],"pdf_url":"https://arxiv.org/pdf/2404.08401v4.pdf","comment":"Extended version of \"No Bells, Just Whistles: Sports Field\n  Registration Leveraging Geometric Properties\""},{"id":"http://arxiv.org/abs/2408.14947v3","updated":"2024-10-24T04:57:51Z","published":"2024-08-27T10:44:34Z","title":"ERX: A Fast Real-Time Anomaly Detection Algorithm for Hyperspectral Line\n  Scanning","summary":"  Detecting unexpected objects (anomalies) in real time has great potential for\nmonitoring, managing, and protecting the environment. Hyperspectral line-scan\ncameras are a low-cost solution that enhance confidence in anomaly detection\nover RGB and multispectral imagery. However, existing line-scan algorithms are\ntoo slow when using small computers (e.g. those onboard a drone or small\nsatellite), do not adapt to changing scenery, or lack robustness against\ngeometric distortions. This paper introduces the Exponentially moving RX\nalgorithm (ERX) to address these issues, and compares it with existing RX-based\nanomaly detection methods for hyperspectral line scanning. Three large and more\ncomplex datasets are also introduced to better assess the practical challenges\nwhen using line-scan cameras (two hyperspectral and one multispectral). ERX is\nevaluated using a Jetson Xavier NX compute module, achieving the best\ncombination of speed and detection performance. This research paves the way for\nfuture studies in grouping and locating anomalous objects, adaptive and\nautomatic threshold selection, and real-time field tests. The datasets and the\nPython code are available at: https://github.com/WiseGamgee/HyperAD.\n","authors":["Samuel Garske","Bradley Evans","Christopher Artlett","KC Wong"],"pdf_url":"https://arxiv.org/pdf/2408.14947v3.pdf","comment":"17 pages, 13 figures, 4 tables, code and datasets accessible at\n  https://github.com/WiseGamgee/HyperAD"},{"id":"http://arxiv.org/abs/2305.19599v5","updated":"2024-10-24T03:14:22Z","published":"2023-05-31T06:59:21Z","title":"RealignDiff: Boosting Text-to-Image Diffusion Model with Coarse-to-fine\n  Semantic Re-alignment","summary":"  Recent advances in text-to-image diffusion models have achieved remarkable\nsuccess in generating high-quality, realistic images from textual descriptions.\nHowever, these approaches have faced challenges in precisely aligning the\ngenerated visual content with the textual concepts described in the prompts. In\nthis paper, we propose a two-stage coarse-to-fine semantic re-alignment method,\nnamed RealignDiff, aimed at improving the alignment between text and images in\ntext-to-image diffusion models. In the coarse semantic re-alignment phase, a\nnovel caption reward, leveraging the BLIP-2 model, is proposed to evaluate the\nsemantic discrepancy between the generated image caption and the given text\nprompt. Subsequently, the fine semantic re-alignment stage employs a local\ndense caption generation module and a re-weighting attention modulation module\nto refine the previously generated images from a local semantic view.\nExperimental results on the MS-COCO and ViLG-300 datasets demonstrate that the\nproposed two-stage coarse-to-fine semantic re-alignment method outperforms\nother baseline re-alignment techniques by a substantial margin in both visual\nquality and semantic similarity with the input prompt.\n","authors":["Zutao Jiang","Guian Fang","Jianhua Han","Guansong Lu","Hang Xu","Shengcai Liao","Xiaojun Chang","Xiaodan Liang"],"pdf_url":"https://arxiv.org/pdf/2305.19599v5.pdf","comment":null}],"Information Retrieval":[{"id":"http://arxiv.org/abs/2403.06737v3","updated":"2024-10-24T02:15:32Z","published":"2024-03-11T14:02:24Z","title":"Post-Training Attribute Unlearning in Recommender Systems","summary":"  With the growing privacy concerns in recommender systems, recommendation\nunlearning is getting increasing attention. Existing studies predominantly use\ntraining data, i.e., model inputs, as unlearning target. However, attackers can\nextract private information from the model even if it has not been explicitly\nencountered during training. We name this unseen information as\n\\textit{attribute} and treat it as unlearning target. To protect the sensitive\nattribute of users, Attribute Unlearning (AU) aims to make target attributes\nindistinguishable. In this paper, we focus on a strict but practical setting of\nAU, namely Post-Training Attribute Unlearning (PoT-AU), where unlearning can\nonly be performed after the training of the recommendation model is completed.\nTo address the PoT-AU problem in recommender systems, we propose a\ntwo-component loss function. The first component is distinguishability loss,\nwhere we design a distribution-based measurement to make attribute labels\nindistinguishable from attackers. We further extend this measurement to handle\nmulti-class attribute cases with efficient computational overhead. The second\ncomponent is regularization loss, where we explore a function-space measurement\nthat effectively maintains recommendation performance compared to\nparameter-space regularization. We use stochastic gradient descent algorithm to\noptimize our proposed loss. Extensive experiments on four real-world datasets\ndemonstrate the effectiveness of our proposed methods.\n","authors":["Chaochao Chen","Yizhao Zhang","Yuyuan Li","Jun Wang","Lianyong Qi","Xiaolong Xu","Xiaolin Zheng","Jianwei Yin"],"pdf_url":"https://arxiv.org/pdf/2403.06737v3.pdf","comment":"Accepted by TOIS"},{"id":"http://arxiv.org/abs/2407.12883v3","updated":"2024-10-24T04:51:21Z","published":"2024-07-16T17:58:27Z","title":"BRIGHT: A Realistic and Challenging Benchmark for Reasoning-Intensive\n  Retrieval","summary":"  Existing retrieval benchmarks primarily consist of information-seeking\nqueries (e.g., aggregated questions from search engines) where keyword or\nsemantic-based retrieval is usually sufficient. However, many complex\nreal-world queries require in-depth reasoning to identify relevant documents\nthat go beyond surface form matching. For example, finding documentation for a\ncoding question requires understanding the logic and syntax of the functions\ninvolved. To better benchmark retrieval on such challenging queries, we\nintroduce BRIGHT, the first text retrieval benchmark that requires intensive\nreasoning to retrieve relevant documents. Our dataset consists of 1,384\nreal-world queries spanning diverse domains, such as economics, psychology,\nmathematics, and coding. These queries are drawn from naturally occurring and\ncarefully curated human data. Extensive evaluation reveals that even\nstate-of-the-art retrieval models perform poorly on BRIGHT. The leading model\non the MTEB leaderboard (Muennighoff et al., 2023), which achieves a score of\n59.0 nDCG@10, produces a score of nDCG@10 of 18.3 on BRIGHT. We show that\nincorporating explicit reasoning about the query improves retrieval performance\nby up to 12.2 points. Moreover, incorporating retrieved documents from the\ntop-performing retriever boosts question-answering performance by over 6.6\npoints. We believe that BRIGHT paves the way for future research on retrieval\nsystems in more realistic and challenging settings.\n","authors":["Hongjin Su","Howard Yen","Mengzhou Xia","Weijia Shi","Niklas Muennighoff","Han-yu Wang","Haisu Liu","Quan Shi","Zachary S. Siegel","Michael Tang","Ruoxi Sun","Jinsung Yoon","Sercan O. Arik","Danqi Chen","Tao Yu"],"pdf_url":"https://arxiv.org/pdf/2407.12883v3.pdf","comment":"48 pages"},{"id":"http://arxiv.org/abs/2410.14066v3","updated":"2024-10-24T13:28:18Z","published":"2024-10-17T22:28:07Z","title":"Lightweight Correlation-Aware Table Compression","summary":"  The growing adoption of data lakes for managing relational data necessitates\nefficient, open storage formats that provide high scan performance and\ncompetitive compression ratios. While existing formats achieve fast scans\nthrough lightweight encoding techniques, they have reached a plateau in terms\nof minimizing storage footprint. Recently, correlation-aware compression\nschemes have been shown to reduce file sizes further. Yet, current approaches\neither incur significant scan overheads or require manual specification of\ncorrelations, limiting their practicability. We present $\\texttt{Virtual}$, a\nframework that integrates seamlessly with existing open formats to\nautomatically leverage data correlations, achieving substantial compression\ngains while having minimal scan performance overhead. Experiments on data-gov\ndatasets show that $\\texttt{Virtual}$ reduces file sizes by up to 40% compared\nto Apache Parquet.\n","authors":["Mihail Stoian","Alexander van Renen","Jan Kobiolka","Ping-Lin Kuo","Josif Grabocka","Andreas Kipf"],"pdf_url":"https://arxiv.org/pdf/2410.14066v3.pdf","comment":"Third Table Representation Learning Workshop (TRL @ NeurIPS 2024)"}],"Machine Learning":[{"id":"http://arxiv.org/abs/2410.17998v2","updated":"2024-10-24T17:47:20Z","published":"2024-10-23T16:12:59Z","title":"Estimating the Spectral Moments of the Kernel Integral Operator from\n  Finite Sample Matrices","summary":"  Analyzing the structure of sampled features from an input data distribution\nis challenging when constrained by limited measurements in both the number of\ninputs and features. Traditional approaches often rely on the eigenvalue\nspectrum of the sample covariance matrix derived from finite measurement\nmatrices; however, these spectra are sensitive to the size of the measurement\nmatrix, leading to biased insights. In this paper, we introduce a novel\nalgorithm that provides unbiased estimates of the spectral moments of the\nkernel integral operator in the limit of infinite inputs and features from\nfinitely sampled measurement matrices. Our method, based on dynamic\nprogramming, is efficient and capable of estimating the moments of the operator\nspectrum. We demonstrate the accuracy of our estimator on radial basis function\n(RBF) kernels, highlighting its consistency with the theoretical spectra.\nFurthermore, we showcase the practical utility and robustness of our method in\nunderstanding the geometry of learned representations in neural networks.\n","authors":["Chanwoo Chun","SueYeon Chung","Daniel D. Lee"],"pdf_url":"https://arxiv.org/pdf/2410.17998v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.17579v2","updated":"2024-10-24T05:24:53Z","published":"2024-10-23T06:08:45Z","title":"Bonsai: Gradient-free Graph Distillation for Node Classification","summary":"  Graph distillation has emerged as a promising avenue to enable scalable\ntraining of GNNs by compressing the training dataset while preserving essential\ngraph characteristics. Our study uncovers significant shortcomings in current\ngraph distillation techniques. First, the majority of the algorithms\nparadoxically require training on the full dataset to perform distillation.\nSecond, due to their gradient-emulating approach, these methods require fresh\ndistillation for any change in hyperparameters or GNN architecture, limiting\ntheir flexibility and reusability. Finally, they fail to achieve substantial\nsize reduction due to synthesizing fully-connected, edge-weighted graphs. To\naddress these challenges, we present Bonsai, a novel graph distillation method\nempowered by the observation that \\textit{computation trees} form the\nfundamental processing units of message-passing GNNs. Bonsai distills datasets\nby encoding a careful selection of \\textit{exemplar} trees that maximize the\nrepresentation of all computation trees in the training set. This unique\napproach imparts Bonsai as the first linear-time, model-agnostic graph\ndistillation algorithm for node classification that outperforms existing\nbaselines across $6$ real-world datasets on accuracy, while being $22$ times\nfaster on average. Bonsai is grounded in rigorous mathematical guarantees on\nthe adopted approximation strategies making it robust to GNN architectures,\ndatasets, and parameters.\n","authors":["Mridul Gupta","Samyak Jain","Vansh Ramani","Hariprasad Kodamana","Sayan Ranu"],"pdf_url":"https://arxiv.org/pdf/2410.17579v2.pdf","comment":null}]}}